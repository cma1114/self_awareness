{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab14e8de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading main GPQA dataset for features...\n",
      "Attempting to load GPQA (train split)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since Idavidrein/gpqa couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'gpqa_main' at /Users/christopherackerman/.cache/huggingface/datasets/Idavidrein___gpqa/gpqa_main/0.0.0/90b8e5be2b1d3d2dbfe016cdab47981150600c4a (last modified on Tue May 20 13:25:45 2025).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPQA Dataset loaded successfully.\n",
      "Formatting 448 questions from GPQA...\n",
      "Warning: Only able to format 447 unique questions, but 448 were requested.\n",
      "Successfully formatted 447 unique questions from GPQA.\n",
      "GPQA feature lookup created with 447 entries.\n",
      "\n",
      "--- Analyzing Model from Game File: claude-3-5-sonnet-20241022_GPQA_100_100_team0.6_1747406864_game_data.json (feedback=False) ---\n",
      "----------------------------------------\n",
      "\n",
      "--- Analyzing Model from Game File: claude-3-5-sonnet-20241022_GPQA_100_100_team0.6_1747407886_game_data.json (feedback=True) ---\n",
      "----------------------------------------\n",
      "\n",
      "--- Analyzing Model from Game File: claude-3-5-sonnet-20241022_GPQA_100_100_team0.6_temp0.0_nobio_1747770061_game_data.json (feedback=False) ---\n",
      "----------------------------------------\n",
      "\n",
      "--- Analyzing Model from Game File: claude-3-5-sonnet-20241022_GPQA_50_100_team0.65_1747405864_game_data.json (feedback=False) ---\n",
      "----------------------------------------\n",
      "\n",
      "--- Analyzing Model from Game File: claude-3-5-sonnet-20241022_GPQA_50_100_team0.6_1747406304_game_data.json (feedback=False) ---\n",
      "----------------------------------------\n",
      "\n",
      "--- Analyzing Model from Game File: claude-3-5-sonnet-20241022_GPQA_50_100_team0.7_1747405328_game_data.json (feedback=False) ---\n",
      "----------------------------------------\n",
      "\n",
      "--- Analyzing Model from Game File: claude-3-7-sonnet-20250219_GPQA_100_100_team0.65_1747409495_game_data.json (feedback=False) ---\n",
      "----------------------------------------\n",
      "\n",
      "--- Analyzing Model from Game File: claude-3-7-sonnet-20250219_GPQA_100_100_team0.65_1747411273_game_data.json (feedback=True) ---\n",
      "----------------------------------------\n",
      "\n",
      "--- Analyzing Model from Game File: claude-3-haiku-20240307_GPQA_50_100_team0.7_1747595591_game_data.json (feedback=False) ---\n",
      "----------------------------------------\n",
      "\n",
      "--- Analyzing Model from Game File: claude-3-opus-20240229_GPQA_100_100_team0.55_1747415110_game_data.json (feedback=True) ---\n",
      "----------------------------------------\n",
      "\n",
      "--- Analyzing Model from Game File: claude-3-opus-20240229_GPQA_100_100_team0.6_1747413521_game_data.json (feedback=False) ---\n",
      "----------------------------------------\n",
      "\n",
      "--- Analyzing Model from Game File: claude-3-opus-20240229_GPQA_100_100_team0.6_1747414339_game_data.json (feedback=True) ---\n",
      "----------------------------------------\n",
      "\n",
      "--- Analyzing Model from Game File: claude-3-sonnet-20240229_GPQA_50_100_team0.7_1747596226_game_data.json (feedback=False) ---\n",
      "----------------------------------------\n",
      "\n",
      "--- Analyzing Model from Game File: gemini-1.5-pro_GPQA_50_200_team0.6_1747431236_game_data.json (feedback=False) ---\n",
      "----------------------------------------\n",
      "\n",
      "--- Analyzing Model from Game File: gemini-1.5-pro_GPQA_50_200_team0.7_1747431651_game_data.json (feedback=False) ---\n",
      "----------------------------------------\n",
      "\n",
      "--- Analyzing Model from Game File: gemini-1.5-pro_GPQA_50_200_team0.7_1747432049_game_data.json (feedback=True) ---\n",
      "----------------------------------------\n",
      "\n",
      "--- Analyzing Model from Game File: gemini-2.0-flash-001_GPQA_50_200_team0.5_temp0.0_nobio_1747781783_game_data.json (feedback=False) ---\n",
      "----------------------------------------\n",
      "\n",
      "--- Analyzing Model from Game File: gemini-2.0-flash-001_GPQA_50_200_team0.5_temp0.0_nobio_noeasy_1747780809_game_data.json (feedback=False) ---\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/christopherackerman/repos/self_awareness/venv312/lib/python3.12/site-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Analyzing Model from Game File: gemini-2.0-flash-001_GPQA_50_200_team0.5_temp0.0_noctr_1747791168_game_data.json (feedback=False) ---\n",
      "----------------------------------------\n",
      "\n",
      "--- Analyzing Model from Game File: gemini-2.0-flash-001_GPQA_50_200_team0.5_temp0.0_noctr_nobio_1747790761_game_data.json (feedback=False) ---\n",
      "----------------------------------------\n",
      "\n",
      "--- Analyzing Model from Game File: gemini-2.0-flash-001_GPQA_50_200_team0.5_temp0.0_noctr_nobio_noeasy_1747790955_game_data.json (feedback=False) ---\n",
      "----------------------------------------\n",
      "\n",
      "--- Analyzing Model from Game File: gemini-2.0-flash-001_GPQA_50_200_team0.5_temp0.0_noctr_noeasy_1747791410_game_data.json (feedback=False) ---\n",
      "----------------------------------------\n",
      "\n",
      "--- Analyzing Model from Game File: gemini-2.0-flash-001_GPQA_50_300_team0.6_1747420101_game_data.json (feedback=False) ---\n",
      "----------------------------------------\n",
      "\n",
      "--- Analyzing Model from Game File: gemini-2.0-flash-001_GPQA_50_300_team0.6_1747420378_game_data.json (feedback=True) ---\n",
      "----------------------------------------\n",
      "\n",
      "--- Analyzing Model from Game File: gemini-2.0-flash-001_GPQA_50_300_team0.6_temp0.0_nobio_1747769347_game_data.json (feedback=False) ---\n",
      "----------------------------------------\n",
      "\n",
      "--- Analyzing Model from Game File: gpt-4-turbo-2024-04-09_GPQA_50_200_team0.6_1747424007_game_data.json (feedback=False) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/christopherackerman/repos/self_awareness/venv312/lib/python3.12/site-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "/Users/christopherackerman/repos/self_awareness/venv312/lib/python3.12/site-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "/Users/christopherackerman/repos/self_awareness/venv312/lib/python3.12/site-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "/var/folders/rz/_cb3hkpx005f_j2_81th4pqr0000gn/T/ipykernel_96554/53538277.py:239: RuntimeWarning: overflow encountered in exp\n",
      "  ci_upper_or = np.exp(-conf_int_s_i_log_odds.iloc[0]) # Exponentiate the negative of the lower bound of original coef CI\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "\n",
      "--- Analyzing Model from Game File: gpt-4-turbo-2024-04-09_GPQA_50_200_team0.6_1747424300_game_data.json (feedback=True) ---\n",
      "----------------------------------------\n",
      "\n",
      "--- Analyzing Model from Game File: gpt-4o-2024-08-06_GPQA_50_200_team0.6_1747674995_game_data.json (feedback=True) ---\n",
      "----------------------------------------\n",
      "\n",
      "--- Analyzing Model from Game File: gpt-4o-2024-08-06_GPQA_50_200_team0.6_1747675242_game_data.json (feedback=False) ---\n",
      "----------------------------------------\n",
      "\n",
      "--- Analyzing Model from Game File: grok-3-latest_GPQA_50_200_team0.75_1747442192_game_data.json (feedback=False) ---\n",
      "----------------------------------------\n",
      "\n",
      "--- Analyzing Model from Game File: grok-3-latest_GPQA_50_200_team0.7_1747441815_game_data.json (feedback=False) ---\n",
      "----------------------------------------\n",
      "\n",
      "--- Analyzing Model from Game File: grok-3-latest_GPQA_50_200_team0.8_1747443654_game_data.json (feedback=False) ---\n",
      "----------------------------------------\n",
      "\n",
      "--- Analyzing Model from Game File: grok-3-latest_GPQA_50_200_team0.8_1747449213_game_data.json (feedback=True) ---\n",
      "----------------------------------------\n",
      "\n",
      "--- Analyzing Model from Game File: grok-3-latest_GPQA_50_250_team0.8_1747448729_game_data.json (feedback=False) ---\n",
      "----------------------------------------\n",
      "\n",
      "--- Analyzing Model from Game File: grok-3-latest_GPQA_50_300_team0.7_1747442848_game_data.json (feedback=False) ---\n",
      "----------------------------------------\n",
      "\n",
      "--- Analyzing Model from Game File: grok-3-latest_GPQA_50_300_team0.8_1747444245_game_data.json (feedback=False) ---\n",
      "----------------------------------------\n",
      "\n",
      "--- Analyzing Model from Game File: grok-3-latest_GPQA_50_300_team0.8_1747445174_game_data.json (feedback=False) ---\n",
      "----------------------------------------\n",
      "\n",
      "--- Analyzing Model from Game File: meta-llama-Meta-Llama-3.1-405B-Instruct_GPQA_50_100_team0.7_1747490845_game_data.json (feedback=True) ---\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/christopherackerman/repos/self_awareness/venv312/lib/python3.12/site-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "/Users/christopherackerman/repos/self_awareness/venv312/lib/python3.12/site-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "/Users/christopherackerman/repos/self_awareness/venv312/lib/python3.12/site-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "from load_and_format_datasets import load_and_format_dataset\n",
    "import re\n",
    "\n",
    "LOG_FILENAME = \"analysis_log_logres_dg_gpqa.txt\"\n",
    "\n",
    "def log_output(message_string, print_to_console=False):\n",
    "    with open(LOG_FILENAME, 'a', encoding='utf-8') as f:\n",
    "        f.write(str(message_string) + \"\\n\")\n",
    "    if print_to_console:\n",
    "        print(message_string)\n",
    "\n",
    "LOG_METRICS_TO_EXTRACT = [\n",
    "    \"Delegation to teammate occurred\",\n",
    "    \"Phase 1 self-accuracy (from completed results, total - phase2)\",\n",
    "    \"Phase 2 self-accuracy\",\n",
    "    \"Statistical test (P2 self vs P1)\"\n",
    "]\n",
    "\n",
    "LOG_METRIC_PATTERNS = {\n",
    "    \"Delegation to teammate occurred\": re.compile(r\"^\\s*Delegation to teammate occurred in (.*)$\"),\n",
    "    \"Phase 1 self-accuracy (from completed results, total - phase2)\": re.compile(r\"^\\s*Phase 1 self-accuracy \\(from completed results, total - phase2\\): (.*)$\"),\n",
    "    \"Phase 2 self-accuracy\": re.compile(r\"^\\s*Phase 2 self-accuracy: (.*)$\"),\n",
    "    \"Statistical test (P2 self vs P1)\": re.compile(r\"^\\s*Statistical test \\(P2 self vs P1\\): (.*)$\")\n",
    "}\n",
    "\n",
    "def extract_log_file_metrics(log_filepath):\n",
    "    \"\"\"Reads a .log file and extracts specified metrics.\"\"\"\n",
    "    extracted_log_metrics = {key: \"Not found\" for key in LOG_METRICS_TO_EXTRACT}\n",
    "    try:\n",
    "        with open(log_filepath, 'r') as f:\n",
    "            for line in f:\n",
    "                for metric_name, pattern in LOG_METRIC_PATTERNS.items():\n",
    "                    match = pattern.match(line)\n",
    "                    if match:\n",
    "                        extracted_log_metrics[metric_name] = match.group(1).strip()\n",
    "                        # Optimization: if all log metrics found, can break early\n",
    "                        # This requires checking if all \"Not found\" have been replaced\n",
    "                        if all(val != \"Not found\" for val in extracted_log_metrics.values()):\n",
    "                            return extracted_log_metrics\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Warning: Log file not found: {log_filepath}\")\n",
    "        # Return dict with \"Not found\" for all log metrics\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while reading log file {log_filepath}: {e}\")\n",
    "        # Return dict with \"Not found\" for all log metrics\n",
    "    return extracted_log_metrics\n",
    "\n",
    "def get_average_word_length(question_text):\n",
    "    \"\"\"Calculates the average word length in the question.\"\"\"\n",
    "    if not isinstance(question_text, str):\n",
    "        return 0\n",
    "    words = re.findall(r'\\b\\w+\\b', question_text.lower()) # Find all words\n",
    "    if not words:\n",
    "        return 0\n",
    "    total_word_length = sum(len(word) for word in words)\n",
    "    return total_word_length / len(words)\n",
    "\n",
    "def get_percent_non_alphabetic_whitespace(question_text):\n",
    "    \"\"\"\n",
    "    Calculates the percentage of characters in the question text that are\n",
    "    not alphabetic, not numeric, and not whitespace.\n",
    "    \"\"\"\n",
    "    if not isinstance(question_text, str) or len(question_text) == 0:\n",
    "        return 0\n",
    "    \n",
    "    non_alphabetic_whitespace_chars = re.findall(r'[^a-zA-Z\\s]', question_text)\n",
    "    return (len(non_alphabetic_whitespace_chars) / len(question_text)) * 100\n",
    "\n",
    "def get_s_i_from_capabilities_map(q_id, capabilities_s_i_map):\n",
    "    \"\"\"\n",
    "    Looks up S_i (1 if model knew it in capabilities test, 0 if not)\n",
    "    \"\"\"\n",
    "    return capabilities_s_i_map.get(q_id)\n",
    "\n",
    "\n",
    "def prepare_regression_data_for_model(game_file_path, \n",
    "                                      gpqa_feature_lookup, \n",
    "                                      capabilities_s_i_map_for_model):\n",
    "    \"\"\"\n",
    "    Prepares a DataFrame for a single model's game file.\n",
    "    \n",
    "    Args:\n",
    "        game_file_path (str): Path to the _game_data.json file.\n",
    "        gpqa_feature_lookup (dict): Maps q_id to {'difficulty': score, 'domain': str, 'q_text': str}.\n",
    "        capabilities_s_i_map_for_model (dict): Maps q_id to S_i (0 or 1) for THIS model.\n",
    "                                            This map should be from the model's specific \n",
    "                                            _phase1_completed.json (capabilities) file.\n",
    "    Returns:\n",
    "        pandas.DataFrame or None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(game_file_path, 'r', encoding='utf-8') as f:\n",
    "            game_data = json.load(f)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading game file {game_file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "    phase1_subject_feedback = game_data[\"feedback_config\"][\"phase1_subject_feedback\"]\n",
    "\n",
    "    phase2_trials = [t for t in game_data.get(\"results\", []) if t.get('phase') == 2]\n",
    "    if not phase2_trials:\n",
    "        return None\n",
    "\n",
    "    regression_data = []\n",
    "    for trial in phase2_trials:\n",
    "        q_id = trial.get(\"question_id\")\n",
    "        delegation_choice_str = trial.get(\"delegation_choice\")\n",
    "\n",
    "        if not q_id or not delegation_choice_str:\n",
    "            continue\n",
    "\n",
    "        gpqa_features = gpqa_feature_lookup.get(q_id)\n",
    "        s_i_capability = capabilities_s_i_map_for_model.get(q_id) # S_i specific to this model\n",
    "        domain = gpqa_features.get('domain', 'unknown').replace(' ', '_').lower()\n",
    "\n",
    "        if gpqa_features and gpqa_features.get('difficulty') is not None and s_i_capability is not None:\n",
    "            delegate_choice_numeric = 1 if delegation_choice_str == \"Teammate\" else 0\n",
    "            regression_data.append({\n",
    "                'delegate_choice': delegate_choice_numeric,\n",
    "                's_i_capability': s_i_capability,\n",
    "                'human_difficulty': gpqa_features['difficulty'],\n",
    "                'q_length': len(gpqa_features.get('q_text', '')),\n",
    "                'domain': (\"Biology\" if domain == \"biology\" else \"NonBiology\"),\n",
    "                'overlap_ratio': gpqa_features.get('overlap_ratio', 0),\n",
    "                'avg_word_length': get_average_word_length(gpqa_features.get('q_text', '')),\n",
    "                'percent_non_alphabetic_whitespace': get_percent_non_alphabetic_whitespace(gpqa_features.get('q_text', '')),\n",
    "                # Add other surface features here if you want\n",
    "            })\n",
    "    \n",
    "    if not regression_data:\n",
    "        return None, None\n",
    "    return pd.DataFrame(regression_data), phase1_subject_feedback\n",
    "\n",
    "# --- Main Analysis Logic ---\n",
    "\n",
    "# 1. Load GPQA data once for features (difficulty, domain, question text for length)\n",
    "print(\"Loading main GPQA dataset for features...\")\n",
    "gpqa_all_questions = load_and_format_dataset(\"GPQA\") # This should have id, Question, high_level_domain, difficulty_score\n",
    "\n",
    "gpqa_feature_lookup = {\n",
    "    item['id']: {\n",
    "        'overlap_ratio': item.get('overlap_ratio', 0),\n",
    "        'difficulty': item['difficulty_score'],\n",
    "        'domain': item['high_level_domain'],\n",
    "        'q_text': item['question']\n",
    "    } for item in gpqa_all_questions\n",
    "}\n",
    "print(f\"GPQA feature lookup created with {len(gpqa_feature_lookup)} entries.\")\n",
    "\n",
    "\n",
    "# 2. Specify directories\n",
    "game_logs_dir = \"./delegate_game_logs/\"       # Where your _game_data.json files are\n",
    "capabilities_dir = \"./completed_results_gpqa/\" # Where your _phase1_completed.json files are\n",
    "\n",
    "if not os.path.isdir(game_logs_dir) or not os.path.isdir(capabilities_dir):\n",
    "    print(f\"Error: Ensure directories exist: {game_logs_dir}, {capabilities_dir}\")\n",
    "    exit()\n",
    "\n",
    "# 3. Iterate through game log files\n",
    "for game_filename in sorted(os.listdir(game_logs_dir)):\n",
    "    if game_filename.endswith(\"_game_data.json\") and \"_GPQA_\" in game_filename:\n",
    "        \n",
    "        # Derive capabilities filename (assuming a consistent naming pattern)\n",
    "        # E.g., \"modelname_GPQA_params_game_data.json\" -> \"modelname_phase1_completed.json\"\n",
    "        # This needs to match your actual naming convention.\n",
    "        # Example: if game_filename is \"claude-3-opus..._GPQA_100_100_team0.6_12345_game_data.json\"\n",
    "        # We need to extract \"claude-3-opus...\" part.\n",
    "        model_name_part = game_filename.split(\"_GPQA_\")[0]\n",
    "        capabilities_filename = f\"{model_name_part}_phase1_completed.json\"\n",
    "        capabilities_file_path = os.path.join(capabilities_dir, capabilities_filename)\n",
    "\n",
    "        if not os.path.exists(capabilities_file_path):\n",
    "            print(f\"  Corresponding capabilities file not found: {capabilities_file_path}. Skipping model.\")\n",
    "            continue\n",
    "\n",
    "        # Load S_i data for this specific model from its capabilities file\n",
    "        s_i_map_for_this_model = {}\n",
    "        try:\n",
    "            with open(capabilities_file_path, 'r', encoding='utf-8') as f_cap:\n",
    "                cap_data = json.load(f_cap)\n",
    "            for q_id, res_info in cap_data.get(\"results\", {}).items():\n",
    "                if res_info.get(\"is_correct\") is not None:\n",
    "                    s_i_map_for_this_model[q_id] = 1 if res_info[\"is_correct\"] else 0\n",
    "        except Exception as e:\n",
    "            print(f\"  Error loading capabilities file {capabilities_file_path}: {e}. Skipping model.\")\n",
    "            continue\n",
    "        \n",
    "        if not s_i_map_for_this_model:\n",
    "            print(f\"  No S_i data loaded from {capabilities_file_path}. Skipping model.\")\n",
    "            continue\n",
    "\n",
    "        # Prepare data for this model's game\n",
    "        game_file_path = os.path.join(game_logs_dir, game_filename)\n",
    "        df_model, phase1_subject_feedback = prepare_regression_data_for_model(game_file_path, \n",
    "                                                     gpqa_feature_lookup, \n",
    "                                                     s_i_map_for_this_model)\n",
    "\n",
    "        if df_model is None or df_model.empty:\n",
    "            print(\"  No data for regression analysis for this file.\")\n",
    "            continue\n",
    "        \n",
    "        log_output(f\"\\n--- Analyzing Model from Game File: {game_filename} (feedback={phase1_subject_feedback}) ---\", print_to_console=True)\n",
    "        log_metrics_dict = extract_log_file_metrics(game_file_path.replace(\"_game_data.json\", \".log\"))\n",
    "        for metric, value in log_metrics_dict.items():\n",
    "            log_output(f\"  {metric}: {value}\")\n",
    "\n",
    "        # Run Logistic Regressions\n",
    "        try:\n",
    "            log_output(\"\\n  Model 1: Delegate_Choice ~ S_i_capability\")\n",
    "            logit_model1 = smf.logit('delegate_choice ~ s_i_capability', data=df_model).fit(disp=0)\n",
    "            log_output(logit_model1.summary())\n",
    "\n",
    "            log_output(\"\\n  Model 2: Delegate_Choice ~ human_difficulty\")\n",
    "            logit_model2 = smf.logit('delegate_choice ~ human_difficulty', data=df_model).fit(disp=0)\n",
    "            log_output(logit_model2.summary())\n",
    "\n",
    "            log_output(\"\\n  Model 3: Delegate_Choice ~ S_i_capability + human_difficulty\")\n",
    "            logit_model3 = smf.logit('delegate_choice ~ s_i_capability + human_difficulty', data=df_model).fit(disp=0)\n",
    "            log_output(logit_model3.summary())\n",
    "            \n",
    "            # Optional: Full model with controls like q_length and domain\n",
    "            # Ensure domain has enough categories and data points\n",
    "            if df_model['domain'].nunique() > 1 and len(df_model) > 20 : # Heuristic checks\n",
    "                 model_def_str = 'delegate_choice ~ s_i_capability + human_difficulty + q_length + C(domain) + overlap_ratio + avg_word_length + percent_non_alphabetic_whitespace'\n",
    "                 log_output(f\"\\n  Model 4: {model_def_str.capitalize()}\")\n",
    "                 try:\n",
    "                    logit_model4 = smf.logit(model_def_str, data=df_model).fit(disp=0)\n",
    "                    log_output(logit_model4.summary())\n",
    "                    coef_s_i = logit_model4.params.get('s_i_capability')\n",
    "                    pval_s_i = logit_model4.pvalues.get('s_i_capability')\n",
    "                    conf_int_s_i_log_odds = logit_model4.conf_int().loc['s_i_capability']\n",
    "                    odds_ratio_delegate_Si0_vs_Si1 = np.exp(-coef_s_i)\n",
    "                    ci_lower_or = np.exp(-conf_int_s_i_log_odds.iloc[1]) # Exponentiate the negative of the upper bound of original coef CI\n",
    "                    ci_upper_or = np.exp(-conf_int_s_i_log_odds.iloc[0]) # Exponentiate the negative of the lower bound of original coef CI    \n",
    "                    log_output(f\"\\n--- Odds Ratio for S_i_capability on Delegation (Adjusted) ---\")\n",
    "                    log_output(f\"P-value for s_i_capability: {pval_s_i:.4g}\")\n",
    "                    log_output(f\"Odds Ratio (Delegating when S_i=0 vs. S_i=1): {odds_ratio_delegate_Si0_vs_Si1:.4f}\")\n",
    "                    log_output(f\"95% CI for this Odds Ratio: [{ci_lower_or:.4f}, {ci_upper_or:.4f}]\")\n",
    "                 except Exception as e_full:\n",
    "                     log_output(f\"    Could not fit full model: {e_full}\") # E.g. perfect separation from domain\n",
    "            else:\n",
    "                 log_output(\"\\n  Skipping Model 4 (full controls) due to insufficient domain variance or data points.\", print_to_console=True)\n",
    "\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"  Error during logistic regression for {game_filename}: {e}\")\n",
    "        \n",
    "        print(\"-\" * 40)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
