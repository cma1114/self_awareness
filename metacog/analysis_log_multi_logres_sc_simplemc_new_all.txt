
--- Analyzing claude-3-5-sonnet-20241022 (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_new/claude-3-5-sonnet-20241022_SimpleMC_redacted_cor_temp0.0_1753745296_game_data.json', './sc_logs_new/claude-3-5-sonnet-20241022_SimpleMC_redacted_temp0.0_1753644934_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    363
1    137
Name: count, dtype: int64

Answer change%: 0.2740 [0.23490630857931788, 0.31309369142068216] (n=500)
P-value vs 25%: 0.2289; P-value vs 0%: 6.095e-43
Phase 2 self-accuracy: 0.3504 [0.2704767218707924, 0.4302532051365069] (n=137)
P-value vs 25%: 0.0138; P-value vs 33%: 0.6701

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Mon, 04 Aug 2025   Pseudo R-squ.:                  0.1404
Time:                        16:46:56   Log-Likelihood:                -252.37
converged:                       True   LL-Null:                       -293.60
Covariance Type:            nonrobust   LLR p-value:                 1.075e-19
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          2.0242      0.355      5.700      0.000       1.328       2.720
p_i_capability    -4.4567      0.534     -8.350      0.000      -5.503      -3.411
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Mon, 04 Aug 2025   Pseudo R-squ.:                  0.1578
Time:                        16:46:56   Log-Likelihood:                -247.27
converged:                       True   LL-Null:                       -293.60
Covariance Type:            nonrobust   LLR p-value:                 6.229e-22
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -3.1118      0.298    -10.439      0.000      -3.696      -2.528
capabilities_entropy     1.8400      0.215      8.561      0.000       1.419       2.261
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.6715 [0.5929, 0.7502] (n=137)
                  P-value vs 33.3%: 3.499e-17

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=7.65, p=1.86e-13
Wilcoxon delta_p: statistic=12157.50, p=1.06e-12
Mean Δp = 0.0674  [0.0501, 0.0846]
Idea 1 N = 363; 

  Idea 1.5: Calibration Metrics
  NLL: 1.0679, Signed ECE (overconf pos under neg): -0.0626, ECE: 0.1490 (n=500)
  Brier: 0.0648, Reliability (absolute calibration error; lower better): 0.0387, Resolution (relative calibration quality; higher better): 0.2126, Uncertainty: 0.2400 (n=500)
  AUROC: 0.9968

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.528
Model:                            OLS   Adj. R-squared:                  0.525
Method:                 Least Squares   F-statistic:                     185.0
Date:                Mon, 04 Aug 2025   Prob (F-statistic):           1.74e-80
Time:                        16:46:56   Log-Likelihood:                 253.84
No. Observations:                 500   AIC:                            -499.7
Df Residuals:                     496   BIC:                            -482.8
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.1292      0.030     -4.349      0.000      -0.188      -0.071
p1                    0.2551      0.037      6.850      0.000       0.182       0.328
answer_changed       -0.0638      0.051     -1.240      0.216      -0.165       0.037
p1:answer_changed     0.6640      0.079      8.394      0.000       0.509       0.819
==============================================================================
Omnibus:                       14.973   Durbin-Watson:                   2.002
Prob(Omnibus):                  0.001   Jarque-Bera (JB):               15.534
Skew:                           0.426   Prob(JB):                     0.000423
Kurtosis:                       3.143   Cond. No.                         19.0
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-0.63, p=0.532
Wilcoxon delta_H: statistic=22156.50, p=0.391
Mean ΔH = -0.0119  [-0.0490, 0.0253]
Paired t-test delta_H Changed: statistic=3.66, p=0.000364
Wilcoxon delta_H Changed: statistic=3052.00, p=0.000321
Mean ΔH Changed = 0.1080  [0.0501, 0.1659]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=-8.60, p=1.01e-16
Wilcoxon (p_top2_game vs p_top2_base): statistic=27058.00, p=2.36e-16
Mean Δp_top2 = -0.0387  [-0.0475, -0.0299] (n=500)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=1.30, p=0.194
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=45919.50, p=0.228
Mean ΔH_unchosen_baseline_set = 0.0210  [-0.0106, 0.0526] (n=500)

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=25348.50, p=9.88e-19
Paired t-test (game_entropy vs capabilities_entropy): statistic=9.42, p=1.7e-19
Mean capabilities_entropy-game_entropy = -0.1853  [-0.2239, -0.1468] (n=500)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      497
Method:                           MLE   Df Model:                            2
Date:                Mon, 04 Aug 2025   Pseudo R-squ.:                  0.1572
Time:                        16:46:56   Log-Likelihood:                -247.44
converged:                       True   LL-Null:                       -293.60
Covariance Type:            nonrobust   LLR p-value:                 8.985e-21
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.8227      0.161     -5.097      0.000      -1.139      -0.506
p1_z            -1.2227      0.154     -7.956      0.000      -1.524      -0.921
I(p1_z ** 2)    -0.4441      0.143     -3.102      0.002      -0.725      -0.163
================================================================================
AUC = 0.760

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Mon, 04 Aug 2025   Pseudo R-squ.:                  0.1522
Time:                        16:46:56   Log-Likelihood:                -248.92
converged:                       True   LL-Null:                       -293.60
Covariance Type:            nonrobust   LLR p-value:                 3.303e-21
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -3.7267      0.404     -9.215      0.000      -4.519      -2.934
game_entropy     2.0155      0.259      7.787      0.000       1.508       2.523
================================================================================

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      497
Method:                           MLE   Df Model:                            2
Date:                Mon, 04 Aug 2025   Pseudo R-squ.:                  0.1837
Time:                        16:46:56   Log-Likelihood:                -239.66
converged:                       True   LL-Null:                       -293.60
Covariance Type:            nonrobust   LLR p-value:                 3.743e-24
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -3.9274      0.408     -9.628      0.000      -4.727      -3.128
capabilities_entropy     1.1413      0.274      4.167      0.000       0.604       1.678
game_entropy             1.1869      0.317      3.746      0.000       0.566       1.808
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.800000
                        1                 0.200000
Geography               0                 0.659091
                        1                 0.340909
Misc                    0                 0.837838
                        1                 0.162162
Music                   0                 0.725000
                        1                 0.275000
Other                   0                 0.615385
                        1                 0.384615
Politics                0                 0.753247
                        1                 0.246753
Science and technology  0                 0.663265
                        1                 0.336735
Sports                  0                 0.700000
                        1                 0.300000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.633136
                     1                 0.366864
Number               0                 0.692308
                     1                 0.307692
Other                0                 0.774436
                     1                 0.225564
Person               0                 0.825000
                     1                 0.175000
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.666667  0.333333           21
                       Number               0.666667  0.333333            9
                       Other                0.944444  0.055556           18
                       Person               0.851852  0.148148           27
Geography              Date                 0.533333  0.466667           15
                       Number               0.777778  0.222222           18
                       Other                0.636364  0.363636           11
Misc                   Date                 0.739130  0.260870           23
                       Number               0.666667  0.333333            9
                       Other                0.925926  0.074074           27
                       Person               0.933333  0.066667           15
Music                  Date                 0.583333  0.416667           12
                       Number               0.750000  0.250000            4
                       Other                0.666667  0.333333           12
                       Person               0.916667  0.083333           12
Other                  Date                 0.555556  0.444444           18
                       Number               0.714286  0.285714            7
                       Other                0.714286  0.285714           14
                       Person               0.538462  0.461538           13
Politics               Date                 0.722222  0.277778           36
                       Number               0.500000  0.500000            6
                       Other                0.750000  0.250000           20
                       Person               0.933333  0.066667           15
Science and technology Date                 0.571429  0.428571           35
                       Number               0.571429  0.428571           14
                       Other                0.684211  0.315789           19
                       Person               0.800000  0.200000           30
Sports                 Date                 0.555556  0.444444            9
                       Number               0.818182  0.181818           11
                       Other                0.666667  0.333333           12
                       Person               0.750000  0.250000            8

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      488
Method:                           MLE   Df Model:                           11
Date:                Mon, 04 Aug 2025   Pseudo R-squ.:                 0.05155
Time:                        16:46:57   Log-Likelihood:                -278.46
converged:                       True   LL-Null:                       -293.60
Covariance Type:            nonrobust   LLR p-value:                  0.001438
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -2.6737      1.293     -2.068      0.039      -5.207      -0.140
C(topic_grouped)[T.Geography]                  0.5291      0.446      1.187      0.235      -0.345       1.403
C(topic_grouped)[T.Misc]                      -0.3447      0.435     -0.792      0.428      -1.197       0.508
C(topic_grouped)[T.Music]                      0.4219      0.465      0.907      0.365      -0.490       1.334
C(topic_grouped)[T.Other]                      0.8747      0.413      2.116      0.034       0.064       1.685
C(topic_grouped)[T.Politics]                   0.0076      0.408      0.019      0.985      -0.791       0.806
C(topic_grouped)[T.Science and technology]     0.6141      0.367      1.674      0.094      -0.105       1.333
C(topic_grouped)[T.Sports]                     0.4888      0.460      1.062      0.288      -0.413       1.391
C(answer_type_grouped)[T.Number]              -0.3647      0.307     -1.188      0.235      -0.966       0.237
C(answer_type_grouped)[T.Other]               -0.6377      0.268     -2.379      0.017      -1.163      -0.112
C(answer_type_grouped)[T.Person]              -0.9987      0.298     -3.354      0.001      -1.582      -0.415
q_length                                       0.4008      0.278      1.444      0.149      -0.143       0.945
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 1.0251
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      487
Method:                           MLE   Df Model:                           12
Date:                Mon, 04 Aug 2025   Pseudo R-squ.:                  0.1926
Time:                        16:46:57   Log-Likelihood:                -237.05
converged:                       True   LL-Null:                       -293.60
Covariance Type:            nonrobust   LLR p-value:                 1.455e-18
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -5.0660      1.495     -3.390      0.001      -7.995      -2.137
C(topic_grouped)[T.Geography]                  0.3613      0.485      0.744      0.457      -0.590       1.313
C(topic_grouped)[T.Misc]                      -0.3393      0.469     -0.723      0.470      -1.259       0.581
C(topic_grouped)[T.Music]                      0.3157      0.507      0.623      0.533      -0.678       1.309
C(topic_grouped)[T.Other]                      1.0175      0.462      2.202      0.028       0.112       1.923
C(topic_grouped)[T.Politics]                   0.2626      0.443      0.593      0.553      -0.606       1.131
C(topic_grouped)[T.Science and technology]     0.6895      0.402      1.717      0.086      -0.098       1.477
C(topic_grouped)[T.Sports]                     0.5743      0.510      1.125      0.260      -0.426       1.574
C(answer_type_grouped)[T.Number]              -0.4894      0.332     -1.476      0.140      -1.139       0.161
C(answer_type_grouped)[T.Other]               -0.4309      0.298     -1.446      0.148      -1.015       0.153
C(answer_type_grouped)[T.Person]              -0.7386      0.329     -2.244      0.025      -1.384      -0.093
q_length                                       0.4315      0.309      1.394      0.163      -0.175       1.038
capabilities_entropy                           1.8176      0.223      8.154      0.000       1.381       2.254
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      487
Method:                           MLE   Df Model:                           12
Date:                Mon, 04 Aug 2025   Pseudo R-squ.:                  0.1909
Time:                        16:46:57   Log-Likelihood:                -237.56
converged:                       True   LL-Null:                       -293.60
Covariance Type:            nonrobust   LLR p-value:                 2.319e-18
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -7.2052      1.581     -4.556      0.000     -10.305      -4.106
C(topic_grouped)[T.Geography]                  0.5360      0.481      1.115      0.265      -0.406       1.478
C(topic_grouped)[T.Misc]                      -0.4789      0.464     -1.033      0.302      -1.388       0.430
C(topic_grouped)[T.Music]                      0.1398      0.499      0.280      0.779      -0.837       1.117
C(topic_grouped)[T.Other]                      0.7922      0.449      1.764      0.078      -0.088       1.672
C(topic_grouped)[T.Politics]                   0.1782      0.438      0.407      0.684      -0.680       1.036
C(topic_grouped)[T.Science and technology]     0.7465      0.401      1.860      0.063      -0.040       1.533
C(topic_grouped)[T.Sports]                     0.4849      0.497      0.976      0.329      -0.489       1.458
C(answer_type_grouped)[T.Number]              -0.6782      0.330     -2.054      0.040      -1.325      -0.031
C(answer_type_grouped)[T.Other]               -0.2418      0.296     -0.817      0.414      -0.822       0.338
C(answer_type_grouped)[T.Person]              -0.4849      0.333     -1.457      0.145      -1.137       0.168
q_length                                       0.7307      0.315      2.318      0.020       0.113       1.349
game_entropy                                   2.1014      0.277      7.596      0.000       1.559       2.644
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      486
Method:                           MLE   Df Model:                           13
Date:                Mon, 04 Aug 2025   Pseudo R-squ.:                  0.2190
Time:                        16:46:57   Log-Likelihood:                -229.31
converged:                       True   LL-Null:                       -293.60
Covariance Type:            nonrobust   LLR p-value:                 4.027e-21
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -6.8561      1.617     -4.241      0.000     -10.024      -3.688
C(topic_grouped)[T.Geography]                  0.4160      0.490      0.849      0.396      -0.545       1.377
C(topic_grouped)[T.Misc]                      -0.4518      0.473     -0.956      0.339      -1.378       0.475
C(topic_grouped)[T.Music]                      0.1658      0.511      0.325      0.745      -0.835       1.167
C(topic_grouped)[T.Other]                      0.8975      0.464      1.932      0.053      -0.013       1.808
C(topic_grouped)[T.Politics]                   0.2809      0.448      0.627      0.531      -0.597       1.159
C(topic_grouped)[T.Science and technology]     0.7098      0.408      1.738      0.082      -0.091       1.510
C(topic_grouped)[T.Sports]                     0.5197      0.511      1.016      0.310      -0.483       1.522
C(answer_type_grouped)[T.Number]              -0.6495      0.337     -1.929      0.054      -1.309       0.010
C(answer_type_grouped)[T.Other]               -0.2667      0.304     -0.876      0.381      -0.863       0.330
C(answer_type_grouped)[T.Person]              -0.5490      0.341     -1.611      0.107      -1.217       0.119
q_length                                       0.6150      0.323      1.905      0.057      -0.018       1.248
capabilities_entropy                           1.1089      0.281      3.943      0.000       0.558       1.660
game_entropy                                   1.2811      0.338      3.787      0.000       0.618       1.944
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing claude-3-haiku-20240307 (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_new/claude-3-haiku-20240307_SimpleMC_redacted_cor_temp0.0_1754173427_game_data.json', './sc_logs_new/claude-3-haiku-20240307_SimpleMC_redacted_temp0.0_1754183680_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    377
1    123
Name: count, dtype: int64

Answer change%: 0.2460 [0.20825005568487207, 0.2837499443151279] (n=500)
P-value vs 25%: 0.8355; P-value vs 0%: 2.343e-37
Phase 2 self-accuracy: 0.2846 [0.20481476406627758, 0.364290926990633] (n=123)
P-value vs 25%: 0.3957; P-value vs 33%: 0.2337

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Mon, 04 Aug 2025   Pseudo R-squ.:                 0.03772
Time:                        16:46:57   Log-Likelihood:                -268.43
converged:                       True   LL-Null:                       -278.95
Covariance Type:            nonrobust   LLR p-value:                 4.489e-06
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          1.9248      0.661      2.914      0.004       0.630       3.220
p_i_capability    -3.4164      0.738     -4.629      0.000      -4.863      -1.970
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Mon, 04 Aug 2025   Pseudo R-squ.:                 0.04029
Time:                        16:46:57   Log-Likelihood:                -267.71
converged:                       True   LL-Null:                       -278.95
Covariance Type:            nonrobust   LLR p-value:                 2.124e-06
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.8785      0.197     -9.546      0.000      -2.264      -1.493
capabilities_entropy     1.6194      0.340      4.757      0.000       0.952       2.287
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.3089 [0.2273, 0.3906] (n=123)
                  P-value vs 33.3%: 0.5583

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=0.38, p=0.707
Wilcoxon delta_p: statistic=6230.50, p=0.315
Mean Δp = 0.0026  [-0.0110, 0.0163]
Idea 1 N = 377; 

  Idea 1.5: Calibration Metrics
  NLL: 2.9673, Signed ECE (overconf pos under neg): -0.0037, ECE: 0.0373 (n=500)
  Brier: 0.0164, Reliability (absolute calibration error; lower better): 0.0039, Resolution (relative calibration quality; higher better): 0.1977, Uncertainty: 0.2108 (n=500)
  AUROC: 0.9988

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.892
Model:                            OLS   Adj. R-squared:                  0.891
Method:                 Least Squares   F-statistic:                     1366.
Date:                Mon, 04 Aug 2025   Prob (F-statistic):          3.22e-239
Time:                        16:46:57   Log-Likelihood:                 373.90
No. Observations:                 500   AIC:                            -739.8
Df Residuals:                     496   BIC:                            -722.9
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.7873      0.053    -14.849      0.000      -0.892      -0.683
p1                    0.8600      0.057     14.992      0.000       0.747       0.973
answer_changed        0.6892      0.075      9.238      0.000       0.543       0.836
p1:answer_changed     0.0989      0.083      1.189      0.235      -0.065       0.262
==============================================================================
Omnibus:                       77.306   Durbin-Watson:                   2.026
Prob(Omnibus):                  0.000   Jarque-Bera (JB):              151.654
Skew:                           0.873   Prob(JB):                     1.17e-33
Kurtosis:                       5.057   Cond. No.                         34.4
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=0.06, p=0.949
Wilcoxon delta_H: statistic=6825.00, p=0.971
Mean ΔH = 0.0021  [-0.0621, 0.0663]
Paired t-test delta_H Changed: statistic=14.49, p=2.74e-28
Wilcoxon delta_H Changed: statistic=382.00, p=4.32e-18
Mean ΔH Changed = 0.8614  [0.7448, 0.9779]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=-0.68, p=0.498
Wilcoxon (p_top2_game vs p_top2_base): statistic=16754.00, p=0.7
Mean Δp_top2 = -0.0013  [-0.0051, 0.0025] (n=500)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=6.45, p=2.71e-10
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=12081.00, p=6.82e-10
Mean ΔH_unchosen_baseline_set = 0.2135  [0.1486, 0.2784] (n=500)

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=13551.50, p=0.00276
Paired t-test (game_entropy vs capabilities_entropy): statistic=2.81, p=0.00521
Mean capabilities_entropy-game_entropy = -0.0476  [-0.0809, -0.0144] (n=500)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      497
Method:                           MLE   Df Model:                            2
Date:                Mon, 04 Aug 2025   Pseudo R-squ.:                 0.04131
Time:                        16:46:57   Log-Likelihood:                -267.43
converged:                       True   LL-Null:                       -278.95
Covariance Type:            nonrobust   LLR p-value:                 9.896e-06
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.3202      0.160     -8.245      0.000      -1.634      -1.006
p1_z            -0.0537      0.292     -0.184      0.854      -0.625       0.518
I(p1_z ** 2)     0.1657      0.121      1.365      0.172      -0.072       0.404
================================================================================
AUC = 0.589

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Mon, 04 Aug 2025   Pseudo R-squ.:                  0.1281
Time:                        16:46:57   Log-Likelihood:                -243.23
converged:                       True   LL-Null:                       -278.95
Covariance Type:            nonrobust   LLR p-value:                 2.848e-17
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -2.5657      0.221    -11.595      0.000      -2.999      -2.132
game_entropy     2.6928      0.339      7.942      0.000       2.028       3.357
================================================================================

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      497
Method:                           MLE   Df Model:                            2
Date:                Mon, 04 Aug 2025   Pseudo R-squ.:                  0.1508
Time:                        16:46:57   Log-Likelihood:                -236.89
converged:                       True   LL-Null:                       -278.95
Covariance Type:            nonrobust   LLR p-value:                 5.413e-19
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -3.1184      0.282    -11.052      0.000      -3.671      -2.565
capabilities_entropy     1.3216      0.366      3.615      0.000       0.605       2.038
game_entropy             2.5651      0.345      7.442      0.000       1.890       3.241
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.746667
                        1                 0.253333
Geography               0                 0.590909
                        1                 0.409091
Misc                    0                 0.770270
                        1                 0.229730
Music                   0                 0.775000
                        1                 0.225000
Other                   0                 0.711538
                        1                 0.288462
Politics                0                 0.857143
                        1                 0.142857
Science and technology  0                 0.775510
                        1                 0.224490
Sports                  0                 0.700000
                        1                 0.300000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.733728
                     1                 0.266272
Number               0                 0.743590
                     1                 0.256410
Other                0                 0.789474
                     1                 0.210526
Person               0                 0.750000
                     1                 0.250000
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.714286  0.285714           21
                       Number               0.444444  0.555556            9
                       Other                0.722222  0.277778           18
                       Person               0.888889  0.111111           27
Geography              Date                 0.533333  0.466667           15
                       Number               0.611111  0.388889           18
                       Other                0.636364  0.363636           11
Misc                   Date                 0.652174  0.347826           23
                       Number               1.000000  0.000000            9
                       Other                0.777778  0.222222           27
                       Person               0.800000  0.200000           15
Music                  Date                 0.583333  0.416667           12
                       Number               1.000000  0.000000            4
                       Other                0.833333  0.166667           12
                       Person               0.833333  0.166667           12
Other                  Date                 0.777778  0.222222           18
                       Number               0.857143  0.142857            7
                       Other                0.571429  0.428571           14
                       Person               0.692308  0.307692           13
Politics               Date                 0.888889  0.111111           36
                       Number               0.666667  0.333333            6
                       Other                0.950000  0.050000           20
                       Person               0.733333  0.266667           15
Science and technology Date                 0.800000  0.200000           35
                       Number               0.785714  0.214286           14
                       Other                0.947368  0.052632           19
                       Person               0.633333  0.366667           30
Sports                 Date                 0.555556  0.444444            9
                       Number               0.818182  0.181818           11
                       Other                0.750000  0.250000           12
                       Person               0.625000  0.375000            8

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      488
Method:                           MLE   Df Model:                           11
Date:                Mon, 04 Aug 2025   Pseudo R-squ.:                 0.02634
Time:                        16:46:57   Log-Likelihood:                -271.60
converged:                       True   LL-Null:                       -278.95
Covariance Type:            nonrobust   LLR p-value:                    0.1969
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -0.1796      1.343     -0.134      0.894      -2.812       2.453
C(topic_grouped)[T.Geography]                  0.7768      0.424      1.833      0.067      -0.054       1.607
C(topic_grouped)[T.Misc]                      -0.0895      0.387     -0.232      0.817      -0.847       0.668
C(topic_grouped)[T.Music]                     -0.1529      0.464     -0.330      0.742      -1.062       0.756
C(topic_grouped)[T.Other]                      0.1826      0.407      0.448      0.654      -0.616       0.981
C(topic_grouped)[T.Politics]                  -0.6931      0.428     -1.619      0.105      -1.532       0.146
C(topic_grouped)[T.Science and technology]    -0.1600      0.361     -0.443      0.658      -0.868       0.548
C(topic_grouped)[T.Sports]                     0.2934      0.440      0.666      0.505      -0.570       1.157
C(answer_type_grouped)[T.Number]              -0.2889      0.328     -0.881      0.378      -0.932       0.354
C(answer_type_grouped)[T.Other]               -0.3761      0.282     -1.334      0.182      -0.928       0.176
C(answer_type_grouped)[T.Person]              -0.0649      0.282     -0.230      0.818      -0.618       0.489
q_length                                      -0.1699      0.291     -0.585      0.559      -0.739       0.400
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.4423
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      487
Method:                           MLE   Df Model:                           12
Date:                Mon, 04 Aug 2025   Pseudo R-squ.:                 0.06478
Time:                        16:46:57   Log-Likelihood:                -260.88
converged:                       True   LL-Null:                       -278.95
Covariance Type:            nonrobust   LLR p-value:                 0.0003074
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.2568      1.413     -0.890      0.374      -4.026       1.512
C(topic_grouped)[T.Geography]                  0.8092      0.436      1.857      0.063      -0.045       1.663
C(topic_grouped)[T.Misc]                      -0.0882      0.396     -0.223      0.823      -0.863       0.687
C(topic_grouped)[T.Music]                     -0.2533      0.483     -0.524      0.600      -1.200       0.694
C(topic_grouped)[T.Other]                      0.1485      0.417      0.356      0.722      -0.670       0.967
C(topic_grouped)[T.Politics]                  -0.6905      0.438     -1.577      0.115      -1.548       0.167
C(topic_grouped)[T.Science and technology]    -0.1961      0.370     -0.530      0.596      -0.921       0.529
C(topic_grouped)[T.Sports]                     0.1862      0.452      0.412      0.681      -0.700       1.073
C(answer_type_grouped)[T.Number]              -0.2755      0.338     -0.816      0.415      -0.937       0.387
C(answer_type_grouped)[T.Other]               -0.3534      0.290     -1.220      0.223      -0.921       0.215
C(answer_type_grouped)[T.Person]               0.0432      0.291      0.149      0.882      -0.526       0.613
q_length                                      -0.1018      0.302     -0.338      0.736      -0.693       0.489
capabilities_entropy                           1.6226      0.351      4.621      0.000       0.934       2.311
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      487
Method:                           MLE   Df Model:                           12
Date:                Mon, 04 Aug 2025   Pseudo R-squ.:                  0.1572
Time:                        16:46:57   Log-Likelihood:                -235.09
converged:                       True   LL-Null:                       -278.95
Covariance Type:            nonrobust   LLR p-value:                 1.366e-13
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -2.3338      1.507     -1.549      0.121      -5.287       0.620
C(topic_grouped)[T.Geography]                  0.9271      0.461      2.011      0.044       0.024       1.830
C(topic_grouped)[T.Misc]                      -0.1487      0.423     -0.351      0.725      -0.979       0.681
C(topic_grouped)[T.Music]                     -0.1498      0.513     -0.292      0.770      -1.156       0.856
C(topic_grouped)[T.Other]                      0.2230      0.446      0.500      0.617      -0.652       1.098
C(topic_grouped)[T.Politics]                  -0.8747      0.466     -1.876      0.061      -1.789       0.039
C(topic_grouped)[T.Science and technology]    -0.0940      0.388     -0.242      0.809      -0.855       0.667
C(topic_grouped)[T.Sports]                     0.0029      0.492      0.006      0.995      -0.962       0.968
C(answer_type_grouped)[T.Number]              -0.3819      0.357     -1.069      0.285      -1.082       0.318
C(answer_type_grouped)[T.Other]               -0.4813      0.310     -1.552      0.121      -1.089       0.126
C(answer_type_grouped)[T.Person]              -0.1283      0.309     -0.415      0.678      -0.734       0.477
q_length                                      -0.0110      0.321     -0.034      0.973      -0.641       0.619
game_entropy                                   2.8221      0.356      7.932      0.000       2.125       3.519
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      486
Method:                           MLE   Df Model:                           13
Date:                Mon, 04 Aug 2025   Pseudo R-squ.:                  0.1790
Time:                        16:46:57   Log-Likelihood:                -229.01
converged:                       True   LL-Null:                       -278.95
Covariance Type:            nonrobust   LLR p-value:                 1.756e-15
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -3.0330      1.551     -1.955      0.051      -6.073       0.007
C(topic_grouped)[T.Geography]                  0.9304      0.466      1.996      0.046       0.017       1.844
C(topic_grouped)[T.Misc]                      -0.1645      0.432     -0.381      0.703      -1.010       0.681
C(topic_grouped)[T.Music]                     -0.2377      0.527     -0.451      0.652      -1.271       0.796
C(topic_grouped)[T.Other]                      0.1795      0.450      0.399      0.690      -0.702       1.061
C(topic_grouped)[T.Politics]                  -0.8876      0.471     -1.883      0.060      -1.812       0.036
C(topic_grouped)[T.Science and technology]    -0.1252      0.392     -0.319      0.750      -0.894       0.644
C(topic_grouped)[T.Sports]                    -0.0809      0.498     -0.162      0.871      -1.057       0.895
C(answer_type_grouped)[T.Number]              -0.3773      0.362     -1.041      0.298      -1.087       0.333
C(answer_type_grouped)[T.Other]               -0.4725      0.314     -1.507      0.132      -1.087       0.142
C(answer_type_grouped)[T.Person]              -0.0590      0.317     -0.186      0.852      -0.680       0.562
q_length                                       0.0214      0.328      0.065      0.948      -0.622       0.665
capabilities_entropy                           1.3273      0.377      3.520      0.000       0.588       2.066
game_entropy                                   2.7070      0.362      7.468      0.000       1.997       3.417
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing claude-3-sonnet-20240229 (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_new/claude-3-sonnet-20240229_SimpleMC_redacted_cor_temp0.0_1751757346_game_data.json', './sc_logs_new/claude-3-sonnet-20240229_SimpleMC_redacted_temp0.0_1751717606_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    207
1    123
Name: count, dtype: int64

Answer change%: 0.3727 [0.3205579847169303, 0.42489656073761517] (n=330)
P-value vs 25%: 4.012e-06; P-value vs 0%: 1.492e-44
Phase 2 self-accuracy: 0.2552 [0.19353998643958548, 0.31687668022708115] (n=192)
P-value vs 25%: 0.8685; P-value vs 33%: 0.01342

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  330
Model:                          Logit   Df Residuals:                      328
Method:                           MLE   Df Model:                            1
Date:                Mon, 04 Aug 2025   Pseudo R-squ.:                  0.1372
Time:                        16:46:57   Log-Likelihood:                -188.02
converged:                       True   LL-Null:                       -217.93
Covariance Type:            nonrobust   LLR p-value:                 1.043e-14
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          2.8368      0.479      5.925      0.000       1.898       3.775
p_i_capability    -4.9918      0.707     -7.059      0.000      -6.378      -3.606
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  330
Model:                          Logit   Df Residuals:                      328
Method:                           MLE   Df Model:                            1
Date:                Mon, 04 Aug 2025   Pseudo R-squ.:                  0.1304
Time:                        16:46:57   Log-Likelihood:                -189.52
converged:                       True   LL-Null:                       -217.93
Covariance Type:            nonrobust   LLR p-value:                 4.768e-14
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.7269      0.364     -7.490      0.000      -3.440      -2.013
capabilities_entropy     1.9325      0.284      6.797      0.000       1.375       2.490
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.3171 [0.2348, 0.3993] (n=123)
                  P-value vs 33.3%: 0.6984
                  Grouped rare topic into 'Misc'/'Other': ['History', 'TV shows', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': None
topic_grouped           answer_changed
Art                     0                 0.600000
                        1                 0.400000
Geography               0                 0.551724
                        1                 0.448276
Misc                    0                 0.772727
                        1                 0.227273
Music                   0                 0.777778
                        1                 0.222222
Other                   0                 0.516129
                        1                 0.483871
Politics                0                 0.627451
                        1                 0.372549
Science and technology  0                 0.625000
                        1                 0.375000
Sports                  0                 0.517241
                        1                 0.482759
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.554545
                     1                 0.445455
Number               0                 0.521739
                     1                 0.478261
Other                0                 0.753425
                     1                 0.246575
Person               0                 0.653846
                     1                 0.346154
Place                0                 0.695652
                     1                 0.304348
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.470588  0.529412           17
                       Number               0.625000  0.375000            8
                       Other                0.777778  0.222222            9
                       Person               0.555556  0.444444           18
                       Place                1.000000  0.000000            3
Geography              Date                 0.500000  0.500000           10
                       Number               0.555556  0.444444            9
                       Other                1.000000  0.000000            3
                       Place                0.428571  0.571429            7
Misc                   Date                 0.733333  0.266667           15
                       Number               1.000000  0.000000            4
                       Other                0.714286  0.285714           14
                       Person               0.800000  0.200000           10
                       Place                1.000000  0.000000            1
Music                  Date                 0.625000  0.375000            8
                       Number               0.666667  0.333333            3
                       Other                0.857143  0.142857            7
                       Person               0.857143  0.142857            7
                       Place                1.000000  0.000000            2
Other                  Date                 0.444444  0.555556            9
                       Number               0.000000  1.000000            2
                       Other                0.750000  0.250000            8
                       Person               0.444444  0.555556            9
                       Place                0.666667  0.333333            3
Politics               Date                 0.681818  0.318182           22
                       Number               0.500000  0.500000            2
                       Other                0.750000  0.250000           12
                       Person               0.400000  0.600000           10
                       Place                0.600000  0.400000            5
Science and technology Date                 0.454545  0.545455           22
                       Number               0.444444  0.555556            9
                       Other                0.833333  0.166667           12
                       Person               0.736842  0.263158           19
                       Place                1.000000  0.000000            2
Sports                 Date                 0.428571  0.571429            7
                       Number               0.333333  0.666667            9
                       Other                0.500000  0.500000            8
                       Person               1.000000  0.000000            5

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  330
Model:                          Logit   Df Residuals:                      317
Method:                           MLE   Df Model:                           12
Date:                Mon, 04 Aug 2025   Pseudo R-squ.:                 0.04944
Time:                        16:46:57   Log-Likelihood:                -207.16
converged:                       True   LL-Null:                       -217.93
Covariance Type:            nonrobust   LLR p-value:                   0.04291
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      1.1692      1.493      0.783      0.434      -1.757       4.095
C(topic_grouped)[T.Geography]                  0.1252      0.489      0.256      0.798      -0.834       1.084
C(topic_grouped)[T.Misc]                      -0.7658      0.462     -1.659      0.097      -1.671       0.139
C(topic_grouped)[T.Music]                     -0.8328      0.547     -1.522      0.128      -1.905       0.240
C(topic_grouped)[T.Other]                      0.4634      0.463      1.002      0.316      -0.443       1.370
C(topic_grouped)[T.Politics]                  -0.0103      0.417     -0.025      0.980      -0.828       0.808
C(topic_grouped)[T.Science and technology]    -0.1106      0.383     -0.289      0.773      -0.862       0.641
C(topic_grouped)[T.Sports]                     0.3413      0.478      0.715      0.475      -0.595       1.277
C(answer_type_grouped)[T.Number]               0.0807      0.371      0.217      0.828      -0.647       0.808
C(answer_type_grouped)[T.Other]               -0.9440      0.345     -2.738      0.006      -1.620      -0.268
C(answer_type_grouped)[T.Person]              -0.4586      0.318     -1.442      0.149      -1.082       0.165
C(answer_type_grouped)[T.Place]               -0.7214      0.509     -1.418      0.156      -1.719       0.276
q_length                                      -0.2804      0.323     -0.869      0.385      -0.913       0.352
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 1.0787
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  330
Model:                          Logit   Df Residuals:                      316
Method:                           MLE   Df Model:                           13
Date:                Mon, 04 Aug 2025   Pseudo R-squ.:                  0.1792
Time:                        16:46:57   Log-Likelihood:                -178.88
converged:                       True   LL-Null:                       -217.93
Covariance Type:            nonrobust   LLR p-value:                 2.515e-11
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.0417      1.677     -0.621      0.535      -4.329       2.246
C(topic_grouped)[T.Geography]                  0.5378      0.542      0.993      0.321      -0.524       1.600
C(topic_grouped)[T.Misc]                      -0.5599      0.501     -1.118      0.264      -1.542       0.422
C(topic_grouped)[T.Music]                     -0.5857      0.608     -0.964      0.335      -1.777       0.606
C(topic_grouped)[T.Other]                      0.9213      0.517      1.783      0.075      -0.091       1.934
C(topic_grouped)[T.Politics]                   0.3893      0.472      0.824      0.410      -0.537       1.315
C(topic_grouped)[T.Science and technology]     0.0694      0.430      0.161      0.872      -0.773       0.912
C(topic_grouped)[T.Sports]                     0.0517      0.519      0.099      0.921      -0.966       1.069
C(answer_type_grouped)[T.Number]               0.2312      0.403      0.574      0.566      -0.558       1.021
C(answer_type_grouped)[T.Other]               -0.8989      0.382     -2.356      0.018      -1.647      -0.151
C(answer_type_grouped)[T.Person]               0.0548      0.357      0.153      0.878      -0.646       0.755
C(answer_type_grouped)[T.Place]               -0.8033      0.548     -1.465      0.143      -1.878       0.271
q_length                                      -0.4058      0.359     -1.131      0.258      -1.109       0.297
capabilities_entropy                           2.1214      0.317      6.701      0.000       1.501       2.742
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing claude-sonnet-4-20250514 (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_new/claude-sonnet-4-20250514_SimpleMC_redacted_cor_temp0.0_1751759842_game_data.json', './sc_logs_new/claude-sonnet-4-20250514_SimpleMC_redacted_temp0.0_1751719035_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    255
1    245
Name: count, dtype: int64

Answer change%: 0.4900 [0.44618263907327455, 0.5338173609267254] (n=500)
P-value vs 25%: 6.951e-27; P-value vs 0%: 1.756e-106
Phase 2 self-accuracy: 0.3633 [0.3030431546377259, 0.4234874576071721] (n=245)
P-value vs 25%: 0.0002276; P-value vs 33%: 0.3246
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.560000
                        1                 0.440000
Geography               0                 0.522727
                        1                 0.477273
Misc                    0                 0.540541
                        1                 0.459459
Music                   0                 0.625000
                        1                 0.375000
Other                   1                 0.653846
                        0                 0.346154
Politics                1                 0.545455
                        0                 0.454545
Science and technology  0                 0.581633
                        1                 0.418367
Sports                  1                 0.625000
                        0                 0.375000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.538462
                     1                 0.461538
Number               1                 0.538462
                     0                 0.461538
Other                0                 0.518797
                     1                 0.481203
Person               1                 0.508333
                     0                 0.491667
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.666667  0.333333           21
                       Number               0.444444  0.555556            9
                       Other                0.666667  0.333333           18
                       Person               0.444444  0.555556           27
Geography              Date                 0.400000  0.600000           15
                       Number               0.555556  0.444444           18
                       Other                0.636364  0.363636           11
Misc                   Date                 0.652174  0.347826           23
                       Number               0.555556  0.444444            9
                       Other                0.481481  0.518519           27
                       Person               0.466667  0.533333           15
Music                  Date                 0.666667  0.333333           12
                       Number               0.500000  0.500000            4
                       Other                0.500000  0.500000           12
                       Person               0.750000  0.250000           12
Other                  Date                 0.277778  0.722222           18
                       Number               0.285714  0.714286            7
                       Other                0.357143  0.642857           14
                       Person               0.461538  0.538462           13
Politics               Date                 0.500000  0.500000           36
                       Number               0.000000  1.000000            6
                       Other                0.550000  0.450000           20
                       Person               0.400000  0.600000           15
Science and technology Date                 0.657143  0.342857           35
                       Number               0.571429  0.428571           14
                       Other                0.578947  0.421053           19
                       Person               0.500000  0.500000           30
Sports                 Date                 0.222222  0.777778            9
                       Number               0.454545  0.545455           11
                       Other                0.333333  0.666667           12
                       Person               0.500000  0.500000            8

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      488
Method:                           MLE   Df Model:                           11
Date:                Mon, 04 Aug 2025   Pseudo R-squ.:                 0.02666
Time:                        16:46:57   Log-Likelihood:                -337.24
converged:                       True   LL-Null:                       -346.47
Covariance Type:            nonrobust   LLR p-value:                   0.07123
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      1.1679      1.149      1.016      0.309      -1.084       3.420
C(topic_grouped)[T.Geography]                  0.1278      0.395      0.323      0.747      -0.647       0.903
C(topic_grouped)[T.Misc]                       0.1161      0.333      0.349      0.727      -0.536       0.768
C(topic_grouped)[T.Music]                     -0.2725      0.403     -0.677      0.499      -1.062       0.517
C(topic_grouped)[T.Other]                      0.8930      0.375      2.381      0.017       0.158       1.628
C(topic_grouped)[T.Politics]                   0.5541      0.336      1.651      0.099      -0.104       1.212
C(topic_grouped)[T.Science and technology]    -0.0516      0.312     -0.165      0.869      -0.663       0.560
C(topic_grouped)[T.Sports]                     0.7445      0.405      1.837      0.066      -0.050       1.539
C(answer_type_grouped)[T.Number]               0.3278      0.287      1.142      0.254      -0.235       0.890
C(answer_type_grouped)[T.Other]                0.0539      0.239      0.226      0.821      -0.414       0.522
C(answer_type_grouped)[T.Person]               0.2189      0.249      0.880      0.379      -0.269       0.707
q_length                                      -0.3452      0.248     -1.393      0.164      -0.831       0.141
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing deepseek-chat (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_new/deepseek-chat_SimpleMC_redacted_cor_temp0.0_1753737594_game_data.json', './sc_logs_new/deepseek-chat_SimpleMC_redacted_temp0.0_1753645078_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    375
1    125
Name: count, dtype: int64

Answer change%: 0.2500 [0.21204546064355018, 0.2879545393564498] (n=500)
P-value vs 25%: 1; P-value vs 0%: 3.956e-38
Phase 2 self-accuracy: 0.3760 [0.2910859995361642, 0.4609140004638358] (n=125)
P-value vs 25%: 0.003634; P-value vs 33%: 0.3209

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Mon, 04 Aug 2025   Pseudo R-squ.:                  0.1484
Time:                        16:46:57   Log-Likelihood:                -239.43
converged:                       True   LL-Null:                       -281.17
Covariance Type:            nonrobust   LLR p-value:                 6.471e-20
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          5.3964      0.813      6.641      0.000       3.804       6.989
p_i_capability    -7.3386      0.907     -8.090      0.000      -9.116      -5.561
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Mon, 04 Aug 2025   Pseudo R-squ.:                  0.1440
Time:                        16:46:57   Log-Likelihood:                -240.69
converged:                       True   LL-Null:                       -281.17
Covariance Type:            nonrobust   LLR p-value:                 2.305e-19
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.6290      0.222    -11.832      0.000      -3.064      -2.194
capabilities_entropy     3.0451      0.374      8.144      0.000       2.312       3.778
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.6560 [0.5727, 0.7393] (n=125)
                  P-value vs 33.3%: 3.099e-14

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=0.02, p=0.988
Wilcoxon delta_p: statistic=4313.00, p=0.749
Mean Δp = 0.0001  [-0.0102, 0.0103]
Idea 1 N = 375; 

  Idea 1.5: Calibration Metrics
  NLL: 1.9508, Signed ECE (overconf pos under neg): -0.0212, ECE: 0.0664 (n=500)
  Brier: 0.0168, Reliability (absolute calibration error; lower better): 0.0135, Resolution (relative calibration quality; higher better): 0.2463, Uncertainty: 0.2495 (n=500)
  AUROC: 0.9999

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.913
Model:                            OLS   Adj. R-squared:                  0.912
Method:                 Least Squares   F-statistic:                     1728.
Date:                Mon, 04 Aug 2025   Prob (F-statistic):          4.06e-262
Time:                        16:46:57   Log-Likelihood:                 462.01
No. Observations:                 500   AIC:                            -916.0
Df Residuals:                     496   BIC:                            -899.2
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.7140      0.057    -12.620      0.000      -0.825      -0.603
p1                    0.7672      0.061     12.671      0.000       0.648       0.886
answer_changed        0.7870      0.070     11.277      0.000       0.650       0.924
p1:answer_changed    -0.0020      0.078     -0.025      0.980      -0.156       0.152
==============================================================================
Omnibus:                       91.611   Durbin-Watson:                   1.854
Prob(Omnibus):                  0.000   Jarque-Bera (JB):              541.251
Skew:                           0.636   Prob(JB):                    2.94e-118
Kurtosis:                       7.936   Cond. No.                         40.8
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=0.85, p=0.398
Wilcoxon delta_H: statistic=4027.00, p=0.336
Mean ΔH = 0.0208  [-0.0273, 0.0689]
Paired t-test delta_H Changed: statistic=10.20, p=4.15e-18
Wilcoxon delta_H Changed: statistic=836.00, p=2.14e-14
Mean ΔH Changed = 0.5950  [0.4807, 0.7093]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=1.59, p=0.113
Wilcoxon (p_top2_game vs p_top2_base): statistic=14499.00, p=0.214
Mean Δp_top2 = 0.0027  [-0.0006, 0.0061] (n=500)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=6.33, p=5.47e-10
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=9230.00, p=4.63e-10
Mean ΔH_unchosen_baseline_set = 0.1643  [0.1135, 0.2152] (n=500)

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=15595.50, p=0.767
Paired t-test (game_entropy vs capabilities_entropy): statistic=-0.53, p=0.594
Mean capabilities_entropy-game_entropy = 0.0083  [-0.0223, 0.0390] (n=500)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      497
Method:                           MLE   Df Model:                            2
Date:                Mon, 04 Aug 2025   Pseudo R-squ.:                  0.1576
Time:                        16:46:57   Log-Likelihood:                -236.87
converged:                       True   LL-Null:                       -281.17
Covariance Type:            nonrobust   LLR p-value:                 5.771e-20
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.0033      0.145     -6.920      0.000      -1.287      -0.719
p1_z            -1.4228      0.249     -5.708      0.000      -1.911      -0.934
I(p1_z ** 2)    -0.2386      0.101     -2.353      0.019      -0.437      -0.040
================================================================================
AUC = 0.769

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Mon, 04 Aug 2025   Pseudo R-squ.:                  0.1489
Time:                        16:46:57   Log-Likelihood:                -239.30
converged:                       True   LL-Null:                       -281.17
Covariance Type:            nonrobust   LLR p-value:                 5.652e-20
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -2.7640      0.233    -11.844      0.000      -3.221      -2.307
game_entropy     3.3752      0.403      8.366      0.000       2.584       4.166
================================================================================

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      497
Method:                           MLE   Df Model:                            2
Date:                Mon, 04 Aug 2025   Pseudo R-squ.:                  0.2479
Time:                        16:46:57   Log-Likelihood:                -211.47
converged:                       True   LL-Null:                       -281.17
Covariance Type:            nonrobust   LLR p-value:                 5.392e-31
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -3.9832      0.321    -12.399      0.000      -4.613      -3.354
capabilities_entropy     2.7215      0.387      7.032      0.000       1.963       3.480
game_entropy             3.0279      0.418      7.244      0.000       2.209       3.847
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.813333
                        1                 0.186667
Geography               0                 0.681818
                        1                 0.318182
Misc                    0                 0.702703
                        1                 0.297297
Music                   0                 0.750000
                        1                 0.250000
Other                   0                 0.750000
                        1                 0.250000
Politics                0                 0.714286
                        1                 0.285714
Science and technology  0                 0.806122
                        1                 0.193878
Sports                  0                 0.725000
                        1                 0.275000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.727811
                     1                 0.272189
Number               0                 0.756410
                     1                 0.243590
Other                0                 0.729323
                     1                 0.270677
Person               0                 0.800000
                     1                 0.200000
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.857143  0.142857           21
                       Number               0.888889  0.111111            9
                       Other                0.666667  0.333333           18
                       Person               0.851852  0.148148           27
Geography              Date                 0.466667  0.533333           15
                       Number               0.888889  0.111111           18
                       Other                0.636364  0.363636           11
Misc                   Date                 0.782609  0.217391           23
                       Number               0.777778  0.222222            9
                       Other                0.666667  0.333333           27
                       Person               0.600000  0.400000           15
Music                  Date                 0.750000  0.250000           12
                       Number               1.000000  0.000000            4
                       Other                0.666667  0.333333           12
                       Person               0.750000  0.250000           12
Other                  Date                 0.666667  0.333333           18
                       Number               0.714286  0.285714            7
                       Other                0.857143  0.142857           14
                       Person               0.769231  0.230769           13
Politics               Date                 0.694444  0.305556           36
                       Number               0.666667  0.333333            6
                       Other                0.800000  0.200000           20
                       Person               0.666667  0.333333           15
Science and technology Date                 0.800000  0.200000           35
                       Number               0.642857  0.357143           14
                       Other                0.789474  0.210526           19
                       Person               0.900000  0.100000           30
Sports                 Date                 0.666667  0.333333            9
                       Number               0.545455  0.454545           11
                       Other                0.750000  0.250000           12
                       Person               1.000000  0.000000            8

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      488
Method:                           MLE   Df Model:                           11
Date:                Mon, 04 Aug 2025   Pseudo R-squ.:                 0.01322
Time:                        16:46:57   Log-Likelihood:                -277.45
converged:                       True   LL-Null:                       -281.17
Covariance Type:            nonrobust   LLR p-value:                    0.7630
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.2856      1.320     -0.974      0.330      -3.872       1.301
C(topic_grouped)[T.Geography]                  0.6569      0.453      1.450      0.147      -0.231       1.545
C(topic_grouped)[T.Misc]                       0.5696      0.393      1.449      0.147      -0.201       1.340
C(topic_grouped)[T.Music]                      0.3533      0.472      0.749      0.454      -0.571       1.277
C(topic_grouped)[T.Other]                      0.3438      0.438      0.785      0.432      -0.514       1.202
C(topic_grouped)[T.Politics]                   0.5010      0.398      1.259      0.208      -0.279       1.281
C(topic_grouped)[T.Science and technology]     0.0341      0.393      0.087      0.931      -0.737       0.805
C(topic_grouped)[T.Sports]                     0.4870      0.466      1.046      0.296      -0.426       1.400
C(answer_type_grouped)[T.Number]              -0.1950      0.327     -0.597      0.551      -0.835       0.445
C(answer_type_grouped)[T.Other]               -0.0329      0.265     -0.124      0.901      -0.552       0.486
C(answer_type_grouped)[T.Person]              -0.3167      0.293     -1.079      0.281      -0.892       0.259
q_length                                      -0.0106      0.283     -0.037      0.970      -0.566       0.545
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.4642
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      487
Method:                           MLE   Df Model:                           12
Date:                Mon, 04 Aug 2025   Pseudo R-squ.:                  0.1568
Time:                        16:46:57   Log-Likelihood:                -237.07
converged:                       True   LL-Null:                       -281.17
Covariance Type:            nonrobust   LLR p-value:                 1.105e-13
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -3.2192      1.489     -2.162      0.031      -6.138      -0.300
C(topic_grouped)[T.Geography]                  0.7448      0.502      1.484      0.138      -0.239       1.729
C(topic_grouped)[T.Misc]                       0.6848      0.431      1.590      0.112      -0.159       1.529
C(topic_grouped)[T.Music]                      0.4569      0.515      0.887      0.375      -0.553       1.466
C(topic_grouped)[T.Other]                      0.2429      0.495      0.491      0.623      -0.727       1.213
C(topic_grouped)[T.Politics]                   0.3851      0.437      0.881      0.378      -0.472       1.242
C(topic_grouped)[T.Science and technology]     0.0744      0.432      0.172      0.863      -0.772       0.921
C(topic_grouped)[T.Sports]                     0.5280      0.525      1.007      0.314      -0.500       1.556
C(answer_type_grouped)[T.Number]              -0.2928      0.368     -0.795      0.426      -1.014       0.429
C(answer_type_grouped)[T.Other]               -0.0309      0.290     -0.106      0.915      -0.599       0.537
C(answer_type_grouped)[T.Person]              -0.3381      0.328     -1.030      0.303      -0.981       0.305
q_length                                       0.0755      0.313      0.242      0.809      -0.537       0.688
capabilities_entropy                           3.0666      0.376      8.158      0.000       2.330       3.803
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      487
Method:                           MLE   Df Model:                           12
Date:                Mon, 04 Aug 2025   Pseudo R-squ.:                  0.1663
Time:                        16:46:57   Log-Likelihood:                -234.40
converged:                       True   LL-Null:                       -281.17
Covariance Type:            nonrobust   LLR p-value:                 1.018e-14
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -2.3508      1.477     -1.591      0.112      -5.246       0.545
C(topic_grouped)[T.Geography]                  0.3520      0.512      0.687      0.492      -0.652       1.356
C(topic_grouped)[T.Misc]                       0.4573      0.431      1.062      0.288      -0.387       1.301
C(topic_grouped)[T.Music]                      0.1538      0.515      0.299      0.765      -0.855       1.163
C(topic_grouped)[T.Other]                      0.1141      0.488      0.234      0.815      -0.843       1.071
C(topic_grouped)[T.Politics]                   0.3006      0.432      0.695      0.487      -0.547       1.148
C(topic_grouped)[T.Science and technology]    -0.3563      0.437     -0.816      0.415      -1.212       0.500
C(topic_grouped)[T.Sports]                     0.4833      0.496      0.975      0.330      -0.488       1.455
C(answer_type_grouped)[T.Number]              -0.6355      0.373     -1.704      0.088      -1.367       0.096
C(answer_type_grouped)[T.Other]               -0.2112      0.296     -0.714      0.475      -0.791       0.369
C(answer_type_grouped)[T.Person]              -0.4045      0.326     -1.242      0.214      -1.043       0.234
q_length                                      -0.0908      0.316     -0.287      0.774      -0.711       0.529
game_entropy                                   3.5417      0.422      8.392      0.000       2.714       4.369
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      486
Method:                           MLE   Df Model:                           13
Date:                Mon, 04 Aug 2025   Pseudo R-squ.:                  0.2641
Time:                        16:46:57   Log-Likelihood:                -206.91
converged:                       True   LL-Null:                       -281.17
Covariance Type:            nonrobust   LLR p-value:                 4.102e-25
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -3.8384      1.616     -2.375      0.018      -7.006      -0.671
C(topic_grouped)[T.Geography]                  0.4765      0.556      0.857      0.391      -0.613       1.566
C(topic_grouped)[T.Misc]                       0.6055      0.456      1.327      0.185      -0.289       1.500
C(topic_grouped)[T.Music]                      0.2956      0.553      0.534      0.593      -0.789       1.380
C(topic_grouped)[T.Other]                      0.0311      0.525      0.059      0.953      -0.998       1.061
C(topic_grouped)[T.Politics]                   0.2734      0.470      0.582      0.561      -0.647       1.194
C(topic_grouped)[T.Science and technology]    -0.2455      0.463     -0.530      0.596      -1.154       0.663
C(topic_grouped)[T.Sports]                     0.5388      0.548      0.984      0.325      -0.535       1.612
C(answer_type_grouped)[T.Number]              -0.7145      0.417     -1.713      0.087      -1.532       0.103
C(answer_type_grouped)[T.Other]               -0.1966      0.317     -0.620      0.535      -0.818       0.425
C(answer_type_grouped)[T.Person]              -0.3763      0.347     -1.085      0.278      -1.056       0.304
q_length                                      -0.0475      0.342     -0.139      0.889      -0.717       0.622
capabilities_entropy                           2.7483      0.394      6.977      0.000       1.976       3.520
game_entropy                                   3.1914      0.436      7.316      0.000       2.336       4.046
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing gemini-1.5-pro (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_new/gemini-1.5-pro_SimpleMC_redacted_cor_temp0.0_1751757561_game_data.json', './sc_logs_new/gemini-1.5-pro_SimpleMC_redacted_temp0.0_1751722404_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    413
1     87
Name: count, dtype: int64

Answer change%: 0.1740 [0.1407701992920378, 0.20722980070796218] (n=500)
P-value vs 25%: 7.372e-06; P-value vs 0%: 1.036e-24
Phase 2 self-accuracy: 0.3678 [0.2664890076427917, 0.46914317626525426] (n=87)
P-value vs 25%: 0.02267; P-value vs 33%: 0.5007
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.893333
                        1                 0.106667
Geography               0                 0.840909
                        1                 0.159091
Misc                    0                 0.770270
                        1                 0.229730
Music                   0                 0.800000
                        1                 0.200000
Other                   0                 0.807692
                        1                 0.192308
Politics                0                 0.857143
                        1                 0.142857
Science and technology  0                 0.795918
                        1                 0.204082
Sports                  0                 0.850000
                        1                 0.150000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.887574
                     1                 0.112426
Number               0                 0.833333
                     1                 0.166667
Other                0                 0.789474
                     1                 0.210526
Person               0                 0.775000
                     1                 0.225000
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.952381  0.047619           21
                       Number               0.888889  0.111111            9
                       Other                0.888889  0.111111           18
                       Person               0.851852  0.148148           27
Geography              Date                 0.866667  0.133333           15
                       Number               0.777778  0.222222           18
                       Other                0.909091  0.090909           11
Misc                   Date                 0.869565  0.130435           23
                       Number               0.777778  0.222222            9
                       Other                0.740741  0.259259           27
                       Person               0.666667  0.333333           15
Music                  Date                 0.916667  0.083333           12
                       Number               1.000000  0.000000            4
                       Other                0.500000  0.500000           12
                       Person               0.916667  0.083333           12
Other                  Date                 0.944444  0.055556           18
                       Number               1.000000  0.000000            7
                       Other                0.642857  0.357143           14
                       Person               0.692308  0.307692           13
Politics               Date                 0.861111  0.138889           36
                       Number               0.833333  0.166667            6
                       Other                0.950000  0.050000           20
                       Person               0.733333  0.266667           15
Science and technology Date                 0.828571  0.171429           35
                       Number               0.785714  0.214286           14
                       Other                0.842105  0.157895           19
                       Person               0.733333  0.266667           30
Sports                 Date                 1.000000  0.000000            9
                       Number               0.818182  0.181818           11
                       Other                0.750000  0.250000           12
                       Person               0.875000  0.125000            8

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      488
Method:                           MLE   Df Model:                           11
Date:                Mon, 04 Aug 2025   Pseudo R-squ.:                 0.03088
Time:                        16:46:57   Log-Likelihood:                -223.95
converged:                       True   LL-Null:                       -231.09
Covariance Type:            nonrobust   LLR p-value:                    0.2182
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -2.4972      1.521     -1.642      0.101      -5.479       0.484
C(topic_grouped)[T.Geography]                  0.6483      0.579      1.120      0.263      -0.486       1.783
C(topic_grouped)[T.Misc]                       0.9746      0.472      2.066      0.039       0.050       1.899
C(topic_grouped)[T.Music]                      0.7626      0.549      1.389      0.165      -0.314       1.839
C(topic_grouped)[T.Other]                      0.7632      0.519      1.471      0.141      -0.253       1.780
C(topic_grouped)[T.Politics]                   0.4881      0.506      0.964      0.335      -0.504       1.480
C(topic_grouped)[T.Science and technology]     0.8454      0.455      1.859      0.063      -0.046       1.737
C(topic_grouped)[T.Sports]                     0.4275      0.587      0.729      0.466      -0.722       1.577
C(answer_type_grouped)[T.Number]               0.4720      0.400      1.180      0.238      -0.312       1.256
C(answer_type_grouped)[T.Other]                0.7384      0.328      2.253      0.024       0.096       1.381
C(answer_type_grouped)[T.Person]               0.8676      0.336      2.584      0.010       0.209       1.526
q_length                                      -0.0499      0.322     -0.155      0.877      -0.681       0.582
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing gemini-2.0-flash-001 (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_new/gemini-2.0-flash-001_SimpleMC_redacted_cor_temp0.0_1754323767_game_data.json', './sc_logs_new/gemini-2.0-flash-001_SimpleMC_redacted_temp0.0_1754323560_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    306
1    194
Name: count, dtype: int64

Answer change%: 0.3880 [0.3452875323652041, 0.4307124676347959] (n=500)
P-value vs 25%: 2.413e-10; P-value vs 0%: 6.543e-71
Phase 2 self-accuracy: 0.3299 [0.26373513050432595, 0.3960586839286637] (n=194)
P-value vs 25%: 0.01794; P-value vs 33%: 0.9268

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Mon, 04 Aug 2025   Pseudo R-squ.:                 0.03324
Time:                        16:46:57   Log-Likelihood:                -322.82
converged:                       True   LL-Null:                       -333.92
Covariance Type:            nonrobust   LLR p-value:                 2.460e-06
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          2.3105      0.611      3.784      0.000       1.114       3.507
p_i_capability    -3.0461      0.664     -4.586      0.000      -4.348      -1.744
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Mon, 04 Aug 2025   Pseudo R-squ.:                 0.04172
Time:                        16:46:57   Log-Likelihood:                -319.99
converged:                       True   LL-Null:                       -333.92
Covariance Type:            nonrobust   LLR p-value:                 1.304e-07
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -0.8333      0.120     -6.936      0.000      -1.069      -0.598
capabilities_entropy     1.1218      0.218      5.149      0.000       0.695       1.549
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.5490 [0.4702, 0.6279] (n=153)
                  P-value vs 33.3%: 8.248e-08

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=5.83, p=2.37e-08
Wilcoxon delta_p: statistic=4192.00, p=9.05e-10
Mean Δp = 0.0771  [0.0512, 0.1031]
Idea 1 N = 186; 

  Idea 1.5: Calibration Metrics
  NLL: 3.4874, Signed ECE (overconf pos under neg): 0.0089, ECE: 0.0666 (n=338)
  Brier: 0.0201, Reliability (absolute calibration error; lower better): 0.0159, Resolution (relative calibration quality; higher better): 0.2310, Uncertainty: 0.2346 (n=338)
  AUROC: 0.9999

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.836
Model:                            OLS   Adj. R-squared:                  0.835
Method:                 Least Squares   F-statistic:                     562.8
Date:                Mon, 04 Aug 2025   Prob (F-statistic):          1.38e-129
Time:                        16:46:57   Log-Likelihood:                 157.53
No. Observations:                 335   AIC:                            -307.1
Df Residuals:                     331   BIC:                            -291.8
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.3806      0.072     -5.309      0.000      -0.522      -0.240
p1                    0.5062      0.078      6.464      0.000       0.352       0.660
answer_changed        0.2894      0.096      3.009      0.003       0.100       0.479
p1:answer_changed     0.4458      0.108      4.144      0.000       0.234       0.657
==============================================================================
Omnibus:                        3.594   Durbin-Watson:                   1.806
Prob(Omnibus):                  0.166   Jarque-Bera (JB):                3.592
Skew:                           0.252   Prob(JB):                        0.166
Kurtosis:                       2.942   Cond. No.                         29.9
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-4.30, p=2.73e-05
Wilcoxon delta_H: statistic=5710.00, p=4.89e-05
Mean ΔH = -0.1924  [-0.2801, -0.1048]
Paired t-test delta_H Changed: statistic=2.34, p=0.0206
Wilcoxon delta_H Changed: statistic=4548.00, p=0.0145
Mean ΔH Changed = 0.1132  [0.0184, 0.2081]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=-6.73, p=7.5e-11
Wilcoxon (p_top2_game vs p_top2_base): statistic=11633.00, p=1.82e-21
Mean Δp_top2 = -0.0297  [-0.0383, -0.0210] (n=339)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=-1.61, p=0.108
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=26337.00, p=0.17
Mean ΔH_unchosen_baseline_set = -0.0545  [-0.1208, 0.0118] (n=339)

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=13026.00, p=2.26e-18
Paired t-test (game_entropy vs capabilities_entropy): statistic=9.59, p=1.94e-19
Mean capabilities_entropy-game_entropy = -0.3025  [-0.3644, -0.2407] (n=339)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  339
Model:                          Logit   Df Residuals:                      336
Method:                           MLE   Df Model:                            2
Date:                Mon, 04 Aug 2025   Pseudo R-squ.:                 0.02093
Time:                        16:46:57   Log-Likelihood:                -228.48
converged:                       True   LL-Null:                       -233.37
Covariance Type:            nonrobust   LLR p-value:                  0.007559
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.0978      0.159     -0.617      0.538      -0.409       0.213
p1_z            -0.4593      0.185     -2.478      0.013      -0.823      -0.096
I(p1_z ** 2)    -0.1009      0.115     -0.875      0.381      -0.327       0.125
================================================================================
AUC = 0.605

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Mon, 04 Aug 2025   Pseudo R-squ.:                 0.09056
Time:                        16:46:57   Log-Likelihood:                -303.68
converged:                       True   LL-Null:                       -333.92
Covariance Type:            nonrobust   LLR p-value:                 7.440e-15
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.3053      0.154     -8.455      0.000      -1.608      -1.003
game_entropy     1.4011      0.190      7.390      0.000       1.030       1.773
================================================================================

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      497
Method:                           MLE   Df Model:                            2
Date:                Mon, 04 Aug 2025   Pseudo R-squ.:                 0.09988
Time:                        16:46:57   Log-Likelihood:                -300.57
converged:                       True   LL-Null:                       -333.92
Covariance Type:            nonrobust   LLR p-value:                 3.272e-15
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.3997      0.161     -8.684      0.000      -1.716      -1.084
capabilities_entropy     0.5935      0.238      2.493      0.013       0.127       1.060
game_entropy             1.2239      0.202      6.058      0.000       0.828       1.620
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.680000
                        1                 0.320000
Geography               1                 0.590909
                        0                 0.409091
Misc                    0                 0.635135
                        1                 0.364865
Music                   0                 0.725000
                        1                 0.275000
Other                   0                 0.615385
                        1                 0.384615
Politics                0                 0.636364
                        1                 0.363636
Science and technology  0                 0.591837
                        1                 0.408163
Sports                  0                 0.550000
                        1                 0.450000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.544379
                     1                 0.455621
Number               1                 0.564103
                     0                 0.435897
Other                0                 0.699248
                     1                 0.300752
Person               0                 0.725000
                     1                 0.275000
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.571429  0.428571           21
                       Number               0.666667  0.333333            9
                       Other                0.722222  0.277778           18
                       Person               0.740741  0.259259           27
Geography              Date                 0.266667  0.733333           15
                       Number               0.333333  0.666667           18
                       Other                0.727273  0.272727           11
Misc                   Date                 0.652174  0.347826           23
                       Number               0.444444  0.555556            9
                       Other                0.703704  0.296296           27
                       Person               0.600000  0.400000           15
Music                  Date                 0.750000  0.250000           12
                       Number               0.750000  0.250000            4
                       Other                0.583333  0.416667           12
                       Person               0.833333  0.166667           12
Other                  Date                 0.500000  0.500000           18
                       Number               0.714286  0.285714            7
                       Other                0.642857  0.357143           14
                       Person               0.692308  0.307692           13
Politics               Date                 0.500000  0.500000           36
                       Number               0.500000  0.500000            6
                       Other                0.800000  0.200000           20
                       Person               0.800000  0.200000           15
Science and technology Date                 0.571429  0.428571           35
                       Number               0.357143  0.642857           14
                       Other                0.631579  0.368421           19
                       Person               0.700000  0.300000           30
Sports                 Date                 0.555556  0.444444            9
                       Number               0.181818  0.818182           11
                       Other                0.750000  0.250000           12
                       Person               0.750000  0.250000            8

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      488
Method:                           MLE   Df Model:                           11
Date:                Mon, 04 Aug 2025   Pseudo R-squ.:                 0.04793
Time:                        16:46:57   Log-Likelihood:                -317.92
converged:                       True   LL-Null:                       -333.92
Covariance Type:            nonrobust   LLR p-value:                 0.0007601
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.6482      1.188     -1.387      0.165      -3.977       0.680
C(topic_grouped)[T.Geography]                  0.8322      0.412      2.020      0.043       0.025       1.640
C(topic_grouped)[T.Misc]                       0.1688      0.354      0.476      0.634      -0.526       0.864
C(topic_grouped)[T.Music]                     -0.2060      0.440     -0.468      0.640      -1.069       0.657
C(topic_grouped)[T.Other]                      0.2379      0.385      0.617      0.537      -0.517       0.993
C(topic_grouped)[T.Politics]                   0.0448      0.357      0.125      0.900      -0.655       0.745
C(topic_grouped)[T.Science and technology]     0.2937      0.329      0.892      0.372      -0.352       0.939
C(topic_grouped)[T.Sports]                     0.4450      0.415      1.071      0.284      -0.369       1.259
C(answer_type_grouped)[T.Number]               0.3011      0.286      1.055      0.292      -0.259       0.861
C(answer_type_grouped)[T.Other]               -0.6498      0.248     -2.616      0.009      -1.137      -0.163
C(answer_type_grouped)[T.Person]              -0.7029      0.262     -2.678      0.007      -1.217      -0.189
q_length                                       0.2776      0.256      1.086      0.277      -0.223       0.779
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.3228
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      487
Method:                           MLE   Df Model:                           12
Date:                Mon, 04 Aug 2025   Pseudo R-squ.:                 0.08310
Time:                        16:46:57   Log-Likelihood:                -306.17
converged:                       True   LL-Null:                       -333.92
Covariance Type:            nonrobust   LLR p-value:                 1.473e-07
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.5997      1.219     -1.313      0.189      -3.988       0.789
C(topic_grouped)[T.Geography]                  0.8541      0.427      2.002      0.045       0.018       1.690
C(topic_grouped)[T.Misc]                       0.1126      0.363      0.310      0.756      -0.599       0.824
C(topic_grouped)[T.Music]                     -0.2512      0.448     -0.561      0.575      -1.129       0.627
C(topic_grouped)[T.Other]                      0.0664      0.397      0.167      0.867      -0.711       0.844
C(topic_grouped)[T.Politics]                   0.0520      0.368      0.141      0.888      -0.669       0.773
C(topic_grouped)[T.Science and technology]     0.2483      0.339      0.732      0.464      -0.416       0.913
C(topic_grouped)[T.Sports]                     0.5347      0.428      1.249      0.212      -0.304       1.374
C(answer_type_grouped)[T.Number]               0.1524      0.296      0.515      0.607      -0.428       0.733
C(answer_type_grouped)[T.Other]               -0.7055      0.255     -2.765      0.006      -1.206      -0.205
C(answer_type_grouped)[T.Person]              -0.6528      0.269     -2.427      0.015      -1.180      -0.126
q_length                                       0.1992      0.263      0.758      0.448      -0.316       0.714
capabilities_entropy                           1.0838      0.229      4.736      0.000       0.635       1.532
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      487
Method:                           MLE   Df Model:                           12
Date:                Mon, 04 Aug 2025   Pseudo R-squ.:                  0.1143
Time:                        16:46:57   Log-Likelihood:                -295.75
converged:                       True   LL-Null:                       -333.92
Covariance Type:            nonrobust   LLR p-value:                 2.043e-11
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -2.4523      1.251     -1.960      0.050      -4.905       0.000
C(topic_grouped)[T.Geography]                  0.8484      0.431      1.968      0.049       0.004       1.693
C(topic_grouped)[T.Misc]                       0.1404      0.371      0.378      0.705      -0.588       0.868
C(topic_grouped)[T.Music]                     -0.3468      0.461     -0.753      0.452      -1.250       0.556
C(topic_grouped)[T.Other]                     -0.0180      0.407     -0.044      0.965      -0.815       0.779
C(topic_grouped)[T.Politics]                   0.0167      0.373      0.045      0.964      -0.714       0.748
C(topic_grouped)[T.Science and technology]     0.2314      0.348      0.666      0.505      -0.450       0.913
C(topic_grouped)[T.Sports]                     0.4976      0.437      1.139      0.255      -0.359       1.354
C(answer_type_grouped)[T.Number]               0.3508      0.303      1.156      0.248      -0.244       0.946
C(answer_type_grouped)[T.Other]               -0.1726      0.270     -0.640      0.522      -0.701       0.356
C(answer_type_grouped)[T.Person]              -0.1969      0.286     -0.688      0.491      -0.758       0.364
q_length                                       0.2360      0.267      0.885      0.376      -0.286       0.758
game_entropy                                   1.3182      0.206      6.398      0.000       0.914       1.722
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      486
Method:                           MLE   Df Model:                           13
Date:                Mon, 04 Aug 2025   Pseudo R-squ.:                  0.1233
Time:                        16:46:57   Log-Likelihood:                -292.75
converged:                       True   LL-Null:                       -333.92
Covariance Type:            nonrobust   LLR p-value:                 3.988e-12
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -2.3042      1.260     -1.828      0.068      -4.774       0.166
C(topic_grouped)[T.Geography]                  0.8461      0.435      1.946      0.052      -0.006       1.698
C(topic_grouped)[T.Misc]                       0.1077      0.374      0.288      0.773      -0.626       0.841
C(topic_grouped)[T.Music]                     -0.3445      0.461     -0.748      0.455      -1.247       0.559
C(topic_grouped)[T.Other]                     -0.0795      0.412     -0.193      0.847      -0.886       0.727
C(topic_grouped)[T.Politics]                   0.0244      0.376      0.065      0.948      -0.712       0.761
C(topic_grouped)[T.Science and technology]     0.2177      0.350      0.622      0.534      -0.468       0.904
C(topic_grouped)[T.Sports]                     0.5364      0.441      1.217      0.224      -0.327       1.400
C(answer_type_grouped)[T.Number]               0.2577      0.308      0.837      0.403      -0.346       0.861
C(answer_type_grouped)[T.Other]               -0.2773      0.275     -1.008      0.313      -0.816       0.262
C(answer_type_grouped)[T.Person]              -0.2376      0.288     -0.824      0.410      -0.803       0.328
q_length                                       0.1980      0.269      0.737      0.461      -0.329       0.725
capabilities_entropy                           0.6074      0.249      2.444      0.015       0.120       1.095
game_entropy                                   1.1193      0.221      5.067      0.000       0.686       1.552
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing gemini-2.5-flash-preview-04-17 (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_new/gemini-2.5-flash-preview-04-17_SimpleMC_redacted_cor_temp0.0_1751802958_game_data.json', './sc_logs_new/gemini-2.5-flash-preview-04-17_SimpleMC_redacted_temp0.0_1751726354_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    324
1    176
Name: count, dtype: int64

Answer change%: 0.3520 [0.3101378120217051, 0.39386218797829486] (n=500)
P-value vs 25%: 1.792e-06; P-value vs 0%: 5.071e-61
Phase 2 self-accuracy: 0.3239 [0.2547299049864159, 0.3929973677408568] (n=176)
P-value vs 25%: 0.03625; P-value vs 33%: 0.7956

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Mon, 04 Aug 2025   Pseudo R-squ.:                0.002049
Time:                        16:46:57   Log-Likelihood:                -323.67
converged:                       True   LL-Null:                       -324.34
Covariance Type:            nonrobust   LLR p-value:                    0.2489
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.6217      0.094     -6.595      0.000      -0.806      -0.437
game_entropy     1.0779      1.024      1.053      0.292      -0.928       3.084
================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.746667
                        1                 0.253333
Geography               0                 0.545455
                        1                 0.454545
Misc                    0                 0.500000
                        1                 0.500000
Music                   0                 0.650000
                        1                 0.350000
Other                   0                 0.807692
                        1                 0.192308
Politics                0                 0.701299
                        1                 0.298701
Science and technology  0                 0.591837
                        1                 0.408163
Sports                  0                 0.675000
                        1                 0.325000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.644970
                     1                 0.355030
Number               0                 0.512821
                     1                 0.487179
Other                0                 0.669173
                     1                 0.330827
Person               0                 0.716667
                     1                 0.283333
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.809524  0.190476           21
                       Number               0.444444  0.555556            9
                       Other                0.666667  0.333333           18
                       Person               0.851852  0.148148           27
Geography              Date                 0.466667  0.533333           15
                       Number               0.500000  0.500000           18
                       Other                0.727273  0.272727           11
Misc                   Date                 0.304348  0.695652           23
                       Number               0.777778  0.222222            9
                       Other                0.629630  0.370370           27
                       Person               0.400000  0.600000           15
Music                  Date                 0.750000  0.250000           12
                       Number               0.500000  0.500000            4
                       Other                0.583333  0.416667           12
                       Person               0.666667  0.333333           12
Other                  Date                 0.777778  0.222222           18
                       Number               0.714286  0.285714            7
                       Other                0.785714  0.214286           14
                       Person               0.923077  0.076923           13
Politics               Date                 0.694444  0.305556           36
                       Number               0.500000  0.500000            6
                       Other                0.800000  0.200000           20
                       Person               0.666667  0.333333           15
Science and technology Date                 0.628571  0.371429           35
                       Number               0.357143  0.642857           14
                       Other                0.578947  0.421053           19
                       Person               0.666667  0.333333           30
Sports                 Date                 0.888889  0.111111            9
                       Number               0.454545  0.545455           11
                       Other                0.583333  0.416667           12
                       Person               0.875000  0.125000            8

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      488
Method:                           MLE   Df Model:                           11
Date:                Mon, 04 Aug 2025   Pseudo R-squ.:                 0.04375
Time:                        16:46:57   Log-Likelihood:                -310.15
converged:                       True   LL-Null:                       -324.34
Covariance Type:            nonrobust   LLR p-value:                  0.002833
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.3452      1.209     -1.112      0.266      -3.716       1.025
C(topic_grouped)[T.Geography]                  0.6557      0.418      1.570      0.116      -0.163       1.474
C(topic_grouped)[T.Misc]                       1.0655      0.357      2.981      0.003       0.365       1.766
C(topic_grouped)[T.Music]                      0.4748      0.428      1.109      0.267      -0.364       1.314
C(topic_grouped)[T.Other]                     -0.3921      0.444     -0.882      0.378      -1.263       0.479
C(topic_grouped)[T.Politics]                   0.1936      0.374      0.518      0.605      -0.539       0.926
C(topic_grouped)[T.Science and technology]     0.6784      0.339      1.999      0.046       0.013       1.344
C(topic_grouped)[T.Sports]                     0.2266      0.437      0.518      0.604      -0.630       1.083
C(answer_type_grouped)[T.Number]               0.5230      0.291      1.794      0.073      -0.048       1.094
C(answer_type_grouped)[T.Other]               -0.1391      0.252     -0.551      0.582      -0.634       0.355
C(answer_type_grouped)[T.Person]              -0.2941      0.269     -1.094      0.274      -0.821       0.233
q_length                                       0.0730      0.260      0.281      0.779      -0.436       0.582
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      487
Method:                           MLE   Df Model:                           12
Date:                Mon, 04 Aug 2025   Pseudo R-squ.:                 0.04530
Time:                        16:46:57   Log-Likelihood:                -309.65
converged:                       True   LL-Null:                       -324.34
Covariance Type:            nonrobust   LLR p-value:                  0.003453
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.3875      1.211     -1.145      0.252      -3.762       0.987
C(topic_grouped)[T.Geography]                  0.6121      0.421      1.455      0.146      -0.212       1.437
C(topic_grouped)[T.Misc]                       1.0599      0.358      2.964      0.003       0.359       1.761
C(topic_grouped)[T.Music]                      0.4755      0.428      1.110      0.267      -0.364       1.315
C(topic_grouped)[T.Other]                     -0.3904      0.444     -0.878      0.380      -1.262       0.481
C(topic_grouped)[T.Politics]                   0.1961      0.374      0.524      0.600      -0.537       0.929
C(topic_grouped)[T.Science and technology]     0.6782      0.340      1.997      0.046       0.013       1.344
C(topic_grouped)[T.Sports]                     0.1781      0.442      0.403      0.687      -0.688       1.044
C(answer_type_grouped)[T.Number]               0.5482      0.293      1.872      0.061      -0.026       1.122
C(answer_type_grouped)[T.Other]               -0.1152      0.254     -0.454      0.650      -0.612       0.382
C(answer_type_grouped)[T.Person]              -0.2768      0.270     -1.026      0.305      -0.805       0.252
q_length                                       0.0787      0.260      0.303      0.762      -0.431       0.588
game_entropy                                   0.9507      1.009      0.942      0.346      -1.027       2.929
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing gpt-4.1-2025-04-14 (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_new/gpt-4.1-2025-04-14_SimpleMC_redacted_cor_temp0.0_1751719329_game_data.json', './sc_logs_new/gpt-4.1-2025-04-14_SimpleMC_redacted_temp0.0_1751719704_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    301
1    191
Name: count, dtype: int64

Answer change%: 0.3882 [0.3451487701638152, 0.43127399406382705] (n=492)
P-value vs 25%: 3.163e-10; P-value vs 0%: 7.246e-70
Phase 2 self-accuracy: 0.3874 [0.31834588520250784, 0.4565232247451362] (n=191)
P-value vs 25%: 9.665e-05; P-value vs 33%: 0.1225

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  492
Model:                          Logit   Df Residuals:                      490
Method:                           MLE   Df Model:                            1
Date:                Mon, 04 Aug 2025   Pseudo R-squ.:                 0.05409
Time:                        16:46:57   Log-Likelihood:                -310.85
converged:                       True   LL-Null:                       -328.63
Covariance Type:            nonrobust   LLR p-value:                 2.484e-09
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          2.1934      0.468      4.688      0.000       1.276       3.110
p_i_capability    -3.0763      0.533     -5.775      0.000      -4.120      -2.032
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  492
Model:                          Logit   Df Residuals:                      490
Method:                           MLE   Df Model:                            1
Date:                Mon, 04 Aug 2025   Pseudo R-squ.:                 0.06625
Time:                        16:46:57   Log-Likelihood:                -306.85
converged:                       True   LL-Null:                       -328.63
Covariance Type:            nonrobust   LLR p-value:                 4.145e-11
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -0.9945      0.130     -7.650      0.000      -1.249      -0.740
capabilities_entropy     1.1421      0.180      6.361      0.000       0.790       1.494
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.7143 [0.6429, 0.7856] (n=154)
                  P-value vs 33.3%: 1.254e-25

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=-4.48, p=1.59e-05
Wilcoxon delta_p: statistic=2460.00, p=4.64e-06
Mean Δp = -0.0681  [-0.0979, -0.0383]
Idea 1 N = 135; 

  Idea 1.5: Calibration Metrics
  NLL: 3.2954, Signed ECE (overconf pos under neg): -0.0090, ECE: 0.1162 (n=265)
  Brier: 0.0387, Reliability (absolute calibration error; lower better): 0.0323, Resolution (relative calibration quality; higher better): 0.2335, Uncertainty: 0.2400 (n=265)
  AUROC: 1.0000

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.906
Model:                            OLS   Adj. R-squared:                  0.905
Method:                 Least Squares   F-statistic:                     835.1
Date:                Mon, 04 Aug 2025   Prob (F-statistic):          1.96e-133
Time:                        16:46:57   Log-Likelihood:                 158.96
No. Observations:                 265   AIC:                            -309.9
Df Residuals:                     261   BIC:                            -295.6
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.6224      0.055    -11.336      0.000      -0.730      -0.514
p1                    0.6732      0.065     10.325      0.000       0.545       0.802
answer_changed        0.4848      0.072      6.776      0.000       0.344       0.626
p1:answer_changed     0.3876      0.087      4.453      0.000       0.216       0.559
==============================================================================
Omnibus:                        5.200   Durbin-Watson:                   1.844
Prob(Omnibus):                  0.074   Jarque-Bera (JB):                7.278
Skew:                          -0.036   Prob(JB):                       0.0263
Kurtosis:                       3.809   Cond. No.                         23.4
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=4.45, p=1.76e-05
Wilcoxon delta_H: statistic=3148.00, p=0.00154
Mean ΔH = 0.1875  [0.1050, 0.2700]
Paired t-test delta_H Changed: statistic=5.98, p=2.09e-08
Wilcoxon delta_H Changed: statistic=1858.00, p=2.47e-08
Mean ΔH Changed = 0.2707  [0.1819, 0.3594]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=6.23, p=1.84e-09
Wilcoxon (p_top2_game vs p_top2_base): statistic=9956.00, p=8.31e-10
Mean Δp_top2 = 0.0310  [0.0213, 0.0408] (n=265)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=7.38, p=2.03e-12
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=9749.00, p=2.89e-10
Mean ΔH_unchosen_baseline_set = 0.2283  [0.1677, 0.2889] (n=265)

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=11088.00, p=1.67e-07
Paired t-test (game_entropy vs capabilities_entropy): statistic=-5.57, p=6.34e-08
Mean capabilities_entropy-game_entropy = 0.1970  [0.1277, 0.2664] (n=265)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  265
Model:                          Logit   Df Residuals:                      262
Method:                           MLE   Df Model:                            2
Date:                Mon, 04 Aug 2025   Pseudo R-squ.:                 0.01734
Time:                        16:46:57   Log-Likelihood:                -180.45
converged:                       True   LL-Null:                       -183.64
Covariance Type:            nonrobust   LLR p-value:                   0.04144
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.1861      0.190     -0.978      0.328      -0.559       0.187
p1_z            -0.1989      0.151     -1.320      0.187      -0.494       0.096
I(p1_z ** 2)     0.1521      0.148      1.025      0.306      -0.139       0.443
================================================================================
AUC = 0.523

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  492
Model:                          Logit   Df Residuals:                      490
Method:                           MLE   Df Model:                            1
Date:                Mon, 04 Aug 2025   Pseudo R-squ.:                 0.08517
Time:                        16:46:57   Log-Likelihood:                -300.64
converged:                       True   LL-Null:                       -328.63
Covariance Type:            nonrobust   LLR p-value:                 7.335e-14
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.0386      0.128     -8.103      0.000      -1.290      -0.787
game_entropy     1.6878      0.238      7.098      0.000       1.222       2.154
================================================================================

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  492
Model:                          Logit   Df Residuals:                      489
Method:                           MLE   Df Model:                            2
Date:                Mon, 04 Aug 2025   Pseudo R-squ.:                  0.1046
Time:                        16:46:57   Log-Likelihood:                -294.24
converged:                       True   LL-Null:                       -328.63
Covariance Type:            nonrobust   LLR p-value:                 1.162e-15
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.2373      0.143     -8.624      0.000      -1.519      -0.956
capabilities_entropy     0.7151      0.201      3.564      0.000       0.322       1.108
game_entropy             1.2883      0.261      4.928      0.000       0.776       1.801
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': None
topic_grouped           answer_changed
Art                     0                 0.621622
                        1                 0.378378
Geography               1                 0.511628
                        0                 0.488372
Misc                    0                 0.594595
                        1                 0.405405
Music                   0                 0.600000
                        1                 0.400000
Other                   0                 0.627451
                        1                 0.372549
Politics                0                 0.586667
                        1                 0.413333
Science and technology  0                 0.635417
                        1                 0.364583
Sports                  0                 0.743590
                        1                 0.256410
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.551515
                     1                 0.448485
Number               1                 0.558442
                     0                 0.441558
Other                0                 0.676768
                     1                 0.323232
Person               0                 0.737288
                     1                 0.262712
Place                0                 0.666667
                     1                 0.333333
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.600000  0.400000           20
                       Number               0.333333  0.666667            9
                       Other                0.538462  0.461538           13
                       Person               0.777778  0.222222           27
                       Place                0.600000  0.400000            5
Geography              Date                 0.428571  0.571429           14
                       Number               0.444444  0.555556           18
                       Other                1.000000  0.000000            3
                       Place                0.500000  0.500000            8
Misc                   Date                 0.434783  0.565217           23
                       Number               0.555556  0.444444            9
                       Other                0.680000  0.320000           25
                       Person               0.733333  0.266667           15
                       Place                0.500000  0.500000            2
Music                  Date                 0.583333  0.416667           12
                       Number               0.250000  0.750000            4
                       Other                0.500000  0.500000           10
                       Person               0.750000  0.250000           12
                       Place                1.000000  0.000000            2
Other                  Date                 0.500000  0.500000           18
                       Number               0.571429  0.428571            7
                       Other                0.555556  0.444444            9
                       Person               0.750000  0.250000           12
                       Place                1.000000  0.000000            5
Politics               Date                 0.600000  0.400000           35
                       Number               0.333333  0.666667            6
                       Other                0.714286  0.285714           14
                       Person               0.500000  0.500000           14
                       Place                0.666667  0.333333            6
Science and technology Date                 0.558824  0.441176           34
                       Number               0.357143  0.642857           14
                       Other                0.866667  0.133333           15
                       Person               0.733333  0.266667           30
                       Place                0.666667  0.333333            3
Sports                 Date                 0.777778  0.222222            9
                       Number               0.600000  0.400000           10
                       Other                0.700000  0.300000           10
                       Person               1.000000  0.000000            8
                       Place                0.500000  0.500000            2

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  492
Model:                          Logit   Df Residuals:                      479
Method:                           MLE   Df Model:                           12
Date:                Mon, 04 Aug 2025   Pseudo R-squ.:                 0.04418
Time:                        16:46:57   Log-Likelihood:                -314.11
converged:                       True   LL-Null:                       -328.63
Covariance Type:            nonrobust   LLR p-value:                  0.003893
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      1.4419      1.198      1.204      0.229      -0.906       3.790
C(topic_grouped)[T.Geography]                  0.1043      0.413      0.253      0.801      -0.705       0.914
C(topic_grouped)[T.Misc]                       0.0652      0.349      0.187      0.852      -0.619       0.749
C(topic_grouped)[T.Music]                      0.0696      0.413      0.169      0.866      -0.739       0.878
C(topic_grouped)[T.Other]                     -0.1354      0.388     -0.349      0.727      -0.896       0.625
C(topic_grouped)[T.Politics]                   0.1227      0.351      0.350      0.727      -0.565       0.810
C(topic_grouped)[T.Science and technology]    -0.1147      0.331     -0.347      0.728      -0.763       0.533
C(topic_grouped)[T.Sports]                    -0.7615      0.453     -1.682      0.093      -1.649       0.126
C(answer_type_grouped)[T.Number]               0.5081      0.289      1.757      0.079      -0.059       1.075
C(answer_type_grouped)[T.Other]               -0.5516      0.273     -2.024      0.043      -1.086      -0.017
C(answer_type_grouped)[T.Person]              -0.8402      0.269     -3.129      0.002      -1.367      -0.314
C(answer_type_grouped)[T.Place]               -0.5153      0.409     -1.260      0.208      -1.317       0.286
q_length                                      -0.3553      0.258     -1.375      0.169      -0.862       0.151
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.4489
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  492
Model:                          Logit   Df Residuals:                      478
Method:                           MLE   Df Model:                           13
Date:                Mon, 04 Aug 2025   Pseudo R-squ.:                 0.09198
Time:                        16:46:57   Log-Likelihood:                -298.40
converged:                       True   LL-Null:                       -328.63
Covariance Type:            nonrobust   LLR p-value:                 4.361e-08
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      0.3518      1.253      0.281      0.779      -2.104       2.807
C(topic_grouped)[T.Geography]                  0.0714      0.426      0.168      0.867      -0.764       0.907
C(topic_grouped)[T.Misc]                      -0.0379      0.363     -0.104      0.917      -0.749       0.673
C(topic_grouped)[T.Music]                      0.0724      0.429      0.169      0.866      -0.769       0.914
C(topic_grouped)[T.Other]                     -0.1288      0.400     -0.322      0.748      -0.913       0.656
C(topic_grouped)[T.Politics]                   0.1921      0.362      0.530      0.596      -0.518       0.903
C(topic_grouped)[T.Science and technology]    -0.1788      0.342     -0.522      0.601      -0.850       0.492
C(topic_grouped)[T.Sports]                    -0.6997      0.469     -1.492      0.136      -1.619       0.219
C(answer_type_grouped)[T.Number]               0.6332      0.300      2.114      0.035       0.046       1.220
C(answer_type_grouped)[T.Other]               -0.2498      0.289     -0.864      0.387      -0.816       0.317
C(answer_type_grouped)[T.Person]              -0.4873      0.284     -1.717      0.086      -1.044       0.069
C(answer_type_grouped)[T.Place]               -0.0967      0.422     -0.229      0.819      -0.925       0.731
q_length                                      -0.2608      0.268     -0.975      0.330      -0.785       0.264
capabilities_entropy                           1.0340      0.189      5.466      0.000       0.663       1.405
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  492
Model:                          Logit   Df Residuals:                      478
Method:                           MLE   Df Model:                           13
Date:                Mon, 04 Aug 2025   Pseudo R-squ.:                  0.1157
Time:                        16:46:57   Log-Likelihood:                -290.61
converged:                       True   LL-Null:                       -328.63
Covariance Type:            nonrobust   LLR p-value:                 6.095e-11
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      0.7976      1.258      0.634      0.526      -1.669       3.264
C(topic_grouped)[T.Geography]                  0.3556      0.435      0.818      0.413      -0.496       1.207
C(topic_grouped)[T.Misc]                       0.1717      0.369      0.465      0.642      -0.552       0.895
C(topic_grouped)[T.Music]                      0.1623      0.442      0.367      0.714      -0.705       1.029
C(topic_grouped)[T.Other]                      0.0779      0.413      0.189      0.850      -0.731       0.887
C(topic_grouped)[T.Politics]                   0.4637      0.373      1.243      0.214      -0.267       1.195
C(topic_grouped)[T.Science and technology]     0.0598      0.350      0.171      0.864      -0.627       0.746
C(topic_grouped)[T.Sports]                    -0.9179      0.487     -1.885      0.059      -1.872       0.036
C(answer_type_grouped)[T.Number]               0.5760      0.304      1.894      0.058      -0.020       1.172
C(answer_type_grouped)[T.Other]               -0.2026      0.292     -0.695      0.487      -0.774       0.369
C(answer_type_grouped)[T.Person]              -0.3971      0.290     -1.367      0.172      -0.966       0.172
C(answer_type_grouped)[T.Place]               -0.2002      0.429     -0.466      0.641      -1.042       0.641
q_length                                      -0.4180      0.271     -1.544      0.123      -0.949       0.113
game_entropy                                   1.6645      0.255      6.537      0.000       1.165       2.164
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  492
Model:                          Logit   Df Residuals:                      477
Method:                           MLE   Df Model:                           14
Date:                Mon, 04 Aug 2025   Pseudo R-squ.:                  0.1294
Time:                        16:46:57   Log-Likelihood:                -286.11
converged:                       True   LL-Null:                       -328.63
Covariance Type:            nonrobust   LLR p-value:                 3.252e-12
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      0.2932      1.287      0.228      0.820      -2.230       2.816
C(topic_grouped)[T.Geography]                  0.2857      0.439      0.651      0.515      -0.575       1.146
C(topic_grouped)[T.Misc]                       0.0858      0.375      0.229      0.819      -0.649       0.821
C(topic_grouped)[T.Music]                      0.1438      0.450      0.319      0.749      -0.738       1.026
C(topic_grouped)[T.Other]                      0.0263      0.416      0.063      0.950      -0.789       0.841
C(topic_grouped)[T.Politics]                   0.4382      0.376      1.166      0.244      -0.298       1.175
C(topic_grouped)[T.Science and technology]    -0.0209      0.355     -0.059      0.953      -0.718       0.676
C(topic_grouped)[T.Sports]                    -0.8452      0.491     -1.721      0.085      -1.808       0.118
C(answer_type_grouped)[T.Number]               0.6384      0.307      2.080      0.038       0.037       1.240
C(answer_type_grouped)[T.Other]               -0.0917      0.298     -0.308      0.758      -0.675       0.492
C(answer_type_grouped)[T.Person]              -0.2728      0.296     -0.921      0.357      -0.854       0.308
C(answer_type_grouped)[T.Place]               -0.0085      0.438     -0.019      0.985      -0.866       0.849
q_length                                      -0.3538      0.275     -1.287      0.198      -0.893       0.185
capabilities_entropy                           0.6262      0.209      2.992      0.003       0.216       1.036
game_entropy                                   1.3381      0.276      4.854      0.000       0.798       1.878
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing gpt-4o-2024-08-06 (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_new/gpt-4o-2024-08-06_SimpleMC_redacted_cor_temp0.0_1751718574_game_data.json', './sc_logs_new/gpt-4o-2024-08-06_SimpleMC_redacted_temp0.0_1751721962_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    380
1    120
Name: count, dtype: int64

Answer change%: 0.2400 [0.20256520097837818, 0.2774347990216218] (n=500)
P-value vs 25%: 0.6006; P-value vs 0%: 3.263e-36
Phase 2 self-accuracy: 0.3833 [0.2963429994672314, 0.4703236671994353] (n=120)
P-value vs 25%: 0.002664; P-value vs 33%: 0.2568

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Mon, 04 Aug 2025   Pseudo R-squ.:                 0.07488
Time:                        16:46:57   Log-Likelihood:                -254.91
converged:                       True   LL-Null:                       -275.54
Covariance Type:            nonrobust   LLR p-value:                 1.330e-10
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          0.5849      0.290      2.015      0.044       0.016       1.154
p_i_capability    -2.5797      0.419     -6.153      0.000      -3.401      -1.758
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Mon, 04 Aug 2025   Pseudo R-squ.:                  0.2024
Time:                        16:46:57   Log-Likelihood:                -219.77
converged:                       True   LL-Null:                       -275.54
Covariance Type:            nonrobust   LLR p-value:                 4.496e-26
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -3.2793      0.307    -10.675      0.000      -3.881      -2.677
capabilities_entropy     2.0562      0.234      8.770      0.000       1.597       2.516
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.7333 [0.6542, 0.8125] (n=120)
                  P-value vs 33.3%: 3.817e-23

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=-2.35, p=0.0194
Wilcoxon delta_p: statistic=28640.00, p=0.237
Mean Δp = -0.0174  [-0.0319, -0.0029]
Idea 1 N = 351; 

  Idea 1.5: Calibration Metrics
  NLL: 1.6964, Signed ECE (overconf pos under neg): -0.0207, ECE: 0.1268 (n=470)
  Brier: 0.0588, Reliability (absolute calibration error; lower better): 0.0315, Resolution (relative calibration quality; higher better): 0.2224, Uncertainty: 0.2498 (n=470)
  AUROC: 0.9961

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.702
Model:                            OLS   Adj. R-squared:                  0.700
Method:                 Least Squares   F-statistic:                     365.2
Date:                Mon, 04 Aug 2025   Prob (F-statistic):          6.14e-122
Time:                        16:46:57   Log-Likelihood:                 307.38
No. Observations:                 470   AIC:                            -606.8
Df Residuals:                     466   BIC:                            -590.1
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.2652      0.028     -9.488      0.000      -0.320      -0.210
p1                    0.3102      0.034      9.135      0.000       0.243       0.377
answer_changed        0.0402      0.050      0.800      0.424      -0.058       0.139
p1:answer_changed     0.7060      0.077      9.139      0.000       0.554       0.858
==============================================================================
Omnibus:                       10.503   Durbin-Watson:                   2.043
Prob(Omnibus):                  0.005   Jarque-Bera (JB):               13.739
Skew:                           0.217   Prob(JB):                      0.00104
Kurtosis:                       3.717   Cond. No.                         20.7
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=1.46, p=0.147
Wilcoxon delta_H: statistic=27468.00, p=0.104
Mean ΔH = 0.0346  [-0.0120, 0.0811]
Paired t-test delta_H Changed: statistic=8.13, p=4.91e-13
Wilcoxon delta_H Changed: statistic=1003.00, p=9.95e-12
Mean ΔH Changed = 0.2976  [0.2259, 0.3694]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=4.91, p=1.24e-06
Wilcoxon (p_top2_game vs p_top2_base): statistic=42258.00, p=8.94e-06
Mean Δp_top2 = 0.0173  [0.0104, 0.0241] (n=470)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=4.89, p=1.37e-06
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=40301.00, p=6.43e-07
Mean ΔH_unchosen_baseline_set = 0.1012  [0.0606, 0.1417] (n=470)

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=43044.00, p=2.99e-05
Paired t-test (game_entropy vs capabilities_entropy): statistic=-4.22, p=2.99e-05
Mean capabilities_entropy-game_entropy = 0.0725  [0.0388, 0.1062] (n=470)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  470
Model:                          Logit   Df Residuals:                      467
Method:                           MLE   Df Model:                            2
Date:                Mon, 04 Aug 2025   Pseudo R-squ.:                  0.1934
Time:                        16:46:57   Log-Likelihood:                -214.50
converged:                       True   LL-Null:                       -265.93
Covariance Type:            nonrobust   LLR p-value:                 4.612e-23
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.2784      0.179     -7.143      0.000      -1.629      -0.928
p1_z            -1.3126      0.174     -7.561      0.000      -1.653      -0.972
I(p1_z ** 2)    -0.1902      0.161     -1.182      0.237      -0.506       0.125
================================================================================
AUC = 0.797

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Mon, 04 Aug 2025   Pseudo R-squ.:                  0.1577
Time:                        16:46:57   Log-Likelihood:                -232.08
converged:                       True   LL-Null:                       -275.54
Covariance Type:            nonrobust   LLR p-value:                 1.133e-20
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -2.8058      0.258    -10.878      0.000      -3.311      -2.300
game_entropy     1.7968      0.217      8.275      0.000       1.371       2.222
================================================================================

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      497
Method:                           MLE   Df Model:                            2
Date:                Mon, 04 Aug 2025   Pseudo R-squ.:                  0.2063
Time:                        16:46:57   Log-Likelihood:                -218.69
converged:                       True   LL-Null:                       -275.54
Covariance Type:            nonrobust   LLR p-value:                 2.047e-25
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -3.3521      0.313    -10.693      0.000      -3.966      -2.738
capabilities_entropy     1.6895      0.340      4.973      0.000       1.024       2.355
game_entropy             0.4848      0.332      1.462      0.144      -0.165       1.135
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.733333
                        1                 0.266667
Geography               0                 0.727273
                        1                 0.272727
Misc                    0                 0.675676
                        1                 0.324324
Music                   0                 0.850000
                        1                 0.150000
Other                   0                 0.846154
                        1                 0.153846
Politics                0                 0.753247
                        1                 0.246753
Science and technology  0                 0.765306
                        1                 0.234694
Sports                  0                 0.800000
                        1                 0.200000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.686391
                     1                 0.313609
Number               0                 0.756410
                     1                 0.243590
Other                0                 0.834586
                     1                 0.165414
Person               0                 0.783333
                     1                 0.216667
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.476190  0.523810           21
                       Number               0.777778  0.222222            9
                       Other                0.888889  0.111111           18
                       Person               0.814815  0.185185           27
Geography              Date                 0.600000  0.400000           15
                       Number               0.722222  0.277778           18
                       Other                0.909091  0.090909           11
Misc                   Date                 0.695652  0.304348           23
                       Number               0.666667  0.333333            9
                       Other                0.814815  0.185185           27
                       Person               0.400000  0.600000           15
Music                  Date                 0.916667  0.083333           12
                       Number               1.000000  0.000000            4
                       Other                0.833333  0.166667           12
                       Person               0.750000  0.250000           12
Other                  Date                 0.833333  0.166667           18
                       Number               1.000000  0.000000            7
                       Other                0.785714  0.214286           14
                       Person               0.846154  0.153846           13
Politics               Date                 0.638889  0.361111           36
                       Number               1.000000  0.000000            6
                       Other                0.900000  0.100000           20
                       Person               0.733333  0.266667           15
Science and technology Date                 0.742857  0.257143           35
                       Number               0.500000  0.500000           14
                       Other                0.789474  0.210526           19
                       Person               0.900000  0.100000           30
Sports                 Date                 0.666667  0.333333            9
                       Number               0.818182  0.181818           11
                       Other                0.750000  0.250000           12
                       Person               1.000000  0.000000            8

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      488
Method:                           MLE   Df Model:                           11
Date:                Mon, 04 Aug 2025   Pseudo R-squ.:                 0.03349
Time:                        16:46:57   Log-Likelihood:                -266.31
converged:                       True   LL-Null:                       -275.54
Covariance Type:            nonrobust   LLR p-value:                   0.07156
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      0.3756      1.343      0.280      0.780      -2.258       3.009
C(topic_grouped)[T.Geography]                 -0.0508      0.448     -0.113      0.910      -0.928       0.827
C(topic_grouped)[T.Misc]                       0.3154      0.367      0.858      0.391      -0.405       1.036
C(topic_grouped)[T.Music]                     -0.7346      0.519     -1.416      0.157      -1.751       0.282
C(topic_grouped)[T.Other]                     -0.7414      0.470     -1.578      0.115      -1.663       0.180
C(topic_grouped)[T.Politics]                  -0.1485      0.384     -0.386      0.699      -0.901       0.604
C(topic_grouped)[T.Science and technology]    -0.2175      0.358     -0.607      0.544      -0.920       0.485
C(topic_grouped)[T.Sports]                    -0.3529      0.482     -0.733      0.464      -1.297       0.591
C(answer_type_grouped)[T.Number]              -0.3577      0.323     -1.106      0.269      -0.991       0.276
C(answer_type_grouped)[T.Other]               -0.8939      0.292     -3.056      0.002      -1.467      -0.321
C(answer_type_grouped)[T.Person]              -0.5136      0.286     -1.796      0.072      -1.074       0.047
q_length                                      -0.2170      0.290     -0.747      0.455      -0.786       0.352
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.8282
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      487
Method:                           MLE   Df Model:                           12
Date:                Mon, 04 Aug 2025   Pseudo R-squ.:                  0.2283
Time:                        16:46:57   Log-Likelihood:                -212.64
converged:                       True   LL-Null:                       -275.54
Covariance Type:            nonrobust   LLR p-value:                 4.289e-21
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -2.9455      1.608     -1.832      0.067      -6.096       0.205
C(topic_grouped)[T.Geography]                 -0.2169      0.506     -0.429      0.668      -1.208       0.775
C(topic_grouped)[T.Misc]                       0.2487      0.419      0.594      0.552      -0.572       1.069
C(topic_grouped)[T.Music]                     -0.7948      0.585     -1.360      0.174      -1.941       0.351
C(topic_grouped)[T.Other]                     -0.9084      0.519     -1.750      0.080      -1.926       0.109
C(topic_grouped)[T.Politics]                  -0.2731      0.439     -0.623      0.534      -1.133       0.587
C(topic_grouped)[T.Science and technology]    -0.3589      0.407     -0.881      0.378      -1.157       0.440
C(topic_grouped)[T.Sports]                    -0.2909      0.544     -0.535      0.593      -1.358       0.776
C(answer_type_grouped)[T.Number]              -0.4718      0.355     -1.328      0.184      -1.168       0.225
C(answer_type_grouped)[T.Other]               -0.2034      0.334     -0.610      0.542      -0.857       0.451
C(answer_type_grouped)[T.Person]               0.5056      0.350      1.443      0.149      -0.181       1.192
q_length                                      -0.0523      0.339     -0.154      0.877      -0.716       0.611
capabilities_entropy                           2.2109      0.257      8.610      0.000       1.708       2.714
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      487
Method:                           MLE   Df Model:                           12
Date:                Mon, 04 Aug 2025   Pseudo R-squ.:                  0.1938
Time:                        16:46:57   Log-Likelihood:                -222.13
converged:                       True   LL-Null:                       -275.54
Covariance Type:            nonrobust   LLR p-value:                 2.534e-17
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -2.2924      1.531     -1.497      0.134      -5.293       0.708
C(topic_grouped)[T.Geography]                 -0.1016      0.491     -0.207      0.836      -1.065       0.862
C(topic_grouped)[T.Misc]                       0.3091      0.408      0.757      0.449      -0.491       1.109
C(topic_grouped)[T.Music]                     -0.9533      0.573     -1.664      0.096      -2.076       0.169
C(topic_grouped)[T.Other]                     -1.0642      0.509     -2.091      0.037      -2.062      -0.067
C(topic_grouped)[T.Politics]                  -0.1073      0.422     -0.254      0.799      -0.934       0.719
C(topic_grouped)[T.Science and technology]    -0.3918      0.400     -0.980      0.327      -1.175       0.392
C(topic_grouped)[T.Sports]                    -0.0738      0.525     -0.140      0.888      -1.103       0.956
C(answer_type_grouped)[T.Number]              -0.6924      0.353     -1.964      0.050      -1.383      -0.002
C(answer_type_grouped)[T.Other]               -0.5535      0.325     -1.704      0.088      -1.190       0.083
C(answer_type_grouped)[T.Person]               0.2484      0.334      0.743      0.457      -0.407       0.903
q_length                                      -0.0637      0.325     -0.196      0.844      -0.700       0.572
game_entropy                                   1.9859      0.240      8.287      0.000       1.516       2.456
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      486
Method:                           MLE   Df Model:                           13
Date:                Mon, 04 Aug 2025   Pseudo R-squ.:                  0.2370
Time:                        16:46:57   Log-Likelihood:                -210.23
converged:                       True   LL-Null:                       -275.54
Covariance Type:            nonrobust   LLR p-value:                 1.573e-21
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -3.1367      1.614     -1.943      0.052      -6.301       0.028
C(topic_grouped)[T.Geography]                 -0.2140      0.507     -0.422      0.673      -1.208       0.780
C(topic_grouped)[T.Misc]                       0.2462      0.419      0.587      0.557      -0.576       1.068
C(topic_grouped)[T.Music]                     -0.8518      0.592     -1.440      0.150      -2.011       0.308
C(topic_grouped)[T.Other]                     -1.0209      0.524     -1.950      0.051      -2.047       0.005
C(topic_grouped)[T.Politics]                  -0.2427      0.439     -0.553      0.580      -1.103       0.617
C(topic_grouped)[T.Science and technology]    -0.4095      0.410     -0.998      0.318      -1.214       0.395
C(topic_grouped)[T.Sports]                    -0.2125      0.546     -0.389      0.697      -1.283       0.858
C(answer_type_grouped)[T.Number]              -0.5805      0.361     -1.607      0.108      -1.288       0.127
C(answer_type_grouped)[T.Other]               -0.2689      0.338     -0.795      0.427      -0.932       0.394
C(answer_type_grouped)[T.Person]               0.5472      0.353      1.552      0.121      -0.144       1.238
q_length                                      -0.0321      0.340     -0.094      0.925      -0.698       0.633
capabilities_entropy                           1.6655      0.354      4.708      0.000       0.972       2.359
game_entropy                                   0.7490      0.344      2.180      0.029       0.076       1.422
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing grok-3-latest (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_new/grok-3-latest_SimpleMC_redacted_cor_temp0.0_1751718904_game_data.json', './sc_logs_new/grok-3-latest_SimpleMC_redacted_temp0.0_1751719937_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    333
1    167
Name: count, dtype: int64

Answer change%: 0.3340 [0.2926597178067086, 0.37534028219329146] (n=500)
P-value vs 25%: 6.82e-05; P-value vs 0%: 1.781e-56
Phase 2 self-accuracy: 0.3593 [0.2865133601073383, 0.4320495141441587] (n=167)
P-value vs 25%: 0.003246; P-value vs 33%: 0.479

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Mon, 04 Aug 2025   Pseudo R-squ.:                 0.07609
Time:                        16:46:57   Log-Likelihood:                -294.25
converged:                       True   LL-Null:                       -318.49
Covariance Type:            nonrobust   LLR p-value:                 3.355e-12
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          2.6597      0.521      5.106      0.000       1.639       3.681
p_i_capability    -3.8695      0.592     -6.535      0.000      -5.030      -2.709
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Mon, 04 Aug 2025   Pseudo R-squ.:                  0.1263
Time:                        16:46:57   Log-Likelihood:                -278.27
converged:                       True   LL-Null:                       -318.49
Covariance Type:            nonrobust   LLR p-value:                 3.018e-19
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.5647      0.151    -10.335      0.000      -1.862      -1.268
capabilities_entropy     1.8794      0.225      8.365      0.000       1.439       2.320
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.5988 [0.5245, 0.6731] (n=167)
                  P-value vs 33.3%: 2.573e-12

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=4.25, p=2.8e-05
Wilcoxon delta_p: statistic=16498.00, p=4.6e-10
Mean Δp = 0.0377  [0.0203, 0.0551]
Idea 1 N = 330; 

  Idea 1.5: Calibration Metrics
  NLL: 2.1840, Signed ECE (overconf pos under neg): -0.0143, ECE: 0.0634 (n=497)
  Brier: 0.0232, Reliability (absolute calibration error; lower better): 0.0147, Resolution (relative calibration quality; higher better): 0.2341, Uncertainty: 0.2423 (n=497)
  AUROC: 0.9996

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.819
Model:                            OLS   Adj. R-squared:                  0.818
Method:                 Least Squares   F-statistic:                     744.1
Date:                Mon, 04 Aug 2025   Prob (F-statistic):          1.44e-182
Time:                        16:46:57   Log-Likelihood:                 256.90
No. Observations:                 497   AIC:                            -505.8
Df Residuals:                     493   BIC:                            -489.0
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.4047      0.056     -7.290      0.000      -0.514      -0.296
p1                    0.4794      0.060      8.053      0.000       0.362       0.596
answer_changed        0.3370      0.076      4.441      0.000       0.188       0.486
p1:answer_changed     0.4171      0.087      4.802      0.000       0.246       0.588
==============================================================================
Omnibus:                       65.754   Durbin-Watson:                   2.002
Prob(Omnibus):                  0.000   Jarque-Bera (JB):              227.500
Skew:                           0.569   Prob(JB):                     3.97e-50
Kurtosis:                       6.113   Cond. No.                         28.6
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-7.28, p=2.54e-12
Wilcoxon delta_H: statistic=15293.00, p=4.3e-12
Mean ΔH = -0.2166  [-0.2749, -0.1582]
Paired t-test delta_H Changed: statistic=0.68, p=0.499
Wilcoxon delta_H Changed: statistic=6525.00, p=0.435
Mean ΔH Changed = 0.0267  [-0.0506, 0.1040]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=-6.55, p=1.42e-10
Wilcoxon (p_top2_game vs p_top2_base): statistic=28567.00, p=2.52e-25
Mean Δp_top2 = -0.0216  [-0.0280, -0.0151] (n=497)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=-5.54, p=4.84e-08
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=44665.00, p=7.74e-08
Mean ΔH_unchosen_baseline_set = -0.1348  [-0.1825, -0.0872] (n=497)

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=37029.00, p=8.71e-15
Paired t-test (game_entropy vs capabilities_entropy): statistic=7.59, p=1.58e-13
Mean capabilities_entropy-game_entropy = -0.1796  [-0.2259, -0.1332] (n=497)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  497
Model:                          Logit   Df Residuals:                      494
Method:                           MLE   Df Model:                            2
Date:                Mon, 04 Aug 2025   Pseudo R-squ.:                  0.1266
Time:                        16:46:57   Log-Likelihood:                -277.10
converged:                       True   LL-Null:                       -317.26
Covariance Type:            nonrobust   LLR p-value:                 3.607e-18
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.3634      0.140     -2.595      0.009      -0.638      -0.089
p1_z            -1.3470      0.181     -7.453      0.000      -1.701      -0.993
I(p1_z ** 2)    -0.4188      0.105     -3.979      0.000      -0.625      -0.212
================================================================================
AUC = 0.762

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Mon, 04 Aug 2025   Pseudo R-squ.:                  0.1660
Time:                        16:46:57   Log-Likelihood:                -265.61
converged:                       True   LL-Null:                       -318.49
Covariance Type:            nonrobust   LLR p-value:                 8.309e-25
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.9938      0.185    -10.770      0.000      -2.357      -1.631
game_entropy     1.9366      0.207      9.371      0.000       1.532       2.342
================================================================================

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      497
Method:                           MLE   Df Model:                            2
Date:                Mon, 04 Aug 2025   Pseudo R-squ.:                  0.2098
Time:                        16:46:57   Log-Likelihood:                -251.68
converged:                       True   LL-Null:                       -318.49
Covariance Type:            nonrobust   LLR p-value:                 9.651e-30
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.3460      0.211    -11.144      0.000      -2.759      -1.933
capabilities_entropy     1.2787      0.247      5.183      0.000       0.795       1.762
game_entropy             1.5549      0.222      7.018      0.000       1.121       1.989
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.720000
                        1                 0.280000
Geography               0                 0.500000
                        1                 0.500000
Misc                    0                 0.675676
                        1                 0.324324
Music                   0                 0.800000
                        1                 0.200000
Other                   0                 0.653846
                        1                 0.346154
Politics                0                 0.688312
                        1                 0.311688
Science and technology  0                 0.642857
                        1                 0.357143
Sports                  0                 0.625000
                        1                 0.375000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.686391
                     1                 0.313609
Number               1                 0.512821
                     0                 0.487179
Other                0                 0.714286
                     1                 0.285714
Person               0                 0.700000
                     1                 0.300000
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.761905  0.238095           21
                       Number               0.666667  0.333333            9
                       Other                0.833333  0.166667           18
                       Person               0.629630  0.370370           27
Geography              Date                 0.533333  0.466667           15
                       Number               0.500000  0.500000           18
                       Other                0.454545  0.545455           11
Misc                   Date                 0.869565  0.130435           23
                       Number               0.444444  0.555556            9
                       Other                0.666667  0.333333           27
                       Person               0.533333  0.466667           15
Music                  Date                 0.833333  0.166667           12
                       Number               0.750000  0.250000            4
                       Other                0.750000  0.250000           12
                       Person               0.833333  0.166667           12
Other                  Date                 0.555556  0.444444           18
                       Number               0.428571  0.571429            7
                       Other                0.785714  0.214286           14
                       Person               0.769231  0.230769           13
Politics               Date                 0.722222  0.277778           36
                       Number               0.333333  0.666667            6
                       Other                0.700000  0.300000           20
                       Person               0.733333  0.266667           15
Science and technology Date                 0.600000  0.400000           35
                       Number               0.285714  0.714286           14
                       Other                0.842105  0.157895           19
                       Person               0.733333  0.266667           30
Sports                 Date                 0.555556  0.444444            9
                       Number               0.636364  0.363636           11
                       Other                0.583333  0.416667           12
                       Person               0.750000  0.250000            8

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      488
Method:                           MLE   Df Model:                           11
Date:                Mon, 04 Aug 2025   Pseudo R-squ.:                 0.03502
Time:                        16:46:57   Log-Likelihood:                -307.33
converged:                       True   LL-Null:                       -318.49
Covariance Type:            nonrobust   LLR p-value:                   0.02211
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -2.9073      1.216     -2.391      0.017      -5.290      -0.524
C(topic_grouped)[T.Geography]                  0.7819      0.416      1.882      0.060      -0.032       1.596
C(topic_grouped)[T.Misc]                       0.2213      0.364      0.609      0.543      -0.491       0.934
C(topic_grouped)[T.Music]                     -0.4020      0.476     -0.845      0.398      -1.335       0.531
C(topic_grouped)[T.Other]                      0.3233      0.393      0.822      0.411      -0.448       1.094
C(topic_grouped)[T.Politics]                   0.1032      0.367      0.281      0.779      -0.617       0.823
C(topic_grouped)[T.Science and technology]     0.3056      0.337      0.906      0.365      -0.356       0.967
C(topic_grouped)[T.Sports]                     0.3243      0.426      0.761      0.447      -0.511       1.160
C(answer_type_grouped)[T.Number]               0.7285      0.291      2.503      0.012       0.158       1.299
C(answer_type_grouped)[T.Other]               -0.0898      0.258     -0.348      0.728      -0.596       0.417
C(answer_type_grouped)[T.Person]               0.0545      0.267      0.204      0.838      -0.469       0.578
q_length                                       0.4167      0.260      1.602      0.109      -0.093       0.927
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.4188
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      487
Method:                           MLE   Df Model:                           12
Date:                Mon, 04 Aug 2025   Pseudo R-squ.:                  0.1641
Time:                        16:46:57   Log-Likelihood:                -266.24
converged:                       True   LL-Null:                       -318.49
Covariance Type:            nonrobust   LLR p-value:                 7.273e-17
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -3.8411      1.354     -2.837      0.005      -6.495      -1.187
C(topic_grouped)[T.Geography]                  0.9118      0.452      2.019      0.043       0.027       1.797
C(topic_grouped)[T.Misc]                       0.0568      0.400      0.142      0.887      -0.727       0.841
C(topic_grouped)[T.Music]                     -0.4363      0.518     -0.842      0.400      -1.452       0.579
C(topic_grouped)[T.Other]                      0.1801      0.436      0.413      0.680      -0.674       1.035
C(topic_grouped)[T.Politics]                   0.3005      0.402      0.748      0.455      -0.487       1.088
C(topic_grouped)[T.Science and technology]     0.1798      0.374      0.480      0.631      -0.554       0.914
C(topic_grouped)[T.Sports]                     0.3202      0.470      0.681      0.496      -0.602       1.242
C(answer_type_grouped)[T.Number]               0.8392      0.318      2.638      0.008       0.216       1.463
C(answer_type_grouped)[T.Other]               -0.0987      0.285     -0.347      0.729      -0.656       0.459
C(answer_type_grouped)[T.Person]               0.0503      0.296      0.170      0.865      -0.530       0.630
q_length                                       0.4208      0.286      1.471      0.141      -0.140       0.982
capabilities_entropy                           1.9734      0.235      8.412      0.000       1.514       2.433
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      487
Method:                           MLE   Df Model:                           12
Date:                Mon, 04 Aug 2025   Pseudo R-squ.:                  0.1930
Time:                        16:46:57   Log-Likelihood:                -257.03
converged:                       True   LL-Null:                       -318.49
Covariance Type:            nonrobust   LLR p-value:                 1.613e-20
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -3.4010      1.367     -2.488      0.013      -6.081      -0.721
C(topic_grouped)[T.Geography]                  0.9627      0.462      2.085      0.037       0.058       1.868
C(topic_grouped)[T.Misc]                       0.1916      0.406      0.472      0.637      -0.604       0.988
C(topic_grouped)[T.Music]                     -0.4459      0.516     -0.864      0.387      -1.457       0.565
C(topic_grouped)[T.Other]                      0.1104      0.435      0.254      0.800      -0.743       0.963
C(topic_grouped)[T.Politics]                   0.4426      0.409      1.081      0.280      -0.360       1.245
C(topic_grouped)[T.Science and technology]     0.3899      0.373      1.047      0.295      -0.340       1.120
C(topic_grouped)[T.Sports]                     0.0792      0.472      0.168      0.867      -0.846       1.004
C(answer_type_grouped)[T.Number]               0.7144      0.328      2.179      0.029       0.072       1.357
C(answer_type_grouped)[T.Other]                0.0818      0.290      0.282      0.778      -0.486       0.650
C(answer_type_grouped)[T.Person]               0.1277      0.300      0.425      0.671      -0.461       0.716
q_length                                       0.2119      0.291      0.728      0.466      -0.358       0.782
game_entropy                                   1.9707      0.216      9.133      0.000       1.548       2.394
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      486
Method:                           MLE   Df Model:                           13
Date:                Mon, 04 Aug 2025   Pseudo R-squ.:                  0.2416
Time:                        16:46:57   Log-Likelihood:                -241.54
converged:                       True   LL-Null:                       -318.49
Covariance Type:            nonrobust   LLR p-value:                 3.386e-26
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -4.0228      1.442     -2.789      0.005      -6.849      -1.196
C(topic_grouped)[T.Geography]                  1.0339      0.478      2.161      0.031       0.096       1.971
C(topic_grouped)[T.Misc]                       0.1041      0.422      0.247      0.805      -0.723       0.932
C(topic_grouped)[T.Music]                     -0.5078      0.545     -0.932      0.351      -1.575       0.560
C(topic_grouped)[T.Other]                      0.0496      0.452      0.110      0.913      -0.836       0.935
C(topic_grouped)[T.Politics]                   0.5080      0.425      1.196      0.232      -0.325       1.341
C(topic_grouped)[T.Science and technology]     0.2814      0.391      0.719      0.472      -0.486       1.048
C(topic_grouped)[T.Sports]                     0.1324      0.495      0.267      0.789      -0.838       1.103
C(answer_type_grouped)[T.Number]               0.7880      0.334      2.358      0.018       0.133       1.443
C(answer_type_grouped)[T.Other]                0.0563      0.305      0.185      0.853      -0.541       0.653
C(answer_type_grouped)[T.Person]               0.1259      0.313      0.402      0.688      -0.488       0.740
q_length                                       0.2646      0.304      0.871      0.384      -0.331       0.860
capabilities_entropy                           1.3897      0.255      5.440      0.000       0.889       1.890
game_entropy                                   1.5597      0.231      6.750      0.000       1.107       2.013
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.
