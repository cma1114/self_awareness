
--- Analyzing claude-3-5-sonnet-20241022 (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_new/claude-3-5-sonnet-20241022_SimpleMC_redacted_cor_temp0.0_1753745296_game_data.json', './sc_logs_new/claude-3-5-sonnet-20241022_SimpleMC_redacted_temp0.0_1753644934_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    363
1    137
Name: count, dtype: int64

Answer change%: 0.2740 [0.23490630857931788, 0.31309369142068216] (n=500)
P-value vs 25%: 0.2289; P-value vs 0%: 6.095e-43
Phase 2 self-accuracy: 0.3504 [0.2704767218707924, 0.4302532051365069] (n=137)
P-value vs 25%: 0.0138; P-value vs 33%: 0.6701

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1404
Time:                        16:14:46   Log-Likelihood:                -252.37
converged:                       True   LL-Null:                       -293.60
Covariance Type:            nonrobust   LLR p-value:                 1.075e-19
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          2.0242      0.355      5.700      0.000       1.328       2.720
p_i_capability    -4.4567      0.534     -8.350      0.000      -5.503      -3.411
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1578
Time:                        16:14:46   Log-Likelihood:                -247.27
converged:                       True   LL-Null:                       -293.60
Covariance Type:            nonrobust   LLR p-value:                 6.229e-22
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -3.1118      0.298    -10.439      0.000      -3.696      -2.528
capabilities_entropy     1.8400      0.215      8.561      0.000       1.419       2.261
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.6715 [0.5929, 0.7502] (n=137)
                  P-value vs 33.3%: 3.499e-17

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=7.65, p=1.86e-13
Wilcoxon delta_p: statistic=12157.50, p=1.06e-12
Mean Δp = 0.0674  [0.0501, 0.0846]
Idea 1 N = 363; 

  Idea 1.5: Calibration Metrics
  NLL: 1.0679, Signed ECE (overconf pos under neg): -0.0626, ECE: 0.1490 (n=500)
  Brier: 0.0648, Reliability (absolute calibration error; lower better): 0.0387, Resolution (relative calibration quality; higher better): 0.2126, Uncertainty: 0.2400 (n=500)
  AUROC: 0.9968

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.528
Model:                            OLS   Adj. R-squared:                  0.525
Method:                 Least Squares   F-statistic:                     185.0
Date:                Wed, 24 Sep 2025   Prob (F-statistic):           1.74e-80
Time:                        16:14:46   Log-Likelihood:                 253.84
No. Observations:                 500   AIC:                            -499.7
Df Residuals:                     496   BIC:                            -482.8
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.1292      0.030     -4.349      0.000      -0.188      -0.071
p1                    0.2551      0.037      6.850      0.000       0.182       0.328
answer_changed       -0.0638      0.051     -1.240      0.216      -0.165       0.037
p1:answer_changed     0.6640      0.079      8.394      0.000       0.509       0.819
==============================================================================
Omnibus:                       14.973   Durbin-Watson:                   2.002
Prob(Omnibus):                  0.001   Jarque-Bera (JB):               15.534
Skew:                           0.426   Prob(JB):                     0.000423
Kurtosis:                       3.143   Cond. No.                         19.0
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-0.63, p=0.532
Wilcoxon delta_H: statistic=22156.50, p=0.391
Mean ΔH = -0.0119  [-0.0490, 0.0253]
Paired t-test delta_H Changed: statistic=3.66, p=0.000364
Wilcoxon delta_H Changed: statistic=3052.00, p=0.000321
Mean ΔH Changed = 0.1080  [0.0501, 0.1659]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=-8.60, p=1.01e-16
Wilcoxon (p_top2_game vs p_top2_base): statistic=27058.00, p=2.36e-16
Mean Δp_top2 = -0.0387  [-0.0475, -0.0299] (n=500)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=1.30, p=0.194
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=45919.50, p=0.228
Mean ΔH_unchosen_baseline_set = 0.0210  [-0.0106, 0.0526] (n=500)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      497
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1572
Time:                        16:14:46   Log-Likelihood:                -247.44
converged:                       True   LL-Null:                       -293.60
Covariance Type:            nonrobust   LLR p-value:                 8.985e-21
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.8227      0.161     -5.097      0.000      -1.139      -0.506
p1_z            -1.2227      0.154     -7.956      0.000      -1.524      -0.921
I(p1_z ** 2)    -0.4441      0.143     -3.102      0.002      -0.725      -0.163
================================================================================
AUC = 0.760

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1522
Time:                        16:14:46   Log-Likelihood:                -248.92
converged:                       True   LL-Null:                       -293.60
Covariance Type:            nonrobust   LLR p-value:                 3.303e-21
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -3.7267      0.404     -9.215      0.000      -4.519      -2.934
game_entropy     2.0155      0.259      7.787      0.000       1.508       2.523
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=25348.50, p=9.88e-19
Paired t-test (game_entropy vs capabilities_entropy): statistic=9.42, p=1.7e-19
Mean game_entropy-capabilities_entropy = 0.1853  [0.1468, 0.2239] (n=500)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      497
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1837
Time:                        16:14:46   Log-Likelihood:                -239.66
converged:                       True   LL-Null:                       -293.60
Covariance Type:            nonrobust   LLR p-value:                 3.743e-24
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -3.9274      0.408     -9.628      0.000      -4.727      -3.128
capabilities_entropy     1.1413      0.274      4.167      0.000       0.604       1.678
game_entropy             1.1869      0.317      3.746      0.000       0.566       1.808
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.800000
                        1                 0.200000
Geography               0                 0.659091
                        1                 0.340909
Misc                    0                 0.837838
                        1                 0.162162
Music                   0                 0.725000
                        1                 0.275000
Other                   0                 0.615385
                        1                 0.384615
Politics                0                 0.753247
                        1                 0.246753
Science and technology  0                 0.663265
                        1                 0.336735
Sports                  0                 0.700000
                        1                 0.300000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.633136
                     1                 0.366864
Number               0                 0.692308
                     1                 0.307692
Other                0                 0.774436
                     1                 0.225564
Person               0                 0.825000
                     1                 0.175000
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.666667  0.333333           21
                       Number               0.666667  0.333333            9
                       Other                0.944444  0.055556           18
                       Person               0.851852  0.148148           27
Geography              Date                 0.533333  0.466667           15
                       Number               0.777778  0.222222           18
                       Other                0.636364  0.363636           11
Misc                   Date                 0.739130  0.260870           23
                       Number               0.666667  0.333333            9
                       Other                0.925926  0.074074           27
                       Person               0.933333  0.066667           15
Music                  Date                 0.583333  0.416667           12
                       Number               0.750000  0.250000            4
                       Other                0.666667  0.333333           12
                       Person               0.916667  0.083333           12
Other                  Date                 0.555556  0.444444           18
                       Number               0.714286  0.285714            7
                       Other                0.714286  0.285714           14
                       Person               0.538462  0.461538           13
Politics               Date                 0.722222  0.277778           36
                       Number               0.500000  0.500000            6
                       Other                0.750000  0.250000           20
                       Person               0.933333  0.066667           15
Science and technology Date                 0.571429  0.428571           35
                       Number               0.571429  0.428571           14
                       Other                0.684211  0.315789           19
                       Person               0.800000  0.200000           30
Sports                 Date                 0.555556  0.444444            9
                       Number               0.818182  0.181818           11
                       Other                0.666667  0.333333           12
                       Person               0.750000  0.250000            8

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      488
Method:                           MLE   Df Model:                           11
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.05155
Time:                        16:14:46   Log-Likelihood:                -278.46
converged:                       True   LL-Null:                       -293.60
Covariance Type:            nonrobust   LLR p-value:                  0.001438
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -2.6737      1.293     -2.068      0.039      -5.207      -0.140
C(topic_grouped)[T.Geography]                  0.5291      0.446      1.187      0.235      -0.345       1.403
C(topic_grouped)[T.Misc]                      -0.3447      0.435     -0.792      0.428      -1.197       0.508
C(topic_grouped)[T.Music]                      0.4219      0.465      0.907      0.365      -0.490       1.334
C(topic_grouped)[T.Other]                      0.8747      0.413      2.116      0.034       0.064       1.685
C(topic_grouped)[T.Politics]                   0.0076      0.408      0.019      0.985      -0.791       0.806
C(topic_grouped)[T.Science and technology]     0.6141      0.367      1.674      0.094      -0.105       1.333
C(topic_grouped)[T.Sports]                     0.4888      0.460      1.062      0.288      -0.413       1.391
C(answer_type_grouped)[T.Number]              -0.3647      0.307     -1.188      0.235      -0.966       0.237
C(answer_type_grouped)[T.Other]               -0.6377      0.268     -2.379      0.017      -1.163      -0.112
C(answer_type_grouped)[T.Person]              -0.9987      0.298     -3.354      0.001      -1.582      -0.415
q_length                                       0.4008      0.278      1.444      0.149      -0.143       0.945
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 1.0251
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      487
Method:                           MLE   Df Model:                           12
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1926
Time:                        16:14:46   Log-Likelihood:                -237.05
converged:                       True   LL-Null:                       -293.60
Covariance Type:            nonrobust   LLR p-value:                 1.455e-18
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -5.0660      1.495     -3.390      0.001      -7.995      -2.137
C(topic_grouped)[T.Geography]                  0.3613      0.485      0.744      0.457      -0.590       1.313
C(topic_grouped)[T.Misc]                      -0.3393      0.469     -0.723      0.470      -1.259       0.581
C(topic_grouped)[T.Music]                      0.3157      0.507      0.623      0.533      -0.678       1.309
C(topic_grouped)[T.Other]                      1.0175      0.462      2.202      0.028       0.112       1.923
C(topic_grouped)[T.Politics]                   0.2626      0.443      0.593      0.553      -0.606       1.131
C(topic_grouped)[T.Science and technology]     0.6895      0.402      1.717      0.086      -0.098       1.477
C(topic_grouped)[T.Sports]                     0.5743      0.510      1.125      0.260      -0.426       1.574
C(answer_type_grouped)[T.Number]              -0.4894      0.332     -1.476      0.140      -1.139       0.161
C(answer_type_grouped)[T.Other]               -0.4309      0.298     -1.446      0.148      -1.015       0.153
C(answer_type_grouped)[T.Person]              -0.7386      0.329     -2.244      0.025      -1.384      -0.093
q_length                                       0.4315      0.309      1.394      0.163      -0.175       1.038
capabilities_entropy                           1.8176      0.223      8.154      0.000       1.381       2.254
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      487
Method:                           MLE   Df Model:                           12
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1909
Time:                        16:14:46   Log-Likelihood:                -237.56
converged:                       True   LL-Null:                       -293.60
Covariance Type:            nonrobust   LLR p-value:                 2.319e-18
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -7.2052      1.581     -4.556      0.000     -10.305      -4.106
C(topic_grouped)[T.Geography]                  0.5360      0.481      1.115      0.265      -0.406       1.478
C(topic_grouped)[T.Misc]                      -0.4789      0.464     -1.033      0.302      -1.388       0.430
C(topic_grouped)[T.Music]                      0.1398      0.499      0.280      0.779      -0.837       1.117
C(topic_grouped)[T.Other]                      0.7922      0.449      1.764      0.078      -0.088       1.672
C(topic_grouped)[T.Politics]                   0.1782      0.438      0.407      0.684      -0.680       1.036
C(topic_grouped)[T.Science and technology]     0.7465      0.401      1.860      0.063      -0.040       1.533
C(topic_grouped)[T.Sports]                     0.4849      0.497      0.976      0.329      -0.489       1.458
C(answer_type_grouped)[T.Number]              -0.6782      0.330     -2.054      0.040      -1.325      -0.031
C(answer_type_grouped)[T.Other]               -0.2418      0.296     -0.817      0.414      -0.822       0.338
C(answer_type_grouped)[T.Person]              -0.4849      0.333     -1.457      0.145      -1.137       0.168
q_length                                       0.7307      0.315      2.318      0.020       0.113       1.349
game_entropy                                   2.1014      0.277      7.596      0.000       1.559       2.644
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      486
Method:                           MLE   Df Model:                           13
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.2190
Time:                        16:14:46   Log-Likelihood:                -229.31
converged:                       True   LL-Null:                       -293.60
Covariance Type:            nonrobust   LLR p-value:                 4.027e-21
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -6.8561      1.617     -4.241      0.000     -10.024      -3.688
C(topic_grouped)[T.Geography]                  0.4160      0.490      0.849      0.396      -0.545       1.377
C(topic_grouped)[T.Misc]                      -0.4518      0.473     -0.956      0.339      -1.378       0.475
C(topic_grouped)[T.Music]                      0.1658      0.511      0.325      0.745      -0.835       1.167
C(topic_grouped)[T.Other]                      0.8975      0.464      1.932      0.053      -0.013       1.808
C(topic_grouped)[T.Politics]                   0.2809      0.448      0.627      0.531      -0.597       1.159
C(topic_grouped)[T.Science and technology]     0.7098      0.408      1.738      0.082      -0.091       1.510
C(topic_grouped)[T.Sports]                     0.5197      0.511      1.016      0.310      -0.483       1.522
C(answer_type_grouped)[T.Number]              -0.6495      0.337     -1.929      0.054      -1.309       0.010
C(answer_type_grouped)[T.Other]               -0.2667      0.304     -0.876      0.381      -0.863       0.330
C(answer_type_grouped)[T.Person]              -0.5490      0.341     -1.611      0.107      -1.217       0.119
q_length                                       0.6150      0.323      1.905      0.057      -0.018       1.248
capabilities_entropy                           1.1089      0.281      3.943      0.000       0.558       1.660
game_entropy                                   1.2811      0.338      3.787      0.000       0.618       1.944
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing claude-3-haiku-20240307 (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_new/claude-3-haiku-20240307_SimpleMC_redacted_cor_temp0.0_1754173427_game_data.json', './sc_logs_new/claude-3-haiku-20240307_SimpleMC_redacted_temp0.0_1754183680_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    377
1    123
Name: count, dtype: int64

Answer change%: 0.2460 [0.20825005568487207, 0.2837499443151279] (n=500)
P-value vs 25%: 0.8355; P-value vs 0%: 2.343e-37
Phase 2 self-accuracy: 0.2846 [0.20481476406627758, 0.364290926990633] (n=123)
P-value vs 25%: 0.3957; P-value vs 33%: 0.2337

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.03772
Time:                        16:14:46   Log-Likelihood:                -268.43
converged:                       True   LL-Null:                       -278.95
Covariance Type:            nonrobust   LLR p-value:                 4.489e-06
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          1.9248      0.661      2.914      0.004       0.630       3.220
p_i_capability    -3.4164      0.738     -4.629      0.000      -4.863      -1.970
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.04029
Time:                        16:14:46   Log-Likelihood:                -267.71
converged:                       True   LL-Null:                       -278.95
Covariance Type:            nonrobust   LLR p-value:                 2.124e-06
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.8785      0.197     -9.546      0.000      -2.264      -1.493
capabilities_entropy     1.6194      0.340      4.757      0.000       0.952       2.287
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.3089 [0.2273, 0.3906] (n=123)
                  P-value vs 33.3%: 0.5583

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=0.38, p=0.707
Wilcoxon delta_p: statistic=6230.50, p=0.315
Mean Δp = 0.0026  [-0.0110, 0.0163]
Idea 1 N = 377; 

  Idea 1.5: Calibration Metrics
  NLL: 2.9673, Signed ECE (overconf pos under neg): -0.0037, ECE: 0.0373 (n=500)
  Brier: 0.0164, Reliability (absolute calibration error; lower better): 0.0039, Resolution (relative calibration quality; higher better): 0.1977, Uncertainty: 0.2108 (n=500)
  AUROC: 0.9988

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.892
Model:                            OLS   Adj. R-squared:                  0.891
Method:                 Least Squares   F-statistic:                     1366.
Date:                Wed, 24 Sep 2025   Prob (F-statistic):          3.22e-239
Time:                        16:14:46   Log-Likelihood:                 373.90
No. Observations:                 500   AIC:                            -739.8
Df Residuals:                     496   BIC:                            -722.9
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.7873      0.053    -14.849      0.000      -0.892      -0.683
p1                    0.8600      0.057     14.992      0.000       0.747       0.973
answer_changed        0.6892      0.075      9.238      0.000       0.543       0.836
p1:answer_changed     0.0989      0.083      1.189      0.235      -0.065       0.262
==============================================================================
Omnibus:                       77.306   Durbin-Watson:                   2.026
Prob(Omnibus):                  0.000   Jarque-Bera (JB):              151.654
Skew:                           0.873   Prob(JB):                     1.17e-33
Kurtosis:                       5.057   Cond. No.                         34.4
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=0.06, p=0.949
Wilcoxon delta_H: statistic=6825.00, p=0.971
Mean ΔH = 0.0021  [-0.0621, 0.0663]
Paired t-test delta_H Changed: statistic=14.49, p=2.74e-28
Wilcoxon delta_H Changed: statistic=382.00, p=4.32e-18
Mean ΔH Changed = 0.8614  [0.7448, 0.9779]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=-0.68, p=0.498
Wilcoxon (p_top2_game vs p_top2_base): statistic=16754.00, p=0.7
Mean Δp_top2 = -0.0013  [-0.0051, 0.0025] (n=500)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=6.45, p=2.71e-10
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=12081.00, p=6.82e-10
Mean ΔH_unchosen_baseline_set = 0.2135  [0.1486, 0.2784] (n=500)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      497
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.04131
Time:                        16:14:46   Log-Likelihood:                -267.43
converged:                       True   LL-Null:                       -278.95
Covariance Type:            nonrobust   LLR p-value:                 9.896e-06
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.3202      0.160     -8.245      0.000      -1.634      -1.006
p1_z            -0.0537      0.292     -0.184      0.854      -0.625       0.518
I(p1_z ** 2)     0.1657      0.121      1.365      0.172      -0.072       0.404
================================================================================
AUC = 0.589

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1281
Time:                        16:14:46   Log-Likelihood:                -243.23
converged:                       True   LL-Null:                       -278.95
Covariance Type:            nonrobust   LLR p-value:                 2.848e-17
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -2.5657      0.221    -11.595      0.000      -2.999      -2.132
game_entropy     2.6928      0.339      7.942      0.000       2.028       3.357
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=13551.50, p=0.00276
Paired t-test (game_entropy vs capabilities_entropy): statistic=2.81, p=0.00521
Mean game_entropy-capabilities_entropy = 0.0476  [0.0144, 0.0809] (n=500)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      497
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1508
Time:                        16:14:46   Log-Likelihood:                -236.89
converged:                       True   LL-Null:                       -278.95
Covariance Type:            nonrobust   LLR p-value:                 5.413e-19
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -3.1184      0.282    -11.052      0.000      -3.671      -2.565
capabilities_entropy     1.3216      0.366      3.615      0.000       0.605       2.038
game_entropy             2.5651      0.345      7.442      0.000       1.890       3.241
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.746667
                        1                 0.253333
Geography               0                 0.590909
                        1                 0.409091
Misc                    0                 0.770270
                        1                 0.229730
Music                   0                 0.775000
                        1                 0.225000
Other                   0                 0.711538
                        1                 0.288462
Politics                0                 0.857143
                        1                 0.142857
Science and technology  0                 0.775510
                        1                 0.224490
Sports                  0                 0.700000
                        1                 0.300000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.733728
                     1                 0.266272
Number               0                 0.743590
                     1                 0.256410
Other                0                 0.789474
                     1                 0.210526
Person               0                 0.750000
                     1                 0.250000
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.714286  0.285714           21
                       Number               0.444444  0.555556            9
                       Other                0.722222  0.277778           18
                       Person               0.888889  0.111111           27
Geography              Date                 0.533333  0.466667           15
                       Number               0.611111  0.388889           18
                       Other                0.636364  0.363636           11
Misc                   Date                 0.652174  0.347826           23
                       Number               1.000000  0.000000            9
                       Other                0.777778  0.222222           27
                       Person               0.800000  0.200000           15
Music                  Date                 0.583333  0.416667           12
                       Number               1.000000  0.000000            4
                       Other                0.833333  0.166667           12
                       Person               0.833333  0.166667           12
Other                  Date                 0.777778  0.222222           18
                       Number               0.857143  0.142857            7
                       Other                0.571429  0.428571           14
                       Person               0.692308  0.307692           13
Politics               Date                 0.888889  0.111111           36
                       Number               0.666667  0.333333            6
                       Other                0.950000  0.050000           20
                       Person               0.733333  0.266667           15
Science and technology Date                 0.800000  0.200000           35
                       Number               0.785714  0.214286           14
                       Other                0.947368  0.052632           19
                       Person               0.633333  0.366667           30
Sports                 Date                 0.555556  0.444444            9
                       Number               0.818182  0.181818           11
                       Other                0.750000  0.250000           12
                       Person               0.625000  0.375000            8

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      488
Method:                           MLE   Df Model:                           11
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.02634
Time:                        16:14:46   Log-Likelihood:                -271.60
converged:                       True   LL-Null:                       -278.95
Covariance Type:            nonrobust   LLR p-value:                    0.1969
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -0.1796      1.343     -0.134      0.894      -2.812       2.453
C(topic_grouped)[T.Geography]                  0.7768      0.424      1.833      0.067      -0.054       1.607
C(topic_grouped)[T.Misc]                      -0.0895      0.387     -0.232      0.817      -0.847       0.668
C(topic_grouped)[T.Music]                     -0.1529      0.464     -0.330      0.742      -1.062       0.756
C(topic_grouped)[T.Other]                      0.1826      0.407      0.448      0.654      -0.616       0.981
C(topic_grouped)[T.Politics]                  -0.6931      0.428     -1.619      0.105      -1.532       0.146
C(topic_grouped)[T.Science and technology]    -0.1600      0.361     -0.443      0.658      -0.868       0.548
C(topic_grouped)[T.Sports]                     0.2934      0.440      0.666      0.505      -0.570       1.157
C(answer_type_grouped)[T.Number]              -0.2889      0.328     -0.881      0.378      -0.932       0.354
C(answer_type_grouped)[T.Other]               -0.3761      0.282     -1.334      0.182      -0.928       0.176
C(answer_type_grouped)[T.Person]              -0.0649      0.282     -0.230      0.818      -0.618       0.489
q_length                                      -0.1699      0.291     -0.585      0.559      -0.739       0.400
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.4423
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      487
Method:                           MLE   Df Model:                           12
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.06478
Time:                        16:14:46   Log-Likelihood:                -260.88
converged:                       True   LL-Null:                       -278.95
Covariance Type:            nonrobust   LLR p-value:                 0.0003074
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.2568      1.413     -0.890      0.374      -4.026       1.512
C(topic_grouped)[T.Geography]                  0.8092      0.436      1.857      0.063      -0.045       1.663
C(topic_grouped)[T.Misc]                      -0.0882      0.396     -0.223      0.823      -0.863       0.687
C(topic_grouped)[T.Music]                     -0.2533      0.483     -0.524      0.600      -1.200       0.694
C(topic_grouped)[T.Other]                      0.1485      0.417      0.356      0.722      -0.670       0.967
C(topic_grouped)[T.Politics]                  -0.6905      0.438     -1.577      0.115      -1.548       0.167
C(topic_grouped)[T.Science and technology]    -0.1961      0.370     -0.530      0.596      -0.921       0.529
C(topic_grouped)[T.Sports]                     0.1862      0.452      0.412      0.681      -0.700       1.073
C(answer_type_grouped)[T.Number]              -0.2755      0.338     -0.816      0.415      -0.937       0.387
C(answer_type_grouped)[T.Other]               -0.3534      0.290     -1.220      0.223      -0.921       0.215
C(answer_type_grouped)[T.Person]               0.0432      0.291      0.149      0.882      -0.526       0.613
q_length                                      -0.1018      0.302     -0.338      0.736      -0.693       0.489
capabilities_entropy                           1.6226      0.351      4.621      0.000       0.934       2.311
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      487
Method:                           MLE   Df Model:                           12
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1572
Time:                        16:14:46   Log-Likelihood:                -235.09
converged:                       True   LL-Null:                       -278.95
Covariance Type:            nonrobust   LLR p-value:                 1.366e-13
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -2.3338      1.507     -1.549      0.121      -5.287       0.620
C(topic_grouped)[T.Geography]                  0.9271      0.461      2.011      0.044       0.024       1.830
C(topic_grouped)[T.Misc]                      -0.1487      0.423     -0.351      0.725      -0.979       0.681
C(topic_grouped)[T.Music]                     -0.1498      0.513     -0.292      0.770      -1.156       0.856
C(topic_grouped)[T.Other]                      0.2230      0.446      0.500      0.617      -0.652       1.098
C(topic_grouped)[T.Politics]                  -0.8747      0.466     -1.876      0.061      -1.789       0.039
C(topic_grouped)[T.Science and technology]    -0.0940      0.388     -0.242      0.809      -0.855       0.667
C(topic_grouped)[T.Sports]                     0.0029      0.492      0.006      0.995      -0.962       0.968
C(answer_type_grouped)[T.Number]              -0.3819      0.357     -1.069      0.285      -1.082       0.318
C(answer_type_grouped)[T.Other]               -0.4813      0.310     -1.552      0.121      -1.089       0.126
C(answer_type_grouped)[T.Person]              -0.1283      0.309     -0.415      0.678      -0.734       0.477
q_length                                      -0.0110      0.321     -0.034      0.973      -0.641       0.619
game_entropy                                   2.8221      0.356      7.932      0.000       2.125       3.519
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      486
Method:                           MLE   Df Model:                           13
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1790
Time:                        16:14:46   Log-Likelihood:                -229.01
converged:                       True   LL-Null:                       -278.95
Covariance Type:            nonrobust   LLR p-value:                 1.756e-15
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -3.0330      1.551     -1.955      0.051      -6.073       0.007
C(topic_grouped)[T.Geography]                  0.9304      0.466      1.996      0.046       0.017       1.844
C(topic_grouped)[T.Misc]                      -0.1645      0.432     -0.381      0.703      -1.010       0.681
C(topic_grouped)[T.Music]                     -0.2377      0.527     -0.451      0.652      -1.271       0.796
C(topic_grouped)[T.Other]                      0.1795      0.450      0.399      0.690      -0.702       1.061
C(topic_grouped)[T.Politics]                  -0.8876      0.471     -1.883      0.060      -1.812       0.036
C(topic_grouped)[T.Science and technology]    -0.1252      0.392     -0.319      0.750      -0.894       0.644
C(topic_grouped)[T.Sports]                    -0.0809      0.498     -0.162      0.871      -1.057       0.895
C(answer_type_grouped)[T.Number]              -0.3773      0.362     -1.041      0.298      -1.087       0.333
C(answer_type_grouped)[T.Other]               -0.4725      0.314     -1.507      0.132      -1.087       0.142
C(answer_type_grouped)[T.Person]              -0.0590      0.317     -0.186      0.852      -0.680       0.562
q_length                                       0.0214      0.328      0.065      0.948      -0.622       0.665
capabilities_entropy                           1.3273      0.377      3.520      0.000       0.588       2.066
game_entropy                                   2.7070      0.362      7.468      0.000       1.997       3.417
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing claude-3-sonnet-20240229 (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_new/claude-3-sonnet-20240229_SimpleMC_redacted_cor_temp0.0_1751757346_game_data.json', './sc_logs_new/claude-3-sonnet-20240229_SimpleMC_redacted_temp0.0_1751717606_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    308
1    192
Name: count, dtype: int64

Answer change%: 0.3840 [0.34136963440733187, 0.42663036559266815] (n=500)
P-value vs 25%: 7.24e-10; P-value vs 0%: 9.364e-70
Phase 2 self-accuracy: 0.2552 [0.19353998643958548, 0.31687668022708115] (n=192)
P-value vs 25%: 0.8685; P-value vs 33%: 0.01342
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.626667
                        1                 0.373333
Geography               0                 0.568182
                        1                 0.431818
Misc                    0                 0.689189
                        1                 0.310811
Music                   0                 0.825000
                        1                 0.175000
Other                   0                 0.519231
                        1                 0.480769
Politics                0                 0.558442
                        1                 0.441558
Science and technology  0                 0.622449
                        1                 0.377551
Sports                  0                 0.525000
                        1                 0.475000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.579882
                     1                 0.420118
Number               1                 0.525641
                     0                 0.474359
Other                0                 0.714286
                     1                 0.285714
Person               0                 0.650000
                     1                 0.350000
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.523810  0.476190           21
                       Number               0.555556  0.444444            9
                       Other                0.777778  0.222222           18
                       Person               0.629630  0.370370           27
Geography              Date                 0.533333  0.466667           15
                       Number               0.555556  0.444444           18
                       Other                0.636364  0.363636           11
Misc                   Date                 0.739130  0.260870           23
                       Number               0.555556  0.444444            9
                       Other                0.703704  0.296296           27
                       Person               0.666667  0.333333           15
Music                  Date                 0.750000  0.250000           12
                       Number               0.750000  0.250000            4
                       Other                0.916667  0.083333           12
                       Person               0.833333  0.166667           12
Other                  Date                 0.500000  0.500000           18
                       Number               0.285714  0.714286            7
                       Other                0.642857  0.357143           14
                       Person               0.538462  0.461538           13
Politics               Date                 0.583333  0.416667           36
                       Number               0.166667  0.833333            6
                       Other                0.700000  0.300000           20
                       Person               0.466667  0.533333           15
Science and technology Date                 0.542857  0.457143           35
                       Number               0.500000  0.500000           14
                       Other                0.789474  0.210526           19
                       Person               0.666667  0.333333           30
Sports                 Date                 0.444444  0.555556            9
                       Number               0.363636  0.636364           11
                       Other                0.500000  0.500000           12
                       Person               0.875000  0.125000            8

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      488
Method:                           MLE   Df Model:                           11
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.04057
Time:                        16:14:46   Log-Likelihood:                -319.48
converged:                       True   LL-Null:                       -332.99
Covariance Type:            nonrobust   LLR p-value:                  0.004564
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      0.1727      1.177      0.147      0.883      -2.135       2.480
C(topic_grouped)[T.Geography]                  0.0240      0.406      0.059      0.953      -0.772       0.820
C(topic_grouped)[T.Misc]                      -0.2554      0.353     -0.724      0.469      -0.947       0.436
C(topic_grouped)[T.Music]                     -1.0309      0.484     -2.129      0.033      -1.980      -0.082
C(topic_grouped)[T.Other]                      0.4291      0.372      1.155      0.248      -0.299       1.157
C(topic_grouped)[T.Politics]                   0.2999      0.342      0.876      0.381      -0.371       0.970
C(topic_grouped)[T.Science and technology]    -0.0230      0.322     -0.072      0.943      -0.653       0.607
C(topic_grouped)[T.Sports]                     0.3532      0.406      0.870      0.384      -0.442       1.148
C(answer_type_grouped)[T.Number]               0.4274      0.287      1.491      0.136      -0.134       0.989
C(answer_type_grouped)[T.Other]               -0.5813      0.253     -2.301      0.021      -1.077      -0.086
C(answer_type_grouped)[T.Person]              -0.2696      0.256     -1.054      0.292      -0.771       0.231
q_length                                      -0.1155      0.254     -0.456      0.649      -0.613       0.381
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing claude-opus-4-1-20250805 (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_new/claude-opus-4-1-20250805_SimpleMC_redacted_cor_temp0.0_1758371084_game_data.json', './sc_logs_new/claude-opus-4-1-20250805_SimpleMC_redacted_temp0.0_1758370707_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    358
1    142
Name: count, dtype: int64

Answer change%: 0.2840 [0.244474372808639, 0.3235256271913609] (n=500)
P-value vs 25%: 0.0918; P-value vs 0%: 4.848e-45
Phase 2 self-accuracy: 0.3732 [0.293687911052664, 0.4527909621867726] (n=142)
P-value vs 25%: 0.002395; P-value vs 33%: 0.3215
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.853333
                        1                 0.146667
Geography               0                 0.750000
                        1                 0.250000
Misc                    0                 0.729730
                        1                 0.270270
Music                   0                 0.650000
                        1                 0.350000
Other                   0                 0.615385
                        1                 0.384615
Politics                0                 0.636364
                        1                 0.363636
Science and technology  0                 0.744898
                        1                 0.255102
Sports                  0                 0.675000
                        1                 0.325000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.757396
                     1                 0.242604
Number               0                 0.653846
                     1                 0.346154
Other                0                 0.684211
                     1                 0.315789
Person               0                 0.733333
                     1                 0.266667
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.857143  0.142857           21
                       Number               0.888889  0.111111            9
                       Other                0.833333  0.166667           18
                       Person               0.851852  0.148148           27
Geography              Date                 0.800000  0.200000           15
                       Number               0.777778  0.222222           18
                       Other                0.636364  0.363636           11
Misc                   Date                 0.826087  0.173913           23
                       Number               0.777778  0.222222            9
                       Other                0.592593  0.407407           27
                       Person               0.800000  0.200000           15
Music                  Date                 0.666667  0.333333           12
                       Number               0.500000  0.500000            4
                       Other                0.583333  0.416667           12
                       Person               0.750000  0.250000           12
Other                  Date                 0.666667  0.333333           18
                       Number               0.285714  0.714286            7
                       Other                0.714286  0.285714           14
                       Person               0.615385  0.384615           13
Politics               Date                 0.694444  0.305556           36
                       Number               0.333333  0.666667            6
                       Other                0.650000  0.350000           20
                       Person               0.600000  0.400000           15
Science and technology Date                 0.800000  0.200000           35
                       Number               0.642857  0.357143           14
                       Other                0.842105  0.157895           19
                       Person               0.666667  0.333333           30
Sports                 Date                 0.666667  0.333333            9
                       Number               0.636364  0.363636           11
                       Other                0.583333  0.416667           12
                       Person               0.875000  0.125000            8

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      488
Method:                           MLE   Df Model:                           11
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.03459
Time:                        16:14:46   Log-Likelihood:                -288.03
converged:                       True   LL-Null:                       -298.35
Covariance Type:            nonrobust   LLR p-value:                   0.03732
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -3.5457      1.280     -2.771      0.006      -6.054      -1.037
C(topic_grouped)[T.Geography]                  0.5731      0.493      1.162      0.245      -0.394       1.540
C(topic_grouped)[T.Misc]                       0.7467      0.422      1.768      0.077      -0.081       1.574
C(topic_grouped)[T.Music]                      1.1709      0.468      2.502      0.012       0.254       2.088
C(topic_grouped)[T.Other]                      1.3160      0.436      3.017      0.003       0.461       2.171
C(topic_grouped)[T.Politics]                   1.1907      0.413      2.885      0.004       0.382       1.999
C(topic_grouped)[T.Science and technology]     0.6774      0.403      1.679      0.093      -0.113       1.468
C(topic_grouped)[T.Sports]                     0.9462      0.476      1.989      0.047       0.014       1.878
C(answer_type_grouped)[T.Number]               0.5971      0.313      1.908      0.056      -0.016       1.211
C(answer_type_grouped)[T.Other]                0.4242      0.266      1.593      0.111      -0.098       0.946
C(answer_type_grouped)[T.Person]               0.2459      0.284      0.866      0.387      -0.311       0.803
q_length                                       0.3373      0.270      1.250      0.211      -0.192       0.866
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing claude-sonnet-4-20250514 (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_new/claude-sonnet-4-20250514_SimpleMC_redacted_cor_temp0.0_1751759842_game_data.json', './sc_logs_new/claude-sonnet-4-20250514_SimpleMC_redacted_temp0.0_1751719035_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    255
1    245
Name: count, dtype: int64

Answer change%: 0.4900 [0.44618263907327455, 0.5338173609267254] (n=500)
P-value vs 25%: 6.951e-27; P-value vs 0%: 1.756e-106
Phase 2 self-accuracy: 0.3633 [0.3030431546377259, 0.4234874576071721] (n=245)
P-value vs 25%: 0.0002276; P-value vs 33%: 0.3246
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.560000
                        1                 0.440000
Geography               0                 0.522727
                        1                 0.477273
Misc                    0                 0.540541
                        1                 0.459459
Music                   0                 0.625000
                        1                 0.375000
Other                   1                 0.653846
                        0                 0.346154
Politics                1                 0.545455
                        0                 0.454545
Science and technology  0                 0.581633
                        1                 0.418367
Sports                  1                 0.625000
                        0                 0.375000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.538462
                     1                 0.461538
Number               1                 0.538462
                     0                 0.461538
Other                0                 0.518797
                     1                 0.481203
Person               1                 0.508333
                     0                 0.491667
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.666667  0.333333           21
                       Number               0.444444  0.555556            9
                       Other                0.666667  0.333333           18
                       Person               0.444444  0.555556           27
Geography              Date                 0.400000  0.600000           15
                       Number               0.555556  0.444444           18
                       Other                0.636364  0.363636           11
Misc                   Date                 0.652174  0.347826           23
                       Number               0.555556  0.444444            9
                       Other                0.481481  0.518519           27
                       Person               0.466667  0.533333           15
Music                  Date                 0.666667  0.333333           12
                       Number               0.500000  0.500000            4
                       Other                0.500000  0.500000           12
                       Person               0.750000  0.250000           12
Other                  Date                 0.277778  0.722222           18
                       Number               0.285714  0.714286            7
                       Other                0.357143  0.642857           14
                       Person               0.461538  0.538462           13
Politics               Date                 0.500000  0.500000           36
                       Number               0.000000  1.000000            6
                       Other                0.550000  0.450000           20
                       Person               0.400000  0.600000           15
Science and technology Date                 0.657143  0.342857           35
                       Number               0.571429  0.428571           14
                       Other                0.578947  0.421053           19
                       Person               0.500000  0.500000           30
Sports                 Date                 0.222222  0.777778            9
                       Number               0.454545  0.545455           11
                       Other                0.333333  0.666667           12
                       Person               0.500000  0.500000            8

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      488
Method:                           MLE   Df Model:                           11
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.02666
Time:                        16:14:46   Log-Likelihood:                -337.24
converged:                       True   LL-Null:                       -346.47
Covariance Type:            nonrobust   LLR p-value:                   0.07123
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      1.1679      1.149      1.016      0.309      -1.084       3.420
C(topic_grouped)[T.Geography]                  0.1278      0.395      0.323      0.747      -0.647       0.903
C(topic_grouped)[T.Misc]                       0.1161      0.333      0.349      0.727      -0.536       0.768
C(topic_grouped)[T.Music]                     -0.2725      0.403     -0.677      0.499      -1.062       0.517
C(topic_grouped)[T.Other]                      0.8930      0.375      2.381      0.017       0.158       1.628
C(topic_grouped)[T.Politics]                   0.5541      0.336      1.651      0.099      -0.104       1.212
C(topic_grouped)[T.Science and technology]    -0.0516      0.312     -0.165      0.869      -0.663       0.560
C(topic_grouped)[T.Sports]                     0.7445      0.405      1.837      0.066      -0.050       1.539
C(answer_type_grouped)[T.Number]               0.3278      0.287      1.142      0.254      -0.235       0.890
C(answer_type_grouped)[T.Other]                0.0539      0.239      0.226      0.821      -0.414       0.522
C(answer_type_grouped)[T.Person]               0.2189      0.249      0.880      0.379      -0.269       0.707
q_length                                      -0.3452      0.248     -1.393      0.164      -0.831       0.141
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing deepseek-chat (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_new/deepseek-chat_SimpleMC_redacted_cor_temp0.0_1753737594_game_data.json', './sc_logs_new/deepseek-chat_SimpleMC_redacted_temp0.0_1753645078_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    370
1    125
Name: count, dtype: int64

Answer change%: 0.2525 [0.21425193035368692, 0.29079857469681814] (n=495)
P-value vs 25%: 0.8971; P-value vs 0%: 2.98e-38
Phase 2 self-accuracy: 0.3760 [0.2910859995361642, 0.4609140004638358] (n=125)
P-value vs 25%: 0.003634; P-value vs 33%: 0.3209

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  495
Model:                          Logit   Df Residuals:                      493
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.06319
Time:                        16:14:47   Log-Likelihood:                -262.04
converged:                       True   LL-Null:                       -279.72
Covariance Type:            nonrobust   LLR p-value:                 2.750e-09
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          1.2606      0.404      3.122      0.002       0.469       2.052
p_i_capability    -3.0717      0.528     -5.818      0.000      -4.106      -2.037
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  495
Model:                          Logit   Df Residuals:                      493
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.08180
Time:                        16:14:47   Log-Likelihood:                -256.84
converged:                       True   LL-Null:                       -279.72
Covariance Type:            nonrobust   LLR p-value:                 1.335e-11
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.1077      0.208    -10.155      0.000      -2.515      -1.701
capabilities_entropy     1.2232      0.190      6.443      0.000       0.851       1.595
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.3760 [0.2911, 0.4609] (n=125)
                  P-value vs 33.3%: 0.3247

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=23.64, p=1.1e-75
Wilcoxon delta_p: statistic=3927.00, p=9.89e-49
Mean Δp = 0.5576  [0.5113, 0.6038]
Idea 1 N = 367; 

  Idea 1.5: Calibration Metrics
  NLL: 3.8173, Signed ECE (overconf pos under neg): -0.2143, ECE: 0.3771 (n=455)
  Brier: 0.4108, Reliability (absolute calibration error; lower better): 0.1739, Resolution (relative calibration quality; higher better): 0.0137, Uncertainty: 0.2480 (n=455)
  AUROC: 0.4243

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.226
Model:                            OLS   Adj. R-squared:                  0.221
Method:                 Least Squares   F-statistic:                     47.51
Date:                Wed, 24 Sep 2025   Prob (F-statistic):           5.91e-27
Time:                        16:14:47   Log-Likelihood:                -234.24
No. Observations:                 492   AIC:                             476.5
Df Residuals:                     488   BIC:                             493.3
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.2788      0.088     -3.158      0.002      -0.452      -0.105
p1                    1.0174      0.104      9.739      0.000       0.812       1.223
answer_changed       -0.1366      0.166     -0.825      0.410      -0.462       0.189
p1:answer_changed     0.2212      0.220      1.004      0.316      -0.212       0.654
==============================================================================
Omnibus:                       93.632   Durbin-Watson:                   1.878
Prob(Omnibus):                  0.000   Jarque-Bera (JB):              104.509
Skew:                          -1.069   Prob(JB):                     2.02e-23
Kurtosis:                       2.277   Cond. No.                         21.2
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=10.38, p=2.59e-22
Wilcoxon delta_H: statistic=15128.00, p=5.03e-20
Mean ΔH = 0.3749  [0.3041, 0.4456]
Paired t-test delta_H Changed: statistic=7.95, p=9.77e-13
Wilcoxon delta_H Changed: statistic=1328.00, p=1.28e-10
Mean ΔH Changed = 0.4279  [0.3224, 0.5333]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=9.84, p=5.7e-21
Wilcoxon (p_top2_game vs p_top2_base): statistic=41758.00, p=2.17e-09
Mean Δp_top2 = 0.0402  [0.0322, 0.0482] (n=492)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=12.86, p=7.76e-33
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=25458.00, p=7.13e-29
Mean ΔH_unchosen_baseline_set = 0.3883  [0.3292, 0.4475] (n=492)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  492
Model:                          Logit   Df Residuals:                      489
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.09213
Time:                        16:14:47   Log-Likelihood:                -253.15
converged:                       True   LL-Null:                       -278.84
Covariance Type:            nonrobust   LLR p-value:                 6.968e-12
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.7036      0.156     -4.506      0.000      -1.010      -0.398
p1_z            -0.9889      0.150     -6.571      0.000      -1.284      -0.694
I(p1_z ** 2)    -0.5358      0.135     -3.980      0.000      -0.800      -0.272
================================================================================
AUC = 0.702

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  495
Model:                          Logit   Df Residuals:                      493
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1477
Time:                        16:14:47   Log-Likelihood:                -238.41
converged:                       True   LL-Null:                       -279.72
Covariance Type:            nonrobust   LLR p-value:                 9.953e-20
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -2.7420      0.234    -11.743      0.000      -3.200      -2.284
game_entropy     3.3527      0.403      8.314      0.000       2.562       4.143
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=34048.00, p=9.15e-18
Paired t-test (game_entropy vs capabilities_entropy): statistic=-10.49, p=2.27e-23
Mean game_entropy-capabilities_entropy = -0.2769  [-0.3286, -0.2251] (n=495)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  495
Model:                          Logit   Df Residuals:                      492
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1927
Time:                        16:14:47   Log-Likelihood:                -225.81
converged:                       True   LL-Null:                       -279.72
Covariance Type:            nonrobust   LLR p-value:                 3.856e-24
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -3.4385      0.301    -11.433      0.000      -4.028      -2.849
capabilities_entropy     1.0147      0.207      4.892      0.000       0.608       1.421
game_entropy             3.0331      0.414      7.330      0.000       2.222       3.844
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.813333
                        1                 0.186667
Geography               0                 0.674419
                        1                 0.325581
Misc                    0                 0.698630
                        1                 0.301370
Music                   0                 0.750000
                        1                 0.250000
Other                   0                 0.750000
                        1                 0.250000
Politics                0                 0.710526
                        1                 0.289474
Science and technology  0                 0.804124
                        1                 0.195876
Sports                  0                 0.717949
                        1                 0.282051
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.724551
                     1                 0.275449
Number               0                 0.753247
                     1                 0.246753
Other                0                 0.727273
                     1                 0.272727
Person               0                 0.798319
                     1                 0.201681
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.857143  0.142857           21
                       Number               0.888889  0.111111            9
                       Other                0.666667  0.333333           18
                       Person               0.851852  0.148148           27
Geography              Date                 0.428571  0.571429           14
                       Number               0.888889  0.111111           18
                       Other                0.636364  0.363636           11
Misc                   Date                 0.772727  0.227273           22
                       Number               0.777778  0.222222            9
                       Other                0.666667  0.333333           27
                       Person               0.600000  0.400000           15
Music                  Date                 0.750000  0.250000           12
                       Number               1.000000  0.000000            4
                       Other                0.666667  0.333333           12
                       Person               0.750000  0.250000           12
Other                  Date                 0.666667  0.333333           18
                       Number               0.714286  0.285714            7
                       Other                0.857143  0.142857           14
                       Person               0.769231  0.230769           13
Politics               Date                 0.694444  0.305556           36
                       Number               0.666667  0.333333            6
                       Other                0.789474  0.210526           19
                       Person               0.666667  0.333333           15
Science and technology Date                 0.800000  0.200000           35
                       Number               0.642857  0.357143           14
                       Other                0.789474  0.210526           19
                       Person               0.896552  0.103448           29
Sports                 Date                 0.666667  0.333333            9
                       Number               0.500000  0.500000           10
                       Other                0.750000  0.250000           12
                       Person               1.000000  0.000000            8

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  495
Model:                          Logit   Df Residuals:                      483
Method:                           MLE   Df Model:                           11
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.01400
Time:                        16:14:47   Log-Likelihood:                -275.81
converged:                       True   LL-Null:                       -279.72
Covariance Type:            nonrobust   LLR p-value:                    0.7284
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.3303      1.318     -1.009      0.313      -3.914       1.254
C(topic_grouped)[T.Geography]                  0.6933      0.455      1.525      0.127      -0.198       1.585
C(topic_grouped)[T.Misc]                       0.5903      0.394      1.500      0.134      -0.181       1.362
C(topic_grouped)[T.Music]                      0.3538      0.472      0.750      0.453      -0.570       1.278
C(topic_grouped)[T.Other]                      0.3437      0.438      0.785      0.432      -0.514       1.202
C(topic_grouped)[T.Politics]                   0.5162      0.398      1.296      0.195      -0.265       1.297
C(topic_grouped)[T.Science and technology]     0.0433      0.394      0.110      0.912      -0.728       0.815
C(topic_grouped)[T.Sports]                     0.5209      0.467      1.116      0.264      -0.394       1.436
C(answer_type_grouped)[T.Number]              -0.2026      0.328     -0.618      0.536      -0.845       0.440
C(answer_type_grouped)[T.Other]               -0.0416      0.266     -0.157      0.876      -0.562       0.479
C(answer_type_grouped)[T.Person]              -0.3229      0.294     -1.099      0.272      -0.899       0.253
q_length                                       0.0006      0.283      0.002      0.998      -0.554       0.556
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.7340
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  495
Model:                          Logit   Df Residuals:                      482
Method:                           MLE   Df Model:                           12
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.09366
Time:                        16:14:47   Log-Likelihood:                -253.52
converged:                       True   LL-Null:                       -279.72
Covariance Type:            nonrobust   LLR p-value:                 5.270e-07
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.8136      1.403     -1.293      0.196      -4.563       0.936
C(topic_grouped)[T.Geography]                  0.6492      0.475      1.367      0.172      -0.282       1.580
C(topic_grouped)[T.Misc]                       0.4172      0.413      1.009      0.313      -0.393       1.227
C(topic_grouped)[T.Music]                      0.3107      0.494      0.629      0.529      -0.658       1.279
C(topic_grouped)[T.Other]                      0.1997      0.458      0.436      0.663      -0.699       1.098
C(topic_grouped)[T.Politics]                   0.4902      0.417      1.175      0.240      -0.328       1.308
C(topic_grouped)[T.Science and technology]     0.0200      0.413      0.048      0.961      -0.790       0.830
C(topic_grouped)[T.Sports]                     0.4743      0.488      0.972      0.331      -0.482       1.431
C(answer_type_grouped)[T.Number]              -0.2797      0.343     -0.816      0.414      -0.952       0.392
C(answer_type_grouped)[T.Other]                0.0103      0.280      0.037      0.971      -0.539       0.559
C(answer_type_grouped)[T.Person]              -0.3269      0.309     -1.059      0.290      -0.932       0.278
q_length                                      -0.1077      0.300     -0.359      0.719      -0.695       0.480
capabilities_entropy                           1.2315      0.194      6.361      0.000       0.852       1.611
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  495
Model:                          Logit   Df Residuals:                      482
Method:                           MLE   Df Model:                           12
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1654
Time:                        16:14:47   Log-Likelihood:                -233.44
converged:                       True   LL-Null:                       -279.72
Covariance Type:            nonrobust   LLR p-value:                 1.578e-14
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -2.3846      1.475     -1.617      0.106      -5.275       0.506
C(topic_grouped)[T.Geography]                  0.3866      0.514      0.752      0.452      -0.621       1.394
C(topic_grouped)[T.Misc]                       0.4759      0.431      1.105      0.269      -0.368       1.320
C(topic_grouped)[T.Music]                      0.1562      0.514      0.304      0.761      -0.851       1.164
C(topic_grouped)[T.Other]                      0.1152      0.488      0.236      0.813      -0.841       1.071
C(topic_grouped)[T.Politics]                   0.3122      0.433      0.722      0.471      -0.536       1.160
C(topic_grouped)[T.Science and technology]    -0.3440      0.436     -0.788      0.431      -1.199       0.511
C(topic_grouped)[T.Sports]                     0.5038      0.496      1.015      0.310      -0.469       1.476
C(answer_type_grouped)[T.Number]              -0.6389      0.374     -1.709      0.087      -1.371       0.094
C(answer_type_grouped)[T.Other]               -0.2166      0.296     -0.731      0.465      -0.798       0.365
C(answer_type_grouped)[T.Person]              -0.4078      0.326     -1.252      0.210      -1.046       0.230
q_length                                      -0.0798      0.316     -0.253      0.800      -0.699       0.539
game_entropy                                   3.5141      0.422      8.331      0.000       2.687       4.341
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  495
Model:                          Logit   Df Residuals:                      481
Method:                           MLE   Df Model:                           13
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.2087
Time:                        16:14:47   Log-Likelihood:                -221.33
converged:                       True   LL-Null:                       -279.72
Covariance Type:            nonrobust   LLR p-value:                 8.688e-19
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -2.4824      1.534     -1.618      0.106      -5.488       0.524
C(topic_grouped)[T.Geography]                  0.3866      0.528      0.732      0.464      -0.649       1.422
C(topic_grouped)[T.Misc]                       0.3553      0.448      0.793      0.428      -0.523       1.234
C(topic_grouped)[T.Music]                      0.1247      0.533      0.234      0.815      -0.920       1.169
C(topic_grouped)[T.Other]                      0.0317      0.496      0.064      0.949      -0.940       1.004
C(topic_grouped)[T.Politics]                   0.3254      0.447      0.728      0.467      -0.551       1.201
C(topic_grouped)[T.Science and technology]    -0.3278      0.449     -0.729      0.466      -1.209       0.553
C(topic_grouped)[T.Sports]                     0.4491      0.519      0.866      0.387      -0.568       1.466
C(answer_type_grouped)[T.Number]              -0.6730      0.380     -1.770      0.077      -1.418       0.072
C(answer_type_grouped)[T.Other]               -0.1733      0.308     -0.563      0.574      -0.777       0.430
C(answer_type_grouped)[T.Person]              -0.3757      0.335     -1.122      0.262      -1.032       0.281
q_length                                      -0.2115      0.328     -0.645      0.519      -0.854       0.431
capabilities_entropy                           1.0227      0.213      4.793      0.000       0.605       1.441
game_entropy                                   3.2083      0.434      7.399      0.000       2.358       4.058
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing gemini-1.5-pro (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_new/gemini-1.5-pro_SimpleMC_redacted_cor_temp0.0_1751757561_game_data.json', './sc_logs_new/gemini-1.5-pro_SimpleMC_redacted_temp0.0_1751722404_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    413
1     87
Name: count, dtype: int64

Answer change%: 0.1740 [0.1407701992920378, 0.20722980070796218] (n=500)
P-value vs 25%: 7.372e-06; P-value vs 0%: 1.036e-24
Phase 2 self-accuracy: 0.3678 [0.2664890076427917, 0.46914317626525426] (n=87)
P-value vs 25%: 0.02267; P-value vs 33%: 0.5007
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.893333
                        1                 0.106667
Geography               0                 0.840909
                        1                 0.159091
Misc                    0                 0.770270
                        1                 0.229730
Music                   0                 0.800000
                        1                 0.200000
Other                   0                 0.807692
                        1                 0.192308
Politics                0                 0.857143
                        1                 0.142857
Science and technology  0                 0.795918
                        1                 0.204082
Sports                  0                 0.850000
                        1                 0.150000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.887574
                     1                 0.112426
Number               0                 0.833333
                     1                 0.166667
Other                0                 0.789474
                     1                 0.210526
Person               0                 0.775000
                     1                 0.225000
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.952381  0.047619           21
                       Number               0.888889  0.111111            9
                       Other                0.888889  0.111111           18
                       Person               0.851852  0.148148           27
Geography              Date                 0.866667  0.133333           15
                       Number               0.777778  0.222222           18
                       Other                0.909091  0.090909           11
Misc                   Date                 0.869565  0.130435           23
                       Number               0.777778  0.222222            9
                       Other                0.740741  0.259259           27
                       Person               0.666667  0.333333           15
Music                  Date                 0.916667  0.083333           12
                       Number               1.000000  0.000000            4
                       Other                0.500000  0.500000           12
                       Person               0.916667  0.083333           12
Other                  Date                 0.944444  0.055556           18
                       Number               1.000000  0.000000            7
                       Other                0.642857  0.357143           14
                       Person               0.692308  0.307692           13
Politics               Date                 0.861111  0.138889           36
                       Number               0.833333  0.166667            6
                       Other                0.950000  0.050000           20
                       Person               0.733333  0.266667           15
Science and technology Date                 0.828571  0.171429           35
                       Number               0.785714  0.214286           14
                       Other                0.842105  0.157895           19
                       Person               0.733333  0.266667           30
Sports                 Date                 1.000000  0.000000            9
                       Number               0.818182  0.181818           11
                       Other                0.750000  0.250000           12
                       Person               0.875000  0.125000            8

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      488
Method:                           MLE   Df Model:                           11
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.03088
Time:                        16:14:47   Log-Likelihood:                -223.95
converged:                       True   LL-Null:                       -231.09
Covariance Type:            nonrobust   LLR p-value:                    0.2182
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -2.4972      1.521     -1.642      0.101      -5.479       0.484
C(topic_grouped)[T.Geography]                  0.6483      0.579      1.120      0.263      -0.486       1.783
C(topic_grouped)[T.Misc]                       0.9746      0.472      2.066      0.039       0.050       1.899
C(topic_grouped)[T.Music]                      0.7626      0.549      1.389      0.165      -0.314       1.839
C(topic_grouped)[T.Other]                      0.7632      0.519      1.471      0.141      -0.253       1.780
C(topic_grouped)[T.Politics]                   0.4881      0.506      0.964      0.335      -0.504       1.480
C(topic_grouped)[T.Science and technology]     0.8454      0.455      1.859      0.063      -0.046       1.737
C(topic_grouped)[T.Sports]                     0.4275      0.587      0.729      0.466      -0.722       1.577
C(answer_type_grouped)[T.Number]               0.4720      0.400      1.180      0.238      -0.312       1.256
C(answer_type_grouped)[T.Other]                0.7384      0.328      2.253      0.024       0.096       1.381
C(answer_type_grouped)[T.Person]               0.8676      0.336      2.584      0.010       0.209       1.526
q_length                                      -0.0499      0.322     -0.155      0.877      -0.681       0.582
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing gemini-2.0-flash-001 (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_new/gemini-2.0-flash-001_SimpleMC_redacted_cor_temp1.0_1757990222_game_data.json', './sc_logs_new/gemini-2.0-flash-001_SimpleMC_redacted_temp1.0_1758161280_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    305
1    195
Name: count, dtype: int64

Answer change%: 0.3900 [0.34724761869923193, 0.4327523813007681] (n=500)
P-value vs 25%: 1.379e-10; P-value vs 0%: 1.707e-71
Phase 2 self-accuracy: 0.3179 [0.2525878457099642, 0.3833095901874717] (n=195)
P-value vs 25%: 0.04159; P-value vs 33%: 0.6517

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.02156
Time:                        16:14:47   Log-Likelihood:                -327.17
converged:                       True   LL-Null:                       -334.37
Covariance Type:            nonrobust   LLR p-value:                 0.0001464
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          1.7966      0.608      2.956      0.003       0.605       2.988
p_i_capability    -2.4594      0.659     -3.735      0.000      -3.750      -1.169
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.03495
Time:                        16:14:47   Log-Likelihood:                -322.69
converged:                       True   LL-Null:                       -334.37
Covariance Type:            nonrobust   LLR p-value:                 1.336e-06
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -0.7864      0.119     -6.627      0.000      -1.019      -0.554
capabilities_entropy     1.0592      0.224      4.722      0.000       0.620       1.499
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.5159 [0.4378, 0.5941] (n=157)
                  P-value vs 33.3%: 4.694e-06

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=8.15, p=5.43e-14
Wilcoxon delta_p: statistic=2941.00, p=1.38e-14
Mean Δp = 0.1442  [0.1095, 0.1788]
Idea 1 N = 184; 

  Idea 1.5: Calibration Metrics
  NLL: 3.7902, Signed ECE (overconf pos under neg): 0.0028, ECE: 0.0230 (n=340)
  Brier: 0.0449, Reliability (absolute calibration error; lower better): 0.0023, Resolution (relative calibration quality; higher better): 0.1899, Uncertainty: 0.2325 (n=340)
  AUROC: 0.9865

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.665
Model:                            OLS   Adj. R-squared:                  0.662
Method:                 Least Squares   F-statistic:                     221.7
Date:                Wed, 24 Sep 2025   Prob (F-statistic):           3.20e-79
Time:                        16:14:47   Log-Likelihood:                 33.869
No. Observations:                 339   AIC:                            -59.74
Df Residuals:                     335   BIC:                            -44.43
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept             0.0161      0.100      0.161      0.872      -0.180       0.212
p1                    0.1416      0.109      1.301      0.194      -0.073       0.356
answer_changed       -0.4606      0.141     -3.268      0.001      -0.738      -0.183
p1:answer_changed     1.1774      0.157      7.495      0.000       0.868       1.486
==============================================================================
Omnibus:                        8.446   Durbin-Watson:                   2.078
Prob(Omnibus):                  0.015   Jarque-Bera (JB):               14.575
Skew:                          -0.022   Prob(JB):                     0.000684
Kurtosis:                       4.015   Cond. No.                         30.0
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-3.04, p=0.00274
Wilcoxon delta_H: statistic=6382.00, p=0.00327
Mean ΔH = -0.1289  [-0.2120, -0.0457]
Paired t-test delta_H Changed: statistic=1.17, p=0.243
Wilcoxon delta_H Changed: statistic=5582.00, p=0.278
Mean ΔH Changed = 0.0602  [-0.0405, 0.1609]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=-8.09, p=1.07e-14
Wilcoxon (p_top2_game vs p_top2_base): statistic=10329.00, p=4.94e-25
Mean Δp_top2 = -0.0382  [-0.0475, -0.0290] (n=341)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=-1.26, p=0.21
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=26741.00, p=0.185
Mean ΔH_unchosen_baseline_set = -0.0418  [-0.1070, 0.0234] (n=341)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  341
Model:                          Logit   Df Residuals:                      338
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.02607
Time:                        16:14:47   Log-Likelihood:                -229.16
converged:                       True   LL-Null:                       -235.29
Covariance Type:            nonrobust   LLR p-value:                  0.002166
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept        0.1301      0.158      0.821      0.412      -0.180       0.441
p1_z            -0.6722      0.196     -3.422      0.001      -1.057      -0.287
I(p1_z ** 2)    -0.2921      0.115     -2.549      0.011      -0.517      -0.068
================================================================================
AUC = 0.609

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.08764
Time:                        16:14:47   Log-Likelihood:                -305.07
converged:                       True   LL-Null:                       -334.37
Covariance Type:            nonrobust   LLR p-value:                 1.924e-14
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.3002      0.156     -8.323      0.000      -1.606      -0.994
game_entropy     1.3445      0.185      7.278      0.000       0.982       1.707
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=26286.00, p=2.53e-29
Paired t-test (game_entropy vs capabilities_entropy): statistic=11.57, p=1.39e-27
Mean game_entropy-capabilities_entropy = 0.2913  [0.2420, 0.3407] (n=500)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      497
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.09729
Time:                        16:14:47   Log-Likelihood:                -301.84
converged:                       True   LL-Null:                       -334.37
Covariance Type:            nonrobust   LLR p-value:                 7.449e-15
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.4075      0.164     -8.574      0.000      -1.729      -1.086
capabilities_entropy     0.6045      0.238      2.535      0.011       0.137       1.072
game_entropy             1.2048      0.193      6.249      0.000       0.827       1.583
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.680000
                        1                 0.320000
Geography               1                 0.522727
                        0                 0.477273
Misc                    0                 0.581081
                        1                 0.418919
Music                   0                 0.725000
                        1                 0.275000
Other                   0                 0.634615
                        1                 0.365385
Politics                0                 0.662338
                        1                 0.337662
Science and technology  0                 0.551020
                        1                 0.448980
Sports                  0                 0.575000
                        1                 0.425000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.550296
                     1                 0.449704
Number               1                 0.589744
                     0                 0.410256
Other                0                 0.714286
                     1                 0.285714
Person               0                 0.708333
                     1                 0.291667
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.571429  0.428571           21
                       Number               0.444444  0.555556            9
                       Other                0.666667  0.333333           18
                       Person               0.851852  0.148148           27
Geography              Date                 0.266667  0.733333           15
                       Number               0.500000  0.500000           18
                       Other                0.727273  0.272727           11
Misc                   Date                 0.608696  0.391304           23
                       Number               0.555556  0.444444            9
                       Other                0.592593  0.407407           27
                       Person               0.533333  0.466667           15
Music                  Date                 0.833333  0.166667           12
                       Number               0.500000  0.500000            4
                       Other                0.583333  0.416667           12
                       Person               0.833333  0.166667           12
Other                  Date                 0.555556  0.444444           18
                       Number               0.571429  0.428571            7
                       Other                0.857143  0.142857           14
                       Person               0.538462  0.461538           13
Politics               Date                 0.527778  0.472222           36
                       Number               0.666667  0.333333            6
                       Other                0.800000  0.200000           20
                       Person               0.800000  0.200000           15
Science and technology Date                 0.514286  0.485714           35
                       Number               0.214286  0.785714           14
                       Other                0.736842  0.263158           19
                       Person               0.633333  0.366667           30
Sports                 Date                 0.666667  0.333333            9
                       Number               0.090909  0.909091           11
                       Other                0.833333  0.166667           12
                       Person               0.750000  0.250000            8

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      488
Method:                           MLE   Df Model:                           11
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.04984
Time:                        16:14:47   Log-Likelihood:                -317.71
converged:                       True   LL-Null:                       -334.37
Covariance Type:            nonrobust   LLR p-value:                 0.0004656
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      0.3616      1.190      0.304      0.761      -1.971       2.694
C(topic_grouped)[T.Geography]                  0.4887      0.411      1.188      0.235      -0.318       1.295
C(topic_grouped)[T.Misc]                       0.4352      0.352      1.236      0.216      -0.255       1.125
C(topic_grouped)[T.Music]                     -0.2179      0.442     -0.493      0.622      -1.084       0.648
C(topic_grouped)[T.Other]                      0.1432      0.390      0.367      0.713      -0.621       0.907
C(topic_grouped)[T.Politics]                   0.0493      0.360      0.137      0.891      -0.656       0.755
C(topic_grouped)[T.Science and technology]     0.5070      0.329      1.542      0.123      -0.138       1.152
C(topic_grouped)[T.Sports]                     0.3265      0.419      0.780      0.436      -0.494       1.147
C(answer_type_grouped)[T.Number]               0.5051      0.287      1.762      0.078      -0.057       1.067
C(answer_type_grouped)[T.Other]               -0.7375      0.251     -2.939      0.003      -1.229      -0.246
C(answer_type_grouped)[T.Person]              -0.6816      0.261     -2.614      0.009      -1.193      -0.171
q_length                                      -0.1758      0.257     -0.685      0.493      -0.679       0.327
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.3084
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      487
Method:                           MLE   Df Model:                           12
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.07470
Time:                        16:14:47   Log-Likelihood:                -309.39
converged:                       True   LL-Null:                       -334.37
Covariance Type:            nonrobust   LLR p-value:                 1.421e-06
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      0.1948      1.212      0.161      0.872      -2.181       2.571
C(topic_grouped)[T.Geography]                  0.5302      0.423      1.253      0.210      -0.299       1.360
C(topic_grouped)[T.Misc]                       0.4728      0.360      1.315      0.189      -0.232       1.178
C(topic_grouped)[T.Music]                     -0.1504      0.446     -0.337      0.736      -1.025       0.725
C(topic_grouped)[T.Other]                      0.1923      0.396      0.486      0.627      -0.584       0.968
C(topic_grouped)[T.Politics]                   0.1584      0.369      0.430      0.667      -0.564       0.881
C(topic_grouped)[T.Science and technology]     0.5514      0.337      1.637      0.102      -0.109       1.211
C(topic_grouped)[T.Sports]                     0.4227      0.428      0.988      0.323      -0.416       1.261
C(answer_type_grouped)[T.Number]               0.3878      0.294      1.320      0.187      -0.188       0.964
C(answer_type_grouped)[T.Other]               -0.7282      0.255     -2.855      0.004      -1.228      -0.228
C(answer_type_grouped)[T.Person]              -0.5955      0.265     -2.243      0.025      -1.116      -0.075
q_length                                      -0.2175      0.262     -0.831      0.406      -0.730       0.295
capabilities_entropy                           0.9360      0.233      4.020      0.000       0.480       1.392
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      487
Method:                           MLE   Df Model:                           12
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1145
Time:                        16:14:47   Log-Likelihood:                -296.08
converged:                       True   LL-Null:                       -334.37
Covariance Type:            nonrobust   LLR p-value:                 1.839e-11
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -0.7400      1.257     -0.589      0.556      -3.204       1.724
C(topic_grouped)[T.Geography]                  0.5140      0.433      1.188      0.235      -0.334       1.362
C(topic_grouped)[T.Misc]                       0.5126      0.367      1.396      0.163      -0.207       1.232
C(topic_grouped)[T.Music]                     -0.1504      0.458     -0.328      0.743      -1.048       0.747
C(topic_grouped)[T.Other]                      0.0651      0.404      0.161      0.872      -0.727       0.857
C(topic_grouped)[T.Politics]                   0.0812      0.377      0.216      0.829      -0.657       0.819
C(topic_grouped)[T.Science and technology]     0.5215      0.347      1.503      0.133      -0.159       1.202
C(topic_grouped)[T.Sports]                     0.4482      0.439      1.021      0.307      -0.412       1.308
C(answer_type_grouped)[T.Number]               0.6236      0.303      2.060      0.039       0.030       1.217
C(answer_type_grouped)[T.Other]               -0.2961      0.271     -1.093      0.275      -0.827       0.235
C(answer_type_grouped)[T.Person]              -0.2329      0.281     -0.829      0.407      -0.784       0.318
q_length                                      -0.1657      0.268     -0.617      0.537      -0.692       0.360
game_entropy                                   1.2506      0.198      6.331      0.000       0.863       1.638
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      486
Method:                           MLE   Df Model:                           13
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1215
Time:                        16:14:47   Log-Likelihood:                -293.73
converged:                       True   LL-Null:                       -334.37
Covariance Type:            nonrobust   LLR p-value:                 6.323e-12
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -0.7401      1.263     -0.586      0.558      -3.216       1.736
C(topic_grouped)[T.Geography]                  0.5288      0.437      1.211      0.226      -0.327       1.384
C(topic_grouped)[T.Misc]                       0.5230      0.370      1.414      0.157      -0.202       1.248
C(topic_grouped)[T.Music]                     -0.1135      0.458     -0.248      0.804      -1.010       0.783
C(topic_grouped)[T.Other]                      0.0970      0.407      0.239      0.811      -0.700       0.894
C(topic_grouped)[T.Politics]                   0.1416      0.379      0.373      0.709      -0.602       0.885
C(topic_grouped)[T.Science and technology]     0.5456      0.350      1.558      0.119      -0.141       1.232
C(topic_grouped)[T.Sports]                     0.4898      0.443      1.106      0.269      -0.378       1.358
C(answer_type_grouped)[T.Number]               0.5413      0.306      1.766      0.077      -0.059       1.142
C(answer_type_grouped)[T.Other]               -0.3368      0.273     -1.232      0.218      -0.873       0.199
C(answer_type_grouped)[T.Person]              -0.2252      0.282     -0.799      0.425      -0.778       0.328
q_length                                      -0.1872      0.270     -0.694      0.488      -0.716       0.341
capabilities_entropy                           0.5351      0.247      2.167      0.030       0.051       1.019
game_entropy                                   1.1252      0.206      5.460      0.000       0.721       1.529
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing gemini-2.5-flash-lite_nothink (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_new/gemini-2.5-flash-lite_nothink_SimpleMC_redacted_cor_temp1.0_1757984044_game_data.json', './sc_logs_new/gemini-2.5-flash-lite_nothink_SimpleMC_redacted_temp1.0_1757983883_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    336
1    164
Name: count, dtype: int64

Answer change%: 0.3280 [0.28684859692739223, 0.3691514030726078] (n=500)
P-value vs 25%: 0.0002032; P-value vs 0%: 5.154e-55
Phase 2 self-accuracy: 0.3293 [0.2573440096403039, 0.4011925757255498] (n=164)
P-value vs 25%: 0.03077; P-value vs 33%: 0.919

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.02687
Time:                        16:14:47   Log-Likelihood:                -307.87
converged:                       True   LL-Null:                       -316.38
Covariance Type:            nonrobust   LLR p-value:                 3.728e-05
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          0.8959      0.401      2.236      0.025       0.110       1.681
p_i_capability    -2.0795      0.508     -4.094      0.000      -3.075      -1.084
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.03391
Time:                        16:14:47   Log-Likelihood:                -305.65
converged:                       True   LL-Null:                       -316.38
Covariance Type:            nonrobust   LLR p-value:                 3.622e-06
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.4091      0.187     -7.547      0.000      -1.775      -1.043
capabilities_entropy     0.8482      0.187      4.540      0.000       0.482       1.214
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.2500 [0.1837, 0.3163] (n=164)
                  P-value vs 33.3%: 0.01372

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=22.89, p=2.83e-69
Wilcoxon delta_p: statistic=2539.00, p=2.34e-44
Mean Δp = 0.5046  [0.4614, 0.5478]
Idea 1 N = 320; 

  Idea 1.5: Calibration Metrics
  NLL: 3.4237, Signed ECE (overconf pos under neg): -0.1584, ECE: 0.3296 (n=498)
  Brier: 0.3613, Reliability (absolute calibration error; lower better): 0.1295, Resolution (relative calibration quality; higher better): 0.0050, Uncertainty: 0.2335 (n=498)
  AUROC: 0.4474

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.163
Model:                            OLS   Adj. R-squared:                  0.158
Method:                 Least Squares   F-statistic:                     31.13
Date:                Wed, 24 Sep 2025   Prob (F-statistic):           2.15e-18
Time:                        16:14:47   Log-Likelihood:                -170.77
No. Observations:                 482   AIC:                             349.5
Df Residuals:                     478   BIC:                             366.3
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.0731      0.088     -0.834      0.405      -0.245       0.099
p1                    0.7167      0.106      6.759      0.000       0.508       0.925
answer_changed       -0.1671      0.140     -1.198      0.232      -0.441       0.107
p1:answer_changed     0.2645      0.178      1.488      0.138      -0.085       0.614
==============================================================================
Omnibus:                       85.293   Durbin-Watson:                   2.064
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               70.923
Skew:                          -0.847   Prob(JB):                     3.97e-16
Kurtosis:                       2.188   Cond. No.                         20.9
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=7.98, p=2.29e-14
Wilcoxon delta_H: statistic=15240.00, p=3.55e-13
Mean ΔH = 0.2630  [0.1984, 0.3275]
Paired t-test delta_H Changed: statistic=3.12, p=0.00215
Wilcoxon delta_H Changed: statistic=4971.00, p=0.00322
Mean ΔH Changed = 0.1227  [0.0456, 0.1998]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=-2.12, p=0.0348
Wilcoxon (p_top2_game vs p_top2_base): statistic=52022.00, p=0.00132
Mean Δp_top2 = -0.0088  [-0.0170, -0.0007] (n=499)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=8.42, p=4.09e-16
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=37434.00, p=1e-14
Mean ΔH_unchosen_baseline_set = 0.2169  [0.1664, 0.2674] (n=499)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  499
Model:                          Logit   Df Residuals:                      496
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.02924
Time:                        16:14:47   Log-Likelihood:                -306.74
converged:                       True   LL-Null:                       -315.98
Covariance Type:            nonrobust   LLR p-value:                 9.725e-05
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.6054      0.139     -4.345      0.000      -0.879      -0.332
p1_z            -0.4861      0.123     -3.964      0.000      -0.726      -0.246
I(p1_z ** 2)    -0.1387      0.106     -1.313      0.189      -0.346       0.068
================================================================================
AUC = 0.620

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1174
Time:                        16:14:47   Log-Likelihood:                -279.23
converged:                       True   LL-Null:                       -316.38
Covariance Type:            nonrobust   LLR p-value:                 6.759e-18
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -2.1854      0.223     -9.807      0.000      -2.622      -1.749
game_entropy     1.6489      0.207      7.981      0.000       1.244       2.054
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=57894.00, p=0.143
Paired t-test (game_entropy vs capabilities_entropy): statistic=1.55, p=0.122
Mean game_entropy-capabilities_entropy = 0.0396  [-0.0105, 0.0898] (n=500)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      497
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1206
Time:                        16:14:47   Log-Likelihood:                -278.22
converged:                       True   LL-Null:                       -316.38
Covariance Type:            nonrobust   LLR p-value:                 2.673e-17
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.3395      0.252     -9.291      0.000      -2.833      -1.846
capabilities_entropy     0.3028      0.212      1.427      0.153      -0.113       0.719
game_entropy             1.5413      0.219      7.024      0.000       1.111       1.971
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.653333
                        1                 0.346667
Geography               0                 0.522727
                        1                 0.477273
Misc                    0                 0.635135
                        1                 0.364865
Music                   0                 0.775000
                        1                 0.225000
Other                   0                 0.692308
                        1                 0.307692
Politics                0                 0.649351
                        1                 0.350649
Science and technology  0                 0.734694
                        1                 0.265306
Sports                  0                 0.700000
                        1                 0.300000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.568047
                     1                 0.431953
Number               0                 0.602564
                     1                 0.397436
Other                0                 0.751880
                     1                 0.248120
Person               0                 0.775000
                     1                 0.225000
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.571429  0.428571           21
                       Number               0.333333  0.666667            9
                       Other                0.833333  0.166667           18
                       Person               0.703704  0.296296           27
Geography              Date                 0.466667  0.533333           15
                       Number               0.611111  0.388889           18
                       Other                0.454545  0.545455           11
Misc                   Date                 0.521739  0.478261           23
                       Number               0.555556  0.444444            9
                       Other                0.703704  0.296296           27
                       Person               0.733333  0.266667           15
Music                  Date                 0.583333  0.416667           12
                       Number               0.750000  0.250000            4
                       Other                0.833333  0.166667           12
                       Person               0.916667  0.083333           12
Other                  Date                 0.611111  0.388889           18
                       Number               0.857143  0.142857            7
                       Other                0.714286  0.285714           14
                       Person               0.692308  0.307692           13
Politics               Date                 0.500000  0.500000           36
                       Number               0.666667  0.333333            6
                       Other                0.850000  0.150000           20
                       Person               0.733333  0.266667           15
Science and technology Date                 0.657143  0.342857           35
                       Number               0.642857  0.357143           14
                       Other                0.789474  0.210526           19
                       Person               0.833333  0.166667           30
Sports                 Date                 0.666667  0.333333            9
                       Number               0.545455  0.454545           11
                       Other                0.750000  0.250000           12
                       Person               0.875000  0.125000            8

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      488
Method:                           MLE   Df Model:                           11
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.04324
Time:                        16:14:47   Log-Likelihood:                -302.70
converged:                       True   LL-Null:                       -316.38
Covariance Type:            nonrobust   LLR p-value:                  0.004057
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      0.6924      1.231      0.562      0.574      -1.721       3.106
C(topic_grouped)[T.Geography]                  0.2911      0.407      0.715      0.475      -0.507       1.089
C(topic_grouped)[T.Misc]                       0.0510      0.352      0.145      0.885      -0.638       0.740
C(topic_grouped)[T.Music]                     -0.6410      0.458     -1.399      0.162      -1.539       0.257
C(topic_grouped)[T.Other]                     -0.2654      0.395     -0.671      0.502      -1.040       0.509
C(topic_grouped)[T.Politics]                  -0.0901      0.356     -0.253      0.800      -0.788       0.607
C(topic_grouped)[T.Science and technology]    -0.4725      0.342     -1.382      0.167      -1.143       0.197
C(topic_grouped)[T.Sports]                    -0.2802      0.433     -0.647      0.518      -1.129       0.569
C(answer_type_grouped)[T.Number]              -0.2021      0.290     -0.696      0.486      -0.771       0.367
C(answer_type_grouped)[T.Other]               -0.8788      0.259     -3.395      0.001      -1.386      -0.371
C(answer_type_grouped)[T.Person]              -0.9306      0.275     -3.380      0.001      -1.470      -0.391
q_length                                      -0.1750      0.266     -0.658      0.511      -0.696       0.346
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.7766
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      487
Method:                           MLE   Df Model:                           12
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.05822
Time:                        16:14:47   Log-Likelihood:                -297.96
converged:                       True   LL-Null:                       -316.38
Covariance Type:            nonrobust   LLR p-value:                 0.0002373
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -0.2615      1.283     -0.204      0.838      -2.775       2.252
C(topic_grouped)[T.Geography]                  0.3078      0.413      0.745      0.456      -0.502       1.117
C(topic_grouped)[T.Misc]                       0.0370      0.355      0.104      0.917      -0.658       0.732
C(topic_grouped)[T.Music]                     -0.6711      0.464     -1.447      0.148      -1.580       0.238
C(topic_grouped)[T.Other]                     -0.2803      0.399     -0.703      0.482      -1.062       0.501
C(topic_grouped)[T.Politics]                  -0.0640      0.360     -0.178      0.859      -0.770       0.642
C(topic_grouped)[T.Science and technology]    -0.4368      0.345     -1.265      0.206      -1.114       0.240
C(topic_grouped)[T.Sports]                    -0.2447      0.438     -0.558      0.577      -1.104       0.614
C(answer_type_grouped)[T.Number]              -0.2891      0.294     -0.983      0.326      -0.866       0.288
C(answer_type_grouped)[T.Other]               -0.6624      0.270     -2.456      0.014      -1.191      -0.134
C(answer_type_grouped)[T.Person]              -0.6526      0.291     -2.241      0.025      -1.223      -0.082
q_length                                      -0.1028      0.270     -0.381      0.703      -0.632       0.426
capabilities_entropy                           0.6350      0.208      3.056      0.002       0.228       1.042
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      487
Method:                           MLE   Df Model:                           12
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1424
Time:                        16:14:47   Log-Likelihood:                -271.33
converged:                       True   LL-Null:                       -316.38
Covariance Type:            nonrobust   LLR p-value:                 4.742e-14
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -0.4705      1.333     -0.353      0.724      -3.082       2.141
C(topic_grouped)[T.Geography]                  0.1721      0.437      0.394      0.693      -0.684       1.028
C(topic_grouped)[T.Misc]                       0.0540      0.378      0.143      0.886      -0.686       0.794
C(topic_grouped)[T.Music]                     -0.7757      0.487     -1.594      0.111      -1.730       0.178
C(topic_grouped)[T.Other]                     -0.4195      0.423     -0.992      0.321      -1.248       0.409
C(topic_grouped)[T.Politics]                   0.0818      0.386      0.212      0.832      -0.675       0.839
C(topic_grouped)[T.Science and technology]    -0.6256      0.371     -1.687      0.092      -1.353       0.101
C(topic_grouped)[T.Sports]                    -0.3990      0.467     -0.854      0.393      -1.314       0.517
C(answer_type_grouped)[T.Number]              -0.3332      0.311     -1.073      0.283      -0.942       0.276
C(answer_type_grouped)[T.Other]               -0.4753      0.281     -1.693      0.090      -1.025       0.075
C(answer_type_grouped)[T.Person]              -0.5580      0.297     -1.877      0.061      -1.141       0.025
q_length                                      -0.2657      0.286     -0.928      0.353      -0.827       0.295
game_entropy                                   1.6351      0.221      7.405      0.000       1.202       2.068
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      486
Method:                           MLE   Df Model:                           13
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1431
Time:                        16:14:47   Log-Likelihood:                -271.09
converged:                       True   LL-Null:                       -316.38
Covariance Type:            nonrobust   LLR p-value:                 1.084e-13
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -0.6774      1.367     -0.496      0.620      -3.357       2.002
C(topic_grouped)[T.Geography]                  0.1811      0.437      0.414      0.679      -0.676       1.038
C(topic_grouped)[T.Misc]                       0.0517      0.378      0.137      0.891      -0.689       0.792
C(topic_grouped)[T.Music]                     -0.7841      0.488     -1.608      0.108      -1.740       0.172
C(topic_grouped)[T.Other]                     -0.4196      0.424     -0.991      0.322      -1.250       0.411
C(topic_grouped)[T.Politics]                   0.0859      0.386      0.222      0.824      -0.671       0.843
C(topic_grouped)[T.Science and technology]    -0.6126      0.372     -1.648      0.099      -1.341       0.116
C(topic_grouped)[T.Sports]                    -0.3834      0.468     -0.819      0.413      -1.301       0.534
C(answer_type_grouped)[T.Number]              -0.3495      0.311     -1.122      0.262      -0.960       0.261
C(answer_type_grouped)[T.Other]               -0.4307      0.288     -1.495      0.135      -0.995       0.134
C(answer_type_grouped)[T.Person]              -0.4955      0.311     -1.596      0.111      -1.104       0.113
q_length                                      -0.2466      0.288     -0.857      0.392      -0.811       0.318
capabilities_entropy                           0.1615      0.232      0.697      0.486      -0.292       0.615
game_entropy                                   1.5911      0.229      6.934      0.000       1.141       2.041
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing gemini-2.5-flash-lite_think (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_new/gemini-2.5-flash-lite_think_SimpleMC_redacted_cor_temp1.0_1758179683_game_data.json', './sc_logs_new/gemini-2.5-flash-lite_think_SimpleMC_redacted_temp1.0_1758167956_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    283
1    217
Name: count, dtype: int64

Answer change%: 0.4340 [0.39055736401757857, 0.4774426359824214] (n=500)
P-value vs 25%: 1.029e-16; P-value vs 0%: 2.272e-85
Phase 2 self-accuracy: 0.2995 [0.23859432751483192, 0.36048401349899295] (n=217)
P-value vs 25%: 0.1111; P-value vs 33%: 0.2819

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:               7.038e-05
Time:                        16:14:47   Log-Likelihood:                -342.18
converged:                       True   LL-Null:                       -342.20
Covariance Type:            nonrobust   LLR p-value:                    0.8263
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept         46.4916    212.677      0.219      0.827    -370.347     463.331
p_i_capability   -46.7608    212.693     -0.220      0.826    -463.632     370.111
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:               0.0002391
Time:                        16:14:47   Log-Likelihood:                -342.12
converged:                       True   LL-Null:                       -342.20
Covariance Type:            nonrobust   LLR p-value:                    0.6858
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -0.2730      0.092     -2.964      0.003      -0.454      -0.092
capabilities_entropy     8.7468     21.619      0.405      0.686     -33.626      51.120
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.0729 [0.0361, 0.1097] (n=192)
                  P-value vs 33.3%: 8.536e-44

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=9.98, p=1.8e-17
Wilcoxon delta_p: statistic=218.00, p=1.75e-19
Mean Δp = 0.4511  [0.3625, 0.5397]
Idea 1 N = 122; 

  Idea 1.5: Calibration Metrics
  NLL: 6.2203, Signed ECE (overconf pos under neg): 0.0707, ECE: 0.5235 (n=212)
  Brier: 0.5236, Reliability (absolute calibration error; lower better): 0.2791, Resolution (relative calibration quality; higher better): 0.0006, Uncertainty: 0.2450 (n=212)
  AUROC: 0.4542

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.021
Model:                            OLS   Adj. R-squared:                  0.008
Method:                 Least Squares   F-statistic:                     1.641
Date:                Wed, 24 Sep 2025   Prob (F-statistic):              0.181
Time:                        16:14:47   Log-Likelihood:                -170.67
No. Observations:                 239   AIC:                             349.3
Df Residuals:                     235   BIC:                             363.3
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept          -118.3450    150.898     -0.784      0.434    -415.631     178.941
p1                  118.8033    150.907      0.787      0.432    -178.501     416.107
answer_changed      272.4782    354.895      0.768      0.443    -426.705     971.661
p1:answer_changed  -272.3623    354.913     -0.767      0.444    -971.579     426.854
==============================================================================
Omnibus:                     1277.684   Durbin-Watson:                   1.833
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               36.963
Skew:                          -0.061   Prob(JB):                     9.41e-09
Kurtosis:                       1.077   Cond. No.                     2.55e+04
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The condition number is large, 2.55e+04. This might indicate that there are
strong multicollinearity or other numerical problems.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=22.12, p=8.51e-61
Wilcoxon delta_H: statistic=1348.00, p=3.36e-36
Mean ΔH = 0.9275  [0.8453, 1.0096]
Paired t-test delta_H Changed: statistic=20.26, p=1.88e-49
Wilcoxon delta_H Changed: statistic=676.00, p=8.12e-29
Mean ΔH Changed = 0.9459  [0.8543, 1.0374]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=-3.41, p=0.00072
Wilcoxon (p_top2_game vs p_top2_base): statistic=6400.00, p=1.12e-56
Mean Δp_top2 = -0.0001  [-0.0001, -0.0000] (n=443)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=30.01, p=1.11e-108
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=3903.00, p=2.87e-63
Mean ΔH_unchosen_baseline_set = 0.9354  [0.8743, 0.9965] (n=443)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  443
Model:                          Logit   Df Residuals:                      440
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                0.008007
Time:                        16:14:47   Log-Likelihood:                -300.70
converged:                       True   LL-Null:                       -303.12
Covariance Type:            nonrobust   LLR p-value:                   0.08830
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.2020      0.103     -1.957      0.050      -0.404       0.000
p1_z            -0.7169      0.363     -1.972      0.049      -1.429      -0.004
I(p1_z ** 2)    -0.0657      0.037     -1.797      0.072      -0.137       0.006
================================================================================
AUC = 0.525

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                0.005151
Time:                        16:14:47   Log-Likelihood:                -340.44
converged:                       True   LL-Null:                       -342.20
Covariance Type:            nonrobust   LLR p-value:                   0.06044
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.2990      0.092     -3.235      0.001      -0.480      -0.118
game_entropy     9.3315      6.478      1.440      0.150      -3.366      22.029
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=11879.00, p=1.52e-55
Paired t-test (game_entropy vs capabilities_entropy): statistic=3.01, p=0.00277
Mean game_entropy-capabilities_entropy = 0.0032  [0.0011, 0.0052] (n=500)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      497
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                0.005414
Time:                        16:14:47   Log-Likelihood:                -340.35
converged:                       True   LL-Null:                       -342.20
Covariance Type:            nonrobust   LLR p-value:                    0.1568
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -0.3069      0.094     -3.254      0.001      -0.492      -0.122
capabilities_entropy     9.1777     21.632      0.424      0.671     -33.221      51.576
game_entropy             9.3476      6.475      1.444      0.149      -3.343      22.038
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.640000
                        1                 0.360000
Geography               0                 0.522727
                        1                 0.477273
Misc                    0                 0.554054
                        1                 0.445946
Music                   0                 0.625000
                        1                 0.375000
Other                   0                 0.615385
                        1                 0.384615
Politics                0                 0.545455
                        1                 0.454545
Science and technology  0                 0.540816
                        1                 0.459184
Sports                  1                 0.525000
                        0                 0.475000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.532544
                     1                 0.467456
Number               0                 0.525641
                     1                 0.474359
Other                0                 0.571429
                     1                 0.428571
Person               0                 0.633333
                     1                 0.366667
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.523810  0.476190           21
                       Number               0.666667  0.333333            9
                       Other                0.833333  0.166667           18
                       Person               0.592593  0.407407           27
Geography              Date                 0.400000  0.600000           15
                       Number               0.444444  0.555556           18
                       Other                0.818182  0.181818           11
Misc                   Date                 0.608696  0.391304           23
                       Number               0.555556  0.444444            9
                       Other                0.444444  0.555556           27
                       Person               0.666667  0.333333           15
Music                  Date                 0.500000  0.500000           12
                       Number               0.250000  0.750000            4
                       Other                0.750000  0.250000           12
                       Person               0.750000  0.250000           12
Other                  Date                 0.444444  0.555556           18
                       Number               0.857143  0.142857            7
                       Other                0.714286  0.285714           14
                       Person               0.615385  0.384615           13
Politics               Date                 0.583333  0.416667           36
                       Number               0.500000  0.500000            6
                       Other                0.450000  0.550000           20
                       Person               0.600000  0.400000           15
Science and technology Date                 0.600000  0.400000           35
                       Number               0.500000  0.500000           14
                       Other                0.421053  0.578947           19
                       Person               0.566667  0.433333           30
Sports                 Date                 0.333333  0.666667            9
                       Number               0.454545  0.545455           11
                       Other                0.333333  0.666667           12
                       Person               0.875000  0.125000            8

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      488
Method:                           MLE   Df Model:                           11
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.01121
Time:                        16:14:47   Log-Likelihood:                -338.37
converged:                       True   LL-Null:                       -342.20
Covariance Type:            nonrobust   LLR p-value:                    0.7426
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      0.0007      1.141      0.001      1.000      -2.235       2.237
C(topic_grouped)[T.Geography]                  0.3499      0.398      0.878      0.380      -0.431       1.131
C(topic_grouped)[T.Misc]                       0.3227      0.338      0.953      0.340      -0.341       0.986
C(topic_grouped)[T.Music]                      0.0470      0.407      0.115      0.908      -0.751       0.845
C(topic_grouped)[T.Other]                      0.0661      0.375      0.176      0.860      -0.669       0.801
C(topic_grouped)[T.Politics]                   0.3549      0.340      1.044      0.297      -0.311       1.021
C(topic_grouped)[T.Science and technology]     0.3945      0.317      1.245      0.213      -0.226       1.015
C(topic_grouped)[T.Sports]                     0.6304      0.402      1.570      0.116      -0.157       1.417
C(answer_type_grouped)[T.Number]              -0.0077      0.283     -0.027      0.978      -0.562       0.547
C(answer_type_grouped)[T.Other]               -0.1626      0.237     -0.687      0.492      -0.627       0.301
C(answer_type_grouped)[T.Person]              -0.3908      0.250     -1.561      0.118      -0.881       0.100
q_length                                      -0.0895      0.246     -0.364      0.716      -0.571       0.392
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.0008
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      487
Method:                           MLE   Df Model:                           12
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.01146
Time:                        16:14:47   Log-Likelihood:                -338.28
converged:                       True   LL-Null:                       -342.20
Covariance Type:            nonrobust   LLR p-value:                    0.7972
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -0.0045      1.141     -0.004      0.997      -2.241       2.232
C(topic_grouped)[T.Geography]                  0.3473      0.399      0.871      0.384      -0.434       1.128
C(topic_grouped)[T.Misc]                       0.3045      0.341      0.892      0.372      -0.364       0.973
C(topic_grouped)[T.Music]                      0.0461      0.407      0.113      0.910      -0.752       0.845
C(topic_grouped)[T.Other]                      0.0591      0.376      0.158      0.875      -0.677       0.795
C(topic_grouped)[T.Politics]                   0.3528      0.340      1.037      0.300      -0.314       1.019
C(topic_grouped)[T.Science and technology]     0.3929      0.317      1.240      0.215      -0.228       1.014
C(topic_grouped)[T.Sports]                     0.6152      0.403      1.525      0.127      -0.175       1.406
C(answer_type_grouped)[T.Number]              -0.0115      0.283     -0.041      0.968      -0.566       0.543
C(answer_type_grouped)[T.Other]               -0.1716      0.238     -0.722      0.470      -0.638       0.294
C(answer_type_grouped)[T.Person]              -0.3999      0.251     -1.591      0.112      -0.892       0.093
q_length                                      -0.0877      0.246     -0.357      0.721      -0.569       0.394
capabilities_entropy                           9.2820     22.177      0.419      0.676     -34.185      52.749
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      487
Method:                           MLE   Df Model:                           12
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.01677
Time:                        16:14:47   Log-Likelihood:                -336.47
converged:                       True   LL-Null:                       -342.20
Covariance Type:            nonrobust   LLR p-value:                    0.4886
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      0.0885      1.147      0.077      0.939      -2.160       2.337
C(topic_grouped)[T.Geography]                  0.3768      0.399      0.943      0.346      -0.406       1.160
C(topic_grouped)[T.Misc]                       0.3069      0.340      0.901      0.367      -0.360       0.974
C(topic_grouped)[T.Music]                      0.0776      0.408      0.190      0.849      -0.723       0.878
C(topic_grouped)[T.Other]                      0.0965      0.376      0.256      0.798      -0.641       0.834
C(topic_grouped)[T.Politics]                   0.3660      0.342      1.072      0.284      -0.303       1.035
C(topic_grouped)[T.Science and technology]     0.4020      0.319      1.262      0.207      -0.223       1.027
C(topic_grouped)[T.Sports]                     0.6635      0.403      1.647      0.099      -0.126       1.453
C(answer_type_grouped)[T.Number]               0.0073      0.283      0.026      0.979      -0.548       0.562
C(answer_type_grouped)[T.Other]               -0.1750      0.238     -0.735      0.462      -0.642       0.292
C(answer_type_grouped)[T.Person]              -0.3972      0.251     -1.581      0.114      -0.890       0.095
q_length                                      -0.1188      0.247     -0.481      0.630      -0.603       0.365
game_entropy                                   9.9815      6.726      1.484      0.138      -3.201      23.164
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      486
Method:                           MLE   Df Model:                           13
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.01707
Time:                        16:14:47   Log-Likelihood:                -336.37
converged:                       True   LL-Null:                       -342.20
Covariance Type:            nonrobust   LLR p-value:                    0.5541
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      0.0831      1.147      0.072      0.942      -2.166       2.332
C(topic_grouped)[T.Geography]                  0.3740      0.400      0.936      0.349      -0.409       1.157
C(topic_grouped)[T.Misc]                       0.2871      0.343      0.836      0.403      -0.386       0.960
C(topic_grouped)[T.Music]                      0.0768      0.409      0.188      0.851      -0.724       0.878
C(topic_grouped)[T.Other]                      0.0891      0.377      0.236      0.813      -0.649       0.828
C(topic_grouped)[T.Politics]                   0.3638      0.342      1.065      0.287      -0.306       1.033
C(topic_grouped)[T.Science and technology]     0.4003      0.319      1.256      0.209      -0.224       1.025
C(topic_grouped)[T.Sports]                     0.6472      0.404      1.600      0.110      -0.145       1.440
C(answer_type_grouped)[T.Number]               0.0033      0.283      0.012      0.991      -0.552       0.559
C(answer_type_grouped)[T.Other]               -0.1848      0.239     -0.773      0.440      -0.653       0.284
C(answer_type_grouped)[T.Person]              -0.4070      0.252     -1.614      0.107      -0.901       0.087
q_length                                      -0.1170      0.247     -0.473      0.636      -0.601       0.367
capabilities_entropy                          10.0195     22.184      0.452      0.652     -33.461      53.500
game_entropy                                  10.0262      6.739      1.488      0.137      -3.182      23.235
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing gemini-2.5-flash-preview-04-17 (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_new/gemini-2.5-flash-preview-04-17_SimpleMC_redacted_cor_temp0.0_1751802958_game_data.json', './sc_logs_new/gemini-2.5-flash-preview-04-17_SimpleMC_redacted_temp0.0_1751726354_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    324
1    176
Name: count, dtype: int64

Answer change%: 0.3520 [0.3101378120217051, 0.39386218797829486] (n=500)
P-value vs 25%: 1.792e-06; P-value vs 0%: 5.071e-61
Phase 2 self-accuracy: 0.3239 [0.2547299049864159, 0.3929973677408568] (n=176)
P-value vs 25%: 0.03625; P-value vs 33%: 0.7956

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                0.002049
Time:                        16:14:47   Log-Likelihood:                -323.67
converged:                       True   LL-Null:                       -324.34
Covariance Type:            nonrobust   LLR p-value:                    0.2489
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.6217      0.094     -6.595      0.000      -0.806      -0.437
game_entropy     1.0779      1.024      1.053      0.292      -0.928       3.084
================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.746667
                        1                 0.253333
Geography               0                 0.545455
                        1                 0.454545
Misc                    0                 0.500000
                        1                 0.500000
Music                   0                 0.650000
                        1                 0.350000
Other                   0                 0.807692
                        1                 0.192308
Politics                0                 0.701299
                        1                 0.298701
Science and technology  0                 0.591837
                        1                 0.408163
Sports                  0                 0.675000
                        1                 0.325000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.644970
                     1                 0.355030
Number               0                 0.512821
                     1                 0.487179
Other                0                 0.669173
                     1                 0.330827
Person               0                 0.716667
                     1                 0.283333
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.809524  0.190476           21
                       Number               0.444444  0.555556            9
                       Other                0.666667  0.333333           18
                       Person               0.851852  0.148148           27
Geography              Date                 0.466667  0.533333           15
                       Number               0.500000  0.500000           18
                       Other                0.727273  0.272727           11
Misc                   Date                 0.304348  0.695652           23
                       Number               0.777778  0.222222            9
                       Other                0.629630  0.370370           27
                       Person               0.400000  0.600000           15
Music                  Date                 0.750000  0.250000           12
                       Number               0.500000  0.500000            4
                       Other                0.583333  0.416667           12
                       Person               0.666667  0.333333           12
Other                  Date                 0.777778  0.222222           18
                       Number               0.714286  0.285714            7
                       Other                0.785714  0.214286           14
                       Person               0.923077  0.076923           13
Politics               Date                 0.694444  0.305556           36
                       Number               0.500000  0.500000            6
                       Other                0.800000  0.200000           20
                       Person               0.666667  0.333333           15
Science and technology Date                 0.628571  0.371429           35
                       Number               0.357143  0.642857           14
                       Other                0.578947  0.421053           19
                       Person               0.666667  0.333333           30
Sports                 Date                 0.888889  0.111111            9
                       Number               0.454545  0.545455           11
                       Other                0.583333  0.416667           12
                       Person               0.875000  0.125000            8

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      488
Method:                           MLE   Df Model:                           11
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.04375
Time:                        16:14:47   Log-Likelihood:                -310.15
converged:                       True   LL-Null:                       -324.34
Covariance Type:            nonrobust   LLR p-value:                  0.002833
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.3452      1.209     -1.112      0.266      -3.716       1.025
C(topic_grouped)[T.Geography]                  0.6557      0.418      1.570      0.116      -0.163       1.474
C(topic_grouped)[T.Misc]                       1.0655      0.357      2.981      0.003       0.365       1.766
C(topic_grouped)[T.Music]                      0.4748      0.428      1.109      0.267      -0.364       1.314
C(topic_grouped)[T.Other]                     -0.3921      0.444     -0.882      0.378      -1.263       0.479
C(topic_grouped)[T.Politics]                   0.1936      0.374      0.518      0.605      -0.539       0.926
C(topic_grouped)[T.Science and technology]     0.6784      0.339      1.999      0.046       0.013       1.344
C(topic_grouped)[T.Sports]                     0.2266      0.437      0.518      0.604      -0.630       1.083
C(answer_type_grouped)[T.Number]               0.5230      0.291      1.794      0.073      -0.048       1.094
C(answer_type_grouped)[T.Other]               -0.1391      0.252     -0.551      0.582      -0.634       0.355
C(answer_type_grouped)[T.Person]              -0.2941      0.269     -1.094      0.274      -0.821       0.233
q_length                                       0.0730      0.260      0.281      0.779      -0.436       0.582
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      487
Method:                           MLE   Df Model:                           12
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.04530
Time:                        16:14:47   Log-Likelihood:                -309.65
converged:                       True   LL-Null:                       -324.34
Covariance Type:            nonrobust   LLR p-value:                  0.003453
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.3875      1.211     -1.145      0.252      -3.762       0.987
C(topic_grouped)[T.Geography]                  0.6121      0.421      1.455      0.146      -0.212       1.437
C(topic_grouped)[T.Misc]                       1.0599      0.358      2.964      0.003       0.359       1.761
C(topic_grouped)[T.Music]                      0.4755      0.428      1.110      0.267      -0.364       1.315
C(topic_grouped)[T.Other]                     -0.3904      0.444     -0.878      0.380      -1.262       0.481
C(topic_grouped)[T.Politics]                   0.1961      0.374      0.524      0.600      -0.537       0.929
C(topic_grouped)[T.Science and technology]     0.6782      0.340      1.997      0.046       0.013       1.344
C(topic_grouped)[T.Sports]                     0.1781      0.442      0.403      0.687      -0.688       1.044
C(answer_type_grouped)[T.Number]               0.5482      0.293      1.872      0.061      -0.026       1.122
C(answer_type_grouped)[T.Other]               -0.1152      0.254     -0.454      0.650      -0.612       0.382
C(answer_type_grouped)[T.Person]              -0.2768      0.270     -1.026      0.305      -0.805       0.252
q_length                                       0.0787      0.260      0.303      0.762      -0.431       0.588
game_entropy                                   0.9507      1.009      0.942      0.346      -1.027       2.929
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing gemini-2.5-flash_nothink (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_new/gemini-2.5-flash_nothink_SimpleMC_redacted_cor_temp1.0_1757984473_game_data.json', './sc_logs_new/gemini-2.5-flash_nothink_SimpleMC_redacted_temp1.0_1758161562_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    302
1    198
Name: count, dtype: int64

Answer change%: 0.3960 [0.3531324018268132, 0.4388675981731868] (n=500)
P-value vs 25%: 2.467e-11; P-value vs 0%: 2.876e-73
Phase 2 self-accuracy: 0.3131 [0.24853382890469403, 0.3777287973579323] (n=198)
P-value vs 25%: 0.05543; P-value vs 33%: 0.5466

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1112
Time:                        16:14:47   Log-Likelihood:                -298.34
converged:                       True   LL-Null:                       -335.68
Covariance Type:            nonrobust   LLR p-value:                 5.556e-18
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          2.2021      0.332      6.637      0.000       1.552       2.852
p_i_capability    -3.7764      0.466     -8.100      0.000      -4.690      -2.863
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1075
Time:                        16:14:47   Log-Likelihood:                -299.59
converged:                       True   LL-Null:                       -335.68
Covariance Type:            nonrobust   LLR p-value:                 1.963e-17
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.8213      0.213     -8.547      0.000      -2.239      -1.404
capabilities_entropy     1.3180      0.168      7.849      0.000       0.989       1.647
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.5859 [0.5172, 0.6545] (n=198)
                  P-value vs 33.3%: 5.439e-13

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=12.76, p=4.22e-30
Wilcoxon delta_p: statistic=6132.00, p=2.9e-28
Mean Δp = 0.1385  [0.1173, 0.1598]
Idea 1 N = 302; 

  Idea 1.5: Calibration Metrics
  NLL: 1.3760, Signed ECE (overconf pos under neg): -0.0393, ECE: 0.1397 (n=500)
  Brier: 0.0702, Reliability (absolute calibration error; lower better): 0.0358, Resolution (relative calibration quality; higher better): 0.2148, Uncertainty: 0.2499 (n=500)
  AUROC: 0.9946

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.546
Model:                            OLS   Adj. R-squared:                  0.543
Method:                 Least Squares   F-statistic:                     198.2
Date:                Wed, 24 Sep 2025   Prob (F-statistic):           2.00e-84
Time:                        16:14:47   Log-Likelihood:                 218.32
No. Observations:                 499   AIC:                            -428.6
Df Residuals:                     495   BIC:                            -411.8
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.0010      0.035     -0.028      0.978      -0.070       0.068
p1                    0.1787      0.043      4.128      0.000       0.094       0.264
answer_changed       -0.2240      0.050     -4.489      0.000      -0.322      -0.126
p1:answer_changed     0.8057      0.071     11.424      0.000       0.667       0.944
==============================================================================
Omnibus:                       22.541   Durbin-Watson:                   1.872
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               38.524
Skew:                           0.312   Prob(JB):                     4.31e-09
Kurtosis:                       4.210   Cond. No.                         17.8
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-9.37, p=1.77e-18
Wilcoxon delta_H: statistic=9452.00, p=9.66e-19
Mean ΔH = -0.2203  [-0.2664, -0.1742]
Paired t-test delta_H Changed: statistic=-4.67, p=5.57e-06
Wilcoxon delta_H Changed: statistic=5977.00, p=1.6e-06
Mean ΔH Changed = -0.1162  [-0.1650, -0.0674]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=-22.82, p=1.86e-79
Wilcoxon (p_top2_game vs p_top2_base): statistic=5758.00, p=2.78e-69
Mean Δp_top2 = -0.1161  [-0.1261, -0.1061] (n=500)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=-10.28, p=1.28e-22
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=30272.00, p=1.39e-23
Mean ΔH_unchosen_baseline_set = -0.1791  [-0.2132, -0.1449] (n=500)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      497
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1141
Time:                        16:14:47   Log-Likelihood:                -297.38
converged:                       True   LL-Null:                       -335.68
Covariance Type:            nonrobust   LLR p-value:                 2.339e-17
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.3302      0.151     -2.184      0.029      -0.627      -0.034
p1_z            -0.8855      0.111     -7.989      0.000      -1.103      -0.668
I(p1_z ** 2)    -0.1779      0.129     -1.384      0.166      -0.430       0.074
================================================================================
AUC = 0.731

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1502
Time:                        16:14:47   Log-Likelihood:                -285.27
converged:                       True   LL-Null:                       -335.68
Covariance Type:            nonrobust   LLR p-value:                 1.005e-23
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -3.3421      0.393     -8.502      0.000      -4.113      -2.572
game_entropy     1.9788      0.240      8.234      0.000       1.508       2.450
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=13906.00, p=2.46e-51
Paired t-test (game_entropy vs capabilities_entropy): statistic=17.87, p=1.44e-55
Mean game_entropy-capabilities_entropy = 0.3766  [0.3353, 0.4179] (n=500)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      497
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1584
Time:                        16:14:47   Log-Likelihood:                -282.52
converged:                       True   LL-Null:                       -335.68
Covariance Type:            nonrobust   LLR p-value:                 8.196e-24
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -3.2935      0.390     -8.436      0.000      -4.059      -2.528
capabilities_entropy     0.5072      0.217      2.334      0.020       0.081       0.933
game_entropy             1.5762      0.291      5.425      0.000       1.007       2.146
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.640000
                        1                 0.360000
Geography               0                 0.500000
                        1                 0.500000
Misc                    0                 0.500000
                        1                 0.500000
Music                   0                 0.725000
                        1                 0.275000
Other                   0                 0.557692
                        1                 0.442308
Politics                0                 0.675325
                        1                 0.324675
Science and technology  0                 0.591837
                        1                 0.408163
Sports                  0                 0.675000
                        1                 0.325000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 1                 0.514793
                     0                 0.485207
Number               0                 0.512821
                     1                 0.487179
Other                0                 0.676692
                     1                 0.323308
Person               0                 0.750000
                     1                 0.250000
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.285714  0.714286           21
                       Number               0.555556  0.444444            9
                       Other                0.777778  0.222222           18
                       Person               0.851852  0.148148           27
Geography              Date                 0.333333  0.666667           15
                       Number               0.500000  0.500000           18
                       Other                0.727273  0.272727           11
Misc                   Date                 0.434783  0.565217           23
                       Number               0.222222  0.777778            9
                       Other                0.592593  0.407407           27
                       Person               0.600000  0.400000           15
Music                  Date                 0.666667  0.333333           12
                       Number               0.500000  0.500000            4
                       Other                0.666667  0.333333           12
                       Person               0.916667  0.083333           12
Other                  Date                 0.388889  0.611111           18
                       Number               0.428571  0.571429            7
                       Other                0.714286  0.285714           14
                       Person               0.692308  0.307692           13
Politics               Date                 0.694444  0.305556           36
                       Number               0.500000  0.500000            6
                       Other                0.750000  0.250000           20
                       Person               0.600000  0.400000           15
Science and technology Date                 0.457143  0.542857           35
                       Number               0.642857  0.357143           14
                       Other                0.578947  0.421053           19
                       Person               0.733333  0.266667           30
Sports                 Date                 0.555556  0.444444            9
                       Number               0.636364  0.363636           11
                       Other                0.666667  0.333333           12
                       Person               0.875000  0.125000            8

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      488
Method:                           MLE   Df Model:                           11
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.06025
Time:                        16:14:47   Log-Likelihood:                -315.45
converged:                       True   LL-Null:                       -335.68
Covariance Type:            nonrobust   LLR p-value:                 2.994e-05
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      2.1002      1.201      1.749      0.080      -0.254       4.454
C(topic_grouped)[T.Geography]                  0.2114      0.407      0.520      0.603      -0.586       1.008
C(topic_grouped)[T.Misc]                       0.5483      0.347      1.578      0.115      -0.133       1.229
C(topic_grouped)[T.Music]                     -0.4583      0.441     -1.039      0.299      -1.323       0.406
C(topic_grouped)[T.Other]                      0.2484      0.382      0.650      0.516      -0.501       0.998
C(topic_grouped)[T.Politics]                  -0.2461      0.360     -0.683      0.495      -0.953       0.461
C(topic_grouped)[T.Science and technology]     0.1550      0.329      0.472      0.637      -0.489       0.799
C(topic_grouped)[T.Sports]                    -0.2664      0.429     -0.621      0.535      -1.108       0.575
C(answer_type_grouped)[T.Number]              -0.1345      0.286     -0.470      0.639      -0.696       0.427
C(answer_type_grouped)[T.Other]               -0.8858      0.248     -3.565      0.000      -1.373      -0.399
C(answer_type_grouped)[T.Person]              -1.2189      0.270     -4.516      0.000      -1.748      -0.690
q_length                                      -0.4587      0.259     -1.769      0.077      -0.967       0.050
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 1.0002
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      487
Method:                           MLE   Df Model:                           12
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1360
Time:                        16:14:48   Log-Likelihood:                -290.02
converged:                       True   LL-Null:                       -335.68
Covariance Type:            nonrobust   LLR p-value:                 2.741e-14
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      0.7637      1.277      0.598      0.550      -1.739       3.267
C(topic_grouped)[T.Geography]                  0.0463      0.432      0.107      0.915      -0.800       0.893
C(topic_grouped)[T.Misc]                       0.4822      0.365      1.322      0.186      -0.233       1.197
C(topic_grouped)[T.Music]                     -0.5501      0.463     -1.188      0.235      -1.458       0.358
C(topic_grouped)[T.Other]                      0.1501      0.403      0.373      0.709      -0.639       0.940
C(topic_grouped)[T.Politics]                  -0.1784      0.381     -0.469      0.639      -0.924       0.567
C(topic_grouped)[T.Science and technology]     0.1062      0.345      0.307      0.759      -0.571       0.783
C(topic_grouped)[T.Sports]                    -0.2997      0.452     -0.663      0.507      -1.186       0.586
C(answer_type_grouped)[T.Number]              -0.0396      0.300     -0.132      0.895      -0.628       0.549
C(answer_type_grouped)[T.Other]               -0.5453      0.266     -2.054      0.040      -1.066      -0.025
C(answer_type_grouped)[T.Person]              -0.7877      0.289     -2.722      0.006      -1.355      -0.220
q_length                                      -0.4768      0.273     -1.745      0.081      -1.012       0.059
capabilities_entropy                           1.1874      0.176      6.730      0.000       0.842       1.533
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      487
Method:                           MLE   Df Model:                           12
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1750
Time:                        16:14:48   Log-Likelihood:                -276.92
converged:                       True   LL-Null:                       -335.68
Covariance Type:            nonrobust   LLR p-value:                 1.932e-19
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -0.1871      1.322     -0.141      0.888      -2.779       2.405
C(topic_grouped)[T.Geography]                  0.0134      0.447      0.030      0.976      -0.863       0.889
C(topic_grouped)[T.Misc]                       0.2995      0.379      0.790      0.429      -0.443       1.042
C(topic_grouped)[T.Music]                     -0.7682      0.481     -1.596      0.111      -1.712       0.175
C(topic_grouped)[T.Other]                     -0.0972      0.421     -0.231      0.817      -0.922       0.727
C(topic_grouped)[T.Politics]                  -0.4304      0.396     -1.088      0.277      -1.206       0.345
C(topic_grouped)[T.Science and technology]    -0.0383      0.362     -0.106      0.916      -0.748       0.671
C(topic_grouped)[T.Sports]                    -0.4085      0.467     -0.875      0.382      -1.324       0.507
C(answer_type_grouped)[T.Number]              -0.2753      0.300     -0.918      0.359      -0.863       0.313
C(answer_type_grouped)[T.Other]               -0.3380      0.277     -1.218      0.223      -0.882       0.206
C(answer_type_grouped)[T.Person]              -0.6115      0.301     -2.035      0.042      -1.201      -0.022
q_length                                      -0.5959      0.279     -2.133      0.033      -1.144      -0.048
game_entropy                                   1.9248      0.260      7.407      0.000       1.415       2.434
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      486
Method:                           MLE   Df Model:                           13
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1808
Time:                        16:14:48   Log-Likelihood:                -274.99
converged:                       True   LL-Null:                       -335.68
Covariance Type:            nonrobust   LLR p-value:                 1.071e-19
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -0.2758      1.330     -0.207      0.836      -2.882       2.330
C(topic_grouped)[T.Geography]                 -0.0178      0.450     -0.040      0.968      -0.899       0.864
C(topic_grouped)[T.Misc]                       0.3220      0.380      0.847      0.397      -0.423       1.067
C(topic_grouped)[T.Music]                     -0.7682      0.483     -1.590      0.112      -1.715       0.179
C(topic_grouped)[T.Other]                     -0.0858      0.422     -0.204      0.839      -0.912       0.741
C(topic_grouped)[T.Politics]                  -0.3784      0.398     -0.950      0.342      -1.159       0.402
C(topic_grouped)[T.Science and technology]    -0.0259      0.363     -0.071      0.943      -0.738       0.686
C(topic_grouped)[T.Sports]                    -0.3928      0.469     -0.837      0.402      -1.312       0.527
C(answer_type_grouped)[T.Number]              -0.2127      0.304     -0.700      0.484      -0.808       0.383
C(answer_type_grouped)[T.Other]               -0.3047      0.279     -1.091      0.275      -0.852       0.243
C(answer_type_grouped)[T.Person]              -0.5531      0.303     -1.825      0.068      -1.147       0.041
q_length                                      -0.5799      0.281     -2.064      0.039      -1.131      -0.029
capabilities_entropy                           0.4393      0.224      1.962      0.050       0.000       0.878
game_entropy                                   1.5848      0.309      5.129      0.000       0.979       2.190
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing gemini-2.5-flash_think (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_new/gemini-2.5-flash_think_SimpleMC_redacted_cor_temp1.0_1758281503_game_data.json', './sc_logs_new/gemini-2.5-flash_think_SimpleMC_redacted_temp1.0_1758262178_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    286
1    214
Name: count, dtype: int64

Answer change%: 0.4280 [0.38463064255382484, 0.47136935744617514] (n=500)
P-value vs 25%: 8.678e-16; P-value vs 0%: 2.365e-83
Phase 2 self-accuracy: 0.2850 [0.2245630689019295, 0.3455303890419957] (n=214)
P-value vs 25%: 0.2561; P-value vs 33%: 0.1202

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                0.002020
Time:                        16:14:48   Log-Likelihood:                -340.68
converged:                       True   LL-Null:                       -341.37
Covariance Type:            nonrobust   LLR p-value:                    0.2403
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept         52.3889     75.929      0.690      0.490     -96.430     201.208
p_i_capability   -52.6854     75.934     -0.694      0.488    -201.513      96.142
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                0.001921
Time:                        16:14:48   Log-Likelihood:                -340.72
converged:                       True   LL-Null:                       -341.37
Covariance Type:            nonrobust   LLR p-value:                    0.2521
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -0.2977      0.091     -3.282      0.001      -0.475      -0.120
capabilities_entropy     7.4864     10.078      0.743      0.458     -12.267      27.240
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.3458 [0.2821, 0.4095] (n=214)
                  P-value vs 33.3%: 0.7015

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=2.62, p=0.00916
Wilcoxon delta_p: statistic=6241.50, p=1.98e-24
Mean Δp = 0.0118  [0.0030, 0.0205]
Idea 1 N = 286; 

  Idea 1.5: Calibration Metrics
  NLL: 3.7978, Signed ECE (overconf pos under neg): -0.0000, ECE: 0.0000 (n=480)
  Brier: 0.0000, Reliability (absolute calibration error; lower better): 0.0000, Resolution (relative calibration quality; higher better): 0.2066, Uncertainty: 0.2066 (n=480)
  AUROC: 1.0000

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.981
Model:                            OLS   Adj. R-squared:                  0.981
Method:                 Least Squares   F-statistic:                     8445.
Date:                Wed, 24 Sep 2025   Prob (F-statistic):               0.00
Time:                        16:14:48   Log-Likelihood:                 634.90
No. Observations:                 495   AIC:                            -1262.
Df Residuals:                     491   BIC:                            -1245.
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept             0.7581     11.575      0.066      0.948     -21.984      23.500
p1                   -0.7464     11.575     -0.064      0.949     -23.489      21.996
answer_changed       -0.6314     11.619     -0.054      0.957     -23.460      22.197
p1:answer_changed     1.6076     11.619      0.138      0.890     -21.222      24.437
==============================================================================
Omnibus:                      558.190   Durbin-Watson:                   1.958
Prob(Omnibus):                  0.000   Jarque-Bera (JB):            60964.934
Skew:                           4.980   Prob(JB):                         0.00
Kurtosis:                      56.448   Cond. No.                     1.20e+04
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The condition number is large, 1.2e+04. This might indicate that there are
strong multicollinearity or other numerical problems.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-5.17, p=4.45e-07
Wilcoxon delta_H: statistic=13879.00, p=2.09e-06
Mean ΔH = -0.1003  [-0.1383, -0.0623]
Paired t-test delta_H Changed: statistic=38.86, p=1.19e-98
Wilcoxon delta_H Changed: statistic=80.00, p=2.24e-36
Mean ΔH Changed = 1.1345  [1.0773, 1.1918]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=-4.06, p=5.69e-05
Wilcoxon (p_top2_game vs p_top2_base): statistic=13721.00, p=1.03e-51
Mean Δp_top2 = -0.0099  [-0.0146, -0.0051] (n=500)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=13.36, p=4.95e-35
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=30060.00, p=7.14e-24
Mean ΔH_unchosen_baseline_set = 0.4282  [0.3654, 0.4910] (n=500)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      497
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                0.003138
Time:                        16:14:48   Log-Likelihood:                -340.30
converged:                       True   LL-Null:                       -341.37
Covariance Type:            nonrobust   LLR p-value:                    0.3426
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.3310      0.107     -3.089      0.002      -0.541      -0.121
p1_z             0.7902      1.224      0.646      0.518      -1.608       3.189
I(p1_z ** 2)     0.0499      0.084      0.593      0.553      -0.115       0.215
================================================================================
AUC = 0.497

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                0.005862
Time:                        16:14:48   Log-Likelihood:                -339.37
converged:                       True   LL-Null:                       -341.37
Covariance Type:            nonrobust   LLR p-value:                   0.04544
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.3290      0.093     -3.550      0.000      -0.511      -0.147
game_entropy     0.5798      0.300      1.931      0.053      -0.009       1.168
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=17251.00, p=9.18e-45
Paired t-test (game_entropy vs capabilities_entropy): statistic=4.68, p=3.74e-06
Mean game_entropy-capabilities_entropy = 0.0663  [0.0385, 0.0940] (n=500)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      497
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                0.007755
Time:                        16:14:48   Log-Likelihood:                -338.72
converged:                       True   LL-Null:                       -341.37
Covariance Type:            nonrobust   LLR p-value:                   0.07085
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -0.3366      0.093     -3.619      0.000      -0.519      -0.154
capabilities_entropy     7.3877      9.934      0.744      0.457     -12.083      26.858
game_entropy             0.5781      0.300      1.928      0.054      -0.010       1.166
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.640000
                        1                 0.360000
Geography               0                 0.613636
                        1                 0.386364
Misc                    1                 0.554054
                        0                 0.445946
Music                   1                 0.525000
                        0                 0.475000
Other                   0                 0.557692
                        1                 0.442308
Politics                0                 0.597403
                        1                 0.402597
Science and technology  0                 0.622449
                        1                 0.377551
Sports                  0                 0.575000
                        1                 0.425000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.520710
                     1                 0.479290
Number               0                 0.551282
                     1                 0.448718
Other                0                 0.654135
                     1                 0.345865
Person               0                 0.566667
                     1                 0.433333
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.666667  0.333333           21
                       Number               0.666667  0.333333            9
                       Other                0.833333  0.166667           18
                       Person               0.481481  0.518519           27
Geography              Date                 0.400000  0.600000           15
                       Number               0.611111  0.388889           18
                       Other                0.909091  0.090909           11
Misc                   Date                 0.347826  0.652174           23
                       Number               0.555556  0.444444            9
                       Other                0.481481  0.518519           27
                       Person               0.466667  0.533333           15
Music                  Date                 0.666667  0.333333           12
                       Number               0.250000  0.750000            4
                       Other                0.250000  0.750000           12
                       Person               0.583333  0.416667           12
Other                  Date                 0.444444  0.555556           18
                       Number               0.571429  0.428571            7
                       Other                0.714286  0.285714           14
                       Person               0.538462  0.461538           13
Politics               Date                 0.555556  0.444444           36
                       Number               0.333333  0.666667            6
                       Other                0.750000  0.250000           20
                       Person               0.600000  0.400000           15
Science and technology Date                 0.542857  0.457143           35
                       Number               0.714286  0.285714           14
                       Other                0.684211  0.315789           19
                       Person               0.633333  0.366667           30
Sports                 Date                 0.555556  0.444444            9
                       Number               0.363636  0.636364           11
                       Other                0.666667  0.333333           12
                       Person               0.750000  0.250000            8

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      488
Method:                           MLE   Df Model:                           11
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.02980
Time:                        16:14:48   Log-Likelihood:                -331.20
converged:                       True   LL-Null:                       -341.37
Covariance Type:            nonrobust   LLR p-value:                   0.04086
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -2.4857      1.164     -2.135      0.033      -4.768      -0.204
C(topic_grouped)[T.Geography]                  0.1179      0.409      0.288      0.773      -0.684       0.920
C(topic_grouped)[T.Misc]                       0.8514      0.342      2.487      0.013       0.180       1.522
C(topic_grouped)[T.Music]                      0.7399      0.403      1.835      0.067      -0.050       1.530
C(topic_grouped)[T.Other]                      0.3656      0.374      0.978      0.328      -0.367       1.098
C(topic_grouped)[T.Politics]                   0.0593      0.346      0.172      0.864      -0.618       0.737
C(topic_grouped)[T.Science and technology]     0.0019      0.323      0.006      0.995      -0.631       0.634
C(topic_grouped)[T.Sports]                     0.3031      0.408      0.743      0.458      -0.497       1.103
C(answer_type_grouped)[T.Number]              -0.1319      0.287     -0.460      0.646      -0.694       0.430
C(answer_type_grouped)[T.Other]               -0.6081      0.245     -2.479      0.013      -1.089      -0.127
C(answer_type_grouped)[T.Person]              -0.1434      0.249     -0.576      0.565      -0.632       0.345
q_length                                       0.4725      0.250      1.890      0.059      -0.018       0.962
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.0013
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      487
Method:                           MLE   Df Model:                           12
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.03161
Time:                        16:14:48   Log-Likelihood:                -330.58
converged:                       True   LL-Null:                       -341.37
Covariance Type:            nonrobust   LLR p-value:                   0.04246
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -2.5426      1.166     -2.180      0.029      -4.829      -0.257
C(topic_grouped)[T.Geography]                  0.1217      0.410      0.297      0.766      -0.681       0.924
C(topic_grouped)[T.Misc]                       0.8195      0.344      2.385      0.017       0.146       1.493
C(topic_grouped)[T.Music]                      0.7432      0.403      1.842      0.065      -0.048       1.534
C(topic_grouped)[T.Other]                      0.3669      0.374      0.981      0.326      -0.366       1.100
C(topic_grouped)[T.Politics]                   0.0577      0.346      0.167      0.867      -0.620       0.735
C(topic_grouped)[T.Science and technology]    -0.0022      0.323     -0.007      0.995      -0.635       0.631
C(topic_grouped)[T.Sports]                     0.3045      0.408      0.746      0.456      -0.496       1.105
C(answer_type_grouped)[T.Number]              -0.1389      0.287     -0.484      0.628      -0.701       0.424
C(answer_type_grouped)[T.Other]               -0.6218      0.246     -2.529      0.011      -1.104      -0.140
C(answer_type_grouped)[T.Person]              -0.1433      0.249     -0.575      0.565      -0.631       0.345
q_length                                       0.4855      0.250      1.938      0.053      -0.005       0.976
capabilities_entropy                           6.8290      8.713      0.784      0.433     -10.247      23.905
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      487
Method:                           MLE   Df Model:                           12
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.03534
Time:                        16:14:48   Log-Likelihood:                -329.31
converged:                       True   LL-Null:                       -341.37
Covariance Type:            nonrobust   LLR p-value:                   0.01956
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -2.4643      1.170     -2.107      0.035      -4.757      -0.172
C(topic_grouped)[T.Geography]                  0.1250      0.411      0.304      0.761      -0.680       0.930
C(topic_grouped)[T.Misc]                       0.8668      0.343      2.527      0.012       0.194       1.539
C(topic_grouped)[T.Music]                      0.7528      0.403      1.866      0.062      -0.038       1.544
C(topic_grouped)[T.Other]                      0.3220      0.377      0.854      0.393      -0.417       1.061
C(topic_grouped)[T.Politics]                   0.0310      0.348      0.089      0.929      -0.651       0.713
C(topic_grouped)[T.Science and technology]     0.0043      0.324      0.013      0.989      -0.631       0.639
C(topic_grouped)[T.Sports]                     0.3138      0.409      0.768      0.442      -0.487       1.115
C(answer_type_grouped)[T.Number]              -0.1375      0.288     -0.478      0.633      -0.702       0.427
C(answer_type_grouped)[T.Other]               -0.5920      0.246     -2.403      0.016      -1.075      -0.109
C(answer_type_grouped)[T.Person]              -0.1382      0.250     -0.553      0.580      -0.628       0.352
q_length                                       0.4589      0.251      1.826      0.068      -0.034       0.951
game_entropy                                   0.5719      0.304      1.883      0.060      -0.024       1.167
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      486
Method:                           MLE   Df Model:                           13
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.03707
Time:                        16:14:48   Log-Likelihood:                -328.72
converged:                       True   LL-Null:                       -341.37
Covariance Type:            nonrobust   LLR p-value:                   0.02100
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -2.5208      1.172     -2.152      0.031      -4.817      -0.224
C(topic_grouped)[T.Geography]                  0.1286      0.411      0.313      0.754      -0.676       0.934
C(topic_grouped)[T.Misc]                       0.8357      0.344      2.427      0.015       0.161       1.510
C(topic_grouped)[T.Music]                      0.7559      0.404      1.872      0.061      -0.035       1.547
C(topic_grouped)[T.Other]                      0.3237      0.377      0.858      0.391      -0.416       1.063
C(topic_grouped)[T.Politics]                   0.0296      0.348      0.085      0.932      -0.653       0.712
C(topic_grouped)[T.Science and technology]     0.0003      0.324      0.001      0.999      -0.635       0.636
C(topic_grouped)[T.Sports]                     0.3152      0.409      0.771      0.441      -0.486       1.116
C(answer_type_grouped)[T.Number]              -0.1443      0.288     -0.501      0.616      -0.709       0.420
C(answer_type_grouped)[T.Other]               -0.6057      0.247     -2.453      0.014      -1.090      -0.122
C(answer_type_grouped)[T.Person]              -0.1381      0.250     -0.553      0.581      -0.628       0.352
q_length                                       0.4718      0.252      1.874      0.061      -0.022       0.965
capabilities_entropy                           6.6738      8.639      0.773      0.440     -10.258      23.606
game_entropy                                   0.5676      0.304      1.870      0.061      -0.027       1.162
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing gpt-4.1-2025-04-14 (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_new/gpt-4.1-2025-04-14_SimpleMC_redacted_cor_temp1.0_1757988452_game_data.json', './sc_logs_new/gpt-4.1-2025-04-14_SimpleMC_redacted_temp1.0_1757987360_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    325
1    175
Name: count, dtype: int64

Answer change%: 0.3500 [0.30819253938092117, 0.3918074606190788] (n=500)
P-value vs 25%: 2.758e-06; P-value vs 0%: 1.669e-60
Phase 2 self-accuracy: 0.4000 [0.3274170379313008, 0.47258296206869926] (n=175)
P-value vs 25%: 5.112e-05; P-value vs 33%: 0.07042

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.01754
Time:                        16:14:48   Log-Likelihood:                -318.05
converged:                       True   LL-Null:                       -323.72
Covariance Type:            nonrobust   LLR p-value:                 0.0007519
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          0.8604      0.447      1.927      0.054      -0.015       1.736
p_i_capability    -1.7207      0.511     -3.369      0.001      -2.722      -0.720
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.02327
Time:                        16:14:48   Log-Likelihood:                -316.19
converged:                       True   LL-Null:                       -323.72
Covariance Type:            nonrobust   LLR p-value:                 0.0001036
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -0.9353      0.128     -7.313      0.000      -1.186      -0.685
capabilities_entropy     0.6632      0.172      3.865      0.000       0.327       1.000
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.2571 [0.1847, 0.3295] (n=140)
                  P-value vs 33.3%: 0.03915

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=12.93, p=1.97e-25
Wilcoxon delta_p: statistic=724.00, p=8.01e-18
Mean Δp = 0.4857  [0.4120, 0.5593]
Idea 1 N = 137; 

  Idea 1.5: Calibration Metrics
  NLL: 5.4716, Signed ECE (overconf pos under neg): -0.1890, ECE: 0.3910 (n=254)
  Brier: 0.4060, Reliability (absolute calibration error; lower better): 0.1726, Resolution (relative calibration quality; higher better): 0.0093, Uncertainty: 0.2438 (n=254)
  AUROC: 0.4709

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.300
Model:                            OLS   Adj. R-squared:                  0.291
Method:                 Least Squares   F-statistic:                     35.67
Date:                Wed, 24 Sep 2025   Prob (F-statistic):           3.16e-19
Time:                        16:14:48   Log-Likelihood:                -94.382
No. Observations:                 254   AIC:                             196.8
Df Residuals:                     250   BIC:                             210.9
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.3734      0.122     -3.055      0.002      -0.614      -0.133
p1                    1.1125      0.153      7.253      0.000       0.810       1.415
answer_changed       -0.0379      0.187     -0.203      0.840      -0.406       0.331
p1:answer_changed     0.1370      0.233      0.588      0.557      -0.322       0.596
==============================================================================
Omnibus:                       37.397   Durbin-Watson:                   2.032
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               46.197
Skew:                          -1.012   Prob(JB):                     9.30e-11
Kurtosis:                       2.484   Cond. No.                         21.3
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=4.06, p=8.23e-05
Wilcoxon delta_H: statistic=3067.00, p=0.000363
Mean ΔH = 0.2128  [0.1101, 0.3155]
Paired t-test delta_H Changed: statistic=2.33, p=0.0214
Wilcoxon delta_H Changed: statistic=2642.00, p=0.0277
Mean ΔH Changed = 0.1404  [0.0224, 0.2583]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=5.18, p=4.56e-07
Wilcoxon (p_top2_game vs p_top2_base): statistic=10931.00, p=7.15e-06
Mean Δp_top2 = 0.0294  [0.0183, 0.0405] (n=254)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=4.53, p=8.94e-06
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=11375.00, p=3.95e-05
Mean ΔH_unchosen_baseline_set = 0.1794  [0.1019, 0.2570] (n=254)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  254
Model:                          Logit   Df Residuals:                      251
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                0.002315
Time:                        16:14:48   Log-Likelihood:                -174.87
converged:                       True   LL-Null:                       -175.27
Covariance Type:            nonrobust   LLR p-value:                    0.6665
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.0594      0.190     -0.313      0.755      -0.432       0.313
p1_z             0.0296      0.141      0.210      0.834      -0.246       0.306
I(p1_z ** 2)    -0.0992      0.144     -0.691      0.490      -0.381       0.182
================================================================================
AUC = 0.546

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.04708
Time:                        16:14:48   Log-Likelihood:                -308.48
converged:                       True   LL-Null:                       -323.72
Covariance Type:            nonrobust   LLR p-value:                 3.365e-08
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.0725      0.131     -8.215      0.000      -1.328      -0.817
game_entropy     1.1668      0.215      5.426      0.000       0.745       1.588
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=38874.00, p=0.000678
Paired t-test (game_entropy vs capabilities_entropy): statistic=-3.78, p=0.000176
Mean game_entropy-capabilities_entropy = -0.0897  [-0.1363, -0.0432] (n=500)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      497
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.05163
Time:                        16:14:48   Log-Likelihood:                -307.01
converged:                       True   LL-Null:                       -323.72
Covariance Type:            nonrobust   LLR p-value:                 5.512e-08
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.1656      0.143     -8.152      0.000      -1.446      -0.885
capabilities_entropy     0.3295      0.191      1.722      0.085      -0.045       0.704
game_entropy             1.0000      0.235      4.253      0.000       0.539       1.461
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.720000
                        1                 0.280000
Geography               0                 0.636364
                        1                 0.363636
Misc                    0                 0.513514
                        1                 0.486486
Music                   0                 0.675000
                        1                 0.325000
Other                   0                 0.673077
                        1                 0.326923
Politics                0                 0.649351
                        1                 0.350649
Science and technology  0                 0.704082
                        1                 0.295918
Sports                  0                 0.600000
                        1                 0.400000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.579882
                     1                 0.420118
Number               0                 0.589744
                     1                 0.410256
Other                0                 0.721805
                     1                 0.278195
Person               0                 0.708333
                     1                 0.291667
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.619048  0.380952           21
                       Number               0.666667  0.333333            9
                       Other                0.777778  0.222222           18
                       Person               0.777778  0.222222           27
Geography              Date                 0.533333  0.466667           15
                       Number               0.555556  0.444444           18
                       Other                0.909091  0.090909           11
Misc                   Date                 0.391304  0.608696           23
                       Number               0.555556  0.444444            9
                       Other                0.629630  0.370370           27
                       Person               0.466667  0.533333           15
Music                  Date                 0.666667  0.333333           12
                       Number               0.750000  0.250000            4
                       Other                0.666667  0.333333           12
                       Person               0.666667  0.333333           12
Other                  Date                 0.666667  0.333333           18
                       Number               0.428571  0.571429            7
                       Other                0.714286  0.285714           14
                       Person               0.769231  0.230769           13
Politics               Date                 0.666667  0.333333           36
                       Number               0.500000  0.500000            6
                       Other                0.600000  0.400000           20
                       Person               0.733333  0.266667           15
Science and technology Date                 0.657143  0.342857           35
                       Number               0.571429  0.428571           14
                       Other                0.789474  0.210526           19
                       Person               0.766667  0.233333           30
Sports                 Date                 0.111111  0.888889            9
                       Number               0.727273  0.272727           11
                       Other                0.833333  0.166667           12
                       Person               0.625000  0.375000            8

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      488
Method:                           MLE   Df Model:                           11
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.03181
Time:                        16:14:48   Log-Likelihood:                -313.43
converged:                       True   LL-Null:                       -323.72
Covariance Type:            nonrobust   LLR p-value:                   0.03782
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      0.3439      1.209      0.284      0.776      -2.025       2.713
C(topic_grouped)[T.Geography]                  0.2044      0.422      0.485      0.628      -0.622       1.031
C(topic_grouped)[T.Misc]                       0.9190      0.353      2.602      0.009       0.227       1.611
C(topic_grouped)[T.Music]                      0.2164      0.429      0.504      0.614      -0.625       1.058
C(topic_grouped)[T.Other]                      0.1797      0.397      0.453      0.651      -0.598       0.958
C(topic_grouped)[T.Politics]                   0.2998      0.362      0.828      0.407      -0.410       1.009
C(topic_grouped)[T.Science and technology]     0.0339      0.344      0.099      0.921      -0.640       0.708
C(topic_grouped)[T.Sports]                     0.5146      0.420      1.224      0.221      -0.309       1.339
C(answer_type_grouped)[T.Number]              -0.0440      0.289     -0.152      0.879      -0.611       0.523
C(answer_type_grouped)[T.Other]               -0.7307      0.255     -2.862      0.004      -1.231      -0.230
C(answer_type_grouped)[T.Person]              -0.5602      0.262     -2.136      0.033      -1.074      -0.046
q_length                                      -0.2075      0.260     -0.797      0.425      -0.718       0.303
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.4519
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      487
Method:                           MLE   Df Model:                           12
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.04723
Time:                        16:14:48   Log-Likelihood:                -308.44
converged:                       True   LL-Null:                       -323.72
Covariance Type:            nonrobust   LLR p-value:                  0.002285
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -0.2229      1.235     -0.180      0.857      -2.644       2.198
C(topic_grouped)[T.Geography]                  0.2178      0.427      0.510      0.610      -0.619       1.055
C(topic_grouped)[T.Misc]                       0.9172      0.357      2.567      0.010       0.217       1.618
C(topic_grouped)[T.Music]                      0.2099      0.434      0.483      0.629      -0.641       1.061
C(topic_grouped)[T.Other]                      0.1990      0.401      0.496      0.620      -0.588       0.986
C(topic_grouped)[T.Politics]                   0.3380      0.366      0.924      0.355      -0.379       1.055
C(topic_grouped)[T.Science and technology]     0.0103      0.348      0.030      0.976      -0.671       0.692
C(topic_grouped)[T.Sports]                     0.5908      0.426      1.388      0.165      -0.243       1.425
C(answer_type_grouped)[T.Number]              -0.0067      0.292     -0.023      0.982      -0.580       0.566
C(answer_type_grouped)[T.Other]               -0.5630      0.263     -2.139      0.032      -1.079      -0.047
C(answer_type_grouped)[T.Person]              -0.3525      0.272     -1.297      0.195      -0.885       0.180
q_length                                      -0.1665      0.264     -0.632      0.528      -0.683       0.350
capabilities_entropy                           0.5745      0.182      3.155      0.002       0.218       0.931
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      487
Method:                           MLE   Df Model:                           12
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.06738
Time:                        16:14:48   Log-Likelihood:                -301.91
converged:                       True   LL-Null:                       -323.72
Covariance Type:            nonrobust   LLR p-value:                 1.769e-05
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -0.4129      1.247     -0.331      0.740      -2.856       2.030
C(topic_grouped)[T.Geography]                  0.2209      0.433      0.510      0.610      -0.628       1.070
C(topic_grouped)[T.Misc]                       0.9847      0.364      2.707      0.007       0.272       1.698
C(topic_grouped)[T.Music]                      0.4006      0.439      0.912      0.362      -0.461       1.262
C(topic_grouped)[T.Other]                      0.1809      0.409      0.442      0.658      -0.621       0.982
C(topic_grouped)[T.Politics]                   0.4162      0.371      1.121      0.262      -0.312       1.144
C(topic_grouped)[T.Science and technology]     0.1024      0.354      0.289      0.772      -0.591       0.796
C(topic_grouped)[T.Sports]                     0.5225      0.434      1.204      0.229      -0.328       1.373
C(answer_type_grouped)[T.Number]              -0.0450      0.297     -0.152      0.880      -0.627       0.537
C(answer_type_grouped)[T.Other]               -0.4670      0.267     -1.751      0.080      -0.990       0.056
C(answer_type_grouped)[T.Person]              -0.2302      0.277     -0.832      0.406      -0.773       0.312
q_length                                      -0.1784      0.265     -0.672      0.502      -0.699       0.342
game_entropy                                   1.0884      0.230      4.739      0.000       0.638       1.539
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      486
Method:                           MLE   Df Model:                           13
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.07076
Time:                        16:14:48   Log-Likelihood:                -300.82
converged:                       True   LL-Null:                       -323.72
Covariance Type:            nonrobust   LLR p-value:                 1.529e-05
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -0.6180      1.258     -0.491      0.623      -3.084       1.848
C(topic_grouped)[T.Geography]                  0.2309      0.434      0.532      0.594      -0.619       1.081
C(topic_grouped)[T.Misc]                       0.9790      0.365      2.680      0.007       0.263       1.695
C(topic_grouped)[T.Music]                      0.3766      0.441      0.853      0.393      -0.488       1.242
C(topic_grouped)[T.Other]                      0.1942      0.410      0.474      0.636      -0.609       0.998
C(topic_grouped)[T.Politics]                   0.4247      0.372      1.142      0.254      -0.304       1.154
C(topic_grouped)[T.Science and technology]     0.0832      0.355      0.234      0.815      -0.613       0.779
C(topic_grouped)[T.Sports]                     0.5628      0.435      1.293      0.196      -0.290       1.416
C(answer_type_grouped)[T.Number]              -0.0215      0.298     -0.072      0.943      -0.605       0.562
C(answer_type_grouped)[T.Other]               -0.4107      0.270     -1.518      0.129      -0.941       0.119
C(answer_type_grouped)[T.Person]              -0.1578      0.281     -0.561      0.575      -0.709       0.394
q_length                                      -0.1607      0.267     -0.603      0.547      -0.683       0.362
capabilities_entropy                           0.2950      0.199      1.485      0.138      -0.094       0.684
game_entropy                                   0.9561      0.246      3.883      0.000       0.474       1.439
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing gpt-4o-2024-08-06 (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_new/gpt-4o-2024-08-06_SimpleMC_redacted_cor_temp1.0_1757988718_game_data.json', './sc_logs_new/gpt-4o-2024-08-06_SimpleMC_redacted_temp1.0_1757987648_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    366
1    134
Name: count, dtype: int64

Answer change%: 0.2680 [0.22917727403675803, 0.306822725963242] (n=500)
P-value vs 25%: 0.3635; P-value vs 0%: 1.041e-41
Phase 2 self-accuracy: 0.5075 [0.4228145664605305, 0.5921108066737979] (n=134)
P-value vs 25%: 2.502e-09; P-value vs 33%: 5.355e-05

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.06191
Time:                        16:14:48   Log-Likelihood:                -272.64
converged:                       True   LL-Null:                       -290.63
Covariance Type:            nonrobust   LLR p-value:                 1.989e-09
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          1.0427      0.355      2.938      0.003       0.347       1.738
p_i_capability    -2.8640      0.494     -5.797      0.000      -3.832      -1.896
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.06604
Time:                        16:14:48   Log-Likelihood:                -271.44
converged:                       True   LL-Null:                       -290.63
Covariance Type:            nonrobust   LLR p-value:                 5.808e-10
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.0135      0.216     -9.321      0.000      -2.437      -1.590
capabilities_entropy     1.0398      0.177      5.864      0.000       0.692       1.387
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.2388 [0.1666, 0.3110] (n=134)
                  P-value vs 33.3%: 0.01027

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=21.69, p=2.47e-65
Wilcoxon delta_p: statistic=3313.00, p=2.5e-43
Mean Δp = 0.5061  [0.4604, 0.5519]
Idea 1 N = 329; 

  Idea 1.5: Calibration Metrics
  NLL: 3.5623, Signed ECE (overconf pos under neg): -0.2183, ECE: 0.4120 (n=478)
  Brier: 0.4339, Reliability (absolute calibration error; lower better): 0.1964, Resolution (relative calibration quality; higher better): 0.0147, Uncertainty: 0.2489 (n=478)
  AUROC: 0.3556

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.409
Model:                            OLS   Adj. R-squared:                  0.405
Method:                 Least Squares   F-statistic:                     105.3
Date:                Wed, 24 Sep 2025   Prob (F-statistic):           7.56e-52
Time:                        16:14:48   Log-Likelihood:                -116.75
No. Observations:                 461   AIC:                             241.5
Df Residuals:                     457   BIC:                             258.0
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.4561      0.065     -6.975      0.000      -0.585      -0.328
p1                    1.2574      0.082     15.257      0.000       1.095       1.419
answer_changed        0.1210      0.112      1.082      0.280      -0.099       0.341
p1:answer_changed    -0.1453      0.156     -0.929      0.353      -0.453       0.162
==============================================================================
Omnibus:                       77.133   Durbin-Watson:                   2.103
Prob(Omnibus):                  0.000   Jarque-Bera (JB):              114.467
Skew:                          -1.212   Prob(JB):                     1.39e-25
Kurtosis:                       3.297   Cond. No.                         17.9
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=12.71, p=1.38e-30
Wilcoxon delta_H: statistic=9975.00, p=1.41e-26
Mean ΔH = 0.3998  [0.3381, 0.4614]
Paired t-test delta_H Changed: statistic=2.76, p=0.00668
Wilcoxon delta_H Changed: statistic=3283.00, p=0.00591
Mean ΔH Changed = 0.1116  [0.0322, 0.1910]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=3.89, p=0.000115
Wilcoxon (p_top2_game vs p_top2_base): statistic=47377.00, p=0.0011
Mean Δp_top2 = 0.0169  [0.0084, 0.0255] (n=478)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=12.27, p=2.74e-30
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=24659.00, p=4.14e-27
Mean ΔH_unchosen_baseline_set = 0.3190  [0.2681, 0.3699] (n=478)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  478
Model:                          Logit   Df Residuals:                      475
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.05366
Time:                        16:14:48   Log-Likelihood:                -268.37
converged:                       True   LL-Null:                       -283.58
Covariance Type:            nonrobust   LLR p-value:                 2.463e-07
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.9245      0.161     -5.742      0.000      -1.240      -0.609
p1_z            -0.6004      0.117     -5.133      0.000      -0.830      -0.371
I(p1_z ** 2)    -0.0942      0.130     -0.727      0.467      -0.348       0.160
================================================================================
AUC = 0.665

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1281
Time:                        16:14:48   Log-Likelihood:                -253.41
converged:                       True   LL-Null:                       -290.63
Covariance Type:            nonrobust   LLR p-value:                 6.277e-18
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -2.4922      0.241    -10.347      0.000      -2.964      -2.020
game_entropy     1.5925      0.204      7.807      0.000       1.193       1.992
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=54126.00, p=0.00855
Paired t-test (game_entropy vs capabilities_entropy): statistic=-3.05, p=0.00237
Mean game_entropy-capabilities_entropy = -0.0675  [-0.1109, -0.0242] (n=500)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      497
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1288
Time:                        16:14:48   Log-Likelihood:                -253.20
converged:                       True   LL-Null:                       -290.63
Covariance Type:            nonrobust   LLR p-value:                 5.554e-17
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.5442      0.255     -9.963      0.000      -3.045      -2.044
capabilities_entropy     0.1554      0.237      0.654      0.513      -0.310       0.621
game_entropy             1.4857      0.260      5.713      0.000       0.976       1.995
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.706667
                        1                 0.293333
Geography               0                 0.704545
                        1                 0.295455
Misc                    0                 0.743243
                        1                 0.256757
Music                   0                 0.700000
                        1                 0.300000
Other                   0                 0.730769
                        1                 0.269231
Politics                0                 0.701299
                        1                 0.298701
Science and technology  0                 0.775510
                        1                 0.224490
Sports                  0                 0.775000
                        1                 0.225000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.621302
                     1                 0.378698
Number               0                 0.743590
                     1                 0.256410
Other                0                 0.834586
                     1                 0.165414
Person               0                 0.766667
                     1                 0.233333
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.571429  0.428571           21
                       Number               0.888889  0.111111            9
                       Other                0.722222  0.277778           18
                       Person               0.740741  0.259259           27
Geography              Date                 0.333333  0.666667           15
                       Number               0.888889  0.111111           18
                       Other                0.909091  0.090909           11
Misc                   Date                 0.739130  0.260870           23
                       Number               0.555556  0.444444            9
                       Other                0.851852  0.148148           27
                       Person               0.666667  0.333333           15
Music                  Date                 0.500000  0.500000           12
                       Number               0.750000  0.250000            4
                       Other                0.833333  0.166667           12
                       Person               0.750000  0.250000           12
Other                  Date                 0.666667  0.333333           18
                       Number               0.571429  0.428571            7
                       Other                0.857143  0.142857           14
                       Person               0.769231  0.230769           13
Politics               Date                 0.611111  0.388889           36
                       Number               0.500000  0.500000            6
                       Other                0.850000  0.150000           20
                       Person               0.800000  0.200000           15
Science and technology Date                 0.714286  0.285714           35
                       Number               0.785714  0.214286           14
                       Other                0.894737  0.105263           19
                       Person               0.766667  0.233333           30
Sports                 Date                 0.666667  0.333333            9
                       Number               0.727273  0.272727           11
                       Other                0.750000  0.250000           12
                       Person               1.000000  0.000000            8

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      488
Method:                           MLE   Df Model:                           11
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.03767
Time:                        16:14:48   Log-Likelihood:                -279.68
converged:                       True   LL-Null:                       -290.63
Covariance Type:            nonrobust   LLR p-value:                   0.02518
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      0.8846      1.310      0.675      0.499      -1.683       3.452
C(topic_grouped)[T.Geography]                 -0.0908      0.440     -0.206      0.836      -0.952       0.771
C(topic_grouped)[T.Misc]                      -0.1626      0.377     -0.431      0.667      -0.902       0.577
C(topic_grouped)[T.Music]                      0.0313      0.437      0.071      0.943      -0.826       0.889
C(topic_grouped)[T.Other]                     -0.1749      0.412     -0.425      0.671      -0.982       0.632
C(topic_grouped)[T.Politics]                  -0.0457      0.371     -0.123      0.902      -0.773       0.682
C(topic_grouped)[T.Science and technology]    -0.4342      0.358     -1.211      0.226      -1.137       0.268
C(topic_grouped)[T.Sports]                    -0.3267      0.467     -0.699      0.484      -1.242       0.589
C(answer_type_grouped)[T.Number]              -0.5533      0.314     -1.764      0.078      -1.168       0.061
C(answer_type_grouped)[T.Other]               -1.1639      0.286     -4.066      0.000      -1.725      -0.603
C(answer_type_grouped)[T.Person]              -0.7197      0.275     -2.616      0.009      -1.259      -0.180
q_length                                      -0.2675      0.283     -0.945      0.344      -0.822       0.287
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.8728
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      487
Method:                           MLE   Df Model:                           12
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.08835
Time:                        16:14:48   Log-Likelihood:                -264.95
converged:                       True   LL-Null:                       -290.63
Covariance Type:            nonrobust   LLR p-value:                 8.061e-07
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -0.7585      1.406     -0.539      0.590      -3.515       1.998
C(topic_grouped)[T.Geography]                 -0.0636      0.455     -0.140      0.889      -0.955       0.828
C(topic_grouped)[T.Misc]                      -0.2306      0.390     -0.592      0.554      -0.994       0.533
C(topic_grouped)[T.Music]                      0.0840      0.453      0.185      0.853      -0.804       0.972
C(topic_grouped)[T.Other]                     -0.1725      0.426     -0.405      0.686      -1.007       0.662
C(topic_grouped)[T.Politics]                   0.0014      0.385      0.004      0.997      -0.753       0.756
C(topic_grouped)[T.Science and technology]    -0.4353      0.371     -1.173      0.241      -1.163       0.292
C(topic_grouped)[T.Sports]                    -0.1964      0.483     -0.407      0.684      -1.143       0.750
C(answer_type_grouped)[T.Number]              -0.6781      0.322     -2.107      0.035      -1.309      -0.047
C(answer_type_grouped)[T.Other]               -0.8188      0.300     -2.734      0.006      -1.406      -0.232
C(answer_type_grouped)[T.Person]              -0.2431      0.298     -0.816      0.415      -0.827       0.341
q_length                                      -0.1590      0.297     -0.536      0.592      -0.741       0.423
capabilities_entropy                           0.9997      0.192      5.208      0.000       0.624       1.376
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      487
Method:                           MLE   Df Model:                           12
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1519
Time:                        16:14:48   Log-Likelihood:                -246.50
converged:                       True   LL-Null:                       -290.63
Covariance Type:            nonrobust   LLR p-value:                 1.068e-13
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.2575      1.457     -0.863      0.388      -4.113       1.598
C(topic_grouped)[T.Geography]                 -0.1704      0.482     -0.353      0.724      -1.116       0.775
C(topic_grouped)[T.Misc]                      -0.3153      0.401     -0.786      0.432      -1.102       0.471
C(topic_grouped)[T.Music]                     -0.0619      0.471     -0.131      0.896      -0.985       0.862
C(topic_grouped)[T.Other]                     -0.3108      0.442     -0.703      0.482      -1.177       0.555
C(topic_grouped)[T.Politics]                  -0.0589      0.405     -0.145      0.884      -0.853       0.735
C(topic_grouped)[T.Science and technology]    -0.3961      0.387     -1.024      0.306      -1.155       0.362
C(topic_grouped)[T.Sports]                    -0.1438      0.499     -0.288      0.773      -1.123       0.835
C(answer_type_grouped)[T.Number]              -0.8150      0.336     -2.427      0.015      -1.473      -0.157
C(answer_type_grouped)[T.Other]               -0.8603      0.308     -2.792      0.005      -1.464      -0.256
C(answer_type_grouped)[T.Person]              -0.2414      0.303     -0.797      0.425      -0.835       0.352
q_length                                      -0.1497      0.309     -0.484      0.628      -0.756       0.457
game_entropy                                   1.6096      0.216      7.455      0.000       1.186       2.033
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      486
Method:                           MLE   Df Model:                           13
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1522
Time:                        16:14:48   Log-Likelihood:                -246.41
converged:                       True   LL-Null:                       -290.63
Covariance Type:            nonrobust   LLR p-value:                 2.770e-13
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.3389      1.471     -0.910      0.363      -4.222       1.545
C(topic_grouped)[T.Geography]                 -0.1637      0.482     -0.340      0.734      -1.109       0.781
C(topic_grouped)[T.Misc]                      -0.3151      0.402     -0.785      0.433      -1.102       0.472
C(topic_grouped)[T.Music]                     -0.0463      0.473     -0.098      0.922      -0.973       0.880
C(topic_grouped)[T.Other]                     -0.3021      0.442     -0.683      0.495      -1.169       0.565
C(topic_grouped)[T.Politics]                  -0.0534      0.405     -0.132      0.895      -0.848       0.741
C(topic_grouped)[T.Science and technology]    -0.3950      0.387     -1.020      0.308      -1.154       0.364
C(topic_grouped)[T.Sports]                    -0.1363      0.500     -0.273      0.785      -1.116       0.843
C(answer_type_grouped)[T.Number]              -0.8154      0.335     -2.431      0.015      -1.473      -0.158
C(answer_type_grouped)[T.Other]               -0.8376      0.313     -2.679      0.007      -1.450      -0.225
C(answer_type_grouped)[T.Person]              -0.2101      0.312     -0.673      0.501      -0.822       0.402
q_length                                      -0.1442      0.310     -0.465      0.642      -0.752       0.463
capabilities_entropy                           0.1060      0.251      0.422      0.673      -0.387       0.598
game_entropy                                   1.5417      0.268      5.742      0.000       1.015       2.068
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing gpt-4o-mini (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_new/gpt-4o-mini_SimpleMC_redacted_cor_temp1.0_1757988920_game_data.json', './sc_logs_new/gpt-4o-mini_SimpleMC_redacted_temp1.0_1757987946_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    328
1    172
Name: count, dtype: int64

Answer change%: 0.3440 [0.3023615811224028, 0.38563841887759714] (n=500)
P-value vs 25%: 9.659e-06; P-value vs 0%: 5.702e-59
Phase 2 self-accuracy: 0.3081 [0.23913671546297355, 0.3771423543044683] (n=172)
P-value vs 25%: 0.09866; P-value vs 33%: 0.4801

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                0.005516
Time:                        16:14:48   Log-Likelihood:                -320.05
converged:                       True   LL-Null:                       -321.83
Covariance Type:            nonrobust   LLR p-value:                   0.05954
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          0.1179      0.413      0.285      0.775      -0.692       0.928
p_i_capability    -0.9433      0.500     -1.888      0.059      -1.923       0.036
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                0.008763
Time:                        16:14:48   Log-Likelihood:                -319.01
converged:                       True   LL-Null:                       -321.83
Covariance Type:            nonrobust   LLR p-value:                   0.01755
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -0.9185      0.152     -6.061      0.000      -1.215      -0.621
capabilities_entropy     0.4055      0.171      2.369      0.018       0.070       0.741
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.3155 [0.2452, 0.3857] (n=168)
                  P-value vs 33.3%: 0.6184

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=17.17, p=3.95e-46
Wilcoxon delta_p: statistic=4241.00, p=1.61e-32
Mean Δp = 0.4597  [0.4073, 0.5122]
Idea 1 N = 292; 

  Idea 1.5: Calibration Metrics
  NLL: 4.3574, Signed ECE (overconf pos under neg): -0.0616, ECE: 0.3258 (n=460)
  Brier: 0.3422, Reliability (absolute calibration error; lower better): 0.1336, Resolution (relative calibration quality; higher better): 0.0065, Uncertainty: 0.2134 (n=460)
  AUROC: 0.4732

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.238
Model:                            OLS   Adj. R-squared:                  0.233
Method:                 Least Squares   F-statistic:                     47.54
Date:                Wed, 24 Sep 2025   Prob (F-statistic):           9.45e-27
Time:                        16:14:48   Log-Likelihood:                -197.54
No. Observations:                 460   AIC:                             403.1
Df Residuals:                     456   BIC:                             419.6
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.4550      0.095     -4.769      0.000      -0.643      -0.268
p1                    1.1369      0.115      9.849      0.000       0.910       1.364
answer_changed        0.1690      0.161      1.052      0.293      -0.147       0.485
p1:answer_changed    -0.1013      0.197     -0.513      0.608      -0.489       0.286
==============================================================================
Omnibus:                      136.699   Durbin-Watson:                   1.823
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               63.841
Skew:                          -0.757   Prob(JB):                     1.37e-14
Kurtosis:                       1.981   Cond. No.                         21.6
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=8.14, p=1.18e-14
Wilcoxon delta_H: statistic=10376.00, p=2.42e-14
Mean ΔH = 0.2783  [0.2112, 0.3453]
Paired t-test delta_H Changed: statistic=4.58, p=9.05e-06
Wilcoxon delta_H Changed: statistic=4293.00, p=8.89e-06
Mean ΔH Changed = 0.1964  [0.1124, 0.2805]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=3.53, p=0.000464
Wilcoxon (p_top2_game vs p_top2_base): statistic=43784.00, p=0.00121
Mean Δp_top2 = 0.0139  [0.0062, 0.0216] (n=460)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=9.27, p=7.46e-19
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=27894.00, p=1.3e-18
Mean ΔH_unchosen_baseline_set = 0.2484  [0.1958, 0.3009] (n=460)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  460
Model:                          Logit   Df Residuals:                      457
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                0.006507
Time:                        16:14:48   Log-Likelihood:                -299.96
converged:                       True   LL-Null:                       -301.93
Covariance Type:            nonrobust   LLR p-value:                    0.1402
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.3672      0.144     -2.546      0.011      -0.650      -0.084
p1_z            -0.2030      0.117     -1.736      0.082      -0.432       0.026
I(p1_z ** 2)    -0.1908      0.111     -1.716      0.086      -0.409       0.027
================================================================================
AUC = 0.557

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.08285
Time:                        16:14:48   Log-Likelihood:                -295.16
converged:                       True   LL-Null:                       -321.83
Covariance Type:            nonrobust   LLR p-value:                 2.821e-13
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.5906      0.175     -9.074      0.000      -1.934      -1.247
game_entropy     1.4666      0.211      6.952      0.000       1.053       1.880
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=55598.00, p=0.059
Paired t-test (game_entropy vs capabilities_entropy): statistic=-2.19, p=0.0292
Mean game_entropy-capabilities_entropy = -0.0571  [-0.1082, -0.0059] (n=500)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      497
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.08297
Time:                        16:14:48   Log-Likelihood:                -295.12
converged:                       True   LL-Null:                       -321.83
Covariance Type:            nonrobust   LLR p-value:                 2.533e-12
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.5684      0.193     -8.135      0.000      -1.946      -1.191
capabilities_entropy    -0.0528      0.193     -0.273      0.785      -0.432       0.326
game_entropy             1.4878      0.225      6.610      0.000       1.047       1.929
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.680000
                        1                 0.320000
Geography               0                 0.613636
                        1                 0.386364
Misc                    0                 0.675676
                        1                 0.324324
Music                   0                 0.700000
                        1                 0.300000
Other                   0                 0.692308
                        1                 0.307692
Politics                0                 0.584416
                        1                 0.415584
Science and technology  0                 0.663265
                        1                 0.336735
Sports                  0                 0.650000
                        1                 0.350000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.538462
                     1                 0.461538
Number               0                 0.692308
                     1                 0.307692
Other                0                 0.721805
                     1                 0.278195
Person               0                 0.725000
                     1                 0.275000
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.571429  0.428571           21
                       Number               0.666667  0.333333            9
                       Other                0.777778  0.222222           18
                       Person               0.703704  0.296296           27
Geography              Date                 0.466667  0.533333           15
                       Number               0.722222  0.277778           18
                       Other                0.636364  0.363636           11
Misc                   Date                 0.652174  0.347826           23
                       Number               0.777778  0.222222            9
                       Other                0.703704  0.296296           27
                       Person               0.600000  0.400000           15
Music                  Date                 0.666667  0.333333           12
                       Number               0.750000  0.250000            4
                       Other                0.666667  0.333333           12
                       Person               0.750000  0.250000           12
Other                  Date                 0.500000  0.500000           18
                       Number               0.857143  0.142857            7
                       Other                0.714286  0.285714           14
                       Person               0.846154  0.153846           13
Politics               Date                 0.444444  0.555556           36
                       Number               0.500000  0.500000            6
                       Other                0.700000  0.300000           20
                       Person               0.800000  0.200000           15
Science and technology Date                 0.571429  0.428571           35
                       Number               0.642857  0.357143           14
                       Other                0.789474  0.210526           19
                       Person               0.700000  0.300000           30
Sports                 Date                 0.444444  0.555556            9
                       Number               0.636364  0.363636           11
                       Other                0.750000  0.250000           12
                       Person               0.750000  0.250000            8

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      488
Method:                           MLE   Df Model:                           11
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.02782
Time:                        16:14:48   Log-Likelihood:                -312.87
converged:                       True   LL-Null:                       -321.83
Covariance Type:            nonrobust   LLR p-value:                   0.08371
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -0.8955      1.205     -0.743      0.457      -3.257       1.466
C(topic_grouped)[T.Geography]                  0.2339      0.415      0.563      0.573      -0.580       1.048
C(topic_grouped)[T.Misc]                      -0.0066      0.358     -0.019      0.985      -0.708       0.695
C(topic_grouped)[T.Music]                     -0.1028      0.431     -0.238      0.812      -0.948       0.743
C(topic_grouped)[T.Other]                     -0.1096      0.396     -0.277      0.782      -0.886       0.667
C(topic_grouped)[T.Politics]                   0.2470      0.352      0.702      0.482      -0.442       0.936
C(topic_grouped)[T.Science and technology]    -0.0001      0.333     -0.000      1.000      -0.653       0.653
C(topic_grouped)[T.Sports]                     0.1699      0.422      0.402      0.688      -0.658       0.998
C(answer_type_grouped)[T.Number]              -0.6817      0.299     -2.277      0.023      -1.268      -0.095
C(answer_type_grouped)[T.Other]               -0.7772      0.250     -3.105      0.002      -1.268      -0.287
C(answer_type_grouped)[T.Person]              -0.7588      0.262     -2.900      0.004      -1.272      -0.246
q_length                                       0.1486      0.260      0.573      0.567      -0.360       0.657
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.6545
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      487
Method:                           MLE   Df Model:                           12
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.03358
Time:                        16:14:48   Log-Likelihood:                -311.02
converged:                       True   LL-Null:                       -321.83
Covariance Type:            nonrobust   LLR p-value:                   0.04205
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.2727      1.225     -1.039      0.299      -3.674       1.129
C(topic_grouped)[T.Geography]                  0.2411      0.417      0.578      0.563      -0.576       1.058
C(topic_grouped)[T.Misc]                      -0.0322      0.361     -0.089      0.929      -0.739       0.674
C(topic_grouped)[T.Music]                     -0.1141      0.433     -0.263      0.792      -0.963       0.735
C(topic_grouped)[T.Other]                     -0.0802      0.398     -0.201      0.840      -0.861       0.700
C(topic_grouped)[T.Politics]                   0.2040      0.354      0.576      0.565      -0.490       0.898
C(topic_grouped)[T.Science and technology]     0.0092      0.335      0.028      0.978      -0.647       0.665
C(topic_grouped)[T.Sports]                     0.1978      0.424      0.467      0.641      -0.633       1.029
C(answer_type_grouped)[T.Number]              -0.7451      0.303     -2.460      0.014      -1.339      -0.151
C(answer_type_grouped)[T.Other]               -0.7090      0.253     -2.799      0.005      -1.205      -0.213
C(answer_type_grouped)[T.Person]              -0.7035      0.264     -2.665      0.008      -1.221      -0.186
q_length                                       0.1769      0.261      0.679      0.497      -0.334       0.688
capabilities_entropy                           0.3458      0.180      1.924      0.054      -0.007       0.698
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      487
Method:                           MLE   Df Model:                           12
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1005
Time:                        16:14:48   Log-Likelihood:                -289.49
converged:                       True   LL-Null:                       -321.83
Covariance Type:            nonrobust   LLR p-value:                 3.143e-09
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.3340      1.266     -1.053      0.292      -3.816       1.148
C(topic_grouped)[T.Geography]                  0.0394      0.440      0.089      0.929      -0.823       0.902
C(topic_grouped)[T.Misc]                       0.0922      0.375      0.246      0.806      -0.643       0.828
C(topic_grouped)[T.Music]                     -0.1404      0.453     -0.310      0.757      -1.028       0.748
C(topic_grouped)[T.Other]                     -0.1173      0.416     -0.282      0.778      -0.932       0.698
C(topic_grouped)[T.Politics]                   0.3356      0.369      0.909      0.363      -0.388       1.059
C(topic_grouped)[T.Science and technology]     0.1370      0.349      0.393      0.694      -0.546       0.820
C(topic_grouped)[T.Sports]                     0.3542      0.444      0.797      0.425      -0.517       1.225
C(answer_type_grouped)[T.Number]              -0.7336      0.314     -2.336      0.019      -1.349      -0.118
C(answer_type_grouped)[T.Other]               -0.4984      0.266     -1.875      0.061      -1.019       0.023
C(answer_type_grouped)[T.Person]              -0.5560      0.275     -2.019      0.044      -1.096      -0.016
q_length                                       0.0036      0.272      0.013      0.990      -0.530       0.537
game_entropy                                   1.4483      0.221      6.564      0.000       1.016       1.881
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      486
Method:                           MLE   Df Model:                           13
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1007
Time:                        16:14:48   Log-Likelihood:                -289.42
converged:                       True   LL-Null:                       -321.83
Covariance Type:            nonrobust   LLR p-value:                 7.103e-09
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.2592      1.280     -0.983      0.325      -3.769       1.250
C(topic_grouped)[T.Geography]                  0.0338      0.440      0.077      0.939      -0.829       0.897
C(topic_grouped)[T.Misc]                       0.0999      0.376      0.266      0.790      -0.636       0.836
C(topic_grouped)[T.Music]                     -0.1367      0.453     -0.302      0.763      -1.024       0.751
C(topic_grouped)[T.Other]                     -0.1254      0.417     -0.301      0.763      -0.942       0.691
C(topic_grouped)[T.Politics]                   0.3472      0.371      0.937      0.349      -0.379       1.073
C(topic_grouped)[T.Science and technology]     0.1367      0.349      0.392      0.695      -0.547       0.820
C(topic_grouped)[T.Sports]                     0.3521      0.444      0.792      0.428      -0.519       1.223
C(answer_type_grouped)[T.Number]              -0.7223      0.316     -2.289      0.022      -1.341      -0.104
C(answer_type_grouped)[T.Other]               -0.5063      0.267     -1.899      0.058      -1.029       0.016
C(answer_type_grouped)[T.Person]              -0.5634      0.276     -2.040      0.041      -1.105      -0.022
q_length                                      -0.0054      0.273     -0.020      0.984      -0.541       0.530
capabilities_entropy                          -0.0790      0.200     -0.394      0.693      -0.471       0.313
game_entropy                                   1.4788      0.234      6.315      0.000       1.020       1.938
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing grok-3-latest (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_new/grok-3-latest_SimpleMC_redacted_cor_temp0.0_1751718904_game_data.json', './sc_logs_new/grok-3-latest_SimpleMC_redacted_temp0.0_1751719937_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    333
1    167
Name: count, dtype: int64

Answer change%: 0.3340 [0.2926597178067086, 0.37534028219329146] (n=500)
P-value vs 25%: 6.82e-05; P-value vs 0%: 1.781e-56
Phase 2 self-accuracy: 0.3593 [0.2865133601073383, 0.4320495141441587] (n=167)
P-value vs 25%: 0.003246; P-value vs 33%: 0.479

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.07609
Time:                        16:14:48   Log-Likelihood:                -294.25
converged:                       True   LL-Null:                       -318.49
Covariance Type:            nonrobust   LLR p-value:                 3.355e-12
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          2.6597      0.521      5.106      0.000       1.639       3.681
p_i_capability    -3.8695      0.592     -6.535      0.000      -5.030      -2.709
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1263
Time:                        16:14:48   Log-Likelihood:                -278.27
converged:                       True   LL-Null:                       -318.49
Covariance Type:            nonrobust   LLR p-value:                 3.018e-19
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.5647      0.151    -10.335      0.000      -1.862      -1.268
capabilities_entropy     1.8794      0.225      8.365      0.000       1.439       2.320
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.5988 [0.5245, 0.6731] (n=167)
                  P-value vs 33.3%: 2.573e-12

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=4.25, p=2.8e-05
Wilcoxon delta_p: statistic=16498.00, p=4.6e-10
Mean Δp = 0.0377  [0.0203, 0.0551]
Idea 1 N = 330; 

  Idea 1.5: Calibration Metrics
  NLL: 2.1840, Signed ECE (overconf pos under neg): -0.0143, ECE: 0.0634 (n=497)
  Brier: 0.0232, Reliability (absolute calibration error; lower better): 0.0147, Resolution (relative calibration quality; higher better): 0.2341, Uncertainty: 0.2423 (n=497)
  AUROC: 0.9996

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.819
Model:                            OLS   Adj. R-squared:                  0.818
Method:                 Least Squares   F-statistic:                     744.1
Date:                Wed, 24 Sep 2025   Prob (F-statistic):          1.44e-182
Time:                        16:14:48   Log-Likelihood:                 256.90
No. Observations:                 497   AIC:                            -505.8
Df Residuals:                     493   BIC:                            -489.0
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.4047      0.056     -7.290      0.000      -0.514      -0.296
p1                    0.4794      0.060      8.053      0.000       0.362       0.596
answer_changed        0.3370      0.076      4.441      0.000       0.188       0.486
p1:answer_changed     0.4171      0.087      4.802      0.000       0.246       0.588
==============================================================================
Omnibus:                       65.754   Durbin-Watson:                   2.002
Prob(Omnibus):                  0.000   Jarque-Bera (JB):              227.500
Skew:                           0.569   Prob(JB):                     3.97e-50
Kurtosis:                       6.113   Cond. No.                         28.6
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-7.28, p=2.54e-12
Wilcoxon delta_H: statistic=15293.00, p=4.3e-12
Mean ΔH = -0.2166  [-0.2749, -0.1582]
Paired t-test delta_H Changed: statistic=0.68, p=0.499
Wilcoxon delta_H Changed: statistic=6525.00, p=0.435
Mean ΔH Changed = 0.0267  [-0.0506, 0.1040]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=-6.55, p=1.42e-10
Wilcoxon (p_top2_game vs p_top2_base): statistic=28567.00, p=2.52e-25
Mean Δp_top2 = -0.0216  [-0.0280, -0.0151] (n=497)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=-5.54, p=4.84e-08
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=44665.00, p=7.74e-08
Mean ΔH_unchosen_baseline_set = -0.1348  [-0.1825, -0.0872] (n=497)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  497
Model:                          Logit   Df Residuals:                      494
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1266
Time:                        16:14:48   Log-Likelihood:                -277.10
converged:                       True   LL-Null:                       -317.26
Covariance Type:            nonrobust   LLR p-value:                 3.607e-18
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.3634      0.140     -2.595      0.009      -0.638      -0.089
p1_z            -1.3470      0.181     -7.453      0.000      -1.701      -0.993
I(p1_z ** 2)    -0.4188      0.105     -3.979      0.000      -0.625      -0.212
================================================================================
AUC = 0.762

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1660
Time:                        16:14:48   Log-Likelihood:                -265.61
converged:                       True   LL-Null:                       -318.49
Covariance Type:            nonrobust   LLR p-value:                 8.309e-25
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.9938      0.185    -10.770      0.000      -2.357      -1.631
game_entropy     1.9366      0.207      9.371      0.000       1.532       2.342
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=37439.00, p=6.6e-15
Paired t-test (game_entropy vs capabilities_entropy): statistic=7.59, p=1.54e-13
Mean game_entropy-capabilities_entropy = 0.1786  [0.1325, 0.2247] (n=500)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      497
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.2098
Time:                        16:14:48   Log-Likelihood:                -251.68
converged:                       True   LL-Null:                       -318.49
Covariance Type:            nonrobust   LLR p-value:                 9.651e-30
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.3460      0.211    -11.144      0.000      -2.759      -1.933
capabilities_entropy     1.2787      0.247      5.183      0.000       0.795       1.762
game_entropy             1.5549      0.222      7.018      0.000       1.121       1.989
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.720000
                        1                 0.280000
Geography               0                 0.500000
                        1                 0.500000
Misc                    0                 0.675676
                        1                 0.324324
Music                   0                 0.800000
                        1                 0.200000
Other                   0                 0.653846
                        1                 0.346154
Politics                0                 0.688312
                        1                 0.311688
Science and technology  0                 0.642857
                        1                 0.357143
Sports                  0                 0.625000
                        1                 0.375000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.686391
                     1                 0.313609
Number               1                 0.512821
                     0                 0.487179
Other                0                 0.714286
                     1                 0.285714
Person               0                 0.700000
                     1                 0.300000
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.761905  0.238095           21
                       Number               0.666667  0.333333            9
                       Other                0.833333  0.166667           18
                       Person               0.629630  0.370370           27
Geography              Date                 0.533333  0.466667           15
                       Number               0.500000  0.500000           18
                       Other                0.454545  0.545455           11
Misc                   Date                 0.869565  0.130435           23
                       Number               0.444444  0.555556            9
                       Other                0.666667  0.333333           27
                       Person               0.533333  0.466667           15
Music                  Date                 0.833333  0.166667           12
                       Number               0.750000  0.250000            4
                       Other                0.750000  0.250000           12
                       Person               0.833333  0.166667           12
Other                  Date                 0.555556  0.444444           18
                       Number               0.428571  0.571429            7
                       Other                0.785714  0.214286           14
                       Person               0.769231  0.230769           13
Politics               Date                 0.722222  0.277778           36
                       Number               0.333333  0.666667            6
                       Other                0.700000  0.300000           20
                       Person               0.733333  0.266667           15
Science and technology Date                 0.600000  0.400000           35
                       Number               0.285714  0.714286           14
                       Other                0.842105  0.157895           19
                       Person               0.733333  0.266667           30
Sports                 Date                 0.555556  0.444444            9
                       Number               0.636364  0.363636           11
                       Other                0.583333  0.416667           12
                       Person               0.750000  0.250000            8

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      488
Method:                           MLE   Df Model:                           11
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.03502
Time:                        16:14:48   Log-Likelihood:                -307.33
converged:                       True   LL-Null:                       -318.49
Covariance Type:            nonrobust   LLR p-value:                   0.02211
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -2.9073      1.216     -2.391      0.017      -5.290      -0.524
C(topic_grouped)[T.Geography]                  0.7819      0.416      1.882      0.060      -0.032       1.596
C(topic_grouped)[T.Misc]                       0.2213      0.364      0.609      0.543      -0.491       0.934
C(topic_grouped)[T.Music]                     -0.4020      0.476     -0.845      0.398      -1.335       0.531
C(topic_grouped)[T.Other]                      0.3233      0.393      0.822      0.411      -0.448       1.094
C(topic_grouped)[T.Politics]                   0.1032      0.367      0.281      0.779      -0.617       0.823
C(topic_grouped)[T.Science and technology]     0.3056      0.337      0.906      0.365      -0.356       0.967
C(topic_grouped)[T.Sports]                     0.3243      0.426      0.761      0.447      -0.511       1.160
C(answer_type_grouped)[T.Number]               0.7285      0.291      2.503      0.012       0.158       1.299
C(answer_type_grouped)[T.Other]               -0.0898      0.258     -0.348      0.728      -0.596       0.417
C(answer_type_grouped)[T.Person]               0.0545      0.267      0.204      0.838      -0.469       0.578
q_length                                       0.4167      0.260      1.602      0.109      -0.093       0.927
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.4188
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      487
Method:                           MLE   Df Model:                           12
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1641
Time:                        16:14:48   Log-Likelihood:                -266.24
converged:                       True   LL-Null:                       -318.49
Covariance Type:            nonrobust   LLR p-value:                 7.273e-17
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -3.8411      1.354     -2.837      0.005      -6.495      -1.187
C(topic_grouped)[T.Geography]                  0.9118      0.452      2.019      0.043       0.027       1.797
C(topic_grouped)[T.Misc]                       0.0568      0.400      0.142      0.887      -0.727       0.841
C(topic_grouped)[T.Music]                     -0.4363      0.518     -0.842      0.400      -1.452       0.579
C(topic_grouped)[T.Other]                      0.1801      0.436      0.413      0.680      -0.674       1.035
C(topic_grouped)[T.Politics]                   0.3005      0.402      0.748      0.455      -0.487       1.088
C(topic_grouped)[T.Science and technology]     0.1798      0.374      0.480      0.631      -0.554       0.914
C(topic_grouped)[T.Sports]                     0.3202      0.470      0.681      0.496      -0.602       1.242
C(answer_type_grouped)[T.Number]               0.8392      0.318      2.638      0.008       0.216       1.463
C(answer_type_grouped)[T.Other]               -0.0987      0.285     -0.347      0.729      -0.656       0.459
C(answer_type_grouped)[T.Person]               0.0503      0.296      0.170      0.865      -0.530       0.630
q_length                                       0.4208      0.286      1.471      0.141      -0.140       0.982
capabilities_entropy                           1.9734      0.235      8.412      0.000       1.514       2.433
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      487
Method:                           MLE   Df Model:                           12
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1930
Time:                        16:14:48   Log-Likelihood:                -257.03
converged:                       True   LL-Null:                       -318.49
Covariance Type:            nonrobust   LLR p-value:                 1.613e-20
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -3.4010      1.367     -2.488      0.013      -6.081      -0.721
C(topic_grouped)[T.Geography]                  0.9627      0.462      2.085      0.037       0.058       1.868
C(topic_grouped)[T.Misc]                       0.1916      0.406      0.472      0.637      -0.604       0.988
C(topic_grouped)[T.Music]                     -0.4459      0.516     -0.864      0.387      -1.457       0.565
C(topic_grouped)[T.Other]                      0.1104      0.435      0.254      0.800      -0.743       0.963
C(topic_grouped)[T.Politics]                   0.4426      0.409      1.081      0.280      -0.360       1.245
C(topic_grouped)[T.Science and technology]     0.3899      0.373      1.047      0.295      -0.340       1.120
C(topic_grouped)[T.Sports]                     0.0792      0.472      0.168      0.867      -0.846       1.004
C(answer_type_grouped)[T.Number]               0.7144      0.328      2.179      0.029       0.072       1.357
C(answer_type_grouped)[T.Other]                0.0818      0.290      0.282      0.778      -0.486       0.650
C(answer_type_grouped)[T.Person]               0.1277      0.300      0.425      0.671      -0.461       0.716
q_length                                       0.2119      0.291      0.728      0.466      -0.358       0.782
game_entropy                                   1.9707      0.216      9.133      0.000       1.548       2.394
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      486
Method:                           MLE   Df Model:                           13
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.2416
Time:                        16:14:48   Log-Likelihood:                -241.54
converged:                       True   LL-Null:                       -318.49
Covariance Type:            nonrobust   LLR p-value:                 3.386e-26
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -4.0228      1.442     -2.789      0.005      -6.849      -1.196
C(topic_grouped)[T.Geography]                  1.0339      0.478      2.161      0.031       0.096       1.971
C(topic_grouped)[T.Misc]                       0.1041      0.422      0.247      0.805      -0.723       0.932
C(topic_grouped)[T.Music]                     -0.5078      0.545     -0.932      0.351      -1.575       0.560
C(topic_grouped)[T.Other]                      0.0496      0.452      0.110      0.913      -0.836       0.935
C(topic_grouped)[T.Politics]                   0.5080      0.425      1.196      0.232      -0.325       1.341
C(topic_grouped)[T.Science and technology]     0.2814      0.391      0.719      0.472      -0.486       1.048
C(topic_grouped)[T.Sports]                     0.1324      0.495      0.267      0.789      -0.838       1.103
C(answer_type_grouped)[T.Number]               0.7880      0.334      2.358      0.018       0.133       1.443
C(answer_type_grouped)[T.Other]                0.0563      0.305      0.185      0.853      -0.541       0.653
C(answer_type_grouped)[T.Person]               0.1259      0.313      0.402      0.688      -0.488       0.740
q_length                                       0.2646      0.304      0.871      0.384      -0.331       0.860
capabilities_entropy                           1.3897      0.255      5.440      0.000       0.889       1.890
game_entropy                                   1.5597      0.231      6.750      0.000       1.107       2.013
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing qwen3-235b-a22b-2507 (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_new/qwen3-235b-a22b-2507_SimpleMC_redacted_cor_temp0.0_1756216549_game_data.json', './sc_logs_new/qwen3-235b-a22b-2507_SimpleMC_redacted_temp0.0_1756212978_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    345
1    155
Name: count, dtype: int64

Answer change%: 0.3100 [0.26946142474761914, 0.35053857525238086] (n=500)
P-value vs 25%: 0.003721; P-value vs 0%: 8.807e-51
Phase 2 self-accuracy: 0.2581 [0.18917875527731465, 0.32695027698074985] (n=155)
P-value vs 25%: 0.8185; P-value vs 33%: 0.033

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.04062
Time:                        16:14:48   Log-Likelihood:                -296.98
converged:                       True   LL-Null:                       -309.55
Covariance Type:            nonrobust   LLR p-value:                 5.305e-07
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          1.3727      0.442      3.106      0.002       0.506       2.239
p_i_capability    -2.5434      0.510     -4.985      0.000      -3.543      -1.543
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.04281
Time:                        16:14:48   Log-Likelihood:                -296.30
converged:                       True   LL-Null:                       -309.55
Covariance Type:            nonrobust   LLR p-value:                 2.627e-07
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.2396      0.136     -9.126      0.000      -1.506      -0.973
capabilities_entropy     0.8636      0.169      5.107      0.000       0.532       1.195
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.6581 [0.5834, 0.7327] (n=155)
                  P-value vs 33.3%: 1.557e-17

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=3.72, p=0.000238
Wilcoxon delta_p: statistic=13852.00, p=3.66e-05
Mean Δp = 0.0501  [0.0237, 0.0765]
Idea 1 N = 283; 

  Idea 1.5: Calibration Metrics
  NLL: 4.2324, Signed ECE (overconf pos under neg): -0.0295, ECE: 0.0799 (n=425)
  Brier: 0.0373, Reliability (absolute calibration error; lower better): 0.0191, Resolution (relative calibration quality; higher better): 0.2215, Uncertainty: 0.2395 (n=425)
  AUROC: 0.9962

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.697
Model:                            OLS   Adj. R-squared:                  0.695
Method:                 Least Squares   F-statistic:                     324.3
Date:                Wed, 24 Sep 2025   Prob (F-statistic):          3.00e-109
Time:                        16:14:48   Log-Likelihood:                 73.775
No. Observations:                 427   AIC:                            -139.5
Df Residuals:                     423   BIC:                            -123.3
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.5283      0.064     -8.257      0.000      -0.654      -0.403
p1                    0.6511      0.071      9.207      0.000       0.512       0.790
answer_changed        0.3309      0.096      3.463      0.001       0.143       0.519
p1:answer_changed     0.3625      0.111      3.274      0.001       0.145       0.580
==============================================================================
Omnibus:                       44.331   Durbin-Watson:                   1.970
Prob(Omnibus):                  0.000   Jarque-Bera (JB):              213.299
Skew:                           0.250   Prob(JB):                     4.82e-47
Kurtosis:                       6.426   Cond. No.                         22.9
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-4.53, p=8.58e-06
Wilcoxon delta_H: statistic=13930.00, p=7.73e-06
Mean ΔH = -0.1803  [-0.2583, -0.1024]
Paired t-test delta_H Changed: statistic=3.51, p=0.000605
Wilcoxon delta_H Changed: statistic=3726.00, p=0.00416
Mean ΔH Changed = 0.1704  [0.0751, 0.2656]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=-1.63, p=0.104
Wilcoxon (p_top2_game vs p_top2_base): statistic=33985.00, p=3.25e-06
Mean Δp_top2 = -0.0064  [-0.0142, 0.0013] (n=429)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=-1.91, p=0.0574
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=40099.00, p=0.0345
Mean ΔH_unchosen_baseline_set = -0.0610  [-0.1237, 0.0018] (n=429)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  429
Model:                          Logit   Df Residuals:                      426
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.03581
Time:                        16:14:48   Log-Likelihood:                -265.25
converged:                       True   LL-Null:                       -275.10
Covariance Type:            nonrobust   LLR p-value:                 5.269e-05
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.5008      0.157     -3.180      0.001      -0.809      -0.192
p1_z            -0.6364      0.175     -3.644      0.000      -0.979      -0.294
I(p1_z ** 2)    -0.1901      0.123     -1.547      0.122      -0.431       0.051
================================================================================
AUC = 0.618

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.05925
Time:                        16:14:48   Log-Likelihood:                -291.21
converged:                       True   LL-Null:                       -309.55
Covariance Type:            nonrobust   LLR p-value:                 1.393e-09
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.4455      0.155     -9.337      0.000      -1.749      -1.142
game_entropy     1.0921      0.185      5.917      0.000       0.730       1.454
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=46844.50, p=0.00122
Paired t-test (game_entropy vs capabilities_entropy): statistic=2.55, p=0.0111
Mean game_entropy-capabilities_entropy = 0.0741  [0.0171, 0.1310] (n=500)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      497
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.07946
Time:                        16:14:48   Log-Likelihood:                -284.95
converged:                       True   LL-Null:                       -309.55
Covariance Type:            nonrobust   LLR p-value:                 2.079e-11
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.6596      0.171     -9.706      0.000      -1.995      -1.324
capabilities_entropy     0.6353      0.179      3.555      0.000       0.285       0.986
game_entropy             0.9076      0.192      4.718      0.000       0.531       1.285
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.786667
                        1                 0.213333
Geography               0                 0.613636
                        1                 0.386364
Misc                    0                 0.675676
                        1                 0.324324
Music                   0                 0.700000
                        1                 0.300000
Other                   0                 0.730769
                        1                 0.269231
Politics                0                 0.649351
                        1                 0.350649
Science and technology  0                 0.663265
                        1                 0.336735
Sports                  0                 0.700000
                        1                 0.300000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.668639
                     1                 0.331361
Number               0                 0.551282
                     1                 0.448718
Other                0                 0.714286
                     1                 0.285714
Person               0                 0.783333
                     1                 0.216667
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.714286  0.285714           21
                       Number               0.555556  0.444444            9
                       Other                0.833333  0.166667           18
                       Person               0.888889  0.111111           27
Geography              Date                 0.733333  0.266667           15
                       Number               0.555556  0.444444           18
                       Other                0.545455  0.454545           11
Misc                   Date                 0.652174  0.347826           23
                       Number               0.777778  0.222222            9
                       Other                0.629630  0.370370           27
                       Person               0.733333  0.266667           15
Music                  Date                 0.750000  0.250000           12
                       Number               0.000000  1.000000            4
                       Other                0.666667  0.333333           12
                       Person               0.916667  0.083333           12
Other                  Date                 0.611111  0.388889           18
                       Number               0.714286  0.285714            7
                       Other                0.714286  0.285714           14
                       Person               0.923077  0.076923           13
Politics               Date                 0.611111  0.388889           36
                       Number               0.333333  0.666667            6
                       Other                0.850000  0.150000           20
                       Person               0.600000  0.400000           15
Science and technology Date                 0.685714  0.314286           35
                       Number               0.428571  0.571429           14
                       Other                0.684211  0.315789           19
                       Person               0.733333  0.266667           30
Sports                 Date                 0.666667  0.333333            9
                       Number               0.727273  0.272727           11
                       Other                0.750000  0.250000           12
                       Person               0.625000  0.375000            8

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      488
Method:                           MLE   Df Model:                           11
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.02890
Time:                        16:14:48   Log-Likelihood:                -300.61
converged:                       True   LL-Null:                       -309.55
Covariance Type:            nonrobust   LLR p-value:                   0.08416
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -0.0336      1.234     -0.027      0.978      -2.451       2.384
C(topic_grouped)[T.Geography]                  0.5090      0.434      1.173      0.241      -0.341       1.359
C(topic_grouped)[T.Misc]                       0.5369      0.382      1.406      0.160      -0.211       1.285
C(topic_grouped)[T.Music]                      0.4520      0.451      1.002      0.317      -0.432       1.336
C(topic_grouped)[T.Other]                      0.2458      0.427      0.575      0.565      -0.591       1.083
C(topic_grouped)[T.Politics]                   0.7084      0.381      1.859      0.063      -0.038       1.455
C(topic_grouped)[T.Science and technology]     0.6168      0.360      1.715      0.086      -0.088       1.322
C(topic_grouped)[T.Sports]                     0.3132      0.454      0.690      0.490      -0.577       1.204
C(answer_type_grouped)[T.Number]               0.5448      0.290      1.876      0.061      -0.024       1.114
C(answer_type_grouped)[T.Other]               -0.2067      0.256     -0.808      0.419      -0.708       0.295
C(answer_type_grouped)[T.Person]              -0.5530      0.282     -1.960      0.050      -1.106   -2.31e-05
q_length                                      -0.2519      0.266     -0.949      0.343      -0.772       0.269
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.4631
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      487
Method:                           MLE   Df Model:                           12
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.06269
Time:                        16:14:48   Log-Likelihood:                -290.15
converged:                       True   LL-Null:                       -309.55
Covariance Type:            nonrobust   LLR p-value:                 0.0001131
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.1840      1.287     -0.920      0.358      -3.707       1.339
C(topic_grouped)[T.Geography]                  0.3673      0.445      0.824      0.410      -0.506       1.240
C(topic_grouped)[T.Misc]                       0.4350      0.392      1.111      0.267      -0.332       1.202
C(topic_grouped)[T.Music]                      0.5239      0.464      1.128      0.259      -0.386       1.434
C(topic_grouped)[T.Other]                      0.2366      0.435      0.544      0.586      -0.616       1.089
C(topic_grouped)[T.Politics]                   0.6132      0.389      1.578      0.115      -0.149       1.375
C(topic_grouped)[T.Science and technology]     0.5021      0.368      1.364      0.173      -0.220       1.224
C(topic_grouped)[T.Sports]                     0.3271      0.461      0.710      0.478      -0.576       1.230
C(answer_type_grouped)[T.Number]               0.5220      0.299      1.748      0.080      -0.063       1.107
C(answer_type_grouped)[T.Other]               -0.0877      0.263     -0.333      0.739      -0.603       0.428
C(answer_type_grouped)[T.Person]              -0.4638      0.288     -1.609      0.108      -1.029       0.101
q_length                                      -0.0838      0.274     -0.306      0.760      -0.621       0.453
capabilities_entropy                           0.7987      0.176      4.543      0.000       0.454       1.143
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      487
Method:                           MLE   Df Model:                           12
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.08196
Time:                        16:14:48   Log-Likelihood:                -284.18
converged:                       True   LL-Null:                       -309.55
Covariance Type:            nonrobust   LLR p-value:                 1.035e-06
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -0.7522      1.285     -0.585      0.558      -3.270       1.766
C(topic_grouped)[T.Geography]                  0.4487      0.450      0.998      0.318      -0.433       1.330
C(topic_grouped)[T.Misc]                       0.4913      0.394      1.246      0.213      -0.281       1.264
C(topic_grouped)[T.Music]                      0.4351      0.468      0.930      0.353      -0.482       1.353
C(topic_grouped)[T.Other]                      0.2716      0.439      0.619      0.536      -0.589       1.132
C(topic_grouped)[T.Politics]                   0.6738      0.394      1.708      0.088      -0.099       1.447
C(topic_grouped)[T.Science and technology]     0.6119      0.371      1.648      0.099      -0.116       1.340
C(topic_grouped)[T.Sports]                     0.2713      0.471      0.575      0.565      -0.653       1.195
C(answer_type_grouped)[T.Number]               0.7196      0.305      2.361      0.018       0.122       1.317
C(answer_type_grouped)[T.Other]                0.0205      0.269      0.076      0.939      -0.506       0.547
C(answer_type_grouped)[T.Person]              -0.3096      0.295     -1.049      0.294      -0.888       0.269
q_length                                      -0.2599      0.274     -0.947      0.343      -0.797       0.278
game_entropy                                   1.0690      0.190      5.612      0.000       0.696       1.442
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      486
Method:                           MLE   Df Model:                           13
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.09744
Time:                        16:14:48   Log-Likelihood:                -279.39
converged:                       True   LL-Null:                       -309.55
Covariance Type:            nonrobust   LLR p-value:                 4.591e-08
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.4742      1.321     -1.116      0.265      -4.064       1.116
C(topic_grouped)[T.Geography]                  0.3709      0.456      0.814      0.416      -0.522       1.264
C(topic_grouped)[T.Misc]                       0.4286      0.401      1.069      0.285      -0.357       1.214
C(topic_grouped)[T.Music]                      0.5009      0.474      1.057      0.290      -0.428       1.429
C(topic_grouped)[T.Other]                      0.2747      0.444      0.619      0.536      -0.596       1.145
C(topic_grouped)[T.Politics]                   0.6162      0.400      1.542      0.123      -0.167       1.399
C(topic_grouped)[T.Science and technology]     0.5369      0.377      1.425      0.154      -0.201       1.275
C(topic_grouped)[T.Sports]                     0.3117      0.472      0.660      0.509      -0.613       1.237
C(answer_type_grouped)[T.Number]               0.6782      0.309      2.198      0.028       0.074       1.283
C(answer_type_grouped)[T.Other]                0.0865      0.273      0.317      0.751      -0.449       0.621
C(answer_type_grouped)[T.Person]              -0.2706      0.299     -0.905      0.365      -0.856       0.315
q_length                                      -0.1410      0.280     -0.504      0.614      -0.689       0.407
capabilities_entropy                           0.5759      0.185      3.107      0.002       0.213       0.939
game_entropy                                   0.9093      0.198      4.592      0.000       0.521       1.297
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.
