
--- Analyzing claude-3-5-sonnet-20241022 (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_new/claude-3-5-sonnet-20241022_SimpleMC_redacted_cor_temp0.0_1753745296_game_data.json', './sc_logs_new/claude-3-5-sonnet-20241022_SimpleMC_redacted_temp0.0_1753644934_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    363
1    137
Name: count, dtype: int64

Answer change%: 0.2740 [0.23490630857931788, 0.31309369142068216] (n=500)
P-value vs 25%: 0.2289; P-value vs 0%: 6.095e-43
Phase 2 self-accuracy: 0.3504 [0.2704767218707924, 0.4302532051365069] (n=137)
P-value vs 25%: 0.0138; P-value vs 33%: 0.6701

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.1404
Time:                        20:27:17   Log-Likelihood:                -252.37
converged:                       True   LL-Null:                       -293.60
Covariance Type:            nonrobust   LLR p-value:                 1.075e-19
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          2.0242      0.355      5.700      0.000       1.328       2.720
p_i_capability    -4.4567      0.534     -8.350      0.000      -5.503      -3.411
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.1578
Time:                        20:27:17   Log-Likelihood:                -247.27
converged:                       True   LL-Null:                       -293.60
Covariance Type:            nonrobust   LLR p-value:                 6.229e-22
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -3.1118      0.298    -10.439      0.000      -3.696      -2.528
capabilities_entropy     1.8400      0.215      8.561      0.000       1.419       2.261
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.6715 [0.5929, 0.7502] (n=137)
                  P-value vs 33.3%: 3.499e-17

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=7.65, p=1.86e-13
Wilcoxon delta_p: statistic=12157.50, p=1.06e-12
Mean Δp = 0.0674  [0.0501, 0.0846]
Idea 1 N = 363; 

  Idea 1.5: Calibration Metrics
  NLL: 1.0679, Signed ECE (overconf pos under neg): -0.0626, ECE: 0.1490 (n=500)
  Brier: 0.0648, Reliability (absolute calibration error; lower better): 0.0387, Resolution (relative calibration quality; higher better): 0.2126, Uncertainty: 0.2400 (n=500)
  AUROC: 0.9968

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.528
Model:                            OLS   Adj. R-squared:                  0.525
Method:                 Least Squares   F-statistic:                     185.0
Date:                Fri, 19 Sep 2025   Prob (F-statistic):           1.74e-80
Time:                        20:27:17   Log-Likelihood:                 253.84
No. Observations:                 500   AIC:                            -499.7
Df Residuals:                     496   BIC:                            -482.8
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.1292      0.030     -4.349      0.000      -0.188      -0.071
p1                    0.2551      0.037      6.850      0.000       0.182       0.328
answer_changed       -0.0638      0.051     -1.240      0.216      -0.165       0.037
p1:answer_changed     0.6640      0.079      8.394      0.000       0.509       0.819
==============================================================================
Omnibus:                       14.973   Durbin-Watson:                   2.002
Prob(Omnibus):                  0.001   Jarque-Bera (JB):               15.534
Skew:                           0.426   Prob(JB):                     0.000423
Kurtosis:                       3.143   Cond. No.                         19.0
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-0.63, p=0.532
Wilcoxon delta_H: statistic=22156.50, p=0.391
Mean ΔH = -0.0119  [-0.0490, 0.0253]
Paired t-test delta_H Changed: statistic=3.66, p=0.000364
Wilcoxon delta_H Changed: statistic=3052.00, p=0.000321
Mean ΔH Changed = 0.1080  [0.0501, 0.1659]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=-8.60, p=1.01e-16
Wilcoxon (p_top2_game vs p_top2_base): statistic=27058.00, p=2.36e-16
Mean Δp_top2 = -0.0387  [-0.0475, -0.0299] (n=500)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=1.30, p=0.194
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=45919.50, p=0.228
Mean ΔH_unchosen_baseline_set = 0.0210  [-0.0106, 0.0526] (n=500)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      497
Method:                           MLE   Df Model:                            2
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.1572
Time:                        20:27:17   Log-Likelihood:                -247.44
converged:                       True   LL-Null:                       -293.60
Covariance Type:            nonrobust   LLR p-value:                 8.985e-21
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.8227      0.161     -5.097      0.000      -1.139      -0.506
p1_z            -1.2227      0.154     -7.956      0.000      -1.524      -0.921
I(p1_z ** 2)    -0.4441      0.143     -3.102      0.002      -0.725      -0.163
================================================================================
AUC = 0.760

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.1522
Time:                        20:27:17   Log-Likelihood:                -248.92
converged:                       True   LL-Null:                       -293.60
Covariance Type:            nonrobust   LLR p-value:                 3.303e-21
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -3.7267      0.404     -9.215      0.000      -4.519      -2.934
game_entropy     2.0155      0.259      7.787      0.000       1.508       2.523
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=25348.50, p=9.88e-19
Paired t-test (game_entropy vs capabilities_entropy): statistic=9.42, p=1.7e-19
Mean capabilities_entropy-game_entropy = -0.1853  [-0.2239, -0.1468] (n=500)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      497
Method:                           MLE   Df Model:                            2
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.1837
Time:                        20:27:17   Log-Likelihood:                -239.66
converged:                       True   LL-Null:                       -293.60
Covariance Type:            nonrobust   LLR p-value:                 3.743e-24
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -3.9274      0.408     -9.628      0.000      -4.727      -3.128
capabilities_entropy     1.1413      0.274      4.167      0.000       0.604       1.678
game_entropy             1.1869      0.317      3.746      0.000       0.566       1.808
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.800000
                        1                 0.200000
Geography               0                 0.659091
                        1                 0.340909
Misc                    0                 0.837838
                        1                 0.162162
Music                   0                 0.725000
                        1                 0.275000
Other                   0                 0.615385
                        1                 0.384615
Politics                0                 0.753247
                        1                 0.246753
Science and technology  0                 0.663265
                        1                 0.336735
Sports                  0                 0.700000
                        1                 0.300000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.633136
                     1                 0.366864
Number               0                 0.692308
                     1                 0.307692
Other                0                 0.774436
                     1                 0.225564
Person               0                 0.825000
                     1                 0.175000
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.666667  0.333333           21
                       Number               0.666667  0.333333            9
                       Other                0.944444  0.055556           18
                       Person               0.851852  0.148148           27
Geography              Date                 0.533333  0.466667           15
                       Number               0.777778  0.222222           18
                       Other                0.636364  0.363636           11
Misc                   Date                 0.739130  0.260870           23
                       Number               0.666667  0.333333            9
                       Other                0.925926  0.074074           27
                       Person               0.933333  0.066667           15
Music                  Date                 0.583333  0.416667           12
                       Number               0.750000  0.250000            4
                       Other                0.666667  0.333333           12
                       Person               0.916667  0.083333           12
Other                  Date                 0.555556  0.444444           18
                       Number               0.714286  0.285714            7
                       Other                0.714286  0.285714           14
                       Person               0.538462  0.461538           13
Politics               Date                 0.722222  0.277778           36
                       Number               0.500000  0.500000            6
                       Other                0.750000  0.250000           20
                       Person               0.933333  0.066667           15
Science and technology Date                 0.571429  0.428571           35
                       Number               0.571429  0.428571           14
                       Other                0.684211  0.315789           19
                       Person               0.800000  0.200000           30
Sports                 Date                 0.555556  0.444444            9
                       Number               0.818182  0.181818           11
                       Other                0.666667  0.333333           12
                       Person               0.750000  0.250000            8

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      488
Method:                           MLE   Df Model:                           11
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.05155
Time:                        20:27:17   Log-Likelihood:                -278.46
converged:                       True   LL-Null:                       -293.60
Covariance Type:            nonrobust   LLR p-value:                  0.001438
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -2.6737      1.293     -2.068      0.039      -5.207      -0.140
C(topic_grouped)[T.Geography]                  0.5291      0.446      1.187      0.235      -0.345       1.403
C(topic_grouped)[T.Misc]                      -0.3447      0.435     -0.792      0.428      -1.197       0.508
C(topic_grouped)[T.Music]                      0.4219      0.465      0.907      0.365      -0.490       1.334
C(topic_grouped)[T.Other]                      0.8747      0.413      2.116      0.034       0.064       1.685
C(topic_grouped)[T.Politics]                   0.0076      0.408      0.019      0.985      -0.791       0.806
C(topic_grouped)[T.Science and technology]     0.6141      0.367      1.674      0.094      -0.105       1.333
C(topic_grouped)[T.Sports]                     0.4888      0.460      1.062      0.288      -0.413       1.391
C(answer_type_grouped)[T.Number]              -0.3647      0.307     -1.188      0.235      -0.966       0.237
C(answer_type_grouped)[T.Other]               -0.6377      0.268     -2.379      0.017      -1.163      -0.112
C(answer_type_grouped)[T.Person]              -0.9987      0.298     -3.354      0.001      -1.582      -0.415
q_length                                       0.4008      0.278      1.444      0.149      -0.143       0.945
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 1.0251
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      487
Method:                           MLE   Df Model:                           12
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.1926
Time:                        20:27:17   Log-Likelihood:                -237.05
converged:                       True   LL-Null:                       -293.60
Covariance Type:            nonrobust   LLR p-value:                 1.455e-18
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -5.0660      1.495     -3.390      0.001      -7.995      -2.137
C(topic_grouped)[T.Geography]                  0.3613      0.485      0.744      0.457      -0.590       1.313
C(topic_grouped)[T.Misc]                      -0.3393      0.469     -0.723      0.470      -1.259       0.581
C(topic_grouped)[T.Music]                      0.3157      0.507      0.623      0.533      -0.678       1.309
C(topic_grouped)[T.Other]                      1.0175      0.462      2.202      0.028       0.112       1.923
C(topic_grouped)[T.Politics]                   0.2626      0.443      0.593      0.553      -0.606       1.131
C(topic_grouped)[T.Science and technology]     0.6895      0.402      1.717      0.086      -0.098       1.477
C(topic_grouped)[T.Sports]                     0.5743      0.510      1.125      0.260      -0.426       1.574
C(answer_type_grouped)[T.Number]              -0.4894      0.332     -1.476      0.140      -1.139       0.161
C(answer_type_grouped)[T.Other]               -0.4309      0.298     -1.446      0.148      -1.015       0.153
C(answer_type_grouped)[T.Person]              -0.7386      0.329     -2.244      0.025      -1.384      -0.093
q_length                                       0.4315      0.309      1.394      0.163      -0.175       1.038
capabilities_entropy                           1.8176      0.223      8.154      0.000       1.381       2.254
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      487
Method:                           MLE   Df Model:                           12
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.1909
Time:                        20:27:17   Log-Likelihood:                -237.56
converged:                       True   LL-Null:                       -293.60
Covariance Type:            nonrobust   LLR p-value:                 2.319e-18
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -7.2052      1.581     -4.556      0.000     -10.305      -4.106
C(topic_grouped)[T.Geography]                  0.5360      0.481      1.115      0.265      -0.406       1.478
C(topic_grouped)[T.Misc]                      -0.4789      0.464     -1.033      0.302      -1.388       0.430
C(topic_grouped)[T.Music]                      0.1398      0.499      0.280      0.779      -0.837       1.117
C(topic_grouped)[T.Other]                      0.7922      0.449      1.764      0.078      -0.088       1.672
C(topic_grouped)[T.Politics]                   0.1782      0.438      0.407      0.684      -0.680       1.036
C(topic_grouped)[T.Science and technology]     0.7465      0.401      1.860      0.063      -0.040       1.533
C(topic_grouped)[T.Sports]                     0.4849      0.497      0.976      0.329      -0.489       1.458
C(answer_type_grouped)[T.Number]              -0.6782      0.330     -2.054      0.040      -1.325      -0.031
C(answer_type_grouped)[T.Other]               -0.2418      0.296     -0.817      0.414      -0.822       0.338
C(answer_type_grouped)[T.Person]              -0.4849      0.333     -1.457      0.145      -1.137       0.168
q_length                                       0.7307      0.315      2.318      0.020       0.113       1.349
game_entropy                                   2.1014      0.277      7.596      0.000       1.559       2.644
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      486
Method:                           MLE   Df Model:                           13
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.2190
Time:                        20:27:17   Log-Likelihood:                -229.31
converged:                       True   LL-Null:                       -293.60
Covariance Type:            nonrobust   LLR p-value:                 4.027e-21
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -6.8561      1.617     -4.241      0.000     -10.024      -3.688
C(topic_grouped)[T.Geography]                  0.4160      0.490      0.849      0.396      -0.545       1.377
C(topic_grouped)[T.Misc]                      -0.4518      0.473     -0.956      0.339      -1.378       0.475
C(topic_grouped)[T.Music]                      0.1658      0.511      0.325      0.745      -0.835       1.167
C(topic_grouped)[T.Other]                      0.8975      0.464      1.932      0.053      -0.013       1.808
C(topic_grouped)[T.Politics]                   0.2809      0.448      0.627      0.531      -0.597       1.159
C(topic_grouped)[T.Science and technology]     0.7098      0.408      1.738      0.082      -0.091       1.510
C(topic_grouped)[T.Sports]                     0.5197      0.511      1.016      0.310      -0.483       1.522
C(answer_type_grouped)[T.Number]              -0.6495      0.337     -1.929      0.054      -1.309       0.010
C(answer_type_grouped)[T.Other]               -0.2667      0.304     -0.876      0.381      -0.863       0.330
C(answer_type_grouped)[T.Person]              -0.5490      0.341     -1.611      0.107      -1.217       0.119
q_length                                       0.6150      0.323      1.905      0.057      -0.018       1.248
capabilities_entropy                           1.1089      0.281      3.943      0.000       0.558       1.660
game_entropy                                   1.2811      0.338      3.787      0.000       0.618       1.944
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing claude-3-haiku-20240307 (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_new/claude-3-haiku-20240307_SimpleMC_redacted_cor_temp0.0_1754173427_game_data.json', './sc_logs_new/claude-3-haiku-20240307_SimpleMC_redacted_temp0.0_1754183680_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    377
1    123
Name: count, dtype: int64

Answer change%: 0.2460 [0.20825005568487207, 0.2837499443151279] (n=500)
P-value vs 25%: 0.8355; P-value vs 0%: 2.343e-37
Phase 2 self-accuracy: 0.2846 [0.20481476406627758, 0.364290926990633] (n=123)
P-value vs 25%: 0.3957; P-value vs 33%: 0.2337

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.03772
Time:                        20:27:17   Log-Likelihood:                -268.43
converged:                       True   LL-Null:                       -278.95
Covariance Type:            nonrobust   LLR p-value:                 4.489e-06
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          1.9248      0.661      2.914      0.004       0.630       3.220
p_i_capability    -3.4164      0.738     -4.629      0.000      -4.863      -1.970
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.04029
Time:                        20:27:17   Log-Likelihood:                -267.71
converged:                       True   LL-Null:                       -278.95
Covariance Type:            nonrobust   LLR p-value:                 2.124e-06
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.8785      0.197     -9.546      0.000      -2.264      -1.493
capabilities_entropy     1.6194      0.340      4.757      0.000       0.952       2.287
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.3089 [0.2273, 0.3906] (n=123)
                  P-value vs 33.3%: 0.5583

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=0.38, p=0.707
Wilcoxon delta_p: statistic=6230.50, p=0.315
Mean Δp = 0.0026  [-0.0110, 0.0163]
Idea 1 N = 377; 

  Idea 1.5: Calibration Metrics
  NLL: 2.9673, Signed ECE (overconf pos under neg): -0.0037, ECE: 0.0373 (n=500)
  Brier: 0.0164, Reliability (absolute calibration error; lower better): 0.0039, Resolution (relative calibration quality; higher better): 0.1977, Uncertainty: 0.2108 (n=500)
  AUROC: 0.9988

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.892
Model:                            OLS   Adj. R-squared:                  0.891
Method:                 Least Squares   F-statistic:                     1366.
Date:                Fri, 19 Sep 2025   Prob (F-statistic):          3.22e-239
Time:                        20:27:17   Log-Likelihood:                 373.90
No. Observations:                 500   AIC:                            -739.8
Df Residuals:                     496   BIC:                            -722.9
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.7873      0.053    -14.849      0.000      -0.892      -0.683
p1                    0.8600      0.057     14.992      0.000       0.747       0.973
answer_changed        0.6892      0.075      9.238      0.000       0.543       0.836
p1:answer_changed     0.0989      0.083      1.189      0.235      -0.065       0.262
==============================================================================
Omnibus:                       77.306   Durbin-Watson:                   2.026
Prob(Omnibus):                  0.000   Jarque-Bera (JB):              151.654
Skew:                           0.873   Prob(JB):                     1.17e-33
Kurtosis:                       5.057   Cond. No.                         34.4
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=0.06, p=0.949
Wilcoxon delta_H: statistic=6825.00, p=0.971
Mean ΔH = 0.0021  [-0.0621, 0.0663]
Paired t-test delta_H Changed: statistic=14.49, p=2.74e-28
Wilcoxon delta_H Changed: statistic=382.00, p=4.32e-18
Mean ΔH Changed = 0.8614  [0.7448, 0.9779]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=-0.68, p=0.498
Wilcoxon (p_top2_game vs p_top2_base): statistic=16754.00, p=0.7
Mean Δp_top2 = -0.0013  [-0.0051, 0.0025] (n=500)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=6.45, p=2.71e-10
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=12081.00, p=6.82e-10
Mean ΔH_unchosen_baseline_set = 0.2135  [0.1486, 0.2784] (n=500)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      497
Method:                           MLE   Df Model:                            2
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.04131
Time:                        20:27:17   Log-Likelihood:                -267.43
converged:                       True   LL-Null:                       -278.95
Covariance Type:            nonrobust   LLR p-value:                 9.896e-06
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.3202      0.160     -8.245      0.000      -1.634      -1.006
p1_z            -0.0537      0.292     -0.184      0.854      -0.625       0.518
I(p1_z ** 2)     0.1657      0.121      1.365      0.172      -0.072       0.404
================================================================================
AUC = 0.589

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.1281
Time:                        20:27:17   Log-Likelihood:                -243.23
converged:                       True   LL-Null:                       -278.95
Covariance Type:            nonrobust   LLR p-value:                 2.848e-17
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -2.5657      0.221    -11.595      0.000      -2.999      -2.132
game_entropy     2.6928      0.339      7.942      0.000       2.028       3.357
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=13551.50, p=0.00276
Paired t-test (game_entropy vs capabilities_entropy): statistic=2.81, p=0.00521
Mean capabilities_entropy-game_entropy = -0.0476  [-0.0809, -0.0144] (n=500)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      497
Method:                           MLE   Df Model:                            2
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.1508
Time:                        20:27:17   Log-Likelihood:                -236.89
converged:                       True   LL-Null:                       -278.95
Covariance Type:            nonrobust   LLR p-value:                 5.413e-19
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -3.1184      0.282    -11.052      0.000      -3.671      -2.565
capabilities_entropy     1.3216      0.366      3.615      0.000       0.605       2.038
game_entropy             2.5651      0.345      7.442      0.000       1.890       3.241
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.746667
                        1                 0.253333
Geography               0                 0.590909
                        1                 0.409091
Misc                    0                 0.770270
                        1                 0.229730
Music                   0                 0.775000
                        1                 0.225000
Other                   0                 0.711538
                        1                 0.288462
Politics                0                 0.857143
                        1                 0.142857
Science and technology  0                 0.775510
                        1                 0.224490
Sports                  0                 0.700000
                        1                 0.300000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.733728
                     1                 0.266272
Number               0                 0.743590
                     1                 0.256410
Other                0                 0.789474
                     1                 0.210526
Person               0                 0.750000
                     1                 0.250000
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.714286  0.285714           21
                       Number               0.444444  0.555556            9
                       Other                0.722222  0.277778           18
                       Person               0.888889  0.111111           27
Geography              Date                 0.533333  0.466667           15
                       Number               0.611111  0.388889           18
                       Other                0.636364  0.363636           11
Misc                   Date                 0.652174  0.347826           23
                       Number               1.000000  0.000000            9
                       Other                0.777778  0.222222           27
                       Person               0.800000  0.200000           15
Music                  Date                 0.583333  0.416667           12
                       Number               1.000000  0.000000            4
                       Other                0.833333  0.166667           12
                       Person               0.833333  0.166667           12
Other                  Date                 0.777778  0.222222           18
                       Number               0.857143  0.142857            7
                       Other                0.571429  0.428571           14
                       Person               0.692308  0.307692           13
Politics               Date                 0.888889  0.111111           36
                       Number               0.666667  0.333333            6
                       Other                0.950000  0.050000           20
                       Person               0.733333  0.266667           15
Science and technology Date                 0.800000  0.200000           35
                       Number               0.785714  0.214286           14
                       Other                0.947368  0.052632           19
                       Person               0.633333  0.366667           30
Sports                 Date                 0.555556  0.444444            9
                       Number               0.818182  0.181818           11
                       Other                0.750000  0.250000           12
                       Person               0.625000  0.375000            8

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      488
Method:                           MLE   Df Model:                           11
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.02634
Time:                        20:27:17   Log-Likelihood:                -271.60
converged:                       True   LL-Null:                       -278.95
Covariance Type:            nonrobust   LLR p-value:                    0.1969
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -0.1796      1.343     -0.134      0.894      -2.812       2.453
C(topic_grouped)[T.Geography]                  0.7768      0.424      1.833      0.067      -0.054       1.607
C(topic_grouped)[T.Misc]                      -0.0895      0.387     -0.232      0.817      -0.847       0.668
C(topic_grouped)[T.Music]                     -0.1529      0.464     -0.330      0.742      -1.062       0.756
C(topic_grouped)[T.Other]                      0.1826      0.407      0.448      0.654      -0.616       0.981
C(topic_grouped)[T.Politics]                  -0.6931      0.428     -1.619      0.105      -1.532       0.146
C(topic_grouped)[T.Science and technology]    -0.1600      0.361     -0.443      0.658      -0.868       0.548
C(topic_grouped)[T.Sports]                     0.2934      0.440      0.666      0.505      -0.570       1.157
C(answer_type_grouped)[T.Number]              -0.2889      0.328     -0.881      0.378      -0.932       0.354
C(answer_type_grouped)[T.Other]               -0.3761      0.282     -1.334      0.182      -0.928       0.176
C(answer_type_grouped)[T.Person]              -0.0649      0.282     -0.230      0.818      -0.618       0.489
q_length                                      -0.1699      0.291     -0.585      0.559      -0.739       0.400
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.4423
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      487
Method:                           MLE   Df Model:                           12
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.06478
Time:                        20:27:17   Log-Likelihood:                -260.88
converged:                       True   LL-Null:                       -278.95
Covariance Type:            nonrobust   LLR p-value:                 0.0003074
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.2568      1.413     -0.890      0.374      -4.026       1.512
C(topic_grouped)[T.Geography]                  0.8092      0.436      1.857      0.063      -0.045       1.663
C(topic_grouped)[T.Misc]                      -0.0882      0.396     -0.223      0.823      -0.863       0.687
C(topic_grouped)[T.Music]                     -0.2533      0.483     -0.524      0.600      -1.200       0.694
C(topic_grouped)[T.Other]                      0.1485      0.417      0.356      0.722      -0.670       0.967
C(topic_grouped)[T.Politics]                  -0.6905      0.438     -1.577      0.115      -1.548       0.167
C(topic_grouped)[T.Science and technology]    -0.1961      0.370     -0.530      0.596      -0.921       0.529
C(topic_grouped)[T.Sports]                     0.1862      0.452      0.412      0.681      -0.700       1.073
C(answer_type_grouped)[T.Number]              -0.2755      0.338     -0.816      0.415      -0.937       0.387
C(answer_type_grouped)[T.Other]               -0.3534      0.290     -1.220      0.223      -0.921       0.215
C(answer_type_grouped)[T.Person]               0.0432      0.291      0.149      0.882      -0.526       0.613
q_length                                      -0.1018      0.302     -0.338      0.736      -0.693       0.489
capabilities_entropy                           1.6226      0.351      4.621      0.000       0.934       2.311
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      487
Method:                           MLE   Df Model:                           12
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.1572
Time:                        20:27:17   Log-Likelihood:                -235.09
converged:                       True   LL-Null:                       -278.95
Covariance Type:            nonrobust   LLR p-value:                 1.366e-13
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -2.3338      1.507     -1.549      0.121      -5.287       0.620
C(topic_grouped)[T.Geography]                  0.9271      0.461      2.011      0.044       0.024       1.830
C(topic_grouped)[T.Misc]                      -0.1487      0.423     -0.351      0.725      -0.979       0.681
C(topic_grouped)[T.Music]                     -0.1498      0.513     -0.292      0.770      -1.156       0.856
C(topic_grouped)[T.Other]                      0.2230      0.446      0.500      0.617      -0.652       1.098
C(topic_grouped)[T.Politics]                  -0.8747      0.466     -1.876      0.061      -1.789       0.039
C(topic_grouped)[T.Science and technology]    -0.0940      0.388     -0.242      0.809      -0.855       0.667
C(topic_grouped)[T.Sports]                     0.0029      0.492      0.006      0.995      -0.962       0.968
C(answer_type_grouped)[T.Number]              -0.3819      0.357     -1.069      0.285      -1.082       0.318
C(answer_type_grouped)[T.Other]               -0.4813      0.310     -1.552      0.121      -1.089       0.126
C(answer_type_grouped)[T.Person]              -0.1283      0.309     -0.415      0.678      -0.734       0.477
q_length                                      -0.0110      0.321     -0.034      0.973      -0.641       0.619
game_entropy                                   2.8221      0.356      7.932      0.000       2.125       3.519
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      486
Method:                           MLE   Df Model:                           13
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.1790
Time:                        20:27:17   Log-Likelihood:                -229.01
converged:                       True   LL-Null:                       -278.95
Covariance Type:            nonrobust   LLR p-value:                 1.756e-15
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -3.0330      1.551     -1.955      0.051      -6.073       0.007
C(topic_grouped)[T.Geography]                  0.9304      0.466      1.996      0.046       0.017       1.844
C(topic_grouped)[T.Misc]                      -0.1645      0.432     -0.381      0.703      -1.010       0.681
C(topic_grouped)[T.Music]                     -0.2377      0.527     -0.451      0.652      -1.271       0.796
C(topic_grouped)[T.Other]                      0.1795      0.450      0.399      0.690      -0.702       1.061
C(topic_grouped)[T.Politics]                  -0.8876      0.471     -1.883      0.060      -1.812       0.036
C(topic_grouped)[T.Science and technology]    -0.1252      0.392     -0.319      0.750      -0.894       0.644
C(topic_grouped)[T.Sports]                    -0.0809      0.498     -0.162      0.871      -1.057       0.895
C(answer_type_grouped)[T.Number]              -0.3773      0.362     -1.041      0.298      -1.087       0.333
C(answer_type_grouped)[T.Other]               -0.4725      0.314     -1.507      0.132      -1.087       0.142
C(answer_type_grouped)[T.Person]              -0.0590      0.317     -0.186      0.852      -0.680       0.562
q_length                                       0.0214      0.328      0.065      0.948      -0.622       0.665
capabilities_entropy                           1.3273      0.377      3.520      0.000       0.588       2.066
game_entropy                                   2.7070      0.362      7.468      0.000       1.997       3.417
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing claude-3-sonnet-20240229 (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_new/claude-3-sonnet-20240229_SimpleMC_redacted_cor_temp0.0_1751757346_game_data.json', './sc_logs_new/claude-3-sonnet-20240229_SimpleMC_redacted_temp0.0_1751717606_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    308
1    192
Name: count, dtype: int64

Answer change%: 0.3840 [0.34136963440733187, 0.42663036559266815] (n=500)
P-value vs 25%: 7.24e-10; P-value vs 0%: 9.364e-70
Phase 2 self-accuracy: 0.2552 [0.19353998643958548, 0.31687668022708115] (n=192)
P-value vs 25%: 0.8685; P-value vs 33%: 0.01342
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.626667
                        1                 0.373333
Geography               0                 0.568182
                        1                 0.431818
Misc                    0                 0.689189
                        1                 0.310811
Music                   0                 0.825000
                        1                 0.175000
Other                   0                 0.519231
                        1                 0.480769
Politics                0                 0.558442
                        1                 0.441558
Science and technology  0                 0.622449
                        1                 0.377551
Sports                  0                 0.525000
                        1                 0.475000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.579882
                     1                 0.420118
Number               1                 0.525641
                     0                 0.474359
Other                0                 0.714286
                     1                 0.285714
Person               0                 0.650000
                     1                 0.350000
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.523810  0.476190           21
                       Number               0.555556  0.444444            9
                       Other                0.777778  0.222222           18
                       Person               0.629630  0.370370           27
Geography              Date                 0.533333  0.466667           15
                       Number               0.555556  0.444444           18
                       Other                0.636364  0.363636           11
Misc                   Date                 0.739130  0.260870           23
                       Number               0.555556  0.444444            9
                       Other                0.703704  0.296296           27
                       Person               0.666667  0.333333           15
Music                  Date                 0.750000  0.250000           12
                       Number               0.750000  0.250000            4
                       Other                0.916667  0.083333           12
                       Person               0.833333  0.166667           12
Other                  Date                 0.500000  0.500000           18
                       Number               0.285714  0.714286            7
                       Other                0.642857  0.357143           14
                       Person               0.538462  0.461538           13
Politics               Date                 0.583333  0.416667           36
                       Number               0.166667  0.833333            6
                       Other                0.700000  0.300000           20
                       Person               0.466667  0.533333           15
Science and technology Date                 0.542857  0.457143           35
                       Number               0.500000  0.500000           14
                       Other                0.789474  0.210526           19
                       Person               0.666667  0.333333           30
Sports                 Date                 0.444444  0.555556            9
                       Number               0.363636  0.636364           11
                       Other                0.500000  0.500000           12
                       Person               0.875000  0.125000            8

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      488
Method:                           MLE   Df Model:                           11
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.04057
Time:                        20:27:17   Log-Likelihood:                -319.48
converged:                       True   LL-Null:                       -332.99
Covariance Type:            nonrobust   LLR p-value:                  0.004564
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      0.1727      1.177      0.147      0.883      -2.135       2.480
C(topic_grouped)[T.Geography]                  0.0240      0.406      0.059      0.953      -0.772       0.820
C(topic_grouped)[T.Misc]                      -0.2554      0.353     -0.724      0.469      -0.947       0.436
C(topic_grouped)[T.Music]                     -1.0309      0.484     -2.129      0.033      -1.980      -0.082
C(topic_grouped)[T.Other]                      0.4291      0.372      1.155      0.248      -0.299       1.157
C(topic_grouped)[T.Politics]                   0.2999      0.342      0.876      0.381      -0.371       0.970
C(topic_grouped)[T.Science and technology]    -0.0230      0.322     -0.072      0.943      -0.653       0.607
C(topic_grouped)[T.Sports]                     0.3532      0.406      0.870      0.384      -0.442       1.148
C(answer_type_grouped)[T.Number]               0.4274      0.287      1.491      0.136      -0.134       0.989
C(answer_type_grouped)[T.Other]               -0.5813      0.253     -2.301      0.021      -1.077      -0.086
C(answer_type_grouped)[T.Person]              -0.2696      0.256     -1.054      0.292      -0.771       0.231
q_length                                      -0.1155      0.254     -0.456      0.649      -0.613       0.381
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing claude-sonnet-4-20250514 (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_new/claude-sonnet-4-20250514_SimpleMC_redacted_cor_temp0.0_1751759842_game_data.json', './sc_logs_new/claude-sonnet-4-20250514_SimpleMC_redacted_temp0.0_1751719035_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    255
1    245
Name: count, dtype: int64

Answer change%: 0.4900 [0.44618263907327455, 0.5338173609267254] (n=500)
P-value vs 25%: 6.951e-27; P-value vs 0%: 1.756e-106
Phase 2 self-accuracy: 0.3633 [0.3030431546377259, 0.4234874576071721] (n=245)
P-value vs 25%: 0.0002276; P-value vs 33%: 0.3246
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.560000
                        1                 0.440000
Geography               0                 0.522727
                        1                 0.477273
Misc                    0                 0.540541
                        1                 0.459459
Music                   0                 0.625000
                        1                 0.375000
Other                   1                 0.653846
                        0                 0.346154
Politics                1                 0.545455
                        0                 0.454545
Science and technology  0                 0.581633
                        1                 0.418367
Sports                  1                 0.625000
                        0                 0.375000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.538462
                     1                 0.461538
Number               1                 0.538462
                     0                 0.461538
Other                0                 0.518797
                     1                 0.481203
Person               1                 0.508333
                     0                 0.491667
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.666667  0.333333           21
                       Number               0.444444  0.555556            9
                       Other                0.666667  0.333333           18
                       Person               0.444444  0.555556           27
Geography              Date                 0.400000  0.600000           15
                       Number               0.555556  0.444444           18
                       Other                0.636364  0.363636           11
Misc                   Date                 0.652174  0.347826           23
                       Number               0.555556  0.444444            9
                       Other                0.481481  0.518519           27
                       Person               0.466667  0.533333           15
Music                  Date                 0.666667  0.333333           12
                       Number               0.500000  0.500000            4
                       Other                0.500000  0.500000           12
                       Person               0.750000  0.250000           12
Other                  Date                 0.277778  0.722222           18
                       Number               0.285714  0.714286            7
                       Other                0.357143  0.642857           14
                       Person               0.461538  0.538462           13
Politics               Date                 0.500000  0.500000           36
                       Number               0.000000  1.000000            6
                       Other                0.550000  0.450000           20
                       Person               0.400000  0.600000           15
Science and technology Date                 0.657143  0.342857           35
                       Number               0.571429  0.428571           14
                       Other                0.578947  0.421053           19
                       Person               0.500000  0.500000           30
Sports                 Date                 0.222222  0.777778            9
                       Number               0.454545  0.545455           11
                       Other                0.333333  0.666667           12
                       Person               0.500000  0.500000            8

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      488
Method:                           MLE   Df Model:                           11
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.02666
Time:                        20:27:17   Log-Likelihood:                -337.24
converged:                       True   LL-Null:                       -346.47
Covariance Type:            nonrobust   LLR p-value:                   0.07123
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      1.1679      1.149      1.016      0.309      -1.084       3.420
C(topic_grouped)[T.Geography]                  0.1278      0.395      0.323      0.747      -0.647       0.903
C(topic_grouped)[T.Misc]                       0.1161      0.333      0.349      0.727      -0.536       0.768
C(topic_grouped)[T.Music]                     -0.2725      0.403     -0.677      0.499      -1.062       0.517
C(topic_grouped)[T.Other]                      0.8930      0.375      2.381      0.017       0.158       1.628
C(topic_grouped)[T.Politics]                   0.5541      0.336      1.651      0.099      -0.104       1.212
C(topic_grouped)[T.Science and technology]    -0.0516      0.312     -0.165      0.869      -0.663       0.560
C(topic_grouped)[T.Sports]                     0.7445      0.405      1.837      0.066      -0.050       1.539
C(answer_type_grouped)[T.Number]               0.3278      0.287      1.142      0.254      -0.235       0.890
C(answer_type_grouped)[T.Other]                0.0539      0.239      0.226      0.821      -0.414       0.522
C(answer_type_grouped)[T.Person]               0.2189      0.249      0.880      0.379      -0.269       0.707
q_length                                      -0.3452      0.248     -1.393      0.164      -0.831       0.141
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing deepseek-chat (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_new/deepseek-chat_SimpleMC_redacted_cor_temp0.0_1753737594_game_data.json', './sc_logs_new/deepseek-chat_SimpleMC_redacted_temp0.0_1753645078_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    370
1    125
Name: count, dtype: int64

Answer change%: 0.2525 [0.21425193035368692, 0.29079857469681814] (n=495)
P-value vs 25%: 0.8971; P-value vs 0%: 2.98e-38
Phase 2 self-accuracy: 0.3760 [0.2910859995361642, 0.4609140004638358] (n=125)
P-value vs 25%: 0.003634; P-value vs 33%: 0.3209

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  495
Model:                          Logit   Df Residuals:                      493
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.06319
Time:                        20:27:17   Log-Likelihood:                -262.04
converged:                       True   LL-Null:                       -279.72
Covariance Type:            nonrobust   LLR p-value:                 2.750e-09
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          1.2606      0.404      3.122      0.002       0.469       2.052
p_i_capability    -3.0717      0.528     -5.818      0.000      -4.106      -2.037
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  495
Model:                          Logit   Df Residuals:                      493
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.08180
Time:                        20:27:17   Log-Likelihood:                -256.84
converged:                       True   LL-Null:                       -279.72
Covariance Type:            nonrobust   LLR p-value:                 1.335e-11
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.1077      0.208    -10.155      0.000      -2.515      -1.701
capabilities_entropy     1.2232      0.190      6.443      0.000       0.851       1.595
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.3760 [0.2911, 0.4609] (n=125)
                  P-value vs 33.3%: 0.3247

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=23.64, p=1.1e-75
Wilcoxon delta_p: statistic=3927.00, p=9.89e-49
Mean Δp = 0.5576  [0.5113, 0.6038]
Idea 1 N = 367; 

  Idea 1.5: Calibration Metrics
  NLL: 3.8173, Signed ECE (overconf pos under neg): -0.2143, ECE: 0.3771 (n=455)
  Brier: 0.4108, Reliability (absolute calibration error; lower better): 0.1739, Resolution (relative calibration quality; higher better): 0.0137, Uncertainty: 0.2480 (n=455)
  AUROC: 0.4243

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.226
Model:                            OLS   Adj. R-squared:                  0.221
Method:                 Least Squares   F-statistic:                     47.51
Date:                Fri, 19 Sep 2025   Prob (F-statistic):           5.91e-27
Time:                        20:27:17   Log-Likelihood:                -234.24
No. Observations:                 492   AIC:                             476.5
Df Residuals:                     488   BIC:                             493.3
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.2788      0.088     -3.158      0.002      -0.452      -0.105
p1                    1.0174      0.104      9.739      0.000       0.812       1.223
answer_changed       -0.1366      0.166     -0.825      0.410      -0.462       0.189
p1:answer_changed     0.2212      0.220      1.004      0.316      -0.212       0.654
==============================================================================
Omnibus:                       93.632   Durbin-Watson:                   1.878
Prob(Omnibus):                  0.000   Jarque-Bera (JB):              104.509
Skew:                          -1.069   Prob(JB):                     2.02e-23
Kurtosis:                       2.277   Cond. No.                         21.2
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=10.38, p=2.59e-22
Wilcoxon delta_H: statistic=15128.00, p=5.03e-20
Mean ΔH = 0.3749  [0.3041, 0.4456]
Paired t-test delta_H Changed: statistic=7.95, p=9.77e-13
Wilcoxon delta_H Changed: statistic=1328.00, p=1.28e-10
Mean ΔH Changed = 0.4279  [0.3224, 0.5333]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=9.84, p=5.7e-21
Wilcoxon (p_top2_game vs p_top2_base): statistic=41758.00, p=2.17e-09
Mean Δp_top2 = 0.0402  [0.0322, 0.0482] (n=492)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=12.86, p=7.76e-33
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=25458.00, p=7.13e-29
Mean ΔH_unchosen_baseline_set = 0.3883  [0.3292, 0.4475] (n=492)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  492
Model:                          Logit   Df Residuals:                      489
Method:                           MLE   Df Model:                            2
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.09213
Time:                        20:27:17   Log-Likelihood:                -253.15
converged:                       True   LL-Null:                       -278.84
Covariance Type:            nonrobust   LLR p-value:                 6.968e-12
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.7036      0.156     -4.506      0.000      -1.010      -0.398
p1_z            -0.9889      0.150     -6.571      0.000      -1.284      -0.694
I(p1_z ** 2)    -0.5358      0.135     -3.980      0.000      -0.800      -0.272
================================================================================
AUC = 0.702

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  495
Model:                          Logit   Df Residuals:                      493
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.1477
Time:                        20:27:17   Log-Likelihood:                -238.41
converged:                       True   LL-Null:                       -279.72
Covariance Type:            nonrobust   LLR p-value:                 9.953e-20
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -2.7420      0.234    -11.743      0.000      -3.200      -2.284
game_entropy     3.3527      0.403      8.314      0.000       2.562       4.143
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=34048.00, p=9.15e-18
Paired t-test (game_entropy vs capabilities_entropy): statistic=-10.49, p=2.27e-23
Mean capabilities_entropy-game_entropy = 0.2769  [0.2251, 0.3286] (n=495)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  495
Model:                          Logit   Df Residuals:                      492
Method:                           MLE   Df Model:                            2
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.1927
Time:                        20:27:17   Log-Likelihood:                -225.81
converged:                       True   LL-Null:                       -279.72
Covariance Type:            nonrobust   LLR p-value:                 3.856e-24
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -3.4385      0.301    -11.433      0.000      -4.028      -2.849
capabilities_entropy     1.0147      0.207      4.892      0.000       0.608       1.421
game_entropy             3.0331      0.414      7.330      0.000       2.222       3.844
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.813333
                        1                 0.186667
Geography               0                 0.674419
                        1                 0.325581
Misc                    0                 0.698630
                        1                 0.301370
Music                   0                 0.750000
                        1                 0.250000
Other                   0                 0.750000
                        1                 0.250000
Politics                0                 0.710526
                        1                 0.289474
Science and technology  0                 0.804124
                        1                 0.195876
Sports                  0                 0.717949
                        1                 0.282051
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.724551
                     1                 0.275449
Number               0                 0.753247
                     1                 0.246753
Other                0                 0.727273
                     1                 0.272727
Person               0                 0.798319
                     1                 0.201681
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.857143  0.142857           21
                       Number               0.888889  0.111111            9
                       Other                0.666667  0.333333           18
                       Person               0.851852  0.148148           27
Geography              Date                 0.428571  0.571429           14
                       Number               0.888889  0.111111           18
                       Other                0.636364  0.363636           11
Misc                   Date                 0.772727  0.227273           22
                       Number               0.777778  0.222222            9
                       Other                0.666667  0.333333           27
                       Person               0.600000  0.400000           15
Music                  Date                 0.750000  0.250000           12
                       Number               1.000000  0.000000            4
                       Other                0.666667  0.333333           12
                       Person               0.750000  0.250000           12
Other                  Date                 0.666667  0.333333           18
                       Number               0.714286  0.285714            7
                       Other                0.857143  0.142857           14
                       Person               0.769231  0.230769           13
Politics               Date                 0.694444  0.305556           36
                       Number               0.666667  0.333333            6
                       Other                0.789474  0.210526           19
                       Person               0.666667  0.333333           15
Science and technology Date                 0.800000  0.200000           35
                       Number               0.642857  0.357143           14
                       Other                0.789474  0.210526           19
                       Person               0.896552  0.103448           29
Sports                 Date                 0.666667  0.333333            9
                       Number               0.500000  0.500000           10
                       Other                0.750000  0.250000           12
                       Person               1.000000  0.000000            8

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  495
Model:                          Logit   Df Residuals:                      483
Method:                           MLE   Df Model:                           11
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.01400
Time:                        20:27:17   Log-Likelihood:                -275.81
converged:                       True   LL-Null:                       -279.72
Covariance Type:            nonrobust   LLR p-value:                    0.7284
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.3303      1.318     -1.009      0.313      -3.914       1.254
C(topic_grouped)[T.Geography]                  0.6933      0.455      1.525      0.127      -0.198       1.585
C(topic_grouped)[T.Misc]                       0.5903      0.394      1.500      0.134      -0.181       1.362
C(topic_grouped)[T.Music]                      0.3538      0.472      0.750      0.453      -0.570       1.278
C(topic_grouped)[T.Other]                      0.3437      0.438      0.785      0.432      -0.514       1.202
C(topic_grouped)[T.Politics]                   0.5162      0.398      1.296      0.195      -0.265       1.297
C(topic_grouped)[T.Science and technology]     0.0433      0.394      0.110      0.912      -0.728       0.815
C(topic_grouped)[T.Sports]                     0.5209      0.467      1.116      0.264      -0.394       1.436
C(answer_type_grouped)[T.Number]              -0.2026      0.328     -0.618      0.536      -0.845       0.440
C(answer_type_grouped)[T.Other]               -0.0416      0.266     -0.157      0.876      -0.562       0.479
C(answer_type_grouped)[T.Person]              -0.3229      0.294     -1.099      0.272      -0.899       0.253
q_length                                       0.0006      0.283      0.002      0.998      -0.554       0.556
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.7340
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  495
Model:                          Logit   Df Residuals:                      482
Method:                           MLE   Df Model:                           12
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.09366
Time:                        20:27:17   Log-Likelihood:                -253.52
converged:                       True   LL-Null:                       -279.72
Covariance Type:            nonrobust   LLR p-value:                 5.270e-07
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.8136      1.403     -1.293      0.196      -4.563       0.936
C(topic_grouped)[T.Geography]                  0.6492      0.475      1.367      0.172      -0.282       1.580
C(topic_grouped)[T.Misc]                       0.4172      0.413      1.009      0.313      -0.393       1.227
C(topic_grouped)[T.Music]                      0.3107      0.494      0.629      0.529      -0.658       1.279
C(topic_grouped)[T.Other]                      0.1997      0.458      0.436      0.663      -0.699       1.098
C(topic_grouped)[T.Politics]                   0.4902      0.417      1.175      0.240      -0.328       1.308
C(topic_grouped)[T.Science and technology]     0.0200      0.413      0.048      0.961      -0.790       0.830
C(topic_grouped)[T.Sports]                     0.4743      0.488      0.972      0.331      -0.482       1.431
C(answer_type_grouped)[T.Number]              -0.2797      0.343     -0.816      0.414      -0.952       0.392
C(answer_type_grouped)[T.Other]                0.0103      0.280      0.037      0.971      -0.539       0.559
C(answer_type_grouped)[T.Person]              -0.3269      0.309     -1.059      0.290      -0.932       0.278
q_length                                      -0.1077      0.300     -0.359      0.719      -0.695       0.480
capabilities_entropy                           1.2315      0.194      6.361      0.000       0.852       1.611
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  495
Model:                          Logit   Df Residuals:                      482
Method:                           MLE   Df Model:                           12
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.1654
Time:                        20:27:17   Log-Likelihood:                -233.44
converged:                       True   LL-Null:                       -279.72
Covariance Type:            nonrobust   LLR p-value:                 1.578e-14
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -2.3846      1.475     -1.617      0.106      -5.275       0.506
C(topic_grouped)[T.Geography]                  0.3866      0.514      0.752      0.452      -0.621       1.394
C(topic_grouped)[T.Misc]                       0.4759      0.431      1.105      0.269      -0.368       1.320
C(topic_grouped)[T.Music]                      0.1562      0.514      0.304      0.761      -0.851       1.164
C(topic_grouped)[T.Other]                      0.1152      0.488      0.236      0.813      -0.841       1.071
C(topic_grouped)[T.Politics]                   0.3122      0.433      0.722      0.471      -0.536       1.160
C(topic_grouped)[T.Science and technology]    -0.3440      0.436     -0.788      0.431      -1.199       0.511
C(topic_grouped)[T.Sports]                     0.5038      0.496      1.015      0.310      -0.469       1.476
C(answer_type_grouped)[T.Number]              -0.6389      0.374     -1.709      0.087      -1.371       0.094
C(answer_type_grouped)[T.Other]               -0.2166      0.296     -0.731      0.465      -0.798       0.365
C(answer_type_grouped)[T.Person]              -0.4078      0.326     -1.252      0.210      -1.046       0.230
q_length                                      -0.0798      0.316     -0.253      0.800      -0.699       0.539
game_entropy                                   3.5141      0.422      8.331      0.000       2.687       4.341
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  495
Model:                          Logit   Df Residuals:                      481
Method:                           MLE   Df Model:                           13
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.2087
Time:                        20:27:17   Log-Likelihood:                -221.33
converged:                       True   LL-Null:                       -279.72
Covariance Type:            nonrobust   LLR p-value:                 8.688e-19
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -2.4824      1.534     -1.618      0.106      -5.488       0.524
C(topic_grouped)[T.Geography]                  0.3866      0.528      0.732      0.464      -0.649       1.422
C(topic_grouped)[T.Misc]                       0.3553      0.448      0.793      0.428      -0.523       1.234
C(topic_grouped)[T.Music]                      0.1247      0.533      0.234      0.815      -0.920       1.169
C(topic_grouped)[T.Other]                      0.0317      0.496      0.064      0.949      -0.940       1.004
C(topic_grouped)[T.Politics]                   0.3254      0.447      0.728      0.467      -0.551       1.201
C(topic_grouped)[T.Science and technology]    -0.3278      0.449     -0.729      0.466      -1.209       0.553
C(topic_grouped)[T.Sports]                     0.4491      0.519      0.866      0.387      -0.568       1.466
C(answer_type_grouped)[T.Number]              -0.6730      0.380     -1.770      0.077      -1.418       0.072
C(answer_type_grouped)[T.Other]               -0.1733      0.308     -0.563      0.574      -0.777       0.430
C(answer_type_grouped)[T.Person]              -0.3757      0.335     -1.122      0.262      -1.032       0.281
q_length                                      -0.2115      0.328     -0.645      0.519      -0.854       0.431
capabilities_entropy                           1.0227      0.213      4.793      0.000       0.605       1.441
game_entropy                                   3.2083      0.434      7.399      0.000       2.358       4.058
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing gemini-1.5-pro (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_new/gemini-1.5-pro_SimpleMC_redacted_cor_temp0.0_1751757561_game_data.json', './sc_logs_new/gemini-1.5-pro_SimpleMC_redacted_temp0.0_1751722404_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    413
1     87
Name: count, dtype: int64

Answer change%: 0.1740 [0.1407701992920378, 0.20722980070796218] (n=500)
P-value vs 25%: 7.372e-06; P-value vs 0%: 1.036e-24
Phase 2 self-accuracy: 0.3678 [0.2664890076427917, 0.46914317626525426] (n=87)
P-value vs 25%: 0.02267; P-value vs 33%: 0.5007
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.893333
                        1                 0.106667
Geography               0                 0.840909
                        1                 0.159091
Misc                    0                 0.770270
                        1                 0.229730
Music                   0                 0.800000
                        1                 0.200000
Other                   0                 0.807692
                        1                 0.192308
Politics                0                 0.857143
                        1                 0.142857
Science and technology  0                 0.795918
                        1                 0.204082
Sports                  0                 0.850000
                        1                 0.150000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.887574
                     1                 0.112426
Number               0                 0.833333
                     1                 0.166667
Other                0                 0.789474
                     1                 0.210526
Person               0                 0.775000
                     1                 0.225000
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.952381  0.047619           21
                       Number               0.888889  0.111111            9
                       Other                0.888889  0.111111           18
                       Person               0.851852  0.148148           27
Geography              Date                 0.866667  0.133333           15
                       Number               0.777778  0.222222           18
                       Other                0.909091  0.090909           11
Misc                   Date                 0.869565  0.130435           23
                       Number               0.777778  0.222222            9
                       Other                0.740741  0.259259           27
                       Person               0.666667  0.333333           15
Music                  Date                 0.916667  0.083333           12
                       Number               1.000000  0.000000            4
                       Other                0.500000  0.500000           12
                       Person               0.916667  0.083333           12
Other                  Date                 0.944444  0.055556           18
                       Number               1.000000  0.000000            7
                       Other                0.642857  0.357143           14
                       Person               0.692308  0.307692           13
Politics               Date                 0.861111  0.138889           36
                       Number               0.833333  0.166667            6
                       Other                0.950000  0.050000           20
                       Person               0.733333  0.266667           15
Science and technology Date                 0.828571  0.171429           35
                       Number               0.785714  0.214286           14
                       Other                0.842105  0.157895           19
                       Person               0.733333  0.266667           30
Sports                 Date                 1.000000  0.000000            9
                       Number               0.818182  0.181818           11
                       Other                0.750000  0.250000           12
                       Person               0.875000  0.125000            8

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      488
Method:                           MLE   Df Model:                           11
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.03088
Time:                        20:27:17   Log-Likelihood:                -223.95
converged:                       True   LL-Null:                       -231.09
Covariance Type:            nonrobust   LLR p-value:                    0.2182
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -2.4972      1.521     -1.642      0.101      -5.479       0.484
C(topic_grouped)[T.Geography]                  0.6483      0.579      1.120      0.263      -0.486       1.783
C(topic_grouped)[T.Misc]                       0.9746      0.472      2.066      0.039       0.050       1.899
C(topic_grouped)[T.Music]                      0.7626      0.549      1.389      0.165      -0.314       1.839
C(topic_grouped)[T.Other]                      0.7632      0.519      1.471      0.141      -0.253       1.780
C(topic_grouped)[T.Politics]                   0.4881      0.506      0.964      0.335      -0.504       1.480
C(topic_grouped)[T.Science and technology]     0.8454      0.455      1.859      0.063      -0.046       1.737
C(topic_grouped)[T.Sports]                     0.4275      0.587      0.729      0.466      -0.722       1.577
C(answer_type_grouped)[T.Number]               0.4720      0.400      1.180      0.238      -0.312       1.256
C(answer_type_grouped)[T.Other]                0.7384      0.328      2.253      0.024       0.096       1.381
C(answer_type_grouped)[T.Person]               0.8676      0.336      2.584      0.010       0.209       1.526
q_length                                      -0.0499      0.322     -0.155      0.877      -0.681       0.582
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing gemini-2.0-flash-001 (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_new/gemini-2.0-flash-001_SimpleMC_redacted_cor_temp1.0_1757990222_game_data.json', './sc_logs_new/gemini-2.0-flash-001_SimpleMC_redacted_temp1.0_1758161280_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    305
1    195
Name: count, dtype: int64

Answer change%: 0.3900 [0.34724761869923193, 0.4327523813007681] (n=500)
P-value vs 25%: 1.379e-10; P-value vs 0%: 1.707e-71
Phase 2 self-accuracy: 0.3179 [0.2525878457099642, 0.3833095901874717] (n=195)
P-value vs 25%: 0.04159; P-value vs 33%: 0.6517

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.02156
Time:                        20:27:17   Log-Likelihood:                -327.17
converged:                       True   LL-Null:                       -334.37
Covariance Type:            nonrobust   LLR p-value:                 0.0001464
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          1.7966      0.608      2.956      0.003       0.605       2.988
p_i_capability    -2.4594      0.659     -3.735      0.000      -3.750      -1.169
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.03495
Time:                        20:27:17   Log-Likelihood:                -322.69
converged:                       True   LL-Null:                       -334.37
Covariance Type:            nonrobust   LLR p-value:                 1.336e-06
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -0.7864      0.119     -6.627      0.000      -1.019      -0.554
capabilities_entropy     1.0592      0.224      4.722      0.000       0.620       1.499
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.5159 [0.4378, 0.5941] (n=157)
                  P-value vs 33.3%: 4.694e-06

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=8.15, p=5.43e-14
Wilcoxon delta_p: statistic=2941.00, p=1.38e-14
Mean Δp = 0.1442  [0.1095, 0.1788]
Idea 1 N = 184; 

  Idea 1.5: Calibration Metrics
  NLL: 3.7902, Signed ECE (overconf pos under neg): 0.0028, ECE: 0.0230 (n=340)
  Brier: 0.0449, Reliability (absolute calibration error; lower better): 0.0023, Resolution (relative calibration quality; higher better): 0.1899, Uncertainty: 0.2325 (n=340)
  AUROC: 0.9865

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.665
Model:                            OLS   Adj. R-squared:                  0.662
Method:                 Least Squares   F-statistic:                     221.7
Date:                Fri, 19 Sep 2025   Prob (F-statistic):           3.20e-79
Time:                        20:27:17   Log-Likelihood:                 33.869
No. Observations:                 339   AIC:                            -59.74
Df Residuals:                     335   BIC:                            -44.43
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept             0.0161      0.100      0.161      0.872      -0.180       0.212
p1                    0.1416      0.109      1.301      0.194      -0.073       0.356
answer_changed       -0.4606      0.141     -3.268      0.001      -0.738      -0.183
p1:answer_changed     1.1774      0.157      7.495      0.000       0.868       1.486
==============================================================================
Omnibus:                        8.446   Durbin-Watson:                   2.078
Prob(Omnibus):                  0.015   Jarque-Bera (JB):               14.575
Skew:                          -0.022   Prob(JB):                     0.000684
Kurtosis:                       4.015   Cond. No.                         30.0
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-3.04, p=0.00274
Wilcoxon delta_H: statistic=6382.00, p=0.00327
Mean ΔH = -0.1289  [-0.2120, -0.0457]
Paired t-test delta_H Changed: statistic=1.17, p=0.243
Wilcoxon delta_H Changed: statistic=5582.00, p=0.278
Mean ΔH Changed = 0.0602  [-0.0405, 0.1609]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=-8.09, p=1.07e-14
Wilcoxon (p_top2_game vs p_top2_base): statistic=10329.00, p=4.94e-25
Mean Δp_top2 = -0.0382  [-0.0475, -0.0290] (n=341)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=-1.26, p=0.21
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=26741.00, p=0.185
Mean ΔH_unchosen_baseline_set = -0.0418  [-0.1070, 0.0234] (n=341)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  341
Model:                          Logit   Df Residuals:                      338
Method:                           MLE   Df Model:                            2
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.02607
Time:                        20:27:17   Log-Likelihood:                -229.16
converged:                       True   LL-Null:                       -235.29
Covariance Type:            nonrobust   LLR p-value:                  0.002166
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept        0.1301      0.158      0.821      0.412      -0.180       0.441
p1_z            -0.6722      0.196     -3.422      0.001      -1.057      -0.287
I(p1_z ** 2)    -0.2921      0.115     -2.549      0.011      -0.517      -0.068
================================================================================
AUC = 0.609

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.08764
Time:                        20:27:17   Log-Likelihood:                -305.07
converged:                       True   LL-Null:                       -334.37
Covariance Type:            nonrobust   LLR p-value:                 1.924e-14
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.3002      0.156     -8.323      0.000      -1.606      -0.994
game_entropy     1.3445      0.185      7.278      0.000       0.982       1.707
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=26286.00, p=2.53e-29
Paired t-test (game_entropy vs capabilities_entropy): statistic=11.57, p=1.39e-27
Mean capabilities_entropy-game_entropy = -0.2913  [-0.3407, -0.2420] (n=500)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      497
Method:                           MLE   Df Model:                            2
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.09729
Time:                        20:27:17   Log-Likelihood:                -301.84
converged:                       True   LL-Null:                       -334.37
Covariance Type:            nonrobust   LLR p-value:                 7.449e-15
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.4075      0.164     -8.574      0.000      -1.729      -1.086
capabilities_entropy     0.6045      0.238      2.535      0.011       0.137       1.072
game_entropy             1.2048      0.193      6.249      0.000       0.827       1.583
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.680000
                        1                 0.320000
Geography               1                 0.522727
                        0                 0.477273
Misc                    0                 0.581081
                        1                 0.418919
Music                   0                 0.725000
                        1                 0.275000
Other                   0                 0.634615
                        1                 0.365385
Politics                0                 0.662338
                        1                 0.337662
Science and technology  0                 0.551020
                        1                 0.448980
Sports                  0                 0.575000
                        1                 0.425000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.550296
                     1                 0.449704
Number               1                 0.589744
                     0                 0.410256
Other                0                 0.714286
                     1                 0.285714
Person               0                 0.708333
                     1                 0.291667
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.571429  0.428571           21
                       Number               0.444444  0.555556            9
                       Other                0.666667  0.333333           18
                       Person               0.851852  0.148148           27
Geography              Date                 0.266667  0.733333           15
                       Number               0.500000  0.500000           18
                       Other                0.727273  0.272727           11
Misc                   Date                 0.608696  0.391304           23
                       Number               0.555556  0.444444            9
                       Other                0.592593  0.407407           27
                       Person               0.533333  0.466667           15
Music                  Date                 0.833333  0.166667           12
                       Number               0.500000  0.500000            4
                       Other                0.583333  0.416667           12
                       Person               0.833333  0.166667           12
Other                  Date                 0.555556  0.444444           18
                       Number               0.571429  0.428571            7
                       Other                0.857143  0.142857           14
                       Person               0.538462  0.461538           13
Politics               Date                 0.527778  0.472222           36
                       Number               0.666667  0.333333            6
                       Other                0.800000  0.200000           20
                       Person               0.800000  0.200000           15
Science and technology Date                 0.514286  0.485714           35
                       Number               0.214286  0.785714           14
                       Other                0.736842  0.263158           19
                       Person               0.633333  0.366667           30
Sports                 Date                 0.666667  0.333333            9
                       Number               0.090909  0.909091           11
                       Other                0.833333  0.166667           12
                       Person               0.750000  0.250000            8

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      488
Method:                           MLE   Df Model:                           11
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.04984
Time:                        20:27:17   Log-Likelihood:                -317.71
converged:                       True   LL-Null:                       -334.37
Covariance Type:            nonrobust   LLR p-value:                 0.0004656
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      0.3616      1.190      0.304      0.761      -1.971       2.694
C(topic_grouped)[T.Geography]                  0.4887      0.411      1.188      0.235      -0.318       1.295
C(topic_grouped)[T.Misc]                       0.4352      0.352      1.236      0.216      -0.255       1.125
C(topic_grouped)[T.Music]                     -0.2179      0.442     -0.493      0.622      -1.084       0.648
C(topic_grouped)[T.Other]                      0.1432      0.390      0.367      0.713      -0.621       0.907
C(topic_grouped)[T.Politics]                   0.0493      0.360      0.137      0.891      -0.656       0.755
C(topic_grouped)[T.Science and technology]     0.5070      0.329      1.542      0.123      -0.138       1.152
C(topic_grouped)[T.Sports]                     0.3265      0.419      0.780      0.436      -0.494       1.147
C(answer_type_grouped)[T.Number]               0.5051      0.287      1.762      0.078      -0.057       1.067
C(answer_type_grouped)[T.Other]               -0.7375      0.251     -2.939      0.003      -1.229      -0.246
C(answer_type_grouped)[T.Person]              -0.6816      0.261     -2.614      0.009      -1.193      -0.171
q_length                                      -0.1758      0.257     -0.685      0.493      -0.679       0.327
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.3084
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      487
Method:                           MLE   Df Model:                           12
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.07470
Time:                        20:27:17   Log-Likelihood:                -309.39
converged:                       True   LL-Null:                       -334.37
Covariance Type:            nonrobust   LLR p-value:                 1.421e-06
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      0.1948      1.212      0.161      0.872      -2.181       2.571
C(topic_grouped)[T.Geography]                  0.5302      0.423      1.253      0.210      -0.299       1.360
C(topic_grouped)[T.Misc]                       0.4728      0.360      1.315      0.189      -0.232       1.178
C(topic_grouped)[T.Music]                     -0.1504      0.446     -0.337      0.736      -1.025       0.725
C(topic_grouped)[T.Other]                      0.1923      0.396      0.486      0.627      -0.584       0.968
C(topic_grouped)[T.Politics]                   0.1584      0.369      0.430      0.667      -0.564       0.881
C(topic_grouped)[T.Science and technology]     0.5514      0.337      1.637      0.102      -0.109       1.211
C(topic_grouped)[T.Sports]                     0.4227      0.428      0.988      0.323      -0.416       1.261
C(answer_type_grouped)[T.Number]               0.3878      0.294      1.320      0.187      -0.188       0.964
C(answer_type_grouped)[T.Other]               -0.7282      0.255     -2.855      0.004      -1.228      -0.228
C(answer_type_grouped)[T.Person]              -0.5955      0.265     -2.243      0.025      -1.116      -0.075
q_length                                      -0.2175      0.262     -0.831      0.406      -0.730       0.295
capabilities_entropy                           0.9360      0.233      4.020      0.000       0.480       1.392
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      487
Method:                           MLE   Df Model:                           12
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.1145
Time:                        20:27:17   Log-Likelihood:                -296.08
converged:                       True   LL-Null:                       -334.37
Covariance Type:            nonrobust   LLR p-value:                 1.839e-11
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -0.7400      1.257     -0.589      0.556      -3.204       1.724
C(topic_grouped)[T.Geography]                  0.5140      0.433      1.188      0.235      -0.334       1.362
C(topic_grouped)[T.Misc]                       0.5126      0.367      1.396      0.163      -0.207       1.232
C(topic_grouped)[T.Music]                     -0.1504      0.458     -0.328      0.743      -1.048       0.747
C(topic_grouped)[T.Other]                      0.0651      0.404      0.161      0.872      -0.727       0.857
C(topic_grouped)[T.Politics]                   0.0812      0.377      0.216      0.829      -0.657       0.819
C(topic_grouped)[T.Science and technology]     0.5215      0.347      1.503      0.133      -0.159       1.202
C(topic_grouped)[T.Sports]                     0.4482      0.439      1.021      0.307      -0.412       1.308
C(answer_type_grouped)[T.Number]               0.6236      0.303      2.060      0.039       0.030       1.217
C(answer_type_grouped)[T.Other]               -0.2961      0.271     -1.093      0.275      -0.827       0.235
C(answer_type_grouped)[T.Person]              -0.2329      0.281     -0.829      0.407      -0.784       0.318
q_length                                      -0.1657      0.268     -0.617      0.537      -0.692       0.360
game_entropy                                   1.2506      0.198      6.331      0.000       0.863       1.638
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      486
Method:                           MLE   Df Model:                           13
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.1215
Time:                        20:27:17   Log-Likelihood:                -293.73
converged:                       True   LL-Null:                       -334.37
Covariance Type:            nonrobust   LLR p-value:                 6.323e-12
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -0.7401      1.263     -0.586      0.558      -3.216       1.736
C(topic_grouped)[T.Geography]                  0.5288      0.437      1.211      0.226      -0.327       1.384
C(topic_grouped)[T.Misc]                       0.5230      0.370      1.414      0.157      -0.202       1.248
C(topic_grouped)[T.Music]                     -0.1135      0.458     -0.248      0.804      -1.010       0.783
C(topic_grouped)[T.Other]                      0.0970      0.407      0.239      0.811      -0.700       0.894
C(topic_grouped)[T.Politics]                   0.1416      0.379      0.373      0.709      -0.602       0.885
C(topic_grouped)[T.Science and technology]     0.5456      0.350      1.558      0.119      -0.141       1.232
C(topic_grouped)[T.Sports]                     0.4898      0.443      1.106      0.269      -0.378       1.358
C(answer_type_grouped)[T.Number]               0.5413      0.306      1.766      0.077      -0.059       1.142
C(answer_type_grouped)[T.Other]               -0.3368      0.273     -1.232      0.218      -0.873       0.199
C(answer_type_grouped)[T.Person]              -0.2252      0.282     -0.799      0.425      -0.778       0.328
q_length                                      -0.1872      0.270     -0.694      0.488      -0.716       0.341
capabilities_entropy                           0.5351      0.247      2.167      0.030       0.051       1.019
game_entropy                                   1.1252      0.206      5.460      0.000       0.721       1.529
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing gemini-2.5-flash-lite_nothink (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_new/gemini-2.5-flash-lite_nothink_SimpleMC_redacted_cor_temp1.0_1757984044_game_data.json', './sc_logs_new/gemini-2.5-flash-lite_nothink_SimpleMC_redacted_temp1.0_1757983883_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    336
1    164
Name: count, dtype: int64

Answer change%: 0.3280 [0.28684859692739223, 0.3691514030726078] (n=500)
P-value vs 25%: 0.0002032; P-value vs 0%: 5.154e-55
Phase 2 self-accuracy: 0.3293 [0.2573440096403039, 0.4011925757255498] (n=164)
P-value vs 25%: 0.03077; P-value vs 33%: 0.919

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.1297
Time:                        20:27:17   Log-Likelihood:                -275.33
converged:                       True   LL-Null:                       -316.38
Covariance Type:            nonrobust   LLR p-value:                 1.301e-19
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          2.8000      0.418      6.700      0.000       1.981       3.619
p_i_capability    -4.6884      0.556     -8.435      0.000      -5.778      -3.599
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.1433
Time:                        20:27:17   Log-Likelihood:                -271.04
converged:                       True   LL-Null:                       -316.38
Covariance Type:            nonrobust   LLR p-value:                 1.695e-21
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.3010      0.227    -10.156      0.000      -2.745      -1.857
capabilities_entropy     1.7909      0.208      8.608      0.000       1.383       2.199
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.4024 [0.3274, 0.4775] (n=164)
                  P-value vs 33.3%: 0.07113

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=4.51, p=9.02e-06
Wilcoxon delta_p: statistic=19625.00, p=1.59e-06
Mean Δp = 0.0515  [0.0291, 0.0739]
Idea 1 N = 335; 

  Idea 1.5: Calibration Metrics
  NLL: 2.3123, Signed ECE (overconf pos under neg): 0.0066, ECE: 0.0318 (n=499)
  Brier: 0.0776, Reliability (absolute calibration error; lower better): 0.0016, Resolution (relative calibration quality; higher better): 0.1571, Uncertainty: 0.2328 (n=499)
  AUROC: 0.9611

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.293
Model:                            OLS   Adj. R-squared:                  0.288
Method:                 Least Squares   F-statistic:                     68.25
Date:                Fri, 19 Sep 2025   Prob (F-statistic):           5.99e-37
Time:                        20:27:17   Log-Likelihood:                 6.7725
No. Observations:                 499   AIC:                            -5.545
Df Residuals:                     495   BIC:                             11.31
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.0981      0.062     -1.587      0.113      -0.219       0.023
p1                    0.1802      0.073      2.477      0.014       0.037       0.323
answer_changed       -0.2276      0.097     -2.352      0.019      -0.418      -0.037
p1:answer_changed     0.7670      0.131      5.873      0.000       0.510       1.024
==============================================================================
Omnibus:                        0.682   Durbin-Watson:                   2.003
Prob(Omnibus):                  0.711   Jarque-Bera (JB):                0.680
Skew:                          -0.089   Prob(JB):                        0.712
Kurtosis:                       2.973   Cond. No.                         21.6
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-3.81, p=0.000165
Wilcoxon delta_H: statistic=21694.00, p=0.000279
Mean ΔH = -0.0819  [-0.1240, -0.0398]
Paired t-test delta_H Changed: statistic=3.32, p=0.00109
Wilcoxon delta_H Changed: statistic=4806.00, p=0.0013
Mean ΔH Changed = 0.1219  [0.0501, 0.1938]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=-1.38, p=0.17
Wilcoxon (p_top2_game vs p_top2_base): statistic=51675.00, p=0.000899
Mean Δp_top2 = -0.0049  [-0.0118, 0.0021] (n=499)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=-0.77, p=0.44
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=59422.00, p=0.359
Mean ΔH_unchosen_baseline_set = -0.0149  [-0.0526, 0.0229] (n=499)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  499
Model:                          Logit   Df Residuals:                      496
Method:                           MLE   Df Model:                            2
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.1443
Time:                        20:27:17   Log-Likelihood:                -270.38
converged:                       True   LL-Null:                       -315.98
Covariance Type:            nonrobust   LLR p-value:                 1.568e-20
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.5101      0.149     -3.414      0.001      -0.803      -0.217
p1_z            -1.1303      0.136     -8.286      0.000      -1.398      -0.863
I(p1_z ** 2)    -0.3896      0.126     -3.101      0.002      -0.636      -0.143
================================================================================
AUC = 0.743

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.1174
Time:                        20:27:17   Log-Likelihood:                -279.23
converged:                       True   LL-Null:                       -316.38
Covariance Type:            nonrobust   LLR p-value:                 6.759e-18
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -2.1854      0.223     -9.807      0.000      -2.622      -1.749
game_entropy     1.6489      0.207      7.981      0.000       1.244       2.054
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=58151.00, p=0.166
Paired t-test (game_entropy vs capabilities_entropy): statistic=0.99, p=0.324
Mean capabilities_entropy-game_entropy = -0.0213  [-0.0636, 0.0210] (n=500)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      497
Method:                           MLE   Df Model:                            2
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.1690
Time:                        20:27:17   Log-Likelihood:                -262.92
converged:                       True   LL-Null:                       -316.38
Covariance Type:            nonrobust   LLR p-value:                 6.066e-24
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.7633      0.270    -10.247      0.000      -3.292      -2.235
capabilities_entropy     1.3243      0.239      5.547      0.000       0.856       1.792
game_entropy             0.9700      0.243      3.994      0.000       0.494       1.446
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.653333
                        1                 0.346667
Geography               0                 0.522727
                        1                 0.477273
Misc                    0                 0.635135
                        1                 0.364865
Music                   0                 0.775000
                        1                 0.225000
Other                   0                 0.692308
                        1                 0.307692
Politics                0                 0.649351
                        1                 0.350649
Science and technology  0                 0.734694
                        1                 0.265306
Sports                  0                 0.700000
                        1                 0.300000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.568047
                     1                 0.431953
Number               0                 0.602564
                     1                 0.397436
Other                0                 0.751880
                     1                 0.248120
Person               0                 0.775000
                     1                 0.225000
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.571429  0.428571           21
                       Number               0.333333  0.666667            9
                       Other                0.833333  0.166667           18
                       Person               0.703704  0.296296           27
Geography              Date                 0.466667  0.533333           15
                       Number               0.611111  0.388889           18
                       Other                0.454545  0.545455           11
Misc                   Date                 0.521739  0.478261           23
                       Number               0.555556  0.444444            9
                       Other                0.703704  0.296296           27
                       Person               0.733333  0.266667           15
Music                  Date                 0.583333  0.416667           12
                       Number               0.750000  0.250000            4
                       Other                0.833333  0.166667           12
                       Person               0.916667  0.083333           12
Other                  Date                 0.611111  0.388889           18
                       Number               0.857143  0.142857            7
                       Other                0.714286  0.285714           14
                       Person               0.692308  0.307692           13
Politics               Date                 0.500000  0.500000           36
                       Number               0.666667  0.333333            6
                       Other                0.850000  0.150000           20
                       Person               0.733333  0.266667           15
Science and technology Date                 0.657143  0.342857           35
                       Number               0.642857  0.357143           14
                       Other                0.789474  0.210526           19
                       Person               0.833333  0.166667           30
Sports                 Date                 0.666667  0.333333            9
                       Number               0.545455  0.454545           11
                       Other                0.750000  0.250000           12
                       Person               0.875000  0.125000            8

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      488
Method:                           MLE   Df Model:                           11
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.04324
Time:                        20:27:17   Log-Likelihood:                -302.70
converged:                       True   LL-Null:                       -316.38
Covariance Type:            nonrobust   LLR p-value:                  0.004057
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      0.6924      1.231      0.562      0.574      -1.721       3.106
C(topic_grouped)[T.Geography]                  0.2911      0.407      0.715      0.475      -0.507       1.089
C(topic_grouped)[T.Misc]                       0.0510      0.352      0.145      0.885      -0.638       0.740
C(topic_grouped)[T.Music]                     -0.6410      0.458     -1.399      0.162      -1.539       0.257
C(topic_grouped)[T.Other]                     -0.2654      0.395     -0.671      0.502      -1.040       0.509
C(topic_grouped)[T.Politics]                  -0.0901      0.356     -0.253      0.800      -0.788       0.607
C(topic_grouped)[T.Science and technology]    -0.4725      0.342     -1.382      0.167      -1.143       0.197
C(topic_grouped)[T.Sports]                    -0.2802      0.433     -0.647      0.518      -1.129       0.569
C(answer_type_grouped)[T.Number]              -0.2021      0.290     -0.696      0.486      -0.771       0.367
C(answer_type_grouped)[T.Other]               -0.8788      0.259     -3.395      0.001      -1.386      -0.371
C(answer_type_grouped)[T.Person]              -0.9306      0.275     -3.380      0.001      -1.470      -0.391
q_length                                      -0.1750      0.266     -0.658      0.511      -0.696       0.346
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.7949
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      487
Method:                           MLE   Df Model:                           12
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.1585
Time:                        20:27:17   Log-Likelihood:                -266.24
converged:                       True   LL-Null:                       -316.38
Covariance Type:            nonrobust   LLR p-value:                 4.926e-16
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.1448      1.359     -0.842      0.400      -3.809       1.520
C(topic_grouped)[T.Geography]                  0.2523      0.435      0.580      0.562      -0.601       1.105
C(topic_grouped)[T.Misc]                       0.0699      0.383      0.183      0.855      -0.680       0.820
C(topic_grouped)[T.Music]                     -0.7448      0.500     -1.490      0.136      -1.724       0.235
C(topic_grouped)[T.Other]                     -0.3946      0.421     -0.937      0.349      -1.220       0.431
C(topic_grouped)[T.Politics]                  -0.0256      0.390     -0.066      0.948      -0.791       0.739
C(topic_grouped)[T.Science and technology]    -0.4043      0.373     -1.084      0.278      -1.135       0.327
C(topic_grouped)[T.Sports]                    -0.2200      0.470     -0.469      0.639      -1.140       0.700
C(answer_type_grouped)[T.Number]              -0.5097      0.314     -1.621      0.105      -1.126       0.107
C(answer_type_grouped)[T.Other]               -0.2098      0.294     -0.714      0.475      -0.785       0.366
C(answer_type_grouped)[T.Person]              -0.2703      0.307     -0.880      0.379      -0.872       0.331
q_length                                      -0.1816      0.287     -0.633      0.526      -0.744       0.380
capabilities_entropy                           1.8037      0.230      7.839      0.000       1.353       2.255
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      487
Method:                           MLE   Df Model:                           12
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.1424
Time:                        20:27:17   Log-Likelihood:                -271.33
converged:                       True   LL-Null:                       -316.38
Covariance Type:            nonrobust   LLR p-value:                 4.742e-14
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -0.4705      1.333     -0.353      0.724      -3.082       2.141
C(topic_grouped)[T.Geography]                  0.1721      0.437      0.394      0.693      -0.684       1.028
C(topic_grouped)[T.Misc]                       0.0540      0.378      0.143      0.886      -0.686       0.794
C(topic_grouped)[T.Music]                     -0.7757      0.487     -1.594      0.111      -1.730       0.178
C(topic_grouped)[T.Other]                     -0.4195      0.423     -0.992      0.321      -1.248       0.409
C(topic_grouped)[T.Politics]                   0.0818      0.386      0.212      0.832      -0.675       0.839
C(topic_grouped)[T.Science and technology]    -0.6256      0.371     -1.687      0.092      -1.353       0.101
C(topic_grouped)[T.Sports]                    -0.3990      0.467     -0.854      0.393      -1.314       0.517
C(answer_type_grouped)[T.Number]              -0.3332      0.311     -1.073      0.283      -0.942       0.276
C(answer_type_grouped)[T.Other]               -0.4753      0.281     -1.693      0.090      -1.025       0.075
C(answer_type_grouped)[T.Person]              -0.5580      0.297     -1.877      0.061      -1.141       0.025
q_length                                      -0.2657      0.286     -0.928      0.353      -0.827       0.295
game_entropy                                   1.6351      0.221      7.405      0.000       1.202       2.068
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      486
Method:                           MLE   Df Model:                           13
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.1864
Time:                        20:27:17   Log-Likelihood:                -257.40
converged:                       True   LL-Null:                       -316.38
Covariance Type:            nonrobust   LLR p-value:                 5.109e-19
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.4291      1.391     -1.027      0.304      -4.155       1.297
C(topic_grouped)[T.Geography]                  0.1831      0.446      0.411      0.681      -0.690       1.057
C(topic_grouped)[T.Misc]                       0.0968      0.391      0.248      0.804      -0.670       0.863
C(topic_grouped)[T.Music]                     -0.7971      0.506     -1.574      0.115      -1.790       0.195
C(topic_grouped)[T.Other]                     -0.4287      0.430     -0.997      0.319      -1.271       0.414
C(topic_grouped)[T.Politics]                   0.0591      0.402      0.147      0.883      -0.729       0.847
C(topic_grouped)[T.Science and technology]    -0.5020      0.382     -1.313      0.189      -1.251       0.247
C(topic_grouped)[T.Sports]                    -0.2912      0.484     -0.602      0.547      -1.239       0.657
C(answer_type_grouped)[T.Number]              -0.5086      0.320     -1.592      0.111      -1.135       0.118
C(answer_type_grouped)[T.Other]               -0.1497      0.300     -0.499      0.617      -0.737       0.438
C(answer_type_grouped)[T.Person]              -0.2191      0.313     -0.700      0.484      -0.833       0.395
q_length                                      -0.2340      0.293     -0.798      0.425      -0.809       0.341
capabilities_entropy                           1.3261      0.258      5.138      0.000       0.820       1.832
game_entropy                                   1.0433      0.251      4.148      0.000       0.550       1.536
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing gemini-2.5-flash-lite_think (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_new/gemini-2.5-flash-lite_think_SimpleMC_redacted_cor_temp1.0_1758179683_game_data.json', './sc_logs_new/gemini-2.5-flash-lite_think_SimpleMC_redacted_temp1.0_1758167956_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    283
1    217
Name: count, dtype: int64

Answer change%: 0.4340 [0.39055736401757857, 0.4774426359824214] (n=500)
P-value vs 25%: 1.029e-16; P-value vs 0%: 2.272e-85
Phase 2 self-accuracy: 0.2995 [0.23859432751483192, 0.36048401349899295] (n=217)
P-value vs 25%: 0.1111; P-value vs 33%: 0.2819

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.01577
Time:                        20:27:17   Log-Likelihood:                -336.81
converged:                       True   LL-Null:                       -342.20
Covariance Type:            nonrobust   LLR p-value:                  0.001019
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept       2108.9658   1128.349      1.869      0.062    -102.557    4320.489
p_i_capability -2109.3211   1128.384     -1.869      0.062   -4320.914     102.271
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.01610
Time:                        20:27:17   Log-Likelihood:                -336.69
converged:                       True   LL-Null:                       -342.20
Covariance Type:            nonrobust   LLR p-value:                 0.0009008
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -0.3578      0.098     -3.667      0.000      -0.549      -0.167
capabilities_entropy   175.0243     88.395      1.980      0.048       1.773     348.275
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.1111 [0.0673, 0.1549] (n=198)
                  P-value vs 33.3%: 2.525e-23

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=1.88, p=0.0615
Wilcoxon delta_p: statistic=1730.00, p=1.46e-35
Mean Δp = 0.0002  [-0.0000, 0.0005]
Idea 1 N = 257; 

  Idea 1.5: Calibration Metrics
  NLL: 3.8108, Signed ECE (overconf pos under neg): 0.0010, ECE: 0.0011 (n=296)
  Brier: 0.0002, Reliability (absolute calibration error; lower better): 0.0002, Resolution (relative calibration quality; higher better): 0.2155, Uncertainty: 0.2155 (n=296)
  AUROC: 1.0000

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       1.000
Model:                            OLS   Adj. R-squared:                  1.000
Method:                 Least Squares   F-statistic:                 5.275e+06
Date:                Fri, 19 Sep 2025   Prob (F-statistic):               0.00
Time:                        20:27:17   Log-Likelihood:                 1726.8
No. Observations:                 367   AIC:                            -3446.
Df Residuals:                     363   BIC:                            -3430.
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -1.2899      1.438     -0.897      0.370      -4.117       1.537
p1                    1.2902      1.438      0.897      0.370      -1.537       4.118
answer_changed        1.2924      1.438      0.899      0.369      -1.535       4.120
p1:answer_changed    -0.2932      1.438     -0.204      0.839      -3.121       2.534
==============================================================================
Omnibus:                      414.366   Durbin-Watson:                   1.803
Prob(Omnibus):                  0.000   Jarque-Bera (JB):           283033.978
Skew:                           4.006   Prob(JB):                         0.00
Kurtosis:                     138.812   Cond. No.                     3.73e+04
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The condition number is large, 3.73e+04. This might indicate that there are
strong multicollinearity or other numerical problems.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=0.11, p=0.914
Wilcoxon delta_H: statistic=16333.00, p=0.838
Mean ΔH = 0.0028  [-0.0477, 0.0532]
Paired t-test delta_H Changed: statistic=57.91, p=1.16e-125
Wilcoxon delta_H Changed: statistic=0.00, p=3.06e-34
Mean ΔH Changed = 1.2465  [1.2043, 1.2887]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=-0.24, p=0.807
Wilcoxon (p_top2_game vs p_top2_base): statistic=6687.00, p=2.54e-58
Mean Δp_top2 = -0.0000  [-0.0001, 0.0001] (n=455)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=16.14, p=1.2e-46
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=17326.00, p=8.08e-35
Mean ΔH_unchosen_baseline_set = 0.5440  [0.4780, 0.6101] (n=455)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  455
Model:                          Logit   Df Residuals:                      452
Method:                           MLE   Df Model:                            2
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.01680
Time:                        20:27:17   Log-Likelihood:                -306.31
converged:                       True   LL-Null:                       -311.55
Covariance Type:            nonrobust   LLR p-value:                  0.005330
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept        1.2652      0.847      1.494      0.135      -0.395       2.925
p1_z           -22.8512     12.396     -1.843      0.065     -47.147       1.445
I(p1_z ** 2)    -1.3971      1.017     -1.374      0.169      -3.389       0.595
================================================================================
AUC = 0.566

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                0.005151
Time:                        20:27:17   Log-Likelihood:                -340.44
converged:                       True   LL-Null:                       -342.20
Covariance Type:            nonrobust   LLR p-value:                   0.06044
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.2990      0.092     -3.235      0.001      -0.480      -0.118
game_entropy     9.3315      6.478      1.440      0.150      -3.366      22.029
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=10992.00, p=1.94e-57
Paired t-test (game_entropy vs capabilities_entropy): statistic=0.18, p=0.859
Mean capabilities_entropy-game_entropy = -0.0004  [-0.0051, 0.0043] (n=500)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      497
Method:                           MLE   Df Model:                            2
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.02107
Time:                        20:27:17   Log-Likelihood:                -335.00
converged:                       True   LL-Null:                       -342.20
Covariance Type:            nonrobust   LLR p-value:                 0.0007401
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -0.3894      0.099     -3.919      0.000      -0.584      -0.195
capabilities_entropy   172.4115     87.389      1.973      0.049       1.132     343.691
game_entropy             8.9880      6.287      1.430      0.153      -3.335      21.311
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.640000
                        1                 0.360000
Geography               0                 0.522727
                        1                 0.477273
Misc                    0                 0.554054
                        1                 0.445946
Music                   0                 0.625000
                        1                 0.375000
Other                   0                 0.615385
                        1                 0.384615
Politics                0                 0.545455
                        1                 0.454545
Science and technology  0                 0.540816
                        1                 0.459184
Sports                  1                 0.525000
                        0                 0.475000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.532544
                     1                 0.467456
Number               0                 0.525641
                     1                 0.474359
Other                0                 0.571429
                     1                 0.428571
Person               0                 0.633333
                     1                 0.366667
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.523810  0.476190           21
                       Number               0.666667  0.333333            9
                       Other                0.833333  0.166667           18
                       Person               0.592593  0.407407           27
Geography              Date                 0.400000  0.600000           15
                       Number               0.444444  0.555556           18
                       Other                0.818182  0.181818           11
Misc                   Date                 0.608696  0.391304           23
                       Number               0.555556  0.444444            9
                       Other                0.444444  0.555556           27
                       Person               0.666667  0.333333           15
Music                  Date                 0.500000  0.500000           12
                       Number               0.250000  0.750000            4
                       Other                0.750000  0.250000           12
                       Person               0.750000  0.250000           12
Other                  Date                 0.444444  0.555556           18
                       Number               0.857143  0.142857            7
                       Other                0.714286  0.285714           14
                       Person               0.615385  0.384615           13
Politics               Date                 0.583333  0.416667           36
                       Number               0.500000  0.500000            6
                       Other                0.450000  0.550000           20
                       Person               0.600000  0.400000           15
Science and technology Date                 0.600000  0.400000           35
                       Number               0.500000  0.500000           14
                       Other                0.421053  0.578947           19
                       Person               0.566667  0.433333           30
Sports                 Date                 0.333333  0.666667            9
                       Number               0.454545  0.545455           11
                       Other                0.333333  0.666667           12
                       Person               0.875000  0.125000            8

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      488
Method:                           MLE   Df Model:                           11
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.01121
Time:                        20:27:17   Log-Likelihood:                -338.37
converged:                       True   LL-Null:                       -342.20
Covariance Type:            nonrobust   LLR p-value:                    0.7426
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      0.0007      1.141      0.001      1.000      -2.235       2.237
C(topic_grouped)[T.Geography]                  0.3499      0.398      0.878      0.380      -0.431       1.131
C(topic_grouped)[T.Misc]                       0.3227      0.338      0.953      0.340      -0.341       0.986
C(topic_grouped)[T.Music]                      0.0470      0.407      0.115      0.908      -0.751       0.845
C(topic_grouped)[T.Other]                      0.0661      0.375      0.176      0.860      -0.669       0.801
C(topic_grouped)[T.Politics]                   0.3549      0.340      1.044      0.297      -0.311       1.021
C(topic_grouped)[T.Science and technology]     0.3945      0.317      1.245      0.213      -0.226       1.015
C(topic_grouped)[T.Sports]                     0.6304      0.402      1.570      0.116      -0.157       1.417
C(answer_type_grouped)[T.Number]              -0.0077      0.283     -0.027      0.978      -0.562       0.547
C(answer_type_grouped)[T.Other]               -0.1626      0.237     -0.687      0.492      -0.627       0.301
C(answer_type_grouped)[T.Person]              -0.3908      0.250     -1.561      0.118      -0.881       0.100
q_length                                      -0.0895      0.246     -0.364      0.716      -0.571       0.392
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.0036
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      487
Method:                           MLE   Df Model:                           12
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.02975
Time:                        20:27:17   Log-Likelihood:                -332.02
converged:                       True   LL-Null:                       -342.20
Covariance Type:            nonrobust   LLR p-value:                   0.06058
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -0.2992      1.159     -0.258      0.796      -2.570       1.972
C(topic_grouped)[T.Geography]                  0.4377      0.409      1.071      0.284      -0.363       1.238
C(topic_grouped)[T.Misc]                       0.4101      0.348      1.180      0.238      -0.271       1.092
C(topic_grouped)[T.Music]                      0.1883      0.414      0.454      0.650      -0.624       1.001
C(topic_grouped)[T.Other]                      0.1335      0.385      0.346      0.729      -0.622       0.889
C(topic_grouped)[T.Politics]                   0.4959      0.348      1.423      0.155      -0.187       1.179
C(topic_grouped)[T.Science and technology]     0.5186      0.325      1.595      0.111      -0.119       1.156
C(topic_grouped)[T.Sports]                     0.7557      0.409      1.849      0.064      -0.045       1.557
C(answer_type_grouped)[T.Number]              -0.0057      0.286     -0.020      0.984      -0.565       0.554
C(answer_type_grouped)[T.Other]               -0.1704      0.240     -0.711      0.477      -0.640       0.299
C(answer_type_grouped)[T.Person]              -0.4056      0.253     -1.602      0.109      -0.902       0.091
q_length                                      -0.0659      0.248     -0.266      0.790      -0.552       0.420
capabilities_entropy                         194.5043     92.511      2.102      0.036      13.185     375.823
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      487
Method:                           MLE   Df Model:                           12
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.01677
Time:                        20:27:17   Log-Likelihood:                -336.47
converged:                       True   LL-Null:                       -342.20
Covariance Type:            nonrobust   LLR p-value:                    0.4886
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      0.0885      1.147      0.077      0.939      -2.160       2.337
C(topic_grouped)[T.Geography]                  0.3768      0.399      0.943      0.346      -0.406       1.160
C(topic_grouped)[T.Misc]                       0.3069      0.340      0.901      0.367      -0.360       0.974
C(topic_grouped)[T.Music]                      0.0776      0.408      0.190      0.849      -0.723       0.878
C(topic_grouped)[T.Other]                      0.0965      0.376      0.256      0.798      -0.641       0.834
C(topic_grouped)[T.Politics]                   0.3660      0.342      1.072      0.284      -0.303       1.035
C(topic_grouped)[T.Science and technology]     0.4020      0.319      1.262      0.207      -0.223       1.027
C(topic_grouped)[T.Sports]                     0.6635      0.403      1.647      0.099      -0.126       1.453
C(answer_type_grouped)[T.Number]               0.0073      0.283      0.026      0.979      -0.548       0.562
C(answer_type_grouped)[T.Other]               -0.1750      0.238     -0.735      0.462      -0.642       0.292
C(answer_type_grouped)[T.Person]              -0.3972      0.251     -1.581      0.114      -0.890       0.095
q_length                                      -0.1188      0.247     -0.481      0.630      -0.603       0.365
game_entropy                                   9.9815      6.726      1.484      0.138      -3.201      23.164
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      486
Method:                           MLE   Df Model:                           13
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.03509
Time:                        20:27:17   Log-Likelihood:                -330.20
converged:                       True   LL-Null:                       -342.20
Covariance Type:            nonrobust   LLR p-value:                   0.03101
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -0.2098      1.165     -0.180      0.857      -2.493       2.074
C(topic_grouped)[T.Geography]                  0.4646      0.410      1.134      0.257      -0.338       1.268
C(topic_grouped)[T.Misc]                       0.3958      0.350      1.131      0.258      -0.290       1.082
C(topic_grouped)[T.Music]                      0.2185      0.416      0.526      0.599      -0.596       1.033
C(topic_grouped)[T.Other]                      0.1632      0.387      0.422      0.673      -0.595       0.921
C(topic_grouped)[T.Politics]                   0.5071      0.350      1.448      0.147      -0.179       1.193
C(topic_grouped)[T.Science and technology]     0.5259      0.327      1.607      0.108      -0.115       1.167
C(topic_grouped)[T.Sports]                     0.7882      0.410      1.923      0.055      -0.015       1.592
C(answer_type_grouped)[T.Number]               0.0099      0.286      0.035      0.972      -0.551       0.570
C(answer_type_grouped)[T.Other]               -0.1826      0.241     -0.758      0.449      -0.655       0.290
C(answer_type_grouped)[T.Person]              -0.4109      0.254     -1.618      0.106      -0.909       0.087
q_length                                      -0.0952      0.249     -0.382      0.703      -0.584       0.394
capabilities_entropy                         191.0264     91.359      2.091      0.037      11.966     370.087
game_entropy                                   9.5544      6.502      1.469      0.142      -3.189      22.298
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing gemini-2.5-flash-preview-04-17 (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_new/gemini-2.5-flash-preview-04-17_SimpleMC_redacted_cor_temp0.0_1751802958_game_data.json', './sc_logs_new/gemini-2.5-flash-preview-04-17_SimpleMC_redacted_temp0.0_1751726354_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    324
1    176
Name: count, dtype: int64

Answer change%: 0.3520 [0.3101378120217051, 0.39386218797829486] (n=500)
P-value vs 25%: 1.792e-06; P-value vs 0%: 5.071e-61
Phase 2 self-accuracy: 0.3239 [0.2547299049864159, 0.3929973677408568] (n=176)
P-value vs 25%: 0.03625; P-value vs 33%: 0.7956

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                0.002049
Time:                        20:27:17   Log-Likelihood:                -323.67
converged:                       True   LL-Null:                       -324.34
Covariance Type:            nonrobust   LLR p-value:                    0.2489
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.6217      0.094     -6.595      0.000      -0.806      -0.437
game_entropy     1.0779      1.024      1.053      0.292      -0.928       3.084
================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.746667
                        1                 0.253333
Geography               0                 0.545455
                        1                 0.454545
Misc                    0                 0.500000
                        1                 0.500000
Music                   0                 0.650000
                        1                 0.350000
Other                   0                 0.807692
                        1                 0.192308
Politics                0                 0.701299
                        1                 0.298701
Science and technology  0                 0.591837
                        1                 0.408163
Sports                  0                 0.675000
                        1                 0.325000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.644970
                     1                 0.355030
Number               0                 0.512821
                     1                 0.487179
Other                0                 0.669173
                     1                 0.330827
Person               0                 0.716667
                     1                 0.283333
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.809524  0.190476           21
                       Number               0.444444  0.555556            9
                       Other                0.666667  0.333333           18
                       Person               0.851852  0.148148           27
Geography              Date                 0.466667  0.533333           15
                       Number               0.500000  0.500000           18
                       Other                0.727273  0.272727           11
Misc                   Date                 0.304348  0.695652           23
                       Number               0.777778  0.222222            9
                       Other                0.629630  0.370370           27
                       Person               0.400000  0.600000           15
Music                  Date                 0.750000  0.250000           12
                       Number               0.500000  0.500000            4
                       Other                0.583333  0.416667           12
                       Person               0.666667  0.333333           12
Other                  Date                 0.777778  0.222222           18
                       Number               0.714286  0.285714            7
                       Other                0.785714  0.214286           14
                       Person               0.923077  0.076923           13
Politics               Date                 0.694444  0.305556           36
                       Number               0.500000  0.500000            6
                       Other                0.800000  0.200000           20
                       Person               0.666667  0.333333           15
Science and technology Date                 0.628571  0.371429           35
                       Number               0.357143  0.642857           14
                       Other                0.578947  0.421053           19
                       Person               0.666667  0.333333           30
Sports                 Date                 0.888889  0.111111            9
                       Number               0.454545  0.545455           11
                       Other                0.583333  0.416667           12
                       Person               0.875000  0.125000            8

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      488
Method:                           MLE   Df Model:                           11
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.04375
Time:                        20:27:17   Log-Likelihood:                -310.15
converged:                       True   LL-Null:                       -324.34
Covariance Type:            nonrobust   LLR p-value:                  0.002833
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.3452      1.209     -1.112      0.266      -3.716       1.025
C(topic_grouped)[T.Geography]                  0.6557      0.418      1.570      0.116      -0.163       1.474
C(topic_grouped)[T.Misc]                       1.0655      0.357      2.981      0.003       0.365       1.766
C(topic_grouped)[T.Music]                      0.4748      0.428      1.109      0.267      -0.364       1.314
C(topic_grouped)[T.Other]                     -0.3921      0.444     -0.882      0.378      -1.263       0.479
C(topic_grouped)[T.Politics]                   0.1936      0.374      0.518      0.605      -0.539       0.926
C(topic_grouped)[T.Science and technology]     0.6784      0.339      1.999      0.046       0.013       1.344
C(topic_grouped)[T.Sports]                     0.2266      0.437      0.518      0.604      -0.630       1.083
C(answer_type_grouped)[T.Number]               0.5230      0.291      1.794      0.073      -0.048       1.094
C(answer_type_grouped)[T.Other]               -0.1391      0.252     -0.551      0.582      -0.634       0.355
C(answer_type_grouped)[T.Person]              -0.2941      0.269     -1.094      0.274      -0.821       0.233
q_length                                       0.0730      0.260      0.281      0.779      -0.436       0.582
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      487
Method:                           MLE   Df Model:                           12
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.04530
Time:                        20:27:17   Log-Likelihood:                -309.65
converged:                       True   LL-Null:                       -324.34
Covariance Type:            nonrobust   LLR p-value:                  0.003453
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.3875      1.211     -1.145      0.252      -3.762       0.987
C(topic_grouped)[T.Geography]                  0.6121      0.421      1.455      0.146      -0.212       1.437
C(topic_grouped)[T.Misc]                       1.0599      0.358      2.964      0.003       0.359       1.761
C(topic_grouped)[T.Music]                      0.4755      0.428      1.110      0.267      -0.364       1.315
C(topic_grouped)[T.Other]                     -0.3904      0.444     -0.878      0.380      -1.262       0.481
C(topic_grouped)[T.Politics]                   0.1961      0.374      0.524      0.600      -0.537       0.929
C(topic_grouped)[T.Science and technology]     0.6782      0.340      1.997      0.046       0.013       1.344
C(topic_grouped)[T.Sports]                     0.1781      0.442      0.403      0.687      -0.688       1.044
C(answer_type_grouped)[T.Number]               0.5482      0.293      1.872      0.061      -0.026       1.122
C(answer_type_grouped)[T.Other]               -0.1152      0.254     -0.454      0.650      -0.612       0.382
C(answer_type_grouped)[T.Person]              -0.2768      0.270     -1.026      0.305      -0.805       0.252
q_length                                       0.0787      0.260      0.303      0.762      -0.431       0.588
game_entropy                                   0.9507      1.009      0.942      0.346      -1.027       2.929
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing gemini-2.5-flash_nothink (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_new/gemini-2.5-flash_nothink_SimpleMC_redacted_cor_temp1.0_1757984473_game_data.json', './sc_logs_new/gemini-2.5-flash_nothink_SimpleMC_redacted_temp1.0_1758161562_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    302
1    198
Name: count, dtype: int64

Answer change%: 0.3960 [0.3531324018268132, 0.4388675981731868] (n=500)
P-value vs 25%: 2.467e-11; P-value vs 0%: 2.876e-73
Phase 2 self-accuracy: 0.3131 [0.24853382890469403, 0.3777287973579323] (n=198)
P-value vs 25%: 0.05543; P-value vs 33%: 0.5466

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.1023
Time:                        20:27:17   Log-Likelihood:                -301.35
converged:                       True   LL-Null:                       -335.68
Covariance Type:            nonrobust   LLR p-value:                 1.173e-16
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          2.0589      0.326      6.323      0.000       1.421       2.697
p_i_capability    -3.5846      0.459     -7.809      0.000      -4.484      -2.685
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.1037
Time:                        20:27:17   Log-Likelihood:                -300.87
converged:                       True   LL-Null:                       -335.68
Covariance Type:            nonrobust   LLR p-value:                 7.229e-17
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.7932      0.212     -8.450      0.000      -2.209      -1.377
capabilities_entropy     1.2845      0.166      7.727      0.000       0.959       1.610
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.6111 [0.5432, 0.6790] (n=198)
                  P-value vs 33.3%: 1.076e-15

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=12.00, p=2.21e-27
Wilcoxon delta_p: statistic=6881.00, p=6.17e-26
Mean Δp = 0.1243  [0.1040, 0.1446]
Idea 1 N = 302; 

  Idea 1.5: Calibration Metrics
  NLL: 1.3658, Signed ECE (overconf pos under neg): -0.0360, ECE: 0.1347 (n=500)
  Brier: 0.0715, Reliability (absolute calibration error; lower better): 0.0335, Resolution (relative calibration quality; higher better): 0.2111, Uncertainty: 0.2500 (n=500)
  AUROC: 0.9931

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.605
Model:                            OLS   Adj. R-squared:                  0.603
Method:                 Least Squares   F-statistic:                     252.9
Date:                Fri, 19 Sep 2025   Prob (F-statistic):           1.76e-99
Time:                        20:27:17   Log-Likelihood:                 253.90
No. Observations:                 499   AIC:                            -499.8
Df Residuals:                     495   BIC:                            -482.9
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.0342      0.032     -1.082      0.280      -0.096       0.028
p1                    0.2044      0.039      5.210      0.000       0.127       0.282
answer_changed       -0.1927      0.046     -4.184      0.000      -0.283      -0.102
p1:answer_changed     0.7965      0.066     12.149      0.000       0.668       0.925
==============================================================================
Omnibus:                       16.862   Durbin-Watson:                   1.942
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               20.783
Skew:                           0.344   Prob(JB):                     3.07e-05
Kurtosis:                       3.726   Cond. No.                         17.6
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-9.85, p=4.9e-20
Wilcoxon delta_H: statistic=8726.00, p=1.2e-20
Mean ΔH = -0.2349  [-0.2816, -0.1882]
Paired t-test delta_H Changed: statistic=-3.94, p=0.000114
Wilcoxon delta_H Changed: statistic=6632.00, p=6.7e-05
Mean ΔH Changed = -0.0986  [-0.1477, -0.0495]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=-22.43, p=1.47e-77
Wilcoxon (p_top2_game vs p_top2_base): statistic=6231.00, p=3.64e-68
Mean Δp_top2 = -0.1147  [-0.1247, -0.1047] (n=500)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=-10.21, p=2.35e-22
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=30477.00, p=2.63e-23
Mean ΔH_unchosen_baseline_set = -0.1809  [-0.2157, -0.1462] (n=500)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      497
Method:                           MLE   Df Model:                            2
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.1088
Time:                        20:27:17   Log-Likelihood:                -299.14
converged:                       True   LL-Null:                       -335.68
Covariance Type:            nonrobust   LLR p-value:                 1.358e-16
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.2407      0.152     -1.584      0.113      -0.538       0.057
p1_z            -0.8651      0.110     -7.855      0.000      -1.081      -0.649
I(p1_z ** 2)    -0.2723      0.130     -2.097      0.036      -0.527      -0.018
================================================================================
AUC = 0.723

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.1502
Time:                        20:27:17   Log-Likelihood:                -285.27
converged:                       True   LL-Null:                       -335.68
Covariance Type:            nonrobust   LLR p-value:                 1.005e-23
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -3.3421      0.393     -8.502      0.000      -4.113      -2.572
game_entropy     1.9788      0.240      8.234      0.000       1.508       2.450
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=13841.00, p=1.81e-51
Paired t-test (game_entropy vs capabilities_entropy): statistic=17.70, p=9.5e-55
Mean capabilities_entropy-game_entropy = -0.3706  [-0.4117, -0.3296] (n=500)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      497
Method:                           MLE   Df Model:                            2
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.1564
Time:                        20:27:17   Log-Likelihood:                -283.16
converged:                       True   LL-Null:                       -335.68
Covariance Type:            nonrobust   LLR p-value:                 1.559e-23
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -3.2908      0.391     -8.423      0.000      -4.056      -2.525
capabilities_entropy     0.4450      0.218      2.045      0.041       0.019       0.871
game_entropy             1.6178      0.293      5.515      0.000       1.043       2.193
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.640000
                        1                 0.360000
Geography               0                 0.500000
                        1                 0.500000
Misc                    0                 0.500000
                        1                 0.500000
Music                   0                 0.725000
                        1                 0.275000
Other                   0                 0.557692
                        1                 0.442308
Politics                0                 0.675325
                        1                 0.324675
Science and technology  0                 0.591837
                        1                 0.408163
Sports                  0                 0.675000
                        1                 0.325000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 1                 0.514793
                     0                 0.485207
Number               0                 0.512821
                     1                 0.487179
Other                0                 0.676692
                     1                 0.323308
Person               0                 0.750000
                     1                 0.250000
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.285714  0.714286           21
                       Number               0.555556  0.444444            9
                       Other                0.777778  0.222222           18
                       Person               0.851852  0.148148           27
Geography              Date                 0.333333  0.666667           15
                       Number               0.500000  0.500000           18
                       Other                0.727273  0.272727           11
Misc                   Date                 0.434783  0.565217           23
                       Number               0.222222  0.777778            9
                       Other                0.592593  0.407407           27
                       Person               0.600000  0.400000           15
Music                  Date                 0.666667  0.333333           12
                       Number               0.500000  0.500000            4
                       Other                0.666667  0.333333           12
                       Person               0.916667  0.083333           12
Other                  Date                 0.388889  0.611111           18
                       Number               0.428571  0.571429            7
                       Other                0.714286  0.285714           14
                       Person               0.692308  0.307692           13
Politics               Date                 0.694444  0.305556           36
                       Number               0.500000  0.500000            6
                       Other                0.750000  0.250000           20
                       Person               0.600000  0.400000           15
Science and technology Date                 0.457143  0.542857           35
                       Number               0.642857  0.357143           14
                       Other                0.578947  0.421053           19
                       Person               0.733333  0.266667           30
Sports                 Date                 0.555556  0.444444            9
                       Number               0.636364  0.363636           11
                       Other                0.666667  0.333333           12
                       Person               0.875000  0.125000            8

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      488
Method:                           MLE   Df Model:                           11
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.06025
Time:                        20:27:17   Log-Likelihood:                -315.45
converged:                       True   LL-Null:                       -335.68
Covariance Type:            nonrobust   LLR p-value:                 2.994e-05
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      2.1002      1.201      1.749      0.080      -0.254       4.454
C(topic_grouped)[T.Geography]                  0.2114      0.407      0.520      0.603      -0.586       1.008
C(topic_grouped)[T.Misc]                       0.5483      0.347      1.578      0.115      -0.133       1.229
C(topic_grouped)[T.Music]                     -0.4583      0.441     -1.039      0.299      -1.323       0.406
C(topic_grouped)[T.Other]                      0.2484      0.382      0.650      0.516      -0.501       0.998
C(topic_grouped)[T.Politics]                  -0.2461      0.360     -0.683      0.495      -0.953       0.461
C(topic_grouped)[T.Science and technology]     0.1550      0.329      0.472      0.637      -0.489       0.799
C(topic_grouped)[T.Sports]                    -0.2664      0.429     -0.621      0.535      -1.108       0.575
C(answer_type_grouped)[T.Number]              -0.1345      0.286     -0.470      0.639      -0.696       0.427
C(answer_type_grouped)[T.Other]               -0.8858      0.248     -3.565      0.000      -1.373      -0.399
C(answer_type_grouped)[T.Person]              -1.2189      0.270     -4.516      0.000      -1.748      -0.690
q_length                                      -0.4587      0.259     -1.769      0.077      -0.967       0.050
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 1.0062
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      487
Method:                           MLE   Df Model:                           12
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.1337
Time:                        20:27:17   Log-Likelihood:                -290.79
converged:                       True   LL-Null:                       -335.68
Covariance Type:            nonrobust   LLR p-value:                 5.438e-14
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      0.7593      1.277      0.595      0.552      -1.744       3.262
C(topic_grouped)[T.Geography]                  0.0957      0.431      0.222      0.824      -0.750       0.941
C(topic_grouped)[T.Misc]                       0.4982      0.363      1.371      0.170      -0.214       1.210
C(topic_grouped)[T.Music]                     -0.5410      0.462     -1.171      0.242      -1.446       0.365
C(topic_grouped)[T.Other]                      0.1754      0.402      0.436      0.663      -0.612       0.963
C(topic_grouped)[T.Politics]                  -0.1787      0.379     -0.472      0.637      -0.921       0.563
C(topic_grouped)[T.Science and technology]     0.1341      0.344      0.390      0.697      -0.540       0.808
C(topic_grouped)[T.Sports]                    -0.2732      0.453     -0.604      0.546      -1.160       0.614
C(answer_type_grouped)[T.Number]              -0.0405      0.300     -0.135      0.893      -0.629       0.548
C(answer_type_grouped)[T.Other]               -0.5796      0.264     -2.196      0.028      -1.097      -0.062
C(answer_type_grouped)[T.Person]              -0.8047      0.289     -2.789      0.005      -1.370      -0.239
q_length                                      -0.4712      0.273     -1.724      0.085      -1.007       0.065
capabilities_entropy                           1.1565      0.174      6.638      0.000       0.815       1.498
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      487
Method:                           MLE   Df Model:                           12
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.1750
Time:                        20:27:17   Log-Likelihood:                -276.92
converged:                       True   LL-Null:                       -335.68
Covariance Type:            nonrobust   LLR p-value:                 1.932e-19
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -0.1871      1.322     -0.141      0.888      -2.779       2.405
C(topic_grouped)[T.Geography]                  0.0134      0.447      0.030      0.976      -0.863       0.889
C(topic_grouped)[T.Misc]                       0.2995      0.379      0.790      0.429      -0.443       1.042
C(topic_grouped)[T.Music]                     -0.7682      0.481     -1.596      0.111      -1.712       0.175
C(topic_grouped)[T.Other]                     -0.0972      0.421     -0.231      0.817      -0.922       0.727
C(topic_grouped)[T.Politics]                  -0.4304      0.396     -1.088      0.277      -1.206       0.345
C(topic_grouped)[T.Science and technology]    -0.0383      0.362     -0.106      0.916      -0.748       0.671
C(topic_grouped)[T.Sports]                    -0.4085      0.467     -0.875      0.382      -1.324       0.507
C(answer_type_grouped)[T.Number]              -0.2753      0.300     -0.918      0.359      -0.863       0.313
C(answer_type_grouped)[T.Other]               -0.3380      0.277     -1.218      0.223      -0.882       0.206
C(answer_type_grouped)[T.Person]              -0.6115      0.301     -2.035      0.042      -1.201      -0.022
q_length                                      -0.5959      0.279     -2.133      0.033      -1.144      -0.048
game_entropy                                   1.9248      0.260      7.407      0.000       1.415       2.434
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      486
Method:                           MLE   Df Model:                           13
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.1794
Time:                        20:27:17   Log-Likelihood:                -275.45
converged:                       True   LL-Null:                       -335.68
Covariance Type:            nonrobust   LLR p-value:                 1.631e-19
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -0.2637      1.328     -0.199      0.843      -2.866       2.339
C(topic_grouped)[T.Geography]                  0.0035      0.449      0.008      0.994      -0.877       0.884
C(topic_grouped)[T.Misc]                       0.3278      0.380      0.863      0.388      -0.417       1.072
C(topic_grouped)[T.Music]                     -0.7631      0.483     -1.581      0.114      -1.709       0.183
C(topic_grouped)[T.Other]                     -0.0753      0.422     -0.179      0.858      -0.902       0.751
C(topic_grouped)[T.Politics]                  -0.3813      0.398     -0.958      0.338      -1.161       0.398
C(topic_grouped)[T.Science and technology]    -0.0155      0.363     -0.043      0.966      -0.727       0.696
C(topic_grouped)[T.Sports]                    -0.3849      0.469     -0.820      0.412      -1.305       0.535
C(answer_type_grouped)[T.Number]              -0.2188      0.304     -0.720      0.471      -0.814       0.377
C(answer_type_grouped)[T.Other]               -0.3205      0.278     -1.151      0.250      -0.866       0.225
C(answer_type_grouped)[T.Person]              -0.5663      0.302     -1.873      0.061      -1.159       0.026
q_length                                      -0.5805      0.281     -2.067      0.039      -1.131      -0.030
capabilities_entropy                           0.3838      0.224      1.713      0.087      -0.055       0.823
game_entropy                                   1.6179      0.313      5.177      0.000       1.005       2.230
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing gemini-2.5-flash_think (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_new/gemini-2.5-flash_think_SimpleMC_redacted_cor_temp1.0_1758281503_game_data.json', './sc_logs_new/gemini-2.5-flash_think_SimpleMC_redacted_temp1.0_1758262178_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    286
1    214
Name: count, dtype: int64

Answer change%: 0.4280 [0.38463064255382484, 0.47136935744617514] (n=500)
P-value vs 25%: 8.678e-16; P-value vs 0%: 2.365e-83
Phase 2 self-accuracy: 0.2850 [0.2245630689019295, 0.3455303890419957] (n=214)
P-value vs 25%: 0.2561; P-value vs 33%: 0.1202

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                0.002020
Time:                        20:27:17   Log-Likelihood:                -340.68
converged:                       True   LL-Null:                       -341.37
Covariance Type:            nonrobust   LLR p-value:                    0.2403
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept         52.3889     75.929      0.690      0.490     -96.430     201.208
p_i_capability   -52.6854     75.934     -0.694      0.488    -201.513      96.142
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                0.001921
Time:                        20:27:17   Log-Likelihood:                -340.72
converged:                       True   LL-Null:                       -341.37
Covariance Type:            nonrobust   LLR p-value:                    0.2521
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -0.2977      0.091     -3.282      0.001      -0.475      -0.120
capabilities_entropy     7.4864     10.078      0.743      0.458     -12.267      27.240
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.3458 [0.2821, 0.4095] (n=214)
                  P-value vs 33.3%: 0.7015

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=2.62, p=0.00916
Wilcoxon delta_p: statistic=6241.50, p=1.98e-24
Mean Δp = 0.0118  [0.0030, 0.0205]
Idea 1 N = 286; 

  Idea 1.5: Calibration Metrics
  NLL: 3.7978, Signed ECE (overconf pos under neg): -0.0000, ECE: 0.0000 (n=480)
  Brier: 0.0000, Reliability (absolute calibration error; lower better): 0.0000, Resolution (relative calibration quality; higher better): 0.2066, Uncertainty: 0.2066 (n=480)
  AUROC: 1.0000

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.981
Model:                            OLS   Adj. R-squared:                  0.981
Method:                 Least Squares   F-statistic:                     8445.
Date:                Fri, 19 Sep 2025   Prob (F-statistic):               0.00
Time:                        20:27:18   Log-Likelihood:                 634.90
No. Observations:                 495   AIC:                            -1262.
Df Residuals:                     491   BIC:                            -1245.
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept             0.7581     11.575      0.066      0.948     -21.984      23.500
p1                   -0.7464     11.575     -0.064      0.949     -23.489      21.996
answer_changed       -0.6314     11.619     -0.054      0.957     -23.460      22.197
p1:answer_changed     1.6076     11.619      0.138      0.890     -21.222      24.437
==============================================================================
Omnibus:                      558.190   Durbin-Watson:                   1.958
Prob(Omnibus):                  0.000   Jarque-Bera (JB):            60964.934
Skew:                           4.980   Prob(JB):                         0.00
Kurtosis:                      56.448   Cond. No.                     1.20e+04
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The condition number is large, 1.2e+04. This might indicate that there are
strong multicollinearity or other numerical problems.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-5.17, p=4.45e-07
Wilcoxon delta_H: statistic=13879.00, p=2.09e-06
Mean ΔH = -0.1003  [-0.1383, -0.0623]
Paired t-test delta_H Changed: statistic=38.86, p=1.19e-98
Wilcoxon delta_H Changed: statistic=80.00, p=2.24e-36
Mean ΔH Changed = 1.1345  [1.0773, 1.1918]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=-4.06, p=5.69e-05
Wilcoxon (p_top2_game vs p_top2_base): statistic=13721.00, p=1.03e-51
Mean Δp_top2 = -0.0099  [-0.0146, -0.0051] (n=500)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=13.36, p=4.95e-35
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=30060.00, p=7.14e-24
Mean ΔH_unchosen_baseline_set = 0.4282  [0.3654, 0.4910] (n=500)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      497
Method:                           MLE   Df Model:                            2
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                0.003138
Time:                        20:27:18   Log-Likelihood:                -340.30
converged:                       True   LL-Null:                       -341.37
Covariance Type:            nonrobust   LLR p-value:                    0.3426
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.3310      0.107     -3.089      0.002      -0.541      -0.121
p1_z             0.7902      1.224      0.646      0.518      -1.608       3.189
I(p1_z ** 2)     0.0499      0.084      0.593      0.553      -0.115       0.215
================================================================================
AUC = 0.497

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                0.005862
Time:                        20:27:18   Log-Likelihood:                -339.37
converged:                       True   LL-Null:                       -341.37
Covariance Type:            nonrobust   LLR p-value:                   0.04544
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.3290      0.093     -3.550      0.000      -0.511      -0.147
game_entropy     0.5798      0.300      1.931      0.053      -0.009       1.168
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=17251.00, p=9.18e-45
Paired t-test (game_entropy vs capabilities_entropy): statistic=4.68, p=3.74e-06
Mean capabilities_entropy-game_entropy = -0.0663  [-0.0940, -0.0385] (n=500)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      497
Method:                           MLE   Df Model:                            2
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                0.007755
Time:                        20:27:18   Log-Likelihood:                -338.72
converged:                       True   LL-Null:                       -341.37
Covariance Type:            nonrobust   LLR p-value:                   0.07085
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -0.3366      0.093     -3.619      0.000      -0.519      -0.154
capabilities_entropy     7.3877      9.934      0.744      0.457     -12.083      26.858
game_entropy             0.5781      0.300      1.928      0.054      -0.010       1.166
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.640000
                        1                 0.360000
Geography               0                 0.613636
                        1                 0.386364
Misc                    1                 0.554054
                        0                 0.445946
Music                   1                 0.525000
                        0                 0.475000
Other                   0                 0.557692
                        1                 0.442308
Politics                0                 0.597403
                        1                 0.402597
Science and technology  0                 0.622449
                        1                 0.377551
Sports                  0                 0.575000
                        1                 0.425000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.520710
                     1                 0.479290
Number               0                 0.551282
                     1                 0.448718
Other                0                 0.654135
                     1                 0.345865
Person               0                 0.566667
                     1                 0.433333
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.666667  0.333333           21
                       Number               0.666667  0.333333            9
                       Other                0.833333  0.166667           18
                       Person               0.481481  0.518519           27
Geography              Date                 0.400000  0.600000           15
                       Number               0.611111  0.388889           18
                       Other                0.909091  0.090909           11
Misc                   Date                 0.347826  0.652174           23
                       Number               0.555556  0.444444            9
                       Other                0.481481  0.518519           27
                       Person               0.466667  0.533333           15
Music                  Date                 0.666667  0.333333           12
                       Number               0.250000  0.750000            4
                       Other                0.250000  0.750000           12
                       Person               0.583333  0.416667           12
Other                  Date                 0.444444  0.555556           18
                       Number               0.571429  0.428571            7
                       Other                0.714286  0.285714           14
                       Person               0.538462  0.461538           13
Politics               Date                 0.555556  0.444444           36
                       Number               0.333333  0.666667            6
                       Other                0.750000  0.250000           20
                       Person               0.600000  0.400000           15
Science and technology Date                 0.542857  0.457143           35
                       Number               0.714286  0.285714           14
                       Other                0.684211  0.315789           19
                       Person               0.633333  0.366667           30
Sports                 Date                 0.555556  0.444444            9
                       Number               0.363636  0.636364           11
                       Other                0.666667  0.333333           12
                       Person               0.750000  0.250000            8

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      488
Method:                           MLE   Df Model:                           11
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.02980
Time:                        20:27:18   Log-Likelihood:                -331.20
converged:                       True   LL-Null:                       -341.37
Covariance Type:            nonrobust   LLR p-value:                   0.04086
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -2.4857      1.164     -2.135      0.033      -4.768      -0.204
C(topic_grouped)[T.Geography]                  0.1179      0.409      0.288      0.773      -0.684       0.920
C(topic_grouped)[T.Misc]                       0.8514      0.342      2.487      0.013       0.180       1.522
C(topic_grouped)[T.Music]                      0.7399      0.403      1.835      0.067      -0.050       1.530
C(topic_grouped)[T.Other]                      0.3656      0.374      0.978      0.328      -0.367       1.098
C(topic_grouped)[T.Politics]                   0.0593      0.346      0.172      0.864      -0.618       0.737
C(topic_grouped)[T.Science and technology]     0.0019      0.323      0.006      0.995      -0.631       0.634
C(topic_grouped)[T.Sports]                     0.3031      0.408      0.743      0.458      -0.497       1.103
C(answer_type_grouped)[T.Number]              -0.1319      0.287     -0.460      0.646      -0.694       0.430
C(answer_type_grouped)[T.Other]               -0.6081      0.245     -2.479      0.013      -1.089      -0.127
C(answer_type_grouped)[T.Person]              -0.1434      0.249     -0.576      0.565      -0.632       0.345
q_length                                       0.4725      0.250      1.890      0.059      -0.018       0.962
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.0013
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      487
Method:                           MLE   Df Model:                           12
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.03161
Time:                        20:27:18   Log-Likelihood:                -330.58
converged:                       True   LL-Null:                       -341.37
Covariance Type:            nonrobust   LLR p-value:                   0.04246
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -2.5426      1.166     -2.180      0.029      -4.829      -0.257
C(topic_grouped)[T.Geography]                  0.1217      0.410      0.297      0.766      -0.681       0.924
C(topic_grouped)[T.Misc]                       0.8195      0.344      2.385      0.017       0.146       1.493
C(topic_grouped)[T.Music]                      0.7432      0.403      1.842      0.065      -0.048       1.534
C(topic_grouped)[T.Other]                      0.3669      0.374      0.981      0.326      -0.366       1.100
C(topic_grouped)[T.Politics]                   0.0577      0.346      0.167      0.867      -0.620       0.735
C(topic_grouped)[T.Science and technology]    -0.0022      0.323     -0.007      0.995      -0.635       0.631
C(topic_grouped)[T.Sports]                     0.3045      0.408      0.746      0.456      -0.496       1.105
C(answer_type_grouped)[T.Number]              -0.1389      0.287     -0.484      0.628      -0.701       0.424
C(answer_type_grouped)[T.Other]               -0.6218      0.246     -2.529      0.011      -1.104      -0.140
C(answer_type_grouped)[T.Person]              -0.1433      0.249     -0.575      0.565      -0.631       0.345
q_length                                       0.4855      0.250      1.938      0.053      -0.005       0.976
capabilities_entropy                           6.8290      8.713      0.784      0.433     -10.247      23.905
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      487
Method:                           MLE   Df Model:                           12
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.03534
Time:                        20:27:18   Log-Likelihood:                -329.31
converged:                       True   LL-Null:                       -341.37
Covariance Type:            nonrobust   LLR p-value:                   0.01956
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -2.4643      1.170     -2.107      0.035      -4.757      -0.172
C(topic_grouped)[T.Geography]                  0.1250      0.411      0.304      0.761      -0.680       0.930
C(topic_grouped)[T.Misc]                       0.8668      0.343      2.527      0.012       0.194       1.539
C(topic_grouped)[T.Music]                      0.7528      0.403      1.866      0.062      -0.038       1.544
C(topic_grouped)[T.Other]                      0.3220      0.377      0.854      0.393      -0.417       1.061
C(topic_grouped)[T.Politics]                   0.0310      0.348      0.089      0.929      -0.651       0.713
C(topic_grouped)[T.Science and technology]     0.0043      0.324      0.013      0.989      -0.631       0.639
C(topic_grouped)[T.Sports]                     0.3138      0.409      0.768      0.442      -0.487       1.115
C(answer_type_grouped)[T.Number]              -0.1375      0.288     -0.478      0.633      -0.702       0.427
C(answer_type_grouped)[T.Other]               -0.5920      0.246     -2.403      0.016      -1.075      -0.109
C(answer_type_grouped)[T.Person]              -0.1382      0.250     -0.553      0.580      -0.628       0.352
q_length                                       0.4589      0.251      1.826      0.068      -0.034       0.951
game_entropy                                   0.5719      0.304      1.883      0.060      -0.024       1.167
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      486
Method:                           MLE   Df Model:                           13
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.03707
Time:                        20:27:18   Log-Likelihood:                -328.72
converged:                       True   LL-Null:                       -341.37
Covariance Type:            nonrobust   LLR p-value:                   0.02100
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -2.5208      1.172     -2.152      0.031      -4.817      -0.224
C(topic_grouped)[T.Geography]                  0.1286      0.411      0.313      0.754      -0.676       0.934
C(topic_grouped)[T.Misc]                       0.8357      0.344      2.427      0.015       0.161       1.510
C(topic_grouped)[T.Music]                      0.7559      0.404      1.872      0.061      -0.035       1.547
C(topic_grouped)[T.Other]                      0.3237      0.377      0.858      0.391      -0.416       1.063
C(topic_grouped)[T.Politics]                   0.0296      0.348      0.085      0.932      -0.653       0.712
C(topic_grouped)[T.Science and technology]     0.0003      0.324      0.001      0.999      -0.635       0.636
C(topic_grouped)[T.Sports]                     0.3152      0.409      0.771      0.441      -0.486       1.116
C(answer_type_grouped)[T.Number]              -0.1443      0.288     -0.501      0.616      -0.709       0.420
C(answer_type_grouped)[T.Other]               -0.6057      0.247     -2.453      0.014      -1.090      -0.122
C(answer_type_grouped)[T.Person]              -0.1381      0.250     -0.553      0.581      -0.628       0.352
q_length                                       0.4718      0.252      1.874      0.061      -0.022       0.965
capabilities_entropy                           6.6738      8.639      0.773      0.440     -10.258      23.606
game_entropy                                   0.5676      0.304      1.870      0.061      -0.027       1.162
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing gpt-4.1-2025-04-14 (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_new/gpt-4.1-2025-04-14_SimpleMC_redacted_cor_temp1.0_1757988452_game_data.json', './sc_logs_new/gpt-4.1-2025-04-14_SimpleMC_redacted_temp1.0_1757987360_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    325
1    175
Name: count, dtype: int64

Answer change%: 0.3500 [0.30819253938092117, 0.3918074606190788] (n=500)
P-value vs 25%: 2.758e-06; P-value vs 0%: 1.669e-60
Phase 2 self-accuracy: 0.4000 [0.3274170379313008, 0.47258296206869926] (n=175)
P-value vs 25%: 5.112e-05; P-value vs 33%: 0.07042

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.03231
Time:                        20:27:18   Log-Likelihood:                -313.26
converged:                       True   LL-Null:                       -323.72
Covariance Type:            nonrobust   LLR p-value:                 4.790e-06
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          1.4465      0.463      3.127      0.002       0.540       2.353
p_i_capability    -2.4187      0.534     -4.531      0.000      -3.465      -1.372
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.03812
Time:                        20:27:18   Log-Likelihood:                -311.38
converged:                       True   LL-Null:                       -323.72
Covariance Type:            nonrobust   LLR p-value:                 6.769e-07
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.0611      0.135     -7.860      0.000      -1.326      -0.796
capabilities_entropy     0.8678      0.177      4.904      0.000       0.521       1.215
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.7391 [0.6659, 0.8124] (n=138)
                  P-value vs 33.3%: 1.864e-27

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=-3.07, p=0.00253
Wilcoxon delta_p: statistic=3495.00, p=0.000581
Mean Δp = -0.0512  [-0.0839, -0.0186]
Idea 1 N = 144; 

  Idea 1.5: Calibration Metrics
  NLL: 3.2437, Signed ECE (overconf pos under neg): 0.0092, ECE: 0.1271 (n=260)
  Brier: 0.0410, Reliability (absolute calibration error; lower better): 0.0311, Resolution (relative calibration quality; higher better): 0.2223, Uncertainty: 0.2319 (n=260)
  AUROC: 0.9992

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.888
Model:                            OLS   Adj. R-squared:                  0.887
Method:                 Least Squares   F-statistic:                     675.6
Date:                Fri, 19 Sep 2025   Prob (F-statistic):          2.84e-121
Time:                        20:27:18   Log-Likelihood:                 141.70
No. Observations:                 260   AIC:                            -275.4
Df Residuals:                     256   BIC:                            -261.2
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.6244      0.055    -11.429      0.000      -0.732      -0.517
p1                    0.7111      0.066     10.745      0.000       0.581       0.841
answer_changed        0.4859      0.077      6.321      0.000       0.335       0.637
p1:answer_changed     0.3513      0.096      3.677      0.000       0.163       0.539
==============================================================================
Omnibus:                        8.062   Durbin-Watson:                   1.956
Prob(Omnibus):                  0.018   Jarque-Bera (JB):                8.054
Skew:                           0.368   Prob(JB):                       0.0178
Kurtosis:                       3.448   Cond. No.                         22.5
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=7.12, p=4.92e-11
Wilcoxon delta_H: statistic=2166.00, p=1.12e-09
Mean ΔH = 0.3076  [0.2229, 0.3923]
Paired t-test delta_H Changed: statistic=5.88, p=4.13e-08
Wilcoxon delta_H Changed: statistic=1514.00, p=2.26e-07
Mean ΔH Changed = 0.2793  [0.1862, 0.3725]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=6.36, p=9.05e-10
Wilcoxon (p_top2_game vs p_top2_base): statistic=9267.00, p=2.26e-10
Mean Δp_top2 = 0.0300  [0.0208, 0.0393] (n=260)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=9.24, p=9.34e-18
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=7264.00, p=1.32e-15
Mean ΔH_unchosen_baseline_set = 0.2950  [0.2324, 0.3576] (n=260)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  260
Model:                          Logit   Df Residuals:                      257
Method:                           MLE   Df Model:                            2
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.01060
Time:                        20:27:18   Log-Likelihood:                -176.81
converged:                       True   LL-Null:                       -178.71
Covariance Type:            nonrobust   LLR p-value:                    0.1504
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.2472      0.187     -1.321      0.186      -0.614       0.120
p1_z            -0.2283      0.143     -1.595      0.111      -0.509       0.052
I(p1_z ** 2)     0.0287      0.140      0.205      0.838      -0.246       0.303
================================================================================
AUC = 0.568

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.04708
Time:                        20:27:18   Log-Likelihood:                -308.48
converged:                       True   LL-Null:                       -323.72
Covariance Type:            nonrobust   LLR p-value:                 3.365e-08
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.0725      0.131     -8.215      0.000      -1.328      -0.817
game_entropy     1.1668      0.215      5.426      0.000       0.745       1.588
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=35414.50, p=3.34e-07
Paired t-test (game_entropy vs capabilities_entropy): statistic=-5.10, p=4.82e-07
Mean capabilities_entropy-game_entropy = 0.1156  [0.0712, 0.1601] (n=500)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      497
Method:                           MLE   Df Model:                            2
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.05856
Time:                        20:27:18   Log-Likelihood:                -304.77
converged:                       True   LL-Null:                       -323.72
Covariance Type:            nonrobust   LLR p-value:                 5.851e-09
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.2353      0.147     -8.432      0.000      -1.522      -0.948
capabilities_entropy     0.5435      0.199      2.727      0.006       0.153       0.934
game_entropy             0.8728      0.240      3.633      0.000       0.402       1.344
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.720000
                        1                 0.280000
Geography               0                 0.636364
                        1                 0.363636
Misc                    0                 0.513514
                        1                 0.486486
Music                   0                 0.675000
                        1                 0.325000
Other                   0                 0.673077
                        1                 0.326923
Politics                0                 0.649351
                        1                 0.350649
Science and technology  0                 0.704082
                        1                 0.295918
Sports                  0                 0.600000
                        1                 0.400000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.579882
                     1                 0.420118
Number               0                 0.589744
                     1                 0.410256
Other                0                 0.721805
                     1                 0.278195
Person               0                 0.708333
                     1                 0.291667
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.619048  0.380952           21
                       Number               0.666667  0.333333            9
                       Other                0.777778  0.222222           18
                       Person               0.777778  0.222222           27
Geography              Date                 0.533333  0.466667           15
                       Number               0.555556  0.444444           18
                       Other                0.909091  0.090909           11
Misc                   Date                 0.391304  0.608696           23
                       Number               0.555556  0.444444            9
                       Other                0.629630  0.370370           27
                       Person               0.466667  0.533333           15
Music                  Date                 0.666667  0.333333           12
                       Number               0.750000  0.250000            4
                       Other                0.666667  0.333333           12
                       Person               0.666667  0.333333           12
Other                  Date                 0.666667  0.333333           18
                       Number               0.428571  0.571429            7
                       Other                0.714286  0.285714           14
                       Person               0.769231  0.230769           13
Politics               Date                 0.666667  0.333333           36
                       Number               0.500000  0.500000            6
                       Other                0.600000  0.400000           20
                       Person               0.733333  0.266667           15
Science and technology Date                 0.657143  0.342857           35
                       Number               0.571429  0.428571           14
                       Other                0.789474  0.210526           19
                       Person               0.766667  0.233333           30
Sports                 Date                 0.111111  0.888889            9
                       Number               0.727273  0.272727           11
                       Other                0.833333  0.166667           12
                       Person               0.625000  0.375000            8

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      488
Method:                           MLE   Df Model:                           11
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.03181
Time:                        20:27:18   Log-Likelihood:                -313.43
converged:                       True   LL-Null:                       -323.72
Covariance Type:            nonrobust   LLR p-value:                   0.03782
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      0.3439      1.209      0.284      0.776      -2.025       2.713
C(topic_grouped)[T.Geography]                  0.2044      0.422      0.485      0.628      -0.622       1.031
C(topic_grouped)[T.Misc]                       0.9190      0.353      2.602      0.009       0.227       1.611
C(topic_grouped)[T.Music]                      0.2164      0.429      0.504      0.614      -0.625       1.058
C(topic_grouped)[T.Other]                      0.1797      0.397      0.453      0.651      -0.598       0.958
C(topic_grouped)[T.Politics]                   0.2998      0.362      0.828      0.407      -0.410       1.009
C(topic_grouped)[T.Science and technology]     0.0339      0.344      0.099      0.921      -0.640       0.708
C(topic_grouped)[T.Sports]                     0.5146      0.420      1.224      0.221      -0.309       1.339
C(answer_type_grouped)[T.Number]              -0.0440      0.289     -0.152      0.879      -0.611       0.523
C(answer_type_grouped)[T.Other]               -0.7307      0.255     -2.862      0.004      -1.231      -0.230
C(answer_type_grouped)[T.Person]              -0.5602      0.262     -2.136      0.033      -1.074      -0.046
q_length                                      -0.2075      0.260     -0.797      0.425      -0.718       0.303
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.4778
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      487
Method:                           MLE   Df Model:                           12
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.06059
Time:                        20:27:18   Log-Likelihood:                -304.11
converged:                       True   LL-Null:                       -323.72
Covariance Type:            nonrobust   LLR p-value:                 9.636e-05
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -0.4975      1.251     -0.398      0.691      -2.950       1.955
C(topic_grouped)[T.Geography]                  0.1151      0.432      0.266      0.790      -0.732       0.962
C(topic_grouped)[T.Misc]                       0.9393      0.360      2.612      0.009       0.235       1.644
C(topic_grouped)[T.Music]                      0.2385      0.435      0.548      0.584      -0.614       1.091
C(topic_grouped)[T.Other]                      0.1610      0.403      0.399      0.690      -0.630       0.952
C(topic_grouped)[T.Politics]                   0.2150      0.368      0.584      0.559      -0.507       0.937
C(topic_grouped)[T.Science and technology]    -0.0678      0.351     -0.193      0.847      -0.755       0.620
C(topic_grouped)[T.Sports]                     0.5335      0.430      1.242      0.214      -0.308       1.375
C(answer_type_grouped)[T.Number]              -0.0190      0.295     -0.064      0.949      -0.598       0.560
C(answer_type_grouped)[T.Other]               -0.4765      0.267     -1.784      0.074      -1.000       0.047
C(answer_type_grouped)[T.Person]              -0.2137      0.278     -0.769      0.442      -0.758       0.331
q_length                                      -0.1389      0.266     -0.522      0.602      -0.661       0.383
capabilities_entropy                           0.8225      0.193      4.264      0.000       0.444       1.201
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      487
Method:                           MLE   Df Model:                           12
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.06738
Time:                        20:27:18   Log-Likelihood:                -301.91
converged:                       True   LL-Null:                       -323.72
Covariance Type:            nonrobust   LLR p-value:                 1.769e-05
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -0.4129      1.247     -0.331      0.740      -2.856       2.030
C(topic_grouped)[T.Geography]                  0.2209      0.433      0.510      0.610      -0.628       1.070
C(topic_grouped)[T.Misc]                       0.9847      0.364      2.707      0.007       0.272       1.698
C(topic_grouped)[T.Music]                      0.4006      0.439      0.912      0.362      -0.461       1.262
C(topic_grouped)[T.Other]                      0.1809      0.409      0.442      0.658      -0.621       0.982
C(topic_grouped)[T.Politics]                   0.4162      0.371      1.121      0.262      -0.312       1.144
C(topic_grouped)[T.Science and technology]     0.1024      0.354      0.289      0.772      -0.591       0.796
C(topic_grouped)[T.Sports]                     0.5225      0.434      1.204      0.229      -0.328       1.373
C(answer_type_grouped)[T.Number]              -0.0450      0.297     -0.152      0.880      -0.627       0.537
C(answer_type_grouped)[T.Other]               -0.4670      0.267     -1.751      0.080      -0.990       0.056
C(answer_type_grouped)[T.Person]              -0.2302      0.277     -0.832      0.406      -0.773       0.312
q_length                                      -0.1784      0.265     -0.672      0.502      -0.699       0.342
game_entropy                                   1.0884      0.230      4.739      0.000       0.638       1.539
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      486
Method:                           MLE   Df Model:                           13
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.07799
Time:                        20:27:18   Log-Likelihood:                -298.48
converged:                       True   LL-Null:                       -323.72
Covariance Type:            nonrobust   LLR p-value:                 2.453e-06
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -0.7941      1.268     -0.627      0.531      -3.279       1.690
C(topic_grouped)[T.Geography]                  0.1601      0.436      0.367      0.714      -0.695       1.015
C(topic_grouped)[T.Misc]                       0.9881      0.366      2.698      0.007       0.270       1.706
C(topic_grouped)[T.Music]                      0.3715      0.443      0.838      0.402      -0.497       1.240
C(topic_grouped)[T.Other]                      0.1711      0.410      0.417      0.677      -0.633       0.975
C(topic_grouped)[T.Politics]                   0.3362      0.374      0.898      0.369      -0.397       1.070
C(topic_grouped)[T.Science and technology]     0.0177      0.358      0.049      0.961      -0.684       0.719
C(topic_grouped)[T.Sports]                     0.5376      0.436      1.233      0.218      -0.317       1.392
C(answer_type_grouped)[T.Number]              -0.0222      0.299     -0.074      0.941      -0.608       0.564
C(answer_type_grouped)[T.Other]               -0.3533      0.273     -1.294      0.196      -0.889       0.182
C(answer_type_grouped)[T.Person]              -0.0665      0.286     -0.233      0.816      -0.626       0.493
q_length                                      -0.1424      0.269     -0.530      0.596      -0.669       0.384
capabilities_entropy                           0.5530      0.211      2.618      0.009       0.139       0.967
game_entropy                                   0.8357      0.249      3.352      0.001       0.347       1.324
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing gpt-4o-2024-08-06 (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_new/gpt-4o-2024-08-06_SimpleMC_redacted_cor_temp1.0_1757988718_game_data.json', './sc_logs_new/gpt-4o-2024-08-06_SimpleMC_redacted_temp1.0_1757987648_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    366
1    134
Name: count, dtype: int64

Answer change%: 0.2680 [0.22917727403675803, 0.306822725963242] (n=500)
P-value vs 25%: 0.3635; P-value vs 0%: 1.041e-41
Phase 2 self-accuracy: 0.5075 [0.4228145664605305, 0.5921108066737979] (n=134)
P-value vs 25%: 2.502e-09; P-value vs 33%: 5.355e-05

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.1410
Time:                        20:27:18   Log-Likelihood:                -249.64
converged:                       True   LL-Null:                       -290.63
Covariance Type:            nonrobust   LLR p-value:                 1.381e-19
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          2.1383      0.374      5.713      0.000       1.405       2.872
p_i_capability    -4.5433      0.551     -8.239      0.000      -5.624      -3.462
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.1391
Time:                        20:27:18   Log-Likelihood:                -250.21
converged:                       True   LL-Null:                       -290.63
Covariance Type:            nonrobust   LLR p-value:                 2.437e-19
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.6839      0.263    -10.189      0.000      -3.200      -2.168
capabilities_entropy     1.6269      0.205      7.934      0.000       1.225       2.029
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.7164 [0.6401, 0.7927] (n=134)
                  P-value vs 33.3%: 7.692e-23

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=-2.47, p=0.0142
Wilcoxon delta_p: statistic=25541.00, p=0.0129
Mean Δp = -0.0209  [-0.0376, -0.0043]
Idea 1 N = 347; 

  Idea 1.5: Calibration Metrics
  NLL: 1.7043, Signed ECE (overconf pos under neg): -0.0021, ECE: 0.1352 (n=481)
  Brier: 0.0606, Reliability (absolute calibration error; lower better): 0.0348, Resolution (relative calibration quality; higher better): 0.2217, Uncertainty: 0.2480 (n=481)
  AUROC: 0.9969

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.699
Model:                            OLS   Adj. R-squared:                  0.697
Method:                 Least Squares   F-statistic:                     369.0
Date:                Fri, 19 Sep 2025   Prob (F-statistic):          6.93e-124
Time:                        20:27:18   Log-Likelihood:                 261.76
No. Observations:                 481   AIC:                            -515.5
Df Residuals:                     477   BIC:                            -498.8
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.2903      0.030     -9.726      0.000      -0.349      -0.232
p1                    0.3451      0.037      9.329      0.000       0.272       0.418
answer_changed        0.0421      0.051      0.831      0.407      -0.058       0.142
p1:answer_changed     0.7020      0.075      9.307      0.000       0.554       0.850
==============================================================================
Omnibus:                        7.146   Durbin-Watson:                   1.983
Prob(Omnibus):                  0.028   Jarque-Bera (JB):                7.160
Skew:                           0.299   Prob(JB):                       0.0279
Kurtosis:                       3.026   Cond. No.                         18.8
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=2.97, p=0.00323
Wilcoxon delta_H: statistic=23736.00, p=0.000559
Mean ΔH = 0.0677  [0.0230, 0.1124]
Paired t-test delta_H Changed: statistic=8.81, p=6.03e-15
Wilcoxon delta_H Changed: statistic=1099.00, p=2.9e-14
Mean ΔH Changed = 0.2982  [0.2319, 0.3646]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=4.59, p=5.75e-06
Wilcoxon (p_top2_game vs p_top2_base): statistic=45079.00, p=2.41e-05
Mean Δp_top2 = 0.0180  [0.0103, 0.0257] (n=481)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=6.75, p=4.2e-11
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=36317.00, p=1.28e-12
Mean ΔH_unchosen_baseline_set = 0.1319  [0.0936, 0.1702] (n=481)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  481
Model:                          Logit   Df Residuals:                      478
Method:                           MLE   Df Model:                            2
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.1303
Time:                        20:27:18   Log-Likelihood:                -247.50
converged:                       True   LL-Null:                       -284.57
Covariance Type:            nonrobust   LLR p-value:                 7.998e-17
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.0511      0.167     -6.277      0.000      -1.379      -0.723
p1_z            -0.9842      0.135     -7.285      0.000      -1.249      -0.719
I(p1_z ** 2)    -0.1054      0.143     -0.739      0.460      -0.385       0.174
================================================================================
AUC = 0.744

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.1281
Time:                        20:27:18   Log-Likelihood:                -253.41
converged:                       True   LL-Null:                       -290.63
Covariance Type:            nonrobust   LLR p-value:                 6.277e-18
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -2.4922      0.241    -10.347      0.000      -2.964      -2.020
game_entropy     1.5925      0.204      7.807      0.000       1.193       1.992
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=49994.00, p=9.32e-05
Paired t-test (game_entropy vs capabilities_entropy): statistic=-4.24, p=2.71e-05
Mean capabilities_entropy-game_entropy = 0.0790  [0.0425, 0.1156] (n=500)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      497
Method:                           MLE   Df Model:                            2
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.1541
Time:                        20:27:18   Log-Likelihood:                -245.83
converged:                       True   LL-Null:                       -290.63
Covariance Type:            nonrobust   LLR p-value:                 3.496e-20
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.8806      0.280    -10.281      0.000      -3.430      -2.331
capabilities_entropy     1.0676      0.278      3.835      0.000       0.522       1.613
game_entropy             0.8205      0.281      2.921      0.003       0.270       1.371
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.706667
                        1                 0.293333
Geography               0                 0.704545
                        1                 0.295455
Misc                    0                 0.743243
                        1                 0.256757
Music                   0                 0.700000
                        1                 0.300000
Other                   0                 0.730769
                        1                 0.269231
Politics                0                 0.701299
                        1                 0.298701
Science and technology  0                 0.775510
                        1                 0.224490
Sports                  0                 0.775000
                        1                 0.225000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.621302
                     1                 0.378698
Number               0                 0.743590
                     1                 0.256410
Other                0                 0.834586
                     1                 0.165414
Person               0                 0.766667
                     1                 0.233333
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.571429  0.428571           21
                       Number               0.888889  0.111111            9
                       Other                0.722222  0.277778           18
                       Person               0.740741  0.259259           27
Geography              Date                 0.333333  0.666667           15
                       Number               0.888889  0.111111           18
                       Other                0.909091  0.090909           11
Misc                   Date                 0.739130  0.260870           23
                       Number               0.555556  0.444444            9
                       Other                0.851852  0.148148           27
                       Person               0.666667  0.333333           15
Music                  Date                 0.500000  0.500000           12
                       Number               0.750000  0.250000            4
                       Other                0.833333  0.166667           12
                       Person               0.750000  0.250000           12
Other                  Date                 0.666667  0.333333           18
                       Number               0.571429  0.428571            7
                       Other                0.857143  0.142857           14
                       Person               0.769231  0.230769           13
Politics               Date                 0.611111  0.388889           36
                       Number               0.500000  0.500000            6
                       Other                0.850000  0.150000           20
                       Person               0.800000  0.200000           15
Science and technology Date                 0.714286  0.285714           35
                       Number               0.785714  0.214286           14
                       Other                0.894737  0.105263           19
                       Person               0.766667  0.233333           30
Sports                 Date                 0.666667  0.333333            9
                       Number               0.727273  0.272727           11
                       Other                0.750000  0.250000           12
                       Person               1.000000  0.000000            8

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      488
Method:                           MLE   Df Model:                           11
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.03767
Time:                        20:27:18   Log-Likelihood:                -279.68
converged:                       True   LL-Null:                       -290.63
Covariance Type:            nonrobust   LLR p-value:                   0.02518
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      0.8846      1.310      0.675      0.499      -1.683       3.452
C(topic_grouped)[T.Geography]                 -0.0908      0.440     -0.206      0.836      -0.952       0.771
C(topic_grouped)[T.Misc]                      -0.1626      0.377     -0.431      0.667      -0.902       0.577
C(topic_grouped)[T.Music]                      0.0313      0.437      0.071      0.943      -0.826       0.889
C(topic_grouped)[T.Other]                     -0.1749      0.412     -0.425      0.671      -0.982       0.632
C(topic_grouped)[T.Politics]                  -0.0457      0.371     -0.123      0.902      -0.773       0.682
C(topic_grouped)[T.Science and technology]    -0.4342      0.358     -1.211      0.226      -1.137       0.268
C(topic_grouped)[T.Sports]                    -0.3267      0.467     -0.699      0.484      -1.242       0.589
C(answer_type_grouped)[T.Number]              -0.5533      0.314     -1.764      0.078      -1.168       0.061
C(answer_type_grouped)[T.Other]               -1.1639      0.286     -4.066      0.000      -1.725      -0.603
C(answer_type_grouped)[T.Person]              -0.7197      0.275     -2.616      0.009      -1.259      -0.180
q_length                                      -0.2675      0.283     -0.945      0.344      -0.822       0.287
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.8843
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      487
Method:                           MLE   Df Model:                           12
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.1626
Time:                        20:27:18   Log-Likelihood:                -243.36
converged:                       True   LL-Null:                       -290.63
Covariance Type:            nonrobust   LLR p-value:                 6.485e-15
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.3336      1.443     -0.924      0.355      -4.162       1.495
C(topic_grouped)[T.Geography]                 -0.2743      0.478     -0.574      0.566      -1.210       0.662
C(topic_grouped)[T.Misc]                      -0.2846      0.406     -0.701      0.484      -1.081       0.512
C(topic_grouped)[T.Music]                      0.0046      0.486      0.009      0.992      -0.948       0.958
C(topic_grouped)[T.Other]                     -0.2756      0.449     -0.614      0.539      -1.155       0.604
C(topic_grouped)[T.Politics]                  -0.1433      0.407     -0.352      0.725      -0.941       0.655
C(topic_grouped)[T.Science and technology]    -0.4145      0.389     -1.066      0.287      -1.177       0.348
C(topic_grouped)[T.Sports]                    -0.3614      0.495     -0.729      0.466      -1.332       0.610
C(answer_type_grouped)[T.Number]              -0.8020      0.333     -2.408      0.016      -1.455      -0.149
C(answer_type_grouped)[T.Other]               -0.6942      0.311     -2.231      0.026      -1.304      -0.084
C(answer_type_grouped)[T.Person]               0.0176      0.313      0.056      0.955      -0.597       0.632
q_length                                      -0.2045      0.306     -0.669      0.503      -0.803       0.394
capabilities_entropy                           1.7032      0.224      7.589      0.000       1.263       2.143
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      487
Method:                           MLE   Df Model:                           12
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.1519
Time:                        20:27:18   Log-Likelihood:                -246.50
converged:                       True   LL-Null:                       -290.63
Covariance Type:            nonrobust   LLR p-value:                 1.068e-13
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.2575      1.457     -0.863      0.388      -4.113       1.598
C(topic_grouped)[T.Geography]                 -0.1704      0.482     -0.353      0.724      -1.116       0.775
C(topic_grouped)[T.Misc]                      -0.3153      0.401     -0.786      0.432      -1.102       0.471
C(topic_grouped)[T.Music]                     -0.0619      0.471     -0.131      0.896      -0.985       0.862
C(topic_grouped)[T.Other]                     -0.3108      0.442     -0.703      0.482      -1.177       0.555
C(topic_grouped)[T.Politics]                  -0.0589      0.405     -0.145      0.884      -0.853       0.735
C(topic_grouped)[T.Science and technology]    -0.3961      0.387     -1.024      0.306      -1.155       0.362
C(topic_grouped)[T.Sports]                    -0.1438      0.499     -0.288      0.773      -1.123       0.835
C(answer_type_grouped)[T.Number]              -0.8150      0.336     -2.427      0.015      -1.473      -0.157
C(answer_type_grouped)[T.Other]               -0.8603      0.308     -2.792      0.005      -1.464      -0.256
C(answer_type_grouped)[T.Person]              -0.2414      0.303     -0.797      0.425      -0.835       0.352
q_length                                      -0.1497      0.309     -0.484      0.628      -0.756       0.457
game_entropy                                   1.6096      0.216      7.455      0.000       1.186       2.033
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      486
Method:                           MLE   Df Model:                           13
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.1780
Time:                        20:27:18   Log-Likelihood:                -238.89
converged:                       True   LL-Null:                       -290.63
Covariance Type:            nonrobust   LLR p-value:                 3.495e-16
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.7290      1.476     -1.171      0.241      -4.622       1.164
C(topic_grouped)[T.Geography]                 -0.2625      0.486     -0.540      0.589      -1.215       0.690
C(topic_grouped)[T.Misc]                      -0.3162      0.408     -0.775      0.438      -1.116       0.483
C(topic_grouped)[T.Music]                     -0.0462      0.488     -0.095      0.925      -1.003       0.910
C(topic_grouped)[T.Other]                     -0.3115      0.452     -0.689      0.491      -1.198       0.575
C(topic_grouped)[T.Politics]                  -0.1262      0.412     -0.306      0.760      -0.935       0.682
C(topic_grouped)[T.Science and technology]    -0.3978      0.393     -1.012      0.312      -1.168       0.373
C(topic_grouped)[T.Sports]                    -0.2414      0.502     -0.481      0.630      -1.225       0.742
C(answer_type_grouped)[T.Number]              -0.8735      0.338     -2.584      0.010      -1.536      -0.211
C(answer_type_grouped)[T.Other]               -0.6994      0.315     -2.220      0.026      -1.317      -0.082
C(answer_type_grouped)[T.Person]               0.0138      0.317      0.043      0.965      -0.607       0.634
q_length                                      -0.1623      0.312     -0.521      0.602      -0.773       0.448
capabilities_entropy                           1.1336      0.295      3.846      0.000       0.556       1.711
game_entropy                                   0.8490      0.287      2.954      0.003       0.286       1.412
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing gpt-4o-mini (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_new/gpt-4o-mini_SimpleMC_redacted_cor_temp1.0_1757988920_game_data.json', './sc_logs_new/gpt-4o-mini_SimpleMC_redacted_temp1.0_1757987946_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    328
1    172
Name: count, dtype: int64

Answer change%: 0.3440 [0.3023615811224028, 0.38563841887759714] (n=500)
P-value vs 25%: 9.659e-06; P-value vs 0%: 5.702e-59
Phase 2 self-accuracy: 0.3081 [0.23913671546297355, 0.3771423543044683] (n=172)
P-value vs 25%: 0.09866; P-value vs 33%: 0.4801

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.06451
Time:                        20:27:18   Log-Likelihood:                -301.06
converged:                       True   LL-Null:                       -321.83
Covariance Type:            nonrobust   LLR p-value:                 1.164e-10
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          1.9231      0.416      4.626      0.000       1.108       2.738
p_i_capability    -3.2354      0.516     -6.265      0.000      -4.248      -2.223
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.06540
Time:                        20:27:18   Log-Likelihood:                -300.78
converged:                       True   LL-Null:                       -321.83
Covariance Type:            nonrobust   LLR p-value:                 8.701e-11
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.4709      0.171     -8.579      0.000      -1.807      -1.135
capabilities_entropy     1.1523      0.184      6.251      0.000       0.791       1.514
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.7321 [0.6652, 0.7991] (n=168)
                  P-value vs 33.3%: 1.758e-31

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=-2.09, p=0.0374
Wilcoxon delta_p: statistic=17130.00, p=0.00181
Mean Δp = -0.0234  [-0.0454, -0.0015]
Idea 1 N = 295; 

  Idea 1.5: Calibration Metrics
  NLL: 3.2860, Signed ECE (overconf pos under neg): -0.0085, ECE: 0.0942 (n=463)
  Brier: 0.0402, Reliability (absolute calibration error; lower better): 0.0223, Resolution (relative calibration quality; higher better): 0.2060, Uncertainty: 0.2234 (n=463)
  AUROC: 0.9976

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.842
Model:                            OLS   Adj. R-squared:                  0.841
Method:                 Least Squares   F-statistic:                     812.6
Date:                Fri, 19 Sep 2025   Prob (F-statistic):          3.75e-183
Time:                        20:27:18   Log-Likelihood:                 236.00
No. Observations:                 463   AIC:                            -464.0
Df Residuals:                     459   BIC:                            -447.5
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.5865      0.042    -14.020      0.000      -0.669      -0.504
p1                    0.6770      0.049     13.747      0.000       0.580       0.774
answer_changed        0.5030      0.060      8.370      0.000       0.385       0.621
p1:answer_changed     0.2682      0.076      3.550      0.000       0.120       0.417
==============================================================================
Omnibus:                       30.514   Durbin-Watson:                   2.027
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               35.198
Skew:                           0.615   Prob(JB):                     2.27e-08
Kurtosis:                       3.556   Cond. No.                         21.7
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=2.15, p=0.0324
Wilcoxon delta_H: statistic=18486.00, p=0.0226
Mean ΔH = 0.0615  [0.0054, 0.1176]
Paired t-test delta_H Changed: statistic=8.48, p=1.14e-14
Wilcoxon delta_H Changed: statistic=2458.00, p=2e-13
Mean ΔH Changed = 0.2914  [0.2240, 0.3587]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=3.98, p=7.87e-05
Wilcoxon (p_top2_game vs p_top2_base): statistic=39033.00, p=3.5e-07
Mean Δp_top2 = 0.0145  [0.0074, 0.0217] (n=463)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=6.40, p=3.88e-10
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=35629.00, p=3.47e-10
Mean ΔH_unchosen_baseline_set = 0.1449  [0.1005, 0.1893] (n=463)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  463
Model:                          Logit   Df Residuals:                      460
Method:                           MLE   Df Model:                            2
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.05426
Time:                        20:27:18   Log-Likelihood:                -286.83
converged:                       True   LL-Null:                       -303.28
Covariance Type:            nonrobust   LLR p-value:                 7.142e-08
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.6194      0.151     -4.106      0.000      -0.915      -0.324
p1_z            -0.5483      0.122     -4.497      0.000      -0.787      -0.309
I(p1_z ** 2)     0.0213      0.118      0.180      0.858      -0.211       0.253
================================================================================
AUC = 0.656

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.08285
Time:                        20:27:18   Log-Likelihood:                -295.16
converged:                       True   LL-Null:                       -321.83
Covariance Type:            nonrobust   LLR p-value:                 2.821e-13
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.5906      0.175     -9.074      0.000      -1.934      -1.247
game_entropy     1.4666      0.211      6.952      0.000       1.053       1.880
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=50805.50, p=0.000548
Paired t-test (game_entropy vs capabilities_entropy): statistic=-2.73, p=0.00646
Mean capabilities_entropy-game_entropy = 0.0691  [0.0196, 0.1187] (n=500)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      497
Method:                           MLE   Df Model:                            2
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.1092
Time:                        20:27:18   Log-Likelihood:                -286.67
converged:                       True   LL-Null:                       -321.83
Covariance Type:            nonrobust   LLR p-value:                 5.411e-16
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.9887      0.212     -9.399      0.000      -2.403      -1.574
capabilities_entropy     0.8064      0.198      4.075      0.000       0.419       1.194
game_entropy             1.1768      0.225      5.220      0.000       0.735       1.619
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.680000
                        1                 0.320000
Geography               0                 0.613636
                        1                 0.386364
Misc                    0                 0.675676
                        1                 0.324324
Music                   0                 0.700000
                        1                 0.300000
Other                   0                 0.692308
                        1                 0.307692
Politics                0                 0.584416
                        1                 0.415584
Science and technology  0                 0.663265
                        1                 0.336735
Sports                  0                 0.650000
                        1                 0.350000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.538462
                     1                 0.461538
Number               0                 0.692308
                     1                 0.307692
Other                0                 0.721805
                     1                 0.278195
Person               0                 0.725000
                     1                 0.275000
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.571429  0.428571           21
                       Number               0.666667  0.333333            9
                       Other                0.777778  0.222222           18
                       Person               0.703704  0.296296           27
Geography              Date                 0.466667  0.533333           15
                       Number               0.722222  0.277778           18
                       Other                0.636364  0.363636           11
Misc                   Date                 0.652174  0.347826           23
                       Number               0.777778  0.222222            9
                       Other                0.703704  0.296296           27
                       Person               0.600000  0.400000           15
Music                  Date                 0.666667  0.333333           12
                       Number               0.750000  0.250000            4
                       Other                0.666667  0.333333           12
                       Person               0.750000  0.250000           12
Other                  Date                 0.500000  0.500000           18
                       Number               0.857143  0.142857            7
                       Other                0.714286  0.285714           14
                       Person               0.846154  0.153846           13
Politics               Date                 0.444444  0.555556           36
                       Number               0.500000  0.500000            6
                       Other                0.700000  0.300000           20
                       Person               0.800000  0.200000           15
Science and technology Date                 0.571429  0.428571           35
                       Number               0.642857  0.357143           14
                       Other                0.789474  0.210526           19
                       Person               0.700000  0.300000           30
Sports                 Date                 0.444444  0.555556            9
                       Number               0.636364  0.363636           11
                       Other                0.750000  0.250000           12
                       Person               0.750000  0.250000            8

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      488
Method:                           MLE   Df Model:                           11
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.02782
Time:                        20:27:18   Log-Likelihood:                -312.87
converged:                       True   LL-Null:                       -321.83
Covariance Type:            nonrobust   LLR p-value:                   0.08371
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -0.8955      1.205     -0.743      0.457      -3.257       1.466
C(topic_grouped)[T.Geography]                  0.2339      0.415      0.563      0.573      -0.580       1.048
C(topic_grouped)[T.Misc]                      -0.0066      0.358     -0.019      0.985      -0.708       0.695
C(topic_grouped)[T.Music]                     -0.1028      0.431     -0.238      0.812      -0.948       0.743
C(topic_grouped)[T.Other]                     -0.1096      0.396     -0.277      0.782      -0.886       0.667
C(topic_grouped)[T.Politics]                   0.2470      0.352      0.702      0.482      -0.442       0.936
C(topic_grouped)[T.Science and technology]    -0.0001      0.333     -0.000      1.000      -0.653       0.653
C(topic_grouped)[T.Sports]                     0.1699      0.422      0.402      0.688      -0.658       0.998
C(answer_type_grouped)[T.Number]              -0.6817      0.299     -2.277      0.023      -1.268      -0.095
C(answer_type_grouped)[T.Other]               -0.7772      0.250     -3.105      0.002      -1.268      -0.287
C(answer_type_grouped)[T.Person]              -0.7588      0.262     -2.900      0.004      -1.272      -0.246
q_length                                       0.1486      0.260      0.573      0.567      -0.360       0.657
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.6666
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      487
Method:                           MLE   Df Model:                           12
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.08235
Time:                        20:27:18   Log-Likelihood:                -295.32
converged:                       True   LL-Null:                       -321.83
Covariance Type:            nonrobust   LLR p-value:                 4.113e-07
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.5485      1.252     -1.237      0.216      -4.002       0.905
C(topic_grouped)[T.Geography]                  0.1626      0.433      0.376      0.707      -0.685       1.010
C(topic_grouped)[T.Misc]                      -0.0738      0.372     -0.198      0.843      -0.803       0.656
C(topic_grouped)[T.Music]                     -0.2488      0.453     -0.550      0.583      -1.136       0.638
C(topic_grouped)[T.Other]                     -0.2731      0.414     -0.660      0.509      -1.084       0.538
C(topic_grouped)[T.Politics]                   0.1299      0.367      0.354      0.723      -0.589       0.849
C(topic_grouped)[T.Science and technology]    -0.0784      0.346     -0.227      0.821      -0.756       0.600
C(topic_grouped)[T.Sports]                     0.1250      0.437      0.286      0.775      -0.731       0.981
C(answer_type_grouped)[T.Number]              -0.7535      0.310     -2.430      0.015      -1.361      -0.146
C(answer_type_grouped)[T.Other]               -0.4539      0.265     -1.715      0.086      -0.973       0.065
C(answer_type_grouped)[T.Person]              -0.5606      0.273     -2.051      0.040      -1.096      -0.025
q_length                                       0.1097      0.268      0.409      0.682      -0.416       0.635
capabilities_entropy                           1.1092      0.193      5.751      0.000       0.731       1.487
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      487
Method:                           MLE   Df Model:                           12
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.1005
Time:                        20:27:18   Log-Likelihood:                -289.49
converged:                       True   LL-Null:                       -321.83
Covariance Type:            nonrobust   LLR p-value:                 3.143e-09
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.3340      1.266     -1.053      0.292      -3.816       1.148
C(topic_grouped)[T.Geography]                  0.0394      0.440      0.089      0.929      -0.823       0.902
C(topic_grouped)[T.Misc]                       0.0922      0.375      0.246      0.806      -0.643       0.828
C(topic_grouped)[T.Music]                     -0.1404      0.453     -0.310      0.757      -1.028       0.748
C(topic_grouped)[T.Other]                     -0.1173      0.416     -0.282      0.778      -0.932       0.698
C(topic_grouped)[T.Politics]                   0.3356      0.369      0.909      0.363      -0.388       1.059
C(topic_grouped)[T.Science and technology]     0.1370      0.349      0.393      0.694      -0.546       0.820
C(topic_grouped)[T.Sports]                     0.3542      0.444      0.797      0.425      -0.517       1.225
C(answer_type_grouped)[T.Number]              -0.7336      0.314     -2.336      0.019      -1.349      -0.118
C(answer_type_grouped)[T.Other]               -0.4984      0.266     -1.875      0.061      -1.019       0.023
C(answer_type_grouped)[T.Person]              -0.5560      0.275     -2.019      0.044      -1.096      -0.016
q_length                                       0.0036      0.272      0.013      0.990      -0.530       0.537
game_entropy                                   1.4483      0.221      6.564      0.000       1.016       1.881
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      486
Method:                           MLE   Df Model:                           13
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.1244
Time:                        20:27:18   Log-Likelihood:                -281.79
converged:                       True   LL-Null:                       -321.83
Covariance Type:            nonrobust   LLR p-value:                 1.065e-11
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.7233      1.289     -1.337      0.181      -4.250       0.803
C(topic_grouped)[T.Geography]                  0.0260      0.445      0.059      0.953      -0.846       0.898
C(topic_grouped)[T.Misc]                       0.0412      0.382      0.108      0.914      -0.707       0.789
C(topic_grouped)[T.Music]                     -0.2444      0.469     -0.521      0.603      -1.164       0.676
C(topic_grouped)[T.Other]                     -0.2459      0.429     -0.573      0.566      -1.087       0.595
C(topic_grouped)[T.Politics]                   0.2399      0.378      0.635      0.526      -0.501       0.980
C(topic_grouped)[T.Science and technology]     0.0580      0.358      0.162      0.871      -0.643       0.759
C(topic_grouped)[T.Sports]                     0.3015      0.454      0.664      0.507      -0.588       1.191
C(answer_type_grouped)[T.Number]              -0.7615      0.316     -2.411      0.016      -1.381      -0.142
C(answer_type_grouped)[T.Other]               -0.3262      0.274     -1.191      0.234      -0.863       0.211
C(answer_type_grouped)[T.Person]              -0.4634      0.282     -1.643      0.100      -1.016       0.089
q_length                                   -9.869e-05      0.276     -0.000      1.000      -0.541       0.541
capabilities_entropy                           0.7945      0.204      3.887      0.000       0.394       1.195
game_entropy                                   1.1899      0.233      5.110      0.000       0.733       1.646
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing grok-3-latest (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_new/grok-3-latest_SimpleMC_redacted_cor_temp0.0_1751718904_game_data.json', './sc_logs_new/grok-3-latest_SimpleMC_redacted_temp0.0_1751719937_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    333
1    167
Name: count, dtype: int64

Answer change%: 0.3340 [0.2926597178067086, 0.37534028219329146] (n=500)
P-value vs 25%: 6.82e-05; P-value vs 0%: 1.781e-56
Phase 2 self-accuracy: 0.3593 [0.2865133601073383, 0.4320495141441587] (n=167)
P-value vs 25%: 0.003246; P-value vs 33%: 0.479

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.07609
Time:                        20:27:18   Log-Likelihood:                -294.25
converged:                       True   LL-Null:                       -318.49
Covariance Type:            nonrobust   LLR p-value:                 3.355e-12
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          2.6597      0.521      5.106      0.000       1.639       3.681
p_i_capability    -3.8695      0.592     -6.535      0.000      -5.030      -2.709
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.1263
Time:                        20:27:18   Log-Likelihood:                -278.27
converged:                       True   LL-Null:                       -318.49
Covariance Type:            nonrobust   LLR p-value:                 3.018e-19
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.5647      0.151    -10.335      0.000      -1.862      -1.268
capabilities_entropy     1.8794      0.225      8.365      0.000       1.439       2.320
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.5988 [0.5245, 0.6731] (n=167)
                  P-value vs 33.3%: 2.573e-12

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=4.25, p=2.8e-05
Wilcoxon delta_p: statistic=16498.00, p=4.6e-10
Mean Δp = 0.0377  [0.0203, 0.0551]
Idea 1 N = 330; 

  Idea 1.5: Calibration Metrics
  NLL: 2.1840, Signed ECE (overconf pos under neg): -0.0143, ECE: 0.0634 (n=497)
  Brier: 0.0232, Reliability (absolute calibration error; lower better): 0.0147, Resolution (relative calibration quality; higher better): 0.2341, Uncertainty: 0.2423 (n=497)
  AUROC: 0.9996

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.819
Model:                            OLS   Adj. R-squared:                  0.818
Method:                 Least Squares   F-statistic:                     744.1
Date:                Fri, 19 Sep 2025   Prob (F-statistic):          1.44e-182
Time:                        20:27:18   Log-Likelihood:                 256.90
No. Observations:                 497   AIC:                            -505.8
Df Residuals:                     493   BIC:                            -489.0
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.4047      0.056     -7.290      0.000      -0.514      -0.296
p1                    0.4794      0.060      8.053      0.000       0.362       0.596
answer_changed        0.3370      0.076      4.441      0.000       0.188       0.486
p1:answer_changed     0.4171      0.087      4.802      0.000       0.246       0.588
==============================================================================
Omnibus:                       65.754   Durbin-Watson:                   2.002
Prob(Omnibus):                  0.000   Jarque-Bera (JB):              227.500
Skew:                           0.569   Prob(JB):                     3.97e-50
Kurtosis:                       6.113   Cond. No.                         28.6
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-7.28, p=2.54e-12
Wilcoxon delta_H: statistic=15293.00, p=4.3e-12
Mean ΔH = -0.2166  [-0.2749, -0.1582]
Paired t-test delta_H Changed: statistic=0.68, p=0.499
Wilcoxon delta_H Changed: statistic=6525.00, p=0.435
Mean ΔH Changed = 0.0267  [-0.0506, 0.1040]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=-6.55, p=1.42e-10
Wilcoxon (p_top2_game vs p_top2_base): statistic=28567.00, p=2.52e-25
Mean Δp_top2 = -0.0216  [-0.0280, -0.0151] (n=497)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=-5.54, p=4.84e-08
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=44665.00, p=7.74e-08
Mean ΔH_unchosen_baseline_set = -0.1348  [-0.1825, -0.0872] (n=497)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  497
Model:                          Logit   Df Residuals:                      494
Method:                           MLE   Df Model:                            2
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.1266
Time:                        20:27:18   Log-Likelihood:                -277.10
converged:                       True   LL-Null:                       -317.26
Covariance Type:            nonrobust   LLR p-value:                 3.607e-18
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.3634      0.140     -2.595      0.009      -0.638      -0.089
p1_z            -1.3470      0.181     -7.453      0.000      -1.701      -0.993
I(p1_z ** 2)    -0.4188      0.105     -3.979      0.000      -0.625      -0.212
================================================================================
AUC = 0.762

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.1660
Time:                        20:27:18   Log-Likelihood:                -265.61
converged:                       True   LL-Null:                       -318.49
Covariance Type:            nonrobust   LLR p-value:                 8.309e-25
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.9938      0.185    -10.770      0.000      -2.357      -1.631
game_entropy     1.9366      0.207      9.371      0.000       1.532       2.342
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=37439.00, p=6.6e-15
Paired t-test (game_entropy vs capabilities_entropy): statistic=7.59, p=1.54e-13
Mean capabilities_entropy-game_entropy = -0.1786  [-0.2247, -0.1325] (n=500)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      497
Method:                           MLE   Df Model:                            2
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.2098
Time:                        20:27:18   Log-Likelihood:                -251.68
converged:                       True   LL-Null:                       -318.49
Covariance Type:            nonrobust   LLR p-value:                 9.651e-30
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.3460      0.211    -11.144      0.000      -2.759      -1.933
capabilities_entropy     1.2787      0.247      5.183      0.000       0.795       1.762
game_entropy             1.5549      0.222      7.018      0.000       1.121       1.989
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.720000
                        1                 0.280000
Geography               0                 0.500000
                        1                 0.500000
Misc                    0                 0.675676
                        1                 0.324324
Music                   0                 0.800000
                        1                 0.200000
Other                   0                 0.653846
                        1                 0.346154
Politics                0                 0.688312
                        1                 0.311688
Science and technology  0                 0.642857
                        1                 0.357143
Sports                  0                 0.625000
                        1                 0.375000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.686391
                     1                 0.313609
Number               1                 0.512821
                     0                 0.487179
Other                0                 0.714286
                     1                 0.285714
Person               0                 0.700000
                     1                 0.300000
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.761905  0.238095           21
                       Number               0.666667  0.333333            9
                       Other                0.833333  0.166667           18
                       Person               0.629630  0.370370           27
Geography              Date                 0.533333  0.466667           15
                       Number               0.500000  0.500000           18
                       Other                0.454545  0.545455           11
Misc                   Date                 0.869565  0.130435           23
                       Number               0.444444  0.555556            9
                       Other                0.666667  0.333333           27
                       Person               0.533333  0.466667           15
Music                  Date                 0.833333  0.166667           12
                       Number               0.750000  0.250000            4
                       Other                0.750000  0.250000           12
                       Person               0.833333  0.166667           12
Other                  Date                 0.555556  0.444444           18
                       Number               0.428571  0.571429            7
                       Other                0.785714  0.214286           14
                       Person               0.769231  0.230769           13
Politics               Date                 0.722222  0.277778           36
                       Number               0.333333  0.666667            6
                       Other                0.700000  0.300000           20
                       Person               0.733333  0.266667           15
Science and technology Date                 0.600000  0.400000           35
                       Number               0.285714  0.714286           14
                       Other                0.842105  0.157895           19
                       Person               0.733333  0.266667           30
Sports                 Date                 0.555556  0.444444            9
                       Number               0.636364  0.363636           11
                       Other                0.583333  0.416667           12
                       Person               0.750000  0.250000            8

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      488
Method:                           MLE   Df Model:                           11
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.03502
Time:                        20:27:18   Log-Likelihood:                -307.33
converged:                       True   LL-Null:                       -318.49
Covariance Type:            nonrobust   LLR p-value:                   0.02211
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -2.9073      1.216     -2.391      0.017      -5.290      -0.524
C(topic_grouped)[T.Geography]                  0.7819      0.416      1.882      0.060      -0.032       1.596
C(topic_grouped)[T.Misc]                       0.2213      0.364      0.609      0.543      -0.491       0.934
C(topic_grouped)[T.Music]                     -0.4020      0.476     -0.845      0.398      -1.335       0.531
C(topic_grouped)[T.Other]                      0.3233      0.393      0.822      0.411      -0.448       1.094
C(topic_grouped)[T.Politics]                   0.1032      0.367      0.281      0.779      -0.617       0.823
C(topic_grouped)[T.Science and technology]     0.3056      0.337      0.906      0.365      -0.356       0.967
C(topic_grouped)[T.Sports]                     0.3243      0.426      0.761      0.447      -0.511       1.160
C(answer_type_grouped)[T.Number]               0.7285      0.291      2.503      0.012       0.158       1.299
C(answer_type_grouped)[T.Other]               -0.0898      0.258     -0.348      0.728      -0.596       0.417
C(answer_type_grouped)[T.Person]               0.0545      0.267      0.204      0.838      -0.469       0.578
q_length                                       0.4167      0.260      1.602      0.109      -0.093       0.927
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.4188
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      487
Method:                           MLE   Df Model:                           12
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.1641
Time:                        20:27:18   Log-Likelihood:                -266.24
converged:                       True   LL-Null:                       -318.49
Covariance Type:            nonrobust   LLR p-value:                 7.273e-17
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -3.8411      1.354     -2.837      0.005      -6.495      -1.187
C(topic_grouped)[T.Geography]                  0.9118      0.452      2.019      0.043       0.027       1.797
C(topic_grouped)[T.Misc]                       0.0568      0.400      0.142      0.887      -0.727       0.841
C(topic_grouped)[T.Music]                     -0.4363      0.518     -0.842      0.400      -1.452       0.579
C(topic_grouped)[T.Other]                      0.1801      0.436      0.413      0.680      -0.674       1.035
C(topic_grouped)[T.Politics]                   0.3005      0.402      0.748      0.455      -0.487       1.088
C(topic_grouped)[T.Science and technology]     0.1798      0.374      0.480      0.631      -0.554       0.914
C(topic_grouped)[T.Sports]                     0.3202      0.470      0.681      0.496      -0.602       1.242
C(answer_type_grouped)[T.Number]               0.8392      0.318      2.638      0.008       0.216       1.463
C(answer_type_grouped)[T.Other]               -0.0987      0.285     -0.347      0.729      -0.656       0.459
C(answer_type_grouped)[T.Person]               0.0503      0.296      0.170      0.865      -0.530       0.630
q_length                                       0.4208      0.286      1.471      0.141      -0.140       0.982
capabilities_entropy                           1.9734      0.235      8.412      0.000       1.514       2.433
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      487
Method:                           MLE   Df Model:                           12
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.1930
Time:                        20:27:18   Log-Likelihood:                -257.03
converged:                       True   LL-Null:                       -318.49
Covariance Type:            nonrobust   LLR p-value:                 1.613e-20
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -3.4010      1.367     -2.488      0.013      -6.081      -0.721
C(topic_grouped)[T.Geography]                  0.9627      0.462      2.085      0.037       0.058       1.868
C(topic_grouped)[T.Misc]                       0.1916      0.406      0.472      0.637      -0.604       0.988
C(topic_grouped)[T.Music]                     -0.4459      0.516     -0.864      0.387      -1.457       0.565
C(topic_grouped)[T.Other]                      0.1104      0.435      0.254      0.800      -0.743       0.963
C(topic_grouped)[T.Politics]                   0.4426      0.409      1.081      0.280      -0.360       1.245
C(topic_grouped)[T.Science and technology]     0.3899      0.373      1.047      0.295      -0.340       1.120
C(topic_grouped)[T.Sports]                     0.0792      0.472      0.168      0.867      -0.846       1.004
C(answer_type_grouped)[T.Number]               0.7144      0.328      2.179      0.029       0.072       1.357
C(answer_type_grouped)[T.Other]                0.0818      0.290      0.282      0.778      -0.486       0.650
C(answer_type_grouped)[T.Person]               0.1277      0.300      0.425      0.671      -0.461       0.716
q_length                                       0.2119      0.291      0.728      0.466      -0.358       0.782
game_entropy                                   1.9707      0.216      9.133      0.000       1.548       2.394
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      486
Method:                           MLE   Df Model:                           13
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.2416
Time:                        20:27:18   Log-Likelihood:                -241.54
converged:                       True   LL-Null:                       -318.49
Covariance Type:            nonrobust   LLR p-value:                 3.386e-26
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -4.0228      1.442     -2.789      0.005      -6.849      -1.196
C(topic_grouped)[T.Geography]                  1.0339      0.478      2.161      0.031       0.096       1.971
C(topic_grouped)[T.Misc]                       0.1041      0.422      0.247      0.805      -0.723       0.932
C(topic_grouped)[T.Music]                     -0.5078      0.545     -0.932      0.351      -1.575       0.560
C(topic_grouped)[T.Other]                      0.0496      0.452      0.110      0.913      -0.836       0.935
C(topic_grouped)[T.Politics]                   0.5080      0.425      1.196      0.232      -0.325       1.341
C(topic_grouped)[T.Science and technology]     0.2814      0.391      0.719      0.472      -0.486       1.048
C(topic_grouped)[T.Sports]                     0.1324      0.495      0.267      0.789      -0.838       1.103
C(answer_type_grouped)[T.Number]               0.7880      0.334      2.358      0.018       0.133       1.443
C(answer_type_grouped)[T.Other]                0.0563      0.305      0.185      0.853      -0.541       0.653
C(answer_type_grouped)[T.Person]               0.1259      0.313      0.402      0.688      -0.488       0.740
q_length                                       0.2646      0.304      0.871      0.384      -0.331       0.860
capabilities_entropy                           1.3897      0.255      5.440      0.000       0.889       1.890
game_entropy                                   1.5597      0.231      6.750      0.000       1.107       2.013
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing qwen3-235b-a22b-2507 (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_new/qwen3-235b-a22b-2507_SimpleMC_redacted_cor_temp0.0_1756216549_game_data.json', './sc_logs_new/qwen3-235b-a22b-2507_SimpleMC_redacted_temp0.0_1756212978_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    345
1    155
Name: count, dtype: int64

Answer change%: 0.3100 [0.26946142474761914, 0.35053857525238086] (n=500)
P-value vs 25%: 0.003721; P-value vs 0%: 8.807e-51
Phase 2 self-accuracy: 0.2581 [0.18917875527731465, 0.32695027698074985] (n=155)
P-value vs 25%: 0.8185; P-value vs 33%: 0.033

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.04062
Time:                        20:27:18   Log-Likelihood:                -296.98
converged:                       True   LL-Null:                       -309.55
Covariance Type:            nonrobust   LLR p-value:                 5.305e-07
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          1.3727      0.442      3.106      0.002       0.506       2.239
p_i_capability    -2.5434      0.510     -4.985      0.000      -3.543      -1.543
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.04281
Time:                        20:27:18   Log-Likelihood:                -296.30
converged:                       True   LL-Null:                       -309.55
Covariance Type:            nonrobust   LLR p-value:                 2.627e-07
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.2396      0.136     -9.126      0.000      -1.506      -0.973
capabilities_entropy     0.8636      0.169      5.107      0.000       0.532       1.195
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.6581 [0.5834, 0.7327] (n=155)
                  P-value vs 33.3%: 1.557e-17

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=3.72, p=0.000238
Wilcoxon delta_p: statistic=13852.00, p=3.66e-05
Mean Δp = 0.0501  [0.0237, 0.0765]
Idea 1 N = 283; 

  Idea 1.5: Calibration Metrics
  NLL: 4.2324, Signed ECE (overconf pos under neg): -0.0295, ECE: 0.0799 (n=425)
  Brier: 0.0373, Reliability (absolute calibration error; lower better): 0.0191, Resolution (relative calibration quality; higher better): 0.2215, Uncertainty: 0.2395 (n=425)
  AUROC: 0.9962

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.697
Model:                            OLS   Adj. R-squared:                  0.695
Method:                 Least Squares   F-statistic:                     324.3
Date:                Fri, 19 Sep 2025   Prob (F-statistic):          3.00e-109
Time:                        20:27:18   Log-Likelihood:                 73.775
No. Observations:                 427   AIC:                            -139.5
Df Residuals:                     423   BIC:                            -123.3
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.5283      0.064     -8.257      0.000      -0.654      -0.403
p1                    0.6511      0.071      9.207      0.000       0.512       0.790
answer_changed        0.3309      0.096      3.463      0.001       0.143       0.519
p1:answer_changed     0.3625      0.111      3.274      0.001       0.145       0.580
==============================================================================
Omnibus:                       44.331   Durbin-Watson:                   1.970
Prob(Omnibus):                  0.000   Jarque-Bera (JB):              213.299
Skew:                           0.250   Prob(JB):                     4.82e-47
Kurtosis:                       6.426   Cond. No.                         22.9
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-4.53, p=8.58e-06
Wilcoxon delta_H: statistic=13930.00, p=7.73e-06
Mean ΔH = -0.1803  [-0.2583, -0.1024]
Paired t-test delta_H Changed: statistic=3.51, p=0.000605
Wilcoxon delta_H Changed: statistic=3726.00, p=0.00416
Mean ΔH Changed = 0.1704  [0.0751, 0.2656]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=-1.63, p=0.104
Wilcoxon (p_top2_game vs p_top2_base): statistic=33985.00, p=3.25e-06
Mean Δp_top2 = -0.0064  [-0.0142, 0.0013] (n=429)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=-1.91, p=0.0574
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=40099.00, p=0.0345
Mean ΔH_unchosen_baseline_set = -0.0610  [-0.1237, 0.0018] (n=429)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  429
Model:                          Logit   Df Residuals:                      426
Method:                           MLE   Df Model:                            2
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.03581
Time:                        20:27:18   Log-Likelihood:                -265.25
converged:                       True   LL-Null:                       -275.10
Covariance Type:            nonrobust   LLR p-value:                 5.269e-05
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.5008      0.157     -3.180      0.001      -0.809      -0.192
p1_z            -0.6364      0.175     -3.644      0.000      -0.979      -0.294
I(p1_z ** 2)    -0.1901      0.123     -1.547      0.122      -0.431       0.051
================================================================================
AUC = 0.618

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.05925
Time:                        20:27:18   Log-Likelihood:                -291.21
converged:                       True   LL-Null:                       -309.55
Covariance Type:            nonrobust   LLR p-value:                 1.393e-09
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.4455      0.155     -9.337      0.000      -1.749      -1.142
game_entropy     1.0921      0.185      5.917      0.000       0.730       1.454
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=46844.50, p=0.00122
Paired t-test (game_entropy vs capabilities_entropy): statistic=2.55, p=0.0111
Mean capabilities_entropy-game_entropy = -0.0741  [-0.1310, -0.0171] (n=500)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      497
Method:                           MLE   Df Model:                            2
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.07946
Time:                        20:27:18   Log-Likelihood:                -284.95
converged:                       True   LL-Null:                       -309.55
Covariance Type:            nonrobust   LLR p-value:                 2.079e-11
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.6596      0.171     -9.706      0.000      -1.995      -1.324
capabilities_entropy     0.6353      0.179      3.555      0.000       0.285       0.986
game_entropy             0.9076      0.192      4.718      0.000       0.531       1.285
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.786667
                        1                 0.213333
Geography               0                 0.613636
                        1                 0.386364
Misc                    0                 0.675676
                        1                 0.324324
Music                   0                 0.700000
                        1                 0.300000
Other                   0                 0.730769
                        1                 0.269231
Politics                0                 0.649351
                        1                 0.350649
Science and technology  0                 0.663265
                        1                 0.336735
Sports                  0                 0.700000
                        1                 0.300000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.668639
                     1                 0.331361
Number               0                 0.551282
                     1                 0.448718
Other                0                 0.714286
                     1                 0.285714
Person               0                 0.783333
                     1                 0.216667
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.714286  0.285714           21
                       Number               0.555556  0.444444            9
                       Other                0.833333  0.166667           18
                       Person               0.888889  0.111111           27
Geography              Date                 0.733333  0.266667           15
                       Number               0.555556  0.444444           18
                       Other                0.545455  0.454545           11
Misc                   Date                 0.652174  0.347826           23
                       Number               0.777778  0.222222            9
                       Other                0.629630  0.370370           27
                       Person               0.733333  0.266667           15
Music                  Date                 0.750000  0.250000           12
                       Number               0.000000  1.000000            4
                       Other                0.666667  0.333333           12
                       Person               0.916667  0.083333           12
Other                  Date                 0.611111  0.388889           18
                       Number               0.714286  0.285714            7
                       Other                0.714286  0.285714           14
                       Person               0.923077  0.076923           13
Politics               Date                 0.611111  0.388889           36
                       Number               0.333333  0.666667            6
                       Other                0.850000  0.150000           20
                       Person               0.600000  0.400000           15
Science and technology Date                 0.685714  0.314286           35
                       Number               0.428571  0.571429           14
                       Other                0.684211  0.315789           19
                       Person               0.733333  0.266667           30
Sports                 Date                 0.666667  0.333333            9
                       Number               0.727273  0.272727           11
                       Other                0.750000  0.250000           12
                       Person               0.625000  0.375000            8

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      488
Method:                           MLE   Df Model:                           11
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.02890
Time:                        20:27:18   Log-Likelihood:                -300.61
converged:                       True   LL-Null:                       -309.55
Covariance Type:            nonrobust   LLR p-value:                   0.08416
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -0.0336      1.234     -0.027      0.978      -2.451       2.384
C(topic_grouped)[T.Geography]                  0.5090      0.434      1.173      0.241      -0.341       1.359
C(topic_grouped)[T.Misc]                       0.5369      0.382      1.406      0.160      -0.211       1.285
C(topic_grouped)[T.Music]                      0.4520      0.451      1.002      0.317      -0.432       1.336
C(topic_grouped)[T.Other]                      0.2458      0.427      0.575      0.565      -0.591       1.083
C(topic_grouped)[T.Politics]                   0.7084      0.381      1.859      0.063      -0.038       1.455
C(topic_grouped)[T.Science and technology]     0.6168      0.360      1.715      0.086      -0.088       1.322
C(topic_grouped)[T.Sports]                     0.3132      0.454      0.690      0.490      -0.577       1.204
C(answer_type_grouped)[T.Number]               0.5448      0.290      1.876      0.061      -0.024       1.114
C(answer_type_grouped)[T.Other]               -0.2067      0.256     -0.808      0.419      -0.708       0.295
C(answer_type_grouped)[T.Person]              -0.5530      0.282     -1.960      0.050      -1.106   -2.31e-05
q_length                                      -0.2519      0.266     -0.949      0.343      -0.772       0.269
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.4631
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      487
Method:                           MLE   Df Model:                           12
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.06269
Time:                        20:27:18   Log-Likelihood:                -290.15
converged:                       True   LL-Null:                       -309.55
Covariance Type:            nonrobust   LLR p-value:                 0.0001131
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.1840      1.287     -0.920      0.358      -3.707       1.339
C(topic_grouped)[T.Geography]                  0.3673      0.445      0.824      0.410      -0.506       1.240
C(topic_grouped)[T.Misc]                       0.4350      0.392      1.111      0.267      -0.332       1.202
C(topic_grouped)[T.Music]                      0.5239      0.464      1.128      0.259      -0.386       1.434
C(topic_grouped)[T.Other]                      0.2366      0.435      0.544      0.586      -0.616       1.089
C(topic_grouped)[T.Politics]                   0.6132      0.389      1.578      0.115      -0.149       1.375
C(topic_grouped)[T.Science and technology]     0.5021      0.368      1.364      0.173      -0.220       1.224
C(topic_grouped)[T.Sports]                     0.3271      0.461      0.710      0.478      -0.576       1.230
C(answer_type_grouped)[T.Number]               0.5220      0.299      1.748      0.080      -0.063       1.107
C(answer_type_grouped)[T.Other]               -0.0877      0.263     -0.333      0.739      -0.603       0.428
C(answer_type_grouped)[T.Person]              -0.4638      0.288     -1.609      0.108      -1.029       0.101
q_length                                      -0.0838      0.274     -0.306      0.760      -0.621       0.453
capabilities_entropy                           0.7987      0.176      4.543      0.000       0.454       1.143
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      487
Method:                           MLE   Df Model:                           12
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.08196
Time:                        20:27:18   Log-Likelihood:                -284.18
converged:                       True   LL-Null:                       -309.55
Covariance Type:            nonrobust   LLR p-value:                 1.035e-06
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -0.7522      1.285     -0.585      0.558      -3.270       1.766
C(topic_grouped)[T.Geography]                  0.4487      0.450      0.998      0.318      -0.433       1.330
C(topic_grouped)[T.Misc]                       0.4913      0.394      1.246      0.213      -0.281       1.264
C(topic_grouped)[T.Music]                      0.4351      0.468      0.930      0.353      -0.482       1.353
C(topic_grouped)[T.Other]                      0.2716      0.439      0.619      0.536      -0.589       1.132
C(topic_grouped)[T.Politics]                   0.6738      0.394      1.708      0.088      -0.099       1.447
C(topic_grouped)[T.Science and technology]     0.6119      0.371      1.648      0.099      -0.116       1.340
C(topic_grouped)[T.Sports]                     0.2713      0.471      0.575      0.565      -0.653       1.195
C(answer_type_grouped)[T.Number]               0.7196      0.305      2.361      0.018       0.122       1.317
C(answer_type_grouped)[T.Other]                0.0205      0.269      0.076      0.939      -0.506       0.547
C(answer_type_grouped)[T.Person]              -0.3096      0.295     -1.049      0.294      -0.888       0.269
q_length                                      -0.2599      0.274     -0.947      0.343      -0.797       0.278
game_entropy                                   1.0690      0.190      5.612      0.000       0.696       1.442
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      486
Method:                           MLE   Df Model:                           13
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.09744
Time:                        20:27:18   Log-Likelihood:                -279.39
converged:                       True   LL-Null:                       -309.55
Covariance Type:            nonrobust   LLR p-value:                 4.591e-08
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.4742      1.321     -1.116      0.265      -4.064       1.116
C(topic_grouped)[T.Geography]                  0.3709      0.456      0.814      0.416      -0.522       1.264
C(topic_grouped)[T.Misc]                       0.4286      0.401      1.069      0.285      -0.357       1.214
C(topic_grouped)[T.Music]                      0.5009      0.474      1.057      0.290      -0.428       1.429
C(topic_grouped)[T.Other]                      0.2747      0.444      0.619      0.536      -0.596       1.145
C(topic_grouped)[T.Politics]                   0.6162      0.400      1.542      0.123      -0.167       1.399
C(topic_grouped)[T.Science and technology]     0.5369      0.377      1.425      0.154      -0.201       1.275
C(topic_grouped)[T.Sports]                     0.3117      0.472      0.660      0.509      -0.613       1.237
C(answer_type_grouped)[T.Number]               0.6782      0.309      2.198      0.028       0.074       1.283
C(answer_type_grouped)[T.Other]                0.0865      0.273      0.317      0.751      -0.449       0.621
C(answer_type_grouped)[T.Person]              -0.2706      0.299     -0.905      0.365      -0.856       0.315
q_length                                      -0.1410      0.280     -0.504      0.614      -0.689       0.407
capabilities_entropy                           0.5759      0.185      3.107      0.002       0.213       0.939
game_entropy                                   0.9093      0.198      4.592      0.000       0.521       1.297
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.
