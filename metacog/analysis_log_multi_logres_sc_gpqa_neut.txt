
--- Analyzing claude-3-5-sonnet-20241022 (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_neutral/claude-3-5-sonnet-20241022_GPQA_redacted_cor_temp0.0_1754437810_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    166
1     29
Name: count, dtype: int64

Answer change%: 0.1487 [0.09877787064691884, 0.1986580267889786] (n=195)
P-value vs 25%: 7.039e-05; P-value vs 0%: 5.327e-09
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=29)
P-value vs 25%: 0; P-value vs 33%: 0

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  195
Model:                          Logit   Df Residuals:                      193
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1893
Time:                        17:34:42   Log-Likelihood:                -66.476
converged:                       True   LL-Null:                       -81.993
Covariance Type:            nonrobust   LLR p-value:                 2.534e-08
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          2.2146      0.727      3.045      0.002       0.789       3.640
p_i_capability    -5.3666      1.028     -5.219      0.000      -7.382      -3.351
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  195
Model:                          Logit   Df Residuals:                      193
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1679
Time:                        17:34:42   Log-Likelihood:                -68.225
converged:                       True   LL-Null:                       -81.993
Covariance Type:            nonrobust   LLR p-value:                 1.542e-07
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -3.5379      0.485     -7.288      0.000      -4.489      -2.586
capabilities_entropy     1.9173      0.390      4.920      0.000       1.154       2.681
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.7241 [0.5615, 0.8868] (n=29)
                  P-value vs 33.3%: 2.493e-06

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=-4.23, p=3.83e-05
Wilcoxon delta_p: statistic=930.00, p=1.89e-05
Mean Δp = -0.0371  [-0.0542, -0.0199]
Idea 1 N = 166; 

  Idea 1.5: Calibration Metrics
  NLL: 0.2495, Signed ECE (overconf pos under neg): -0.1901, ECE: 0.1901 (n=195)
  Brier: 0.0745, Reliability (absolute calibration error; lower better): 0.0740, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=195)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.749
Model:                            OLS   Adj. R-squared:                  0.746
Method:                 Least Squares   F-statistic:                     190.4
Date:                Sat, 09 Aug 2025   Prob (F-statistic):           3.78e-57
Time:                        17:34:42   Log-Likelihood:                 171.22
No. Observations:                 195   AIC:                            -334.4
Df Residuals:                     191   BIC:                            -321.3
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.3585      0.039     -9.222      0.000      -0.435      -0.282
p1                    0.3804      0.045      8.444      0.000       0.292       0.469
answer_changed        0.2186      0.075      2.920      0.004       0.071       0.366
p1:answer_changed     0.4802      0.110      4.370      0.000       0.263       0.697
==============================================================================
Omnibus:                       20.759   Durbin-Watson:                   2.067
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               32.046
Skew:                           0.611   Prob(JB):                     1.10e-07
Kurtosis:                       4.566   Cond. No.                         24.1
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-0.35, p=0.729
Wilcoxon delta_H: statistic=1971.50, p=0.899
Mean ΔH = -0.0110  [-0.0732, 0.0512]
Paired t-test delta_H Changed: statistic=5.25, p=1.4e-05
Wilcoxon delta_H Changed: statistic=25.00, p=3.37e-06
Mean ΔH Changed = 0.3936  [0.2467, 0.5406]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=4.94, p=1.65e-06
Wilcoxon (p_top2_game vs p_top2_base): statistic=1662.50, p=6.95e-07
Mean Δp_top2 = 0.0226  [0.0136, 0.0315] (n=195)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=1.59, p=0.114
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=2813.50, p=0.0612
Mean ΔH_unchosen_baseline_set = 0.0492  [-0.0114, 0.1098] (n=195)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  195
Model:                          Logit   Df Residuals:                      192
Method:                           MLE   Df Model:                            2
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.2205
Time:                        17:34:42   Log-Likelihood:                -63.916
converged:                       True   LL-Null:                       -81.993
Covariance Type:            nonrobust   LLR p-value:                 1.409e-08
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.8425      0.305     -6.042      0.000      -2.440      -1.245
p1_z            -1.8281      0.432     -4.228      0.000      -2.676      -0.981
I(p1_z ** 2)    -0.5155      0.233     -2.216      0.027      -0.971      -0.060
================================================================================
AUC = 0.831

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  195
Model:                          Logit   Df Residuals:                      193
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1812
Time:                        17:34:42   Log-Likelihood:                -67.132
converged:                       True   LL-Null:                       -81.993
Covariance Type:            nonrobust   LLR p-value:                 4.987e-08
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -3.4913      0.460     -7.593      0.000      -4.393      -2.590
game_entropy     2.2387      0.435      5.141      0.000       1.385       3.092
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=1547.50, p=1.35e-07
Paired t-test (game_entropy vs capabilities_entropy): statistic=-5.07, p=9.26e-07
Mean capabilities_entropy-game_entropy = 0.1254  [0.0769, 0.1738] (n=195)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  195
Model:                          Logit   Df Residuals:                      192
Method:                           MLE   Df Model:                            2
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1970
Time:                        17:34:42   Log-Likelihood:                -65.840
converged:                       True   LL-Null:                       -81.993
Covariance Type:            nonrobust   LLR p-value:                 9.655e-08
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -3.7320      0.499     -7.472      0.000      -4.711      -2.753
capabilities_entropy     0.9378      0.586      1.600      0.110      -0.211       2.087
game_entropy             1.4318      0.660      2.169      0.030       0.138       2.726
========================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  195
Model:                          Logit   Df Residuals:                      193
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.01484
Time:                        17:34:42   Log-Likelihood:                -80.777
converged:                       True   LL-Null:                       -81.993
Covariance Type:            nonrobust   LLR p-value:                    0.1188
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -0.4037      0.873     -0.463      0.644      -2.114       1.306
human_difficulty    -0.5898      0.383     -1.540      0.124      -1.341       0.161
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  195
Model:                          Logit   Df Residuals:                      188
Method:                           MLE   Df Model:                            6
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.03897
Time:                        17:34:42   Log-Likelihood:                -78.798
converged:                       True   LL-Null:                       -81.993
Covariance Type:            nonrobust   LLR p-value:                    0.3810
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -2.4943      3.187     -0.783      0.434      -8.741       3.752
C(domain_grouped)[T.chemistry]        0.7458      0.674      1.107      0.268      -0.575       2.067
C(domain_grouped)[T.physics]          0.5803      0.661      0.877      0.380      -0.716       1.877
human_difficulty                     -0.5115      0.397     -1.288      0.198      -1.290       0.267
q_length                              0.4376      0.374      1.171      0.242      -0.295       1.170
avg_word_length                      -0.2630      0.373     -0.705      0.481      -0.994       0.468
percent_non_alphabetic_whitespace    -0.0006      0.039     -0.015      0.988      -0.078       0.076
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 0.7453
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  195
Model:                          Logit   Df Residuals:                      187
Method:                           MLE   Df Model:                            7
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1866
Time:                        17:34:42   Log-Likelihood:                -66.695
converged:                       True   LL-Null:                       -81.993
Covariance Type:            nonrobust   LLR p-value:                 7.378e-05
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -4.6984      3.446     -1.364      0.173     -11.452       2.055
C(domain_grouped)[T.chemistry]        0.1190      0.732      0.162      0.871      -1.316       1.554
C(domain_grouped)[T.physics]          0.2356      0.709      0.332      0.740      -1.154       1.625
human_difficulty                     -0.6441      0.458     -1.406      0.160      -1.542       0.254
q_length                              0.2448      0.405      0.605      0.545      -0.549       1.038
avg_word_length                       0.1508      0.367      0.411      0.681      -0.569       0.870
percent_non_alphabetic_whitespace     0.0336      0.042      0.792      0.428      -0.050       0.117
capabilities_entropy                  1.9370      0.425      4.561      0.000       1.105       2.769
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  195
Model:                          Logit   Df Residuals:                      187
Method:                           MLE   Df Model:                            7
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.2068
Time:                        17:34:42   Log-Likelihood:                -65.040
converged:                       True   LL-Null:                       -81.993
Covariance Type:            nonrobust   LLR p-value:                 1.793e-05
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -5.0424      3.366     -1.498      0.134     -11.639       1.554
C(domain_grouped)[T.chemistry]       -0.3014      0.766     -0.394      0.694      -1.802       1.199
C(domain_grouped)[T.physics]         -0.1717      0.772     -0.222      0.824      -1.686       1.342
human_difficulty                     -0.7768      0.475     -1.634      0.102      -1.709       0.155
q_length                              0.3750      0.409      0.917      0.359      -0.426       1.176
avg_word_length                       0.1737      0.369      0.471      0.637      -0.549       0.896
percent_non_alphabetic_whitespace     0.0426      0.043      0.983      0.326      -0.042       0.128
game_entropy                          2.3641      0.487      4.858      0.000       1.410       3.318
=====================================================================================================

                  Model 4.95: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  195
Model:                          Logit   Df Residuals:                      186
Method:                           MLE   Df Model:                            8
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.2195
Time:                        17:34:42   Log-Likelihood:                -63.992
converged:                       True   LL-Null:                       -81.993
Covariance Type:            nonrobust   LLR p-value:                 1.754e-05
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -5.2173      3.391     -1.539      0.124     -11.864       1.429
C(domain_grouped)[T.chemistry]       -0.3138      0.764     -0.411      0.681      -1.811       1.184
C(domain_grouped)[T.physics]         -0.1425      0.759     -0.188      0.851      -1.629       1.344
human_difficulty                     -0.7523      0.481     -1.564      0.118      -1.695       0.190
q_length                              0.2934      0.412      0.712      0.477      -0.515       1.101
avg_word_length                       0.2441      0.363      0.673      0.501      -0.467       0.955
percent_non_alphabetic_whitespace     0.0445      0.044      1.022      0.307      -0.041       0.130
capabilities_entropy                  0.8913      0.618      1.442      0.149      -0.320       2.102
game_entropy                          1.6199      0.703      2.303      0.021       0.241       2.998
=====================================================================================================

--- Analyzing claude-3-5-sonnet-20241022 (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_neutral/claude-3-5-sonnet-20241022_GPQA_redacted_temp0.0_1754429083_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    176
1     76
Name: count, dtype: int64

Answer change%: 0.3016 [0.24492288653530575, 0.3582517166392974] (n=252)
P-value vs 25%: 0.07437; P-value vs 0%: 1.779e-25
Phase 2 self-accuracy: 0.3553 [0.247664309130959, 0.4628620066585147] (n=76)
P-value vs 25%: 0.05518; P-value vs 33%: 0.6851

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  252
Model:                          Logit   Df Residuals:                      250
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1058
Time:                        17:34:42   Log-Likelihood:                -137.95
converged:                       True   LL-Null:                       -154.28
Covariance Type:            nonrobust   LLR p-value:                 1.098e-08
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          1.7255      0.485      3.560      0.000       0.776       2.675
p_i_capability    -4.0868      0.776     -5.265      0.000      -5.608      -2.565
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  252
Model:                          Logit   Df Residuals:                      250
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1022
Time:                        17:34:42   Log-Likelihood:                -138.51
converged:                       True   LL-Null:                       -154.28
Covariance Type:            nonrobust   LLR p-value:                 1.955e-08
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.8268      0.443     -6.381      0.000      -3.695      -1.959
capabilities_entropy     1.5803      0.310      5.092      0.000       0.972       2.189
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.7105 [0.6086, 0.8125] (n=76)
                  P-value vs 33.3%: 4.148e-13

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=-6.70, p=2.79e-10
Wilcoxon delta_p: statistic=2572.00, p=5.49e-10
Mean Δp = -0.0800  [-0.1034, -0.0566]
Idea 1 N = 176; 

  Idea 1.5: Calibration Metrics
  NLL: 2.6878, Signed ECE (overconf pos under neg): 0.1284, ECE: 0.1284 (n=252)
  Brier: 0.0300, Reliability (absolute calibration error; lower better): 0.0292, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=252)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.752
Model:                            OLS   Adj. R-squared:                  0.749
Method:                 Least Squares   F-statistic:                     251.0
Date:                Sat, 09 Aug 2025   Prob (F-statistic):           7.88e-75
Time:                        17:34:42   Log-Likelihood:                 148.03
No. Observations:                 252   AIC:                            -288.1
Df Residuals:                     248   BIC:                            -273.9
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.3666      0.037     -9.925      0.000      -0.439      -0.294
p1                    0.4035      0.050      8.074      0.000       0.305       0.502
answer_changed        0.1128      0.064      1.771      0.078      -0.013       0.238
p1:answer_changed     0.6954      0.103      6.764      0.000       0.493       0.898
==============================================================================
Omnibus:                        0.971   Durbin-Watson:                   1.806
Prob(Omnibus):                  0.615   Jarque-Bera (JB):                0.689
Skew:                           0.089   Prob(JB):                        0.709
Kurtosis:                       3.184   Cond. No.                         18.4
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=0.11, p=0.911
Wilcoxon delta_H: statistic=5634.00, p=0.463
Mean ΔH = 0.0039  [-0.0643, 0.0721]
Paired t-test delta_H Changed: statistic=9.65, p=8.57e-15
Wilcoxon delta_H Changed: statistic=74.00, p=6.42e-13
Mean ΔH Changed = 0.4294  [0.3422, 0.5166]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=9.32, p=6.01e-18
Wilcoxon (p_top2_game vs p_top2_base): statistic=4666.50, p=8.91e-18
Mean Δp_top2 = 0.0454  [0.0359, 0.0550] (n=252)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=4.36, p=1.89e-05
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=8310.00, p=5.62e-07
Mean ΔH_unchosen_baseline_set = 0.1322  [0.0728, 0.1917] (n=252)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  252
Model:                          Logit   Df Residuals:                      249
Method:                           MLE   Df Model:                            2
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1082
Time:                        17:34:42   Log-Likelihood:                -137.58
converged:                       True   LL-Null:                       -154.28
Covariance Type:            nonrobust   LLR p-value:                 5.611e-08
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.8491      0.218     -3.901      0.000      -1.276      -0.422
p1_z            -0.8892      0.174     -5.117      0.000      -1.230      -0.549
I(p1_z ** 2)    -0.1583      0.186     -0.850      0.395      -0.523       0.207
================================================================================
AUC = 0.719

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  252
Model:                          Logit   Df Residuals:                      250
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1006
Time:                        17:34:42   Log-Likelihood:                -138.75
converged:                       True   LL-Null:                       -154.28
Covariance Type:            nonrobust   LLR p-value:                 2.518e-08
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -2.3936      0.349     -6.860      0.000      -3.077      -1.710
game_entropy     1.5370      0.293      5.249      0.000       0.963       2.111
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=4535.50, p=2.88e-18
Paired t-test (game_entropy vs capabilities_entropy): statistic=-9.66, p=5.66e-19
Mean capabilities_entropy-game_entropy = 0.2298  [0.1832, 0.2764] (n=252)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  252
Model:                          Logit   Df Residuals:                      249
Method:                           MLE   Df Model:                            2
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1161
Time:                        17:34:42   Log-Likelihood:                -136.37
converged:                       True   LL-Null:                       -154.28
Covariance Type:            nonrobust   LLR p-value:                 1.673e-08
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.8825      0.439     -6.563      0.000      -3.743      -2.022
capabilities_entropy     0.9433      0.435      2.167      0.030       0.090       1.796
game_entropy             0.8487      0.418      2.030      0.042       0.029       1.668
========================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  252
Model:                          Logit   Df Residuals:                      250
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:               0.0007880
Time:                        17:34:42   Log-Likelihood:                -154.15
converged:                       True   LL-Null:                       -154.28
Covariance Type:            nonrobust   LLR p-value:                    0.6220
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -1.1128      0.572     -1.947      0.052      -2.233       0.007
human_difficulty     0.1134      0.230      0.494      0.621      -0.337       0.564
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  252
Model:                          Logit   Df Residuals:                      245
Method:                           MLE   Df Model:                            6
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.02412
Time:                        17:34:42   Log-Likelihood:                -150.55
converged:                       True   LL-Null:                       -154.28
Covariance Type:            nonrobust   LLR p-value:                    0.2820
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                             0.1502      2.271      0.066      0.947      -4.302       4.602
C(domain_grouped)[T.chemistry]       -0.0404      0.523     -0.077      0.938      -1.065       0.984
C(domain_grouped)[T.physics]          0.3106      0.530      0.586      0.558      -0.728       1.349
human_difficulty                      0.1411      0.242      0.584      0.559      -0.332       0.615
q_length                              0.1039      0.230      0.452      0.651      -0.347       0.554
avg_word_length                      -0.4287      0.271     -1.584      0.113      -0.959       0.102
percent_non_alphabetic_whitespace    -0.0144      0.026     -0.551      0.582      -0.066       0.037
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 1.1634
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  252
Model:                          Logit   Df Residuals:                      244
Method:                           MLE   Df Model:                            7
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1292
Time:                        17:34:42   Log-Likelihood:                -134.34
converged:                       True   LL-Null:                       -154.28
Covariance Type:            nonrobust   LLR p-value:                 1.336e-06
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -2.7075      2.488     -1.088      0.276      -7.583       2.168
C(domain_grouped)[T.chemistry]       -0.8276      0.583     -1.420      0.155      -1.970       0.314
C(domain_grouped)[T.physics]         -0.2221      0.591     -0.376      0.707      -1.381       0.937
human_difficulty                      0.2132      0.261      0.819      0.413      -0.297       0.724
q_length                              0.1397      0.254      0.549      0.583      -0.359       0.638
avg_word_length                      -0.2639      0.289     -0.915      0.360      -0.830       0.302
percent_non_alphabetic_whitespace     0.0051      0.028      0.181      0.856      -0.050       0.060
capabilities_entropy                  1.7054      0.330      5.169      0.000       1.059       2.352
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  252
Model:                          Logit   Df Residuals:                      244
Method:                           MLE   Df Model:                            7
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1261
Time:                        17:34:42   Log-Likelihood:                -134.82
converged:                       True   LL-Null:                       -154.28
Covariance Type:            nonrobust   LLR p-value:                 2.037e-06
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -1.9578      2.441     -0.802      0.423      -6.743       2.827
C(domain_grouped)[T.chemistry]       -0.6597      0.566     -1.167      0.243      -1.768       0.449
C(domain_grouped)[T.physics]         -0.0302      0.567     -0.053      0.958      -1.141       1.080
human_difficulty                      0.2556      0.262      0.976      0.329      -0.258       0.769
q_length                              0.0307      0.250      0.123      0.902      -0.458       0.520
avg_word_length                      -0.2471      0.281     -0.879      0.380      -0.798       0.304
percent_non_alphabetic_whitespace     0.0101      0.028      0.366      0.715      -0.044       0.064
game_entropy                          1.6381      0.313      5.240      0.000       1.025       2.251
=====================================================================================================

                  Model 4.95: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  252
Model:                          Logit   Df Residuals:                      243
Method:                           MLE   Df Model:                            8
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1443
Time:                        17:34:42   Log-Likelihood:                -132.01
converged:                       True   LL-Null:                       -154.28
Covariance Type:            nonrobust   LLR p-value:                 4.515e-07
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -2.7750      2.495     -1.112      0.266      -7.665       2.115
C(domain_grouped)[T.chemistry]       -0.8732      0.583     -1.498      0.134      -2.016       0.269
C(domain_grouped)[T.physics]         -0.2071      0.586     -0.353      0.724      -1.356       0.942
human_difficulty                      0.2553      0.265      0.965      0.335      -0.263       0.774
q_length                              0.0838      0.257      0.326      0.744      -0.419       0.587
avg_word_length                      -0.2271      0.289     -0.787      0.431      -0.793       0.338
percent_non_alphabetic_whitespace     0.0112      0.028      0.398      0.691      -0.044       0.067
capabilities_entropy                  1.0500      0.446      2.353      0.019       0.175       1.925
game_entropy                          0.9038      0.427      2.119      0.034       0.068       1.740
=====================================================================================================

--- Analyzing claude-3-haiku-20240307 (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_neutral/claude-3-haiku-20240307_GPQA_redacted_cor_temp0.0_1754422886_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    124
1     28
Name: count, dtype: int64

Answer change%: 0.1842 [0.12258330770936504, 0.24583774492221389] (n=152)
P-value vs 25%: 0.03641; P-value vs 0%: 4.669e-09
Phase 2 self-accuracy: 0.0714 [0.0, 0.16682073868459768] (n=28)
P-value vs 25%: 0.0002435; P-value vs 33%: 7.686e-08

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  152
Model:                          Logit   Df Residuals:                      150
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1709
Time:                        17:34:42   Log-Likelihood:                -60.203
converged:                       True   LL-Null:                       -72.613
Covariance Type:            nonrobust   LLR p-value:                 6.295e-07
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          4.0337      1.137      3.548      0.000       1.806       6.262
p_i_capability    -6.5265      1.360     -4.800      0.000      -9.191      -3.862
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  152
Model:                          Logit   Df Residuals:                      150
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1557
Time:                        17:34:42   Log-Likelihood:                -61.309
converged:                       True   LL-Null:                       -72.613
Covariance Type:            nonrobust   LLR p-value:                 1.986e-06
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -3.0953      0.454     -6.811      0.000      -3.986      -2.205
capabilities_entropy     2.8585      0.633      4.515      0.000       1.618       4.099
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.6071 [0.4262, 0.7880] (n=28)
                  P-value vs 33.3%: 0.003011

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=-0.38, p=0.708
Wilcoxon delta_p: statistic=467.00, p=0.942
Mean Δp = -0.0046  [-0.0288, 0.0196]
Idea 1 N = 124; 

  Idea 1.5: Calibration Metrics
  NLL: 0.1565, Signed ECE (overconf pos under neg): -0.1233, ECE: 0.1233 (n=152)
  Brier: 0.0413, Reliability (absolute calibration error; lower better): 0.0410, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=152)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.857
Model:                            OLS   Adj. R-squared:                  0.854
Method:                 Least Squares   F-statistic:                     296.2
Date:                Sat, 09 Aug 2025   Prob (F-statistic):           2.54e-62
Time:                        17:34:42   Log-Likelihood:                 119.23
No. Observations:                 152   AIC:                            -230.5
Df Residuals:                     148   BIC:                            -218.4
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.7091      0.080     -8.876      0.000      -0.867      -0.551
p1                    0.7713      0.087      8.888      0.000       0.600       0.943
answer_changed        0.5611      0.125      4.485      0.000       0.314       0.808
p1:answer_changed     0.2687      0.152      1.765      0.080      -0.032       0.570
==============================================================================
Omnibus:                       48.051   Durbin-Watson:                   1.851
Prob(Omnibus):                  0.000   Jarque-Bera (JB):              113.292
Skew:                           1.332   Prob(JB):                     2.51e-25
Kurtosis:                       6.285   Cond. No.                         31.6
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-1.00, p=0.319
Wilcoxon delta_H: statistic=378.00, p=0.251
Mean ΔH = -0.0502  [-0.1484, 0.0481]
Paired t-test delta_H Changed: statistic=2.87, p=0.00797
Wilcoxon delta_H Changed: statistic=116.00, p=0.0476
Mean ΔH Changed = 0.3967  [0.1253, 0.6680]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=-0.63, p=0.531
Wilcoxon (p_top2_game vs p_top2_base): statistic=890.00, p=0.0576
Mean Δp_top2 = -0.0017  [-0.0071, 0.0037] (n=152)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=0.64, p=0.521
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=1192.00, p=0.622
Mean ΔH_unchosen_baseline_set = 0.0321  [-0.0658, 0.1301] (n=152)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  152
Model:                          Logit   Df Residuals:                      149
Method:                           MLE   Df Model:                            2
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.2132
Time:                        17:34:42   Log-Likelihood:                -57.134
converged:                       True   LL-Null:                       -72.613
Covariance Type:            nonrobust   LLR p-value:                 1.894e-07
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.1950      0.335     -3.567      0.000      -1.852      -0.538
p1_z            -2.0652      0.508     -4.069      0.000      -3.060      -1.070
I(p1_z ** 2)    -0.6423      0.261     -2.457      0.014      -1.155      -0.130
================================================================================
AUC = 0.759

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  152
Model:                          Logit   Df Residuals:                      150
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.08064
Time:                        17:34:42   Log-Likelihood:                -66.758
converged:                       True   LL-Null:                       -72.613
Covariance Type:            nonrobust   LLR p-value:                 0.0006214
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -2.5729      0.407     -6.328      0.000      -3.370      -1.776
game_entropy     2.1257      0.618      3.438      0.001       0.914       3.338
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=1076.00, p=0.432
Paired t-test (game_entropy vs capabilities_entropy): statistic=-1.04, p=0.302
Mean capabilities_entropy-game_entropy = 0.0282  [-0.0252, 0.0815] (n=152)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  152
Model:                          Logit   Df Residuals:                      149
Method:                           MLE   Df Model:                            2
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1764
Time:                        17:34:42   Log-Likelihood:                -59.808
converged:                       True   LL-Null:                       -72.613
Covariance Type:            nonrobust   LLR p-value:                 2.745e-06
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -3.4969      0.530     -6.598      0.000      -4.536      -2.458
capabilities_entropy     2.4679      0.672      3.670      0.000       1.150       3.786
game_entropy             1.2373      0.710      1.742      0.082      -0.155       2.629
========================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  152
Model:                          Logit   Df Residuals:                      150
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                0.002542
Time:                        17:34:42   Log-Likelihood:                -72.429
converged:                       True   LL-Null:                       -72.613
Covariance Type:            nonrobust   LLR p-value:                    0.5435
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -2.0475      0.950     -2.156      0.031      -3.909      -0.186
human_difficulty     0.2348      0.385      0.609      0.542      -0.520       0.990
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  152
Model:                          Logit   Df Residuals:                      145
Method:                           MLE   Df Model:                            6
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.04482
Time:                        17:34:42   Log-Likelihood:                -69.358
converged:                       True   LL-Null:                       -72.613
Covariance Type:            nonrobust   LLR p-value:                    0.3686
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                             2.2333      3.508      0.637      0.524      -4.643       9.110
C(domain_grouped)[T.chemistry]        1.1059      0.678      1.631      0.103      -0.223       2.435
C(domain_grouped)[T.physics]          0.4460      0.683      0.653      0.514      -0.893       1.785
human_difficulty                      0.3237      0.397      0.815      0.415      -0.455       1.102
q_length                             -0.4964      0.417     -1.190      0.234      -1.314       0.322
avg_word_length                      -0.3561      0.368     -0.968      0.333      -1.078       0.365
percent_non_alphabetic_whitespace    -0.0686      0.045     -1.534      0.125      -0.156       0.019
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 0.4847
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  152
Model:                          Logit   Df Residuals:                      144
Method:                           MLE   Df Model:                            7
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1964
Time:                        17:34:42   Log-Likelihood:                -58.356
converged:                       True   LL-Null:                       -72.613
Covariance Type:            nonrobust   LLR p-value:                 0.0001773
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                             0.9995      3.714      0.269      0.788      -6.279       8.278
C(domain_grouped)[T.chemistry]        0.6027      0.734      0.821      0.412      -0.836       2.041
C(domain_grouped)[T.physics]         -0.1127      0.736     -0.153      0.878      -1.555       1.330
human_difficulty                      0.4663      0.447      1.042      0.297      -0.411       1.343
q_length                             -0.7475      0.450     -1.662      0.096      -1.629       0.134
avg_word_length                      -0.1527      0.390     -0.392      0.695      -0.916       0.611
percent_non_alphabetic_whitespace    -0.0507      0.050     -1.022      0.307      -0.148       0.047
capabilities_entropy                  3.0366      0.701      4.331      0.000       1.662       4.411
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  152
Model:                          Logit   Df Residuals:                      144
Method:                           MLE   Df Model:                            7
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1160
Time:                        17:34:42   Log-Likelihood:                -64.187
converged:                       True   LL-Null:                       -72.613
Covariance Type:            nonrobust   LLR p-value:                   0.01838
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                             1.3251      3.526      0.376      0.707      -5.587       8.237
C(domain_grouped)[T.chemistry]        0.6939      0.702      0.988      0.323      -0.683       2.070
C(domain_grouped)[T.physics]          0.1728      0.714      0.242      0.809      -1.226       1.572
human_difficulty                      0.4308      0.422      1.020      0.308      -0.397       1.258
q_length                             -0.6625      0.438     -1.512      0.130      -1.521       0.196
avg_word_length                      -0.2078      0.353     -0.589      0.556      -0.899       0.484
percent_non_alphabetic_whitespace    -0.0516      0.046     -1.115      0.265      -0.142       0.039
game_entropy                          2.1088      0.665      3.173      0.002       0.806       3.412
=====================================================================================================

                  Model 4.95: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  152
Model:                          Logit   Df Residuals:                      143
Method:                           MLE   Df Model:                            8
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.2168
Time:                        17:34:42   Log-Likelihood:                -56.867
converged:                       True   LL-Null:                       -72.613
Covariance Type:            nonrobust   LLR p-value:                 0.0001148
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                             0.4831      3.656      0.132      0.895      -6.682       7.648
C(domain_grouped)[T.chemistry]        0.4058      0.743      0.546      0.585      -1.050       1.862
C(domain_grouped)[T.physics]         -0.2062      0.746     -0.276      0.782      -1.668       1.256
human_difficulty                      0.5164      0.453      1.139      0.255      -0.372       1.405
q_length                             -0.8152      0.461     -1.770      0.077      -1.718       0.088
avg_word_length                      -0.0712      0.371     -0.192      0.848      -0.798       0.656
percent_non_alphabetic_whitespace    -0.0415      0.049     -0.838      0.402      -0.138       0.056
capabilities_entropy                  2.6737      0.730      3.660      0.000       1.242       4.105
game_entropy                          1.2941      0.750      1.726      0.084      -0.176       2.764
=====================================================================================================

--- Analyzing claude-3-haiku-20240307 (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_neutral/claude-3-haiku-20240307_GPQA_redacted_temp0.0_1754341516_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    237
1     58
Name: count, dtype: int64

Answer change%: 0.1966 [0.15125746012944494, 0.24196287885360593] (n=295)
P-value vs 25%: 0.02104; P-value vs 0%: 1.95e-17
Phase 2 self-accuracy: 0.2586 [0.14593053939027428, 0.3713108399200706] (n=58)
P-value vs 25%: 0.8808; P-value vs 33%: 0.1958

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  295
Model:                          Logit   Df Residuals:                      293
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1189
Time:                        17:34:42   Log-Likelihood:                -128.83
converged:                       True   LL-Null:                       -146.22
Covariance Type:            nonrobust   LLR p-value:                 3.701e-09
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          3.2698      0.808      4.047      0.000       1.686       4.853
p_i_capability    -5.3985      0.933     -5.786      0.000      -7.227      -3.570
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  295
Model:                          Logit   Df Residuals:                      293
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1503
Time:                        17:34:42   Log-Likelihood:                -124.24
converged:                       True   LL-Null:                       -146.22
Covariance Type:            nonrobust   LLR p-value:                 3.360e-11
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.9440      0.307     -9.590      0.000      -3.546      -2.342
capabilities_entropy     2.9620      0.469      6.314      0.000       2.043       3.882
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.5517 [0.4237, 0.6797] (n=58)
                  P-value vs 33.3%: 0.0008247

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=0.92, p=0.358
Wilcoxon delta_p: statistic=1439.00, p=0.491
Mean Δp = 0.0078  [-0.0088, 0.0243]
Idea 1 N = 237; 

  Idea 1.5: Calibration Metrics
  NLL: 4.2117, Signed ECE (overconf pos under neg): 0.0400, ECE: 0.0400 (n=295)
  Brier: 0.0110, Reliability (absolute calibration error; lower better): 0.0108, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=295)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.876
Model:                            OLS   Adj. R-squared:                  0.875
Method:                 Least Squares   F-statistic:                     684.4
Date:                Sat, 09 Aug 2025   Prob (F-statistic):          1.87e-131
Time:                        17:34:42   Log-Likelihood:                 231.14
No. Observations:                 295   AIC:                            -454.3
Df Residuals:                     291   BIC:                            -439.5
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.5950      0.059    -10.039      0.000      -0.712      -0.478
p1                    0.6554      0.064     10.247      0.000       0.529       0.781
answer_changed        0.5096      0.088      5.810      0.000       0.337       0.682
p1:answer_changed     0.3414      0.102      3.330      0.001       0.140       0.543
==============================================================================
Omnibus:                       80.433   Durbin-Watson:                   2.058
Prob(Omnibus):                  0.000   Jarque-Bera (JB):              262.073
Skew:                           1.170   Prob(JB):                     1.23e-57
Kurtosis:                       6.981   Cond. No.                         31.3
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=1.20, p=0.231
Wilcoxon delta_H: statistic=1344.00, p=0.249
Mean ΔH = 0.0438  [-0.0277, 0.1152]
Paired t-test delta_H Changed: statistic=6.60, p=1.5e-08
Wilcoxon delta_H Changed: statistic=217.00, p=7.61e-07
Mean ΔH Changed = 0.5838  [0.4103, 0.7572]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=0.38, p=0.707
Wilcoxon (p_top2_game vs p_top2_base): statistic=4103.50, p=0.954
Mean Δp_top2 = 0.0007  [-0.0029, 0.0043] (n=295)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=4.14, p=4.55e-05
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=2884.00, p=7.53e-05
Mean ΔH_unchosen_baseline_set = 0.1499  [0.0790, 0.2209] (n=295)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  295
Model:                          Logit   Df Residuals:                      292
Method:                           MLE   Df Model:                            2
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1528
Time:                        17:34:42   Log-Likelihood:                -123.88
converged:                       True   LL-Null:                       -146.22
Covariance Type:            nonrobust   LLR p-value:                 1.988e-10
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.0809      0.228     -4.750      0.000      -1.527      -0.635
p1_z            -1.8743      0.391     -4.799      0.000      -2.640      -1.109
I(p1_z ** 2)    -0.5344      0.177     -3.016      0.003      -0.882      -0.187
================================================================================
AUC = 0.748

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  295
Model:                          Logit   Df Residuals:                      293
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.03033
Time:                        17:34:42   Log-Likelihood:                -141.79
converged:                       True   LL-Null:                       -146.22
Covariance Type:            nonrobust   LLR p-value:                  0.002898
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -2.0754      0.275     -7.544      0.000      -2.615      -1.536
game_entropy     1.3947      0.456      3.061      0.002       0.502       2.288
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=3971.50, p=0.71
Paired t-test (game_entropy vs capabilities_entropy): statistic=-0.47, p=0.64
Mean capabilities_entropy-game_entropy = 0.0093  [-0.0298, 0.0485] (n=295)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  295
Model:                          Logit   Df Residuals:                      292
Method:                           MLE   Df Model:                            2
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1549
Time:                        17:34:42   Log-Likelihood:                -123.57
converged:                       True   LL-Null:                       -146.22
Covariance Type:            nonrobust   LLR p-value:                 1.446e-10
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -3.1639      0.367     -8.616      0.000      -3.884      -2.444
capabilities_entropy     2.8087      0.483      5.810      0.000       1.861       3.756
game_entropy             0.6297      0.533      1.182      0.237      -0.415       1.674
========================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  295
Model:                          Logit   Df Residuals:                      293
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                0.007179
Time:                        17:34:42   Log-Likelihood:                -145.17
converged:                       True   LL-Null:                       -146.22
Covariance Type:            nonrobust   LLR p-value:                    0.1474
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -0.5513      0.607     -0.909      0.363      -1.740       0.638
human_difficulty    -0.3664      0.256     -1.431      0.152      -0.868       0.135
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  295
Model:                          Logit   Df Residuals:                      288
Method:                           MLE   Df Model:                            6
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.04744
Time:                        17:34:42   Log-Likelihood:                -139.28
converged:                       True   LL-Null:                       -146.22
Covariance Type:            nonrobust   LLR p-value:                   0.03108
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                             1.2601      2.314      0.545      0.586      -3.276       5.796
C(domain_grouped)[T.chemistry]        0.6454      0.515      1.253      0.210      -0.364       1.655
C(domain_grouped)[T.physics]         -0.2343      0.540     -0.434      0.664      -1.292       0.823
human_difficulty                     -0.3364      0.279     -1.206      0.228      -0.883       0.210
q_length                              0.2468      0.244      1.012      0.311      -0.231       0.725
avg_word_length                      -0.7134      0.305     -2.339      0.019      -1.311      -0.116
percent_non_alphabetic_whitespace    -0.0411      0.030     -1.377      0.168      -0.100       0.017
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 0.4562
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  295
Model:                          Logit   Df Residuals:                      287
Method:                           MLE   Df Model:                            7
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1843
Time:                        17:34:42   Log-Likelihood:                -119.28
converged:                       True   LL-Null:                       -146.22
Covariance Type:            nonrobust   LLR p-value:                 2.476e-09
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                             0.2470      2.574      0.096      0.924      -4.798       5.292
C(domain_grouped)[T.chemistry]        0.4690      0.550      0.853      0.393      -0.608       1.546
C(domain_grouped)[T.physics]         -0.4113      0.581     -0.707      0.479      -1.551       0.728
human_difficulty                     -0.3242      0.304     -1.066      0.286      -0.920       0.272
q_length                              0.1723      0.269      0.641      0.521      -0.354       0.699
avg_word_length                      -0.6662      0.336     -1.982      0.048      -1.325      -0.007
percent_non_alphabetic_whitespace    -0.0584      0.034     -1.726      0.084      -0.125       0.008
capabilities_entropy                  2.9386      0.494      5.947      0.000       1.970       3.907
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  295
Model:                          Logit   Df Residuals:                      287
Method:                           MLE   Df Model:                            7
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.07574
Time:                        17:34:42   Log-Likelihood:                -135.15
converged:                       True   LL-Null:                       -146.22
Covariance Type:            nonrobust   LLR p-value:                  0.002395
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                             0.2639      2.371      0.111      0.911      -4.383       4.910
C(domain_grouped)[T.chemistry]        0.5573      0.524      1.063      0.288      -0.470       1.585
C(domain_grouped)[T.physics]         -0.3758      0.555     -0.678      0.498      -1.463       0.711
human_difficulty                     -0.3601      0.286     -1.259      0.208      -0.921       0.200
q_length                              0.2835      0.246      1.151      0.250      -0.199       0.766
avg_word_length                      -0.6636      0.307     -2.160      0.031      -1.266      -0.061
percent_non_alphabetic_whitespace    -0.0361      0.030     -1.200      0.230      -0.095       0.023
game_entropy                          1.3880      0.474      2.930      0.003       0.460       2.316
=====================================================================================================

                  Model 4.95: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  295
Model:                          Logit   Df Residuals:                      286
Method:                           MLE   Df Model:                            8
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1890
Time:                        17:34:42   Log-Likelihood:                -118.58
converged:                       True   LL-Null:                       -146.22
Covariance Type:            nonrobust   LLR p-value:                 3.884e-09
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -0.1954      2.593     -0.075      0.940      -5.278       4.887
C(domain_grouped)[T.chemistry]        0.4185      0.549      0.762      0.446      -0.658       1.495
C(domain_grouped)[T.physics]         -0.4951      0.587     -0.843      0.399      -1.646       0.656
human_difficulty                     -0.3427      0.308     -1.114      0.265      -0.946       0.260
q_length                              0.1979      0.267      0.741      0.459      -0.325       0.721
avg_word_length                      -0.6378      0.336     -1.898      0.058      -1.296       0.021
percent_non_alphabetic_whitespace    -0.0548      0.034     -1.626      0.104      -0.121       0.011
capabilities_entropy                  2.7783      0.508      5.465      0.000       1.782       3.775
game_entropy                          0.6597      0.550      1.198      0.231      -0.419       1.739
=====================================================================================================

--- Analyzing claude-3-sonnet-20240229 (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_neutral/claude-3-sonnet-20240229_GPQA_redacted_cor_temp0.0_1751845558_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    119
1     27
Name: count, dtype: int64

Answer change%: 0.1849 [0.12195563768895391, 0.24790737600967622] (n=146)
P-value vs 25%: 0.04286; P-value vs 0%: 8.637e-09
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=27)
P-value vs 25%: 0; P-value vs 33%: 0

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  146
Model:                          Logit   Df Residuals:                      144
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1085
Time:                        17:34:42   Log-Likelihood:                -62.321
converged:                       True   LL-Null:                       -69.903
Covariance Type:            nonrobust   LLR p-value:                 9.855e-05
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          1.6651      0.819      2.034      0.042       0.060       3.270
p_i_capability    -4.2041      1.116     -3.766      0.000      -6.392      -2.016
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  146
Model:                          Logit   Df Residuals:                      144
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1075
Time:                        17:34:42   Log-Likelihood:                -62.386
converged:                       True   LL-Null:                       -69.903
Covariance Type:            nonrobust   LLR p-value:                 0.0001055
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.9486      0.504     -5.853      0.000      -3.936      -1.961
capabilities_entropy     1.5836      0.428      3.698      0.000       0.744       2.423
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.3704 [0.1882, 0.5525] (n=27)
                  P-value vs 33.3%: 0.6902

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  146
Model:                          Logit   Df Residuals:                      144
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                0.006871
Time:                        17:34:42   Log-Likelihood:                -69.423
converged:                       True   LL-Null:                       -69.903
Covariance Type:            nonrobust   LLR p-value:                    0.3270
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -0.6312      0.891     -0.709      0.479      -2.377       1.114
human_difficulty    -0.3655      0.377     -0.969      0.332      -1.104       0.373
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  146
Model:                          Logit   Df Residuals:                      139
Method:                           MLE   Df Model:                            6
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.01964
Time:                        17:34:42   Log-Likelihood:                -68.531
converged:                       True   LL-Null:                       -69.903
Covariance Type:            nonrobust   LLR p-value:                    0.8401
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -2.6477      3.245     -0.816      0.414      -9.007       3.712
C(domain_grouped)[T.chemistry]        0.7697      0.646      1.191      0.234      -0.497       2.036
C(domain_grouped)[T.physics]          0.3500      0.682      0.513      0.608      -0.987       1.687
human_difficulty                     -0.3360      0.395     -0.850      0.395      -1.110       0.439
q_length                              0.2397      0.401      0.597      0.550      -0.547       1.026
avg_word_length                       0.0182      0.374      0.049      0.961      -0.715       0.752
percent_non_alphabetic_whitespace    -0.0026      0.039     -0.066      0.948      -0.080       0.075
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 0.7921
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  146
Model:                          Logit   Df Residuals:                      138
Method:                           MLE   Df Model:                            7
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1156
Time:                        17:34:42   Log-Likelihood:                -61.821
converged:                       True   LL-Null:                       -69.903
Covariance Type:            nonrobust   LLR p-value:                   0.02365
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -2.8895      3.486     -0.829      0.407      -9.721       3.942
C(domain_grouped)[T.chemistry]       -0.1534      0.730     -0.210      0.834      -1.584       1.277
C(domain_grouped)[T.physics]         -0.3242      0.772     -0.420      0.674      -1.837       1.189
human_difficulty                     -0.3915      0.419     -0.935      0.350      -1.212       0.429
q_length                              0.1625      0.420      0.387      0.699      -0.660       0.985
avg_word_length                       0.0081      0.401      0.020      0.984      -0.778       0.794
percent_non_alphabetic_whitespace    -0.0038      0.043     -0.088      0.930      -0.089       0.081
capabilities_entropy                  1.6339      0.470      3.477      0.001       0.713       2.555
=====================================================================================================

--- Analyzing claude-3-sonnet-20240229 (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_neutral/claude-3-sonnet-20240229_GPQA_redacted_temp0.0_1751827240_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    214
1     87
Name: count, dtype: int64

Answer change%: 0.2890 [0.2378253556861314, 0.3402477340148653] (n=301)
P-value vs 25%: 0.1352; P-value vs 0%: 1.916e-28
Phase 2 self-accuracy: 0.3448 [0.24495017724267196, 0.44470499517112116] (n=87)
P-value vs 25%: 0.06276; P-value vs 33%: 0.8165

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  301
Model:                          Logit   Df Residuals:                      299
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1909
Time:                        17:34:42   Log-Likelihood:                -146.43
converged:                       True   LL-Null:                       -180.99
Covariance Type:            nonrobust   LLR p-value:                 9.321e-17
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          2.9873      0.519      5.757      0.000       1.970       4.004
p_i_capability    -5.8147      0.797     -7.299      0.000      -7.376      -4.253
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  301
Model:                          Logit   Df Residuals:                      299
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1734
Time:                        17:34:42   Log-Likelihood:                -149.60
converged:                       True   LL-Null:                       -180.99
Covariance Type:            nonrobust   LLR p-value:                 2.325e-15
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -3.3013      0.402     -8.214      0.000      -4.089      -2.514
capabilities_entropy     2.1626      0.309      6.990      0.000       1.556       2.769
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.3218 [0.2237, 0.4200] (n=87)
                  P-value vs 33.3%: 0.8185

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  301
Model:                          Logit   Df Residuals:                      299
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:               0.0007180
Time:                        17:34:42   Log-Likelihood:                -180.86
converged:                       True   LL-Null:                       -180.99
Covariance Type:            nonrobust   LLR p-value:                    0.6102
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -0.6296      0.545     -1.155      0.248      -1.698       0.439
human_difficulty    -0.1144      0.225     -0.509      0.611      -0.555       0.327
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  301
Model:                          Logit   Df Residuals:                      294
Method:                           MLE   Df Model:                            6
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.01474
Time:                        17:34:42   Log-Likelihood:                -178.32
converged:                       True   LL-Null:                       -180.99
Covariance Type:            nonrobust   LLR p-value:                    0.5016
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -0.2650      1.949     -0.136      0.892      -4.086       3.556
C(domain_grouped)[T.chemistry]        0.5930      0.484      1.226      0.220      -0.355       1.541
C(domain_grouped)[T.physics]          0.6669      0.484      1.377      0.169      -0.283       1.616
human_difficulty                     -0.0716      0.232     -0.308      0.758      -0.527       0.383
q_length                              0.0621      0.205      0.304      0.761      -0.339       0.463
avg_word_length                      -0.2579      0.229     -1.125      0.260      -0.707       0.191
percent_non_alphabetic_whitespace    -0.0253      0.025     -1.023      0.306      -0.074       0.023
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 0.9932
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  301
Model:                          Logit   Df Residuals:                      293
Method:                           MLE   Df Model:                            7
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1753
Time:                        17:34:42   Log-Likelihood:                -149.26
converged:                       True   LL-Null:                       -180.99
Covariance Type:            nonrobust   LLR p-value:                 3.081e-11
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -3.0025      2.128     -1.411      0.158      -7.173       1.168
C(domain_grouped)[T.chemistry]       -0.3400      0.552     -0.616      0.538      -1.422       0.742
C(domain_grouped)[T.physics]         -0.3478      0.570     -0.611      0.541      -1.464       0.769
human_difficulty                     -0.1415      0.255     -0.554      0.579      -0.642       0.359
q_length                              0.0417      0.238      0.175      0.861      -0.425       0.508
avg_word_length                       0.0042      0.231      0.018      0.985      -0.449       0.457
percent_non_alphabetic_whitespace     0.0003      0.028      0.009      0.992      -0.055       0.055
capabilities_entropy                  2.2281      0.332      6.710      0.000       1.577       2.879
=====================================================================================================

--- Analyzing claude-sonnet-4-20250514 (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_neutral/claude-sonnet-4-20250514_GPQA_redacted_cor_temp0.0_1751827811_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    195
1     63
Name: count, dtype: int64

Answer change%: 0.2442 [0.1917649486145487, 0.2966071444087071] (n=258)
P-value vs 25%: 0.8279; P-value vs 0%: 6.861e-20
Phase 2 self-accuracy: 0.0635 [0.0032786471838967685, 0.12370547980023021] (n=63)
P-value vs 25%: 1.272e-09; P-value vs 33%: 1.746e-18

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  258
Model:                          Logit   Df Residuals:                      256
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:               0.0002089
Time:                        17:34:42   Log-Likelihood:                -143.38
converged:                       True   LL-Null:                       -143.41
Covariance Type:            nonrobust   LLR p-value:                    0.8066
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -1.2729      0.603     -2.111      0.035      -2.455      -0.091
human_difficulty     0.0607      0.248      0.245      0.806      -0.425       0.546
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  258
Model:                          Logit   Df Residuals:                      251
Method:                           MLE   Df Model:                            6
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.03027
Time:                        17:34:42   Log-Likelihood:                -139.07
converged:                       True   LL-Null:                       -143.41
Covariance Type:            nonrobust   LLR p-value:                    0.1923
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -4.3388      2.089     -2.077      0.038      -8.433      -0.245
C(domain_grouped)[T.chemistry]        0.9012      0.469      1.923      0.054      -0.017       1.820
C(domain_grouped)[T.physics]          0.6052      0.468      1.292      0.196      -0.313       1.523
human_difficulty                      0.0250      0.260      0.096      0.923      -0.484       0.534
q_length                              0.5171      0.255      2.027      0.043       0.017       1.017
avg_word_length                      -0.0521      0.232     -0.225      0.822      -0.507       0.403
percent_non_alphabetic_whitespace    -0.0346      0.029     -1.176      0.239      -0.092       0.023
=====================================================================================================

--- Analyzing claude-sonnet-4-20250514 (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_neutral/claude-sonnet-4-20250514_GPQA_redacted_temp0.0_1751824757_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    109
1     80
Name: count, dtype: int64

Answer change%: 0.4233 [0.3528413510356713, 0.4937194955251752] (n=189)
P-value vs 25%: 1.425e-06; P-value vs 0%: 5.083e-32
Phase 2 self-accuracy: 0.4000 [0.29264835137697054, 0.5073516486230295] (n=80)
P-value vs 25%: 0.00617; P-value vs 33%: 0.2212

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  189
Model:                          Logit   Df Residuals:                      187
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                0.004024
Time:                        17:34:42   Log-Likelihood:                -128.25
converged:                       True   LL-Null:                       -128.77
Covariance Type:            nonrobust   LLR p-value:                    0.3087
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept            0.3378      0.654      0.516      0.606      -0.944       1.620
human_difficulty    -0.2709      0.268     -1.012      0.311      -0.795       0.253
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  189
Model:                          Logit   Df Residuals:                      182
Method:                           MLE   Df Model:                            6
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.01928
Time:                        17:34:42   Log-Likelihood:                -126.29
converged:                       True   LL-Null:                       -128.77
Covariance Type:            nonrobust   LLR p-value:                    0.5483
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                             2.8682      2.410      1.190      0.234      -1.856       7.592
C(domain_grouped)[T.chemistry]        0.4155      0.509      0.816      0.415      -0.583       1.414
C(domain_grouped)[T.physics]          0.2346      0.534      0.440      0.660      -0.812       1.281
human_difficulty                     -0.2226      0.278     -0.802      0.423      -0.767       0.322
q_length                             -0.3530      0.242     -1.461      0.144      -0.827       0.121
avg_word_length                      -0.1225      0.263     -0.466      0.641      -0.637       0.392
percent_non_alphabetic_whitespace    -0.0336      0.029     -1.151      0.250      -0.091       0.024
=====================================================================================================

--- Analyzing deepseek-chat (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_neutral/deepseek-chat_GPQA_redacted_cor_temp0.0_1754437275_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    193
1     16
Name: count, dtype: int64

Answer change%: 0.0766 [0.040508174890447085, 0.11260187295644286] (n=209)
P-value vs 25%: 4.075e-21; P-value vs 0%: 3.148e-05
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=16)
P-value vs 25%: 0; P-value vs 33%: 0

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  209
Model:                          Logit   Df Residuals:                      207
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.2946
Time:                        17:34:42   Log-Likelihood:                -39.847
converged:                       True   LL-Null:                       -56.487
Covariance Type:            nonrobust   LLR p-value:                 7.978e-09
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          9.4262      2.245      4.199      0.000       5.027      13.826
p_i_capability   -13.2836      2.539     -5.231      0.000     -18.261      -8.307
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  209
Model:                          Logit   Df Residuals:                      207
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.3027
Time:                        17:34:42   Log-Likelihood:                -39.388
converged:                       True   LL-Null:                       -56.487
Covariance Type:            nonrobust   LLR p-value:                 4.979e-09
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -5.2908      0.668     -7.919      0.000      -6.600      -3.981
capabilities_entropy     5.9527      1.068      5.576      0.000       3.860       8.045
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.8125 [0.6213, 1.0000] (n=16)
                  P-value vs 33.3%: 9.08e-07

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=0.22, p=0.829
Wilcoxon delta_p: statistic=383.00, p=0.717
Mean Δp = 0.0012  [-0.0093, 0.0116]
Idea 1 N = 193; 

  Idea 1.5: Calibration Metrics
  NLL: 0.0715, Signed ECE (overconf pos under neg): -0.0653, ECE: 0.0653 (n=209)
  Brier: 0.0099, Reliability (absolute calibration error; lower better): 0.0097, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=209)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.887
Model:                            OLS   Adj. R-squared:                  0.886
Method:                 Least Squares   F-statistic:                     537.4
Date:                Sat, 09 Aug 2025   Prob (F-statistic):           7.91e-97
Time:                        17:34:42   Log-Likelihood:                 267.41
No. Observations:                 209   AIC:                            -526.8
Df Residuals:                     205   BIC:                            -513.5
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.7694      0.093     -8.280      0.000      -0.953      -0.586
p1                    0.8139      0.098      8.304      0.000       0.621       1.007
answer_changed        0.7014      0.133      5.271      0.000       0.439       0.964
p1:answer_changed     0.1350      0.154      0.877      0.381      -0.168       0.438
==============================================================================
Omnibus:                      197.111   Durbin-Watson:                   1.312
Prob(Omnibus):                  0.000   Jarque-Bera (JB):             4220.671
Skew:                           3.642   Prob(JB):                         0.00
Kurtosis:                      23.775   Cond. No.                         66.1
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-1.42, p=0.158
Wilcoxon delta_H: statistic=288.00, p=0.101
Mean ΔH = -0.0378  [-0.0901, 0.0145]
Paired t-test delta_H Changed: statistic=2.98, p=0.0094
Wilcoxon delta_H Changed: statistic=22.00, p=0.0174
Mean ΔH Changed = 0.4513  [0.1542, 0.7485]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=-1.75, p=0.0812
Wilcoxon (p_top2_game vs p_top2_base): statistic=499.50, p=0.0364
Mean Δp_top2 = -0.0011  [-0.0024, 0.0001] (n=209)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=-0.01, p=0.99
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=773.00, p=0.838
Mean ΔH_unchosen_baseline_set = -0.0004  [-0.0563, 0.0556] (n=209)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  209
Model:                          Logit   Df Residuals:                      206
Method:                           MLE   Df Model:                            2
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.3310
Time:                        17:34:42   Log-Likelihood:                -37.791
converged:                       True   LL-Null:                       -56.487
Covariance Type:            nonrobust   LLR p-value:                 7.590e-09
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -2.8670      0.376     -7.620      0.000      -3.605      -2.130
p1_z            -2.0824      0.571     -3.647      0.000      -3.202      -0.963
I(p1_z ** 2)    -0.2944      0.141     -2.082      0.037      -0.572      -0.017
================================================================================
AUC = 0.861

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  209
Model:                          Logit   Df Residuals:                      207
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1009
Time:                        17:34:42   Log-Likelihood:                -50.786
converged:                       True   LL-Null:                       -56.487
Covariance Type:            nonrobust   LLR p-value:                 0.0007336
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -3.9678      0.538     -7.376      0.000      -5.022      -2.913
game_entropy     3.5989      1.005      3.579      0.000       1.628       5.569
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=591.50, p=0.193
Paired t-test (game_entropy vs capabilities_entropy): statistic=-1.06, p=0.292
Mean capabilities_entropy-game_entropy = 0.0146  [-0.0125, 0.0418] (n=209)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  209
Model:                          Logit   Df Residuals:                      206
Method:                           MLE   Df Model:                            2
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.3472
Time:                        17:34:42   Log-Likelihood:                -36.878
converged:                       True   LL-Null:                       -56.487
Covariance Type:            nonrobust   LLR p-value:                 3.045e-09
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -6.2952      0.874     -7.199      0.000      -8.009      -4.581
capabilities_entropy     5.6279      1.088      5.174      0.000       3.496       7.760
game_entropy             2.6538      1.142      2.323      0.020       0.415       4.893
========================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  209
Model:                          Logit   Df Residuals:                      207
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:               0.0007847
Time:                        17:34:42   Log-Likelihood:                -56.443
converged:                       True   LL-Null:                       -56.487
Covariance Type:            nonrobust   LLR p-value:                    0.7659
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -2.1726      1.093     -1.989      0.047      -4.314      -0.031
human_difficulty    -0.1342      0.452     -0.297      0.767      -1.020       0.752
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  209
Model:                          Logit   Df Residuals:                      202
Method:                           MLE   Df Model:                            6
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.06240
Time:                        17:34:42   Log-Likelihood:                -52.962
converged:                       True   LL-Null:                       -56.487
Covariance Type:            nonrobust   LLR p-value:                    0.3163
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -2.9488      4.406     -0.669      0.503     -11.585       5.687
C(domain_grouped)[T.chemistry]        2.2631      1.128      2.006      0.045       0.052       4.474
C(domain_grouped)[T.physics]          1.4068      1.129      1.246      0.213      -0.805       3.619
human_difficulty                      0.0187      0.452      0.041      0.967      -0.868       0.905
q_length                              0.3041      0.443      0.686      0.493      -0.565       1.173
avg_word_length                      -0.5096      0.581     -0.876      0.381      -1.649       0.630
percent_non_alphabetic_whitespace    -0.0736      0.059     -1.241      0.215      -0.190       0.043
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 0.3732
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  209
Model:                          Logit   Df Residuals:                      201
Method:                           MLE   Df Model:                            7
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.3371
Time:                        17:34:42   Log-Likelihood:                -37.446
converged:                       True   LL-Null:                       -56.487
Covariance Type:            nonrobust   LLR p-value:                 2.923e-06
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -7.7111      5.554     -1.388      0.165     -18.597       3.174
C(domain_grouped)[T.chemistry]        1.3237      1.207      1.097      0.273      -1.042       3.689
C(domain_grouped)[T.physics]          0.8624      1.227      0.703      0.482      -1.543       3.268
human_difficulty                      0.2470      0.553      0.446      0.655      -0.837       1.331
q_length                              0.2420      0.517      0.468      0.640      -0.771       1.255
avg_word_length                       0.0039      0.649      0.006      0.995      -1.269       1.277
percent_non_alphabetic_whitespace    -0.0815      0.067     -1.211      0.226      -0.213       0.050
capabilities_entropy                  6.2356      1.273      4.897      0.000       3.740       8.731
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  209
Model:                          Logit   Df Residuals:                      201
Method:                           MLE   Df Model:                            7
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1403
Time:                        17:34:42   Log-Likelihood:                -48.563
converged:                       True   LL-Null:                       -56.487
Covariance Type:            nonrobust   LLR p-value:                   0.02654
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -3.7139      4.632     -0.802      0.423     -12.793       5.365
C(domain_grouped)[T.chemistry]        1.7058      1.169      1.459      0.145      -0.586       3.998
C(domain_grouped)[T.physics]          1.1865      1.161      1.022      0.307      -1.090       3.463
human_difficulty                     -0.2161      0.492     -0.439      0.661      -1.181       0.749
q_length                              0.2845      0.450      0.632      0.527      -0.597       1.166
avg_word_length                      -0.4456      0.581     -0.767      0.443      -1.585       0.694
percent_non_alphabetic_whitespace    -0.0591      0.063     -0.945      0.345      -0.182       0.063
game_entropy                          3.2936      1.080      3.051      0.002       1.178       5.410
=====================================================================================================

                  Model 4.95: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  209
Model:                          Logit   Df Residuals:                      200
Method:                           MLE   Df Model:                            8
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.3651
Time:                        17:34:42   Log-Likelihood:                -35.862
converged:                       True   LL-Null:                       -56.487
Covariance Type:            nonrobust   LLR p-value:                 1.872e-06
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -8.1215      5.786     -1.404      0.160     -19.462       3.219
C(domain_grouped)[T.chemistry]        0.8183      1.284      0.637      0.524      -1.699       3.336
C(domain_grouped)[T.physics]          0.7188      1.269      0.566      0.571      -1.768       3.206
human_difficulty                      0.1101      0.576      0.191      0.848      -1.019       1.239
q_length                              0.2529      0.519      0.487      0.626      -0.764       1.270
avg_word_length                      -0.0029      0.664     -0.004      0.996      -1.305       1.299
percent_non_alphabetic_whitespace    -0.0618      0.069     -0.892      0.372      -0.197       0.074
capabilities_entropy                  5.9014      1.295      4.557      0.000       3.363       8.440
game_entropy                          2.2498      1.229      1.830      0.067      -0.160       4.659
=====================================================================================================

--- Analyzing deepseek-chat (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_neutral/deepseek-chat_GPQA_redacted_temp0.0_1754429196_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    196
1     42
Name: count, dtype: int64

Answer change%: 0.1765 [0.12803826118299494, 0.22490291528759332] (n=238)
P-value vs 25%: 0.002924; P-value vs 0%: 9.237e-13
Phase 2 self-accuracy: 0.4524 [0.30185379028554304, 0.6029081144763617] (n=42)
P-value vs 25%: 0.00841; P-value vs 33%: 0.1201

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  238
Model:                          Logit   Df Residuals:                      236
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1147
Time:                        17:34:42   Log-Likelihood:                -98.188
converged:                       True   LL-Null:                       -110.91
Covariance Type:            nonrobust   LLR p-value:                 4.566e-07
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          3.4537      1.002      3.447      0.001       1.490       5.418
p_i_capability    -5.7528      1.161     -4.957      0.000      -8.027      -3.478
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  238
Model:                          Logit   Df Residuals:                      236
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1135
Time:                        17:34:42   Log-Likelihood:                -98.321
converged:                       True   LL-Null:                       -110.91
Covariance Type:            nonrobust   LLR p-value:                 5.237e-07
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.8933      0.352     -8.231      0.000      -3.582      -2.204
capabilities_entropy     2.5296      0.515      4.915      0.000       1.521       3.538
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.5476 [0.3971, 0.6981] (n=42)
                  P-value vs 33.3%: 0.005268

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=-1.38, p=0.169
Wilcoxon delta_p: statistic=1121.00, p=0.368
Mean Δp = -0.0102  [-0.0247, 0.0043]
Idea 1 N = 196; 

  Idea 1.5: Calibration Metrics
  NLL: 4.1283, Signed ECE (overconf pos under neg): 0.0401, ECE: 0.0401 (n=238)
  Brier: 0.0087, Reliability (absolute calibration error; lower better): 0.0086, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=238)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.898
Model:                            OLS   Adj. R-squared:                  0.896
Method:                 Least Squares   F-statistic:                     684.5
Date:                Sat, 09 Aug 2025   Prob (F-statistic):          1.64e-115
Time:                        17:34:42   Log-Likelihood:                 230.45
No. Observations:                 238   AIC:                            -452.9
Df Residuals:                     234   BIC:                            -439.0
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.5976      0.058    -10.281      0.000      -0.712      -0.483
p1                    0.6404      0.063     10.172      0.000       0.516       0.764
answer_changed        0.5221      0.089      5.859      0.000       0.347       0.698
p1:answer_changed     0.2893      0.104      2.774      0.006       0.084       0.495
==============================================================================
Omnibus:                       33.336   Durbin-Watson:                   2.012
Prob(Omnibus):                  0.000   Jarque-Bera (JB):              148.672
Skew:                           0.400   Prob(JB):                     5.20e-33
Kurtosis:                       6.789   Cond. No.                         33.9
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-0.67, p=0.502
Wilcoxon delta_H: statistic=1168.50, p=0.53
Mean ΔH = -0.0243  [-0.0951, 0.0465]
Paired t-test delta_H Changed: statistic=6.19, p=2.29e-07
Wilcoxon delta_H Changed: statistic=94.00, p=7.76e-06
Mean ΔH Changed = 0.6433  [0.4398, 0.8469]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=0.51, p=0.612
Wilcoxon (p_top2_game vs p_top2_base): statistic=2647.00, p=0.552
Mean Δp_top2 = 0.0012  [-0.0035, 0.0060] (n=238)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=2.42, p=0.0161
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=2367.50, p=0.0145
Mean ΔH_unchosen_baseline_set = 0.0935  [0.0179, 0.1691] (n=238)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  238
Model:                          Logit   Df Residuals:                      235
Method:                           MLE   Df Model:                            2
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1314
Time:                        17:34:42   Log-Likelihood:                -96.331
converged:                       True   LL-Null:                       -110.91
Covariance Type:            nonrobust   LLR p-value:                 4.671e-07
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.4735      0.225     -6.561      0.000      -1.914      -1.033
p1_z            -1.3432      0.348     -3.858      0.000      -2.026      -0.661
I(p1_z ** 2)    -0.2743      0.143     -1.925      0.054      -0.554       0.005
================================================================================
AUC = 0.731

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  238
Model:                          Logit   Df Residuals:                      236
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1106
Time:                        17:34:42   Log-Likelihood:                -98.637
converged:                       True   LL-Null:                       -110.91
Covariance Type:            nonrobust   LLR p-value:                 7.273e-07
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -2.9001      0.356     -8.142      0.000      -3.598      -2.202
game_entropy     2.7388      0.581      4.714      0.000       1.600       3.877
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=2500.00, p=0.29
Paired t-test (game_entropy vs capabilities_entropy): statistic=-1.35, p=0.178
Mean capabilities_entropy-game_entropy = 0.0256  [-0.0116, 0.0627] (n=238)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  238
Model:                          Logit   Df Residuals:                      235
Method:                           MLE   Df Model:                            2
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1556
Time:                        17:34:43   Log-Likelihood:                -93.656
converged:                       True   LL-Null:                       -110.91
Covariance Type:            nonrobust   LLR p-value:                 3.218e-08
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -3.4944      0.434     -8.056      0.000      -4.345      -2.644
capabilities_entropy     1.8417      0.573      3.215      0.001       0.719       2.964
game_entropy             1.9663      0.654      3.007      0.003       0.685       3.248
========================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  238
Model:                          Logit   Df Residuals:                      236
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.01134
Time:                        17:34:43   Log-Likelihood:                -109.65
converged:                       True   LL-Null:                       -110.91
Covariance Type:            nonrobust   LLR p-value:                    0.1127
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -0.4027      0.737     -0.546      0.585      -1.847       1.042
human_difficulty    -0.4930      0.317     -1.554      0.120      -1.115       0.129
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  238
Model:                          Logit   Df Residuals:                      231
Method:                           MLE   Df Model:                            6
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.05043
Time:                        17:34:43   Log-Likelihood:                -105.31
converged:                       True   LL-Null:                       -110.91
Covariance Type:            nonrobust   LLR p-value:                   0.08278
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -2.0851      2.621     -0.796      0.426      -7.221       3.051
C(domain_grouped)[T.chemistry]        0.4614      0.633      0.729      0.466      -0.779       1.702
C(domain_grouped)[T.physics]          0.3756      0.664      0.566      0.572      -0.926       1.677
human_difficulty                     -0.6180      0.334     -1.853      0.064      -1.272       0.036
q_length                              0.4811      0.308      1.564      0.118      -0.122       1.084
avg_word_length                      -0.1397      0.295     -0.474      0.636      -0.718       0.438
percent_non_alphabetic_whitespace    -0.0825      0.042     -1.957      0.050      -0.165       0.000
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 0.4696
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  238
Model:                          Logit   Df Residuals:                      230
Method:                           MLE   Df Model:                            7
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1669
Time:                        17:34:43   Log-Likelihood:                -92.400
converged:                       True   LL-Null:                       -110.91
Covariance Type:            nonrobust   LLR p-value:                 4.660e-06
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -1.7954      2.714     -0.662      0.508      -7.114       3.523
C(domain_grouped)[T.chemistry]       -0.1735      0.667     -0.260      0.795      -1.481       1.134
C(domain_grouped)[T.physics]         -0.2917      0.710     -0.411      0.681      -1.684       1.101
human_difficulty                     -0.6959      0.370     -1.880      0.060      -1.422       0.030
q_length                              0.3829      0.331      1.158      0.247      -0.265       1.031
avg_word_length                      -0.2009      0.281     -0.716      0.474      -0.751       0.349
percent_non_alphabetic_whitespace    -0.1025      0.047     -2.191      0.028      -0.194      -0.011
capabilities_entropy                  2.7657      0.563      4.912      0.000       1.662       3.869
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  238
Model:                          Logit   Df Residuals:                      230
Method:                           MLE   Df Model:                            7
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1479
Time:                        17:34:43   Log-Likelihood:                -94.507
converged:                       True   LL-Null:                       -110.91
Covariance Type:            nonrobust   LLR p-value:                 2.883e-05
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -2.5275      2.732     -0.925      0.355      -7.882       2.827
C(domain_grouped)[T.chemistry]        0.1809      0.656      0.276      0.783      -1.105       1.467
C(domain_grouped)[T.physics]          0.0277      0.696      0.040      0.968      -1.337       1.393
human_difficulty                     -0.6278      0.361     -1.740      0.082      -1.335       0.079
q_length                              0.3726      0.328      1.137      0.255      -0.270       1.015
avg_word_length                      -0.1242      0.306     -0.406      0.685      -0.723       0.475
percent_non_alphabetic_whitespace    -0.0820      0.045     -1.805      0.071      -0.171       0.007
game_entropy                          2.6562      0.603      4.402      0.000       1.474       3.839
=====================================================================================================

                  Model 4.95: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  238
Model:                          Logit   Df Residuals:                      229
Method:                           MLE   Df Model:                            8
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.2004
Time:                        17:34:43   Log-Likelihood:                -88.677
converged:                       True   LL-Null:                       -110.91
Covariance Type:            nonrobust   LLR p-value:                 4.653e-07
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -2.1971      2.760     -0.796      0.426      -7.607       3.213
C(domain_grouped)[T.chemistry]       -0.2594      0.677     -0.383      0.702      -1.587       1.068
C(domain_grouped)[T.physics]         -0.3577      0.718     -0.498      0.618      -1.765       1.049
human_difficulty                     -0.6788      0.377     -1.801      0.072      -1.418       0.060
q_length                              0.3367      0.337      1.000      0.317      -0.323       0.997
avg_word_length                      -0.1763      0.291     -0.606      0.544      -0.747       0.394
percent_non_alphabetic_whitespace    -0.0970      0.048     -2.016      0.044      -0.191      -0.003
capabilities_entropy                  2.1292      0.619      3.440      0.001       0.916       3.342
game_entropy                          1.8150      0.677      2.680      0.007       0.488       3.142
=====================================================================================================

--- Analyzing gemini-1.5-pro (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_neutral/gemini-1.5-pro_GPQA_redacted_cor_temp0.0_1751845110_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    185
1     16
Name: count, dtype: int64

Answer change%: 0.0796 [0.04218232804266971, 0.11702165205683276] (n=201)
P-value vs 25%: 4.453e-19; P-value vs 0%: 3.054e-05
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=16)
P-value vs 25%: 0; P-value vs 33%: 0

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  201
Model:                          Logit   Df Residuals:                      199
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.03282
Time:                        17:34:43   Log-Likelihood:                -54.004
converged:                       True   LL-Null:                       -55.837
Covariance Type:            nonrobust   LLR p-value:                   0.05555
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -4.6783      1.263     -3.705      0.000      -7.153      -2.204
human_difficulty     0.9011      0.477      1.889      0.059      -0.034       1.836
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  201
Model:                          Logit   Df Residuals:                      194
Method:                           MLE   Df Model:                            6
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.09790
Time:                        17:34:43   Log-Likelihood:                -50.370
converged:                       True   LL-Null:                       -55.837
Covariance Type:            nonrobust   LLR p-value:                   0.09046
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                             0.7528      3.861      0.195      0.845      -6.815       8.321
C(domain_grouped)[T.chemistry]        0.4688      0.871      0.538      0.590      -1.239       2.176
C(domain_grouped)[T.physics]          0.2787      0.776      0.359      0.720      -1.243       1.800
human_difficulty                      1.0314      0.496      2.077      0.038       0.058       2.005
q_length                              0.2043      0.433      0.471      0.637      -0.645       1.054
avg_word_length                      -1.4443      0.632     -2.284      0.022      -2.684      -0.205
percent_non_alphabetic_whitespace    -0.0992      0.061     -1.625      0.104      -0.219       0.020
=====================================================================================================

--- Analyzing gemini-1.5-pro (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_neutral/gemini-1.5-pro_GPQA_redacted_temp0.0_1751826706_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    191
1     55
Name: count, dtype: int64

Answer change%: 0.2236 [0.17151252517067941, 0.27564194637403605] (n=246)
P-value vs 25%: 0.3199; P-value vs 0%: 3.879e-17
Phase 2 self-accuracy: 0.4545 [0.32295187866027497, 0.5861390304306341] (n=55)
P-value vs 25%: 0.002315; P-value vs 33%: 0.07025

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  246
Model:                          Logit   Df Residuals:                      244
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                0.003686
Time:                        17:34:43   Log-Likelihood:                -130.24
converged:                       True   LL-Null:                       -130.72
Covariance Type:            nonrobust   LLR p-value:                    0.3262
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -0.6324      0.642     -0.985      0.325      -1.891       0.626
human_difficulty    -0.2601      0.267     -0.972      0.331      -0.784       0.264
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  246
Model:                          Logit   Df Residuals:                      239
Method:                           MLE   Df Model:                            6
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.01008
Time:                        17:34:43   Log-Likelihood:                -129.41
converged:                       True   LL-Null:                       -130.72
Covariance Type:            nonrobust   LLR p-value:                    0.8529
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                             1.5139      2.412      0.628      0.530      -3.214       6.242
C(domain_grouped)[T.chemistry]       -0.4991      0.504     -0.991      0.322      -1.486       0.488
C(domain_grouped)[T.physics]         -0.4623      0.522     -0.885      0.376      -1.486       0.561
human_difficulty                     -0.2728      0.280     -0.975      0.329      -0.821       0.275
q_length                             -0.0676      0.255     -0.265      0.791      -0.568       0.433
avg_word_length                      -0.2628      0.271     -0.969      0.333      -0.795       0.269
percent_non_alphabetic_whitespace    -0.0112      0.030     -0.376      0.707      -0.069       0.047
=====================================================================================================

--- Analyzing gemini-2.0-flash-001 (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_neutral/gemini-2.0-flash-001_GPQA_redacted_cor_temp0.0_1754341249_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    172
1     27
Name: count, dtype: int64

Answer change%: 0.1357 [0.08809947171529611, 0.1832573122043019] (n=199)
P-value vs 25%: 2.485e-06; P-value vs 0%: 2.282e-08
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=27)
P-value vs 25%: 0; P-value vs 33%: 0

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  199
Model:                          Logit   Df Residuals:                      197
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.2778
Time:                        17:34:43   Log-Likelihood:                -57.060
converged:                       True   LL-Null:                       -79.011
Covariance Type:            nonrobust   LLR p-value:                 3.454e-11
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          6.1918      1.327      4.668      0.000       3.592       8.792
p_i_capability    -8.9644      1.495     -5.996      0.000     -11.895      -6.034
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  199
Model:                          Logit   Df Residuals:                      197
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.3119
Time:                        17:34:43   Log-Likelihood:                -54.369
converged:                       True   LL-Null:                       -79.011
Covariance Type:            nonrobust   LLR p-value:                 2.214e-12
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -3.0151      0.354     -8.505      0.000      -3.710      -2.320
capabilities_entropy     3.3904      0.540      6.280      0.000       2.332       4.449
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.7391 [0.5597, 0.9186] (n=23)
                  P-value vs 33.3%: 9.336e-06

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=0.33, p=0.74
Wilcoxon delta_p: statistic=1001.00, p=0.794
Mean Δp = 0.0063  [-0.0306, 0.0431]
Idea 1 N = 64; 

  Idea 1.5: Calibration Metrics
  NLL: 0.1426, Signed ECE (overconf pos under neg): -0.1140, ECE: 0.1140 (n=87)
  Brier: 0.0408, Reliability (absolute calibration error; lower better): 0.0403, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=87)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.833
Model:                            OLS   Adj. R-squared:                  0.827
Method:                 Least Squares   F-statistic:                     138.4
Date:                Sat, 09 Aug 2025   Prob (F-statistic):           3.35e-32
Time:                        17:34:43   Log-Likelihood:                 52.877
No. Observations:                  87   AIC:                            -97.75
Df Residuals:                      83   BIC:                            -87.89
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.5919      0.128     -4.629      0.000      -0.846      -0.338
p1                    0.6369      0.135      4.719      0.000       0.368       0.905
answer_changed        0.5863      0.175      3.353      0.001       0.239       0.934
p1:answer_changed     0.2257      0.207      1.090      0.279      -0.186       0.638
==============================================================================
Omnibus:                       25.406   Durbin-Watson:                   2.218
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               59.672
Skew:                           0.994   Prob(JB):                     1.10e-13
Kurtosis:                       6.536   Cond. No.                         29.1
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-1.79, p=0.0784
Wilcoxon delta_H: statistic=763.00, p=0.064
Mean ΔH = -0.1305  [-0.2734, 0.0125]
Paired t-test delta_H Changed: statistic=0.88, p=0.391
Wilcoxon delta_H Changed: statistic=116.00, p=0.52
Mean ΔH Changed = 0.0847  [-0.1050, 0.2745]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=-1.95, p=0.055
Wilcoxon (p_top2_game vs p_top2_base): statistic=1531.00, p=0.105
Mean Δp_top2 = -0.0110  [-0.0220, 0.0001] (n=87)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=-1.23, p=0.224
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=1597.00, p=0.18
Mean ΔH_unchosen_baseline_set = -0.0736  [-0.1913, 0.0441] (n=87)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                   87
Model:                          Logit   Df Residuals:                       84
Method:                           MLE   Df Model:                            2
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.2475
Time:                        17:34:43   Log-Likelihood:                -37.813
converged:                       True   LL-Null:                       -50.249
Covariance Type:            nonrobust   LLR p-value:                 3.972e-06
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.7925      0.453     -1.751      0.080      -1.680       0.095
p1_z            -1.8439      0.580     -3.178      0.001      -2.981      -0.707
I(p1_z ** 2)    -0.5385      0.398     -1.353      0.176      -1.319       0.241
================================================================================
AUC = 0.802

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  199
Model:                          Logit   Df Residuals:                      197
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1742
Time:                        17:34:43   Log-Likelihood:                -65.250
converged:                       True   LL-Null:                       -79.011
Covariance Type:            nonrobust   LLR p-value:                 1.553e-07
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -2.5401      0.290     -8.766      0.000      -3.108      -1.972
game_entropy     2.3577      0.464      5.081      0.000       1.448       3.267
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=8472.00, p=0.0692
Paired t-test (game_entropy vs capabilities_entropy): statistic=-0.42, p=0.673
Mean capabilities_entropy-game_entropy = 0.0104  [-0.0377, 0.0584] (n=199)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  199
Model:                          Logit   Df Residuals:                      196
Method:                           MLE   Df Model:                            2
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.3333
Time:                        17:34:43   Log-Likelihood:                -52.673
converged:                       True   LL-Null:                       -79.011
Covariance Type:            nonrobust   LLR p-value:                 3.644e-12
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -3.1604      0.377     -8.394      0.000      -3.898      -2.422
capabilities_entropy     2.8835      0.599      4.811      0.000       1.709       4.058
game_entropy             1.1118      0.582      1.911      0.056      -0.028       2.252
========================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  199
Model:                          Logit   Df Residuals:                      197
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                0.004137
Time:                        17:34:43   Log-Likelihood:                -78.684
converged:                       True   LL-Null:                       -79.011
Covariance Type:            nonrobust   LLR p-value:                    0.4188
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -1.1067      0.939     -1.179      0.239      -2.947       0.734
human_difficulty    -0.3200      0.399     -0.802      0.422      -1.102       0.462
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  199
Model:                          Logit   Df Residuals:                      192
Method:                           MLE   Df Model:                            6
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.05912
Time:                        17:34:43   Log-Likelihood:                -74.340
converged:                       True   LL-Null:                       -79.011
Covariance Type:            nonrobust   LLR p-value:                    0.1552
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -1.6345      3.241     -0.504      0.614      -7.987       4.718
C(domain_grouped)[T.chemistry]        1.6750      0.828      2.022      0.043       0.052       3.298
C(domain_grouped)[T.physics]          0.8021      0.840      0.955      0.339      -0.843       2.448
human_difficulty                     -0.1465      0.419     -0.349      0.727      -0.968       0.675
q_length                              0.1050      0.360      0.291      0.771      -0.601       0.811
avg_word_length                      -0.3232      0.387     -0.835      0.404      -1.082       0.436
percent_non_alphabetic_whitespace    -0.0098      0.038     -0.259      0.795      -0.084       0.064
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 0.1846
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  199
Model:                          Logit   Df Residuals:                      191
Method:                           MLE   Df Model:                            7
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.3344
Time:                        17:34:43   Log-Likelihood:                -52.591
converged:                       True   LL-Null:                       -79.011
Covariance Type:            nonrobust   LLR p-value:                 3.986e-09
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -1.8592      3.854     -0.482      0.630      -9.413       5.694
C(domain_grouped)[T.chemistry]        0.4777      0.943      0.506      0.613      -1.371       2.327
C(domain_grouped)[T.physics]         -0.4230      0.997     -0.424      0.671      -2.377       1.531
human_difficulty                     -0.5137      0.544     -0.944      0.345      -1.580       0.553
q_length                             -0.0069      0.416     -0.017      0.987      -0.823       0.809
avg_word_length                       0.0005      0.451      0.001      0.999      -0.883       0.884
percent_non_alphabetic_whitespace    -0.0002      0.047     -0.004      0.997      -0.092       0.092
capabilities_entropy                  3.4698      0.608      5.703      0.000       2.277       4.662
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  199
Model:                          Logit   Df Residuals:                      191
Method:                           MLE   Df Model:                            7
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.2094
Time:                        17:34:43   Log-Likelihood:                -62.463
converged:                       True   LL-Null:                       -79.011
Covariance Type:            nonrobust   LLR p-value:                 2.540e-05
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -1.5916      3.513     -0.453      0.651      -8.478       5.295
C(domain_grouped)[T.chemistry]        1.3733      0.865      1.587      0.112      -0.323       3.069
C(domain_grouped)[T.physics]          0.4608      0.891      0.517      0.605      -1.285       2.207
human_difficulty                     -0.1496      0.469     -0.319      0.750      -1.069       0.770
q_length                             -0.1909      0.388     -0.492      0.623      -0.951       0.569
avg_word_length                      -0.0237      0.396     -0.060      0.952      -0.800       0.753
percent_non_alphabetic_whitespace    -0.0172      0.043     -0.402      0.688      -0.101       0.067
game_entropy                          2.3417      0.505      4.640      0.000       1.353       3.331
=====================================================================================================

                  Model 4.95: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  199
Model:                          Logit   Df Residuals:                      190
Method:                           MLE   Df Model:                            8
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.3589
Time:                        17:34:43   Log-Likelihood:                -50.653
converged:                       True   LL-Null:                       -79.011
Covariance Type:            nonrobust   LLR p-value:                 2.046e-09
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -1.5451      3.904     -0.396      0.692      -9.198       6.107
C(domain_grouped)[T.chemistry]        0.4960      0.950      0.522      0.602      -1.367       2.359
C(domain_grouped)[T.physics]         -0.4822      1.018     -0.474      0.636      -2.477       1.513
human_difficulty                     -0.4791      0.560     -0.855      0.393      -1.578       0.619
q_length                             -0.1764      0.431     -0.409      0.682      -1.021       0.668
avg_word_length                       0.1058      0.444      0.238      0.812      -0.764       0.976
percent_non_alphabetic_whitespace    -0.0076      0.048     -0.159      0.873      -0.101       0.086
capabilities_entropy                  2.9633      0.656      4.520      0.000       1.678       4.248
game_entropy                          1.2692      0.628      2.021      0.043       0.038       2.500
=====================================================================================================

--- Analyzing gemini-2.0-flash-001 (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_neutral/gemini-2.0-flash-001_GPQA_redacted_temp0.0_1754341030_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    177
1     71
Name: count, dtype: int64

Answer change%: 0.2863 [0.2300320520247502, 0.3425485931365402] (n=248)
P-value vs 25%: 0.2061; P-value vs 0%: 1.981e-23
Phase 2 self-accuracy: 0.4930 [0.3766668173265613, 0.6092486756311852] (n=71)
P-value vs 25%: 4.225e-05; P-value vs 33%: 0.007019

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  248
Model:                          Logit   Df Residuals:                      246
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.07759
Time:                        17:34:43   Log-Likelihood:                -136.98
converged:                       True   LL-Null:                       -148.50
Covariance Type:            nonrobust   LLR p-value:                 1.583e-06
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          3.5593      0.981      3.627      0.000       1.636       5.483
p_i_capability    -4.9324      1.075     -4.589      0.000      -7.039      -2.826
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  248
Model:                          Logit   Df Residuals:                      246
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.09164
Time:                        17:34:43   Log-Likelihood:                -134.89
converged:                       True   LL-Null:                       -148.50
Covariance Type:            nonrobust   LLR p-value:                 1.817e-07
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.5261      0.199     -7.663      0.000      -1.916      -1.136
capabilities_entropy     1.6947      0.339      4.995      0.000       1.030       2.360
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.6984 [0.5851, 0.8117] (n=63)
                  P-value vs 33.3%: 2.722e-10

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=0.90, p=0.369
Wilcoxon delta_p: statistic=3246.00, p=0.576
Mean Δp = 0.0126  [-0.0147, 0.0399]
Idea 1 N = 117; 

  Idea 1.5: Calibration Metrics
  NLL: 6.9639, Signed ECE (overconf pos under neg): 0.0411, ECE: 0.0411 (n=176)
  Brier: 0.0094, Reliability (absolute calibration error; lower better): 0.0090, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=176)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.875
Model:                            OLS   Adj. R-squared:                  0.873
Method:                 Least Squares   F-statistic:                     398.3
Date:                Sat, 09 Aug 2025   Prob (F-statistic):           6.83e-77
Time:                        17:34:43   Log-Likelihood:                 104.20
No. Observations:                 175   AIC:                            -200.4
Df Residuals:                     171   BIC:                            -187.7
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.5005      0.098     -5.097      0.000      -0.694      -0.307
p1                    0.5561      0.106      5.268      0.000       0.348       0.765
answer_changed        0.2963      0.132      2.240      0.026       0.035       0.557
p1:answer_changed     0.5491      0.148      3.701      0.000       0.256       0.842
==============================================================================
Omnibus:                       21.847   Durbin-Watson:                   1.791
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               30.727
Skew:                           0.730   Prob(JB):                     2.13e-07
Kurtosis:                       4.444   Cond. No.                         32.0
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-0.95, p=0.342
Wilcoxon delta_H: statistic=3160.00, p=0.428
Mean ΔH = -0.0480  [-0.1465, 0.0505]
Paired t-test delta_H Changed: statistic=4.20, p=9.02e-05
Wilcoxon delta_H Changed: statistic=284.00, p=2.02e-06
Mean ΔH Changed = 0.2852  [0.1520, 0.4183]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=-0.15, p=0.884
Wilcoxon (p_top2_game vs p_top2_base): statistic=7658.00, p=0.655
Mean Δp_top2 = -0.0006  [-0.0087, 0.0075] (n=178)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=1.58, p=0.117
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=6728.00, p=0.0722
Mean ΔH_unchosen_baseline_set = 0.0662  [-0.0162, 0.1485] (n=178)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  178
Model:                          Logit   Df Residuals:                      175
Method:                           MLE   Df Model:                            2
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.06682
Time:                        17:34:43   Log-Likelihood:                -106.77
converged:                       True   LL-Null:                       -114.42
Covariance Type:            nonrobust   LLR p-value:                 0.0004781
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.5983      0.222     -2.690      0.007      -1.034      -0.162
p1_z            -0.7448      0.283     -2.631      0.009      -1.300      -0.190
I(p1_z ** 2)    -0.0960      0.162     -0.594      0.552      -0.413       0.221
================================================================================
AUC = 0.691

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  248
Model:                          Logit   Df Residuals:                      246
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.07145
Time:                        17:34:43   Log-Likelihood:                -137.89
converged:                       True   LL-Null:                       -148.50
Covariance Type:            nonrobust   LLR p-value:                 4.091e-06
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.4318      0.193     -7.419      0.000      -1.810      -1.054
game_entropy     1.3779      0.306      4.503      0.000       0.778       1.978
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=14892.00, p=0.629
Paired t-test (game_entropy vs capabilities_entropy): statistic=0.54, p=0.59
Mean capabilities_entropy-game_entropy = -0.0144  [-0.0665, 0.0377] (n=248)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  248
Model:                          Logit   Df Residuals:                      245
Method:                           MLE   Df Model:                            2
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1076
Time:                        17:34:43   Log-Likelihood:                -132.52
converged:                       True   LL-Null:                       -148.50
Covariance Type:            nonrobust   LLR p-value:                 1.149e-07
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.6663      0.214     -7.778      0.000      -2.086      -1.246
capabilities_entropy     1.2660      0.390      3.247      0.001       0.502       2.030
game_entropy             0.7874      0.359      2.193      0.028       0.084       1.491
========================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  248
Model:                          Logit   Df Residuals:                      246
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                0.001923
Time:                        17:34:43   Log-Likelihood:                -148.22
converged:                       True   LL-Null:                       -148.50
Covariance Type:            nonrobust   LLR p-value:                    0.4498
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -0.4954      0.570     -0.869      0.385      -1.613       0.622
human_difficulty    -0.1767      0.235     -0.752      0.452      -0.637       0.284
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  248
Model:                          Logit   Df Residuals:                      241
Method:                           MLE   Df Model:                            6
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.02955
Time:                        17:34:43   Log-Likelihood:                -144.11
converged:                       True   LL-Null:                       -148.50
Covariance Type:            nonrobust   LLR p-value:                    0.1866
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                             1.3045      2.324      0.561      0.575      -3.250       5.859
C(domain_grouped)[T.chemistry]       -0.0753      0.475     -0.159      0.874      -1.006       0.855
C(domain_grouped)[T.physics]         -0.5909      0.505     -1.170      0.242      -1.580       0.399
human_difficulty                     -0.1227      0.256     -0.479      0.632      -0.624       0.379
q_length                              0.1853      0.244      0.759      0.448      -0.293       0.664
avg_word_length                      -0.5991      0.284     -2.106      0.035      -1.157      -0.042
percent_non_alphabetic_whitespace    -0.0049      0.027     -0.180      0.857      -0.058       0.048
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 0.3146
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  248
Model:                          Logit   Df Residuals:                      240
Method:                           MLE   Df Model:                            7
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1113
Time:                        17:34:43   Log-Likelihood:                -131.97
converged:                       True   LL-Null:                       -148.50
Covariance Type:            nonrobust   LLR p-value:                 2.577e-05
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -0.1235      2.409     -0.051      0.959      -4.845       4.598
C(domain_grouped)[T.chemistry]       -0.2197      0.500     -0.439      0.661      -1.200       0.761
C(domain_grouped)[T.physics]         -0.7323      0.534     -1.370      0.171      -1.780       0.315
human_difficulty                     -0.0259      0.271     -0.095      0.924      -0.558       0.506
q_length                              0.1387      0.259      0.535      0.593      -0.370       0.647
avg_word_length                      -0.4075      0.286     -1.424      0.154      -0.968       0.153
percent_non_alphabetic_whitespace     0.0105      0.028      0.378      0.706      -0.044       0.065
capabilities_entropy                  1.6665      0.354      4.702      0.000       0.972       2.361
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  248
Model:                          Logit   Df Residuals:                      240
Method:                           MLE   Df Model:                            7
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.09202
Time:                        17:34:43   Log-Likelihood:                -134.84
converged:                       True   LL-Null:                       -148.50
Covariance Type:            nonrobust   LLR p-value:                 0.0002908
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -0.0271      2.389     -0.011      0.991      -4.709       4.655
C(domain_grouped)[T.chemistry]       -0.3860      0.491     -0.787      0.432      -1.348       0.576
C(domain_grouped)[T.physics]         -0.8724      0.526     -1.657      0.097      -1.904       0.159
human_difficulty                     -0.0451      0.266     -0.169      0.866      -0.567       0.477
q_length                              0.1481      0.255      0.582      0.561      -0.351       0.647
avg_word_length                      -0.3871      0.286     -1.353      0.176      -0.948       0.173
percent_non_alphabetic_whitespace     0.0130      0.028      0.466      0.641      -0.042       0.068
game_entropy                          1.3593      0.324      4.196      0.000       0.724       1.994
=====================================================================================================

                  Model 4.95: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  248
Model:                          Logit   Df Residuals:                      239
Method:                           MLE   Df Model:                            8
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1266
Time:                        17:34:43   Log-Likelihood:                -129.70
converged:                       True   LL-Null:                       -148.50
Covariance Type:            nonrobust   LLR p-value:                 8.878e-06
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -0.5112      2.423     -0.211      0.833      -5.261       4.238
C(domain_grouped)[T.chemistry]       -0.3822      0.506     -0.755      0.450      -1.374       0.610
C(domain_grouped)[T.physics]         -0.8749      0.541     -1.616      0.106      -1.936       0.186
human_difficulty                     -0.0129      0.275     -0.047      0.963      -0.552       0.526
q_length                              0.1269      0.262      0.484      0.628      -0.387       0.640
avg_word_length                      -0.3319      0.284     -1.168      0.243      -0.889       0.225
percent_non_alphabetic_whitespace     0.0175      0.028      0.620      0.536      -0.038       0.073
capabilities_entropy                  1.2698      0.400      3.175      0.001       0.486       2.054
game_entropy                          0.7976      0.373      2.141      0.032       0.067       1.528
=====================================================================================================

--- Analyzing gemini-2.5-flash-preview-04-17 (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_neutral/gemini-2.5-flash-preview-04-17_GPQA_redacted_cor_temp0.0_1751846071_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    294
1     43
Name: count, dtype: int64

Answer change%: 0.1276 [0.09197502698812982, 0.1632178513501491] (n=337)
P-value vs 25%: 1.64e-11; P-value vs 0%: 2.209e-12
Phase 2 self-accuracy: 0.2791 [0.1450043151794982, 0.41313521970422273] (n=43)
P-value vs 25%: 0.6708; P-value vs 33%: 0.4304

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  333
Model:                          Logit   Df Residuals:                      331
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.03647
Time:                        17:34:43   Log-Likelihood:                -123.44
converged:                       True   LL-Null:                       -128.11
Covariance Type:            nonrobust   LLR p-value:                  0.002236
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -2.1791      0.197    -11.035      0.000      -2.566      -1.792
game_entropy     1.1467      0.357      3.213      0.001       0.447       1.846
================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  337
Model:                          Logit   Df Residuals:                      335
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                0.003073
Time:                        17:34:43   Log-Likelihood:                -128.27
converged:                       True   LL-Null:                       -128.66
Covariance Type:            nonrobust   LLR p-value:                    0.3739
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -2.5224      0.700     -3.603      0.000      -3.894      -1.150
human_difficulty     0.2557      0.286      0.893      0.372      -0.306       0.817
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  337
Model:                          Logit   Df Residuals:                      330
Method:                           MLE   Df Model:                            6
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.03940
Time:                        17:34:43   Log-Likelihood:                -123.59
converged:                       True   LL-Null:                       -128.66
Covariance Type:            nonrobust   LLR p-value:                    0.1189
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -2.3983      2.242     -1.070      0.285      -6.793       1.996
C(domain_grouped)[T.chemistry]       -0.1637      0.481     -0.341      0.733      -1.106       0.778
C(domain_grouped)[T.physics]         -0.8952      0.509     -1.760      0.078      -1.892       0.102
human_difficulty                      0.3134      0.322      0.973      0.331      -0.318       0.945
q_length                             -0.1204      0.276     -0.437      0.662      -0.661       0.420
avg_word_length                       0.0943      0.227      0.415      0.678      -0.351       0.540
percent_non_alphabetic_whitespace     0.0472      0.025      1.860      0.063      -0.003       0.097
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  333
Model:                          Logit   Df Residuals:                      325
Method:                           MLE   Df Model:                            7
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.07413
Time:                        17:34:43   Log-Likelihood:                -118.62
converged:                       True   LL-Null:                       -128.11
Covariance Type:            nonrobust   LLR p-value:                  0.008203
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -1.2683      2.291     -0.554      0.580      -5.759       3.222
C(domain_grouped)[T.chemistry]       -0.5254      0.511     -1.028      0.304      -1.527       0.476
C(domain_grouped)[T.physics]         -1.0867      0.526     -2.067      0.039      -2.117      -0.056
human_difficulty                      0.2457      0.328      0.749      0.454      -0.397       0.888
q_length                             -0.2867      0.287     -0.998      0.318      -0.850       0.276
avg_word_length                       0.0902      0.229      0.395      0.693      -0.358       0.538
percent_non_alphabetic_whitespace     0.0443      0.026      1.704      0.088      -0.007       0.095
game_entropy                          1.2049      0.391      3.081      0.002       0.438       1.971
=====================================================================================================

--- Analyzing gemini-2.5-flash-preview-04-17 (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_neutral/gemini-2.5-flash-preview-04-17_GPQA_redacted_temp0.0_1751828022_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    56
1    50
Name: count, dtype: int64

Answer change%: 0.4717 [0.3766664546809168, 0.5667297717341776] (n=106)
P-value vs 25%: 4.822e-06; P-value vs 0%: 2.28e-22
Phase 2 self-accuracy: 0.5800 [0.44319507547452175, 0.7168049245254782] (n=50)
P-value vs 25%: 2.27e-06; P-value vs 33%: 0.0004021

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  103
Model:                          Logit   Df Residuals:                      101
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.04958
Time:                        17:34:43   Log-Likelihood:                -67.813
converged:                       True   LL-Null:                       -71.350
Covariance Type:            nonrobust   LLR p-value:                  0.007815
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.4167      0.243     -1.717      0.086      -0.892       0.059
game_entropy     1.2109      0.479      2.527      0.012       0.272       2.150
================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  106
Model:                          Logit   Df Residuals:                      104
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:               0.0003629
Time:                        17:34:43   Log-Likelihood:                -73.277
converged:                       True   LL-Null:                       -73.304
Covariance Type:            nonrobust   LLR p-value:                    0.8176
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -0.3134      0.889     -0.352      0.725      -2.057       1.430
human_difficulty     0.0791      0.343      0.231      0.818      -0.593       0.751
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  106
Model:                          Logit   Df Residuals:                       99
Method:                           MLE   Df Model:                            6
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.03936
Time:                        17:34:43   Log-Likelihood:                -70.418
converged:                       True   LL-Null:                       -73.304
Covariance Type:            nonrobust   LLR p-value:                    0.4493
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                             0.4091      3.340      0.122      0.903      -6.137       6.955
C(domain_grouped)[T.chemistry]        0.8072      0.656      1.230      0.219      -0.479       2.094
C(domain_grouped)[T.physics]          0.1630      0.723      0.225      0.822      -1.254       1.580
human_difficulty                      0.2514      0.381      0.660      0.509      -0.495       0.998
q_length                              0.1154      0.307      0.376      0.707      -0.486       0.717
avg_word_length                      -0.4909      0.389     -1.263      0.207      -1.253       0.271
percent_non_alphabetic_whitespace    -0.0082      0.043     -0.192      0.848      -0.092       0.076
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  103
Model:                          Logit   Df Residuals:                       95
Method:                           MLE   Df Model:                            7
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.08167
Time:                        17:34:43   Log-Likelihood:                -65.523
converged:                       True   LL-Null:                       -71.350
Covariance Type:            nonrobust   LLR p-value:                    0.1125
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                             0.7651      3.442      0.222      0.824      -5.980       7.511
C(domain_grouped)[T.chemistry]        0.5594      0.695      0.805      0.421      -0.802       1.921
C(domain_grouped)[T.physics]          0.0687      0.734      0.094      0.925      -1.369       1.507
human_difficulty                      0.3625      0.400      0.906      0.365      -0.422       1.147
q_length                             -0.0136      0.320     -0.042      0.966      -0.641       0.614
avg_word_length                      -0.4958      0.397     -1.248      0.212      -1.274       0.283
percent_non_alphabetic_whitespace     0.0014      0.045      0.030      0.976      -0.086       0.089
game_entropy                          1.0353      0.518      1.997      0.046       0.019       2.051
=====================================================================================================

--- Analyzing gpt-4.1-2025-04-14 (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_neutral/gpt-4.1-2025-04-14_GPQA_redacted_cor_temp0.0_1751832342_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    173
1     34
Name: count, dtype: int64

Answer change%: 0.1643 [0.11377867679093989, 0.21472373866799732] (n=207)
P-value vs 25%: 0.000869; P-value vs 0%: 1.791e-10
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=34)
P-value vs 25%: 0; P-value vs 33%: 0

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  207
Model:                          Logit   Df Residuals:                      205
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1093
Time:                        17:34:43   Log-Likelihood:                -82.350
converged:                       True   LL-Null:                       -92.457
Covariance Type:            nonrobust   LLR p-value:                 6.927e-06
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          3.8380      1.247      3.077      0.002       1.394       6.282
p_i_capability    -5.9008      1.349     -4.374      0.000      -8.545      -3.256
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  207
Model:                          Logit   Df Residuals:                      205
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1621
Time:                        17:34:43   Log-Likelihood:                -77.466
converged:                       True   LL-Null:                       -92.457
Covariance Type:            nonrobust   LLR p-value:                 4.360e-08
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.2648      0.256     -8.848      0.000      -2.767      -1.763
capabilities_entropy     2.3852      0.455      5.243      0.000       1.494       3.277
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.6667 [0.4489, 0.8844] (n=18)
                  P-value vs 33.3%: 0.0027

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=-0.49, p=0.632
Wilcoxon delta_p: statistic=27.00, p=0.638
Mean Δp = -0.0395  [-0.1961, 0.1171]
Idea 1 N = 11; 

  Idea 1.5: Calibration Metrics
  NLL: 0.2610, Signed ECE (overconf pos under neg): -0.2065, ECE: 0.2065 (n=23)
  Brier: 0.0753, Reliability (absolute calibration error; lower better): 0.0747, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=23)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.878
Model:                            OLS   Adj. R-squared:                  0.859
Method:                 Least Squares   F-statistic:                     45.53
Date:                Sat, 09 Aug 2025   Prob (F-statistic):           7.19e-09
Time:                        17:34:43   Log-Likelihood:                 11.838
No. Observations:                  23   AIC:                            -15.68
Df Residuals:                      19   BIC:                            -11.13
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.7334      0.188     -3.898      0.001      -1.127      -0.340
p1                    0.8428      0.221      3.814      0.001       0.380       1.305
answer_changed        0.8007      0.328      2.445      0.024       0.115       1.486
p1:answer_changed    -0.0456      0.409     -0.111      0.912      -0.903       0.811
==============================================================================
Omnibus:                        3.039   Durbin-Watson:                   1.559
Prob(Omnibus):                  0.219   Jarque-Bera (JB):                1.558
Skew:                           0.587   Prob(JB):                        0.459
Kurtosis:                       3.498   Cond. No.                         24.4
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=1.85, p=0.0937
Wilcoxon delta_H: statistic=15.00, p=0.123
Mean ΔH = 0.2238  [-0.0130, 0.4606]
Paired t-test delta_H Changed: statistic=3.01, p=0.0118
Wilcoxon delta_H Changed: statistic=8.00, p=0.0122
Mean ΔH Changed = 0.5341  [0.1864, 0.8817]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=3.32, p=0.00313
Wilcoxon (p_top2_game vs p_top2_base): statistic=43.00, p=0.00273
Mean Δp_top2 = 0.0478  [0.0196, 0.0760] (n=23)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=3.45, p=0.00226
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=42.00, p=0.00242
Mean ΔH_unchosen_baseline_set = 0.3857  [0.1668, 0.6046] (n=23)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                   23
Model:                          Logit   Df Residuals:                       20
Method:                           MLE   Df Model:                            2
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.2359
Time:                        17:34:43   Log-Likelihood:                -12.165
converged:                       True   LL-Null:                       -15.921
Covariance Type:            nonrobust   LLR p-value:                   0.02340
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept        1.4577      0.813      1.792      0.073      -0.137       3.052
p1_z            -0.7719      0.534     -1.446      0.148      -1.818       0.274
I(p1_z ** 2)    -1.4194      0.707     -2.007      0.045      -2.806      -0.033
================================================================================
AUC = 0.818

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  207
Model:                          Logit   Df Residuals:                      205
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1131
Time:                        17:34:43   Log-Likelihood:                -81.996
converged:                       True   LL-Null:                       -92.457
Covariance Type:            nonrobust   LLR p-value:                 4.782e-06
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -2.0183      0.227     -8.897      0.000      -2.463      -1.574
game_entropy     2.8607      0.652      4.386      0.000       1.582       4.139
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=1365.50, p=2.19e-06
Paired t-test (game_entropy vs capabilities_entropy): statistic=-3.80, p=0.000188
Mean capabilities_entropy-game_entropy = 0.0843  [0.0409, 0.1277] (n=207)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  207
Model:                          Logit   Df Residuals:                      204
Method:                           MLE   Df Model:                            2
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1871
Time:                        17:34:43   Log-Likelihood:                -75.159
converged:                       True   LL-Null:                       -92.457
Covariance Type:            nonrobust   LLR p-value:                 3.074e-08
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.3487      0.265     -8.873      0.000      -2.868      -1.830
capabilities_entropy     1.8699      0.503      3.716      0.000       0.884       2.856
game_entropy             1.6342      0.763      2.142      0.032       0.139       3.129
========================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  207
Model:                          Logit   Df Residuals:                      205
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                0.005736
Time:                        17:34:43   Log-Likelihood:                -91.927
converged:                       True   LL-Null:                       -92.457
Covariance Type:            nonrobust   LLR p-value:                    0.3031
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -2.4483      0.832     -2.942      0.003      -4.079      -0.817
human_difficulty     0.3374      0.328      1.029      0.304      -0.305       0.980
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  207
Model:                          Logit   Df Residuals:                      200
Method:                           MLE   Df Model:                            6
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1327
Time:                        17:34:43   Log-Likelihood:                -80.191
converged:                       True   LL-Null:                       -92.457
Covariance Type:            nonrobust   LLR p-value:                 0.0004169
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -0.7241      3.174     -0.228      0.820      -6.945       5.496
C(domain_grouped)[T.chemistry]        2.6401      0.819      3.224      0.001       1.035       4.245
C(domain_grouped)[T.physics]          1.4202      0.814      1.745      0.081      -0.175       3.016
human_difficulty                      0.6568      0.355      1.849      0.064      -0.039       1.353
q_length                              0.1450      0.331      0.438      0.661      -0.504       0.794
avg_word_length                      -1.0203      0.467     -2.183      0.029      -1.936      -0.104
percent_non_alphabetic_whitespace    -0.0522      0.041     -1.284      0.199      -0.132       0.027
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 0.1733
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  207
Model:                          Logit   Df Residuals:                      199
Method:                           MLE   Df Model:                            7
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.2558
Time:                        17:34:43   Log-Likelihood:                -68.805
converged:                       True   LL-Null:                       -92.457
Covariance Type:            nonrobust   LLR p-value:                 4.868e-08
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -0.9617      3.358     -0.286      0.775      -7.544       5.621
C(domain_grouped)[T.chemistry]        2.1655      0.860      2.519      0.012       0.480       3.851
C(domain_grouped)[T.physics]          1.0986      0.837      1.313      0.189      -0.541       2.739
human_difficulty                      0.9167      0.393      2.330      0.020       0.146       1.688
q_length                              0.1005      0.362      0.278      0.781      -0.609       0.810
avg_word_length                      -1.0851      0.517     -2.101      0.036      -2.098      -0.073
percent_non_alphabetic_whitespace    -0.0663      0.044     -1.490      0.136      -0.153       0.021
capabilities_entropy                  2.2993      0.513      4.485      0.000       1.295       3.304
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  207
Model:                          Logit   Df Residuals:                      199
Method:                           MLE   Df Model:                            7
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.2201
Time:                        17:34:43   Log-Likelihood:                -72.108
converged:                       True   LL-Null:                       -92.457
Covariance Type:            nonrobust   LLR p-value:                 9.254e-07
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                             0.2556      3.269      0.078      0.938      -6.152       6.663
C(domain_grouped)[T.chemistry]        2.5290      0.863      2.932      0.003       0.838       4.220
C(domain_grouped)[T.physics]          1.3381      0.842      1.590      0.112      -0.312       2.988
human_difficulty                      0.6694      0.364      1.837      0.066      -0.045       1.383
q_length                              0.0317      0.346      0.092      0.927      -0.647       0.710
avg_word_length                      -1.1291      0.499     -2.263      0.024      -2.107      -0.151
percent_non_alphabetic_whitespace    -0.0699      0.044     -1.591      0.112      -0.156       0.016
game_entropy                          2.6975      0.699      3.860      0.000       1.328       4.067
=====================================================================================================

                  Model 4.95: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  207
Model:                          Logit   Df Residuals:                      198
Method:                           MLE   Df Model:                            8
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.2795
Time:                        17:34:43   Log-Likelihood:                -66.617
converged:                       True   LL-Null:                       -92.457
Covariance Type:            nonrobust   LLR p-value:                 1.939e-08
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -0.2631      3.403     -0.077      0.938      -6.932       6.406
C(domain_grouped)[T.chemistry]        2.2742      0.891      2.552      0.011       0.528       4.021
C(domain_grouped)[T.physics]          1.1729      0.859      1.365      0.172      -0.511       2.857
human_difficulty                      0.9015      0.398      2.268      0.023       0.122       1.681
q_length                              0.0141      0.367      0.038      0.969      -0.705       0.734
avg_word_length                      -1.1381      0.523     -2.177      0.029      -2.163      -0.114
percent_non_alphabetic_whitespace    -0.0776      0.046     -1.691      0.091      -0.167       0.012
capabilities_entropy                  1.8183      0.556      3.272      0.001       0.729       2.907
game_entropy                          1.6390      0.779      2.105      0.035       0.113       3.165
=====================================================================================================

--- Analyzing gpt-4.1-2025-04-14 (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_neutral/gpt-4.1-2025-04-14_GPQA_redacted_temp0.0_1751825484_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    171
1     69
Name: count, dtype: int64

Answer change%: 0.2875 [0.23023967231794326, 0.34476032768205667] (n=240)
P-value vs 25%: 0.1993; P-value vs 0%: 7.508e-23
Phase 2 self-accuracy: 0.4203 [0.3038227047253018, 0.5367570054196257] (n=69)
P-value vs 25%: 0.004161; P-value vs 33%: 0.1418

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  240
Model:                          Logit   Df Residuals:                      238
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.05615
Time:                        17:34:43   Log-Likelihood:                -135.89
converged:                       True   LL-Null:                       -143.98
Covariance Type:            nonrobust   LLR p-value:                 5.791e-05
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          1.6329      0.645      2.531      0.011       0.368       2.897
p_i_capability    -3.0035      0.755     -3.979      0.000      -4.483      -1.524
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  240
Model:                          Logit   Df Residuals:                      238
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.06184
Time:                        17:34:43   Log-Likelihood:                -135.07
converged:                       True   LL-Null:                       -143.98
Covariance Type:            nonrobust   LLR p-value:                 2.445e-05
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.4767      0.211     -6.982      0.000      -1.891      -1.062
capabilities_entropy     1.1154      0.269      4.149      0.000       0.588       1.642
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.6400 [0.5070, 0.7730] (n=50)
                  P-value vs 33.3%: 6.254e-06

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=-4.29, p=7.93e-05
Wilcoxon delta_p: statistic=208.00, p=1.18e-05
Mean Δp = -0.1183  [-0.1723, -0.0643]
Idea 1 N = 52; 

  Idea 1.5: Calibration Metrics
  NLL: 5.4111, Signed ECE (overconf pos under neg): 0.0824, ECE: 0.0824 (n=88)
  Brier: 0.0204, Reliability (absolute calibration error; lower better): 0.0198, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=88)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.888
Model:                            OLS   Adj. R-squared:                  0.884
Method:                 Least Squares   F-statistic:                     221.9
Date:                Sat, 09 Aug 2025   Prob (F-statistic):           8.33e-40
Time:                        17:34:43   Log-Likelihood:                 48.852
No. Observations:                  88   AIC:                            -89.70
Df Residuals:                      84   BIC:                            -79.79
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.5939      0.081     -7.296      0.000      -0.756      -0.432
p1                    0.6089      0.101      6.023      0.000       0.408       0.810
answer_changed        0.4337      0.120      3.607      0.001       0.195       0.673
p1:answer_changed     0.5014      0.160      3.135      0.002       0.183       0.819
==============================================================================
Omnibus:                       27.802   Durbin-Watson:                   1.709
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               46.297
Skew:                           1.296   Prob(JB):                     8.85e-11
Kurtosis:                       5.431   Cond. No.                         19.7
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=3.60, p=0.000725
Wilcoxon delta_H: statistic=341.00, p=0.00153
Mean ΔH = 0.2354  [0.1071, 0.3636]
Paired t-test delta_H Changed: statistic=5.83, p=1.29e-06
Wilcoxon delta_H Changed: statistic=48.00, p=7.11e-07
Mean ΔH Changed = 0.4556  [0.3025, 0.6088]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=4.97, p=3.38e-06
Wilcoxon (p_top2_game vs p_top2_base): statistic=411.00, p=1.22e-10
Mean Δp_top2 = 0.0431  [0.0261, 0.0602] (n=88)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=6.36, p=9.22e-09
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=652.00, p=5.51e-08
Mean ΔH_unchosen_baseline_set = 0.3255  [0.2251, 0.4258] (n=88)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                   88
Model:                          Logit   Df Residuals:                       85
Method:                           MLE   Df Model:                            2
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.04347
Time:                        17:34:43   Log-Likelihood:                -56.946
converged:                       True   LL-Null:                       -59.534
Covariance Type:            nonrobust   LLR p-value:                   0.07518
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.2134      0.335     -0.637      0.524      -0.870       0.443
p1_z            -0.5339      0.243     -2.199      0.028      -1.010      -0.058
I(p1_z ** 2)    -0.1820      0.264     -0.689      0.491      -0.700       0.336
================================================================================
AUC = 0.653

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  240
Model:                          Logit   Df Residuals:                      238
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.06383
Time:                        17:34:43   Log-Likelihood:                -134.79
converged:                       True   LL-Null:                       -143.98
Covariance Type:            nonrobust   LLR p-value:                 1.810e-05
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.2761      0.176     -7.252      0.000      -1.621      -0.931
game_entropy     1.4863      0.357      4.165      0.000       0.787       2.186
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=4243.50, p=5.48e-15
Paired t-test (game_entropy vs capabilities_entropy): statistic=-7.76, p=2.4e-13
Mean capabilities_entropy-game_entropy = 0.2365  [0.1768, 0.2962] (n=240)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  240
Model:                          Logit   Df Residuals:                      237
Method:                           MLE   Df Model:                            2
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.08334
Time:                        17:34:43   Log-Likelihood:                -131.98
converged:                       True   LL-Null:                       -143.98
Covariance Type:            nonrobust   LLR p-value:                 6.152e-06
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.5310      0.214     -7.157      0.000      -1.950      -1.112
capabilities_entropy     0.7373      0.310      2.378      0.017       0.130       1.345
game_entropy             1.0113      0.409      2.472      0.013       0.209       1.813
========================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  240
Model:                          Logit   Df Residuals:                      238
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                0.004672
Time:                        17:34:43   Log-Likelihood:                -143.30
converged:                       True   LL-Null:                       -143.98
Covariance Type:            nonrobust   LLR p-value:                    0.2461
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -0.2247      0.607     -0.371      0.711      -1.414       0.964
human_difficulty    -0.2935      0.256     -1.148      0.251      -0.795       0.208
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  240
Model:                          Logit   Df Residuals:                      233
Method:                           MLE   Df Model:                            6
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.01902
Time:                        17:34:43   Log-Likelihood:                -141.24
converged:                       True   LL-Null:                       -143.98
Covariance Type:            nonrobust   LLR p-value:                    0.4841
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                             0.3338      2.248      0.148      0.882      -4.073       4.740
C(domain_grouped)[T.chemistry]       -0.4893      0.575     -0.851      0.395      -1.616       0.638
C(domain_grouped)[T.physics]         -0.4256      0.596     -0.714      0.476      -1.595       0.743
human_difficulty                     -0.2821      0.268     -1.054      0.292      -0.807       0.243
q_length                              0.2446      0.254      0.963      0.335      -0.253       0.742
avg_word_length                      -0.3485      0.245     -1.420      0.156      -0.830       0.133
percent_non_alphabetic_whitespace    -0.0045      0.025     -0.179      0.858      -0.054       0.045
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 0.4513
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  240
Model:                          Logit   Df Residuals:                      232
Method:                           MLE   Df Model:                            7
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.07105
Time:                        17:34:43   Log-Likelihood:                -133.75
converged:                       True   LL-Null:                       -143.98
Covariance Type:            nonrobust   LLR p-value:                  0.004657
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -0.5621      2.314     -0.243      0.808      -5.097       3.973
C(domain_grouped)[T.chemistry]       -0.5373      0.598     -0.899      0.369      -1.709       0.634
C(domain_grouped)[T.physics]         -0.4136      0.624     -0.663      0.507      -1.636       0.809
human_difficulty                     -0.1764      0.279     -0.633      0.526      -0.722       0.369
q_length                              0.1414      0.267      0.529      0.597      -0.383       0.665
avg_word_length                      -0.2081      0.248     -0.838      0.402      -0.695       0.279
percent_non_alphabetic_whitespace     0.0069      0.026      0.263      0.792      -0.044       0.058
capabilities_entropy                  1.0575      0.278      3.805      0.000       0.513       1.602
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  240
Model:                          Logit   Df Residuals:                      232
Method:                           MLE   Df Model:                            7
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.07779
Time:                        17:34:43   Log-Likelihood:                -132.78
converged:                       True   LL-Null:                       -143.98
Covariance Type:            nonrobust   LLR p-value:                  0.002167
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -0.2764      2.311     -0.120      0.905      -4.806       4.254
C(domain_grouped)[T.chemistry]       -0.6759      0.590     -1.146      0.252      -1.832       0.481
C(domain_grouped)[T.physics]         -0.4800      0.612     -0.784      0.433      -1.680       0.720
human_difficulty                     -0.2806      0.278     -1.009      0.313      -0.826       0.265
q_length                              0.1856      0.266      0.697      0.486      -0.336       0.707
avg_word_length                      -0.2123      0.252     -0.844      0.399      -0.705       0.281
percent_non_alphabetic_whitespace     0.0050      0.026      0.191      0.848      -0.046       0.056
game_entropy                          1.4624      0.366      3.998      0.000       0.746       2.179
=====================================================================================================

                  Model 4.95: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  240
Model:                          Logit   Df Residuals:                      231
Method:                           MLE   Df Model:                            8
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.09325
Time:                        17:34:43   Log-Likelihood:                -130.55
converged:                       True   LL-Null:                       -143.98
Covariance Type:            nonrobust   LLR p-value:                 0.0007497
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -0.6305      2.336     -0.270      0.787      -5.209       3.948
C(domain_grouped)[T.chemistry]       -0.6446      0.605     -1.066      0.287      -1.830       0.541
C(domain_grouped)[T.physics]         -0.4551      0.630     -0.722      0.470      -1.691       0.780
human_difficulty                     -0.2136      0.284     -0.753      0.451      -0.770       0.342
q_length                              0.1335      0.272      0.491      0.623      -0.399       0.666
avg_word_length                      -0.1652      0.252     -0.657      0.511      -0.658       0.328
percent_non_alphabetic_whitespace     0.0087      0.026      0.335      0.737      -0.042       0.060
capabilities_entropy                  0.6729      0.318      2.114      0.034       0.049       1.297
game_entropy                          1.0443      0.416      2.508      0.012       0.228       1.860
=====================================================================================================

--- Analyzing gpt-4o-2024-08-06 (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_neutral/gpt-4o-2024-08-06_GPQA_redacted_cor_temp0.0_1751845346_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    155
1     29
Name: count, dtype: int64

Answer change%: 0.1576 [0.10496017113298224, 0.2102572201713656] (n=184)
P-value vs 25%: 0.0005828; P-value vs 0%: 4.428e-09
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=29)
P-value vs 25%: 0; P-value vs 33%: 0

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  184
Model:                          Logit   Df Residuals:                      182
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.06892
Time:                        17:34:43   Log-Likelihood:                -74.640
converged:                       True   LL-Null:                       -80.166
Covariance Type:            nonrobust   LLR p-value:                 0.0008867
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept         -0.2162      0.452     -0.478      0.632      -1.102       0.670
p_i_capability    -2.0755      0.619     -3.350      0.001      -3.290      -0.861
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  184
Model:                          Logit   Df Residuals:                      182
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.2869
Time:                        17:34:43   Log-Likelihood:                -57.168
converged:                       True   LL-Null:                       -80.166
Covariance Type:            nonrobust   LLR p-value:                 1.185e-11
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -3.6891      0.517     -7.141      0.000      -4.702      -2.677
capabilities_entropy     2.3882      0.423      5.649      0.000       1.560       3.217
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.4138 [0.2345, 0.5930] (n=29)
                  P-value vs 33.3%: 0.379

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=-1.34, p=0.184
Wilcoxon delta_p: statistic=2165.00, p=0.000125
Mean Δp = -0.0174  [-0.0430, 0.0081]
Idea 1 N = 120; 

  Idea 1.5: Calibration Metrics
  NLL: 0.4057, Signed ECE (overconf pos under neg): -0.2403, ECE: 0.2403 (n=147)
  Brier: 0.1357, Reliability (absolute calibration error; lower better): 0.1351, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=147)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.166
Model:                            OLS   Adj. R-squared:                  0.149
Method:                 Least Squares   F-statistic:                     9.494
Date:                Sat, 09 Aug 2025   Prob (F-statistic):           9.25e-06
Time:                        17:34:43   Log-Likelihood:                 46.655
No. Observations:                 147   AIC:                            -85.31
Df Residuals:                     143   BIC:                            -73.35
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.1431      0.075     -1.909      0.058      -0.291       0.005
p1                    0.1469      0.085      1.718      0.088      -0.022       0.316
answer_changed        0.0533      0.144      0.371      0.711      -0.231       0.337
p1:answer_changed     0.2852      0.223      1.281      0.202      -0.155       0.725
==============================================================================
Omnibus:                       25.767   Durbin-Watson:                   1.754
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               94.701
Skew:                           0.527   Prob(JB):                     2.73e-21
Kurtosis:                       6.788   Cond. No.                         23.7
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=1.01, p=0.315
Wilcoxon delta_H: statistic=3266.00, p=0.42
Mean ΔH = 0.0397  [-0.0374, 0.1168]
Paired t-test delta_H Changed: statistic=4.32, p=0.000204
Wilcoxon delta_H Changed: statistic=37.00, p=8.37e-05
Mean ΔH Changed = 0.2829  [0.1545, 0.4114]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=3.82, p=0.000197
Wilcoxon (p_top2_game vs p_top2_base): statistic=2575.00, p=3.05e-08
Mean Δp_top2 = 0.0219  [0.0107, 0.0331] (n=147)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=2.40, p=0.0175
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=4138.00, p=0.0165
Mean ΔH_unchosen_baseline_set = 0.0844  [0.0156, 0.1531] (n=147)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  147
Model:                          Logit   Df Residuals:                      144
Method:                           MLE   Df Model:                            2
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.2907
Time:                        17:34:43   Log-Likelihood:                -49.729
converged:                       True   LL-Null:                       -70.107
Covariance Type:            nonrobust   LLR p-value:                 1.412e-09
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.7126      0.372     -4.606      0.000      -2.441      -0.984
p1_z            -2.1645      0.543     -3.984      0.000      -3.229      -1.100
I(p1_z ** 2)    -0.6575      0.328     -2.005      0.045      -1.300      -0.015
================================================================================
AUC = 0.850

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  184
Model:                          Logit   Df Residuals:                      182
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.2109
Time:                        17:34:43   Log-Likelihood:                -63.259
converged:                       True   LL-Null:                       -80.166
Covariance Type:            nonrobust   LLR p-value:                 6.066e-09
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -2.9489      0.385     -7.652      0.000      -3.704      -2.194
game_entropy     2.0289      0.381      5.327      0.000       1.282       2.775
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=4103.00, p=1.12e-09
Paired t-test (game_entropy vs capabilities_entropy): statistic=-5.79, p=3.01e-08
Mean capabilities_entropy-game_entropy = 0.1354  [0.0896, 0.1813] (n=184)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  184
Model:                          Logit   Df Residuals:                      181
Method:                           MLE   Df Model:                            2
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.2869
Time:                        17:34:43   Log-Likelihood:                -57.165
converged:                       True   LL-Null:                       -80.166
Covariance Type:            nonrobust   LLR p-value:                 1.025e-10
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -3.6847      0.518     -7.109      0.000      -4.701      -2.669
capabilities_entropy     2.3405      0.706      3.317      0.001       0.958       3.723
game_entropy             0.0571      0.677      0.084      0.933      -1.270       1.385
========================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  184
Model:                          Logit   Df Residuals:                      182
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                0.001407
Time:                        17:34:43   Log-Likelihood:                -80.053
converged:                       True   LL-Null:                       -80.166
Covariance Type:            nonrobust   LLR p-value:                    0.6348
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -1.2833      0.847     -1.516      0.130      -2.943       0.376
human_difficulty    -0.1628      0.343     -0.474      0.636      -0.836       0.510
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  184
Model:                          Logit   Df Residuals:                      177
Method:                           MLE   Df Model:                            6
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.07380
Time:                        17:34:43   Log-Likelihood:                -74.250
converged:                       True   LL-Null:                       -80.166
Covariance Type:            nonrobust   LLR p-value:                   0.06583
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -5.9045      2.747     -2.149      0.032     -11.289      -0.520
C(domain_grouped)[T.chemistry]        2.0143      0.690      2.921      0.003       0.663       3.366
C(domain_grouped)[T.physics]          1.3213      0.698      1.893      0.058      -0.047       2.689
human_difficulty                     -0.0110      0.359     -0.031      0.975      -0.714       0.692
q_length                              0.1678      0.340      0.493      0.622      -0.499       0.834
avg_word_length                       0.4196      0.264      1.591      0.112      -0.097       0.937
percent_non_alphabetic_whitespace -8.103e-05      0.039     -0.002      0.998      -0.076       0.076
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 0.5517
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  184
Model:                          Logit   Df Residuals:                      176
Method:                           MLE   Df Model:                            7
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.3456
Time:                        17:34:43   Log-Likelihood:                -52.462
converged:                       True   LL-Null:                       -80.166
Covariance Type:            nonrobust   LLR p-value:                 1.238e-09
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                           -11.0265      3.774     -2.921      0.003     -18.424      -3.629
C(domain_grouped)[T.chemistry]        0.9842      0.838      1.174      0.240      -0.658       2.627
C(domain_grouped)[T.physics]          0.3612      0.868      0.416      0.677      -1.341       2.063
human_difficulty                      0.0889      0.413      0.215      0.830      -0.721       0.899
q_length                              0.3712      0.432      0.860      0.390      -0.475       1.218
avg_word_length                       0.7794      0.376      2.073      0.038       0.042       1.516
percent_non_alphabetic_whitespace     0.0572      0.049      1.178      0.239      -0.038       0.152
capabilities_entropy                  2.6978      0.528      5.109      0.000       1.663       3.733
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  184
Model:                          Logit   Df Residuals:                      176
Method:                           MLE   Df Model:                            7
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.2615
Time:                        17:34:43   Log-Likelihood:                -59.204
converged:                       True   LL-Null:                       -80.166
Covariance Type:            nonrobust   LLR p-value:                 5.378e-07
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -7.4983      3.179     -2.359      0.018     -13.729      -1.268
C(domain_grouped)[T.chemistry]        1.4977      0.782      1.915      0.056      -0.036       3.031
C(domain_grouped)[T.physics]          0.9534      0.805      1.184      0.236      -0.625       2.532
human_difficulty                      0.1046      0.400      0.261      0.794      -0.680       0.889
q_length                              0.0128      0.390      0.033      0.974      -0.751       0.777
avg_word_length                       0.6368      0.326      1.955      0.051      -0.002       1.275
percent_non_alphabetic_whitespace     0.0299      0.043      0.688      0.491      -0.055       0.115
game_entropy                          2.0747      0.423      4.901      0.000       1.245       2.904
=====================================================================================================

                  Model 4.95: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  184
Model:                          Logit   Df Residuals:                      175
Method:                           MLE   Df Model:                            8
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.3456
Time:                        17:34:43   Log-Likelihood:                -52.462
converged:                       True   LL-Null:                       -80.166
Covariance Type:            nonrobust   LLR p-value:                 3.679e-09
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                           -11.0281      3.775     -2.921      0.003     -18.427      -3.629
C(domain_grouped)[T.chemistry]        0.9841      0.838      1.174      0.240      -0.659       2.627
C(domain_grouped)[T.physics]          0.3621      0.869      0.417      0.677      -1.341       2.065
human_difficulty                      0.0903      0.416      0.217      0.828      -0.726       0.907
q_length                              0.3706      0.432      0.857      0.391      -0.477       1.218
avg_word_length                       0.7797      0.376      2.073      0.038       0.043       1.517
percent_non_alphabetic_whitespace     0.0572      0.049      1.179      0.238      -0.038       0.152
capabilities_entropy                  2.6816      0.773      3.470      0.001       1.167       4.196
game_entropy                          0.0200      0.697      0.029      0.977      -1.347       1.387
=====================================================================================================

--- Analyzing gpt-4o-2024-08-06 (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_neutral/gpt-4o-2024-08-06_GPQA_redacted_temp0.0_1751827002_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    168
1     95
Name: count, dtype: int64

Answer change%: 0.3612 [0.30316289536565666, 0.4192705647103889] (n=263)
P-value vs 25%: 0.0001735; P-value vs 0%: 3.301e-34
Phase 2 self-accuracy: 0.4316 [0.33198074697834873, 0.5311771477584935] (n=95)
P-value vs 25%: 0.0003526; P-value vs 33%: 0.05239

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  263
Model:                          Logit   Df Residuals:                      261
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.09178
Time:                        17:34:43   Log-Likelihood:                -156.24
converged:                       True   LL-Null:                       -172.03
Covariance Type:            nonrobust   LLR p-value:                 1.915e-08
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          1.9226      0.484      3.969      0.000       0.973       2.872
p_i_capability    -3.6581      0.699     -5.230      0.000      -5.029      -2.287
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  263
Model:                          Logit   Df Residuals:                      261
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1353
Time:                        17:34:43   Log-Likelihood:                -148.75
converged:                       True   LL-Null:                       -172.03
Covariance Type:            nonrobust   LLR p-value:                 8.865e-12
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.4460      0.362     -6.761      0.000      -3.155      -1.737
capabilities_entropy     1.7378      0.287      6.046      0.000       1.175       2.301
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.3158 [0.2223, 0.4093] (n=95)
                  P-value vs 33.3%: 0.713

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=-0.13, p=0.899
Wilcoxon delta_p: statistic=5535.00, p=0.243
Mean Δp = -0.0020  [-0.0323, 0.0283]
Idea 1 N = 157; 

  Idea 1.5: Calibration Metrics
  NLL: 3.2531, Signed ECE (overconf pos under neg): 0.1718, ECE: 0.1718 (n=252)
  Brier: 0.0761, Reliability (absolute calibration error; lower better): 0.0754, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=252)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.139
Model:                            OLS   Adj. R-squared:                  0.128
Method:                 Least Squares   F-statistic:                     13.27
Date:                Sat, 09 Aug 2025   Prob (F-statistic):           4.66e-08
Time:                        17:34:43   Log-Likelihood:                 2.2436
No. Observations:                 251   AIC:                             3.513
Df Residuals:                     247   BIC:                             17.61
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.0399      0.077     -0.520      0.603      -0.191       0.111
p1                    0.0498      0.097      0.511      0.610      -0.142       0.242
answer_changed       -0.2788      0.126     -2.218      0.027      -0.526      -0.031
p1:answer_changed     0.6951      0.187      3.716      0.000       0.327       1.064
==============================================================================
Omnibus:                        2.030   Durbin-Watson:                   2.022
Prob(Omnibus):                  0.362   Jarque-Bera (JB):                2.070
Skew:                           0.214   Prob(JB):                        0.355
Kurtosis:                       2.880   Cond. No.                         20.3
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=6.01, p=1.25e-08
Wilcoxon delta_H: statistic=2972.00, p=9.27e-09
Mean ΔH = 0.2111  [0.1423, 0.2800]
Paired t-test delta_H Changed: statistic=7.46, p=4.56e-11
Wilcoxon delta_H Changed: statistic=529.00, p=2.2e-10
Mean ΔH Changed = 0.3074  [0.2266, 0.3882]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=7.69, p=3.35e-13
Wilcoxon (p_top2_game vs p_top2_base): statistic=5892.00, p=4.16e-18
Mean Δp_top2 = 0.0436  [0.0325, 0.0547] (n=252)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=9.16, p=1.91e-17
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=6131.00, p=4.13e-17
Mean ΔH_unchosen_baseline_set = 0.2470  [0.1942, 0.2999] (n=252)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  252
Model:                          Logit   Df Residuals:                      249
Method:                           MLE   Df Model:                            2
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1412
Time:                        17:34:43   Log-Likelihood:                -142.95
converged:                       True   LL-Null:                       -166.46
Covariance Type:            nonrobust   LLR p-value:                 6.205e-11
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.2218      0.196     -1.134      0.257      -0.605       0.162
p1_z            -1.0314      0.184     -5.618      0.000      -1.391      -0.672
I(p1_z ** 2)    -0.5007      0.176     -2.839      0.005      -0.846      -0.155
================================================================================
AUC = 0.720

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  263
Model:                          Logit   Df Residuals:                      261
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.08388
Time:                        17:34:43   Log-Likelihood:                -157.60
converged:                       True   LL-Null:                       -172.03
Covariance Type:            nonrobust   LLR p-value:                 7.773e-08
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.6081      0.255     -6.304      0.000      -2.108      -1.108
game_entropy     1.2876      0.252      5.103      0.000       0.793       1.782
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=7146.00, p=1.33e-16
Paired t-test (game_entropy vs capabilities_entropy): statistic=-8.73, p=3.12e-16
Mean capabilities_entropy-game_entropy = 0.2424  [0.1880, 0.2969] (n=263)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  263
Model:                          Logit   Df Residuals:                      260
Method:                           MLE   Df Model:                            2
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1392
Time:                        17:34:43   Log-Likelihood:                -148.09
converged:                       True   LL-Null:                       -172.03
Covariance Type:            nonrobust   LLR p-value:                 3.990e-11
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.4842      0.364     -6.819      0.000      -3.198      -1.770
capabilities_entropy     1.4836      0.358      4.146      0.000       0.782       2.185
game_entropy             0.3835      0.332      1.154      0.249      -0.268       1.035
========================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  263
Model:                          Logit   Df Residuals:                      261
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.01165
Time:                        17:34:43   Log-Likelihood:                -170.03
converged:                       True   LL-Null:                       -172.03
Covariance Type:            nonrobust   LLR p-value:                   0.04526
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept            0.5237      0.565      0.926      0.354      -0.584       1.632
human_difficulty    -0.4744      0.241     -1.969      0.049      -0.947      -0.002
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  263
Model:                          Logit   Df Residuals:                      256
Method:                           MLE   Df Model:                            6
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.03894
Time:                        17:34:43   Log-Likelihood:                -165.33
converged:                       True   LL-Null:                       -172.03
Covariance Type:            nonrobust   LLR p-value:                   0.03715
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -0.6134      2.167     -0.283      0.777      -4.861       3.635
C(domain_grouped)[T.chemistry]       -0.1651      0.528     -0.313      0.754      -1.200       0.870
C(domain_grouped)[T.physics]          0.1986      0.541      0.367      0.714      -0.862       1.259
human_difficulty                     -0.4945      0.250     -1.976      0.048      -0.985      -0.004
q_length                              0.4170      0.228      1.832      0.067      -0.029       0.863
avg_word_length                      -0.2836      0.252     -1.125      0.261      -0.778       0.210
percent_non_alphabetic_whitespace     0.0005      0.024      0.019      0.985      -0.047       0.048
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 0.9955
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  263
Model:                          Logit   Df Residuals:                      255
Method:                           MLE   Df Model:                            7
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1623
Time:                        17:34:43   Log-Likelihood:                -144.10
converged:                       True   LL-Null:                       -172.03
Covariance Type:            nonrobust   LLR p-value:                 1.008e-09
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -2.2895      2.386     -0.960      0.337      -6.965       2.386
C(domain_grouped)[T.chemistry]       -0.8543      0.597     -1.430      0.153      -2.025       0.317
C(domain_grouped)[T.physics]         -0.4166      0.613     -0.679      0.497      -1.619       0.786
human_difficulty                     -0.5161      0.279     -1.851      0.064      -1.063       0.030
q_length                              0.3126      0.249      1.254      0.210      -0.176       0.801
avg_word_length                      -0.0712      0.275     -0.259      0.796      -0.610       0.467
percent_non_alphabetic_whitespace     0.0104      0.027      0.391      0.696      -0.042       0.063
capabilities_entropy                  1.7529      0.301      5.815      0.000       1.162       2.344
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  263
Model:                          Logit   Df Residuals:                      255
Method:                           MLE   Df Model:                            7
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1105
Time:                        17:34:43   Log-Likelihood:                -153.02
converged:                       True   LL-Null:                       -172.03
Covariance Type:            nonrobust   LLR p-value:                 2.992e-06
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -2.4649      2.326     -1.060      0.289      -7.025       2.095
C(domain_grouped)[T.chemistry]       -0.6385      0.558     -1.145      0.252      -1.732       0.455
C(domain_grouped)[T.physics]         -0.1730      0.572     -0.302      0.762      -1.294       0.948
human_difficulty                     -0.4797      0.262     -1.832      0.067      -0.993       0.034
q_length                              0.3570      0.241      1.482      0.138      -0.115       0.829
avg_word_length                       0.0307      0.269      0.114      0.909      -0.496       0.557
percent_non_alphabetic_whitespace     0.0124      0.025      0.490      0.624      -0.037       0.062
game_entropy                          1.2885      0.272      4.733      0.000       0.755       1.822
=====================================================================================================

                  Model 4.95: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  263
Model:                          Logit   Df Residuals:                      254
Method:                           MLE   Df Model:                            8
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1657
Time:                        17:34:43   Log-Likelihood:                -143.53
converged:                       True   LL-Null:                       -172.03
Covariance Type:            nonrobust   LLR p-value:                 1.804e-09
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -2.5496      2.402     -1.061      0.289      -7.258       2.159
C(domain_grouped)[T.chemistry]       -0.8972      0.599     -1.498      0.134      -2.072       0.277
C(domain_grouped)[T.physics]         -0.4478      0.615     -0.728      0.467      -1.653       0.758
human_difficulty                     -0.5152      0.279     -1.847      0.065      -1.062       0.032
q_length                              0.3068      0.250      1.228      0.220      -0.183       0.796
avg_word_length                      -0.0134      0.280     -0.048      0.962      -0.562       0.535
percent_non_alphabetic_whitespace     0.0120      0.027      0.450      0.653      -0.040       0.064
capabilities_entropy                  1.5221      0.367      4.143      0.000       0.802       2.242
game_entropy                          0.3718      0.348      1.068      0.286      -0.311       1.054
=====================================================================================================

--- Analyzing grok-3-latest (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_neutral/grok-3-latest_GPQA_redacted_cor_temp0.0_1751833528_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    185
1     18
Name: count, dtype: int64

Answer change%: 0.0887 [0.04956550353533102, 0.1277743979425015] (n=203)
P-value vs 25%: 6.162e-16; P-value vs 0%: 8.82e-06
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=18)
P-value vs 25%: 0; P-value vs 33%: 0

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  203
Model:                          Logit   Df Residuals:                      201
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                0.006112
Time:                        17:34:43   Log-Likelihood:                -60.417
converged:                       True   LL-Null:                       -60.788
Covariance Type:            nonrobust   LLR p-value:                    0.3887
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept         -1.6188      0.795     -2.036      0.042      -3.177      -0.061
p_i_capability    -0.7993      0.870     -0.919      0.358      -2.504       0.906
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  197
Model:                          Logit   Df Residuals:                      195
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1233
Time:                        17:34:43   Log-Likelihood:                -52.794
converged:                       True   LL-Null:                       -60.222
Covariance Type:            nonrobust   LLR p-value:                 0.0001161
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.9623      0.353     -8.401      0.000      -3.653      -2.271
capabilities_entropy     2.5126      0.629      3.997      0.000       1.281       3.745
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.8889 [0.7437, 1.0000] (n=18)
                  P-value vs 33.3%: 6.382e-14

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=-0.62, p=0.535
Wilcoxon delta_p: statistic=4519.00, p=3.34e-06
Mean Δp = -0.0049  [-0.0202, 0.0105]
Idea 1 N = 174; 

  Idea 1.5: Calibration Metrics
  NLL: 0.0495, Signed ECE (overconf pos under neg): -0.0419, ECE: 0.0419 (n=192)
  Brier: 0.0114, Reliability (absolute calibration error; lower better): 0.0110, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=192)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.881
Model:                            OLS   Adj. R-squared:                  0.879
Method:                 Least Squares   F-statistic:                     465.0
Date:                Sat, 09 Aug 2025   Prob (F-statistic):           1.07e-86
Time:                        17:34:43   Log-Likelihood:                 194.90
No. Observations:                 192   AIC:                            -381.8
Df Residuals:                     188   BIC:                            -368.8
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.7519      0.078     -9.623      0.000      -0.906      -0.598
p1                    0.7717      0.080      9.597      0.000       0.613       0.930
answer_changed        0.3134      0.140      2.232      0.027       0.036       0.590
p1:answer_changed     0.6133      0.156      3.938      0.000       0.306       0.920
==============================================================================
Omnibus:                      131.079   Durbin-Watson:                   2.157
Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1595.665
Skew:                           2.381   Prob(JB):                         0.00
Kurtosis:                      16.296   Cond. No.                         47.7
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-1.71, p=0.0897
Wilcoxon delta_H: statistic=6428.00, p=0.0751
Mean ΔH = -0.0676  [-0.1453, 0.0100]
Paired t-test delta_H Changed: statistic=3.11, p=0.00635
Wilcoxon delta_H Changed: statistic=19.00, p=0.00233
Mean ΔH Changed = 0.2553  [0.0945, 0.4161]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=-0.14, p=0.889
Wilcoxon (p_top2_game vs p_top2_base): statistic=6442.00, p=0.000252
Mean Δp_top2 = -0.0002  [-0.0031, 0.0027] (n=192)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=-1.00, p=0.318
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=8474.00, p=0.306
Mean ΔH_unchosen_baseline_set = -0.0374  [-0.1105, 0.0358] (n=192)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  192
Model:                          Logit   Df Residuals:                      189
Method:                           MLE   Df Model:                            2
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1239
Time:                        17:34:43   Log-Likelihood:                -52.336
converged:                       True   LL-Null:                       -59.737
Covariance Type:            nonrobust   LLR p-value:                 0.0006105
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -2.3333      0.302     -7.724      0.000      -2.925      -1.741
p1_z            -1.2672      0.471     -2.688      0.007      -2.191      -0.343
I(p1_z ** 2)    -0.1995      0.143     -1.400      0.162      -0.479       0.080
================================================================================
AUC = 0.845

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  203
Model:                          Logit   Df Residuals:                      201
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.09751
Time:                        17:34:43   Log-Likelihood:                -54.861
converged:                       True   LL-Null:                       -60.788
Covariance Type:            nonrobust   LLR p-value:                 0.0005749
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -2.8168      0.321     -8.763      0.000      -3.447      -2.187
game_entropy     2.3536      0.658      3.576      0.000       1.064       3.644
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=6138.00, p=6.49e-06
Paired t-test (game_entropy vs capabilities_entropy): statistic=-1.54, p=0.125
Mean capabilities_entropy-game_entropy = 0.0328  [-0.0090, 0.0747] (n=197)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  197
Model:                          Logit   Df Residuals:                      194
Method:                           MLE   Df Model:                            2
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1547
Time:                        17:34:43   Log-Likelihood:                -50.904
converged:                       True   LL-Null:                       -60.222
Covariance Type:            nonrobust   LLR p-value:                 8.973e-05
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -3.1338      0.379     -8.274      0.000      -3.876      -2.391
capabilities_entropy     1.9428      0.699      2.778      0.005       0.572       3.314
game_entropy             1.5182      0.741      2.050      0.040       0.067       2.970
========================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  203
Model:                          Logit   Df Residuals:                      201
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:               0.0006524
Time:                        17:34:43   Log-Likelihood:                -60.749
converged:                       True   LL-Null:                       -60.788
Covariance Type:            nonrobust   LLR p-value:                    0.7782
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -2.0128      1.147     -1.754      0.079      -4.262       0.236
human_difficulty    -0.1323      0.470     -0.281      0.778      -1.054       0.789
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  203
Model:                          Logit   Df Residuals:                      196
Method:                           MLE   Df Model:                            6
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.05875
Time:                        17:34:43   Log-Likelihood:                -57.217
converged:                       True   LL-Null:                       -60.788
Covariance Type:            nonrobust   LLR p-value:                    0.3079
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -2.8375      4.025     -0.705      0.481     -10.727       5.052
C(domain_grouped)[T.chemistry]        1.8542      0.846      2.192      0.028       0.197       3.512
C(domain_grouped)[T.physics]          0.8223      0.882      0.932      0.351      -0.906       2.551
human_difficulty                      0.0829      0.489      0.170      0.865      -0.875       1.040
q_length                              0.0817      0.436      0.187      0.851      -0.774       0.937
avg_word_length                      -0.1860      0.472     -0.394      0.694      -1.112       0.740
percent_non_alphabetic_whitespace    -0.0514      0.048     -1.061      0.289      -0.146       0.044
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 0.1592
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  197
Model:                          Logit   Df Residuals:                      189
Method:                           MLE   Df Model:                            7
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1769
Time:                        17:34:43   Log-Likelihood:                -49.569
converged:                       True   LL-Null:                       -60.222
Covariance Type:            nonrobust   LLR p-value:                  0.003342
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -5.4887      4.177     -1.314      0.189     -13.676       2.699
C(domain_grouped)[T.chemistry]        1.5602      0.884      1.765      0.078      -0.172       3.292
C(domain_grouped)[T.physics]          0.5697      0.963      0.592      0.554      -1.317       2.457
human_difficulty                     -0.1814      0.531     -0.342      0.733      -1.223       0.860
q_length                              0.1756      0.443      0.396      0.692      -0.693       1.044
avg_word_length                       0.2658      0.474      0.561      0.575      -0.663       1.195
percent_non_alphabetic_whitespace    -0.0345      0.047     -0.739      0.460      -0.126       0.057
capabilities_entropy                  2.7446      0.721      3.807      0.000       1.332       4.158
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  203
Model:                          Logit   Df Residuals:                      195
Method:                           MLE   Df Model:                            7
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1394
Time:                        17:34:43   Log-Likelihood:                -52.315
converged:                       True   LL-Null:                       -60.788
Covariance Type:            nonrobust   LLR p-value:                   0.01774
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -4.0818      4.055     -1.007      0.314     -12.030       3.866
C(domain_grouped)[T.chemistry]        1.4800      0.860      1.722      0.085      -0.205       3.165
C(domain_grouped)[T.physics]          0.5788      0.924      0.626      0.531      -1.233       2.391
human_difficulty                     -0.1681      0.511     -0.329      0.742      -1.170       0.834
q_length                              0.0849      0.442      0.192      0.848      -0.781       0.950
avg_word_length                       0.1282      0.487      0.263      0.792      -0.826       1.083
percent_non_alphabetic_whitespace    -0.0344      0.051     -0.672      0.501      -0.135       0.066
game_entropy                          2.2983      0.710      3.238      0.001       0.907       3.689
=====================================================================================================

                  Model 4.95: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  197
Model:                          Logit   Df Residuals:                      188
Method:                           MLE   Df Model:                            8
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.2058
Time:                        17:34:43   Log-Likelihood:                -47.829
converged:                       True   LL-Null:                       -60.222
Covariance Type:            nonrobust   LLR p-value:                  0.001689
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -6.0291      4.179     -1.443      0.149     -14.221       2.163
C(domain_grouped)[T.chemistry]        1.3117      0.887      1.479      0.139      -0.427       3.050
C(domain_grouped)[T.physics]          0.3350      0.992      0.338      0.736      -1.609       2.279
human_difficulty                     -0.3560      0.548     -0.650      0.516      -1.430       0.718
q_length                              0.1813      0.447      0.406      0.685      -0.694       1.057
avg_word_length                       0.4346      0.484      0.897      0.370      -0.515       1.384
percent_non_alphabetic_whitespace    -0.0205      0.048     -0.426      0.670      -0.115       0.074
capabilities_entropy                  2.2636      0.778      2.910      0.004       0.739       3.788
game_entropy                          1.5895      0.811      1.960      0.050   -4.49e-05       3.179
=====================================================================================================

--- Analyzing grok-3-latest (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_neutral/grok-3-latest_GPQA_redacted_temp0.0_1751825913_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    184
1     60
Name: count, dtype: int64

Answer change%: 0.2459 [0.1918700318770172, 0.2999332468115074] (n=244)
P-value vs 25%: 0.8818; P-value vs 0%: 4.666e-19
Phase 2 self-accuracy: 0.3000 [0.18404696695459213, 0.41595303304540787] (n=60)
P-value vs 25%: 0.398; P-value vs 33%: 0.577

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  244
Model:                          Logit   Df Residuals:                      242
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.01341
Time:                        17:34:43   Log-Likelihood:                -134.28
converged:                       True   LL-Null:                       -136.10
Covariance Type:            nonrobust   LLR p-value:                   0.05610
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept         -0.1700      0.504     -0.337      0.736      -1.158       0.818
p_i_capability    -1.1359      0.583     -1.947      0.051      -2.279       0.007
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  236
Model:                          Logit   Df Residuals:                      234
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.05787
Time:                        17:34:43   Log-Likelihood:                -123.99
converged:                       True   LL-Null:                       -131.60
Covariance Type:            nonrobust   LLR p-value:                 9.512e-05
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.7303      0.235     -7.374      0.000      -2.190      -1.270
capabilities_entropy     1.3057      0.338      3.865      0.000       0.644       1.968
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.7719 [0.6630, 0.8809] (n=57)
                  P-value vs 33.3%: 2.977e-15

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=0.41, p=0.679
Wilcoxon delta_p: statistic=6235.00, p=0.0846
Mean Δp = 0.0050  [-0.0188, 0.0288]
Idea 1 N = 171; 

  Idea 1.5: Calibration Metrics
  NLL: 6.9395, Signed ECE (overconf pos under neg): 0.0391, ECE: 0.0391 (n=228)
  Brier: 0.0077, Reliability (absolute calibration error; lower better): 0.0072, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=228)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.838
Model:                            OLS   Adj. R-squared:                  0.836
Method:                 Least Squares   F-statistic:                     386.4
Date:                Sat, 09 Aug 2025   Prob (F-statistic):           3.11e-88
Time:                        17:34:43   Log-Likelihood:                 123.05
No. Observations:                 228   AIC:                            -238.1
Df Residuals:                     224   BIC:                            -224.4
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.5005      0.076     -6.546      0.000      -0.651      -0.350
p1                    0.5538      0.083      6.680      0.000       0.390       0.717
answer_changed        0.4321      0.122      3.551      0.000       0.192       0.672
p1:answer_changed     0.3847      0.139      2.759      0.006       0.110       0.660
==============================================================================
Omnibus:                       37.325   Durbin-Watson:                   2.285
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               57.773
Skew:                           0.932   Prob(JB):                     2.85e-13
Kurtosis:                       4.614   Cond. No.                         29.4
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=0.49, p=0.628
Wilcoxon delta_H: statistic=7121.00, p=0.72
Mean ΔH = 0.0186  [-0.0563, 0.0934]
Paired t-test delta_H Changed: statistic=4.44, p=4.27e-05
Wilcoxon delta_H Changed: statistic=271.00, p=1.02e-05
Mean ΔH Changed = 0.2373  [0.1326, 0.3421]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=2.04, p=0.0429
Wilcoxon (p_top2_game vs p_top2_base): statistic=6546.00, p=6.76e-11
Mean Δp_top2 = 0.0080  [0.0003, 0.0156] (n=228)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=2.28, p=0.0238
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=10691.00, p=0.0178
Mean ΔH_unchosen_baseline_set = 0.0732  [0.0102, 0.1363] (n=228)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  228
Model:                          Logit   Df Residuals:                      225
Method:                           MLE   Df Model:                            2
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.05785
Time:                        17:34:43   Log-Likelihood:                -120.80
converged:                       True   LL-Null:                       -128.21
Covariance Type:            nonrobust   LLR p-value:                 0.0006013
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.0014      0.205     -4.897      0.000      -1.402      -0.601
p1_z            -0.7971      0.265     -3.006      0.003      -1.317      -0.277
I(p1_z ** 2)    -0.1741      0.142     -1.225      0.221      -0.453       0.105
================================================================================
AUC = 0.705

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  244
Model:                          Logit   Df Residuals:                      242
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.06803
Time:                        17:34:43   Log-Likelihood:                -126.84
converged:                       True   LL-Null:                       -136.10
Covariance Type:            nonrobust   LLR p-value:                 1.684e-05
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.7335      0.225     -7.708      0.000      -2.174      -1.293
game_entropy     1.4162      0.338      4.192      0.000       0.754       2.078
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=11341.00, p=0.0119
Paired t-test (game_entropy vs capabilities_entropy): statistic=-1.21, p=0.229
Mean capabilities_entropy-game_entropy = 0.0365  [-0.0228, 0.0957] (n=236)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  236
Model:                          Logit   Df Residuals:                      233
Method:                           MLE   Df Model:                            2
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.08478
Time:                        17:34:43   Log-Likelihood:                -120.44
converged:                       True   LL-Null:                       -131.60
Covariance Type:            nonrobust   LLR p-value:                 1.428e-05
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.9783      0.264     -7.499      0.000      -2.495      -1.461
capabilities_entropy     0.9217      0.371      2.484      0.013       0.194       1.649
game_entropy             0.9846      0.369      2.669      0.008       0.261       1.708
========================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  244
Model:                          Logit   Df Residuals:                      242
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                0.001344
Time:                        17:34:43   Log-Likelihood:                -135.92
converged:                       True   LL-Null:                       -136.10
Covariance Type:            nonrobust   LLR p-value:                    0.5453
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -0.7733      0.593     -1.304      0.192      -1.935       0.389
human_difficulty    -0.1496      0.249     -0.602      0.547      -0.637       0.338
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  244
Model:                          Logit   Df Residuals:                      237
Method:                           MLE   Df Model:                            6
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                0.007017
Time:                        17:34:43   Log-Likelihood:                -135.15
converged:                       True   LL-Null:                       -136.10
Covariance Type:            nonrobust   LLR p-value:                    0.9278
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -1.2857      2.175     -0.591      0.554      -5.549       2.978
C(domain_grouped)[T.chemistry]        0.0044      0.591      0.007      0.994      -1.154       1.163
C(domain_grouped)[T.physics]          0.3848      0.620      0.621      0.535      -0.830       1.600
human_difficulty                     -0.1216      0.252     -0.482      0.630      -0.616       0.373
q_length                              0.0112      0.246      0.046      0.964      -0.471       0.494
avg_word_length                       0.0317      0.235      0.135      0.893      -0.429       0.492
percent_non_alphabetic_whitespace     0.0075      0.027      0.280      0.780      -0.045       0.060
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 0.4085
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  236
Model:                          Logit   Df Residuals:                      228
Method:                           MLE   Df Model:                            7
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.06505
Time:                        17:34:43   Log-Likelihood:                -123.04
converged:                       True   LL-Null:                       -131.60
Covariance Type:            nonrobust   LLR p-value:                   0.01664
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -1.9344      2.271     -0.852      0.394      -6.386       2.517
C(domain_grouped)[T.chemistry]       -0.4392      0.630     -0.697      0.486      -1.675       0.796
C(domain_grouped)[T.physics]         -0.1235      0.668     -0.185      0.853      -1.433       1.186
human_difficulty                     -0.1836      0.266     -0.690      0.490      -0.705       0.338
q_length                              0.0951      0.261      0.364      0.716      -0.417       0.607
avg_word_length                       0.0426      0.244      0.175      0.861      -0.435       0.521
percent_non_alphabetic_whitespace     0.0150      0.028      0.543      0.587      -0.039       0.069
capabilities_entropy                  1.3133      0.347      3.785      0.000       0.633       1.993
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  244
Model:                          Logit   Df Residuals:                      236
Method:                           MLE   Df Model:                            7
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.07811
Time:                        17:34:43   Log-Likelihood:                -125.47
converged:                       True   LL-Null:                       -136.10
Covariance Type:            nonrobust   LLR p-value:                  0.003400
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -3.0684      2.318     -1.324      0.186      -7.612       1.475
C(domain_grouped)[T.chemistry]        0.1612      0.634      0.254      0.799      -1.081       1.403
C(domain_grouped)[T.physics]          0.6051      0.666      0.909      0.363      -0.700       1.910
human_difficulty                     -0.1176      0.263     -0.447      0.655      -0.634       0.398
q_length                              0.0655      0.265      0.247      0.805      -0.454       0.585
avg_word_length                       0.1401      0.241      0.581      0.561      -0.333       0.613
percent_non_alphabetic_whitespace     0.0238      0.028      0.849      0.396      -0.031       0.079
game_entropy                          1.4755      0.345      4.273      0.000       0.799       2.152
=====================================================================================================

                  Model 4.95: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  236
Model:                          Logit   Df Residuals:                      227
Method:                           MLE   Df Model:                            8
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.09379
Time:                        17:34:43   Log-Likelihood:                -119.26
converged:                       True   LL-Null:                       -131.60
Covariance Type:            nonrobust   LLR p-value:                  0.001757
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -2.8322      2.368     -1.196      0.232      -7.473       1.808
C(domain_grouped)[T.chemistry]       -0.2258      0.660     -0.342      0.732      -1.520       1.068
C(domain_grouped)[T.physics]          0.1753      0.699      0.251      0.802      -1.195       1.546
human_difficulty                     -0.1777      0.271     -0.656      0.512      -0.709       0.353
q_length                              0.1027      0.271      0.379      0.705      -0.428       0.634
avg_word_length                       0.1019      0.247      0.412      0.680      -0.382       0.586
percent_non_alphabetic_whitespace     0.0241      0.028      0.852      0.394      -0.031       0.079
capabilities_entropy                  0.8907      0.385      2.315      0.021       0.136       1.645
game_entropy                          1.0443      0.380      2.747      0.006       0.299       1.789
=====================================================================================================
