
--- Analyzing claude-3-5-sonnet-20241022 (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_neutral/claude-3-5-sonnet-20241022_SimpleMC_redacted_cor_temp0.0_1754440066_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    262
1     38
Name: count, dtype: int64

Answer change%: 0.1267 [0.08903021663391511, 0.16430311669941824] (n=300)
P-value vs 25%: 1.338e-10; P-value vs 0%: 4.215e-11
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=38)
P-value vs 25%: 0; P-value vs 33%: 0

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  300
Model:                          Logit   Df Residuals:                      298
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.2304
Time:                        09:26:53   Log-Likelihood:                -87.732
converged:                       True   LL-Null:                       -114.00
Covariance Type:            nonrobust   LLR p-value:                 4.225e-13
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          2.6491      0.669      3.961      0.000       1.338       3.960
p_i_capability    -6.5784      1.043     -6.307      0.000      -8.623      -4.534
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  300
Model:                          Logit   Df Residuals:                      298
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.2541
Time:                        09:26:53   Log-Likelihood:                -85.035
converged:                       True   LL-Null:                       -114.00
Covariance Type:            nonrobust   LLR p-value:                 2.716e-14
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -4.9464      0.623     -7.946      0.000      -6.166      -3.726
capabilities_entropy     2.7038      0.436      6.205      0.000       1.850       3.558
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.6842 [0.5364, 0.8320] (n=38)
                  P-value vs 33.3%: 3.268e-06

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=-0.55, p=0.583
Wilcoxon delta_p: statistic=8195.00, p=0.756
Mean Δp = -0.0049  [-0.0222, 0.0125]
Idea 1 N = 262; 

  Idea 1.5: Calibration Metrics
  NLL: 0.2738, Signed ECE (overconf pos under neg): -0.2103, ECE: 0.2103 (n=300)
  Brier: 0.0822, Reliability (absolute calibration error; lower better): 0.0817, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=300)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.534
Model:                            OLS   Adj. R-squared:                  0.529
Method:                 Least Squares   F-statistic:                     113.0
Date:                Sat, 20 Sep 2025   Prob (F-statistic):           8.92e-49
Time:                        09:26:53   Log-Likelihood:                 192.48
No. Observations:                 300   AIC:                            -377.0
Df Residuals:                     296   BIC:                            -362.1
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.2916      0.037     -7.800      0.000      -0.365      -0.218
p1                    0.3489      0.044      7.848      0.000       0.261       0.436
answer_changed        0.0760      0.087      0.872      0.384      -0.096       0.248
p1:answer_changed     0.6113      0.141      4.334      0.000       0.334       0.889
==============================================================================
Omnibus:                       24.447   Durbin-Watson:                   1.796
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               33.192
Skew:                           0.584   Prob(JB):                     6.20e-08
Kurtosis:                       4.136   Cond. No.                         28.8
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-0.34, p=0.733
Wilcoxon delta_H: statistic=8209.50, p=0.771
Mean ΔH = -0.0080  [-0.0540, 0.0380]
Paired t-test delta_H Changed: statistic=4.65, p=4.13e-05
Wilcoxon delta_H Changed: statistic=111.00, p=7.31e-05
Mean ΔH Changed = 0.2638  [0.1526, 0.3750]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=0.06, p=0.954
Wilcoxon (p_top2_game vs p_top2_base): statistic=12076.50, p=0.934
Mean Δp_top2 = 0.0002  [-0.0079, 0.0084] (n=300)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=1.18, p=0.237
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=10987.50, p=0.179
Mean ΔH_unchosen_baseline_set = 0.0264  [-0.0173, 0.0701] (n=300)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  300
Model:                          Logit   Df Residuals:                      297
Method:                           MLE   Df Model:                            2
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.2468
Time:                        09:26:53   Log-Likelihood:                -85.862
converged:                       True   LL-Null:                       -114.00
Covariance Type:            nonrobust   LLR p-value:                 6.023e-13
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -2.3693      0.304     -7.793      0.000      -2.965      -1.773
p1_z            -1.8807      0.415     -4.536      0.000      -2.693      -1.068
I(p1_z ** 2)    -0.4329      0.231     -1.878      0.060      -0.885       0.019
================================================================================
AUC = 0.847

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  300
Model:                          Logit   Df Residuals:                      298
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.2548
Time:                        09:26:53   Log-Likelihood:                -84.954
converged:                       True   LL-Null:                       -114.00
Covariance Type:            nonrobust   LLR p-value:                 2.502e-14
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -4.9094      0.613     -8.013      0.000      -6.110      -3.709
game_entropy     2.6930      0.431      6.253      0.000       1.849       3.537
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=12140.50, p=0.895
Paired t-test (game_entropy vs capabilities_entropy): statistic=-0.36, p=0.72
Mean capabilities_entropy-game_entropy = 0.0078  [-0.0348, 0.0505] (n=300)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  300
Model:                          Logit   Df Residuals:                      297
Method:                           MLE   Df Model:                            2
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.2930
Time:                        09:26:53   Log-Likelihood:                -80.597
converged:                       True   LL-Null:                       -114.00
Covariance Type:            nonrobust   LLR p-value:                 3.114e-15
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -5.4755      0.691     -7.919      0.000      -6.831      -4.120
capabilities_entropy     1.6207      0.567      2.856      0.004       0.509       2.733
game_entropy             1.5608      0.554      2.817      0.005       0.475       2.647
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.914894
                        1                 0.085106
Geography               0                 0.782609
                        1                 0.217391
Misc                    0                 0.857143
                        1                 0.142857
Music                   0                 0.791667
                        1                 0.208333
Other                   0                 0.843750
                        1                 0.156250
Politics                0                 0.880000
                        1                 0.120000
Science and technology  0                 0.923077
                        1                 0.076923
Sports                  0                 0.913043
                        1                 0.086957
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.810000
                     1                 0.190000
Number               0                 0.857143
                     1                 0.142857
Other                0                 0.909091
                     1                 0.090909
Person               0                 0.922078
                     1                 0.077922
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.900000  0.100000           10
                       Number               0.833333  0.166667            6
                       Other                0.916667  0.083333           12
                       Person               0.947368  0.052632           19
Geography              Date                 0.571429  0.428571            7
                       Number               0.888889  0.111111            9
                       Other                0.857143  0.142857            7
Misc                   Date                 0.750000  0.250000           16
                       Number               0.666667  0.333333            6
                       Other                1.000000  0.000000           17
                       Person               0.900000  0.100000           10
Music                  Date                 0.714286  0.285714            7
                       Other                0.714286  0.285714            7
                       Person               0.900000  0.100000           10
Other                  Date                 0.818182  0.181818           11
                       Number               1.000000  0.000000            2
                       Other                0.900000  0.100000           10
                       Person               0.777778  0.222222            9
Politics               Date                 0.818182  0.181818           22
                       Number               0.666667  0.333333            3
                       Other                0.937500  0.062500           16
                       Person               1.000000  0.000000            9
Science and technology Date                 0.850000  0.150000           20
                       Number               1.000000  0.000000            5
                       Other                0.923077  0.076923           13
                       Person               1.000000  0.000000           14
Sports                 Date                 1.000000  0.000000            7
                       Number               1.000000  0.000000            4
                       Other                0.833333  0.166667            6
                       Person               0.833333  0.166667            6

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  300
Model:                          Logit   Df Residuals:                      288
Method:                           MLE   Df Model:                           11
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.05219
Time:                        09:26:53   Log-Likelihood:                -108.05
converged:                       True   LL-Null:                       -114.00
Covariance Type:            nonrobust   LLR p-value:                    0.3712
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.6310      2.350     -0.694      0.488      -6.236       2.974
C(topic_grouped)[T.Geography]                  0.8666      0.758      1.143      0.253      -0.619       2.352
C(topic_grouped)[T.Misc]                       0.4651      0.674      0.690      0.490      -0.857       1.787
C(topic_grouped)[T.Music]                      1.0505      0.740      1.419      0.156      -0.401       2.502
C(topic_grouped)[T.Other]                      0.5905      0.726      0.813      0.416      -0.832       2.013
C(topic_grouped)[T.Politics]                   0.1860      0.715      0.260      0.795      -1.215       1.587
C(topic_grouped)[T.Science and technology]    -0.2778      0.752     -0.370      0.712      -1.751       1.195
C(topic_grouped)[T.Sports]                    -0.1051      0.916     -0.115      0.909      -1.900       1.690
C(answer_type_grouped)[T.Number]              -0.4042      0.580     -0.697      0.486      -1.541       0.733
C(answer_type_grouped)[T.Other]               -0.9149      0.458     -1.996      0.046      -1.813      -0.017
C(answer_type_grouped)[T.Person]              -1.0292      0.515     -2.000      0.045      -2.038      -0.021
q_length                                      -0.0265      0.510     -0.052      0.958      -1.026       0.973
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.8267
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  300
Model:                          Logit   Df Residuals:                      287
Method:                           MLE   Df Model:                           12
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.2807
Time:                        09:26:53   Log-Likelihood:                -82.000
converged:                       True   LL-Null:                       -114.00
Covariance Type:            nonrobust   LLR p-value:                 4.169e-09
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -6.3699      2.910     -2.189      0.029     -12.073      -0.667
C(topic_grouped)[T.Geography]                  0.6331      0.865      0.732      0.464      -1.062       2.328
C(topic_grouped)[T.Misc]                       0.2771      0.751      0.369      0.712      -1.196       1.750
C(topic_grouped)[T.Music]                      0.4887      0.848      0.576      0.564      -1.174       2.151
C(topic_grouped)[T.Other]                      0.2178      0.839      0.260      0.795      -1.427       1.863
C(topic_grouped)[T.Politics]                   0.2170      0.767      0.283      0.777      -1.287       1.721
C(topic_grouped)[T.Science and technology]    -0.3194      0.824     -0.388      0.698      -1.934       1.295
C(topic_grouped)[T.Sports]                    -0.0529      1.017     -0.052      0.959      -2.046       1.941
C(answer_type_grouped)[T.Number]              -0.9250      0.647     -1.430      0.153      -2.193       0.343
C(answer_type_grouped)[T.Other]               -0.5939      0.523     -1.137      0.256      -1.618       0.430
C(answer_type_grouped)[T.Person]              -0.7702      0.576     -1.337      0.181      -1.899       0.359
q_length                                       0.3763      0.602      0.625      0.532      -0.803       1.555
capabilities_entropy                           2.7023      0.460      5.872      0.000       1.800       3.604
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  300
Model:                          Logit   Df Residuals:                      287
Method:                           MLE   Df Model:                           12
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.2739
Time:                        09:26:53   Log-Likelihood:                -82.781
converged:                       True   LL-Null:                       -114.00
Covariance Type:            nonrobust   LLR p-value:                 8.082e-09
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -7.0874      3.083     -2.299      0.021     -13.129      -1.046
C(topic_grouped)[T.Geography]                  0.7669      0.843      0.909      0.363      -0.886       2.420
C(topic_grouped)[T.Misc]                       0.0823      0.770      0.107      0.915      -1.426       1.591
C(topic_grouped)[T.Music]                      0.1469      0.872      0.168      0.866      -1.562       1.856
C(topic_grouped)[T.Other]                      0.0386      0.813      0.048      0.962      -1.555       1.632
C(topic_grouped)[T.Politics]                   0.6545      0.797      0.821      0.411      -0.907       2.216
C(topic_grouped)[T.Science and technology]    -0.2724      0.859     -0.317      0.751      -1.955       1.411
C(topic_grouped)[T.Sports]                    -0.1263      0.994     -0.127      0.899      -2.074       1.821
C(answer_type_grouped)[T.Number]              -0.7074      0.634     -1.116      0.264      -1.949       0.535
C(answer_type_grouped)[T.Other]                0.1081      0.547      0.197      0.843      -0.964       1.181
C(answer_type_grouped)[T.Person]              -0.0358      0.597     -0.060      0.952      -1.206       1.135
q_length                                       0.4126      0.642      0.643      0.520      -0.845       1.670
game_entropy                                   2.8800      0.502      5.741      0.000       1.897       3.863
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  300
Model:                          Logit   Df Residuals:                      286
Method:                           MLE   Df Model:                           13
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.3145
Time:                        09:26:53   Log-Likelihood:                -78.151
converged:                       True   LL-Null:                       -114.00
Covariance Type:            nonrobust   LLR p-value:                 3.903e-10
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -7.9905      3.163     -2.526      0.012     -14.190      -1.791
C(topic_grouped)[T.Geography]                  0.6453      0.883      0.731      0.465      -1.085       2.376
C(topic_grouped)[T.Misc]                       0.0813      0.783      0.104      0.917      -1.453       1.615
C(topic_grouped)[T.Music]                      0.0648      0.902      0.072      0.943      -1.703       1.833
C(topic_grouped)[T.Other]                      0.0596      0.847      0.070      0.944      -1.601       1.720
C(topic_grouped)[T.Politics]                   0.5120      0.804      0.637      0.524      -1.064       2.088
C(topic_grouped)[T.Science and technology]    -0.3619      0.869     -0.416      0.677      -2.066       1.342
C(topic_grouped)[T.Sports]                    -0.1329      1.044     -0.127      0.899      -2.180       1.914
C(answer_type_grouped)[T.Number]              -0.9779      0.666     -1.468      0.142      -2.284       0.328
C(answer_type_grouped)[T.Other]               -0.1184      0.567     -0.209      0.835      -1.230       0.993
C(answer_type_grouped)[T.Person]              -0.2779      0.615     -0.452      0.651      -1.483       0.927
q_length                                       0.5307      0.647      0.820      0.412      -0.738       1.799
capabilities_entropy                           1.7216      0.585      2.941      0.003       0.574       2.869
game_entropy                                   1.6457      0.623      2.640      0.008       0.424       2.868
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing claude-3-5-sonnet-20241022 (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_neutral/claude-3-5-sonnet-20241022_SimpleMC_redacted_temp0.0_1754435021_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    131
1     69
Name: count, dtype: int64

Answer change%: 0.3450 [0.2791185285149779, 0.410881471485022] (n=200)
P-value vs 25%: 0.00471; P-value vs 0%: 1.027e-24
Phase 2 self-accuracy: 0.5507 [0.4333573413948548, 0.668091933967464] (n=69)
P-value vs 25%: 5.116e-07; P-value vs 33%: 0.000277

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  200
Model:                          Logit   Df Residuals:                      198
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1187
Time:                        09:26:53   Log-Likelihood:                -113.56
converged:                       True   LL-Null:                       -128.86
Covariance Type:            nonrobust   LLR p-value:                 3.176e-08
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          1.9998      0.530      3.772      0.000       0.961       3.039
p_i_capability    -4.5730      0.922     -4.958      0.000      -6.381      -2.765
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  200
Model:                          Logit   Df Residuals:                      198
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1033
Time:                        09:26:53   Log-Likelihood:                -115.54
converged:                       True   LL-Null:                       -128.86
Covariance Type:            nonrobust   LLR p-value:                 2.461e-07
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -3.0700      0.582     -5.278      0.000      -4.210      -1.930
capabilities_entropy     1.7342      0.379      4.580      0.000       0.992       2.476
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.6522 [0.5398, 0.7646] (n=69)
                  P-value vs 33.3%: 2.686e-08

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=0.10, p=0.921
Wilcoxon delta_p: statistic=3612.00, p=0.722
Mean Δp = 0.0014  [-0.0268, 0.0296]
Idea 1 N = 131; 

  Idea 1.5: Calibration Metrics
  NLL: 2.2591, Signed ECE (overconf pos under neg): 0.1590, ECE: 0.1590 (n=200)
  Brier: 0.0387, Reliability (absolute calibration error; lower better): 0.0380, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=200)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.614
Model:                            OLS   Adj. R-squared:                  0.608
Method:                 Least Squares   F-statistic:                     104.1
Date:                Sat, 20 Sep 2025   Prob (F-statistic):           2.46e-40
Time:                        09:26:53   Log-Likelihood:                 118.69
No. Observations:                 200   AIC:                            -229.4
Df Residuals:                     196   BIC:                            -216.2
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.2613      0.041     -6.437      0.000      -0.341      -0.181
p1                    0.3962      0.059      6.764      0.000       0.281       0.512
answer_changed        0.0600      0.067      0.896      0.372      -0.072       0.192
p1:answer_changed     0.5424      0.117      4.654      0.000       0.313       0.772
==============================================================================
Omnibus:                        0.357   Durbin-Watson:                   2.222
Prob(Omnibus):                  0.837   Jarque-Bera (JB):                0.507
Skew:                           0.040   Prob(JB):                        0.776
Kurtosis:                       2.767   Cond. No.                         18.2
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=2.25, p=0.0265
Wilcoxon delta_H: statistic=3176.00, p=0.0813
Mean ΔH = 0.0742  [0.0094, 0.1390]
Paired t-test delta_H Changed: statistic=8.07, p=1.63e-11
Wilcoxon delta_H Changed: statistic=109.00, p=5.1e-11
Mean ΔH Changed = 0.3663  [0.2773, 0.4552]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=3.28, p=0.00123
Wilcoxon (p_top2_game vs p_top2_base): statistic=7087.00, p=0.00343
Mean Δp_top2 = 0.0236  [0.0095, 0.0378] (n=200)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=6.16, p=3.98e-09
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=4956.00, p=1.44e-08
Mean ΔH_unchosen_baseline_set = 0.1750  [0.1193, 0.2306] (n=200)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  200
Model:                          Logit   Df Residuals:                      197
Method:                           MLE   Df Model:                            2
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1188
Time:                        09:26:53   Log-Likelihood:                -113.55
converged:                       True   LL-Null:                       -128.86
Covariance Type:            nonrobust   LLR p-value:                 2.249e-07
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.7586      0.236     -3.219      0.001      -1.220      -0.297
p1_z            -0.9299      0.189     -4.930      0.000      -1.300      -0.560
I(p1_z ** 2)    -0.0270      0.199     -0.135      0.892      -0.418       0.364
================================================================================
AUC = 0.730

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  200
Model:                          Logit   Df Residuals:                      198
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.03538
Time:                        09:26:53   Log-Likelihood:                -124.30
converged:                       True   LL-Null:                       -128.86
Covariance Type:            nonrobust   LLR p-value:                  0.002530
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.8963      0.472     -4.016      0.000      -2.822      -0.971
game_entropy     0.9680      0.334      2.894      0.004       0.312       1.624
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=7553.00, p=0.02
Paired t-test (game_entropy vs capabilities_entropy): statistic=-2.35, p=0.0196
Mean capabilities_entropy-game_entropy = 0.0645  [0.0108, 0.1183] (n=200)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  200
Model:                          Logit   Df Residuals:                      197
Method:                           MLE   Df Model:                            2
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1049
Time:                        09:26:53   Log-Likelihood:                -115.34
converged:                       True   LL-Null:                       -128.86
Covariance Type:            nonrobust   LLR p-value:                 1.339e-06
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.9559      0.604     -4.896      0.000      -4.139      -1.773
capabilities_entropy     1.9263      0.485      3.970      0.000       0.975       2.877
game_entropy            -0.2927      0.456     -0.642      0.521      -1.186       0.600
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'Video games', 'History']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.500000
                        1                 0.500000
Geography               0                 0.619048
                        1                 0.380952
Misc                    0                 0.840000
                        1                 0.160000
Music                   0                 0.812500
                        1                 0.187500
Other                   0                 0.650000
                        1                 0.350000
Politics                0                 0.666667
                        1                 0.333333
Science and technology  0                 0.630435
                        1                 0.369565
Sports                  0                 0.588235
                        1                 0.411765
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.550725
                     1                 0.449275
Number               0                 0.813953
                     1                 0.186047
Other                0                 0.711111
                     1                 0.288889
Person               0                 0.604651
                     1                 0.395349
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.363636  0.636364           11
                       Number               0.666667  0.333333            3
                       Other                0.833333  0.166667            6
                       Person               0.375000  0.625000            8
Geography              Date                 0.500000  0.500000            8
                       Number               0.777778  0.222222            9
                       Other                0.500000  0.500000            4
Misc                   Date                 0.857143  0.142857            7
                       Number               1.000000  0.000000            3
                       Other                0.800000  0.200000           10
                       Person               0.800000  0.200000            5
Music                  Date                 0.600000  0.400000            5
                       Number               1.000000  0.000000            4
                       Other                0.800000  0.200000            5
                       Person               1.000000  0.000000            2
Other                  Date                 0.571429  0.428571            7
                       Number               1.000000  0.000000            5
                       Other                0.500000  0.500000            4
                       Person               0.500000  0.500000            4
Politics               Date                 0.428571  0.571429           14
                       Number               1.000000  0.000000            3
                       Other                1.000000  0.000000            4
                       Person               0.833333  0.166667            6
Science and technology Date                 0.666667  0.333333           15
                       Number               0.555556  0.444444            9
                       Other                0.833333  0.166667            6
                       Person               0.562500  0.437500           16
Sports                 Date                 0.500000  0.500000            2
                       Number               0.857143  0.142857            7
                       Other                0.333333  0.666667            6
                       Person               0.500000  0.500000            2

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  200
Model:                          Logit   Df Residuals:                      188
Method:                           MLE   Df Model:                           11
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.07904
Time:                        09:26:53   Log-Likelihood:                -118.67
converged:                       True   LL-Null:                       -128.86
Covariance Type:            nonrobust   LLR p-value:                   0.04052
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -0.5005      1.962     -0.255      0.799      -4.347       3.346
C(topic_grouped)[T.Geography]                 -0.1351      0.629     -0.215      0.830      -1.367       1.097
C(topic_grouped)[T.Misc]                      -1.5966      0.676     -2.361      0.018      -2.922      -0.271
C(topic_grouped)[T.Music]                     -1.3022      0.763     -1.708      0.088      -2.797       0.193
C(topic_grouped)[T.Other]                     -0.4732      0.623     -0.759      0.448      -1.695       0.749
C(topic_grouped)[T.Politics]                  -0.8039      0.575     -1.399      0.162      -1.930       0.322
C(topic_grouped)[T.Science and technology]    -0.4838      0.501     -0.965      0.334      -1.466       0.499
C(topic_grouped)[T.Sports]                     0.1106      0.662      0.167      0.867      -1.187       1.408
C(answer_type_grouped)[T.Number]              -1.4687      0.492     -2.984      0.003      -2.433      -0.504
C(answer_type_grouped)[T.Other]               -0.6629      0.436     -1.522      0.128      -1.517       0.191
C(answer_type_grouped)[T.Person]              -0.2159      0.419     -0.516      0.606      -1.036       0.605
q_length                                       0.1890      0.420      0.450      0.653      -0.634       1.012
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 1.3228
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  200
Model:                          Logit   Df Residuals:                      187
Method:                           MLE   Df Model:                           12
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1693
Time:                        09:26:53   Log-Likelihood:                -107.04
converged:                       True   LL-Null:                       -128.86
Covariance Type:            nonrobust   LLR p-value:                 1.759e-05
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -2.2884      2.169     -1.055      0.292      -6.540       1.964
C(topic_grouped)[T.Geography]                 -0.3370      0.662     -0.509      0.611      -1.634       0.960
C(topic_grouped)[T.Misc]                      -1.5887      0.716     -2.218      0.027      -2.992      -0.185
C(topic_grouped)[T.Music]                     -1.1865      0.804     -1.477      0.140      -2.761       0.388
C(topic_grouped)[T.Other]                     -0.5332      0.681     -0.783      0.434      -1.868       0.801
C(topic_grouped)[T.Politics]                  -0.5239      0.630     -0.831      0.406      -1.759       0.711
C(topic_grouped)[T.Science and technology]    -0.5728      0.539     -1.062      0.288      -1.630       0.484
C(topic_grouped)[T.Sports]                    -0.0094      0.718     -0.013      0.990      -1.416       1.397
C(answer_type_grouped)[T.Number]              -1.1989      0.509     -2.356      0.018      -2.196      -0.201
C(answer_type_grouped)[T.Other]               -0.4084      0.465     -0.878      0.380      -1.320       0.503
C(answer_type_grouped)[T.Person]               0.3201      0.475      0.674      0.501      -0.611       1.251
q_length                                       0.0055      0.455      0.012      0.990      -0.886       0.897
capabilities_entropy                           1.7309      0.394      4.391      0.000       0.958       2.503
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  200
Model:                          Logit   Df Residuals:                      187
Method:                           MLE   Df Model:                           12
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1195
Time:                        09:26:53   Log-Likelihood:                -113.46
converged:                       True   LL-Null:                       -128.86
Covariance Type:            nonrobust   LLR p-value:                  0.002111
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -2.2073      2.110     -1.046      0.295      -6.343       1.928
C(topic_grouped)[T.Geography]                 -0.1222      0.649     -0.188      0.851      -1.394       1.149
C(topic_grouped)[T.Misc]                      -1.6507      0.694     -2.379      0.017      -3.011      -0.291
C(topic_grouped)[T.Music]                     -1.3551      0.778     -1.742      0.082      -2.880       0.170
C(topic_grouped)[T.Other]                     -0.5197      0.647     -0.803      0.422      -1.789       0.749
C(topic_grouped)[T.Politics]                  -0.6307      0.597     -1.056      0.291      -1.801       0.540
C(topic_grouped)[T.Science and technology]    -0.4703      0.517     -0.911      0.363      -1.483       0.542
C(topic_grouped)[T.Sports]                     0.1826      0.686      0.266      0.790      -1.162       1.527
C(answer_type_grouped)[T.Number]              -1.4429      0.502     -2.875      0.004      -2.427      -0.459
C(answer_type_grouped)[T.Other]               -0.5327      0.451     -1.180      0.238      -1.417       0.352
C(answer_type_grouped)[T.Person]               0.1145      0.449      0.255      0.799      -0.765       0.994
q_length                                       0.2216      0.434      0.511      0.610      -0.629       1.072
game_entropy                                   1.1084      0.359      3.090      0.002       0.405       1.811
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  200
Model:                          Logit   Df Residuals:                      186
Method:                           MLE   Df Model:                           13
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1693
Time:                        09:26:53   Log-Likelihood:                -107.04
converged:                       True   LL-Null:                       -128.86
Covariance Type:            nonrobust   LLR p-value:                 3.521e-05
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -2.2810      2.213     -1.031      0.303      -6.618       2.056
C(topic_grouped)[T.Geography]                 -0.3380      0.664     -0.509      0.611      -1.640       0.964
C(topic_grouped)[T.Misc]                      -1.5882      0.717     -2.216      0.027      -2.993      -0.184
C(topic_grouped)[T.Music]                     -1.1859      0.804     -1.474      0.140      -2.763       0.391
C(topic_grouped)[T.Other]                     -0.5330      0.681     -0.783      0.434      -1.868       0.802
C(topic_grouped)[T.Politics]                  -0.5243      0.631     -0.831      0.406      -1.761       0.712
C(topic_grouped)[T.Science and technology]    -0.5733      0.540     -1.061      0.289      -1.632       0.485
C(topic_grouped)[T.Sports]                    -0.0104      0.720     -0.014      0.989      -1.421       1.400
C(answer_type_grouped)[T.Number]              -1.1982      0.511     -2.346      0.019      -2.199      -0.197
C(answer_type_grouped)[T.Other]               -0.4085      0.465     -0.878      0.380      -1.320       0.503
C(answer_type_grouped)[T.Person]               0.3194      0.477      0.670      0.503      -0.615       1.254
q_length                                       0.0046      0.458      0.010      0.992      -0.893       0.902
capabilities_entropy                           1.7363      0.507      3.427      0.001       0.743       2.729
game_entropy                                  -0.0082      0.480     -0.017      0.986      -0.950       0.933
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing claude-3-haiku-20240307 (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_neutral/claude-3-haiku-20240307_SimpleMC_redacted_cor_temp0.0_1754426360_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    124
1     27
Name: count, dtype: int64

Answer change%: 0.1788 [0.11768906596126844, 0.23992682807846666] (n=151)
P-value vs 25%: 0.02243; P-value vs 0%: 9.808e-09
Phase 2 self-accuracy: 0.1481 [0.014150752226827906, 0.28214554406946835] (n=27)
P-value vs 25%: 0.1363; P-value vs 33%: 0.006855

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  151
Model:                          Logit   Df Residuals:                      149
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1165
Time:                        09:26:53   Log-Likelihood:                -62.643
converged:                       True   LL-Null:                       -70.907
Covariance Type:            nonrobust   LLR p-value:                 4.795e-05
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          3.5527      1.277      2.781      0.005       1.049       6.056
p_i_capability    -5.7869      1.457     -3.971      0.000      -8.643      -2.930
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  151
Model:                          Logit   Df Residuals:                      149
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1390
Time:                        09:26:53   Log-Likelihood:                -61.048
converged:                       True   LL-Null:                       -70.907
Covariance Type:            nonrobust   LLR p-value:                 8.980e-06
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -3.0787      0.458     -6.716      0.000      -3.977      -2.180
capabilities_entropy     3.1237      0.744      4.201      0.000       1.666       4.581
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.5556 [0.3681, 0.7430] (n=27)
                  P-value vs 33.3%: 0.02014

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=0.15, p=0.878
Wilcoxon delta_p: statistic=572.00, p=0.87
Mean Δp = 0.0014  [-0.0161, 0.0189]
Idea 1 N = 124; 

  Idea 1.5: Calibration Metrics
  NLL: 0.1291, Signed ECE (overconf pos under neg): -0.1033, ECE: 0.1033 (n=151)
  Brier: 0.0321, Reliability (absolute calibration error; lower better): 0.0319, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=151)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.869
Model:                            OLS   Adj. R-squared:                  0.867
Method:                 Least Squares   F-statistic:                     326.1
Date:                Sat, 20 Sep 2025   Prob (F-statistic):           9.78e-65
Time:                        09:26:53   Log-Likelihood:                 134.56
No. Observations:                 151   AIC:                            -261.1
Df Residuals:                     147   BIC:                            -249.0
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.5437      0.090     -6.071      0.000      -0.721      -0.367
p1                    0.5894      0.096      6.118      0.000       0.399       0.780
answer_changed        0.5158      0.122      4.232      0.000       0.275       0.757
p1:answer_changed     0.2352      0.139      1.691      0.093      -0.040       0.510
==============================================================================
Omnibus:                       26.219   Durbin-Watson:                   2.003
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               53.663
Skew:                           0.765   Prob(JB):                     2.22e-12
Kurtosis:                       5.488   Cond. No.                         35.4
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-0.47, p=0.638
Wilcoxon delta_H: statistic=517.50, p=0.469
Mean ΔH = -0.0230  [-0.1187, 0.0727]
Paired t-test delta_H Changed: statistic=5.29, p=1.56e-05
Wilcoxon delta_H Changed: statistic=35.00, p=0.000215
Mean ΔH Changed = 0.7751  [0.4880, 1.0622]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=-0.29, p=0.773
Wilcoxon (p_top2_game vs p_top2_base): statistic=1274.50, p=0.825
Mean Δp_top2 = -0.0008  [-0.0065, 0.0048] (n=151)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=2.23, p=0.0276
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=1034.00, p=0.0389
Mean ΔH_unchosen_baseline_set = 0.1197  [0.0143, 0.2251] (n=151)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  151
Model:                          Logit   Df Residuals:                      148
Method:                           MLE   Df Model:                            2
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1166
Time:                        09:26:53   Log-Likelihood:                -62.639
converged:                       True   LL-Null:                       -70.907
Covariance Type:            nonrobust   LLR p-value:                 0.0002567
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.6558      0.295     -5.607      0.000      -2.235      -1.077
p1_z            -0.7767      0.515     -1.507      0.132      -1.787       0.234
I(p1_z ** 2)    -0.0176      0.202     -0.087      0.930      -0.413       0.378
================================================================================
AUC = 0.674

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  151
Model:                          Logit   Df Residuals:                      149
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1458
Time:                        09:26:53   Log-Likelihood:                -60.566
converged:                       True   LL-Null:                       -70.907
Covariance Type:            nonrobust   LLR p-value:                 5.423e-06
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -3.0964      0.458     -6.764      0.000      -3.994      -2.199
game_entropy     2.9748      0.689      4.314      0.000       1.623       4.326
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=1140.50, p=0.33
Paired t-test (game_entropy vs capabilities_entropy): statistic=0.89, p=0.375
Mean capabilities_entropy-game_entropy = -0.0217  [-0.0695, 0.0261] (n=151)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  151
Model:                          Logit   Df Residuals:                      148
Method:                           MLE   Df Model:                            2
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.2058
Time:                        09:26:53   Log-Likelihood:                -56.315
converged:                       True   LL-Null:                       -70.907
Covariance Type:            nonrobust   LLR p-value:                 4.604e-07
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -3.9018      0.588     -6.640      0.000      -5.054      -2.750
capabilities_entropy     2.3286      0.796      2.926      0.003       0.769       3.889
game_entropy             2.3445      0.774      3.029      0.002       0.827       3.862
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['Video games', 'Sports', 'History', 'TV shows']
                  Grouped rare answer_type into 'Misc'/'Other': None
topic_grouped           answer_changed
Art                     0                 0.840000
                        1                 0.160000
Geography               0                 0.857143
                        1                 0.142857
Misc                    0                 0.851852
                        1                 0.148148
Music                   0                 1.000000
Other                   0                 0.714286
                        1                 0.285714
Politics                0                 0.739130
                        1                 0.260870
Science and technology  0                 0.833333
                        1                 0.166667
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.730769
                     1                 0.269231
Number               0                 0.866667
                     1                 0.133333
Other                0                 0.846154
                     1                 0.153846
Person               0                 0.870968
                     1                 0.129032
Place                0                 0.928571
                     1                 0.071429
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.666667  0.333333            6
                       Number               1.000000  0.000000            1
                       Other                0.800000  0.200000            5
                       Person               0.909091  0.090909           11
                       Place                1.000000  0.000000            2
Geography              Date                 1.000000  0.000000            2
                       Number               0.833333  0.166667            6
                       Other                1.000000  0.000000            3
                       Place                0.666667  0.333333            3
Misc                   Date                 0.777778  0.222222            9
                       Number               1.000000  0.000000            3
                       Other                0.750000  0.250000            8
                       Person               1.000000  0.000000            5
                       Place                1.000000  0.000000            2
Music                  Date                 1.000000  0.000000            5
                       Other                1.000000  0.000000            3
                       Person               1.000000  0.000000            3
Other                  Date                 0.800000  0.200000           10
                       Number               1.000000  0.000000            1
                       Other                0.500000  0.500000            4
                       Person               0.500000  0.500000            4
                       Place                1.000000  0.000000            2
Politics               Date                 0.500000  0.500000            8
                       Number               0.000000  1.000000            1
                       Other                1.000000  0.000000            6
                       Person               0.750000  0.250000            4
                       Place                1.000000  0.000000            4
Science and technology Date                 0.666667  0.333333           12
                       Number               1.000000  0.000000            3
                       Other                0.900000  0.100000           10
                       Person               1.000000  0.000000            4
                       Place                1.000000  0.000000            1

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  151
Model:                          Logit   Df Residuals:                      139
Method:                           MLE   Df Model:                           11
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1020
Time:                        09:26:53   Log-Likelihood:                -63.677
converged:                      False   LL-Null:                       -70.907
Covariance Type:            nonrobust   LLR p-value:                    0.2086
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      2.9720      2.894      1.027      0.304      -2.700       8.644
C(topic_grouped)[T.Geography]                 -0.0315      1.038     -0.030      0.976      -2.066       2.003
C(topic_grouped)[T.Misc]                      -0.1640      0.795     -0.206      0.837      -1.723       1.395
C(topic_grouped)[T.Music]                    -23.7330   8.83e+04     -0.000      1.000   -1.73e+05    1.73e+05
C(topic_grouped)[T.Other]                      0.5413      0.763      0.710      0.478      -0.954       2.036
C(topic_grouped)[T.Politics]                   0.8263      0.773      1.069      0.285      -0.688       2.341
C(topic_grouped)[T.Science and technology]     0.0315      0.779      0.040      0.968      -1.496       1.559
C(answer_type_grouped)[T.Number]              -0.6179      0.917     -0.674      0.500      -2.414       1.179
C(answer_type_grouped)[T.Other]               -0.8335      0.571     -1.459      0.145      -1.953       0.286
C(answer_type_grouped)[T.Person]              -0.9065      0.656     -1.381      0.167      -2.193       0.380
C(answer_type_grouped)[T.Place]               -1.6378      1.106     -1.480      0.139      -3.806       0.531
q_length                                      -0.9044      0.642     -1.410      0.159      -2.162       0.353
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.4401
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  151
Model:                          Logit   Df Residuals:                      138
Method:                           MLE   Df Model:                           12
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.2578
Time:                        09:26:53   Log-Likelihood:                -52.627
converged:                      False   LL-Null:                       -70.907
Covariance Type:            nonrobust   LLR p-value:                 0.0002633
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.3627      3.469     -0.393      0.694      -8.162       5.437
C(topic_grouped)[T.Geography]                 -0.5492      1.307     -0.420      0.674      -3.111       2.012
C(topic_grouped)[T.Misc]                      -0.3643      0.923     -0.395      0.693      -2.174       1.445
C(topic_grouped)[T.Music]                    -21.0662   1.23e+04     -0.002      0.999   -2.42e+04    2.42e+04
C(topic_grouped)[T.Other]                      0.3339      0.858      0.389      0.697      -1.348       2.016
C(topic_grouped)[T.Politics]                   0.6934      0.876      0.792      0.428      -1.023       2.410
C(topic_grouped)[T.Science and technology]    -0.2833      0.893     -0.317      0.751      -2.034       1.467
C(answer_type_grouped)[T.Number]              -1.5232      1.245     -1.223      0.221      -3.964       0.918
C(answer_type_grouped)[T.Other]               -0.6115      0.639     -0.957      0.338      -1.864       0.641
C(answer_type_grouped)[T.Person]              -0.8466      0.716     -1.182      0.237      -2.251       0.558
C(answer_type_grouped)[T.Place]               -2.4705      1.240     -1.993      0.046      -4.900      -0.041
q_length                                      -0.3238      0.744     -0.435      0.663      -1.782       1.134
capabilities_entropy                           4.0773      1.023      3.987      0.000       2.073       6.082
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  151
Model:                          Logit   Df Residuals:                      138
Method:                           MLE   Df Model:                           12
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.2496
Time:                        09:26:53   Log-Likelihood:                -53.206
converged:                      False   LL-Null:                       -70.907
Covariance Type:            nonrobust   LLR p-value:                 0.0004042
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -0.0286      3.222     -0.009      0.993      -6.343       6.286
C(topic_grouped)[T.Geography]                 -0.7856      1.289     -0.609      0.542      -3.312       1.741
C(topic_grouped)[T.Misc]                      -0.5829      0.892     -0.654      0.513      -2.331       1.165
C(topic_grouped)[T.Music]                    -18.3050   2651.326     -0.007      0.994   -5214.808    5178.198
C(topic_grouped)[T.Other]                     -0.0866      0.834     -0.104      0.917      -1.722       1.548
C(topic_grouped)[T.Politics]                   0.6287      0.833      0.755      0.451      -1.005       2.262
C(topic_grouped)[T.Science and technology]    -0.5222      0.862     -0.606      0.544      -2.211       1.166
C(answer_type_grouped)[T.Number]              -0.7824      1.170     -0.669      0.504      -3.076       1.511
C(answer_type_grouped)[T.Other]               -0.6455      0.639     -1.010      0.313      -1.898       0.608
C(answer_type_grouped)[T.Person]              -0.7995      0.713     -1.122      0.262      -2.196       0.597
C(answer_type_grouped)[T.Place]               -1.6741      1.205     -1.389      0.165      -4.036       0.688
q_length                                      -0.5624      0.703     -0.800      0.424      -1.941       0.816
game_entropy                                   3.4527      0.812      4.251      0.000       1.861       5.045
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  151
Model:                          Logit   Df Residuals:                      137
Method:                           MLE   Df Model:                           13
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.3349
Time:                        09:26:53   Log-Likelihood:                -47.159
converged:                      False   LL-Null:                       -70.907
Covariance Type:            nonrobust   LLR p-value:                 7.967e-06
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -2.8929      3.632     -0.796      0.426     -10.012       4.226
C(topic_grouped)[T.Geography]                 -1.0376      1.577     -0.658      0.511      -4.129       2.054
C(topic_grouped)[T.Misc]                      -0.5456      0.979     -0.557      0.578      -2.465       1.374
C(topic_grouped)[T.Music]                    -34.2216   5.72e+06  -5.98e-06      1.000   -1.12e+07    1.12e+07
C(topic_grouped)[T.Other]                     -0.0279      0.887     -0.032      0.975      -1.766       1.710
C(topic_grouped)[T.Politics]                   0.7056      0.923      0.764      0.445      -1.104       2.515
C(topic_grouped)[T.Science and technology]    -0.5079      0.921     -0.552      0.581      -2.313       1.297
C(answer_type_grouped)[T.Number]              -1.6992      1.532     -1.109      0.267      -4.702       1.304
C(answer_type_grouped)[T.Other]               -0.5018      0.685     -0.733      0.464      -1.844       0.841
C(answer_type_grouped)[T.Person]              -0.7951      0.739     -1.076      0.282      -2.244       0.653
C(answer_type_grouped)[T.Place]               -2.7209      1.421     -1.915      0.055      -5.505       0.063
q_length                                      -0.2151      0.773     -0.278      0.781      -1.730       1.299
capabilities_entropy                           3.4250      1.119      3.061      0.002       1.232       5.618
game_entropy                                   2.8916      0.903      3.200      0.001       1.121       4.662
==============================================================================================================

                  Model 6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length (after removing deterministic categories: defaultdict(<class 'list'>, {'topic_grouped': ['Music']}))
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  140
Model:                          Logit   Df Residuals:                      129
Method:                           MLE   Df Model:                           10
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.07241
Time:                        09:26:53   Log-Likelihood:                -63.677
converged:                       True   LL-Null:                       -68.648
Covariance Type:            nonrobust   LLR p-value:                    0.4456
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      2.9720      2.894      1.027      0.304      -2.700       8.644
C(topic_grouped)[T.Geography]                 -0.0315      1.038     -0.030      0.976      -2.066       2.003
C(topic_grouped)[T.Misc]                      -0.1640      0.795     -0.206      0.837      -1.723       1.395
C(topic_grouped)[T.Other]                      0.5413      0.763      0.710      0.478      -0.954       2.036
C(topic_grouped)[T.Politics]                   0.8263      0.773      1.069      0.285      -0.688       2.341
C(topic_grouped)[T.Science and technology]     0.0315      0.779      0.040      0.968      -1.496       1.559
C(answer_type_grouped)[T.Number]              -0.6179      0.917     -0.674      0.500      -2.414       1.179
C(answer_type_grouped)[T.Other]               -0.8335      0.571     -1.459      0.145      -1.953       0.286
C(answer_type_grouped)[T.Person]              -0.9065      0.656     -1.381      0.167      -2.193       0.380
C(answer_type_grouped)[T.Place]               -1.6378      1.106     -1.480      0.139      -3.806       0.531
q_length                                      -0.9044      0.642     -1.410      0.159      -2.162       0.353
==============================================================================================================

                  Model 6.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  140
Model:                          Logit   Df Residuals:                      128
Method:                           MLE   Df Model:                           11
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.2334
Time:                        09:26:53   Log-Likelihood:                -52.627
converged:                       True   LL-Null:                       -68.648
Covariance Type:            nonrobust   LLR p-value:                 0.0007514
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.3627      3.469     -0.393      0.694      -8.162       5.437
C(topic_grouped)[T.Geography]                 -0.5492      1.307     -0.420      0.674      -3.111       2.012
C(topic_grouped)[T.Misc]                      -0.3643      0.923     -0.395      0.693      -2.174       1.445
C(topic_grouped)[T.Other]                      0.3339      0.858      0.389      0.697      -1.348       2.016
C(topic_grouped)[T.Politics]                   0.6934      0.876      0.792      0.428      -1.023       2.410
C(topic_grouped)[T.Science and technology]    -0.2833      0.893     -0.317      0.751      -2.034       1.467
C(answer_type_grouped)[T.Number]              -1.5232      1.245     -1.223      0.221      -3.964       0.918
C(answer_type_grouped)[T.Other]               -0.6115      0.639     -0.957      0.338      -1.864       0.641
C(answer_type_grouped)[T.Person]              -0.8466      0.716     -1.182      0.237      -2.251       0.558
C(answer_type_grouped)[T.Place]               -2.4705      1.240     -1.993      0.046      -4.900      -0.041
q_length                                      -0.3238      0.744     -0.435      0.663      -1.782       1.134
capabilities_entropy                           4.0773      1.023      3.987      0.000       2.073       6.082
==============================================================================================================

--- Analyzing claude-3-haiku-20240307 (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_neutral/claude-3-haiku-20240307_SimpleMC_redacted_temp0.0_1754368901_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    268
1     81
Name: count, dtype: int64

Answer change%: 0.2321 [0.18780024475464002, 0.2763831363341852] (n=349)
P-value vs 25%: 0.4281; P-value vs 0%: 9.58e-25
Phase 2 self-accuracy: 0.4815 [0.3726693014451997, 0.5902936615177632] (n=81)
P-value vs 25%: 3.052e-05; P-value vs 33%: 0.007484

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  349
Model:                          Logit   Df Residuals:                      347
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.07032
Time:                        09:26:53   Log-Likelihood:                -175.79
converged:                       True   LL-Null:                       -189.09
Covariance Type:            nonrobust   LLR p-value:                 2.513e-07
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          2.9155      0.809      3.603      0.000       1.329       4.502
p_i_capability    -4.6346      0.908     -5.102      0.000      -6.415      -2.854
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  349
Model:                          Logit   Df Residuals:                      347
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.07144
Time:                        09:26:53   Log-Likelihood:                -175.58
converged:                       True   LL-Null:                       -189.09
Covariance Type:            nonrobust   LLR p-value:                 2.016e-07
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.2038      0.244     -9.019      0.000      -2.683      -1.725
capabilities_entropy     2.1052      0.411      5.117      0.000       1.299       2.912
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.5062 [0.3973, 0.6151] (n=81)
                  P-value vs 33.3%: 0.001862

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=2.81, p=0.0054
Wilcoxon delta_p: statistic=2885.00, p=0.00211
Mean Δp = 0.0227  [0.0068, 0.0386]
Idea 1 N = 268; 

  Idea 1.5: Calibration Metrics
  NLL: 4.1953, Signed ECE (overconf pos under neg): 0.0394, ECE: 0.0394 (n=349)
  Brier: 0.0097, Reliability (absolute calibration error; lower better): 0.0095, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=349)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.869
Model:                            OLS   Adj. R-squared:                  0.867
Method:                 Least Squares   F-statistic:                     760.4
Date:                Sat, 20 Sep 2025   Prob (F-statistic):          1.20e-151
Time:                        09:26:53   Log-Likelihood:                 253.87
No. Observations:                 349   AIC:                            -499.7
Df Residuals:                     345   BIC:                            -484.3
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.6231      0.069     -8.980      0.000      -0.760      -0.487
p1                    0.6993      0.075      9.358      0.000       0.552       0.846
answer_changed        0.5712      0.093      6.150      0.000       0.389       0.754
p1:answer_changed     0.1976      0.104      1.900      0.058      -0.007       0.402
==============================================================================
Omnibus:                       99.452   Durbin-Watson:                   2.114
Prob(Omnibus):                  0.000   Jarque-Bera (JB):              250.869
Skew:                           1.370   Prob(JB):                     3.35e-55
Kurtosis:                       6.121   Cond. No.                         35.6
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=1.73, p=0.085
Wilcoxon delta_H: statistic=3483.00, p=0.0953
Mean ΔH = 0.0618  [-0.0083, 0.1319]
Paired t-test delta_H Changed: statistic=8.21, p=3.09e-12
Wilcoxon delta_H Changed: statistic=393.00, p=2.39e-09
Mean ΔH Changed = 0.6737  [0.5129, 0.8344]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=-4.52, p=8.34e-06
Wilcoxon (p_top2_game vs p_top2_base): statistic=7335.50, p=0.000651
Mean Δp_top2 = -0.0137  [-0.0196, -0.0077] (n=349)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=5.64, p=3.43e-08
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=6375.50, p=9.63e-08
Mean ΔH_unchosen_baseline_set = 0.2038  [0.1330, 0.2746] (n=349)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  349
Model:                          Logit   Df Residuals:                      346
Method:                           MLE   Df Model:                            2
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.07308
Time:                        09:26:53   Log-Likelihood:                -175.27
converged:                       True   LL-Null:                       -189.09
Covariance Type:            nonrobust   LLR p-value:                 9.973e-07
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.4122      0.198     -7.130      0.000      -1.800      -1.024
p1_z            -0.2495      0.357     -0.699      0.484      -0.949       0.450
I(p1_z ** 2)     0.1522      0.153      0.995      0.320      -0.148       0.452
================================================================================
AUC = 0.644

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  349
Model:                          Logit   Df Residuals:                      347
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1260
Time:                        09:26:53   Log-Likelihood:                -165.26
converged:                       True   LL-Null:                       -189.09
Covariance Type:            nonrobust   LLR p-value:                 5.109e-12
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -2.5147      0.255     -9.845      0.000      -3.015      -2.014
game_entropy     2.1041      0.323      6.521      0.000       1.472       2.737
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=5887.50, p=2.42e-07
Paired t-test (game_entropy vs capabilities_entropy): statistic=5.18, p=3.7e-07
Mean capabilities_entropy-game_entropy = -0.1161  [-0.1600, -0.0722] (n=349)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  349
Model:                          Logit   Df Residuals:                      346
Method:                           MLE   Df Model:                            2
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1616
Time:                        09:26:53   Log-Likelihood:                -158.52
converged:                       True   LL-Null:                       -189.09
Covariance Type:            nonrobust   LLR p-value:                 5.332e-14
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -3.1663      0.331     -9.556      0.000      -3.816      -2.517
capabilities_entropy     1.6661      0.453      3.681      0.000       0.779       2.553
game_entropy             1.8879      0.335      5.643      0.000       1.232       2.544
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.740000
                        1                 0.260000
Geography               0                 0.800000
                        1                 0.200000
Misc                    0                 0.800000
                        1                 0.200000
Music                   0                 0.758621
                        1                 0.241379
Other                   0                 0.806452
                        1                 0.193548
Politics                0                 0.814815
                        1                 0.185185
Science and technology  0                 0.720588
                        1                 0.279412
Sports                  0                 0.750000
                        1                 0.250000
TV shows                0                 0.760000
                        1                 0.240000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.786325
                     1                 0.213675
Number               0                 0.746032
                     1                 0.253968
Other                0                 0.762500
                     1                 0.237500
Person               0                 0.764045
                     1                 0.235955
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.733333  0.266667           15
                       Number               0.750000  0.250000            8
                       Other                0.636364  0.363636           11
                       Person               0.812500  0.187500           16
Geography              Date                 0.846154  0.153846           13
                       Number               0.750000  0.250000           12
                       Other                0.800000  0.200000            5
Misc                   Date                 0.615385  0.384615           13
                       Number               1.000000  0.000000            5
                       Other                1.000000  0.000000            7
                       Person               0.800000  0.200000            5
Music                  Date                 0.571429  0.428571            7
                       Number               1.000000  0.000000            4
                       Other                0.777778  0.222222            9
                       Person               0.777778  0.222222            9
Other                  Date                 1.000000  0.000000            8
                       Number               0.833333  0.166667            6
                       Other                0.625000  0.375000            8
                       Person               0.777778  0.222222            9
Politics               Date                 0.821429  0.178571           28
                       Number               0.800000  0.200000            5
                       Other                0.900000  0.100000           10
                       Person               0.727273  0.272727           11
Science and technology Date                 0.826087  0.173913           23
                       Number               0.454545  0.545455           11
                       Other                0.750000  0.250000            8
                       Person               0.730769  0.269231           26
Sports                 Date                 1.000000  0.000000            8
                       Number               0.727273  0.272727           11
                       Other                0.555556  0.444444            9
                       Person               0.750000  0.250000            4
TV shows               Date                 0.000000  1.000000            2
                       Number               1.000000  0.000000            1
                       Other                0.846154  0.153846           13
                       Person               0.777778  0.222222            9

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  349
Model:                          Logit   Df Residuals:                      336
Method:                           MLE   Df Model:                           12
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.01483
Time:                        09:26:53   Log-Likelihood:                -186.28
converged:                       True   LL-Null:                       -189.09
Covariance Type:            nonrobust   LLR p-value:                    0.9345
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -3.7329      1.605     -2.326      0.020      -6.879      -0.587
C(topic_grouped)[T.Geography]                 -0.3320      0.575     -0.577      0.564      -1.459       0.795
C(topic_grouped)[T.Misc]                      -0.3772      0.563     -0.669      0.503      -1.481       0.727
C(topic_grouped)[T.Music]                     -0.0610      0.544     -0.112      0.911      -1.127       1.005
C(topic_grouped)[T.Other]                     -0.3763      0.559     -0.673      0.501      -1.472       0.720
C(topic_grouped)[T.Politics]                  -0.5354      0.489     -1.095      0.274      -1.494       0.423
C(topic_grouped)[T.Science and technology]     0.0799      0.424      0.188      0.851      -0.752       0.911
C(topic_grouped)[T.Sports]                    -0.1252      0.530     -0.236      0.813      -1.164       0.913
C(topic_grouped)[T.TV shows]                  -0.0588      0.582     -0.101      0.920      -1.199       1.081
C(answer_type_grouped)[T.Number]               0.2032      0.380      0.535      0.593      -0.541       0.947
C(answer_type_grouped)[T.Other]                0.1535      0.363      0.423      0.672      -0.557       0.864
C(answer_type_grouped)[T.Person]               0.1089      0.352      0.309      0.757      -0.581       0.799
q_length                                       0.5760      0.342      1.682      0.093      -0.095       1.247
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.4433
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  349
Model:                          Logit   Df Residuals:                      335
Method:                           MLE   Df Model:                           13
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.08910
Time:                        09:26:53   Log-Likelihood:                -172.24
converged:                       True   LL-Null:                       -189.09
Covariance Type:            nonrobust   LLR p-value:                  0.001339
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -5.4930      1.746     -3.146      0.002      -8.916      -2.070
C(topic_grouped)[T.Geography]                 -0.2437      0.600     -0.406      0.685      -1.421       0.933
C(topic_grouped)[T.Misc]                      -0.4428      0.592     -0.748      0.455      -1.603       0.718
C(topic_grouped)[T.Music]                     -0.1573      0.582     -0.270      0.787      -1.298       0.983
C(topic_grouped)[T.Other]                     -0.4361      0.587     -0.742      0.458      -1.587       0.715
C(topic_grouped)[T.Politics]                  -0.4660      0.508     -0.918      0.359      -1.461       0.529
C(topic_grouped)[T.Science and technology]     0.0574      0.446      0.129      0.898      -0.816       0.931
C(topic_grouped)[T.Sports]                    -0.2828      0.563     -0.503      0.615      -1.386       0.820
C(topic_grouped)[T.TV shows]                  -0.0700      0.607     -0.115      0.908      -1.260       1.120
C(answer_type_grouped)[T.Number]               0.3105      0.401      0.775      0.439      -0.475       1.096
C(answer_type_grouped)[T.Other]                0.2260      0.379      0.596      0.551      -0.517       0.969
C(answer_type_grouped)[T.Person]               0.2913      0.375      0.778      0.437      -0.443       1.026
q_length                                       0.7181      0.363      1.978      0.048       0.007       1.430
capabilities_entropy                           2.2015      0.425      5.178      0.000       1.368       3.035
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  349
Model:                          Logit   Df Residuals:                      335
Method:                           MLE   Df Model:                           13
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1465
Time:                        09:26:53   Log-Likelihood:                -161.39
converged:                       True   LL-Null:                       -189.09
Covariance Type:            nonrobust   LLR p-value:                 3.452e-07
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -5.8667      1.796     -3.267      0.001      -9.387      -2.347
C(topic_grouped)[T.Geography]                 -0.1868      0.626     -0.298      0.765      -1.415       1.041
C(topic_grouped)[T.Misc]                      -0.1322      0.613     -0.216      0.829      -1.334       1.069
C(topic_grouped)[T.Music]                      0.1613      0.607      0.266      0.790      -1.028       1.351
C(topic_grouped)[T.Other]                     -0.0813      0.600     -0.135      0.892      -1.258       1.095
C(topic_grouped)[T.Politics]                  -0.4175      0.538     -0.776      0.438      -1.471       0.636
C(topic_grouped)[T.Science and technology]     0.4270      0.469      0.909      0.363      -0.493       1.347
C(topic_grouped)[T.Sports]                    -0.1568      0.608     -0.258      0.796      -1.348       1.034
C(topic_grouped)[T.TV shows]                  -0.1697      0.654     -0.259      0.795      -1.452       1.112
C(answer_type_grouped)[T.Number]               0.2270      0.414      0.548      0.584      -0.584       1.038
C(answer_type_grouped)[T.Other]                0.4089      0.399      1.024      0.306      -0.374       1.192
C(answer_type_grouped)[T.Person]               0.0094      0.387      0.024      0.981      -0.750       0.769
q_length                                       0.6964      0.376      1.850      0.064      -0.041       1.434
game_entropy                                   2.2248      0.339      6.569      0.000       1.561       2.889
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  349
Model:                          Logit   Df Residuals:                      334
Method:                           MLE   Df Model:                           14
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1828
Time:                        09:26:53   Log-Likelihood:                -154.52
converged:                       True   LL-Null:                       -189.09
Covariance Type:            nonrobust   LLR p-value:                 2.764e-09
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -6.9830      1.880     -3.714      0.000     -10.668      -3.298
C(topic_grouped)[T.Geography]                 -0.1412      0.642     -0.220      0.826      -1.399       1.116
C(topic_grouped)[T.Misc]                      -0.2319      0.628     -0.369      0.712      -1.462       0.998
C(topic_grouped)[T.Music]                      0.0530      0.609      0.087      0.931      -1.141       1.247
C(topic_grouped)[T.Other]                     -0.1822      0.623     -0.292      0.770      -1.403       1.039
C(topic_grouped)[T.Politics]                  -0.3802      0.542     -0.702      0.483      -1.442       0.681
C(topic_grouped)[T.Science and technology]     0.3906      0.474      0.825      0.410      -0.538       1.319
C(topic_grouped)[T.Sports]                    -0.3300      0.625     -0.528      0.598      -1.556       0.896
C(topic_grouped)[T.TV shows]                  -0.1752      0.674     -0.260      0.795      -1.495       1.145
C(answer_type_grouped)[T.Number]               0.3070      0.423      0.725      0.468      -0.523       1.137
C(answer_type_grouped)[T.Other]                0.4143      0.402      1.030      0.303      -0.374       1.203
C(answer_type_grouped)[T.Person]               0.1241      0.400      0.310      0.757      -0.661       0.909
q_length                                       0.7920      0.387      2.048      0.041       0.034       1.550
capabilities_entropy                           1.7437      0.473      3.690      0.000       0.818       2.670
game_entropy                                   1.9898      0.349      5.698      0.000       1.305       2.674
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing claude-3-sonnet-20240229 (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_neutral/claude-3-sonnet-20240229_SimpleMC_redacted_cor_temp0.0_1751845655_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    105
1     47
Name: count, dtype: int64

Answer change%: 0.3092 [0.2357377776155138, 0.3826832750160652] (n=152)
P-value vs 25%: 0.1142; P-value vs 0%: 1.604e-16
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=47)
P-value vs 25%: 0; P-value vs 33%: 0
                  Grouped rare topic into 'Misc'/'Other': ['Sports', 'TV shows', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.666667
                        1                 0.333333
Geography               0                 0.642857
                        1                 0.357143
Misc                    0                 0.714286
                        1                 0.285714
Music                   0                 0.857143
                        1                 0.142857
Other                   0                 0.833333
                        1                 0.166667
Politics                0                 0.619048
                        1                 0.380952
Science and technology  0                 0.636364
                        1                 0.363636
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.656716
                     1                 0.343284
Number               1                 0.550000
                     0                 0.450000
Other                0                 0.818182
                     1                 0.181818
Person               0                 0.781250
                     1                 0.218750
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.555556  0.444444            9
                       Number               0.333333  0.666667            3
                       Other                0.833333  0.166667            6
                       Person               0.750000  0.250000           12
Geography              Date                 0.750000  0.250000            4
                       Number               0.571429  0.428571            7
                       Other                0.666667  0.333333            3
Misc                   Date                 0.769231  0.230769           13
                       Number               0.500000  0.500000            4
                       Other                0.666667  0.333333            6
                       Person               0.800000  0.200000            5
Music                  Date                 1.000000  0.000000            5
                       Number               0.000000  1.000000            1
                       Other                0.666667  0.333333            3
                       Person               1.000000  0.000000            5
Other                  Date                 0.833333  0.166667            6
                       Number               0.000000  1.000000            1
                       Other                1.000000  0.000000            3
                       Person               1.000000  0.000000            2
Politics               Date                 0.461538  0.538462           13
                       Other                0.833333  0.166667            6
                       Person               1.000000  0.000000            2
Science and technology Date                 0.588235  0.411765           17
                       Number               0.500000  0.500000            4
                       Other                1.000000  0.000000            6
                       Person               0.500000  0.500000            6

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  152
Model:                          Logit   Df Residuals:                      141
Method:                           MLE   Df Model:                           10
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.08071
Time:                        09:26:53   Log-Likelihood:                -86.419
converged:                       True   LL-Null:                       -94.007
Covariance Type:            nonrobust   LLR p-value:                    0.1258
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      1.9076      2.436      0.783      0.434      -2.868       6.683
C(topic_grouped)[T.Geography]                 -0.5956      0.775     -0.769      0.442      -2.114       0.923
C(topic_grouped)[T.Misc]                      -0.4138      0.607     -0.682      0.495      -1.603       0.775
C(topic_grouped)[T.Music]                     -1.1595      0.890     -1.303      0.193      -2.904       0.585
C(topic_grouped)[T.Other]                     -1.0858      0.909     -1.194      0.232      -2.868       0.696
C(topic_grouped)[T.Politics]                   0.3837      0.656      0.585      0.559      -0.902       1.669
C(topic_grouped)[T.Science and technology]     0.0698      0.573      0.122      0.903      -1.053       1.192
C(answer_type_grouped)[T.Number]               1.0664      0.575      1.853      0.064      -0.061       2.194
C(answer_type_grouped)[T.Other]               -0.9067      0.533     -1.700      0.089      -1.952       0.139
C(answer_type_grouped)[T.Person]              -0.6505      0.532     -1.223      0.221      -1.693       0.392
q_length                                      -0.5211      0.536     -0.973      0.331      -1.571       0.529
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing claude-3-sonnet-20240229 (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_neutral/claude-3-sonnet-20240229_SimpleMC_redacted_temp0.0_1751827442_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    221
1    127
Name: count, dtype: int64

Answer change%: 0.3649 [0.31436271538025695, 0.41552234209100747] (n=348)
P-value vs 25%: 8.428e-06; P-value vs 0%: 2.108e-45
Phase 2 self-accuracy: 0.3937 [0.30872936773146276, 0.4786722070716869] (n=127)
P-value vs 25%: 0.0009177; P-value vs 33%: 0.1615
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': None
topic_grouped           answer_changed
Art                     0                 0.511111
                        1                 0.488889
Geography               0                 0.600000
                        1                 0.400000
Misc                    0                 0.709091
                        1                 0.290909
Music                   0                 0.807692
                        1                 0.192308
Other                   0                 0.575000
                        1                 0.425000
Politics                0                 0.625000
                        1                 0.375000
Science and technology  0                 0.676923
                        1                 0.323077
Sports                  0                 0.580645
                        1                 0.419355
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.637255
                     1                 0.362745
Number               0                 0.586207
                     1                 0.413793
Other                0                 0.689189
                     1                 0.310811
Person               0                 0.625000
                     1                 0.375000
Place                0                 0.615385
                     1                 0.384615
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.500000  0.500000           12
                       Number               0.333333  0.666667            6
                       Other                0.500000  0.500000           10
                       Person               0.600000  0.400000           15
                       Place                0.500000  0.500000            2
Geography              Date                 0.545455  0.454545           11
                       Number               0.545455  0.454545           11
                       Other                1.000000  0.000000            1
                       Place                0.714286  0.285714            7
Misc                   Date                 0.833333  0.166667           12
                       Number               0.714286  0.285714            7
                       Other                0.714286  0.285714           21
                       Person               0.538462  0.461538           13
                       Place                1.000000  0.000000            2
Music                  Date                 0.571429  0.428571            7
                       Number               1.000000  0.000000            3
                       Other                0.875000  0.125000            8
                       Person               0.857143  0.142857            7
                       Place                1.000000  0.000000            1
Other                  Date                 0.583333  0.416667           12
                       Number               0.833333  0.166667            6
                       Other                0.857143  0.142857            7
                       Person               0.363636  0.636364           11
                       Place                0.250000  0.750000            4
Politics               Date                 0.739130  0.260870           23
                       Number               0.333333  0.666667            6
                       Other                0.666667  0.333333            9
                       Person               0.538462  0.461538           13
                       Place                0.600000  0.400000            5
Science and technology Date                 0.611111  0.388889           18
                       Number               0.600000  0.400000           10
                       Other                0.700000  0.300000           10
                       Person               0.750000  0.250000           24
                       Place                0.666667  0.333333            3
Sports                 Date                 0.571429  0.428571            7
                       Number               0.555556  0.444444            9
                       Other                0.500000  0.500000            8
                       Person               0.800000  0.200000            5
                       Place                0.500000  0.500000            2

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  348
Model:                          Logit   Df Residuals:                      335
Method:                           MLE   Df Model:                           12
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.02870
Time:                        09:26:53   Log-Likelihood:                -221.81
converged:                       True   LL-Null:                       -228.36
Covariance Type:            nonrobust   LLR p-value:                    0.3614
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      2.0984      1.422      1.476      0.140      -0.689       4.886
C(topic_grouped)[T.Geography]                 -0.4835      0.502     -0.963      0.336      -1.467       0.500
C(topic_grouped)[T.Misc]                      -0.8206      0.425     -1.931      0.053      -1.654       0.012
C(topic_grouped)[T.Music]                     -1.4162      0.583     -2.429      0.015      -2.559      -0.273
C(topic_grouped)[T.Other]                     -0.2972      0.441     -0.674      0.500      -1.161       0.567
C(topic_grouped)[T.Politics]                  -0.3944      0.413     -0.954      0.340      -1.205       0.416
C(topic_grouped)[T.Science and technology]    -0.7153      0.402     -1.778      0.075      -1.504       0.073
C(topic_grouped)[T.Sports]                    -0.2863      0.476     -0.601      0.548      -1.220       0.648
C(answer_type_grouped)[T.Number]               0.2257      0.348      0.649      0.516      -0.456       0.907
C(answer_type_grouped)[T.Other]               -0.2203      0.340     -0.647      0.518      -0.887       0.447
C(answer_type_grouped)[T.Person]               0.0301      0.314      0.096      0.923      -0.584       0.645
C(answer_type_grouped)[T.Place]                0.0682      0.464      0.147      0.883      -0.841       0.977
q_length                                      -0.4762      0.304     -1.567      0.117      -1.072       0.119
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing claude-opus-4-1-20250805 (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_neutral/claude-opus-4-1-20250805_SimpleMC_neut_redacted_cor_temp0.0_1758369604_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    310
1     32
Name: count, dtype: int64

Answer change%: 0.0936 [0.06270235901025259, 0.12443214391372401] (n=342)
P-value vs 25%: 2.97e-23; P-value vs 0%: 2.822e-09
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=32)
P-value vs 25%: 0; P-value vs 33%: 0
                  Grouped rare topic into 'Misc'/'Other': ['History', 'TV shows', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.944444
                        1                 0.055556
Geography               0                 0.861111
                        1                 0.138889
Misc                    0                 0.907407
                        1                 0.092593
Music                   0                 0.807692
                        1                 0.192308
Other                   0                 0.882353
                        1                 0.117647
Politics                0                 0.936170
                        1                 0.063830
Science and technology  0                 0.938462
                        1                 0.061538
Sports                  0                 0.884615
                        1                 0.115385
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.918033
                     1                 0.081967
Number               0                 0.820000
                     1                 0.180000
Other                0                 0.935484
                     1                 0.064516
Person               0                 0.909091
                     1                 0.090909
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 1.000000  0.000000           14
                       Number               1.000000  0.000000            5
                       Other                1.000000  0.000000           14
                       Person               0.857143  0.142857           21
Geography              Date                 0.909091  0.090909           11
                       Number               0.823529  0.176471           17
                       Other                0.875000  0.125000            8
Misc                   Date                 0.894737  0.105263           19
                       Number               1.000000  0.000000            7
                       Other                0.888889  0.111111           18
                       Person               0.900000  0.100000           10
Music                  Date                 0.714286  0.285714            7
                       Number               0.500000  0.500000            2
                       Other                1.000000  0.000000            8
                       Person               0.777778  0.222222            9
Other                  Date                 0.846154  0.153846           13
                       Number               0.500000  0.500000            4
                       Other                1.000000  0.000000           10
                       Person               1.000000  0.000000            7
Politics               Date                 0.956522  0.043478           23
                       Number               1.000000  0.000000            1
                       Other                0.866667  0.133333           15
                       Person               1.000000  0.000000            8
Science and technology Date                 1.000000  0.000000           27
                       Number               0.777778  0.222222            9
                       Other                0.923077  0.076923           13
                       Person               0.937500  0.062500           16
Sports                 Date                 0.750000  0.250000            8
                       Number               0.800000  0.200000            5
                       Other                1.000000  0.000000            7
                       Person               1.000000  0.000000            6

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  342
Model:                          Logit   Df Residuals:                      330
Method:                           MLE   Df Model:                           11
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.06842
Time:                        09:26:53   Log-Likelihood:                -98.994
converged:                       True   LL-Null:                       -106.26
Covariance Type:            nonrobust   LLR p-value:                    0.2045
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -7.8648      2.482     -3.169      0.002     -12.729      -3.001
C(topic_grouped)[T.Geography]                  0.6773      0.824      0.822      0.411      -0.938       2.292
C(topic_grouped)[T.Misc]                       0.5505      0.772      0.713      0.476      -0.963       2.064
C(topic_grouped)[T.Music]                      1.5431      0.786      1.964      0.050       0.003       3.083
C(topic_grouped)[T.Other]                      0.8638      0.813      1.063      0.288      -0.729       2.457
C(topic_grouped)[T.Politics]                  -0.0748      0.891     -0.084      0.933      -1.820       1.671
C(topic_grouped)[T.Science and technology]    -0.0251      0.802     -0.031      0.975      -1.598       1.548
C(topic_grouped)[T.Sports]                     0.6837      0.882      0.776      0.438      -1.044       2.412
C(answer_type_grouped)[T.Number]               0.7783      0.544      1.432      0.152      -0.287       1.844
C(answer_type_grouped)[T.Other]               -0.3078      0.544     -0.566      0.572      -1.375       0.759
C(answer_type_grouped)[T.Person]               0.0955      0.541      0.176      0.860      -0.966       1.157
q_length                                       1.0987      0.525      2.093      0.036       0.070       2.127
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing claude-opus-4-1-20250805 (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_neutral/claude-opus-4-1-20250805_SimpleMC_neut_redacted_temp0.0_1758369148_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    93
1    65
Name: count, dtype: int64

Answer change%: 0.4114 [0.3346632151271283, 0.488121594999454] (n=158)
P-value vs 25%: 3.746e-05; P-value vs 0%: 7.888e-26
Phase 2 self-accuracy: 0.6308 [0.5134482715107075, 0.748090190027754] (n=65)
P-value vs 25%: 2.003e-10; P-value vs 33%: 6.541e-07
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'Geography', 'Video games', 'History']
                  Grouped rare answer_type into 'Misc'/'Other': None
topic_grouped           answer_changed
Art                     0                 0.571429
                        1                 0.428571
Misc                    0                 0.500000
                        1                 0.500000
Music                   0                 0.642857
                        1                 0.357143
Other                   0                 0.555556
                        1                 0.444444
Politics                0                 0.633333
                        1                 0.366667
Science and technology  0                 0.636364
                        1                 0.363636
Sports                  0                 0.571429
                        1                 0.428571
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 1                 0.510638
                     0                 0.489362
Number               0                 0.607143
                     1                 0.392857
Other                0                 0.620690
                     1                 0.379310
Person               0                 0.651163
                     1                 0.348837
Place                0                 0.636364
                     1                 0.363636
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.571429  0.428571            7
                       Number               0.500000  0.500000            4
                       Other                1.000000  0.000000            2
                       Person               0.500000  0.500000            6
                       Place                0.500000  0.500000            2
Misc                   Date                 0.500000  0.500000            8
                       Number               0.333333  0.666667            3
                       Other                0.500000  0.500000           10
                       Person               0.600000  0.400000            5
                       Place                0.500000  0.500000            2
Music                  Date                 0.200000  0.800000            5
                       Number               1.000000  0.000000            2
                       Other                0.500000  0.500000            2
                       Person               1.000000  0.000000            3
                       Place                1.000000  0.000000            2
Other                  Date                 0.400000  0.600000            5
                       Number               0.666667  0.333333            3
                       Other                0.666667  0.333333            3
                       Person               0.500000  0.500000            6
                       Place                1.000000  0.000000            1
Politics               Date                 0.615385  0.384615           13
                       Number               0.800000  0.200000            5
                       Other                0.400000  0.600000            5
                       Person               0.714286  0.285714            7
Science and technology Date                 0.500000  0.500000            8
                       Number               0.600000  0.400000            5
                       Other                1.000000  0.000000            4
                       Person               0.642857  0.357143           14
                       Place                0.500000  0.500000            2
Sports                 Date                 0.000000  1.000000            1
                       Number               0.500000  0.500000            6
                       Other                0.666667  0.333333            3
                       Person               1.000000  0.000000            2
                       Place                0.500000  0.500000            2

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  158
Model:                          Logit   Df Residuals:                      146
Method:                           MLE   Df Model:                           11
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.02675
Time:                        09:26:53   Log-Likelihood:                -104.16
converged:                       True   LL-Null:                       -107.02
Covariance Type:            nonrobust   LLR p-value:                    0.8910
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.6287      2.143     -0.760      0.447      -5.830       2.572
C(topic_grouped)[T.Misc]                       0.3324      0.601      0.553      0.580      -0.846       1.511
C(topic_grouped)[T.Music]                     -0.2977      0.722     -0.412      0.680      -1.713       1.117
C(topic_grouped)[T.Other]                      0.1133      0.658      0.172      0.863      -1.177       1.403
C(topic_grouped)[T.Politics]                  -0.3812      0.599     -0.637      0.524      -1.554       0.792
C(topic_grouped)[T.Science and technology]    -0.2775      0.587     -0.473      0.637      -1.428       0.873
C(topic_grouped)[T.Sports]                     0.1059      0.721      0.147      0.883      -1.308       1.520
C(answer_type_grouped)[T.Number]              -0.5289      0.505     -1.048      0.295      -1.518       0.460
C(answer_type_grouped)[T.Other]               -0.5751      0.512     -1.124      0.261      -1.578       0.428
C(answer_type_grouped)[T.Person]              -0.5813      0.459     -1.266      0.206      -1.481       0.319
C(answer_type_grouped)[T.Place]               -0.5998      0.723     -0.830      0.406      -2.016       0.816
q_length                                       0.3815      0.451      0.847      0.397      -0.502       1.265
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing claude-sonnet-4-20250514 (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_neutral/claude-sonnet-4-20250514_SimpleMC_redacted_cor_temp0.0_1751828378_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    175
1     44
Name: count, dtype: int64

Answer change%: 0.2009 [0.14784590663059066, 0.25398057738767416] (n=219)
P-value vs 25%: 0.06984; P-value vs 0%: 1.167e-13
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=44)
P-value vs 25%: 0; P-value vs 33%: 0
                  Grouped rare topic into 'Misc'/'Other': ['History', 'TV shows', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': None
topic_grouped           answer_changed
Art                     0                 0.894737
                        1                 0.105263
Geography               0                 0.666667
                        1                 0.333333
Misc                    0                 0.914286
                        1                 0.085714
Music                   0                 0.809524
                        1                 0.190476
Other                   0                 0.944444
                        1                 0.055556
Politics                0                 0.806452
                        1                 0.193548
Science and technology  0                 0.625000
                        1                 0.375000
Sports                  0                 0.733333
                        1                 0.266667
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.736842
                     1                 0.263158
Number               0                 0.677419
                     1                 0.322581
Other                0                 0.921569
                     1                 0.078431
Person               0                 0.826087
                     1                 0.173913
Place                0                 0.866667
                     1                 0.133333
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.777778  0.222222            9
                       Number               1.000000  0.000000            3
                       Other                1.000000  0.000000            8
                       Person               0.866667  0.133333           15
                       Place                1.000000  0.000000            3
Geography              Date                 0.250000  0.750000            4
                       Number               0.666667  0.333333            9
                       Other                1.000000  0.000000            3
                       Place                0.800000  0.200000            5
Misc                   Date                 0.846154  0.153846           13
                       Number               1.000000  0.000000            4
                       Other                0.923077  0.076923           13
                       Person               1.000000  0.000000            4
                       Place                1.000000  0.000000            1
Music                  Date                 0.750000  0.250000            8
                       Number               0.666667  0.333333            3
                       Other                0.500000  0.500000            2
                       Person               1.000000  0.000000            7
                       Place                1.000000  0.000000            1
Other                  Date                 1.000000  0.000000            6
                       Number               0.750000  0.250000            4
                       Other                1.000000  0.000000            4
                       Person               1.000000  0.000000            3
                       Place                1.000000  0.000000            1
Politics               Date                 0.800000  0.200000           15
                       Number               0.000000  1.000000            1
                       Other                1.000000  0.000000            5
                       Person               0.714286  0.285714            7
                       Place                1.000000  0.000000            3
Science and technology Date                 0.588235  0.411765           17
                       Number               0.500000  0.500000            4
                       Other                0.833333  0.166667           12
                       Person               0.500000  0.500000            6
                       Place                0.000000  1.000000            1
Sports                 Date                 0.750000  0.250000            4
                       Number               0.333333  0.666667            3
                       Other                1.000000  0.000000            4
                       Person               0.750000  0.250000            4

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  219
Model:                          Logit   Df Residuals:                      206
Method:                           MLE   Df Model:                           12
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1295
Time:                        09:26:53   Log-Likelihood:                -95.642
converged:                       True   LL-Null:                       -109.86
Covariance Type:            nonrobust   LLR p-value:                  0.004759
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -2.2083      2.199     -1.004      0.315      -6.519       2.102
C(topic_grouped)[T.Geography]                  1.3091      0.774      1.690      0.091      -0.209       2.827
C(topic_grouped)[T.Misc]                      -0.2224      0.826     -0.269      0.788      -1.840       1.396
C(topic_grouped)[T.Music]                      0.5067      0.779      0.651      0.515      -1.020       2.033
C(topic_grouped)[T.Other]                     -0.8304      1.180     -0.704      0.482      -3.143       1.482
C(topic_grouped)[T.Politics]                   0.6021      0.730      0.825      0.409      -0.829       2.033
C(topic_grouped)[T.Science and technology]     1.6610      0.649      2.559      0.011       0.389       2.933
C(topic_grouped)[T.Sports]                     1.0929      0.815      1.341      0.180      -0.504       2.690
C(answer_type_grouped)[T.Number]               0.2270      0.533      0.425      0.670      -0.819       1.272
C(answer_type_grouped)[T.Other]               -1.5199      0.608     -2.501      0.012      -2.711      -0.329
C(answer_type_grouped)[T.Person]              -0.3652      0.501     -0.728      0.466      -1.348       0.617
C(answer_type_grouped)[T.Place]               -0.9421      0.862     -1.093      0.274      -2.631       0.747
q_length                                       0.1041      0.471      0.221      0.825      -0.820       1.028
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing claude-sonnet-4-20250514 (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_neutral/claude-sonnet-4-20250514_SimpleMC_redacted_temp0.0_1751824015_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
1    149
0    132
Name: count, dtype: int64

Answer change%: 0.5302 [0.47189536831085716, 0.5886028523297121] (n=281)
P-value vs 25%: 4.826e-21; P-value vs 0%: 5.931e-71
Phase 2 self-accuracy: 0.5034 [0.4230742598581297, 0.5836371495378435] (n=149)
P-value vs 25%: 6.197e-10; P-value vs 33%: 3.196e-05
                  Grouped rare topic into 'Misc'/'Other': ['History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     1                 0.594595
                        0                 0.405405
Geography               1                 0.565217
                        0                 0.434783
Misc                    0                 0.550000
                        1                 0.450000
Music                   0                 0.684211
                        1                 0.315789
Other                   1                 0.588235
                        0                 0.411765
Politics                0                 0.521739
                        1                 0.478261
Science and technology  0                 0.534483
                        1                 0.465517
Sports                  1                 0.600000
                        0                 0.400000
TV shows                1                 0.789474
                        0                 0.210526
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.505376
                     1                 0.494624
Number               0                 0.510638
                     1                 0.489362
Other                1                 0.611940
                     0                 0.388060
Person               1                 0.527027
                     0                 0.472973
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.666667  0.333333           12
                       Number               0.333333  0.666667            6
                       Other                0.428571  0.571429            7
                       Person               0.166667  0.833333           12
Geography              Date                 0.272727  0.727273           11
                       Number               0.666667  0.333333            9
                       Other                0.333333  0.666667            3
Misc                   Date                 0.777778  0.222222            9
                       Number               0.000000  1.000000            4
                       Other                0.500000  0.500000            4
                       Person               0.666667  0.333333            3
Music                  Date                 0.750000  0.250000            4
                       Number               1.000000  0.000000            1
                       Other                0.666667  0.333333            9
                       Person               0.600000  0.400000            5
Other                  Date                 0.166667  0.833333           12
                       Number               0.666667  0.333333            3
                       Other                0.444444  0.555556            9
                       Person               0.600000  0.400000           10
Politics               Date                 0.523810  0.476190           21
                       Number               0.600000  0.400000            5
                       Other                0.333333  0.666667           12
                       Person               0.750000  0.250000            8
Science and technology Date                 0.611111  0.388889           18
                       Number               0.600000  0.400000           10
                       Other                0.500000  0.500000            6
                       Person               0.458333  0.541667           24
Sports                 Date                 0.400000  0.600000            5
                       Number               0.500000  0.500000            8
                       Other                0.250000  0.750000            8
                       Person               0.500000  0.500000            4
TV shows               Date                 0.000000  1.000000            1
                       Number               0.000000  1.000000            1
                       Other                0.111111  0.888889            9
                       Person               0.375000  0.625000            8

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  281
Model:                          Logit   Df Residuals:                      268
Method:                           MLE   Df Model:                           12
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.03866
Time:                        09:26:53   Log-Likelihood:                -186.75
converged:                       True   LL-Null:                       -194.26
Covariance Type:            nonrobust   LLR p-value:                    0.2403
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      0.2911      1.583      0.184      0.854      -2.811       3.393
C(topic_grouped)[T.Geography]                 -0.0493      0.553     -0.089      0.929      -1.134       1.035
C(topic_grouped)[T.Misc]                      -0.5782      0.567     -1.020      0.308      -1.689       0.532
C(topic_grouped)[T.Music]                     -1.3001      0.609     -2.136      0.033      -2.493      -0.107
C(topic_grouped)[T.Other]                     -0.0657      0.487     -0.135      0.893      -1.020       0.888
C(topic_grouped)[T.Politics]                  -0.5022      0.455     -1.103      0.270      -1.394       0.390
C(topic_grouped)[T.Science and technology]    -0.4923      0.429     -1.147      0.251      -1.334       0.349
C(topic_grouped)[T.Sports]                    -0.0040      0.537     -0.008      0.994      -1.057       1.049
C(topic_grouped)[T.TV shows]                   0.8051      0.665      1.210      0.226      -0.499       2.109
C(answer_type_grouped)[T.Number]              -0.1151      0.371     -0.310      0.756      -0.842       0.612
C(answer_type_grouped)[T.Other]                0.4346      0.348      1.250      0.211      -0.247       1.116
C(answer_type_grouped)[T.Person]               0.0623      0.336      0.185      0.853      -0.596       0.720
q_length                                       0.0026      0.339      0.008      0.994      -0.663       0.668
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing deepseek-chat (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_neutral/deepseek-chat_SimpleMC_redacted_cor_temp0.0_1754439842_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    228
1     30
Name: count, dtype: int64

Answer change%: 0.1163 [0.07716377720140655, 0.15539436233347717] (n=258)
P-value vs 25%: 2.078e-11; P-value vs 0%: 5.662e-09
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=30)
P-value vs 25%: 0; P-value vs 33%: 0

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  258
Model:                          Logit   Df Residuals:                      256
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.05808
Time:                        09:26:53   Log-Likelihood:                -87.351
converged:                       True   LL-Null:                       -92.737
Covariance Type:            nonrobust   LLR p-value:                  0.001031
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          0.3369      0.705      0.478      0.633      -1.046       1.720
p_i_capability    -3.0470      0.929     -3.279      0.001      -4.869      -1.226
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  258
Model:                          Logit   Df Residuals:                      256
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.07257
Time:                        09:26:53   Log-Likelihood:                -86.007
converged:                       True   LL-Null:                       -92.737
Covariance Type:            nonrobust   LLR p-value:                 0.0002438
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.9622      0.373     -7.938      0.000      -3.694      -2.231
capabilities_entropy     1.1910      0.334      3.562      0.000       0.536       1.846
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.4000 [0.2247, 0.5753] (n=30)
                  P-value vs 33.3%: 0.4561

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=19.90, p=1.98e-51
Wilcoxon delta_p: statistic=1266.00, p=1.14e-31
Mean Δp = 0.5864  [0.5286, 0.6441]
Idea 1 N = 225; 

  Idea 1.5: Calibration Metrics
  NLL: 3.9199, Signed ECE (overconf pos under neg): -0.4308, ECE: 0.5124 (n=233)
  Brier: 0.5393, Reliability (absolute calibration error; lower better): 0.3599, Resolution (relative calibration quality; higher better): 0.0338, Uncertainty: 0.2084 (n=233)
  AUROC: 0.3595

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.194
Model:                            OLS   Adj. R-squared:                  0.184
Method:                 Least Squares   F-statistic:                     20.08
Date:                Sat, 20 Sep 2025   Prob (F-statistic):           1.07e-11
Time:                        09:26:53   Log-Likelihood:                -125.49
No. Observations:                 255   AIC:                             259.0
Df Residuals:                     251   BIC:                             273.1
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.2304      0.119     -1.931      0.055      -0.465       0.005
p1                    0.9763      0.139      7.024      0.000       0.703       1.250
answer_changed       -0.0252      0.293     -0.086      0.931      -0.602       0.552
p1:answer_changed     0.0040      0.389      0.010      0.992      -0.763       0.771
==============================================================================
Omnibus:                       46.930   Durbin-Watson:                   1.984
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               60.334
Skew:                          -1.154   Prob(JB):                     7.92e-14
Kurtosis:                       2.408   Cond. No.                         25.6
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=7.37, p=3.3e-12
Wilcoxon delta_H: statistic=6187.00, p=2.46e-11
Mean ΔH = 0.3622  [0.2659, 0.4586]
Paired t-test delta_H Changed: statistic=4.36, p=0.00015
Wilcoxon delta_H Changed: statistic=59.00, p=0.000153
Mean ΔH Changed = 0.4421  [0.2433, 0.6409]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=5.29, p=2.61e-07
Wilcoxon (p_top2_game vs p_top2_base): statistic=14852.00, p=0.213
Mean Δp_top2 = 0.0285  [0.0179, 0.0390] (n=255)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=8.27, p=7.79e-15
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=7556.00, p=1.06e-13
Mean ΔH_unchosen_baseline_set = 0.3716  [0.2835, 0.4597] (n=255)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  255
Model:                          Logit   Df Residuals:                      252
Method:                           MLE   Df Model:                            2
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.06332
Time:                        09:26:53   Log-Likelihood:                -86.516
converged:                       True   LL-Null:                       -92.364
Covariance Type:            nonrobust   LLR p-value:                  0.002885
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.9193      0.296     -6.485      0.000      -2.499      -1.339
p1_z            -0.8662      0.312     -2.778      0.005      -1.477      -0.255
I(p1_z ** 2)    -0.2725      0.244     -1.116      0.264      -0.751       0.206
================================================================================
AUC = 0.700

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  258
Model:                          Logit   Df Residuals:                      256
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1445
Time:                        09:26:53   Log-Likelihood:                -79.340
converged:                       True   LL-Null:                       -92.737
Covariance Type:            nonrobust   LLR p-value:                 2.263e-07
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -3.6415      0.413     -8.812      0.000      -4.451      -2.832
game_entropy     3.4866      0.702      4.964      0.000       2.110       4.863
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=10974.00, p=1.78e-06
Paired t-test (game_entropy vs capabilities_entropy): statistic=-6.44, p=5.9e-10
Mean capabilities_entropy-game_entropy = 0.2252  [0.1567, 0.2938] (n=258)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  258
Model:                          Logit   Df Residuals:                      255
Method:                           MLE   Df Model:                            2
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1681
Time:                        09:26:53   Log-Likelihood:                -77.147
converged:                       True   LL-Null:                       -92.737
Covariance Type:            nonrobust   LLR p-value:                 1.697e-07
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -4.0010      0.476     -8.400      0.000      -4.935      -3.067
capabilities_entropy     0.7682      0.367      2.094      0.036       0.049       1.487
game_entropy             2.9826      0.739      4.037      0.000       1.534       4.431
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['Music', 'TV shows', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.975000
                        1                 0.025000
Geography               0                 0.793103
                        1                 0.206897
History                 0                 0.894737
                        1                 0.105263
Misc                    0                 0.897436
                        1                 0.102564
Other                   0                 0.956522
                        1                 0.043478
Politics                0                 0.790698
                        1                 0.209302
Science and technology  0                 0.872340
                        1                 0.127660
Sports                  0                 0.944444
                        1                 0.055556
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.877551
                     1                 0.122449
Number               0                 0.857143
                     1                 0.142857
Other                0                 0.861111
                     1                 0.138889
Person               0                 0.943396
                     1                 0.056604
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 1.000000  0.000000           13
                       Number               1.000000  0.000000            5
                       Other                0.875000  0.125000            8
                       Person               1.000000  0.000000           14
Geography              Date                 0.666667  0.333333            9
                       Number               0.916667  0.083333           12
                       Other                0.750000  0.250000            8
History                Date                 0.818182  0.181818           11
                       Number               1.000000  0.000000            2
                       Other                1.000000  0.000000            3
                       Person               1.000000  0.000000            3
Misc                   Date                 1.000000  0.000000           10
                       Number               0.666667  0.333333            3
                       Other                0.882353  0.117647           17
                       Person               0.888889  0.111111            9
Other                  Date                 0.888889  0.111111            9
                       Number               1.000000  0.000000            2
                       Other                1.000000  0.000000            7
                       Person               1.000000  0.000000            5
Politics               Date                 0.850000  0.150000           20
                       Number               0.333333  0.666667            3
                       Other                0.833333  0.166667           12
                       Person               0.750000  0.250000            8
Science and technology Date                 0.904762  0.095238           21
                       Number               0.833333  0.166667            6
                       Other                0.727273  0.272727           11
                       Person               1.000000  0.000000            9
Sports                 Date                 0.800000  0.200000            5
                       Number               1.000000  0.000000            2
                       Other                1.000000  0.000000            6
                       Person               1.000000  0.000000            5

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  258
Model:                          Logit   Df Residuals:                      246
Method:                           MLE   Df Model:                           11
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.07444
Time:                        09:26:54   Log-Likelihood:                -85.834
converged:                       True   LL-Null:                       -92.737
Covariance Type:            nonrobust   LLR p-value:                    0.2439
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.9705      2.638     -0.747      0.455      -7.141       3.200
C(topic_grouped)[T.Geography]                  2.1112      1.130      1.868      0.062      -0.104       4.327
C(topic_grouped)[T.History]                    1.4485      1.266      1.144      0.253      -1.033       3.930
C(topic_grouped)[T.Misc]                       1.3935      1.149      1.213      0.225      -0.859       3.646
C(topic_grouped)[T.Other]                      0.4892      1.443      0.339      0.735      -2.340       3.318
C(topic_grouped)[T.Politics]                   2.3657      1.097      2.157      0.031       0.216       4.515
C(topic_grouped)[T.Science and technology]     1.7427      1.113      1.566      0.117      -0.439       3.924
C(topic_grouped)[T.Sports]                     0.7406      1.449      0.511      0.609      -2.099       3.580
C(answer_type_grouped)[T.Number]               0.1105      0.616      0.179      0.858      -1.097       1.318
C(answer_type_grouped)[T.Other]                0.1907      0.480      0.397      0.691      -0.751       1.132
C(answer_type_grouped)[T.Person]              -0.6245      0.694     -0.900      0.368      -1.984       0.735
q_length                                      -0.3578      0.547     -0.655      0.513      -1.429       0.713
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.6231
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  258
Model:                          Logit   Df Residuals:                      245
Method:                           MLE   Df Model:                           12
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1564
Time:                        09:26:54   Log-Likelihood:                -78.235
converged:                       True   LL-Null:                       -92.737
Covariance Type:            nonrobust   LLR p-value:                  0.003934
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -2.0146      2.802     -0.719      0.472      -7.507       3.477
C(topic_grouped)[T.Geography]                  1.9099      1.145      1.669      0.095      -0.333       4.153
C(topic_grouped)[T.History]                    1.4498      1.303      1.112      0.266      -1.105       4.004
C(topic_grouped)[T.Misc]                       0.9606      1.175      0.818      0.413      -1.342       3.263
C(topic_grouped)[T.Other]                      0.2404      1.459      0.165      0.869      -2.618       3.099
C(topic_grouped)[T.Politics]                   2.4481      1.115      2.195      0.028       0.262       4.634
C(topic_grouped)[T.Science and technology]     1.5427      1.133      1.362      0.173      -0.678       3.763
C(topic_grouped)[T.Sports]                     0.6124      1.468      0.417      0.677      -2.265       3.490
C(answer_type_grouped)[T.Number]               0.0196      0.627      0.031      0.975      -1.209       1.249
C(answer_type_grouped)[T.Other]                0.2764      0.506      0.546      0.585      -0.715       1.268
C(answer_type_grouped)[T.Person]              -0.7457      0.729     -1.023      0.306      -2.174       0.683
q_length                                      -0.5550      0.584     -0.950      0.342      -1.700       0.590
capabilities_entropy                           1.3681      0.368      3.719      0.000       0.647       2.089
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  258
Model:                          Logit   Df Residuals:                      245
Method:                           MLE   Df Model:                           12
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.2177
Time:                        09:26:54   Log-Likelihood:                -72.552
converged:                       True   LL-Null:                       -92.737
Covariance Type:            nonrobust   LLR p-value:                 6.240e-05
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -3.8411      2.919     -1.316      0.188      -9.562       1.880
C(topic_grouped)[T.Geography]                  1.7271      1.210      1.427      0.154      -0.645       4.099
C(topic_grouped)[T.History]                    0.7017      1.381      0.508      0.611      -2.005       3.408
C(topic_grouped)[T.Misc]                       1.0995      1.196      0.919      0.358      -1.244       3.444
C(topic_grouped)[T.Other]                      0.2691      1.546      0.174      0.862      -2.761       3.299
C(topic_grouped)[T.Politics]                   2.3388      1.154      2.027      0.043       0.078       4.600
C(topic_grouped)[T.Science and technology]     1.7893      1.160      1.543      0.123      -0.484       4.063
C(topic_grouped)[T.Sports]                     1.1107      1.483      0.749      0.454      -1.796       4.017
C(answer_type_grouped)[T.Number]               0.0915      0.745      0.123      0.902      -1.368       1.551
C(answer_type_grouped)[T.Other]                0.2220      0.525      0.423      0.673      -0.808       1.251
C(answer_type_grouped)[T.Person]              -1.0174      0.782     -1.301      0.193      -2.550       0.515
q_length                                      -0.3021      0.610     -0.496      0.620      -1.497       0.893
game_entropy                                   3.9139      0.834      4.690      0.000       2.278       5.549
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  258
Model:                          Logit   Df Residuals:                      244
Method:                           MLE   Df Model:                           13
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.2456
Time:                        09:26:54   Log-Likelihood:                -69.963
converged:                       True   LL-Null:                       -92.737
Covariance Type:            nonrobust   LLR p-value:                 1.696e-05
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -3.4197      2.996     -1.141      0.254      -9.293       2.453
C(topic_grouped)[T.Geography]                  1.5530      1.204      1.290      0.197      -0.807       3.913
C(topic_grouped)[T.History]                    0.6957      1.397      0.498      0.619      -2.042       3.434
C(topic_grouped)[T.Misc]                       0.7819      1.196      0.654      0.513      -1.562       3.126
C(topic_grouped)[T.Other]                     -0.0192      1.544     -0.012      0.990      -3.045       3.007
C(topic_grouped)[T.Politics]                   2.3162      1.145      2.024      0.043       0.073       4.559
C(topic_grouped)[T.Science and technology]     1.5894      1.160      1.370      0.171      -0.685       3.864
C(topic_grouped)[T.Sports]                     0.8502      1.493      0.570      0.569      -2.076       3.776
C(answer_type_grouped)[T.Number]               0.0454      0.730      0.062      0.950      -1.385       1.476
C(answer_type_grouped)[T.Other]                0.2873      0.538      0.534      0.593      -0.767       1.342
C(answer_type_grouped)[T.Person]              -1.0049      0.787     -1.276      0.202      -2.548       0.539
q_length                                      -0.4533      0.630     -0.719      0.472      -1.688       0.782
capabilities_entropy                           0.9017      0.399      2.259      0.024       0.119       1.684
game_entropy                                   3.2753      0.864      3.792      0.000       1.582       4.968
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing deepseek-chat (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_neutral/deepseek-chat_SimpleMC_redacted_temp0.0_1754433214_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    176
1     61
Name: count, dtype: int64

Answer change%: 0.2574 [0.20172350211484746, 0.31304443037460405] (n=237)
P-value vs 25%: 0.7949; P-value vs 0%: 1.266e-19
Phase 2 self-accuracy: 0.6066 [0.48396602880304085, 0.7291487252953198] (n=61)
P-value vs 25%: 1.194e-08; P-value vs 33%: 1.222e-05

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  237
Model:                          Logit   Df Residuals:                      235
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.03498
Time:                        09:26:54   Log-Likelihood:                -130.43
converged:                       True   LL-Null:                       -135.16
Covariance Type:            nonrobust   LLR p-value:                  0.002104
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          0.6613      0.573      1.155      0.248      -0.461       1.784
p_i_capability    -2.3352      0.770     -3.031      0.002      -3.845      -0.825
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  237
Model:                          Logit   Df Residuals:                      235
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.03818
Time:                        09:26:54   Log-Likelihood:                -130.00
converged:                       True   LL-Null:                       -135.16
Covariance Type:            nonrobust   LLR p-value:                  0.001315
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.8530      0.312     -5.935      0.000      -2.465      -1.241
capabilities_entropy     0.8602      0.276      3.115      0.002       0.319       1.401
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.2951 [0.1806, 0.4095] (n=61)
                  P-value vs 33.3%: 0.5124

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=12.10, p=6.8e-25
Wilcoxon delta_p: statistic=1781.00, p=7.04e-19
Mean Δp = 0.4483  [0.3757, 0.5209]
Idea 1 N = 176; 

  Idea 1.5: Calibration Metrics
  NLL: 3.7096, Signed ECE (overconf pos under neg): 0.0130, ECE: 0.2592 (n=222)
  Brier: 0.2760, Reliability (absolute calibration error; lower better): 0.1258, Resolution (relative calibration quality; higher better): 0.0054, Uncertainty: 0.1562 (n=222)
  AUROC: 0.4481

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.224
Model:                            OLS   Adj. R-squared:                  0.214
Method:                 Least Squares   F-statistic:                     22.44
Date:                Sat, 20 Sep 2025   Prob (F-statistic):           8.45e-13
Time:                        09:26:54   Log-Likelihood:                -125.14
No. Observations:                 237   AIC:                             258.3
Df Residuals:                     233   BIC:                             272.2
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.4874      0.127     -3.827      0.000      -0.738      -0.236
p1                    1.1977      0.158      7.579      0.000       0.886       1.509
answer_changed        0.2957      0.250      1.184      0.238      -0.196       0.788
p1:answer_changed    -0.2531      0.340     -0.744      0.458      -0.923       0.417
==============================================================================
Omnibus:                      123.183   Durbin-Watson:                   1.951
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               39.754
Skew:                          -0.813   Prob(JB):                     2.33e-09
Kurtosis:                       1.825   Cond. No.                         21.0
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=6.41, p=1.33e-09
Wilcoxon delta_H: statistic=3876.00, p=7.5e-09
Mean ΔH = 0.3230  [0.2241, 0.4218]
Paired t-test delta_H Changed: statistic=3.52, p=0.000839
Wilcoxon delta_H Changed: statistic=489.00, p=0.00104
Mean ΔH Changed = 0.3248  [0.1438, 0.5058]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=8.46, p=2.83e-15
Wilcoxon (p_top2_game vs p_top2_base): statistic=7109.00, p=3.64e-11
Mean Δp_top2 = 0.0508  [0.0390, 0.0625] (n=237)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=7.31, p=4.13e-12
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=7085.00, p=3.12e-11
Mean ΔH_unchosen_baseline_set = 0.3234  [0.2367, 0.4102] (n=237)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  237
Model:                          Logit   Df Residuals:                      234
Method:                           MLE   Df Model:                            2
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.05403
Time:                        09:26:54   Log-Likelihood:                -127.86
converged:                       True   LL-Null:                       -135.16
Covariance Type:            nonrobust   LLR p-value:                 0.0006734
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.7625      0.214     -3.555      0.000      -1.183      -0.342
p1_z            -0.6540      0.187     -3.500      0.000      -1.020      -0.288
I(p1_z ** 2)    -0.3928      0.178     -2.208      0.027      -0.742      -0.044
================================================================================
AUC = 0.661

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  237
Model:                          Logit   Df Residuals:                      235
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.07249
Time:                        09:26:54   Log-Likelihood:                -125.36
converged:                       True   LL-Null:                       -135.16
Covariance Type:            nonrobust   LLR p-value:                 9.566e-06
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -2.1131      0.297     -7.104      0.000      -2.696      -1.530
game_entropy     2.0664      0.481      4.292      0.000       1.123       3.010
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=5158.00, p=2.57e-17
Paired t-test (game_entropy vs capabilities_entropy): statistic=-10.48, p=2.36e-21
Mean capabilities_entropy-game_entropy = 0.3773  [0.3067, 0.4478] (n=237)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  237
Model:                          Logit   Df Residuals:                      234
Method:                           MLE   Df Model:                            2
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.08570
Time:                        09:26:54   Log-Likelihood:                -123.58
converged:                       True   LL-Null:                       -135.16
Covariance Type:            nonrobust   LLR p-value:                 9.325e-06
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.4672      0.367     -6.730      0.000      -3.186      -1.749
capabilities_entropy     0.5521      0.295      1.872      0.061      -0.026       1.130
game_entropy             1.7665      0.505      3.498      0.000       0.777       2.756
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'Geography', 'Video games', 'History']
                  Grouped rare answer_type into 'Misc'/'Other': None
topic_grouped           answer_changed
Art                     0                 0.742857
                        1                 0.257143
Misc                    0                 0.739130
                        1                 0.260870
Music                   0                 0.782609
                        1                 0.217391
Other                   0                 0.827586
                        1                 0.172414
Politics                0                 0.696970
                        1                 0.303030
Science and technology  0                 0.720000
                        1                 0.280000
Sports                  0                 0.714286
                        1                 0.285714
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.666667
                     1                 0.333333
Number               0                 0.785714
                     1                 0.214286
Other                0                 0.750000
                     1                 0.250000
Person               0                 0.803030
                     1                 0.196970
Place                0                 0.687500
                     1                 0.312500
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.625000  0.375000            8
                       Number               1.000000  0.000000            4
                       Other                0.714286  0.285714            7
                       Person               0.769231  0.230769           13
                       Place                0.666667  0.333333            3
Misc                   Date                 0.909091  0.090909           11
                       Number               0.800000  0.200000           10
                       Other                0.727273  0.272727           11
                       Person               0.600000  0.400000           10
                       Place                0.500000  0.500000            4
Music                  Date                 0.857143  0.142857            7
                       Number               0.750000  0.250000            4
                       Other                0.800000  0.200000            5
                       Person               0.800000  0.200000            5
                       Place                0.500000  0.500000            2
Other                  Date                 0.666667  0.333333            9
                       Number               1.000000  0.000000            5
                       Other                0.800000  0.200000            5
                       Person               0.875000  0.125000            8
                       Place                1.000000  0.000000            2
Politics               Date                 0.625000  0.375000           16
                       Number               0.666667  0.333333            3
                       Other                0.833333  0.166667            6
                       Person               0.714286  0.285714            7
                       Place                1.000000  0.000000            1
Science and technology Date                 0.500000  0.500000           14
                       Number               0.750000  0.250000            8
                       Other                0.666667  0.333333            6
                       Person               0.900000  0.100000           20
                       Place                0.500000  0.500000            2
Sports                 Date                 0.500000  0.500000            4
                       Number               0.625000  0.375000            8
                       Other                0.750000  0.250000            4
                       Person               1.000000  0.000000            3
                       Place                1.000000  0.000000            2

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  237
Model:                          Logit   Df Residuals:                      225
Method:                           MLE   Df Model:                           11
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.02461
Time:                        09:26:54   Log-Likelihood:                -131.84
converged:                       True   LL-Null:                       -135.16
Covariance Type:            nonrobust   LLR p-value:                    0.8265
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -2.0946      1.883     -1.112      0.266      -5.786       1.596
C(topic_grouped)[T.Misc]                      -0.0134      0.521     -0.026      0.979      -1.034       1.007
C(topic_grouped)[T.Music]                     -0.2596      0.646     -0.402      0.688      -1.526       1.007
C(topic_grouped)[T.Other]                     -0.5352      0.634     -0.844      0.399      -1.778       0.707
C(topic_grouped)[T.Politics]                   0.0421      0.559      0.075      0.940      -1.053       1.137
C(topic_grouped)[T.Science and technology]     0.1442      0.507      0.284      0.776      -0.850       1.138
C(topic_grouped)[T.Sports]                     0.1322      0.636      0.208      0.835      -1.113       1.378
C(answer_type_grouped)[T.Number]              -0.6493      0.471     -1.378      0.168      -1.573       0.274
C(answer_type_grouped)[T.Other]               -0.3902      0.439     -0.889      0.374      -1.251       0.470
C(answer_type_grouped)[T.Person]              -0.6971      0.412     -1.692      0.091      -1.504       0.110
C(answer_type_grouped)[T.Place]               -0.0201      0.611     -0.033      0.974      -1.217       1.177
q_length                                       0.3165      0.401      0.790      0.430      -0.469       1.102
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.8547
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  237
Model:                          Logit   Df Residuals:                      224
Method:                           MLE   Df Model:                           12
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.05906
Time:                        09:26:54   Log-Likelihood:                -127.18
converged:                       True   LL-Null:                       -135.16
Covariance Type:            nonrobust   LLR p-value:                    0.1929
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -2.8146      1.967     -1.431      0.152      -6.669       1.040
C(topic_grouped)[T.Misc]                      -0.1058      0.533     -0.199      0.843      -1.150       0.939
C(topic_grouped)[T.Music]                     -0.1745      0.661     -0.264      0.792      -1.469       1.120
C(topic_grouped)[T.Other]                     -0.5798      0.648     -0.894      0.371      -1.851       0.691
C(topic_grouped)[T.Politics]                  -0.0665      0.574     -0.116      0.908      -1.191       1.058
C(topic_grouped)[T.Science and technology]     0.2607      0.522      0.499      0.618      -0.763       1.285
C(topic_grouped)[T.Sports]                     0.1400      0.653      0.214      0.830      -1.139       1.419
C(answer_type_grouped)[T.Number]              -0.6125      0.485     -1.264      0.206      -1.562       0.337
C(answer_type_grouped)[T.Other]               -0.3443      0.451     -0.763      0.445      -1.229       0.540
C(answer_type_grouped)[T.Person]              -0.5851      0.422     -1.388      0.165      -1.412       0.241
C(answer_type_grouped)[T.Place]               -0.0436      0.627     -0.070      0.945      -1.273       1.186
q_length                                       0.2944      0.414      0.711      0.477      -0.517       1.106
capabilities_entropy                           0.8491      0.286      2.971      0.003       0.289       1.409
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  237
Model:                          Logit   Df Residuals:                      224
Method:                           MLE   Df Model:                           12
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.09786
Time:                        09:26:54   Log-Likelihood:                -121.93
converged:                       True   LL-Null:                       -135.16
Covariance Type:            nonrobust   LLR p-value:                  0.009250
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -2.5196      1.973     -1.277      0.202      -6.386       1.347
C(topic_grouped)[T.Misc]                       0.0023      0.547      0.004      0.997      -1.070       1.074
C(topic_grouped)[T.Music]                     -0.3427      0.679     -0.505      0.614      -1.673       0.988
C(topic_grouped)[T.Other]                     -0.6885      0.687     -1.003      0.316      -2.034       0.657
C(topic_grouped)[T.Politics]                   0.3182      0.584      0.545      0.586      -0.826       1.462
C(topic_grouped)[T.Science and technology]     0.2922      0.535      0.546      0.585      -0.756       1.341
C(topic_grouped)[T.Sports]                     0.1176      0.678      0.173      0.862      -1.212       1.447
C(answer_type_grouped)[T.Number]              -0.6535      0.516     -1.265      0.206      -1.666       0.359
C(answer_type_grouped)[T.Other]               -0.1494      0.460     -0.325      0.746      -1.051       0.753
C(answer_type_grouped)[T.Person]              -0.3968      0.437     -0.908      0.364      -1.253       0.460
C(answer_type_grouped)[T.Place]                0.4560      0.634      0.719      0.472      -0.787       1.699
q_length                                       0.1128      0.417      0.270      0.787      -0.705       0.930
game_entropy                                   2.2108      0.514      4.299      0.000       1.203       3.219
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  237
Model:                          Logit   Df Residuals:                      223
Method:                           MLE   Df Model:                           13
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1090
Time:                        09:26:54   Log-Likelihood:                -120.42
converged:                       True   LL-Null:                       -135.16
Covariance Type:            nonrobust   LLR p-value:                  0.005598
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -2.9446      2.016     -1.461      0.144      -6.896       1.007
C(topic_grouped)[T.Misc]                      -0.0570      0.552     -0.103      0.918      -1.139       1.025
C(topic_grouped)[T.Music]                     -0.2801      0.684     -0.410      0.682      -1.621       1.061
C(topic_grouped)[T.Other]                     -0.7147      0.693     -1.032      0.302      -2.073       0.643
C(topic_grouped)[T.Politics]                   0.2273      0.590      0.385      0.700      -0.930       1.384
C(topic_grouped)[T.Science and technology]     0.3520      0.542      0.649      0.516      -0.710       1.414
C(topic_grouped)[T.Sports]                     0.1271      0.687      0.185      0.853      -1.219       1.473
C(answer_type_grouped)[T.Number]              -0.6335      0.521     -1.215      0.224      -1.655       0.388
C(answer_type_grouped)[T.Other]               -0.1421      0.465     -0.306      0.760      -1.053       0.768
C(answer_type_grouped)[T.Person]              -0.3506      0.440     -0.796      0.426      -1.214       0.512
C(answer_type_grouped)[T.Place]                0.3953      0.643      0.615      0.539      -0.865       1.656
q_length                                       0.1308      0.423      0.309      0.757      -0.698       0.959
capabilities_entropy                           0.5266      0.305      1.726      0.084      -0.071       1.124
game_entropy                                   1.9312      0.539      3.583      0.000       0.875       2.988
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing gemini-1.5-pro (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_neutral/gemini-1.5-pro_SimpleMC_redacted_cor_temp0.0_1751845219_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    217
1     23
Name: count, dtype: int64

Answer change%: 0.0958 [0.05859201783934817, 0.1330746488273185] (n=240)
P-value vs 25%: 4.914e-16; P-value vs 0%: 4.569e-07
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=23)
P-value vs 25%: 0; P-value vs 33%: 0
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.968750
                        1                 0.031250
Geography               0                 0.850000
                        1                 0.150000
History                 0                 0.900000
                        1                 0.100000
Misc                    0                 0.818182
                        1                 0.181818
Music                   0                 0.944444
                        1                 0.055556
Other                   0                 0.875000
                        1                 0.125000
Politics                0                 0.951220
                        1                 0.048780
Science and technology  0                 0.860465
                        1                 0.139535
Sports                  0                 0.950000
                        1                 0.050000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.930000
                     1                 0.070000
Number               0                 0.787879
                     1                 0.212121
Other                0                 0.885246
                     1                 0.114754
Person               0                 0.956522
                     1                 0.043478
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 1.000000  0.000000           12
                       Number               0.750000  0.250000            4
                       Other                1.000000  0.000000            7
                       Person               1.000000  0.000000            9
Geography              Date                 0.750000  0.250000            8
                       Number               0.857143  0.142857            7
                       Other                1.000000  0.000000            5
History                Date                 1.000000  0.000000           11
                       Number               0.666667  0.333333            3
                       Other                0.666667  0.333333            3
                       Person               1.000000  0.000000            3
Misc                   Date                 1.000000  0.000000            5
                       Number               0.666667  0.333333            3
                       Other                0.800000  0.200000           10
                       Person               0.750000  0.250000            4
Music                  Date                 1.000000  0.000000            6
                       Other                0.750000  0.250000            4
                       Person               1.000000  0.000000            8
Other                  Date                 0.909091  0.090909           11
                       Number               1.000000  0.000000            4
                       Other                0.714286  0.285714            7
                       Person               1.000000  0.000000            2
Politics               Date                 0.913043  0.086957           23
                       Number               1.000000  0.000000            1
                       Other                1.000000  0.000000           11
                       Person               1.000000  0.000000            6
Science and technology Date                 0.882353  0.117647           17
                       Number               0.571429  0.428571            7
                       Other                0.909091  0.090909           11
                       Person               1.000000  0.000000            8
Sports                 Date                 1.000000  0.000000            7
                       Number               1.000000  0.000000            4
                       Other                1.000000  0.000000            3
                       Person               0.833333  0.166667            6

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  240
Model:                          Logit   Df Residuals:                      227
Method:                           MLE   Df Model:                           12
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.08547
Time:                        09:26:54   Log-Likelihood:                -69.321
converged:                       True   LL-Null:                       -75.799
Covariance Type:            nonrobust   LLR p-value:                    0.3722
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -6.0134      2.940     -2.045      0.041     -11.777      -0.250
C(topic_grouped)[T.Geography]                  1.4078      1.219      1.154      0.248      -0.982       3.798
C(topic_grouped)[T.History]                    1.1647      1.277      0.912      0.362      -1.339       3.668
C(topic_grouped)[T.Misc]                       1.8210      1.172      1.553      0.120      -0.477       4.119
C(topic_grouped)[T.Music]                      0.8793      1.464      0.600      0.548      -1.991       3.750
C(topic_grouped)[T.Other]                      1.4263      1.203      1.186      0.236      -0.931       3.784
C(topic_grouped)[T.Politics]                   0.4177      1.278      0.327      0.744      -2.087       2.923
C(topic_grouped)[T.Science and technology]     1.4992      1.119      1.340      0.180      -0.694       3.692
C(topic_grouped)[T.Sports]                     0.4064      1.458      0.279      0.780      -2.451       3.264
C(answer_type_grouped)[T.Number]               1.1183      0.608      1.838      0.066      -0.074       2.311
C(answer_type_grouped)[T.Other]                0.4293      0.580      0.741      0.459      -0.707       1.565
C(answer_type_grouped)[T.Person]              -0.4369      0.847     -0.516      0.606      -2.097       1.223
q_length                                       0.5231      0.607      0.862      0.389      -0.666       1.713
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing gemini-1.5-pro (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_neutral/gemini-1.5-pro_SimpleMC_redacted_temp0.0_1751826859_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    192
1     68
Name: count, dtype: int64

Answer change%: 0.2615 [0.20811978306785434, 0.31495714000906877] (n=260)
P-value vs 25%: 0.672; P-value vs 0%: 8.31e-22
Phase 2 self-accuracy: 0.5441 [0.4257408920044083, 0.6624944021132387] (n=68)
P-value vs 25%: 1.118e-06; P-value vs 33%: 0.0004732
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'Video games', 'History']
                  Grouped rare answer_type into 'Misc'/'Other': None
topic_grouped           answer_changed
Art                     0                 0.790698
                        1                 0.209302
Geography               0                 0.708333
                        1                 0.291667
Misc                    0                 0.750000
                        1                 0.250000
Music                   0                 0.636364
                        1                 0.363636
Other                   0                 0.678571
                        1                 0.321429
Politics                0                 0.750000
                        1                 0.250000
Science and technology  0                 0.709091
                        1                 0.290909
Sports                  0                 0.900000
                        1                 0.100000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.782609
                     1                 0.217391
Number               0                 0.800000
                     1                 0.200000
Other                0                 0.722222
                     1                 0.277778
Person               0                 0.716216
                     1                 0.283784
Place                0                 0.555556
                     1                 0.444444
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.888889  0.111111            9
                       Number               0.800000  0.200000            5
                       Other                0.900000  0.100000           10
                       Person               0.722222  0.277778           18
                       Place                0.000000  1.000000            1
Geography              Date                 0.714286  0.285714            7
                       Number               0.727273  0.272727           11
                       Other                1.000000  0.000000            1
                       Place                0.600000  0.400000            5
Misc                   Date                 0.714286  0.285714            7
                       Number               1.000000  0.000000            3
                       Other                0.769231  0.230769           13
                       Person               0.625000  0.375000            8
                       Place                1.000000  0.000000            1
Music                  Date                 0.833333  0.166667            6
                       Number               0.750000  0.250000            4
                       Other                0.285714  0.714286            7
                       Person               1.000000  0.000000            4
                       Place                0.000000  1.000000            1
Other                  Date                 0.857143  0.142857            7
                       Number               1.000000  0.000000            3
                       Other                0.500000  0.500000            4
                       Person               0.636364  0.363636           11
                       Place                0.333333  0.666667            3
Politics               Date                 0.846154  0.153846           13
                       Number               1.000000  0.000000            5
                       Other                0.714286  0.285714            7
                       Person               0.555556  0.444444            9
                       Place                0.500000  0.500000            2
Science and technology Date                 0.666667  0.333333           18
                       Number               0.714286  0.285714            7
                       Other                0.600000  0.400000            5
                       Person               0.772727  0.227273           22
                       Place                0.666667  0.333333            3
Sports                 Date                 1.000000  0.000000            2
                       Number               0.714286  0.285714            7
                       Other                1.000000  0.000000            7
                       Person               1.000000  0.000000            2
                       Place                1.000000  0.000000            2

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  260
Model:                          Logit   Df Residuals:                      247
Method:                           MLE   Df Model:                           12
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.03908
Time:                        09:26:54   Log-Likelihood:                -143.57
converged:                       True   LL-Null:                       -149.41
Covariance Type:            nonrobust   LLR p-value:                    0.4718
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -0.0832      1.826     -0.046      0.964      -3.662       3.496
C(topic_grouped)[T.Geography]                  0.4775      0.638      0.749      0.454      -0.772       1.727
C(topic_grouped)[T.Misc]                       0.2116      0.563      0.376      0.707      -0.893       1.316
C(topic_grouped)[T.Music]                      0.7647      0.593      1.289      0.197      -0.398       1.927
C(topic_grouped)[T.Other]                      0.5464      0.560      0.975      0.329      -0.552       1.644
C(topic_grouped)[T.Politics]                   0.3281      0.549      0.597      0.550      -0.748       1.404
C(topic_grouped)[T.Science and technology]     0.5049      0.488      1.035      0.301      -0.451       1.461
C(topic_grouped)[T.Sports]                    -0.9096      0.854     -1.066      0.287      -2.583       0.763
C(answer_type_grouped)[T.Number]              -0.0117      0.490     -0.024      0.981      -0.972       0.949
C(answer_type_grouped)[T.Other]                0.4269      0.445      0.959      0.338      -0.446       1.299
C(answer_type_grouped)[T.Person]               0.3425      0.407      0.841      0.400      -0.455       1.140
C(answer_type_grouped)[T.Place]                1.1122      0.578      1.924      0.054      -0.021       2.245
q_length                                      -0.3436      0.388     -0.887      0.375      -1.103       0.416
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing gemini-2.0-flash-001 (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_neutral/gemini-2.0-flash-001_SimpleMC_neut_redacted_cor_temp1.0_1757986981_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    172
1     43
Name: count, dtype: int64

Answer change%: 0.2000 [0.14653262627910751, 0.2534673737208925] (n=215)
P-value vs 25%: 0.06682; P-value vs 0%: 2.277e-13
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=43)
P-value vs 25%: 0; P-value vs 33%: 0

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  215
Model:                          Logit   Df Residuals:                      213
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.05992
Time:                        09:26:54   Log-Likelihood:                -101.14
converged:                       True   LL-Null:                       -107.59
Covariance Type:            nonrobust   LLR p-value:                 0.0003297
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          2.7729      1.165      2.380      0.017       0.490       5.056
p_i_capability    -4.4891      1.256     -3.573      0.000      -6.951      -2.027
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  215
Model:                          Logit   Df Residuals:                      213
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.07136
Time:                        09:26:54   Log-Likelihood:                -99.909
converged:                       True   LL-Null:                       -107.59
Covariance Type:            nonrobust   LLR p-value:                 8.907e-05
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.8355      0.223     -8.248      0.000      -2.272      -1.399
capabilities_entropy     1.6403      0.422      3.891      0.000       0.814       2.467
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.5143 [0.3487, 0.6799] (n=35)
                  P-value vs 33.3%: 0.0322

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=4.32, p=4.37e-05
Wilcoxon delta_p: statistic=924.00, p=0.000123
Mean Δp = 0.0884  [0.0482, 0.1285]
Idea 1 N = 84; 

  Idea 1.5: Calibration Metrics
  NLL: 0.1949, Signed ECE (overconf pos under neg): -0.1228, ECE: 0.1228 (n=119)
  Brier: 0.0625, Reliability (absolute calibration error; lower better): 0.0619, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=119)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.624
Model:                            OLS   Adj. R-squared:                  0.615
Method:                 Least Squares   F-statistic:                     63.74
Date:                Sat, 20 Sep 2025   Prob (F-statistic):           2.39e-24
Time:                        09:26:54   Log-Likelihood:                 14.199
No. Observations:                 119   AIC:                            -20.40
Df Residuals:                     115   BIC:                            -9.282
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept             0.2283      0.179      1.276      0.204      -0.126       0.583
p1                   -0.1509      0.191     -0.789      0.432      -0.530       0.228
answer_changed       -1.1959      0.272     -4.393      0.000      -1.735      -0.657
p1:answer_changed     1.9278      0.299      6.445      0.000       1.335       2.520
==============================================================================
Omnibus:                        7.350   Durbin-Watson:                   2.106
Prob(Omnibus):                  0.025   Jarque-Bera (JB):               10.533
Skew:                          -0.272   Prob(JB):                      0.00516
Kurtosis:                       4.353   Cond. No.                         31.6
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-2.66, p=0.00942
Wilcoxon delta_H: statistic=1201.00, p=0.0092
Mean ΔH = -0.1783  [-0.3097, -0.0468]
Paired t-test delta_H Changed: statistic=0.50, p=0.62
Wilcoxon delta_H Changed: statistic=281.00, p=0.588
Mean ΔH Changed = 0.0494  [-0.1440, 0.2428]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=-3.97, p=0.000124
Wilcoxon (p_top2_game vs p_top2_base): statistic=1518.00, p=5.28e-08
Mean Δp_top2 = -0.0253  [-0.0378, -0.0128] (n=119)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=-1.98, p=0.0496
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=2834.00, p=0.051
Mean ΔH_unchosen_baseline_set = -0.1113  [-0.2213, -0.0013] (n=119)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  119
Model:                          Logit   Df Residuals:                      116
Method:                           MLE   Df Model:                            2
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.02251
Time:                        09:26:54   Log-Likelihood:                -70.467
converged:                       True   LL-Null:                       -72.090
Covariance Type:            nonrobust   LLR p-value:                    0.1973
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.8290      0.268     -3.088      0.002      -1.355      -0.303
p1_z            -0.4654      0.387     -1.203      0.229      -1.224       0.293
I(p1_z ** 2)    -0.0687      0.181     -0.379      0.705      -0.424       0.287
================================================================================
AUC = 0.638

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  215
Model:                          Logit   Df Residuals:                      213
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1576
Time:                        09:26:54   Log-Likelihood:                -90.631
converged:                       True   LL-Null:                       -107.59
Covariance Type:            nonrobust   LLR p-value:                 5.771e-09
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -2.2855      0.272     -8.390      0.000      -2.819      -1.752
game_entropy     1.8791      0.338      5.551      0.000       1.216       2.543
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=7695.00, p=1.81e-05
Paired t-test (game_entropy vs capabilities_entropy): statistic=4.42, p=1.59e-05
Mean capabilities_entropy-game_entropy = -0.1357  [-0.1959, -0.0755] (n=215)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  215
Model:                          Logit   Df Residuals:                      212
Method:                           MLE   Df Model:                            2
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1662
Time:                        09:26:54   Log-Likelihood:                -89.700
converged:                       True   LL-Null:                       -107.59
Covariance Type:            nonrobust   LLR p-value:                 1.707e-08
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.3667      0.283     -8.369      0.000      -2.921      -1.812
capabilities_entropy     0.6787      0.493      1.377      0.168      -0.287       1.644
game_entropy             1.6537      0.374      4.419      0.000       0.920       2.387
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'Sports', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': None
topic_grouped           answer_changed
Art                     0                 0.727273
                        1                 0.272727
Geography               0                 0.761905
                        1                 0.238095
Misc                    0                 0.765957
                        1                 0.234043
Music                   0                 0.772727
                        1                 0.227273
Other                   0                 0.850000
                        1                 0.150000
Politics                0                 0.848485
                        1                 0.151515
Science and technology  0                 0.871795
                        1                 0.128205
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.734177
                     1                 0.265823
Number               0                 0.826087
                     1                 0.173913
Other                0                 0.782609
                     1                 0.217391
Person               0                 0.923077
                     1                 0.076923
Place                0                 0.733333
                     1                 0.266667
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.600000  0.400000           10
                       Number               0.500000  0.500000            2
                       Other                0.666667  0.333333            6
                       Person               0.928571  0.071429           14
                       Place                0.000000  1.000000            1
Geography              Date                 0.600000  0.400000            5
                       Number               0.750000  0.250000            8
                       Other                1.000000  0.000000            2
                       Place                0.833333  0.166667            6
Misc                   Date                 0.666667  0.333333           15
                       Number               1.000000  0.000000            5
                       Other                0.687500  0.312500           16
                       Person               0.888889  0.111111            9
                       Place                1.000000  0.000000            2
Music                  Date                 0.750000  0.250000            8
                       Number               1.000000  0.000000            1
                       Other                0.333333  0.666667            3
                       Person               1.000000  0.000000            9
                       Place                0.000000  1.000000            1
Other                  Date                 0.750000  0.250000            8
                       Number               1.000000  0.000000            2
                       Other                1.000000  0.000000            4
                       Person               0.750000  0.250000            4
                       Place                1.000000  0.000000            2
Politics               Date                 0.789474  0.210526           19
                       Number               1.000000  0.000000            1
                       Other                1.000000  0.000000            6
                       Person               1.000000  0.000000            4
                       Place                0.666667  0.333333            3
Science and technology Date                 0.857143  0.142857           14
                       Number               0.750000  0.250000            4
                       Other                0.888889  0.111111            9
                       Person               0.916667  0.083333           12

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  215
Model:                          Logit   Df Residuals:                      203
Method:                           MLE   Df Model:                           11
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.06846
Time:                        09:26:54   Log-Likelihood:                -100.22
converged:                       True   LL-Null:                       -107.59
Covariance Type:            nonrobust   LLR p-value:                    0.1952
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.3634      2.424     -0.563      0.574      -6.113       3.387
C(topic_grouped)[T.Geography]                 -0.5898      0.721     -0.818      0.413      -2.003       0.823
C(topic_grouped)[T.Misc]                      -0.4817      0.552     -0.873      0.383      -1.563       0.600
C(topic_grouped)[T.Music]                     -0.3046      0.674     -0.452      0.651      -1.626       1.017
C(topic_grouped)[T.Other]                     -1.0927      0.766     -1.426      0.154      -2.595       0.409
C(topic_grouped)[T.Politics]                  -1.3118      0.686     -1.912      0.056      -2.657       0.033
C(topic_grouped)[T.Science and technology]    -1.1582      0.648     -1.787      0.074      -2.429       0.112
C(answer_type_grouped)[T.Number]              -0.6538      0.645     -1.013      0.311      -1.918       0.611
C(answer_type_grouped)[T.Other]               -0.3175      0.459     -0.691      0.489      -1.218       0.583
C(answer_type_grouped)[T.Person]              -1.7232      0.604     -2.851      0.004      -2.908      -0.539
C(answer_type_grouped)[T.Place]               -0.0470      0.685     -0.069      0.945      -1.390       1.296
q_length                                       0.2401      0.533      0.450      0.653      -0.805       1.286
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.2166
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  215
Model:                          Logit   Df Residuals:                      202
Method:                           MLE   Df Model:                           12
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1349
Time:                        09:26:54   Log-Likelihood:                -93.068
converged:                       True   LL-Null:                       -107.59
Covariance Type:            nonrobust   LLR p-value:                  0.003890
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.5106      2.514     -0.601      0.548      -6.437       3.416
C(topic_grouped)[T.Geography]                 -0.6944      0.781     -0.889      0.374      -2.226       0.837
C(topic_grouped)[T.Misc]                      -0.5388      0.591     -0.912      0.362      -1.697       0.619
C(topic_grouped)[T.Music]                     -0.1331      0.699     -0.190      0.849      -1.504       1.237
C(topic_grouped)[T.Other]                     -1.2061      0.796     -1.516      0.129      -2.765       0.353
C(topic_grouped)[T.Politics]                  -1.3388      0.726     -1.844      0.065      -2.762       0.084
C(topic_grouped)[T.Science and technology]    -0.8789      0.677     -1.298      0.194      -2.206       0.449
C(answer_type_grouped)[T.Number]              -0.8527      0.686     -1.244      0.214      -2.197       0.491
C(answer_type_grouped)[T.Other]               -0.5477      0.500     -1.096      0.273      -1.527       0.432
C(answer_type_grouped)[T.Person]              -1.6770      0.616     -2.720      0.007      -2.885      -0.469
C(answer_type_grouped)[T.Place]                0.1674      0.714      0.235      0.815      -1.232       1.566
q_length                                       0.1733      0.555      0.312      0.755      -0.914       1.261
capabilities_entropy                           1.7307      0.468      3.694      0.000       0.812       2.649
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  215
Model:                          Logit   Df Residuals:                      202
Method:                           MLE   Df Model:                           12
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.2335
Time:                        09:26:54   Log-Likelihood:                -82.464
converged:                       True   LL-Null:                       -107.59
Covariance Type:            nonrobust   LLR p-value:                 1.266e-06
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.0871      2.811     -0.387      0.699      -6.597       4.423
C(topic_grouped)[T.Geography]                 -1.1875      0.819     -1.450      0.147      -2.793       0.418
C(topic_grouped)[T.Misc]                      -1.1474      0.645     -1.780      0.075      -2.411       0.116
C(topic_grouped)[T.Music]                     -0.7653      0.760     -1.007      0.314      -2.255       0.725
C(topic_grouped)[T.Other]                     -1.8849      0.884     -2.132      0.033      -3.617      -0.152
C(topic_grouped)[T.Politics]                  -2.2271      0.815     -2.734      0.006      -3.824      -0.631
C(topic_grouped)[T.Science and technology]    -1.7303      0.759     -2.279      0.023      -3.218      -0.243
C(answer_type_grouped)[T.Number]              -0.5414      0.722     -0.749      0.454      -1.957       0.875
C(answer_type_grouped)[T.Other]               -0.1093      0.533     -0.205      0.837      -1.153       0.935
C(answer_type_grouped)[T.Person]              -1.4202      0.651     -2.180      0.029      -2.697      -0.143
C(answer_type_grouped)[T.Place]                0.6032      0.796      0.758      0.448      -0.956       2.163
q_length                                       0.0374      0.625      0.060      0.952      -1.187       1.262
game_entropy                                   2.1402      0.393      5.452      0.000       1.371       2.910
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  215
Model:                          Logit   Df Residuals:                      201
Method:                           MLE   Df Model:                           13
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.2403
Time:                        09:26:54   Log-Likelihood:                -81.739
converged:                       True   LL-Null:                       -107.59
Covariance Type:            nonrobust   LLR p-value:                 1.522e-06
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.1098      2.794     -0.397      0.691      -6.586       4.367
C(topic_grouped)[T.Geography]                 -1.2356      0.844     -1.464      0.143      -2.890       0.419
C(topic_grouped)[T.Misc]                      -1.1137      0.650     -1.714      0.087      -2.387       0.160
C(topic_grouped)[T.Music]                     -0.6799      0.765     -0.889      0.374      -2.179       0.819
C(topic_grouped)[T.Other]                     -1.9351      0.896     -2.159      0.031      -3.692      -0.178
C(topic_grouped)[T.Politics]                  -2.1842      0.822     -2.658      0.008      -3.795      -0.574
C(topic_grouped)[T.Science and technology]    -1.5823      0.764     -2.072      0.038      -3.079      -0.086
C(answer_type_grouped)[T.Number]              -0.6087      0.730     -0.833      0.405      -2.040       0.823
C(answer_type_grouped)[T.Other]               -0.2608      0.556     -0.469      0.639      -1.351       0.829
C(answer_type_grouped)[T.Person]              -1.4407      0.648     -2.222      0.026      -2.711      -0.170
C(answer_type_grouped)[T.Place]                0.6365      0.797      0.799      0.424      -0.925       2.198
q_length                                       0.0252      0.622      0.040      0.968      -1.194       1.245
capabilities_entropy                           0.6621      0.546      1.213      0.225      -0.408       1.732
game_entropy                                   1.9360      0.427      4.538      0.000       1.100       2.772
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing gemini-2.0-flash-001 (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_neutral/gemini-2.0-flash-001_SimpleMC_neut_redacted_temp1.0_1758161429_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    190
1     95
Name: count, dtype: int64

Answer change%: 0.3333 [0.2786040949976289, 0.38806257166903774] (n=285)
P-value vs 25%: 0.002842; P-value vs 0%: 7.561e-33
Phase 2 self-accuracy: 0.5579 [0.458026987378912, 0.6577624863052984] (n=95)
P-value vs 25%: 1.516e-09; P-value vs 33%: 1.016e-05

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  285
Model:                          Logit   Df Residuals:                      283
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.05109
Time:                        09:26:54   Log-Likelihood:                -172.14
converged:                       True   LL-Null:                       -181.41
Covariance Type:            nonrobust   LLR p-value:                 1.666e-05
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          2.4111      0.748      3.223      0.001       0.945       3.877
p_i_capability    -3.5042      0.835     -4.195      0.000      -5.141      -1.867
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  285
Model:                          Logit   Df Residuals:                      283
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.07534
Time:                        09:26:54   Log-Likelihood:                -167.74
converged:                       True   LL-Null:                       -181.41
Covariance Type:            nonrobust   LLR p-value:                 1.710e-07
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.3059      0.184     -7.090      0.000      -1.667      -0.945
capabilities_entropy     1.4849      0.295      5.025      0.000       0.906       2.064
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.5904 [0.4846, 0.6962] (n=83)
                  P-value vs 33.3%: 1.92e-06

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=4.85, p=3.52e-06
Wilcoxon delta_p: statistic=2246.00, p=1.22e-05
Mean Δp = 0.0874  [0.0521, 0.1227]
Idea 1 N = 127; 

  Idea 1.5: Calibration Metrics
  NLL: 5.7239, Signed ECE (overconf pos under neg): 0.0794, ECE: 0.0794 (n=208)
  Brier: 0.0345, Reliability (absolute calibration error; lower better): 0.0339, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=208)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.614
Model:                            OLS   Adj. R-squared:                  0.608
Method:                 Least Squares   F-statistic:                     106.5
Date:                Sat, 20 Sep 2025   Prob (F-statistic):           2.66e-41
Time:                        09:26:54   Log-Likelihood:                 14.856
No. Observations:                 205   AIC:                            -21.71
Df Residuals:                     201   BIC:                            -8.419
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept             0.0680      0.127      0.537      0.592      -0.182       0.318
p1                    0.0215      0.139      0.155      0.877      -0.252       0.295
answer_changed       -0.5970      0.180     -3.325      0.001      -0.951      -0.243
p1:answer_changed     1.3539      0.206      6.561      0.000       0.947       1.761
==============================================================================
Omnibus:                       11.820   Durbin-Watson:                   2.237
Prob(Omnibus):                  0.003   Jarque-Bera (JB):               16.140
Skew:                          -0.388   Prob(JB):                     0.000313
Kurtosis:                       4.134   Cond. No.                         27.8
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-0.29, p=0.771
Wilcoxon delta_H: statistic=3931.00, p=0.639
Mean ΔH = -0.0147  [-0.1136, 0.0842]
Paired t-test delta_H Changed: statistic=1.89, p=0.0618
Wilcoxon delta_H Changed: statistic=1227.00, p=0.0412
Mean ΔH Changed = 0.1188  [-0.0041, 0.2418]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=-2.92, p=0.00387
Wilcoxon (p_top2_game vs p_top2_base): statistic=7241.00, p=2.02e-05
Mean Δp_top2 = -0.0116  [-0.0194, -0.0038] (n=209)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=0.94, p=0.349
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=10202.00, p=0.379
Mean ΔH_unchosen_baseline_set = 0.0371  [-0.0403, 0.1144] (n=209)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  209
Model:                          Logit   Df Residuals:                      206
Method:                           MLE   Df Model:                            2
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.06701
Time:                        09:26:54   Log-Likelihood:                -130.19
converged:                       True   LL-Null:                       -139.54
Covariance Type:            nonrobust   LLR p-value:                 8.698e-05
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.1286      0.207     -0.623      0.534      -0.533       0.276
p1_z            -0.9628      0.241     -3.998      0.000      -1.435      -0.491
I(p1_z ** 2)    -0.3672      0.153     -2.396      0.017      -0.668      -0.067
================================================================================
AUC = 0.681

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  285
Model:                          Logit   Df Residuals:                      283
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.07540
Time:                        09:26:54   Log-Likelihood:                -167.73
converged:                       True   LL-Null:                       -181.41
Covariance Type:            nonrobust   LLR p-value:                 1.691e-07
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.3963      0.199     -7.022      0.000      -1.786      -1.007
game_entropy     1.3368      0.265      5.043      0.000       0.817       1.856
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=15810.00, p=0.00104
Paired t-test (game_entropy vs capabilities_entropy): statistic=3.37, p=0.000846
Mean capabilities_entropy-game_entropy = -0.1035  [-0.1637, -0.0434] (n=285)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  285
Model:                          Logit   Df Residuals:                      282
Method:                           MLE   Df Model:                            2
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1101
Time:                        09:26:54   Log-Likelihood:                -161.44
converged:                       True   LL-Null:                       -181.41
Covariance Type:            nonrobust   LLR p-value:                 2.136e-09
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.6793      0.224     -7.498      0.000      -2.118      -1.240
capabilities_entropy     1.1115      0.318      3.500      0.000       0.489       1.734
game_entropy             1.0067      0.286      3.519      0.000       0.446       1.567
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['Music', 'TV shows', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.738095
                        1                 0.261905
Geography               1                 0.521739
                        0                 0.478261
Misc                    0                 0.689655
                        1                 0.310345
Other                   0                 0.718750
                        1                 0.281250
Politics                0                 0.681818
                        1                 0.318182
Science and technology  0                 0.610169
                        1                 0.389831
Sports                  0                 0.703704
                        1                 0.296296
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.611111
                     1                 0.388889
Number               0                 0.654545
                     1                 0.345455
Other                0                 0.722222
                     1                 0.277778
Person               0                 0.691176
                     1                 0.308824
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.727273  0.272727           11
                       Number               0.714286  0.285714            7
                       Other                0.727273  0.272727           11
                       Person               0.769231  0.230769           13
Geography              Date                 0.500000  0.500000           10
                       Number               0.400000  0.600000           10
                       Other                0.666667  0.333333            3
Misc                   Date                 0.714286  0.285714           14
                       Number               0.777778  0.222222            9
                       Other                0.681818  0.318182           22
                       Person               0.615385  0.384615           13
Other                  Date                 0.600000  0.400000           10
                       Number               1.000000  0.000000            5
                       Other                0.750000  0.250000            8
                       Person               0.666667  0.333333            9
Politics               Date                 0.647059  0.352941           17
                       Number               0.800000  0.200000            5
                       Other                0.818182  0.181818           11
                       Person               0.545455  0.454545           11
Science and technology Date                 0.523810  0.476190           21
                       Number               0.600000  0.400000           10
                       Other                0.600000  0.400000           10
                       Person               0.722222  0.277778           18
Sports                 Date                 0.571429  0.428571            7
                       Number               0.555556  0.444444            9
                       Other                0.857143  0.142857            7
                       Person               1.000000  0.000000            4

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  285
Model:                          Logit   Df Residuals:                      274
Method:                           MLE   Df Model:                           10
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.02092
Time:                        09:26:54   Log-Likelihood:                -177.61
converged:                       True   LL-Null:                       -181.41
Covariance Type:            nonrobust   LLR p-value:                    0.6688
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.1392      1.550     -0.735      0.462      -4.177       1.899
C(topic_grouped)[T.Geography]                  1.0635      0.561      1.894      0.058      -0.037       2.164
C(topic_grouped)[T.Misc]                       0.2627      0.454      0.578      0.563      -0.628       1.153
C(topic_grouped)[T.Other]                      0.0857      0.529      0.162      0.871      -0.950       1.122
C(topic_grouped)[T.Politics]                   0.2294      0.483      0.475      0.635      -0.718       1.177
C(topic_grouped)[T.Science and technology]     0.5465      0.444      1.232      0.218      -0.323       1.416
C(topic_grouped)[T.Sports]                     0.1658      0.554      0.299      0.765      -0.920       1.252
C(answer_type_grouped)[T.Number]              -0.2367      0.368     -0.644      0.520      -0.957       0.484
C(answer_type_grouped)[T.Other]               -0.4100      0.349     -1.174      0.240      -1.095       0.275
C(answer_type_grouped)[T.Person]              -0.2410      0.353     -0.683      0.495      -0.933       0.451
q_length                                       0.0714      0.330      0.216      0.829      -0.576       0.718
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.3777
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  285
Model:                          Logit   Df Residuals:                      273
Method:                           MLE   Df Model:                           11
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.09404
Time:                        09:26:54   Log-Likelihood:                -164.35
converged:                       True   LL-Null:                       -181.41
Covariance Type:            nonrobust   LLR p-value:                 0.0003459
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.4661      1.618     -0.906      0.365      -4.637       1.705
C(topic_grouped)[T.Geography]                  1.2177      0.593      2.055      0.040       0.056       2.379
C(topic_grouped)[T.Misc]                       0.3352      0.477      0.703      0.482      -0.600       1.270
C(topic_grouped)[T.Other]                      0.2768      0.556      0.498      0.619      -0.813       1.367
C(topic_grouped)[T.Politics]                   0.5289      0.515      1.026      0.305      -0.481       1.539
C(topic_grouped)[T.Science and technology]     0.5719      0.466      1.226      0.220      -0.342       1.486
C(topic_grouped)[T.Sports]                     0.5167      0.579      0.892      0.373      -0.619       1.652
C(answer_type_grouped)[T.Number]              -0.4974      0.394     -1.262      0.207      -1.270       0.275
C(answer_type_grouped)[T.Other]               -0.3016      0.369     -0.818      0.413      -1.024       0.421
C(answer_type_grouped)[T.Person]              -0.0231      0.373     -0.062      0.951      -0.754       0.708
q_length                                      -0.0333      0.346     -0.096      0.923      -0.711       0.644
capabilities_entropy                           1.5564      0.317      4.908      0.000       0.935       2.178
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  285
Model:                          Logit   Df Residuals:                      273
Method:                           MLE   Df Model:                           11
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.08924
Time:                        09:26:54   Log-Likelihood:                -165.22
converged:                       True   LL-Null:                       -181.41
Covariance Type:            nonrobust   LLR p-value:                 0.0006635
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.8869      1.628     -1.159      0.246      -5.077       1.303
C(topic_grouped)[T.Geography]                  1.1432      0.593      1.927      0.054      -0.020       2.306
C(topic_grouped)[T.Misc]                       0.3985      0.478      0.834      0.405      -0.538       1.335
C(topic_grouped)[T.Other]                      0.1697      0.554      0.306      0.759      -0.916       1.255
C(topic_grouped)[T.Politics]                   0.2528      0.509      0.497      0.619      -0.744       1.250
C(topic_grouped)[T.Science and technology]     0.5414      0.468      1.156      0.248      -0.377       1.460
C(topic_grouped)[T.Sports]                     0.5452      0.582      0.936      0.349      -0.596       1.687
C(answer_type_grouped)[T.Number]              -0.2800      0.391     -0.716      0.474      -1.046       0.486
C(answer_type_grouped)[T.Other]               -0.0592      0.373     -0.159      0.874      -0.790       0.672
C(answer_type_grouped)[T.Person]               0.1491      0.380      0.393      0.695      -0.595       0.893
q_length                                       0.0230      0.345      0.067      0.947      -0.654       0.700
game_entropy                                   1.3612      0.283      4.804      0.000       0.806       1.917
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  285
Model:                          Logit   Df Residuals:                      272
Method:                           MLE   Df Model:                           12
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1274
Time:                        09:26:54   Log-Likelihood:                -158.29
converged:                       True   LL-Null:                       -181.41
Covariance Type:            nonrobust   LLR p-value:                 6.336e-06
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -2.0230      1.663     -1.217      0.224      -5.282       1.236
C(topic_grouped)[T.Geography]                  1.2254      0.603      2.033      0.042       0.044       2.407
C(topic_grouped)[T.Misc]                       0.4092      0.486      0.842      0.400      -0.543       1.361
C(topic_grouped)[T.Other]                      0.2657      0.569      0.467      0.640      -0.849       1.380
C(topic_grouped)[T.Politics]                   0.4750      0.524      0.906      0.365      -0.552       1.502
C(topic_grouped)[T.Science and technology]     0.5538      0.476      1.164      0.244      -0.378       1.486
C(topic_grouped)[T.Sports]                     0.7323      0.589      1.244      0.214      -0.422       1.886
C(answer_type_grouped)[T.Number]              -0.4765      0.406     -1.173      0.241      -1.273       0.320
C(answer_type_grouped)[T.Other]               -0.0434      0.387     -0.112      0.911      -0.801       0.714
C(answer_type_grouped)[T.Person]               0.2350      0.390      0.602      0.547      -0.530       1.000
q_length                                      -0.0345      0.353     -0.098      0.922      -0.727       0.658
capabilities_entropy                           1.2278      0.338      3.636      0.000       0.566       1.890
game_entropy                                   1.0451      0.303      3.444      0.001       0.450       1.640
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing gemini-2.5-flash-lite_nothink (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_neutral/gemini-2.5-flash-lite_nothink_SimpleMC_neut_redacted_cor_temp1.0_1757983727_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    147
1     37
Name: count, dtype: int64

Answer change%: 0.2011 [0.1431733133538262, 0.2590005996896521] (n=184)
P-value vs 25%: 0.09785; P-value vs 0%: 1.008e-11
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=37)
P-value vs 25%: 0; P-value vs 33%: 0

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  184
Model:                          Logit   Df Residuals:                      182
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.2726
Time:                        09:26:54   Log-Likelihood:                -67.176
converged:                       True   LL-Null:                       -92.351
Covariance Type:            nonrobust   LLR p-value:                 1.286e-12
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          4.3408      0.906      4.793      0.000       2.566       6.116
p_i_capability    -7.6291      1.270     -6.006      0.000     -10.119      -5.139
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  184
Model:                          Logit   Df Residuals:                      182
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.2832
Time:                        09:26:54   Log-Likelihood:                -66.200
converged:                       True   LL-Null:                       -92.351
Covariance Type:            nonrobust   LLR p-value:                 4.762e-13
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -3.9505      0.580     -6.815      0.000      -5.087      -2.814
capabilities_entropy     2.8888      0.500      5.783      0.000       1.910       3.868
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.3243 [0.1735, 0.4752] (n=37)
                  P-value vs 33.3%: 0.9068

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=-2.25, p=0.0262
Wilcoxon delta_p: statistic=3041.00, p=3.53e-06
Mean Δp = -0.0276  [-0.0518, -0.0035]
Idea 1 N = 147; 

  Idea 1.5: Calibration Metrics
  NLL: 0.3360, Signed ECE (overconf pos under neg): -0.2212, ECE: 0.2212 (n=184)
  Brier: 0.1114, Reliability (absolute calibration error; lower better): 0.1107, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=184)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.201
Model:                            OLS   Adj. R-squared:                  0.187
Method:                 Least Squares   F-statistic:                     15.05
Date:                Sat, 20 Sep 2025   Prob (F-statistic):           8.76e-09
Time:                        09:26:54   Log-Likelihood:                 40.312
No. Observations:                 184   AIC:                            -72.62
Df Residuals:                     180   BIC:                            -59.76
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.2655      0.089     -2.969      0.003      -0.442      -0.089
p1                    0.2739      0.101      2.705      0.007       0.074       0.474
answer_changed       -0.1867      0.169     -1.103      0.272      -0.521       0.147
p1:answer_changed     0.6648      0.246      2.705      0.007       0.180       1.150
==============================================================================
Omnibus:                       14.805   Durbin-Watson:                   2.057
Prob(Omnibus):                  0.001   Jarque-Bera (JB):               23.380
Skew:                           0.451   Prob(JB):                     8.38e-06
Kurtosis:                       4.495   Cond. No.                         27.6
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-0.48, p=0.633
Wilcoxon delta_H: statistic=5223.00, p=0.676
Mean ΔH = -0.0175  [-0.0893, 0.0542]
Paired t-test delta_H Changed: statistic=2.48, p=0.0178
Wilcoxon delta_H Changed: statistic=178.00, p=0.00794
Mean ΔH Changed = 0.1900  [0.0401, 0.3398]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=5.80, p=2.82e-08
Wilcoxon (p_top2_game vs p_top2_base): statistic=3506.00, p=4.61e-12
Mean Δp_top2 = 0.0231  [0.0153, 0.0309] (n=184)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=0.72, p=0.471
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=7923.00, p=0.417
Mean ΔH_unchosen_baseline_set = 0.0242  [-0.0415, 0.0899] (n=184)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  184
Model:                          Logit   Df Residuals:                      181
Method:                           MLE   Df Model:                            2
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.2936
Time:                        09:26:54   Log-Likelihood:                -65.233
converged:                       True   LL-Null:                       -92.351
Covariance Type:            nonrobust   LLR p-value:                 1.670e-12
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.6597      0.317     -5.243      0.000      -2.280      -1.039
p1_z            -2.0075      0.431     -4.657      0.000      -2.852      -1.163
I(p1_z ** 2)    -0.5131      0.264     -1.943      0.052      -1.031       0.005
================================================================================
AUC = 0.857

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  184
Model:                          Logit   Df Residuals:                      182
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.2109
Time:                        09:26:54   Log-Likelihood:                -72.873
converged:                       True   LL-Null:                       -92.351
Covariance Type:            nonrobust   LLR p-value:                 4.336e-10
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -2.8861      0.385     -7.502      0.000      -3.640      -2.132
game_entropy     2.5000      0.447      5.589      0.000       1.623       3.377
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=3018.00, p=3.16e-14
Paired t-test (game_entropy vs capabilities_entropy): statistic=-7.41, p=4.54e-12
Mean capabilities_entropy-game_entropy = 0.2029  [0.1492, 0.2566] (n=184)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  184
Model:                          Logit   Df Residuals:                      181
Method:                           MLE   Df Model:                            2
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.3053
Time:                        09:26:54   Log-Likelihood:                -64.158
converged:                       True   LL-Null:                       -92.351
Covariance Type:            nonrobust   LLR p-value:                 5.702e-13
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -4.1528      0.619     -6.709      0.000      -5.366      -2.940
capabilities_entropy     2.2877      0.584      3.915      0.000       1.142       3.433
game_entropy             1.1481      0.570      2.014      0.044       0.031       2.265
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': None
topic_grouped           answer_changed
Art                     0                 0.925926
                        1                 0.074074
Geography               0                 0.866667
                        1                 0.133333
Misc                    0                 0.578947
                        1                 0.421053
Music                   0                 0.785714
                        1                 0.214286
Other                   0                 0.823529
                        1                 0.176471
Politics                0                 0.774194
                        1                 0.225806
Science and technology  0                 0.800000
                        1                 0.200000
Sports                  0                 0.866667
                        1                 0.133333
TV shows                0                 0.750000
                        1                 0.250000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.714286
                     1                 0.285714
Number               0                 0.720000
                     1                 0.280000
Other                0                 0.875000
                     1                 0.125000
Person               0                 0.821429
                     1                 0.178571
Place                0                 0.928571
                     1                 0.071429
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.857143  0.142857            7
                       Number               0.000000  1.000000            1
                       Other                1.000000  0.000000            4
                       Person               1.000000  0.000000           13
                       Place                1.000000  0.000000            2
Geography              Date                 0.666667  0.333333            3
                       Number               0.857143  0.142857            7
                       Other                1.000000  0.000000            2
                       Place                1.000000  0.000000            3
Misc                   Date                 0.500000  0.500000            8
                       Number               1.000000  0.000000            2
                       Other                0.750000  0.250000            4
                       Person               0.333333  0.666667            3
                       Place                0.500000  0.500000            2
Music                  Date                 0.750000  0.250000            4
                       Number               0.000000  1.000000            1
                       Other                1.000000  0.000000            1
                       Person               0.875000  0.125000            8
Other                  Date                 0.800000  0.200000            5
                       Number               1.000000  0.000000            2
                       Other                1.000000  0.000000            2
                       Person               0.666667  0.333333            6
                       Place                1.000000  0.000000            2
Politics               Date                 0.700000  0.300000           10
                       Number               0.333333  0.666667            3
                       Other                1.000000  0.000000            7
                       Person               0.714286  0.285714            7
                       Place                1.000000  0.000000            4
Science and technology Date                 0.777778  0.222222            9
                       Number               0.500000  0.500000            4
                       Other                0.750000  0.250000            8
                       Person               1.000000  0.000000            9
Sports                 Date                 0.500000  0.500000            2
                       Number               1.000000  0.000000            5
                       Other                1.000000  0.000000            2
                       Person               0.800000  0.200000            5
                       Place                1.000000  0.000000            1
TV shows               Date                 1.000000  0.000000            1
                       Other                0.800000  0.200000           10
                       Person               0.600000  0.400000            5

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  184
Model:                          Logit   Df Residuals:                      170
Method:                           MLE   Df Model:                           13
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1025
Time:                        09:26:54   Log-Likelihood:                -82.883
converged:                       True   LL-Null:                       -92.351
Covariance Type:            nonrobust   LLR p-value:                    0.1252
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      0.7963      2.497      0.319      0.750      -4.098       5.691
C(topic_grouped)[T.Geography]                  0.3398      1.131      0.300      0.764      -1.878       2.557
C(topic_grouped)[T.Misc]                       2.2479      0.899      2.501      0.012       0.486       4.009
C(topic_grouped)[T.Music]                      1.1209      0.994      1.128      0.259      -0.827       3.068
C(topic_grouped)[T.Other]                      0.9005      0.991      0.908      0.364      -1.042       2.843
C(topic_grouped)[T.Politics]                   1.4741      0.878      1.679      0.093      -0.246       3.195
C(topic_grouped)[T.Science and technology]     1.1062      0.882      1.254      0.210      -0.622       2.835
C(topic_grouped)[T.Sports]                     0.4047      1.093      0.370      0.711      -1.737       2.546
C(topic_grouped)[T.TV shows]                   1.9013      0.985      1.930      0.054      -0.029       3.832
C(answer_type_grouped)[T.Number]               0.3679      0.617      0.596      0.551      -0.842       1.578
C(answer_type_grouped)[T.Other]               -1.3108      0.636     -2.061      0.039      -2.557      -0.064
C(answer_type_grouped)[T.Person]              -0.4986      0.507     -0.984      0.325      -1.492       0.495
C(answer_type_grouped)[T.Place]               -1.6505      1.134     -1.456      0.145      -3.872       0.571
q_length                                      -0.6476      0.532     -1.217      0.223      -1.690       0.395
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.6596
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  184
Model:                          Logit   Df Residuals:                      169
Method:                           MLE   Df Model:                           14
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.3985
Time:                        09:26:54   Log-Likelihood:                -55.545
converged:                       True   LL-Null:                       -92.351
Covariance Type:            nonrobust   LLR p-value:                 4.251e-10
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.2771      3.081     -0.415      0.678      -7.315       4.761
C(topic_grouped)[T.Geography]                  0.7319      1.253      0.584      0.559      -1.723       3.187
C(topic_grouped)[T.Misc]                       2.1211      1.077      1.969      0.049       0.010       4.232
C(topic_grouped)[T.Music]                      0.8843      1.274      0.694      0.488      -1.613       3.382
C(topic_grouped)[T.Other]                      0.5720      1.163      0.492      0.623      -1.707       2.851
C(topic_grouped)[T.Politics]                   2.0445      1.083      1.889      0.059      -0.077       4.166
C(topic_grouped)[T.Science and technology]     2.1312      1.085      1.965      0.049       0.005       4.257
C(topic_grouped)[T.Sports]                     0.4088      1.288      0.317      0.751      -2.116       2.934
C(topic_grouped)[T.TV shows]                   1.1366      1.229      0.925      0.355      -1.273       3.546
C(answer_type_grouped)[T.Number]              -0.4382      0.727     -0.603      0.547      -1.864       0.987
C(answer_type_grouped)[T.Other]                0.0072      0.875      0.008      0.993      -1.708       1.723
C(answer_type_grouped)[T.Person]               1.8614      0.816      2.282      0.022       0.263       3.460
C(answer_type_grouped)[T.Place]               -0.9662      1.371     -0.705      0.481      -3.654       1.722
q_length                                      -1.2595      0.660     -1.908      0.056      -2.553       0.034
capabilities_entropy                           4.2232      0.794      5.316      0.000       2.666       5.780
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  184
Model:                          Logit   Df Residuals:                      169
Method:                           MLE   Df Model:                           14
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.3043
Time:                        09:26:54   Log-Likelihood:                -64.251
converged:                       True   LL-Null:                       -92.351
Covariance Type:            nonrobust   LLR p-value:                 5.382e-07
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      0.0084      2.855      0.003      0.998      -5.587       5.604
C(topic_grouped)[T.Geography]                  0.0438      1.259      0.035      0.972      -2.425       2.512
C(topic_grouped)[T.Misc]                       2.4288      1.066      2.277      0.023       0.339       4.519
C(topic_grouped)[T.Music]                      1.8240      1.210      1.508      0.132      -0.547       4.195
C(topic_grouped)[T.Other]                      0.3666      1.154      0.318      0.751      -1.896       2.629
C(topic_grouped)[T.Politics]                   2.0178      1.087      1.856      0.064      -0.113       4.149
C(topic_grouped)[T.Science and technology]     1.7593      1.033      1.702      0.089      -0.266       3.785
C(topic_grouped)[T.Sports]                     0.3408      1.210      0.282      0.778      -2.031       2.713
C(topic_grouped)[T.TV shows]                   1.3959      1.154      1.210      0.226      -0.866       3.657
C(answer_type_grouped)[T.Number]              -0.4574      0.742     -0.616      0.538      -1.912       0.997
C(answer_type_grouped)[T.Other]               -0.0681      0.745     -0.091      0.927      -1.529       1.393
C(answer_type_grouped)[T.Person]               0.4839      0.618      0.784      0.433      -0.727       1.694
C(answer_type_grouped)[T.Place]               -0.3877      1.259     -0.308      0.758      -2.854       2.079
q_length                                      -1.0490      0.631     -1.663      0.096      -2.285       0.187
game_entropy                                   3.2818      0.633      5.182      0.000       2.040       4.523
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  184
Model:                          Logit   Df Residuals:                      168
Method:                           MLE   Df Model:                           15
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.4370
Time:                        09:26:54   Log-Likelihood:                -51.991
converged:                       True   LL-Null:                       -92.351
Covariance Type:            nonrobust   LLR p-value:                 5.157e-11
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.7891      3.211     -0.557      0.577      -8.083       4.505
C(topic_grouped)[T.Geography]                  0.5811      1.241      0.468      0.640      -1.852       3.014
C(topic_grouped)[T.Misc]                       2.3308      1.108      2.103      0.035       0.159       4.503
C(topic_grouped)[T.Music]                      1.1400      1.301      0.876      0.381      -1.409       3.689
C(topic_grouped)[T.Other]                      0.4071      1.184      0.344      0.731      -1.913       2.727
C(topic_grouped)[T.Politics]                   2.2779      1.114      2.045      0.041       0.095       4.461
C(topic_grouped)[T.Science and technology]     2.3626      1.108      2.133      0.033       0.191       4.534
C(topic_grouped)[T.Sports]                     0.3923      1.275      0.308      0.758      -2.107       2.892
C(topic_grouped)[T.TV shows]                   1.1324      1.220      0.928      0.353      -1.258       3.523
C(answer_type_grouped)[T.Number]              -0.6425      0.761     -0.844      0.399      -2.135       0.850
C(answer_type_grouped)[T.Other]                0.2989      0.911      0.328      0.743      -1.487       2.085
C(answer_type_grouped)[T.Person]               2.0553      0.845      2.433      0.015       0.399       3.711
C(answer_type_grouped)[T.Place]               -0.2696      1.453     -0.186      0.853      -3.117       2.578
q_length                                      -1.3309      0.696     -1.912      0.056      -2.695       0.033
capabilities_entropy                           3.5864      0.862      4.159      0.000       1.896       5.277
game_entropy                                   1.8232      0.706      2.581      0.010       0.439       3.208
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing gemini-2.5-flash-lite_nothink (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_neutral/gemini-2.5-flash-lite_nothink_SimpleMC_neut_redacted_temp1.0_1757983564_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    199
1    117
Name: count, dtype: int64

Answer change%: 0.3703 [0.3170133007087754, 0.4234930284051486] (n=316)
P-value vs 25%: 9.556e-06; P-value vs 0%: 2.64e-42
Phase 2 self-accuracy: 0.4615 [0.37120753746320173, 0.5518693856137215] (n=117)
P-value vs 25%: 4.435e-06; P-value vs 33%: 0.005288

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  316
Model:                          Logit   Df Residuals:                      314
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1268
Time:                        09:26:54   Log-Likelihood:                -181.86
converged:                       True   LL-Null:                       -208.27
Covariance Type:            nonrobust   LLR p-value:                 3.649e-13
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          2.8724      0.510      5.634      0.000       1.873       3.872
p_i_capability    -4.6548      0.691     -6.733      0.000      -6.010      -3.300
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  316
Model:                          Logit   Df Residuals:                      314
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1331
Time:                        09:26:54   Log-Likelihood:                -180.55
converged:                       True   LL-Null:                       -208.27
Covariance Type:            nonrobust   LLR p-value:                 9.644e-14
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.1813      0.291     -7.493      0.000      -2.752      -1.611
capabilities_entropy     1.7542      0.261      6.728      0.000       1.243       2.265
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.3761 [0.2883, 0.4638] (n=117)
                  P-value vs 33.3%: 0.3399

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=0.07, p=0.947
Wilcoxon delta_p: statistic=8782.00, p=0.186
Mean Δp = 0.0010  [-0.0295, 0.0316]
Idea 1 N = 198; 

  Idea 1.5: Calibration Metrics
  NLL: 3.4667, Signed ECE (overconf pos under neg): 0.1396, ECE: 0.1396 (n=315)
  Brier: 0.0579, Reliability (absolute calibration error; lower better): 0.0571, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=315)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.194
Model:                            OLS   Adj. R-squared:                  0.186
Method:                 Least Squares   F-statistic:                     24.89
Date:                Sat, 20 Sep 2025   Prob (F-statistic):           1.88e-14
Time:                        09:26:54   Log-Likelihood:                -34.489
No. Observations:                 314   AIC:                             76.98
Df Residuals:                     310   BIC:                             91.97
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.1942      0.087     -2.223      0.027      -0.366      -0.022
p1                    0.2411      0.105      2.291      0.023       0.034       0.448
answer_changed       -0.1632      0.133     -1.229      0.220      -0.424       0.098
p1:answer_changed     0.6096      0.183      3.338      0.001       0.250       0.969
==============================================================================
Omnibus:                        2.960   Durbin-Watson:                   1.957
Prob(Omnibus):                  0.228   Jarque-Bera (JB):                2.803
Skew:                           0.169   Prob(JB):                        0.246
Kurtosis:                       2.684   Cond. No.                         21.2
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=0.42, p=0.673
Wilcoxon delta_H: statistic=9737.00, p=0.888
Mean ΔH = 0.0116  [-0.0424, 0.0657]
Paired t-test delta_H Changed: statistic=4.17, p=5.81e-05
Wilcoxon delta_H Changed: statistic=2102.00, p=0.000242
Mean ΔH Changed = 0.1944  [0.1031, 0.2857]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=4.96, p=1.17e-06
Wilcoxon (p_top2_game vs p_top2_base): statistic=16422.00, p=1.68e-07
Mean Δp_top2 = 0.0211  [0.0128, 0.0295] (n=315)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=3.19, p=0.00158
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=21122.00, p=0.02
Mean ΔH_unchosen_baseline_set = 0.0795  [0.0306, 0.1284] (n=315)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  315
Model:                          Logit   Df Residuals:                      312
Method:                           MLE   Df Model:                            2
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1400
Time:                        09:26:54   Log-Likelihood:                -178.72
converged:                       True   LL-Null:                       -207.81
Covariance Type:            nonrobust   LLR p-value:                 2.327e-13
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.3007      0.183     -1.647      0.100      -0.658       0.057
p1_z            -1.0537      0.156     -6.754      0.000      -1.359      -0.748
I(p1_z ** 2)    -0.3750      0.154     -2.442      0.015      -0.676      -0.074
================================================================================
AUC = 0.730

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  316
Model:                          Logit   Df Residuals:                      314
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.07963
Time:                        09:26:54   Log-Likelihood:                -191.69
converged:                       True   LL-Null:                       -208.27
Covariance Type:            nonrobust   LLR p-value:                 8.445e-09
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.4929      0.220     -6.796      0.000      -1.923      -1.062
game_entropy     1.3409      0.244      5.499      0.000       0.863       1.819
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=13668.00, p=2.59e-12
Paired t-test (game_entropy vs capabilities_entropy): statistic=-7.48, p=7.67e-13
Mean capabilities_entropy-game_entropy = 0.1941  [0.1432, 0.2450] (n=316)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  316
Model:                          Logit   Df Residuals:                      313
Method:                           MLE   Df Model:                            2
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1401
Time:                        09:26:54   Log-Likelihood:                -179.10
converged:                       True   LL-Null:                       -208.27
Covariance Type:            nonrobust   LLR p-value:                 2.133e-13
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.2928      0.303     -7.570      0.000      -2.886      -1.699
capabilities_entropy     1.4752      0.306      4.828      0.000       0.876       2.074
game_entropy             0.5126      0.300      1.709      0.087      -0.075       1.100
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.562500
                        1                 0.437500
Geography               0                 0.517241
                        1                 0.482759
Misc                    0                 0.641026
                        1                 0.358974
Music                   0                 0.769231
                        1                 0.230769
Other                   0                 0.628571
                        1                 0.371429
Politics                0                 0.652174
                        1                 0.347826
Science and technology  0                 0.661765
                        1                 0.338235
Sports                  0                 0.600000
                        1                 0.400000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.533333
                     1                 0.466667
Number               0                 0.660377
                     1                 0.339623
Other                0                 0.721519
                     1                 0.278481
Person               0                 0.671875
                     1                 0.328125
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.285714  0.714286           14
                       Number               0.625000  0.375000            8
                       Other                0.833333  0.166667           12
                       Person               0.571429  0.428571           14
Geography              Date                 0.333333  0.666667           12
                       Number               0.727273  0.272727           11
                       Other                0.500000  0.500000            6
Misc                   Date                 0.571429  0.428571           14
                       Number               0.571429  0.428571            7
                       Other                0.727273  0.272727           11
                       Person               0.714286  0.285714            7
Music                  Date                 0.500000  0.500000            8
                       Number               0.666667  0.333333            3
                       Other                0.909091  0.090909           11
                       Person               1.000000  0.000000            4
Other                  Date                 0.538462  0.461538           13
                       Number               1.000000  0.000000            5
                       Other                0.700000  0.300000           10
                       Person               0.428571  0.571429            7
Politics               Date                 0.653846  0.346154           26
                       Number               0.666667  0.333333            3
                       Other                0.666667  0.333333            9
                       Person               0.625000  0.375000            8
Science and technology Date                 0.538462  0.461538           26
                       Number               0.700000  0.300000           10
                       Other                0.727273  0.272727           11
                       Person               0.761905  0.238095           21
Sports                 Date                 0.857143  0.142857            7
                       Number               0.333333  0.666667            6
                       Other                0.555556  0.444444            9
                       Person               0.666667  0.333333            3

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  316
Model:                          Logit   Df Residuals:                      304
Method:                           MLE   Df Model:                           11
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.03473
Time:                        09:26:54   Log-Likelihood:                -201.04
converged:                       True   LL-Null:                       -208.27
Covariance Type:            nonrobust   LLR p-value:                    0.2082
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      1.1433      1.534      0.745      0.456      -1.863       4.150
C(topic_grouped)[T.Geography]                  0.0988      0.493      0.200      0.841      -0.867       1.065
C(topic_grouped)[T.Misc]                      -0.3658      0.451     -0.811      0.417      -1.250       0.518
C(topic_grouped)[T.Music]                     -0.9716      0.560     -1.735      0.083      -2.069       0.126
C(topic_grouped)[T.Other]                     -0.3333      0.463     -0.720      0.472      -1.241       0.575
C(topic_grouped)[T.Politics]                  -0.5385      0.442     -1.218      0.223      -1.405       0.328
C(topic_grouped)[T.Science and technology]    -0.4954      0.396     -1.253      0.210      -1.271       0.280
C(topic_grouped)[T.Sports]                    -0.1116      0.513     -0.218      0.828      -1.117       0.894
C(answer_type_grouped)[T.Number]              -0.6629      0.356     -1.863      0.062      -1.360       0.034
C(answer_type_grouped)[T.Other]               -0.8592      0.320     -2.682      0.007      -1.487      -0.231
C(answer_type_grouped)[T.Person]              -0.6151      0.337     -1.826      0.068      -1.275       0.045
q_length                                      -0.2002      0.330     -0.607      0.544      -0.847       0.446
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.8737
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  316
Model:                          Logit   Df Residuals:                      303
Method:                           MLE   Df Model:                           12
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1631
Time:                        09:26:54   Log-Likelihood:                -174.30
converged:                       True   LL-Null:                       -208.27
Covariance Type:            nonrobust   LLR p-value:                 7.743e-10
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -0.9137      1.719     -0.532      0.595      -4.283       2.455
C(topic_grouped)[T.Geography]                 -0.0202      0.526     -0.038      0.969      -1.052       1.011
C(topic_grouped)[T.Misc]                      -0.0238      0.497     -0.048      0.962      -0.999       0.951
C(topic_grouped)[T.Music]                     -1.1177      0.619     -1.807      0.071      -2.330       0.095
C(topic_grouped)[T.Other]                     -0.4247      0.501     -0.848      0.396      -1.406       0.557
C(topic_grouped)[T.Politics]                  -0.5641      0.488     -1.157      0.247      -1.520       0.391
C(topic_grouped)[T.Science and technology]    -0.4168      0.436     -0.957      0.339      -1.270       0.437
C(topic_grouped)[T.Sports]                     0.0732      0.568      0.129      0.898      -1.041       1.187
C(answer_type_grouped)[T.Number]              -1.0438      0.392     -2.664      0.008      -1.812      -0.276
C(answer_type_grouped)[T.Other]               -0.2154      0.363     -0.593      0.553      -0.928       0.497
C(answer_type_grouped)[T.Person]              -0.1094      0.380     -0.288      0.774      -0.855       0.636
q_length                                      -0.2010      0.362     -0.556      0.578      -0.910       0.508
capabilities_entropy                           1.9403      0.296      6.545      0.000       1.359       2.521
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  316
Model:                          Logit   Df Residuals:                      303
Method:                           MLE   Df Model:                           12
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1073
Time:                        09:26:54   Log-Likelihood:                -185.92
converged:                       True   LL-Null:                       -208.27
Covariance Type:            nonrobust   LLR p-value:                 1.154e-05
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -0.2118      1.628     -0.130      0.896      -3.402       2.978
C(topic_grouped)[T.Geography]                 -0.2280      0.527     -0.433      0.665      -1.260       0.804
C(topic_grouped)[T.Misc]                      -0.3470      0.476     -0.729      0.466      -1.280       0.586
C(topic_grouped)[T.Music]                     -1.0969      0.596     -1.842      0.065      -2.264       0.070
C(topic_grouped)[T.Other]                     -0.5806      0.484     -1.200      0.230      -1.529       0.368
C(topic_grouped)[T.Politics]                  -0.6253      0.466     -1.341      0.180      -1.539       0.289
C(topic_grouped)[T.Science and technology]    -0.6786      0.417     -1.626      0.104      -1.497       0.139
C(topic_grouped)[T.Sports]                    -0.2036      0.540     -0.377      0.706      -1.263       0.856
C(answer_type_grouped)[T.Number]              -0.8281      0.375     -2.210      0.027      -1.563      -0.094
C(answer_type_grouped)[T.Other]               -0.6507      0.339     -1.918      0.055      -1.316       0.014
C(answer_type_grouped)[T.Person]              -0.3673      0.358     -1.026      0.305      -1.069       0.334
q_length                                      -0.1052      0.346     -0.304      0.761      -0.784       0.574
game_entropy                                   1.3640      0.259      5.266      0.000       0.856       1.872
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  316
Model:                          Logit   Df Residuals:                      302
Method:                           MLE   Df Model:                           13
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1702
Time:                        09:26:54   Log-Likelihood:                -172.81
converged:                       True   LL-Null:                       -208.27
Covariance Type:            nonrobust   LLR p-value:                 5.441e-10
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.1485      1.724     -0.666      0.505      -4.528       2.231
C(topic_grouped)[T.Geography]                 -0.1276      0.537     -0.238      0.812      -1.179       0.924
C(topic_grouped)[T.Misc]                      -0.0564      0.502     -0.112      0.911      -1.041       0.928
C(topic_grouped)[T.Music]                     -1.1339      0.619     -1.831      0.067      -2.348       0.080
C(topic_grouped)[T.Other]                     -0.4960      0.502     -0.988      0.323      -1.480       0.488
C(topic_grouped)[T.Politics]                  -0.5923      0.491     -1.206      0.228      -1.555       0.370
C(topic_grouped)[T.Science and technology]    -0.4884      0.440     -1.110      0.267      -1.351       0.374
C(topic_grouped)[T.Sports]                     0.0178      0.572      0.031      0.975      -1.104       1.140
C(answer_type_grouped)[T.Number]              -1.0568      0.394     -2.680      0.007      -1.830      -0.284
C(answer_type_grouped)[T.Other]               -0.2353      0.365     -0.645      0.519      -0.950       0.479
C(answer_type_grouped)[T.Person]              -0.0851      0.383     -0.222      0.824      -0.836       0.666
q_length                                      -0.1641      0.362     -0.453      0.650      -0.874       0.546
capabilities_entropy                           1.6530      0.338      4.896      0.000       0.991       2.315
game_entropy                                   0.5361      0.311      1.725      0.085      -0.073       1.145
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing gemini-2.5-flash-lite_think (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_neutral/gemini-2.5-flash-lite_think_SimpleMC_neut_redacted_cor_temp1.0_1758214203_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    176
1     52
Name: count, dtype: int64

Answer change%: 0.2281 [0.17360689124072182, 0.28253345963647114] (n=228)
P-value vs 25%: 0.43; P-value vs 0%: 2.258e-16
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=52)
P-value vs 25%: 0; P-value vs 33%: 0

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  228
Model:                          Logit   Df Residuals:                      226
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                0.009453
Time:                        09:26:54   Log-Likelihood:                -121.26
converged:                       True   LL-Null:                       -122.42
Covariance Type:            nonrobust   LLR p-value:                    0.1282
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept       1091.4413    749.403      1.456      0.145    -377.362    2560.245
p_i_capability -1092.7141    749.440     -1.458      0.145   -2561.590     376.161
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  228
Model:                          Logit   Df Residuals:                      226
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.01016
Time:                        09:26:54   Log-Likelihood:                -121.18
converged:                       True   LL-Null:                       -122.42
Covariance Type:            nonrobust   LLR p-value:                    0.1147
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.2769      0.163     -7.814      0.000      -1.597      -0.957
capabilities_entropy    97.5434     64.801      1.505      0.132     -29.464     224.551
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.1042 [0.0177, 0.1906] (n=48)
                  P-value vs 33.3%: 2.02e-07

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=1.04, p=0.301
Wilcoxon delta_p: statistic=870.00, p=5.97e-20
Mean Δp = 0.0020  [-0.0018, 0.0059]
Idea 1 N = 153; 

  Idea 1.5: Calibration Metrics
  NLL: 0.0000, Signed ECE (overconf pos under neg): -0.0000, ECE: 0.0000 (n=200)
  Brier: 0.0000, Reliability (absolute calibration error; lower better): 0.0000, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=200)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.995
Model:                            OLS   Adj. R-squared:                  0.995
Method:                 Least Squares   F-statistic:                 1.208e+04
Date:                Sat, 20 Sep 2025   Prob (F-statistic):          9.18e-199
Time:                        09:26:54   Log-Likelihood:                 413.94
No. Observations:                 175   AIC:                            -819.9
Df Residuals:                     171   BIC:                            -807.2
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept             1.8749     10.528      0.178      0.859     -18.907      22.657
p1                   -1.8729     10.528     -0.178      0.859     -22.655      18.910
answer_changed       -1.8641     19.975     -0.093      0.926     -41.293      37.565
p1:answer_changed     2.8620     19.976      0.143      0.886     -36.570      42.294
==============================================================================
Omnibus:                      384.166   Durbin-Watson:                   2.001
Prob(Omnibus):                  0.000   Jarque-Bera (JB):           214324.798
Skew:                          13.082   Prob(JB):                         0.00
Kurtosis:                     172.436   Cond. No.                     2.43e+04
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The condition number is large, 2.43e+04. This might indicate that there are
strong multicollinearity or other numerical problems.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=2.90, p=0.00429
Wilcoxon delta_H: statistic=4378.00, p=0.00587
Mean ΔH = 0.0999  [0.0324, 0.1675]
Paired t-test delta_H Changed: statistic=29.28, p=2.17e-31
Wilcoxon delta_H Changed: statistic=0.00, p=1.42e-14
Mean ΔH Changed = 1.2330  [1.1505, 1.3155]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=-2.47, p=0.0142
Wilcoxon (p_top2_game vs p_top2_base): statistic=2174.00, p=7.25e-22
Mean Δp_top2 = -0.0000  [-0.0001, -0.0000] (n=200)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=8.29, p=1.64e-14
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=4438.00, p=7.51e-12
Mean ΔH_unchosen_baseline_set = 0.3662  [0.2796, 0.4527] (n=200)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  200
Model:                          Logit   Df Residuals:                      197
Method:                           MLE   Df Model:                            2
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.04003
Time:                        09:26:54   Log-Likelihood:                -104.68
converged:                       True   LL-Null:                       -109.05
Covariance Type:            nonrobust   LLR p-value:                   0.01271
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.0203      0.189     -5.413      0.000      -1.390      -0.651
p1_z            -1.7161      0.726     -2.365      0.018      -3.138      -0.294
I(p1_z ** 2)    -0.1812      0.090     -2.017      0.044      -0.357      -0.005
================================================================================
AUC = 0.575

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  228
Model:                          Logit   Df Residuals:                      226
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:               0.0009315
Time:                        09:26:54   Log-Likelihood:                -122.31
converged:                       True   LL-Null:                       -122.42
Covariance Type:            nonrobust   LLR p-value:                    0.6330
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.2123      0.158     -7.653      0.000      -1.523      -0.902
game_entropy    -1.8274      4.884     -0.374      0.708     -11.399       7.745
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=2619.00, p=1.26e-25
Paired t-test (game_entropy vs capabilities_entropy): statistic=1.24, p=0.216
Mean capabilities_entropy-game_entropy = -0.0048  [-0.0125, 0.0028] (n=228)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  228
Model:                          Logit   Df Residuals:                      225
Method:                           MLE   Df Model:                            2
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.01113
Time:                        09:26:54   Log-Likelihood:                -121.06
converged:                       True   LL-Null:                       -122.42
Covariance Type:            nonrobust   LLR p-value:                    0.2561
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.2699      0.164     -7.746      0.000      -1.591      -0.949
capabilities_entropy    97.7223     64.888      1.506      0.132     -29.457     224.901
game_entropy            -1.8503      4.877     -0.379      0.704     -11.410       7.709
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': None
topic_grouped           answer_changed
Art                     0                 0.837838
                        1                 0.162162
Geography               0                 0.863636
                        1                 0.136364
Misc                    0                 0.740741
                        1                 0.259259
Music                   0                 0.705882
                        1                 0.294118
Other                   0                 0.640000
                        1                 0.360000
Politics                0                 0.820513
                        1                 0.179487
Science and technology  0                 0.767442
                        1                 0.232558
Sports                  0                 0.722222
                        1                 0.277778
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.726027
                     1                 0.273973
Number               0                 0.629630
                     1                 0.370370
Other                0                 0.796296
                     1                 0.203704
Person               0                 0.824561
                     1                 0.175439
Place                0                 0.941176
                     1                 0.058824
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.800000  0.200000           10
                       Number               0.500000  0.500000            4
                       Other                0.875000  0.125000            8
                       Person               0.916667  0.083333           12
                       Place                1.000000  0.000000            3
Geography              Date                 0.800000  0.200000            5
                       Number               0.750000  0.250000            8
                       Other                1.000000  0.000000            3
                       Place                1.000000  0.000000            6
Misc                   Date                 0.714286  0.285714            7
                       Number               1.000000  0.000000            2
                       Other                0.666667  0.333333            9
                       Person               0.857143  0.142857            7
                       Place                0.500000  0.500000            2
Music                  Date                 0.600000  0.400000            5
                       Other                0.750000  0.250000            4
                       Person               0.750000  0.250000            8
Other                  Date                 0.333333  0.666667            6
                       Number               0.333333  0.666667            3
                       Other                0.800000  0.200000            5
                       Person               0.750000  0.250000            8
                       Place                1.000000  0.000000            3
Politics               Date                 0.777778  0.222222           18
                       Number               1.000000  0.000000            2
                       Other                0.818182  0.181818           11
                       Person               0.833333  0.166667            6
                       Place                1.000000  0.000000            2
Science and technology Date                 0.722222  0.277778           18
                       Number               0.600000  0.400000            5
                       Other                0.888889  0.111111            9
                       Person               0.800000  0.200000           10
                       Place                1.000000  0.000000            1
Sports                 Date                 1.000000  0.000000            4
                       Number               0.333333  0.666667            3
                       Other                0.600000  0.400000            5
                       Person               0.833333  0.166667            6

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  228
Model:                          Logit   Df Residuals:                      215
Method:                           MLE   Df Model:                           12
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.06522
Time:                        09:26:54   Log-Likelihood:                -114.44
converged:                       True   LL-Null:                       -122.42
Covariance Type:            nonrobust   LLR p-value:                    0.1927
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -0.8941      1.994     -0.449      0.654      -4.801       3.013
C(topic_grouped)[T.Geography]                 -0.4804      0.813     -0.591      0.554      -2.073       1.112
C(topic_grouped)[T.Misc]                       0.6680      0.649      1.029      0.303      -0.604       1.940
C(topic_grouped)[T.Music]                      0.9129      0.717      1.273      0.203      -0.492       2.318
C(topic_grouped)[T.Other]                      1.1802      0.635      1.860      0.063      -0.063       2.424
C(topic_grouped)[T.Politics]                   0.0674      0.637      0.106      0.916      -1.181       1.316
C(topic_grouped)[T.Science and technology]     0.3429      0.600      0.572      0.568      -0.833       1.518
C(topic_grouped)[T.Sports]                     0.6113      0.708      0.863      0.388      -0.777       1.999
C(answer_type_grouped)[T.Number]               0.6041      0.520      1.161      0.246      -0.416       1.624
C(answer_type_grouped)[T.Other]               -0.4706      0.439     -1.071      0.284      -1.332       0.391
C(answer_type_grouped)[T.Person]              -0.7761      0.455     -1.705      0.088      -1.668       0.116
C(answer_type_grouped)[T.Place]               -1.7524      1.092     -1.604      0.109      -3.893       0.389
q_length                                      -0.0973      0.440     -0.221      0.825      -0.960       0.765
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.0005
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  228
Model:                          Logit   Df Residuals:                      214
Method:                           MLE   Df Model:                           13
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.08140
Time:                        09:26:54   Log-Likelihood:                -112.46
converged:                       True   LL-Null:                       -122.42
Covariance Type:            nonrobust   LLR p-value:                   0.09699
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.0760      2.018     -0.533      0.594      -5.031       2.879
C(topic_grouped)[T.Geography]                 -0.2210      0.842     -0.262      0.793      -1.872       1.430
C(topic_grouped)[T.Misc]                       0.9042      0.681      1.328      0.184      -0.430       2.239
C(topic_grouped)[T.Music]                      1.0904      0.738      1.477      0.140      -0.356       2.537
C(topic_grouped)[T.Other]                      1.3158      0.661      1.989      0.047       0.019       2.612
C(topic_grouped)[T.Politics]                   0.3162      0.668      0.473      0.636      -0.993       1.626
C(topic_grouped)[T.Science and technology]     0.5579      0.631      0.884      0.376      -0.678       1.794
C(topic_grouped)[T.Sports]                     0.8117      0.732      1.110      0.267      -0.622       2.245
C(answer_type_grouped)[T.Number]               0.6511      0.524      1.242      0.214      -0.376       1.678
C(answer_type_grouped)[T.Other]               -0.4115      0.442     -0.931      0.352      -1.278       0.455
C(answer_type_grouped)[T.Person]              -0.7061      0.458     -1.541      0.123      -1.604       0.192
C(answer_type_grouped)[T.Place]               -2.5747      1.498     -1.719      0.086      -5.511       0.361
q_length                                      -0.1201      0.446     -0.270      0.787      -0.993       0.753
capabilities_entropy                         138.0277     71.862      1.921      0.055      -2.819     278.874
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  228
Model:                          Logit   Df Residuals:                      214
Method:                           MLE   Df Model:                           13
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.06588
Time:                        09:26:54   Log-Likelihood:                -114.36
converged:                       True   LL-Null:                       -122.42
Covariance Type:            nonrobust   LLR p-value:                    0.2421
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -0.8561      1.995     -0.429      0.668      -4.765       3.053
C(topic_grouped)[T.Geography]                 -0.4784      0.812     -0.589      0.556      -2.071       1.114
C(topic_grouped)[T.Misc]                       0.6678      0.649      1.029      0.303      -0.604       1.939
C(topic_grouped)[T.Music]                      0.9169      0.717      1.279      0.201      -0.488       2.322
C(topic_grouped)[T.Other]                      1.1829      0.634      1.864      0.062      -0.061       2.426
C(topic_grouped)[T.Politics]                   0.0705      0.637      0.111      0.912      -1.178       1.319
C(topic_grouped)[T.Science and technology]     0.3653      0.602      0.607      0.544      -0.815       1.545
C(topic_grouped)[T.Sports]                     0.6100      0.708      0.862      0.389      -0.777       1.997
C(answer_type_grouped)[T.Number]               0.6063      0.520      1.165      0.244      -0.413       1.626
C(answer_type_grouped)[T.Other]               -0.4509      0.442     -1.021      0.307      -1.316       0.414
C(answer_type_grouped)[T.Person]              -0.7707      0.455     -1.693      0.091      -1.663       0.122
C(answer_type_grouped)[T.Place]               -1.7486      1.092     -1.601      0.109      -3.890       0.392
q_length                                      -0.1070      0.441     -0.243      0.808      -0.971       0.757
game_entropy                                  -1.6065      4.904     -0.328      0.743     -11.219       8.006
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  228
Model:                          Logit   Df Residuals:                      213
Method:                           MLE   Df Model:                           14
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.08220
Time:                        09:26:54   Log-Likelihood:                -112.36
converged:                       True   LL-Null:                       -122.42
Covariance Type:            nonrobust   LLR p-value:                    0.1262
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.0317      2.019     -0.511      0.609      -4.989       2.926
C(topic_grouped)[T.Geography]                 -0.2177      0.842     -0.258      0.796      -1.868       1.433
C(topic_grouped)[T.Misc]                       0.9051      0.681      1.329      0.184      -0.429       2.239
C(topic_grouped)[T.Music]                      1.0955      0.738      1.484      0.138      -0.351       2.542
C(topic_grouped)[T.Other]                      1.3194      0.661      1.995      0.046       0.023       2.616
C(topic_grouped)[T.Politics]                   0.3207      0.668      0.480      0.631      -0.989       1.630
C(topic_grouped)[T.Science and technology]     0.5846      0.633      0.923      0.356      -0.657       1.826
C(topic_grouped)[T.Sports]                     0.8112      0.731      1.109      0.267      -0.622       2.245
C(answer_type_grouped)[T.Number]               0.6539      0.524      1.248      0.212      -0.373       1.681
C(answer_type_grouped)[T.Other]               -0.3889      0.444     -0.875      0.381      -1.260       0.482
C(answer_type_grouped)[T.Person]              -0.6999      0.458     -1.527      0.127      -1.598       0.198
C(answer_type_grouped)[T.Place]               -2.5756      1.501     -1.716      0.086      -5.517       0.366
q_length                                      -0.1316      0.446     -0.295      0.768      -1.006       0.743
capabilities_entropy                         138.7266     71.947      1.928      0.054      -2.287     279.740
game_entropy                                  -1.7523      4.936     -0.355      0.723     -11.426       7.921
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing gemini-2.5-flash-lite_think (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_neutral/gemini-2.5-flash-lite_think_SimpleMC_neut_redacted_temp1.0_1758205360_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    138
1    134
Name: count, dtype: int64

Answer change%: 0.4926 [0.43323334810380293, 0.552060769543256] (n=272)
P-value vs 25%: 1.199e-15; P-value vs 0%: 2.175e-59
Phase 2 self-accuracy: 0.4925 [0.4078891933262021, 0.5771854335394695] (n=134)
P-value vs 25%: 1.957e-08; P-value vs 33%: 0.0002208

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  272
Model:                          Logit   Df Residuals:                      270
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.01653
Time:                        09:26:54   Log-Likelihood:                -185.39
converged:                       True   LL-Null:                       -188.51
Covariance Type:            nonrobust   LLR p-value:                   0.01254
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept       2349.4658   1711.757      1.373      0.170   -1005.516    5704.448
p_i_capability -2349.6030   1711.817     -1.373      0.170   -5704.702    1005.496
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  272
Model:                          Logit   Df Residuals:                      270
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.01616
Time:                        09:26:54   Log-Likelihood:                -185.46
converged:                       True   LL-Null:                       -188.51
Covariance Type:            nonrobust   LLR p-value:                   0.01357
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -0.1319      0.135     -0.979      0.328      -0.396       0.132
capabilities_entropy   175.5986    127.838      1.374      0.170     -74.960     426.157
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.1600 [0.0957, 0.2243] (n=125)
                  P-value vs 33.3%: 1.249e-07

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=3.73, p=0.00029
Wilcoxon delta_p: statistic=639.00, p=4.39e-16
Mean Δp = 0.0001  [0.0000, 0.0001]
Idea 1 N = 125; 

  Idea 1.5: Calibration Metrics
  NLL: 12.1372, Signed ECE (overconf pos under neg): 0.0032, ECE: 0.0032 (n=94)
  Brier: 0.0005, Reliability (absolute calibration error; lower better): 0.0005, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=94)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       1.000
Model:                            OLS   Adj. R-squared:                  1.000
Method:                 Least Squares   F-statistic:                 1.266e+07
Date:                Sat, 20 Sep 2025   Prob (F-statistic):               0.00
Time:                        09:26:54   Log-Likelihood:                 931.11
No. Observations:                 166   AIC:                            -1854.
Df Residuals:                     162   BIC:                            -1842.
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.7378      1.306     -0.565      0.573      -3.317       1.841
p1                    0.7379      1.306      0.565      0.573      -1.841       3.317
answer_changed        0.7392      1.306      0.566      0.572      -1.840       3.318
p1:answer_changed     0.2603      1.306      0.199      0.842      -2.319       2.839
==============================================================================
Omnibus:                      306.200   Durbin-Watson:                   2.024
Prob(Omnibus):                  0.000   Jarque-Bera (JB):            71481.787
Skew:                          -9.153   Prob(JB):                         0.00
Kurtosis:                     102.998   Cond. No.                     5.49e+04
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The condition number is large, 5.49e+04. This might indicate that there are
strong multicollinearity or other numerical problems.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=1.75, p=0.0831
Wilcoxon delta_H: statistic=3182.00, p=0.0627
Mean ΔH = 0.0612  [-0.0074, 0.1298]
Paired t-test delta_H Changed: statistic=44.08, p=3.28e-77
Wilcoxon delta_H Changed: statistic=0.00, p=4.33e-22
Mean ΔH Changed = 1.2424  [1.1871, 1.2976]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=1.08, p=0.282
Wilcoxon (p_top2_game vs p_top2_base): statistic=5202.00, p=8.48e-20
Mean Δp_top2 = 0.0001  [-0.0001, 0.0003] (n=249)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=14.86, p=3.8e-36
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=3322.00, p=5.36e-27
Mean ΔH_unchosen_baseline_set = 0.6494  [0.5637, 0.7351] (n=249)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  249
Model:                          Logit   Df Residuals:                      246
Method:                           MLE   Df Model:                            2
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.01833
Time:                        09:26:54   Log-Likelihood:                -169.43
converged:                       True   LL-Null:                       -172.59
Covariance Type:            nonrobust   LLR p-value:                   0.04230
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept        3.3746      2.435      1.386      0.166      -1.397       8.147
p1_z           -37.3321     27.076     -1.379      0.168     -90.401      15.737
I(p1_z ** 2)    -3.0694     35.861     -0.086      0.932     -73.355      67.216
================================================================================
AUC = 0.562

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  272
Model:                          Logit   Df Residuals:                      270
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                0.009475
Time:                        09:26:54   Log-Likelihood:                -186.72
converged:                       True   LL-Null:                       -188.51
Covariance Type:            nonrobust   LLR p-value:                   0.05875
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.1087      0.130     -0.837      0.403      -0.363       0.146
game_entropy    41.6095     27.361      1.521      0.128     -12.018      95.237
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=5989.00, p=3.53e-22
Paired t-test (game_entropy vs capabilities_entropy): statistic=-1.01, p=0.311
Mean capabilities_entropy-game_entropy = 0.0040  [-0.0038, 0.0119] (n=272)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  272
Model:                          Logit   Df Residuals:                      269
Method:                           MLE   Df Model:                            2
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.02504
Time:                        09:26:54   Log-Likelihood:                -183.79
converged:                       True   LL-Null:                       -188.51
Covariance Type:            nonrobust   LLR p-value:                  0.008917
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -0.2024      0.141     -1.437      0.151      -0.478       0.074
capabilities_entropy   163.9768    125.868      1.303      0.193     -82.721     410.674
game_entropy            39.2402     26.450      1.484      0.138     -12.601      91.081
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     1                 0.526316
                        0                 0.473684
Geography               0                 0.500000
                        1                 0.500000
Misc                    1                 0.518519
                        0                 0.481481
Music                   1                 0.521739
                        0                 0.478261
Other                   0                 0.592593
                        1                 0.407407
Politics                0                 0.552632
                        1                 0.447368
Science and technology  1                 0.563636
                        0                 0.436364
Sports                  0                 0.545455
                        1                 0.454545
TV shows                0                 0.600000
                        1                 0.400000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 1                 0.531250
                     0                 0.468750
Number               1                 0.627451
                     0                 0.372549
Other                0                 0.661290
                     1                 0.338710
Person               0                 0.523810
                     1                 0.476190
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.363636  0.636364           11
                       Number               0.400000  0.600000            5
                       Other                0.571429  0.428571            7
                       Person               0.533333  0.466667           15
Geography              Date                 0.500000  0.500000           10
                       Number               0.400000  0.600000           10
                       Other                1.000000  0.000000            2
Misc                   Date                 0.428571  0.571429           14
                       Number               0.333333  0.666667            6
                       Other                1.000000  0.000000            5
                       Person               0.000000  1.000000            2
Music                  Date                 0.571429  0.428571            7
                       Number               0.000000  1.000000            4
                       Other                0.750000  0.250000            8
                       Person               0.250000  0.750000            4
Other                  Date                 0.333333  0.666667           12
                       Number               0.750000  0.250000            4
                       Other                0.833333  0.166667            6
                       Person               0.800000  0.200000            5
Politics               Date                 0.500000  0.500000           18
                       Number               0.500000  0.500000            4
                       Other                0.428571  0.571429            7
                       Person               0.777778  0.222222            9
Science and technology Date                 0.529412  0.470588           17
                       Number               0.222222  0.777778            9
                       Other                0.555556  0.444444            9
                       Person               0.400000  0.600000           20
Sports                 Date                 0.600000  0.400000            5
                       Number               0.375000  0.625000            8
                       Other                0.714286  0.285714            7
                       Person               0.500000  0.500000            2
TV shows               Date                 0.500000  0.500000            2
                       Number               1.000000  0.000000            1
                       Other                0.545455  0.454545           11
                       Person               0.666667  0.333333            6

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  272
Model:                          Logit   Df Residuals:                      259
Method:                           MLE   Df Model:                           12
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.04007
Time:                        09:26:54   Log-Likelihood:                -180.95
converged:                       True   LL-Null:                       -188.51
Covariance Type:            nonrobust   LLR p-value:                    0.2357
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.5802      1.689     -0.935      0.350      -4.891       1.731
C(topic_grouped)[T.Geography]                 -0.4012      0.572     -0.701      0.483      -1.523       0.720
C(topic_grouped)[T.Misc]                      -0.1894      0.526     -0.360      0.719      -1.220       0.841
C(topic_grouped)[T.Music]                      0.1036      0.553      0.187      0.851      -0.980       1.187
C(topic_grouped)[T.Other]                     -0.4760      0.528     -0.902      0.367      -1.511       0.558
C(topic_grouped)[T.Politics]                  -0.4679      0.481     -0.972      0.331      -1.411       0.476
C(topic_grouped)[T.Science and technology]     0.1337      0.433      0.309      0.758      -0.715       0.982
C(topic_grouped)[T.Sports]                    -0.3922      0.567     -0.692      0.489      -1.504       0.719
C(topic_grouped)[T.TV shows]                  -0.1410      0.585     -0.241      0.809      -1.287       1.005
C(answer_type_grouped)[T.Number]               0.4003      0.367      1.091      0.275      -0.319       1.119
C(answer_type_grouped)[T.Other]               -0.7866      0.357     -2.204      0.028      -1.486      -0.087
C(answer_type_grouped)[T.Person]              -0.2821      0.348     -0.810      0.418      -0.964       0.400
q_length                                       0.4198      0.359      1.168      0.243      -0.285       1.124
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.0062
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  272
Model:                          Logit   Df Residuals:                      258
Method:                           MLE   Df Model:                           13
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.06101
Time:                        09:26:54   Log-Likelihood:                -177.01
converged:                       True   LL-Null:                       -188.51
Covariance Type:            nonrobust   LLR p-value:                   0.04166
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.9576      1.711     -1.144      0.253      -5.312       1.397
C(topic_grouped)[T.Geography]                 -0.4236      0.588     -0.720      0.472      -1.577       0.729
C(topic_grouped)[T.Misc]                      -0.1419      0.533     -0.266      0.790      -1.187       0.903
C(topic_grouped)[T.Music]                      0.2405      0.561      0.429      0.668      -0.858       1.339
C(topic_grouped)[T.Other]                     -0.4352      0.536     -0.812      0.417      -1.486       0.616
C(topic_grouped)[T.Politics]                  -0.4026      0.488     -0.825      0.409      -1.359       0.553
C(topic_grouped)[T.Science and technology]     0.2108      0.441      0.478      0.633      -0.653       1.075
C(topic_grouped)[T.Sports]                    -0.3411      0.574     -0.595      0.552      -1.465       0.783
C(topic_grouped)[T.TV shows]                  -0.2472      0.606     -0.408      0.683      -1.435       0.941
C(answer_type_grouped)[T.Number]               0.3882      0.369      1.051      0.293      -0.336       1.112
C(answer_type_grouped)[T.Other]               -0.8355      0.362     -2.309      0.021      -1.545      -0.126
C(answer_type_grouped)[T.Person]              -0.3374      0.353     -0.956      0.339      -1.029       0.354
q_length                                       0.4716      0.362      1.301      0.193      -0.239       1.182
capabilities_entropy                         228.1987    140.406      1.625      0.104     -46.992     503.390
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  272
Model:                          Logit   Df Residuals:                      258
Method:                           MLE   Df Model:                           13
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.05017
Time:                        09:26:54   Log-Likelihood:                -179.05
converged:                       True   LL-Null:                       -188.51
Covariance Type:            nonrobust   LLR p-value:                    0.1258
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.5624      1.703     -0.918      0.359      -4.900       1.775
C(topic_grouped)[T.Geography]                 -0.3787      0.573     -0.660      0.509      -1.503       0.745
C(topic_grouped)[T.Misc]                      -0.1394      0.526     -0.265      0.791      -1.171       0.892
C(topic_grouped)[T.Music]                      0.1243      0.552      0.225      0.822      -0.958       1.206
C(topic_grouped)[T.Other]                     -0.5458      0.535     -1.020      0.308      -1.594       0.503
C(topic_grouped)[T.Politics]                  -0.4082      0.482     -0.847      0.397      -1.352       0.536
C(topic_grouped)[T.Science and technology]     0.1232      0.434      0.284      0.777      -0.728       0.974
C(topic_grouped)[T.Sports]                    -0.5068      0.575     -0.882      0.378      -1.633       0.620
C(topic_grouped)[T.TV shows]                  -0.2380      0.601     -0.396      0.692      -1.415       0.939
C(answer_type_grouped)[T.Number]               0.4738      0.371      1.275      0.202      -0.254       1.202
C(answer_type_grouped)[T.Other]               -0.7348      0.360     -2.040      0.041      -1.441      -0.029
C(answer_type_grouped)[T.Person]              -0.2488      0.351     -0.709      0.478      -0.936       0.439
q_length                                       0.3905      0.362      1.078      0.281      -0.320       1.100
game_entropy                                  48.3811     31.400      1.541      0.123     -13.162     109.924
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  272
Model:                          Logit   Df Residuals:                      257
Method:                           MLE   Df Model:                           14
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.07029
Time:                        09:26:54   Log-Likelihood:                -175.26
converged:                       True   LL-Null:                       -188.51
Covariance Type:            nonrobust   LLR p-value:                   0.02234
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.9167      1.724     -1.112      0.266      -5.297       1.463
C(topic_grouped)[T.Geography]                 -0.3990      0.589     -0.677      0.498      -1.554       0.756
C(topic_grouped)[T.Misc]                      -0.0926      0.533     -0.174      0.862      -1.137       0.952
C(topic_grouped)[T.Music]                      0.2552      0.559      0.457      0.648      -0.841       1.351
C(topic_grouped)[T.Other]                     -0.5000      0.542     -0.923      0.356      -1.562       0.562
C(topic_grouped)[T.Politics]                  -0.3454      0.487     -0.709      0.478      -1.301       0.610
C(topic_grouped)[T.Science and technology]     0.2002      0.441      0.454      0.650      -0.665       1.065
C(topic_grouped)[T.Sports]                    -0.4408      0.582     -0.757      0.449      -1.581       0.700
C(topic_grouped)[T.TV shows]                  -0.3672      0.625     -0.588      0.557      -1.592       0.857
C(answer_type_grouped)[T.Number]               0.4598      0.374      1.230      0.219      -0.273       1.193
C(answer_type_grouped)[T.Other]               -0.7780      0.365     -2.131      0.033      -1.494      -0.062
C(answer_type_grouped)[T.Person]              -0.2949      0.355     -0.831      0.406      -0.991       0.401
q_length                                       0.4394      0.365      1.203      0.229      -0.276       1.155
capabilities_entropy                         212.1099    139.786      1.517      0.129     -61.866     486.086
game_entropy                                  43.8334     29.595      1.481      0.139     -14.171     101.838
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing gemini-2.5-flash-preview-04-17 (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_neutral/gemini-2.5-flash-preview-04-17_SimpleMC_redacted_cor_temp0.0_1751845050_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    288
1     47
Name: count, dtype: int64

Answer change%: 0.1403 [0.10310851817082055, 0.17748849675455258] (n=335)
P-value vs 25%: 7.407e-09; P-value vs 0%: 1.426e-13
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=47)
P-value vs 25%: 0; P-value vs 33%: 0

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  335
Model:                          Logit   Df Residuals:                      333
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.02297
Time:                        09:26:54   Log-Likelihood:                -132.72
converged:                       True   LL-Null:                       -135.84
Covariance Type:            nonrobust   LLR p-value:                   0.01248
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.9690      0.173    -11.351      0.000      -2.309      -1.629
game_entropy   406.5528    170.056      2.391      0.017      73.249     739.856
================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['Music', 'History', 'TV shows', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': None
topic_grouped           answer_changed
Art                     0                 0.859649
                        1                 0.140351
Geography               0                 0.903226
                        1                 0.096774
Misc                    0                 0.868852
                        1                 0.131148
Other                   0                 0.837838
                        1                 0.162162
Politics                0                 0.928571
                        1                 0.071429
Science and technology  0                 0.815385
                        1                 0.184615
Sports                  0                 0.785714
                        1                 0.214286
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.904348
                     1                 0.095652
Number               0                 0.790698
                     1                 0.209302
Other                0                 0.838235
                     1                 0.161765
Person               0                 0.837209
                     1                 0.162791
Place                0                 0.913043
                     1                 0.086957
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.941176  0.058824           17
                       Number               0.571429  0.428571            7
                       Other                0.777778  0.222222            9
                       Person               0.894737  0.105263           19
                       Place                1.000000  0.000000            5
Geography              Date                 1.000000  0.000000           10
                       Number               0.818182  0.181818           11
                       Other                1.000000  0.000000            3
                       Place                0.857143  0.142857            7
Misc                   Date                 0.894737  0.105263           19
                       Number               1.000000  0.000000            6
                       Other                0.750000  0.250000           16
                       Person               0.894737  0.105263           19
                       Place                1.000000  0.000000            1
Other                  Date                 0.818182  0.181818           11
                       Number               1.000000  0.000000            3
                       Other                1.000000  0.000000            8
                       Person               0.727273  0.272727           11
                       Place                0.750000  0.250000            4
Politics               Date                 0.920000  0.080000           25
                       Number               1.000000  0.000000            4
                       Other                0.909091  0.090909           11
                       Person               0.909091  0.090909           11
                       Place                1.000000  0.000000            5
Science and technology Date                 0.958333  0.041667           24
                       Number               0.571429  0.428571            7
                       Other                0.833333  0.166667           12
                       Person               0.714286  0.285714           21
                       Place                1.000000  0.000000            1
Sports                 Date                 0.666667  0.333333            9
                       Number               0.800000  0.200000            5
                       Other                0.777778  0.222222            9
                       Person               1.000000  0.000000            5

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  335
Model:                          Logit   Df Residuals:                      323
Method:                           MLE   Df Model:                           11
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.03565
Time:                        09:26:54   Log-Likelihood:                -131.00
converged:                       True   LL-Null:                       -135.84
Covariance Type:            nonrobust   LLR p-value:                    0.5588
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.3973      2.065     -0.677      0.499      -5.444       2.650
C(topic_grouped)[T.Geography]                 -0.4958      0.750     -0.661      0.508      -1.966       0.974
C(topic_grouped)[T.Misc]                      -0.0868      0.544     -0.159      0.873      -1.153       0.980
C(topic_grouped)[T.Other]                      0.2015      0.592      0.340      0.734      -0.959       1.362
C(topic_grouped)[T.Politics]                  -0.6141      0.658     -0.933      0.351      -1.904       0.676
C(topic_grouped)[T.Science and technology]     0.3644      0.506      0.720      0.472      -0.628       1.356
C(topic_grouped)[T.Sports]                     0.4728      0.610      0.775      0.438      -0.723       1.669
C(answer_type_grouped)[T.Number]               0.9687      0.512      1.893      0.058      -0.034       1.972
C(answer_type_grouped)[T.Other]                0.5379      0.464      1.160      0.246      -0.371       1.447
C(answer_type_grouped)[T.Person]               0.5231      0.438      1.194      0.232      -0.336       1.382
C(answer_type_grouped)[T.Place]                0.0906      0.827      0.110      0.913      -1.531       1.712
q_length                                      -0.1889      0.454     -0.416      0.677      -1.079       0.701
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  335
Model:                          Logit   Df Residuals:                      322
Method:                           MLE   Df Model:                           12
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.06304
Time:                        09:26:54   Log-Likelihood:                -127.28
converged:                       True   LL-Null:                       -135.84
Covariance Type:            nonrobust   LLR p-value:                    0.1449
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.5162      2.102     -0.721      0.471      -5.636       2.604
C(topic_grouped)[T.Geography]                 -0.4083      0.758     -0.538      0.590      -1.895       1.078
C(topic_grouped)[T.Misc]                      -0.2075      0.571     -0.363      0.716      -1.327       0.912
C(topic_grouped)[T.Other]                      0.3102      0.601      0.516      0.606      -0.868       1.488
C(topic_grouped)[T.Politics]                  -0.5510      0.666     -0.827      0.408      -1.856       0.754
C(topic_grouped)[T.Science and technology]     0.4746      0.516      0.920      0.357      -0.536       1.485
C(topic_grouped)[T.Sports]                     0.4896      0.620      0.790      0.430      -0.726       1.705
C(answer_type_grouped)[T.Number]               1.0675      0.521      2.050      0.040       0.047       2.088
C(answer_type_grouped)[T.Other]                0.4532      0.480      0.944      0.345      -0.488       1.395
C(answer_type_grouped)[T.Person]               0.6368      0.447      1.425      0.154      -0.239       1.513
C(answer_type_grouped)[T.Place]                0.1405      0.834      0.169      0.866      -1.493       1.774
q_length                                      -0.2176      0.463     -0.470      0.638      -1.125       0.690
game_entropy                                 470.2804    182.696      2.574      0.010     112.202     828.359
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing gemini-2.5-flash-preview-04-17 (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_neutral/gemini-2.5-flash-preview-04-17_SimpleMC_redacted_temp0.0_1751839721_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    86
1    79
Name: count, dtype: int64

Answer change%: 0.4788 [0.40256507041902645, 0.5550106871567311] (n=165)
P-value vs 25%: 4.03e-09; P-value vs 0%: 7.868e-35
Phase 2 self-accuracy: 0.6709 [0.5672688257264862, 0.774503326172248] (n=79)
P-value vs 25%: 1.703e-15; P-value vs 33%: 1.645e-10

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  165
Model:                          Logit   Df Residuals:                      163
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                0.008473
Time:                        09:26:54   Log-Likelihood:                -113.25
converged:                       True   LL-Null:                       -114.22
Covariance Type:            nonrobust   LLR p-value:                    0.1642
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.1647      0.173     -0.951      0.342      -0.504       0.175
game_entropy   186.9246    205.488      0.910      0.363    -215.824     589.673
================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['Video games', 'History']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.500000
                        1                 0.500000
Geography               1                 0.538462
                        0                 0.461538
Misc                    1                 0.600000
                        0                 0.400000
Music                   0                 0.666667
                        1                 0.333333
Other                   0                 0.666667
                        1                 0.333333
Politics                1                 0.523810
                        0                 0.476190
Science and technology  0                 0.515152
                        1                 0.484848
Sports                  1                 0.583333
                        0                 0.416667
TV shows                0                 0.600000
                        1                 0.400000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 1                 0.555556
                     0                 0.444444
Number               0                 0.514286
                     1                 0.485714
Other                0                 0.619048
                     1                 0.380952
Person               0                 0.529412
                     1                 0.470588
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.500000  0.500000            4
                       Number               0.500000  0.500000            2
                       Other                0.500000  0.500000            4
                       Person               0.500000  0.500000            8
Geography              Date                 0.200000  0.800000            5
                       Number               0.571429  0.428571            7
                       Other                1.000000  0.000000            1
Misc                   Date                 0.333333  0.666667            9
                       Number               0.333333  0.666667            3
                       Other                0.500000  0.500000            6
                       Person               0.500000  0.500000            2
Music                  Date                 0.800000  0.200000            5
                       Number               0.333333  0.666667            3
                       Other                0.714286  0.285714            7
                       Person               0.666667  0.333333            3
Other                  Date                 0.571429  0.428571            7
                       Number               0.750000  0.250000            4
                       Other                0.500000  0.500000            2
                       Person               1.000000  0.000000            2
Politics               Date                 0.272727  0.727273           11
                       Number               1.000000  0.000000            2
                       Other                1.000000  0.000000            4
                       Person               0.250000  0.750000            4
Science and technology Date                 0.545455  0.454545           11
                       Number               0.428571  0.571429            7
                       Other                0.666667  0.333333            6
                       Person               0.444444  0.555556            9
Sports                 Number               0.500000  0.500000            6
                       Other                0.333333  0.666667            3
                       Person               0.333333  0.666667            3
TV shows               Date                 0.500000  0.500000            2
                       Number               0.000000  1.000000            1
                       Other                0.555556  0.444444            9
                       Person               1.000000  0.000000            3

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  165
Model:                          Logit   Df Residuals:                      152
Method:                           MLE   Df Model:                           12
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.04248
Time:                        09:26:54   Log-Likelihood:                -109.37
converged:                       True   LL-Null:                       -114.22
Covariance Type:            nonrobust   LLR p-value:                    0.6420
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      2.8798      2.065      1.394      0.163      -1.168       6.928
C(topic_grouped)[T.Geography]                 -0.0352      0.779     -0.045      0.964      -1.562       1.492
C(topic_grouped)[T.Misc]                       0.3934      0.681      0.578      0.563      -0.941       1.728
C(topic_grouped)[T.Music]                     -0.7946      0.712     -1.117      0.264      -2.189       0.600
C(topic_grouped)[T.Other]                     -0.9402      0.752     -1.250      0.211      -2.414       0.534
C(topic_grouped)[T.Politics]                  -0.0142      0.664     -0.021      0.983      -1.315       1.286
C(topic_grouped)[T.Science and technology]    -0.1266      0.599     -0.211      0.833      -1.300       1.047
C(topic_grouped)[T.Sports]                     0.4156      0.780      0.533      0.594      -1.113       1.944
C(topic_grouped)[T.TV shows]                  -0.3439      0.734     -0.468      0.639      -1.783       1.095
C(answer_type_grouped)[T.Number]              -0.4011      0.471     -0.853      0.394      -1.323       0.521
C(answer_type_grouped)[T.Other]               -0.8191      0.457     -1.791      0.073      -1.716       0.077
C(answer_type_grouped)[T.Person]              -0.4716      0.474     -0.996      0.319      -1.400       0.457
q_length                                      -0.5354      0.425     -1.259      0.208      -1.369       0.298
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  165
Model:                          Logit   Df Residuals:                      151
Method:                           MLE   Df Model:                           13
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.05676
Time:                        09:26:54   Log-Likelihood:                -107.74
converged:                       True   LL-Null:                       -114.22
Covariance Type:            nonrobust   LLR p-value:                    0.4505
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      2.8907      2.080      1.390      0.165      -1.186       6.967
C(topic_grouped)[T.Geography]                 -0.0462      0.780     -0.059      0.953      -1.576       1.483
C(topic_grouped)[T.Misc]                       0.3493      0.684      0.511      0.609      -0.990       1.689
C(topic_grouped)[T.Music]                     -0.7847      0.713     -1.101      0.271      -2.182       0.612
C(topic_grouped)[T.Other]                     -1.0518      0.762     -1.381      0.167      -2.545       0.441
C(topic_grouped)[T.Politics]                  -0.0345      0.666     -0.052      0.959      -1.339       1.270
C(topic_grouped)[T.Science and technology]    -0.1261      0.600     -0.210      0.833      -1.302       1.050
C(topic_grouped)[T.Sports]                     0.4134      0.781      0.529      0.597      -1.117       1.944
C(topic_grouped)[T.TV shows]                  -0.6098      0.771     -0.791      0.429      -2.121       0.901
C(answer_type_grouped)[T.Number]              -0.3891      0.473     -0.822      0.411      -1.317       0.539
C(answer_type_grouped)[T.Other]               -0.8896      0.462     -1.924      0.054      -1.796       0.017
C(answer_type_grouped)[T.Person]              -0.4626      0.476     -0.971      0.331      -1.396       0.471
q_length                                      -0.5525      0.430     -1.286      0.199      -1.395       0.290
game_entropy                                 286.6064    243.881      1.175      0.240    -191.392     764.604
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing gemini-2.5-flash_nothink (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_neutral/gemini-2.5-flash_nothink_SimpleMC_neut_redacted_cor_temp1.0_1757984952_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    185
1     68
Name: count, dtype: int64

Answer change%: 0.2688 [0.21414766844092456, 0.3234017386736999] (n=253)
P-value vs 25%: 0.5006; P-value vs 0%: 5.244e-22
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=68)
P-value vs 25%: 0; P-value vs 33%: 0

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  253
Model:                          Logit   Df Residuals:                      251
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.2005
Time:                        09:26:54   Log-Likelihood:                -117.73
converged:                       True   LL-Null:                       -147.26
Covariance Type:            nonrobust   LLR p-value:                 1.542e-14
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          2.6629      0.522      5.098      0.000       1.639       3.687
p_i_capability    -5.0741      0.730     -6.950      0.000      -6.505      -3.643
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  253
Model:                          Logit   Df Residuals:                      251
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1873
Time:                        09:26:54   Log-Likelihood:                -119.67
converged:                       True   LL-Null:                       -147.26
Covariance Type:            nonrobust   LLR p-value:                 1.102e-13
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.6661      0.332     -8.034      0.000      -3.317      -2.016
capabilities_entropy     1.7118      0.259      6.601      0.000       1.204       2.220
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.5735 [0.4560, 0.6911] (n=68)
                  P-value vs 33.3%: 6.203e-05

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=2.10, p=0.0374
Wilcoxon delta_p: statistic=7032.00, p=0.0313
Mean Δp = 0.0216  [0.0014, 0.0419]
Idea 1 N = 185; 

  Idea 1.5: Calibration Metrics
  NLL: 0.3101, Signed ECE (overconf pos under neg): -0.2264, ECE: 0.2264 (n=253)
  Brier: 0.1025, Reliability (absolute calibration error; lower better): 0.1017, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=253)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.685
Model:                            OLS   Adj. R-squared:                  0.681
Method:                 Least Squares   F-statistic:                     179.5
Date:                Sat, 20 Sep 2025   Prob (F-statistic):           7.41e-62
Time:                        09:26:54   Log-Likelihood:                 156.79
No. Observations:                 252   AIC:                            -305.6
Df Residuals:                     248   BIC:                            -291.5
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.1362      0.044     -3.117      0.002      -0.222      -0.050
p1                    0.1880      0.051      3.704      0.000       0.088       0.288
answer_changed       -0.0504      0.063     -0.796      0.427      -0.175       0.074
p1:answer_changed     0.7554      0.088      8.550      0.000       0.581       0.929
==============================================================================
Omnibus:                       33.033   Durbin-Watson:                   1.947
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               46.744
Skew:                           0.824   Prob(JB):                     7.08e-11
Kurtosis:                       4.318   Cond. No.                         18.5
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=1.70, p=0.0902
Wilcoxon delta_H: statistic=7558.00, p=0.152
Mean ΔH = 0.0619  [-0.0093, 0.1332]
Paired t-test delta_H Changed: statistic=5.74, p=2.53e-07
Wilcoxon delta_H Changed: statistic=382.00, p=1.34e-06
Mean ΔH Changed = 0.2629  [0.1731, 0.3527]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=-2.51, p=0.0127
Wilcoxon (p_top2_game vs p_top2_base): statistic=11909.00, p=0.000361
Mean Δp_top2 = -0.0130  [-0.0231, -0.0028] (n=253)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=3.89, p=0.000127
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=11790.00, p=0.000243
Mean ΔH_unchosen_baseline_set = 0.1159  [0.0576, 0.1743] (n=253)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  253
Model:                          Logit   Df Residuals:                      250
Method:                           MLE   Df Model:                            2
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.2006
Time:                        09:26:54   Log-Likelihood:                -117.72
converged:                       True   LL-Null:                       -147.26
Covariance Type:            nonrobust   LLR p-value:                 1.489e-13
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.2907      0.248     -5.200      0.000      -1.777      -0.804
p1_z            -1.1209      0.234     -4.782      0.000      -1.580      -0.661
I(p1_z ** 2)     0.0350      0.214      0.164      0.870      -0.384       0.454
================================================================================
AUC = 0.806

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  253
Model:                          Logit   Df Residuals:                      251
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.2229
Time:                        09:26:54   Log-Likelihood:                -114.44
converged:                       True   LL-Null:                       -147.26
Covariance Type:            nonrobust   LLR p-value:                 5.435e-16
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -3.1786      0.407     -7.816      0.000      -3.976      -2.382
game_entropy     2.0513      0.302      6.801      0.000       1.460       2.642
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=14229.00, p=0.115
Paired t-test (game_entropy vs capabilities_entropy): statistic=2.13, p=0.0343
Mean capabilities_entropy-game_entropy = -0.0617  [-0.1184, -0.0049] (n=253)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  253
Model:                          Logit   Df Residuals:                      250
Method:                           MLE   Df Model:                            2
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.2415
Time:                        09:26:54   Log-Likelihood:                -111.70
converged:                       True   LL-Null:                       -147.26
Covariance Type:            nonrobust   LLR p-value:                 3.604e-16
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -3.3636      0.426     -7.898      0.000      -4.198      -2.529
capabilities_entropy     0.7836      0.339      2.313      0.021       0.120       1.448
game_entropy             1.4986      0.383      3.909      0.000       0.747       2.250
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': None
topic_grouped           answer_changed
Art                     0                 0.860465
                        1                 0.139535
Geography               0                 0.619048
                        1                 0.380952
Misc                    0                 0.638889
                        1                 0.361111
Music                   0                 0.722222
                        1                 0.277778
Other                   0                 0.720000
                        1                 0.280000
Politics                0                 0.738095
                        1                 0.261905
Science and technology  0                 0.739130
                        1                 0.260870
Sports                  0                 0.727273
                        1                 0.272727
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.662791
                     1                 0.337209
Number               0                 0.611111
                     1                 0.388889
Other                0                 0.816327
                     1                 0.183673
Person               0                 0.819672
                     1                 0.180328
Place                0                 0.761905
                     1                 0.238095
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.900000  0.100000           10
                       Number               0.500000  0.500000            4
                       Other                0.750000  0.250000            8
                       Person               0.937500  0.062500           16
                       Place                1.000000  0.000000            5
Geography              Date                 0.333333  0.666667            6
                       Number               0.666667  0.333333            6
                       Other                0.666667  0.333333            3
                       Place                0.833333  0.166667            6
Misc                   Date                 0.600000  0.400000           10
                       Number               0.571429  0.428571            7
                       Other                0.700000  0.300000           10
                       Person               0.625000  0.375000            8
                       Place                1.000000  0.000000            1
Music                  Date                 0.714286  0.285714            7
                       Number               1.000000  0.000000            1
                       Other                0.666667  0.333333            3
                       Person               0.714286  0.285714            7
Other                  Date                 0.625000  0.375000            8
                       Number               0.666667  0.333333            3
                       Other                1.000000  0.000000            3
                       Person               1.000000  0.000000            7
                       Place                0.250000  0.750000            4
Politics               Date                 0.619048  0.380952           21
                       Number               0.333333  0.666667            3
                       Other                1.000000  0.000000            6
                       Person               0.875000  0.125000            8
                       Place                1.000000  0.000000            4
Science and technology Date                 0.800000  0.200000           20
                       Number               0.600000  0.400000            5
                       Other                0.800000  0.200000           10
                       Person               0.700000  0.300000           10
                       Place                0.000000  1.000000            1
Sports                 Date                 0.250000  0.750000            4
                       Number               0.714286  0.285714            7
                       Other                1.000000  0.000000            6
                       Person               0.800000  0.200000            5

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  253
Model:                          Logit   Df Residuals:                      240
Method:                           MLE   Df Model:                           12
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.06176
Time:                        09:26:54   Log-Likelihood:                -138.16
converged:                       True   LL-Null:                       -147.26
Covariance Type:            nonrobust   LLR p-value:                    0.1101
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      2.0568      1.890      1.088      0.276      -1.648       5.761
C(topic_grouped)[T.Geography]                  0.9909      0.658      1.506      0.132      -0.299       2.280
C(topic_grouped)[T.Misc]                       1.1664      0.576      2.026      0.043       0.038       2.295
C(topic_grouped)[T.Music]                      0.8202      0.702      1.168      0.243      -0.556       2.196
C(topic_grouped)[T.Other]                      0.8314      0.640      1.299      0.194      -0.423       2.086
C(topic_grouped)[T.Politics]                   0.8309      0.587      1.415      0.157      -0.320       1.982
C(topic_grouped)[T.Science and technology]     0.7727      0.574      1.346      0.178      -0.352       1.898
C(topic_grouped)[T.Sports]                     0.6704      0.673      0.997      0.319      -0.648       1.989
C(answer_type_grouped)[T.Number]               0.1740      0.438      0.398      0.691      -0.684       1.032
C(answer_type_grouped)[T.Other]               -0.9232      0.448     -2.061      0.039      -1.801      -0.045
C(answer_type_grouped)[T.Person]              -0.8379      0.420     -1.994      0.046      -1.661      -0.014
C(answer_type_grouped)[T.Place]               -0.4107      0.600     -0.685      0.494      -1.586       0.765
q_length                                      -0.7655      0.408     -1.878      0.060      -1.564       0.033
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.8057
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  253
Model:                          Logit   Df Residuals:                      239
Method:                           MLE   Df Model:                           13
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.2235
Time:                        09:26:54   Log-Likelihood:                -114.34
converged:                       True   LL-Null:                       -147.26
Covariance Type:            nonrobust   LLR p-value:                 4.661e-09
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      0.9376      2.118      0.443      0.658      -3.214       5.090
C(topic_grouped)[T.Geography]                  1.1031      0.722      1.527      0.127      -0.313       2.519
C(topic_grouped)[T.Misc]                       1.1854      0.623      1.904      0.057      -0.035       2.406
C(topic_grouped)[T.Music]                      1.2232      0.794      1.541      0.123      -0.332       2.779
C(topic_grouped)[T.Other]                      0.7893      0.702      1.125      0.261      -0.586       2.165
C(topic_grouped)[T.Politics]                   1.1639      0.649      1.792      0.073      -0.109       2.437
C(topic_grouped)[T.Science and technology]     1.0688      0.625      1.710      0.087      -0.157       2.294
C(topic_grouped)[T.Sports]                     0.8204      0.746      1.099      0.272      -0.642       2.283
C(answer_type_grouped)[T.Number]               0.2089      0.492      0.425      0.671      -0.755       1.173
C(answer_type_grouped)[T.Other]               -0.2647      0.513     -0.516      0.606      -1.269       0.740
C(answer_type_grouped)[T.Person]               0.0182      0.483      0.038      0.970      -0.928       0.965
C(answer_type_grouped)[T.Place]                0.0843      0.640      0.132      0.895      -1.171       1.340
q_length                                      -1.0077      0.463     -2.176      0.030      -1.916      -0.100
capabilities_entropy                           1.7565      0.286      6.151      0.000       1.197       2.316
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  253
Model:                          Logit   Df Residuals:                      239
Method:                           MLE   Df Model:                           13
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.2587
Time:                        09:26:54   Log-Likelihood:                -109.16
converged:                       True   LL-Null:                       -147.26
Covariance Type:            nonrobust   LLR p-value:                 5.706e-11
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      0.2740      2.198      0.125      0.901      -4.033       4.581
C(topic_grouped)[T.Geography]                  1.3141      0.754      1.742      0.081      -0.164       2.792
C(topic_grouped)[T.Misc]                       1.2115      0.652      1.859      0.063      -0.066       2.489
C(topic_grouped)[T.Music]                      0.9185      0.823      1.116      0.264      -0.695       2.532
C(topic_grouped)[T.Other]                      0.6773      0.723      0.937      0.349      -0.739       2.094
C(topic_grouped)[T.Politics]                   0.9074      0.664      1.367      0.172      -0.394       2.209
C(topic_grouped)[T.Science and technology]     0.8401      0.654      1.284      0.199      -0.442       2.122
C(topic_grouped)[T.Sports]                     0.8535      0.770      1.109      0.268      -0.655       2.362
C(answer_type_grouped)[T.Number]              -0.0743      0.485     -0.153      0.878      -1.025       0.876
C(answer_type_grouped)[T.Other]                0.1236      0.553      0.224      0.823      -0.959       1.207
C(answer_type_grouped)[T.Person]               0.1499      0.511      0.293      0.769      -0.852       1.152
C(answer_type_grouped)[T.Place]                0.2264      0.695      0.326      0.744      -1.135       1.588
q_length                                      -1.0058      0.473     -2.127      0.033      -1.933      -0.079
game_entropy                                   2.2324      0.352      6.334      0.000       1.542       2.923
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  253
Model:                          Logit   Df Residuals:                      238
Method:                           MLE   Df Model:                           14
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.2795
Time:                        09:26:54   Log-Likelihood:                -106.09
converged:                       True   LL-Null:                       -147.26
Covariance Type:            nonrobust   LLR p-value:                 1.046e-11
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      0.2033      2.235      0.091      0.928      -4.178       4.585
C(topic_grouped)[T.Geography]                  1.2936      0.762      1.697      0.090      -0.200       2.788
C(topic_grouped)[T.Misc]                       1.2362      0.659      1.876      0.061      -0.055       2.528
C(topic_grouped)[T.Music]                      1.0842      0.845      1.283      0.200      -0.572       2.741
C(topic_grouped)[T.Other]                      0.7575      0.725      1.045      0.296      -0.663       2.178
C(topic_grouped)[T.Politics]                   1.1058      0.678      1.632      0.103      -0.222       2.434
C(topic_grouped)[T.Science and technology]     0.9801      0.666      1.471      0.141      -0.326       2.286
C(topic_grouped)[T.Sports]                     0.9339      0.782      1.194      0.232      -0.599       2.467
C(answer_type_grouped)[T.Number]               0.0210      0.503      0.042      0.967      -0.966       1.008
C(answer_type_grouped)[T.Other]                0.1713      0.565      0.303      0.762      -0.937       1.279
C(answer_type_grouped)[T.Person]               0.3440      0.519      0.663      0.507      -0.673       1.361
C(answer_type_grouped)[T.Place]                0.3535      0.677      0.522      0.601      -0.973       1.680
q_length                                      -1.0808      0.484     -2.235      0.025      -2.029      -0.133
capabilities_entropy                           0.8728      0.357      2.444      0.015       0.173       1.573
game_entropy                                   1.6501      0.422      3.908      0.000       0.822       2.478
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing gemini-2.5-flash_nothink (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_neutral/gemini-2.5-flash_nothink_SimpleMC_neut_redacted_temp1.0_1757984766_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    162
1     85
Name: count, dtype: int64

Answer change%: 0.3441 [0.28488210900308925, 0.4033770003086516] (n=247)
P-value vs 25%: 0.001846; P-value vs 0%: 5.016e-30
Phase 2 self-accuracy: 0.5176 [0.411419312192355, 0.6238748054547039] (n=85)
P-value vs 25%: 7.883e-07; P-value vs 33%: 0.0006572

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  247
Model:                          Logit   Df Residuals:                      245
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.07233
Time:                        09:26:54   Log-Likelihood:                -147.50
converged:                       True   LL-Null:                       -159.00
Covariance Type:            nonrobust   LLR p-value:                 1.620e-06
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          1.4996      0.481      3.120      0.002       0.558       2.442
p_i_capability    -3.4521      0.768     -4.497      0.000      -4.957      -1.948
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  247
Model:                          Logit   Df Residuals:                      245
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.05691
Time:                        09:26:54   Log-Likelihood:                -149.95
converged:                       True   LL-Null:                       -159.00
Covariance Type:            nonrobust   LLR p-value:                 2.099e-05
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.1282      0.417     -5.100      0.000      -2.946      -1.310
capabilities_entropy     1.1685      0.296      3.945      0.000       0.588       1.749
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.6235 [0.5205, 0.7265] (n=85)
                  P-value vs 33.3%: 3.349e-08

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=0.51, p=0.611
Wilcoxon delta_p: statistic=6204.00, p=0.506
Mean Δp = 0.0075  [-0.0214, 0.0365]
Idea 1 N = 162; 

  Idea 1.5: Calibration Metrics
  NLL: 2.4472, Signed ECE (overconf pos under neg): 0.1591, ECE: 0.1591 (n=247)
  Brier: 0.0398, Reliability (absolute calibration error; lower better): 0.0390, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=247)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.632
Model:                            OLS   Adj. R-squared:                  0.628
Method:                 Least Squares   F-statistic:                     138.6
Date:                Sat, 20 Sep 2025   Prob (F-statistic):           2.77e-52
Time:                        09:26:54   Log-Likelihood:                 106.79
No. Observations:                 246   AIC:                            -205.6
Df Residuals:                     242   BIC:                            -191.6
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.2168      0.044     -4.916      0.000      -0.304      -0.130
p1                    0.3267      0.062      5.302      0.000       0.205       0.448
answer_changed        0.0106      0.074      0.142      0.887      -0.136       0.157
p1:answer_changed     0.6914      0.119      5.809      0.000       0.457       0.926
==============================================================================
Omnibus:                        0.306   Durbin-Watson:                   1.939
Prob(Omnibus):                  0.858   Jarque-Bera (JB):                0.224
Skew:                           0.073   Prob(JB):                        0.894
Kurtosis:                       3.015   Cond. No.                         18.4
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-2.33, p=0.0208
Wilcoxon delta_H: statistic=4890.00, p=0.00421
Mean ΔH = -0.0715  [-0.1316, -0.0115]
Paired t-test delta_H Changed: statistic=5.43, p=5.38e-07
Wilcoxon delta_H Changed: statistic=769.00, p=3.52e-06
Mean ΔH Changed = 0.2225  [0.1422, 0.3028]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=-2.82, p=0.00523
Wilcoxon (p_top2_game vs p_top2_base): statistic=12431.00, p=0.0103
Mean Δp_top2 = -0.0180  [-0.0306, -0.0055] (n=247)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=1.14, p=0.257
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=14552.00, p=0.498
Mean ΔH_unchosen_baseline_set = 0.0296  [-0.0215, 0.0807] (n=247)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  247
Model:                          Logit   Df Residuals:                      244
Method:                           MLE   Df Model:                            2
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.07310
Time:                        09:26:54   Log-Likelihood:                -147.38
converged:                       True   LL-Null:                       -159.00
Covariance Type:            nonrobust   LLR p-value:                 8.962e-06
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.6493      0.206     -3.157      0.002      -1.052      -0.246
p1_z            -0.6873      0.156     -4.397      0.000      -0.994      -0.381
I(p1_z ** 2)    -0.0824      0.167     -0.492      0.622      -0.410       0.246
================================================================================
AUC = 0.679

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  247
Model:                          Logit   Df Residuals:                      245
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.03549
Time:                        09:26:54   Log-Likelihood:                -153.36
converged:                       True   LL-Null:                       -159.00
Covariance Type:            nonrobust   LLR p-value:                 0.0007809
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.6687      0.357     -4.675      0.000      -2.368      -0.969
game_entropy     0.8251      0.256      3.225      0.001       0.324       1.327
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=15050.00, p=0.814
Paired t-test (game_entropy vs capabilities_entropy): statistic=-0.55, p=0.586
Mean capabilities_entropy-game_entropy = 0.0164  [-0.0425, 0.0753] (n=247)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  247
Model:                          Logit   Df Residuals:                      244
Method:                           MLE   Df Model:                            2
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.05942
Time:                        09:26:54   Log-Likelihood:                -149.55
converged:                       True   LL-Null:                       -159.00
Covariance Type:            nonrobust   LLR p-value:                 7.879e-05
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.2391      0.438     -5.107      0.000      -3.098      -1.380
capabilities_entropy     0.9749      0.365      2.673      0.008       0.260       1.690
game_entropy             0.2869      0.322      0.892      0.373      -0.344       0.917
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'Video games', 'History']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.593750
                        1                 0.406250
Geography               0                 0.695652
                        1                 0.304348
Misc                    0                 0.605263
                        1                 0.394737
Music                   0                 0.636364
                        1                 0.363636
Other                   0                 0.518519
                        1                 0.481481
Politics                0                 0.628571
                        1                 0.371429
Science and technology  0                 0.750000
                        1                 0.250000
Sports                  0                 0.833333
                        1                 0.166667
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.602410
                     1                 0.397590
Number               0                 0.666667
                     1                 0.333333
Other                0                 0.682540
                     1                 0.317460
Person               0                 0.694915
                     1                 0.305085
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.363636  0.636364           11
                       Number               0.600000  0.400000            5
                       Other                0.800000  0.200000            5
                       Person               0.727273  0.272727           11
Geography              Date                 0.444444  0.555556            9
                       Number               0.916667  0.083333           12
                       Other                0.500000  0.500000            2
Misc                   Date                 0.461538  0.538462           13
                       Number               0.500000  0.500000            2
                       Other                0.750000  0.250000           16
                       Person               0.571429  0.428571            7
Music                  Date                 0.800000  0.200000            5
                       Number               0.333333  0.666667            3
                       Other                0.555556  0.444444            9
                       Person               0.800000  0.200000            5
Other                  Date                 0.600000  0.400000           10
                       Number               0.500000  0.500000            4
                       Other                0.428571  0.571429            7
                       Person               0.500000  0.500000            6
Politics               Date                 0.733333  0.266667           15
                       Number               0.333333  0.666667            3
                       Other                0.600000  0.400000           10
                       Person               0.571429  0.428571            7
Science and technology Date                 0.733333  0.266667           15
                       Number               0.666667  0.333333            9
                       Other                0.875000  0.125000            8
                       Person               0.750000  0.250000           20
Sports                 Date                 0.800000  0.200000            5
                       Number               0.750000  0.250000            4
                       Other                0.833333  0.166667            6
                       Person               1.000000  0.000000            3

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  247
Model:                          Logit   Df Residuals:                      235
Method:                           MLE   Df Model:                           11
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.04074
Time:                        09:26:54   Log-Likelihood:                -152.52
converged:                       True   LL-Null:                       -159.00
Covariance Type:            nonrobust   LLR p-value:                    0.2962
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      2.8217      1.817      1.553      0.120      -0.740       6.383
C(topic_grouped)[T.Geography]                 -0.5692      0.605     -0.941      0.347      -1.755       0.617
C(topic_grouped)[T.Misc]                       0.0509      0.506      0.101      0.920      -0.941       1.043
C(topic_grouped)[T.Music]                     -0.1563      0.583     -0.268      0.789      -1.298       0.986
C(topic_grouped)[T.Other]                      0.2281      0.537      0.425      0.671      -0.824       1.280
C(topic_grouped)[T.Politics]                  -0.0575      0.515     -0.112      0.911      -1.067       0.952
C(topic_grouped)[T.Science and technology]    -0.7056      0.487     -1.448      0.147      -1.660       0.249
C(topic_grouped)[T.Sports]                    -1.1441      0.738     -1.551      0.121      -2.590       0.302
C(answer_type_grouped)[T.Number]              -0.0901      0.422     -0.214      0.831      -0.917       0.737
C(answer_type_grouped)[T.Other]               -0.4689      0.369     -1.269      0.204      -1.193       0.255
C(answer_type_grouped)[T.Person]              -0.4459      0.378     -1.180      0.238      -1.187       0.295
q_length                                      -0.6679      0.396     -1.687      0.092      -1.444       0.108
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 1.2115
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  247
Model:                          Logit   Df Residuals:                      234
Method:                           MLE   Df Model:                           12
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.09977
Time:                        09:26:54   Log-Likelihood:                -143.14
converged:                       True   LL-Null:                       -159.00
Covariance Type:            nonrobust   LLR p-value:                  0.001524
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      1.4203      1.886      0.753      0.451      -2.276       5.117
C(topic_grouped)[T.Geography]                 -0.8186      0.630     -1.299      0.194      -2.054       0.417
C(topic_grouped)[T.Misc]                       0.0867      0.524      0.165      0.869      -0.941       1.114
C(topic_grouped)[T.Music]                     -0.2761      0.610     -0.453      0.651      -1.471       0.919
C(topic_grouped)[T.Other]                      0.2110      0.560      0.377      0.706      -0.886       1.308
C(topic_grouped)[T.Politics]                   0.0669      0.536      0.125      0.901      -0.984       1.118
C(topic_grouped)[T.Science and technology]    -0.8385      0.507     -1.652      0.098      -1.833       0.156
C(topic_grouped)[T.Sports]                    -1.1599      0.757     -1.532      0.126      -2.644       0.324
C(answer_type_grouped)[T.Number]               0.2388      0.443      0.539      0.590      -0.629       1.107
C(answer_type_grouped)[T.Other]               -0.1847      0.388     -0.476      0.634      -0.945       0.576
C(answer_type_grouped)[T.Person]              -0.0043      0.409     -0.010      0.992      -0.805       0.797
q_length                                      -0.7654      0.406     -1.886      0.059      -1.561       0.030
capabilities_entropy                           1.2968      0.324      4.002      0.000       0.662       1.932
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  247
Model:                          Logit   Df Residuals:                      234
Method:                           MLE   Df Model:                           12
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.07603
Time:                        09:26:54   Log-Likelihood:                -146.91
converged:                       True   LL-Null:                       -159.00
Covariance Type:            nonrobust   LLR p-value:                   0.01924
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      1.7086      1.861      0.918      0.358      -1.938       5.355
C(topic_grouped)[T.Geography]                 -0.6708      0.618     -1.086      0.278      -1.882       0.540
C(topic_grouped)[T.Misc]                      -0.0069      0.519     -0.013      0.989      -1.024       1.010
C(topic_grouped)[T.Music]                     -0.2527      0.602     -0.419      0.675      -1.433       0.928
C(topic_grouped)[T.Other]                      0.1772      0.551      0.321      0.748      -0.904       1.258
C(topic_grouped)[T.Politics]                   0.0497      0.530      0.094      0.925      -0.990       1.089
C(topic_grouped)[T.Science and technology]    -0.7087      0.503     -1.408      0.159      -1.695       0.278
C(topic_grouped)[T.Sports]                    -1.3362      0.754     -1.773      0.076      -2.813       0.141
C(answer_type_grouped)[T.Number]              -0.0821      0.429     -0.191      0.848      -0.924       0.759
C(answer_type_grouped)[T.Other]               -0.2213      0.383     -0.578      0.564      -0.972       0.530
C(answer_type_grouped)[T.Person]              -0.1220      0.402     -0.304      0.761      -0.910       0.666
q_length                                      -0.6944      0.400     -1.737      0.082      -1.478       0.089
game_entropy                                   0.9048      0.282      3.209      0.001       0.352       1.457
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  247
Model:                          Logit   Df Residuals:                      233
Method:                           MLE   Df Model:                           13
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1024
Time:                        09:26:54   Log-Likelihood:                -142.73
converged:                       True   LL-Null:                       -159.00
Covariance Type:            nonrobust   LLR p-value:                  0.001986
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      1.2484      1.897      0.658      0.511      -2.471       4.967
C(topic_grouped)[T.Geography]                 -0.8119      0.631     -1.287      0.198      -2.048       0.424
C(topic_grouped)[T.Misc]                       0.0671      0.526      0.128      0.898      -0.963       1.097
C(topic_grouped)[T.Music]                     -0.3003      0.613     -0.490      0.624      -1.503       0.902
C(topic_grouped)[T.Other]                      0.1902      0.563      0.338      0.736      -0.914       1.294
C(topic_grouped)[T.Politics]                   0.0849      0.538      0.158      0.875      -0.970       1.140
C(topic_grouped)[T.Science and technology]    -0.8191      0.511     -1.604      0.109      -1.820       0.182
C(topic_grouped)[T.Sports]                    -1.2328      0.764     -1.614      0.106      -2.729       0.264
C(answer_type_grouped)[T.Number]               0.1837      0.447      0.411      0.681      -0.693       1.060
C(answer_type_grouped)[T.Other]               -0.1373      0.392     -0.351      0.726      -0.905       0.630
C(answer_type_grouped)[T.Person]               0.0418      0.414      0.101      0.920      -0.769       0.853
q_length                                      -0.7592      0.406     -1.868      0.062      -1.556       0.037
capabilities_entropy                           1.0936      0.391      2.795      0.005       0.327       1.861
game_entropy                                   0.3175      0.350      0.907      0.364      -0.369       1.004
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing gemini-2.5-flash_think (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_neutral/gemini-2.5-flash_think_SimpleMC_neut_redacted_cor_temp1.0_1758287106_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    280
1     60
Name: count, dtype: int64

Answer change%: 0.1765 [0.13594919619861046, 0.2169919802719778] (n=340)
P-value vs 25%: 0.0003758; P-value vs 0%: 1.394e-17
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=60)
P-value vs 25%: 0; P-value vs 33%: 0

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  340
Model:                          Logit   Df Residuals:                      338
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                0.002525
Time:                        09:26:54   Log-Likelihood:                -158.04
converged:                       True   LL-Null:                       -158.44
Covariance Type:            nonrobust   LLR p-value:                    0.3711
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept        314.8630    335.297      0.939      0.348    -342.306     972.032
p_i_capability  -316.4225    335.320     -0.944      0.345    -973.637     340.792
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  340
Model:                          Logit   Df Residuals:                      338
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                0.002183
Time:                        09:26:54   Log-Likelihood:                -158.09
converged:                       True   LL-Null:                       -158.44
Covariance Type:            nonrobust   LLR p-value:                    0.4056
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.5604      0.145    -10.781      0.000      -1.844      -1.277
capabilities_entropy    31.0357     35.320      0.879      0.380     -38.191     100.262
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.2667 [0.1548, 0.3786] (n=60)
                  P-value vs 33.3%: 0.2429

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=1.41, p=0.159
Wilcoxon delta_p: statistic=9674.00, p=7.12e-13
Mean Δp = 0.0007  [-0.0003, 0.0016]
Idea 1 N = 280; 

  Idea 1.5: Calibration Metrics
  NLL: 0.0000, Signed ECE (overconf pos under neg): -0.0000, ECE: 0.0000 (n=340)
  Brier: 0.0000, Reliability (absolute calibration error; lower better): 0.0000, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=340)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       1.000
Model:                            OLS   Adj. R-squared:                  1.000
Method:                 Least Squares   F-statistic:                 2.801e+05
Date:                Sat, 20 Sep 2025   Prob (F-statistic):               0.00
Time:                        09:26:54   Log-Likelihood:                 1170.7
No. Observations:                 335   AIC:                            -2333.
Df Residuals:                     331   BIC:                            -2318.
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept             1.2063      1.679      0.718      0.473      -2.097       4.509
p1                   -1.2057      1.679     -0.718      0.473      -4.509       2.098
answer_changed       -1.5168      2.421     -0.627      0.531      -6.279       3.245
p1:answer_changed     2.5161      2.421      1.039      0.299      -2.246       7.279
==============================================================================
Omnibus:                      697.851   Durbin-Watson:                   2.010
Prob(Omnibus):                  0.000   Jarque-Bera (JB):           650234.856
Skew:                          14.265   Prob(JB):                         0.00
Kurtosis:                     216.939   Cond. No.                     1.38e+04
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The condition number is large, 1.38e+04. This might indicate that there are
strong multicollinearity or other numerical problems.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=2.49, p=0.0134
Wilcoxon delta_H: statistic=15393.00, p=0.00161
Mean ΔH = 0.0465  [0.0099, 0.0831]
Paired t-test delta_H Changed: statistic=26.36, p=2.47e-34
Wilcoxon delta_H Changed: statistic=1.00, p=1.71e-11
Mean ΔH Changed = 1.2095  [1.1196, 1.2994]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=-1.89, p=0.0596
Wilcoxon (p_top2_game vs p_top2_base): statistic=16005.00, p=8.29e-13
Mean Δp_top2 = -0.0001  [-0.0001, 0.0000] (n=340)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=8.48, p=7.03e-16
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=15658.00, p=2.02e-13
Mean ΔH_unchosen_baseline_set = 0.2517  [0.1935, 0.3099] (n=340)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  340
Model:                          Logit   Df Residuals:                      337
Method:                           MLE   Df Model:                            2
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                0.007826
Time:                        09:26:54   Log-Likelihood:                -157.20
converged:                       True   LL-Null:                       -158.44
Covariance Type:            nonrobust   LLR p-value:                    0.2894
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.6479      0.184     -8.959      0.000      -2.008      -1.287
p1_z             0.9722      1.114      0.873      0.383      -1.211       3.156
I(p1_z ** 2)     0.0916      0.093      0.989      0.323      -0.090       0.273
================================================================================
AUC = 0.429

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  340
Model:                          Logit   Df Residuals:                      338
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:               0.0007780
Time:                        09:26:54   Log-Likelihood:                -158.32
converged:                       True   LL-Null:                       -158.44
Covariance Type:            nonrobust   LLR p-value:                    0.6195
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.5487      0.143    -10.795      0.000      -1.830      -1.267
game_entropy     1.5614      2.990      0.522      0.601      -4.298       7.421
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=14018.00, p=1.56e-16
Paired t-test (game_entropy vs capabilities_entropy): statistic=1.86, p=0.0635
Mean capabilities_entropy-game_entropy = -0.0039  [-0.0080, 0.0002] (n=340)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  340
Model:                          Logit   Df Residuals:                      337
Method:                           MLE   Df Model:                            2
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                0.002272
Time:                        09:26:54   Log-Likelihood:                -158.08
converged:                       True   LL-Null:                       -158.44
Covariance Type:            nonrobust   LLR p-value:                    0.6977
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.5616      0.145    -10.774      0.000      -1.846      -1.277
capabilities_entropy    28.0919     39.461      0.712      0.477     -49.249     105.433
game_entropy             0.5904      3.451      0.171      0.864      -6.173       7.354
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['History', 'TV shows', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': None
topic_grouped           answer_changed
Art                     0                 0.800000
                        1                 0.200000
Geography               0                 0.777778
                        1                 0.222222
Misc                    0                 0.727273
                        1                 0.272727
Music                   0                 0.840000
                        1                 0.160000
Other                   0                 0.920000
                        1                 0.080000
Politics                0                 0.842105
                        1                 0.157895
Science and technology  0                 0.861538
                        1                 0.138462
Sports                  0                 0.857143
                        1                 0.142857
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.808333
                     1                 0.191667
Number               0                 0.860465
                     1                 0.139535
Other                0                 0.794118
                     1                 0.205882
Person               0                 0.879518
                     1                 0.120482
Place                0                 0.730769
                     1                 0.269231
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.823529  0.176471           17
                       Number               0.833333  0.166667            6
                       Other                0.900000  0.100000           10
                       Person               0.772727  0.227273           22
                       Place                0.600000  0.400000            5
Geography              Date                 0.714286  0.285714           14
                       Number               0.909091  0.090909           11
                       Other                1.000000  0.000000            3
                       Place                0.625000  0.375000            8
Misc                   Date                 0.800000  0.200000           15
                       Number               0.714286  0.285714            7
                       Other                0.583333  0.416667           12
                       Person               0.777778  0.222222            9
                       Place                1.000000  0.000000            1
Music                  Date                 0.750000  0.250000            8
                       Number               1.000000  0.000000            2
                       Other                0.800000  0.200000            5
                       Person               1.000000  0.000000            8
                       Place                0.500000  0.500000            2
Other                  Date                 0.857143  0.142857            7
                       Number               1.000000  0.000000            1
                       Other                1.000000  0.000000            5
                       Person               1.000000  0.000000            8
                       Place                0.750000  0.250000            4
Politics               Date                 0.800000  0.200000           25
                       Number               0.800000  0.200000            5
                       Other                0.750000  0.250000           12
                       Person               1.000000  0.000000           11
                       Place                1.000000  0.000000            4
Science and technology Date                 0.884615  0.115385           26
                       Number               1.000000  0.000000            6
                       Other                0.750000  0.250000           12
                       Person               0.850000  0.150000           20
                       Place                1.000000  0.000000            1
Sports                 Date                 0.750000  0.250000            8
                       Number               0.800000  0.200000            5
                       Other                0.888889  0.111111            9
                       Person               1.000000  0.000000            5
                       Place                1.000000  0.000000            1

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  340
Model:                          Logit   Df Residuals:                      327
Method:                           MLE   Df Model:                           12
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.03458
Time:                        09:26:54   Log-Likelihood:                -152.96
converged:                       True   LL-Null:                       -158.44
Covariance Type:            nonrobust   LLR p-value:                    0.5325
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -2.0923      1.836     -1.140      0.254      -5.691       1.506
C(topic_grouped)[T.Geography]                 -0.0051      0.544     -0.009      0.993      -1.071       1.061
C(topic_grouped)[T.Misc]                       0.3776      0.477      0.791      0.429      -0.558       1.313
C(topic_grouped)[T.Music]                     -0.2961      0.640     -0.463      0.643      -1.550       0.957
C(topic_grouped)[T.Other]                     -1.1740      0.813     -1.444      0.149      -2.767       0.419
C(topic_grouped)[T.Politics]                  -0.4311      0.507     -0.850      0.396      -1.426       0.564
C(topic_grouped)[T.Science and technology]    -0.4583      0.491     -0.933      0.351      -1.421       0.504
C(topic_grouped)[T.Sports]                    -0.4511      0.639     -0.706      0.480      -1.704       0.802
C(answer_type_grouped)[T.Number]              -0.5039      0.510     -0.988      0.323      -1.503       0.495
C(answer_type_grouped)[T.Other]                0.0990      0.390      0.254      0.799      -0.664       0.862
C(answer_type_grouped)[T.Person]              -0.5195      0.422     -1.231      0.218      -1.347       0.308
C(answer_type_grouped)[T.Place]                0.4749      0.522      0.909      0.363      -0.549       1.499
q_length                                       0.1922      0.400      0.481      0.631      -0.591       0.975
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.0005
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  340
Model:                          Logit   Df Residuals:                      326
Method:                           MLE   Df Model:                           13
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.03719
Time:                        09:26:54   Log-Likelihood:                -152.55
converged:                       True   LL-Null:                       -158.44
Covariance Type:            nonrobust   LLR p-value:                    0.5454
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -2.0568      1.847     -1.114      0.265      -5.676       1.563
C(topic_grouped)[T.Geography]                  0.0120      0.545      0.022      0.982      -1.056       1.080
C(topic_grouped)[T.Misc]                       0.3326      0.482      0.690      0.490      -0.612       1.277
C(topic_grouped)[T.Music]                     -0.2936      0.640     -0.459      0.646      -1.548       0.961
C(topic_grouped)[T.Other]                     -1.1780      0.813     -1.449      0.147      -2.772       0.416
C(topic_grouped)[T.Politics]                  -0.4249      0.508     -0.837      0.403      -1.420       0.570
C(topic_grouped)[T.Science and technology]    -0.4835      0.493     -0.981      0.327      -1.450       0.483
C(topic_grouped)[T.Sports]                    -0.4516      0.640     -0.706      0.480      -1.705       0.802
C(answer_type_grouped)[T.Number]              -0.5906      0.526     -1.122      0.262      -1.622       0.441
C(answer_type_grouped)[T.Other]                0.1092      0.390      0.280      0.779      -0.654       0.873
C(answer_type_grouped)[T.Person]              -0.5307      0.423     -1.255      0.209      -1.359       0.298
C(answer_type_grouped)[T.Place]                0.4687      0.522      0.898      0.369      -0.555       1.492
q_length                                       0.1833      0.402      0.456      0.648      -0.605       0.971
capabilities_entropy                          35.9778     37.501      0.959      0.337     -37.522     109.478
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  340
Model:                          Logit   Df Residuals:                      326
Method:                           MLE   Df Model:                           13
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.03537
Time:                        09:26:54   Log-Likelihood:                -152.84
converged:                       True   LL-Null:                       -158.44
Covariance Type:            nonrobust   LLR p-value:                    0.5933
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.9256      1.865     -1.032      0.302      -5.581       1.730
C(topic_grouped)[T.Geography]                 -0.0036      0.544     -0.007      0.995      -1.070       1.063
C(topic_grouped)[T.Misc]                       0.3678      0.478      0.770      0.442      -0.569       1.305
C(topic_grouped)[T.Music]                     -0.2987      0.640     -0.467      0.640      -1.552       0.955
C(topic_grouped)[T.Other]                     -1.1739      0.813     -1.444      0.149      -2.767       0.419
C(topic_grouped)[T.Politics]                  -0.4210      0.507     -0.830      0.407      -1.416       0.574
C(topic_grouped)[T.Science and technology]    -0.4772      0.494     -0.966      0.334      -1.445       0.491
C(topic_grouped)[T.Sports]                    -0.4728      0.641     -0.738      0.461      -1.729       0.784
C(answer_type_grouped)[T.Number]              -0.5379      0.516     -1.041      0.298      -1.550       0.474
C(answer_type_grouped)[T.Other]                0.0797      0.392      0.203      0.839      -0.688       0.847
C(answer_type_grouped)[T.Person]              -0.5202      0.422     -1.233      0.218      -1.347       0.307
C(answer_type_grouped)[T.Place]                0.4696      0.522      0.899      0.369      -0.554       1.493
q_length                                       0.1563      0.406      0.385      0.700      -0.639       0.952
game_entropy                                   1.6433      3.150      0.522      0.602      -4.530       7.816
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  340
Model:                          Logit   Df Residuals:                      325
Method:                           MLE   Df Model:                           14
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.03724
Time:                        09:26:54   Log-Likelihood:                -152.54
converged:                       True   LL-Null:                       -158.44
Covariance Type:            nonrobust   LLR p-value:                    0.6223
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -2.0151      1.874     -1.075      0.282      -5.689       1.659
C(topic_grouped)[T.Geography]                  0.0118      0.545      0.022      0.983      -1.056       1.079
C(topic_grouped)[T.Misc]                       0.3320      0.482      0.689      0.491      -0.612       1.277
C(topic_grouped)[T.Music]                     -0.2945      0.640     -0.460      0.645      -1.549       0.960
C(topic_grouped)[T.Other]                     -1.1778      0.813     -1.449      0.147      -2.771       0.416
C(topic_grouped)[T.Politics]                  -0.4226      0.508     -0.832      0.405      -1.418       0.573
C(topic_grouped)[T.Science and technology]    -0.4860      0.493     -0.985      0.325      -1.453       0.481
C(topic_grouped)[T.Sports]                    -0.4578      0.642     -0.714      0.475      -1.715       0.800
C(answer_type_grouped)[T.Number]              -0.5963      0.529     -1.128      0.259      -1.633       0.440
C(answer_type_grouped)[T.Other]                0.1037      0.392      0.265      0.791      -0.664       0.872
C(answer_type_grouped)[T.Person]              -0.5295      0.423     -1.253      0.210      -1.358       0.299
C(answer_type_grouped)[T.Place]                0.4676      0.522      0.895      0.371      -0.556       1.491
q_length                                       0.1744      0.408      0.428      0.669      -0.625       0.974
capabilities_entropy                          33.6625     41.850      0.804      0.421     -48.362     115.687
game_entropy                                   0.4759      3.666      0.130      0.897      -6.709       7.661
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing gemini-2.5-flash_think (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_neutral/gemini-2.5-flash_think_SimpleMC_neut_redacted_temp1.0_1758279039_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
1    90
0    70
Name: count, dtype: int64

Answer change%: 0.5625 [0.4856332725322915, 0.6393667274677085] (n=160)
P-value vs 25%: 1.61e-15; P-value vs 0%: 1.183e-46
Phase 2 self-accuracy: 0.5556 [0.45289601301113497, 0.6582150980999761] (n=90)
P-value vs 25%: 5.423e-09; P-value vs 33%: 2.147e-05

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  160
Model:                          Logit   Df Residuals:                      158
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                0.007513
Time:                        09:26:54   Log-Likelihood:                -108.83
converged:                       True   LL-Null:                       -109.65
Covariance Type:            nonrobust   LLR p-value:                    0.1993
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept       -109.4257    509.536     -0.215      0.830   -1108.098     889.247
p_i_capability   109.6935    509.547      0.215      0.830    -889.000    1108.387
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  160
Model:                          Logit   Df Residuals:                      158
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                0.007568
Time:                        09:26:54   Log-Likelihood:                -108.82
converged:                       True   LL-Null:                       -109.65
Covariance Type:            nonrobust   LLR p-value:                    0.1976
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept                0.2709      0.164      1.651      0.099      -0.051       0.593
capabilities_entropy   -20.0733    139.702     -0.144      0.886    -293.884     253.738
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.3667 [0.2671, 0.4662] (n=90)
                  P-value vs 33.3%: 0.5117

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=-0.98, p=0.331
Wilcoxon delta_p: statistic=511.00, p=1.86e-05
Mean Δp = -0.0009  [-0.0028, 0.0009]
Idea 1 N = 70; 

  Idea 1.5: Calibration Metrics
  NLL: 13.0208, Signed ECE (overconf pos under neg): 0.0000, ECE: 0.0000 (n=140)
  Brier: 0.0000, Reliability (absolute calibration error; lower better): 0.0000, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=140)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       1.000
Model:                            OLS   Adj. R-squared:                  1.000
Method:                 Least Squares   F-statistic:                 2.122e+09
Date:                Sat, 20 Sep 2025   Prob (F-statistic):               0.00
Time:                        09:26:54   Log-Likelihood:                 1218.3
No. Observations:                 151   AIC:                            -2429.
Df Residuals:                     147   BIC:                            -2416.
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.9923      0.001   -857.291      0.000      -0.995      -0.990
p1                    0.9923      0.001    856.517      0.000       0.990       0.995
answer_changed        1.0743      0.287      3.746      0.000       0.508       1.641
p1:answer_changed    -0.0744      0.287     -0.259      0.796      -0.641       0.492
==============================================================================
Omnibus:                       56.186   Durbin-Watson:                   1.919
Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2497.647
Skew:                          -0.235   Prob(JB):                         0.00
Kurtosis:                      22.919   Cond. No.                     1.07e+05
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The condition number is large, 1.07e+05. This might indicate that there are
strong multicollinearity or other numerical problems.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=3.35, p=0.00132
Wilcoxon delta_H: statistic=683.00, p=0.00106
Mean ΔH = 0.1208  [0.0501, 0.1915]
Paired t-test delta_H Changed: statistic=42.67, p=4.8e-61
Wilcoxon delta_H Changed: statistic=0.00, p=1.74e-16
Mean ΔH Changed = 1.2234  [1.1672, 1.2796]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=0.79, p=0.433
Wilcoxon (p_top2_game vs p_top2_base): statistic=3483.00, p=4.71e-07
Mean Δp_top2 = 0.0002  [-0.0002, 0.0005] (n=160)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=15.17, p=1.06e-32
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=691.00, p=1.19e-22
Mean ΔH_unchosen_baseline_set = 0.7410  [0.6453, 0.8368] (n=160)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  160
Model:                          Logit   Df Residuals:                      157
Method:                           MLE   Df Model:                            2
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                0.008236
Time:                        09:26:54   Log-Likelihood:                -108.75
converged:                       True   LL-Null:                       -109.65
Covariance Type:            nonrobust   LLR p-value:                    0.4053
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.0763      7.154     -0.150      0.880     -15.098      12.945
p1_z            55.6090    228.138      0.244      0.807    -391.533     502.751
I(p1_z ** 2)  -484.9002   1759.277     -0.276      0.783   -3933.020    2963.220
================================================================================
AUC = 0.488

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  160
Model:                          Logit   Df Residuals:                      158
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.01634
Time:                        09:26:54   Log-Likelihood:                -107.86
converged:                       True   LL-Null:                       -109.65
Covariance Type:            nonrobust   LLR p-value:                   0.05837
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept        0.1575      0.171      0.918      0.358      -0.179       0.494
game_entropy    94.4162     87.571      1.078      0.281     -77.219     266.051
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=3310.00, p=9.69e-08
Paired t-test (game_entropy vs capabilities_entropy): statistic=-0.49, p=0.622
Mean capabilities_entropy-game_entropy = 0.0013  [-0.0040, 0.0067] (n=160)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  160
Model:                          Logit   Df Residuals:                      157
Method:                           MLE   Df Model:                            2
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.02727
Time:                        09:26:54   Log-Likelihood:                -106.66
converged:                       True   LL-Null:                       -109.65
Covariance Type:            nonrobust   LLR p-value:                   0.05031
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept                0.1561      0.179      0.869      0.385      -0.196       0.508
capabilities_entropy   -21.9497    145.778     -0.151      0.880    -307.669     263.769
game_entropy           134.4743    117.404      1.145      0.252     -95.633     364.581
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['Video games', 'Geography', 'History']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     1                 0.533333
                        0                 0.466667
Misc                    1                 0.680000
                        0                 0.320000
Music                   1                 0.533333
                        0                 0.466667
Other                   1                 0.518519
                        0                 0.481481
Politics                0                 0.500000
                        1                 0.500000
Science and technology  1                 0.515152
                        0                 0.484848
Sports                  1                 0.666667
                        0                 0.333333
TV shows                1                 0.615385
                        0                 0.384615
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 1                 0.530612
                     0                 0.469388
Number               1                 0.600000
                     0                 0.400000
Other                1                 0.564103
                     0                 0.435897
Person               1                 0.567568
                     0                 0.432432
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.500000  0.500000            4
                       Number               0.666667  0.333333            3
                       Other                0.333333  0.666667            3
                       Person               0.400000  0.600000            5
Misc                   Date                 0.333333  0.666667            9
                       Number               0.222222  0.777778            9
                       Other                0.500000  0.500000            6
                       Person               0.000000  1.000000            1
Music                  Date                 0.250000  0.750000            4
                       Number               0.000000  1.000000            2
                       Other                0.400000  0.600000            5
                       Person               1.000000  0.000000            4
Other                  Date                 0.545455  0.454545           11
                       Number               0.500000  0.500000            6
                       Other                0.400000  0.600000            5
                       Person               0.400000  0.600000            5
Politics               Date                 0.545455  0.454545           11
                       Number               1.000000  0.000000            1
                       Other                0.750000  0.250000            4
                       Person               0.000000  1.000000            4
Science and technology Date                 0.444444  0.555556            9
                       Number               0.500000  0.500000            8
                       Other                0.500000  0.500000            6
                       Person               0.500000  0.500000           10
Sports                 Date                 1.000000  0.000000            1
                       Number               0.333333  0.666667            6
                       Other                0.000000  1.000000            2
                       Person               0.333333  0.666667            3
TV shows               Other                0.375000  0.625000            8
                       Person               0.400000  0.600000            5

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  160
Model:                          Logit   Df Residuals:                      148
Method:                           MLE   Df Model:                           11
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.01480
Time:                        09:26:54   Log-Likelihood:                -108.03
converged:                       True   LL-Null:                       -109.65
Covariance Type:            nonrobust   LLR p-value:                    0.9871
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      0.2306      2.082      0.111      0.912      -3.850       4.311
C(topic_grouped)[T.Misc]                       0.6464      0.684      0.945      0.344      -0.694       1.986
C(topic_grouped)[T.Music]                      0.0126      0.735      0.017      0.986      -1.427       1.452
C(topic_grouped)[T.Other]                     -0.0403      0.650     -0.062      0.951      -1.314       1.233
C(topic_grouped)[T.Politics]                  -0.0823      0.698     -0.118      0.906      -1.450       1.286
C(topic_grouped)[T.Science and technology]    -0.0684      0.627     -0.109      0.913      -1.297       1.160
C(topic_grouped)[T.Sports]                     0.5361      0.813      0.659      0.510      -1.058       2.130
C(topic_grouped)[T.TV shows]                   0.3346      0.792      0.422      0.673      -1.218       1.887
C(answer_type_grouped)[T.Number]               0.1437      0.474      0.303      0.762      -0.785       1.072
C(answer_type_grouped)[T.Other]                0.0480      0.462      0.104      0.917      -0.858       0.954
C(answer_type_grouped)[T.Person]               0.1569      0.468      0.335      0.737      -0.760       1.074
q_length                                      -0.0421      0.439     -0.096      0.924      -0.903       0.819
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.0029
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  160
Model:                          Logit   Df Residuals:                      147
Method:                           MLE   Df Model:                           12
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.02415
Time:                        09:26:54   Log-Likelihood:                -107.00
converged:                       True   LL-Null:                       -109.65
Covariance Type:            nonrobust   LLR p-value:                    0.9474
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      0.4721      2.095      0.225      0.822      -3.633       4.577
C(topic_grouped)[T.Misc]                       0.6393      0.684      0.935      0.350      -0.701       1.980
C(topic_grouped)[T.Music]                     -0.0028      0.739     -0.004      0.997      -1.450       1.445
C(topic_grouped)[T.Other]                     -0.0474      0.650     -0.073      0.942      -1.321       1.226
C(topic_grouped)[T.Politics]                  -0.0820      0.699     -0.117      0.907      -1.453       1.289
C(topic_grouped)[T.Science and technology]    -0.0622      0.627     -0.099      0.921      -1.290       1.166
C(topic_grouped)[T.Sports]                     0.5400      0.814      0.664      0.507      -1.055       2.135
C(topic_grouped)[T.TV shows]                   0.5428      0.823      0.660      0.509      -1.069       2.155
C(answer_type_grouped)[T.Number]               0.1456      0.476      0.306      0.760      -0.787       1.078
C(answer_type_grouped)[T.Other]                0.0788      0.469      0.168      0.867      -0.841       0.999
C(answer_type_grouped)[T.Person]               0.1235      0.470      0.262      0.793      -0.799       1.045
q_length                                      -0.0923      0.442     -0.209      0.835      -0.958       0.774
capabilities_entropy                         -43.1141    395.503     -0.109      0.913    -818.286     732.058
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  160
Model:                          Logit   Df Residuals:                      147
Method:                           MLE   Df Model:                           12
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.03033
Time:                        09:26:54   Log-Likelihood:                -106.32
converged:                       True   LL-Null:                       -109.65
Covariance Type:            nonrobust   LLR p-value:                    0.8797
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      0.3881      2.095      0.185      0.853      -3.718       4.494
C(topic_grouped)[T.Misc]                       0.6344      0.688      0.922      0.357      -0.715       1.984
C(topic_grouped)[T.Music]                      0.0492      0.736      0.067      0.947      -1.394       1.493
C(topic_grouped)[T.Other]                     -0.0257      0.652     -0.040      0.968      -1.303       1.252
C(topic_grouped)[T.Politics]                  -0.1422      0.702     -0.202      0.840      -1.519       1.235
C(topic_grouped)[T.Science and technology]    -0.0620      0.630     -0.098      0.922      -1.297       1.173
C(topic_grouped)[T.Sports]                     0.5805      0.815      0.712      0.476      -1.017       2.178
C(topic_grouped)[T.TV shows]                   0.2199      0.808      0.272      0.785      -1.364       1.804
C(answer_type_grouped)[T.Number]               0.0747      0.478      0.156      0.876      -0.862       1.012
C(answer_type_grouped)[T.Other]                0.0306      0.465      0.066      0.948      -0.881       0.942
C(answer_type_grouped)[T.Person]               0.0244      0.476      0.051      0.959      -0.908       0.957
q_length                                      -0.0868      0.442     -0.196      0.845      -0.954       0.780
game_entropy                                 108.8828     95.800      1.137      0.256     -78.883     296.648
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  160
Model:                          Logit   Df Residuals:                      146
Method:                           MLE   Df Model:                           13
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.04417
Time:                        09:26:55   Log-Likelihood:                -104.81
converged:                       True   LL-Null:                       -109.65
Covariance Type:            nonrobust   LLR p-value:                    0.7193
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      0.7102      2.117      0.335      0.737      -3.439       4.860
C(topic_grouped)[T.Misc]                       0.6587      0.691      0.953      0.341      -0.696       2.013
C(topic_grouped)[T.Music]                      0.0538      0.742      0.072      0.942      -1.400       1.508
C(topic_grouped)[T.Other]                     -0.0162      0.654     -0.025      0.980      -1.299       1.267
C(topic_grouped)[T.Politics]                  -0.1614      0.708     -0.228      0.820      -1.549       1.226
C(topic_grouped)[T.Science and technology]    -0.0322      0.634     -0.051      0.960      -1.274       1.210
C(topic_grouped)[T.Sports]                     0.6058      0.818      0.741      0.459      -0.998       2.209
C(topic_grouped)[T.TV shows]                   0.5169      0.841      0.614      0.539      -1.132       2.166
C(answer_type_grouped)[T.Number]               0.0666      0.481      0.138      0.890      -0.877       1.010
C(answer_type_grouped)[T.Other]                0.0502      0.473      0.106      0.916      -0.877       0.978
C(answer_type_grouped)[T.Person]              -0.0411      0.481     -0.085      0.932      -0.984       0.901
q_length                                      -0.1625      0.448     -0.363      0.717      -1.040       0.715
capabilities_entropy                         -60.7386    396.578     -0.153      0.878    -838.017     716.540
game_entropy                                 165.9202    128.850      1.288      0.198     -86.621     418.461
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing gpt-4.1-2025-04-14 (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_neutral/gpt-4.1-2025-04-14_SimpleMC_neut_redacted_cor_temp1.0_1757986326_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    230
1     28
Name: count, dtype: int64

Answer change%: 0.1085 [0.07057278985928281, 0.14648147370660866] (n=258)
P-value vs 25%: 2.759e-13; P-value vs 0%: 2.09e-08
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=28)
P-value vs 25%: 0; P-value vs 33%: 0

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  258
Model:                          Logit   Df Residuals:                      256
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1825
Time:                        09:26:55   Log-Likelihood:                -72.432
converged:                       True   LL-Null:                       -88.604
Covariance Type:            nonrobust   LLR p-value:                 1.292e-08
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          3.4223      0.963      3.554      0.000       1.535       5.310
p_i_capability    -6.5349      1.191     -5.487      0.000      -8.869      -4.200
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  258
Model:                          Logit   Df Residuals:                      256
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1695
Time:                        09:26:55   Log-Likelihood:                -73.583
converged:                       True   LL-Null:                       -88.604
Covariance Type:            nonrobust   LLR p-value:                 4.229e-08
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -3.2069      0.360     -8.917      0.000      -3.912      -2.502
capabilities_entropy     2.0716      0.396      5.225      0.000       1.295       2.849
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.7391 [0.5597, 0.9186] (n=23)
                  P-value vs 33.3%: 9.336e-06

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=-5.12, p=3.14e-06
Wilcoxon delta_p: statistic=328.00, p=1.92e-06
Mean Δp = -0.1081  [-0.1495, -0.0667]
Idea 1 N = 64; 

  Idea 1.5: Calibration Metrics
  NLL: 0.2547, Signed ECE (overconf pos under neg): -0.2060, ECE: 0.2060 (n=77)
  Brier: 0.0693, Reliability (absolute calibration error; lower better): 0.0684, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=77)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.807
Model:                            OLS   Adj. R-squared:                  0.799
Method:                 Least Squares   F-statistic:                     101.5
Date:                Sat, 20 Sep 2025   Prob (F-statistic):           5.66e-26
Time:                        09:26:55   Log-Likelihood:                 51.291
No. Observations:                  77   AIC:                            -94.58
Df Residuals:                      73   BIC:                            -85.21
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.7656      0.088     -8.692      0.000      -0.941      -0.590
p1                    0.7959      0.105      7.591      0.000       0.587       1.005
answer_changed        0.4330      0.206      2.103      0.039       0.023       0.844
p1:answer_changed     0.4780      0.306      1.562      0.123      -0.132       1.088
==============================================================================
Omnibus:                       16.975   Durbin-Watson:                   2.048
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               20.990
Skew:                           1.022   Prob(JB):                     2.77e-05
Kurtosis:                       4.537   Cond. No.                         33.1
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=7.00, p=2.03e-09
Wilcoxon delta_H: statistic=210.00, p=2.85e-08
Mean ΔH = 0.4089  [0.2944, 0.5235]
Paired t-test delta_H Changed: statistic=3.06, p=0.00983
Wilcoxon delta_H Changed: statistic=9.00, p=0.00806
Mean ΔH Changed = 0.2796  [0.1007, 0.4584]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=6.25, p=2.21e-08
Wilcoxon (p_top2_game vs p_top2_base): statistic=151.00, p=7.03e-12
Mean Δp_top2 = 0.0363  [0.0249, 0.0476] (n=77)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=7.58, p=6.93e-11
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=300.00, p=1.06e-09
Mean ΔH_unchosen_baseline_set = 0.3871  [0.2870, 0.4872] (n=77)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                   77
Model:                          Logit   Df Residuals:                       74
Method:                           MLE   Df Model:                            2
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.2322
Time:                        09:26:55   Log-Likelihood:                -26.842
converged:                       True   LL-Null:                       -34.960
Covariance Type:            nonrobust   LLR p-value:                 0.0002982
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.9702      0.496     -3.971      0.000      -2.943      -0.998
p1_z            -1.8868      0.761     -2.480      0.013      -3.378      -0.396
I(p1_z ** 2)    -0.4584      0.408     -1.124      0.261      -1.258       0.341
================================================================================
AUC = 0.839

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  258
Model:                          Logit   Df Residuals:                      256
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.2056
Time:                        09:26:55   Log-Likelihood:                -70.387
converged:                       True   LL-Null:                       -88.604
Covariance Type:            nonrobust   LLR p-value:                 1.580e-09
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -2.9001      0.294     -9.848      0.000      -3.477      -2.323
game_entropy     2.8836      0.500      5.763      0.000       1.903       3.864
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=2226.00, p=7.22e-15
Paired t-test (game_entropy vs capabilities_entropy): statistic=-7.56, p=7.16e-13
Mean capabilities_entropy-game_entropy = 0.1852  [0.1372, 0.2332] (n=258)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  258
Model:                          Logit   Df Residuals:                      255
Method:                           MLE   Df Model:                            2
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.2400
Time:                        09:26:55   Log-Likelihood:                -67.341
converged:                       True   LL-Null:                       -88.604
Covariance Type:            nonrobust   LLR p-value:                 5.829e-10
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -3.3110      0.372     -8.910      0.000      -4.039      -2.583
capabilities_entropy     1.2196      0.487      2.506      0.012       0.266       2.173
game_entropy             2.0652      0.597      3.461      0.001       0.896       3.235
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': None
topic_grouped           answer_changed
Art                     0                 0.953488
                        1                 0.046512
Geography               0                 0.842105
                        1                 0.157895
Misc                    0                 0.818182
                        1                 0.181818
Music                   0                 0.714286
                        1                 0.285714
Other                   0                 0.931034
                        1                 0.068966
Politics                0                 0.918919
                        1                 0.081081
Science and technology  0                 0.956522
                        1                 0.043478
Sports                  0                 0.782609
                        1                 0.217391
TV shows                0                 0.944444
                        1                 0.055556
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.816901
                     1                 0.183099
Number               0                 0.843750
                     1                 0.156250
Other                0                 0.937500
                     1                 0.062500
Person               0                 0.931507
                     1                 0.068493
Place                0                 0.944444
                     1                 0.055556
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.777778  0.222222            9
                       Number               1.000000  0.000000            3
                       Other                1.000000  0.000000            9
                       Person               1.000000  0.000000           18
                       Place                1.000000  0.000000            4
Geography              Date                 0.666667  0.333333            3
                       Number               0.750000  0.250000            8
                       Other                1.000000  0.000000            3
                       Place                1.000000  0.000000            5
Misc                   Date                 0.777778  0.222222            9
                       Number               1.000000  0.000000            3
                       Other                0.600000  0.400000            5
                       Person               1.000000  0.000000            5
Music                  Date                 0.400000  0.600000            5
                       Number               1.000000  0.000000            2
                       Other                0.750000  0.250000            4
                       Person               0.800000  0.200000           10
Other                  Date                 0.875000  0.125000            8
                       Number               1.000000  0.000000            4
                       Other                1.000000  0.000000            5
                       Person               1.000000  0.000000            9
                       Place                0.666667  0.333333            3
Politics               Date                 0.842105  0.157895           19
                       Number               1.000000  0.000000            1
                       Other                1.000000  0.000000            8
                       Person               1.000000  0.000000            5
                       Place                1.000000  0.000000            4
Science and technology Date                 1.000000  0.000000           13
                       Number               1.000000  0.000000            5
                       Other                1.000000  0.000000           12
                       Person               0.875000  0.125000           16
Sports                 Date                 0.750000  0.250000            4
                       Number               0.400000  0.600000            5
                       Other                1.000000  0.000000            6
                       Person               0.833333  0.166667            6
                       Place                1.000000  0.000000            2
TV shows               Date                 1.000000  0.000000            1
                       Number               1.000000  0.000000            1
                       Other                0.916667  0.083333           12
                       Person               1.000000  0.000000            4

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  258
Model:                          Logit   Df Residuals:                      244
Method:                           MLE   Df Model:                           13
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1287
Time:                        09:26:55   Log-Likelihood:                -77.196
converged:                       True   LL-Null:                       -88.604
Covariance Type:            nonrobust   LLR p-value:                   0.04395
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -2.3386      2.794     -0.837      0.403      -7.814       3.137
C(topic_grouped)[T.Geography]                  1.2325      1.018      1.211      0.226      -0.762       3.227
C(topic_grouped)[T.Misc]                       1.2202      0.935      1.305      0.192      -0.612       3.052
C(topic_grouped)[T.Music]                      2.1300      0.894      2.384      0.017       0.379       3.881
C(topic_grouped)[T.Other]                      0.2766      1.045      0.265      0.791      -1.771       2.324
C(topic_grouped)[T.Politics]                   0.1905      0.985      0.193      0.847      -1.740       2.121
C(topic_grouped)[T.Science and technology]    -0.2283      1.040     -0.219      0.826      -2.268       1.811
C(topic_grouped)[T.Sports]                     1.7512      0.909      1.927      0.054      -0.030       3.532
C(topic_grouped)[T.TV shows]                   0.4889      1.297      0.377      0.706      -2.054       3.032
C(answer_type_grouped)[T.Number]              -0.5697      0.648     -0.880      0.379      -1.839       0.699
C(answer_type_grouped)[T.Other]               -1.3408      0.654     -2.050      0.040      -2.623      -0.059
C(answer_type_grouped)[T.Person]              -1.3323      0.612     -2.177      0.029      -2.532      -0.133
C(answer_type_grouped)[T.Place]               -1.4841      1.136     -1.306      0.191      -3.711       0.742
q_length                                       0.0389      0.601      0.065      0.948      -1.138       1.216
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.3327
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  258
Model:                          Logit   Df Residuals:                      243
Method:                           MLE   Df Model:                           14
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.2929
Time:                        09:26:55   Log-Likelihood:                -62.648
converged:                       True   LL-Null:                       -88.604
Covariance Type:            nonrobust   LLR p-value:                 2.911e-06
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -2.0582      3.241     -0.635      0.525      -8.410       4.293
C(topic_grouped)[T.Geography]                  1.8072      1.132      1.596      0.110      -0.412       4.026
C(topic_grouped)[T.Misc]                       2.1066      1.090      1.933      0.053      -0.030       4.243
C(topic_grouped)[T.Music]                      2.5169      1.010      2.491      0.013       0.536       4.497
C(topic_grouped)[T.Other]                      0.1525      1.148      0.133      0.894      -2.098       2.403
C(topic_grouped)[T.Politics]                   0.0280      1.072      0.026      0.979      -2.073       2.129
C(topic_grouped)[T.Science and technology]     0.0195      1.119      0.017      0.986      -2.173       2.212
C(topic_grouped)[T.Sports]                     2.5697      1.048      2.453      0.014       0.516       4.623
C(topic_grouped)[T.TV shows]                   1.2618      1.474      0.856      0.392      -1.627       4.151
C(answer_type_grouped)[T.Number]              -0.7654      0.744     -1.029      0.303      -2.223       0.692
C(answer_type_grouped)[T.Other]               -1.1382      0.793     -1.436      0.151      -2.692       0.416
C(answer_type_grouped)[T.Person]              -0.5857      0.701     -0.836      0.403      -1.959       0.788
C(answer_type_grouped)[T.Place]               -0.3060      1.205     -0.254      0.800      -2.668       2.056
q_length                                      -0.4580      0.724     -0.633      0.527      -1.876       0.960
capabilities_entropy                           2.4442      0.503      4.860      0.000       1.459       3.430
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  258
Model:                          Logit   Df Residuals:                      243
Method:                           MLE   Df Model:                           14
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.3207
Time:                        09:26:55   Log-Likelihood:                -60.184
converged:                       True   LL-Null:                       -88.604
Covariance Type:            nonrobust   LLR p-value:                 4.172e-07
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -0.1153      3.186     -0.036      0.971      -6.360       6.130
C(topic_grouped)[T.Geography]                  0.6220      1.200      0.518      0.604      -1.730       2.974
C(topic_grouped)[T.Misc]                       1.8416      1.112      1.656      0.098      -0.338       4.021
C(topic_grouped)[T.Music]                      2.3103      1.064      2.171      0.030       0.225       4.396
C(topic_grouped)[T.Other]                     -0.3162      1.238     -0.255      0.798      -2.743       2.111
C(topic_grouped)[T.Politics]                   0.5649      1.136      0.497      0.619      -1.662       2.792
C(topic_grouped)[T.Science and technology]     0.1875      1.187      0.158      0.874      -2.139       2.514
C(topic_grouped)[T.Sports]                     2.0810      1.069      1.946      0.052      -0.015       4.177
C(topic_grouped)[T.TV shows]                  -0.6010      1.621     -0.371      0.711      -3.779       2.577
C(answer_type_grouped)[T.Number]               0.3648      0.770      0.474      0.636      -1.144       1.874
C(answer_type_grouped)[T.Other]               -0.7871      0.824     -0.955      0.340      -2.403       0.828
C(answer_type_grouped)[T.Person]              -0.6567      0.694     -0.947      0.344      -2.016       0.703
C(answer_type_grouped)[T.Place]               -0.3218      1.255     -0.256      0.798      -2.782       2.139
q_length                                      -0.7964      0.702     -1.135      0.256      -2.172       0.579
game_entropy                                   3.4333      0.684      5.016      0.000       2.092       4.775
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  258
Model:                          Logit   Df Residuals:                      242
Method:                           MLE   Df Model:                           15
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.3600
Time:                        09:26:55   Log-Likelihood:                -56.710
converged:                       True   LL-Null:                       -88.604
Covariance Type:            nonrobust   LLR p-value:                 5.570e-08
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -0.0460      3.379     -0.014      0.989      -6.670       6.578
C(topic_grouped)[T.Geography]                  1.1957      1.227      0.974      0.330      -1.209       3.601
C(topic_grouped)[T.Misc]                       2.3122      1.162      1.990      0.047       0.034       4.590
C(topic_grouped)[T.Music]                      2.5666      1.107      2.318      0.020       0.397       4.737
C(topic_grouped)[T.Other]                     -0.3781      1.283     -0.295      0.768      -2.892       2.136
C(topic_grouped)[T.Politics]                   0.5357      1.168      0.459      0.647      -1.754       2.825
C(topic_grouped)[T.Science and technology]     0.2945      1.222      0.241      0.810      -2.101       2.690
C(topic_grouped)[T.Sports]                     2.5150      1.135      2.215      0.027       0.290       4.740
C(topic_grouped)[T.TV shows]                   0.0647      1.799      0.036      0.971      -3.461       3.590
C(answer_type_grouped)[T.Number]               0.1792      0.814      0.220      0.826      -1.416       1.774
C(answer_type_grouped)[T.Other]               -0.7844      0.875     -0.897      0.370      -2.499       0.930
C(answer_type_grouped)[T.Person]              -0.3666      0.736     -0.498      0.618      -1.809       1.076
C(answer_type_grouped)[T.Place]                0.0960      1.305      0.074      0.941      -2.463       2.655
q_length                                      -1.0094      0.765     -1.320      0.187      -2.508       0.489
capabilities_entropy                           1.5288      0.583      2.620      0.009       0.385       2.672
game_entropy                                   2.4494      0.755      3.246      0.001       0.970       3.928
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing gpt-4.1-2025-04-14 (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_neutral/gpt-4.1-2025-04-14_SimpleMC_neut_redacted_temp1.0_1757985243_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    185
1     57
Name: count, dtype: int64

Answer change%: 0.2355 [0.18207480446610497, 0.2889995756991843] (n=242)
P-value vs 25%: 0.596; P-value vs 0%: 5.876e-18
Phase 2 self-accuracy: 0.6140 [0.48765426736537676, 0.7404159080732198] (n=57)
P-value vs 25%: 1.646e-08; P-value vs 33%: 1.31e-05

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  242
Model:                          Logit   Df Residuals:                      240
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.07930
Time:                        09:26:55   Log-Likelihood:                -121.63
converged:                       True   LL-Null:                       -132.10
Covariance Type:            nonrobust   LLR p-value:                 4.710e-06
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          1.6662      0.635      2.624      0.009       0.422       2.911
p_i_capability    -3.6322      0.815     -4.455      0.000      -5.230      -2.034
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  242
Model:                          Logit   Df Residuals:                      240
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.08982
Time:                        09:26:55   Log-Likelihood:                -120.24
converged:                       True   LL-Null:                       -132.10
Covariance Type:            nonrobust   LLR p-value:                 1.107e-06
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.1967      0.296     -7.410      0.000      -2.778      -1.616
capabilities_entropy     1.3810      0.299      4.620      0.000       0.795       1.967
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.7115 [0.5884, 0.8347] (n=52)
                  P-value vs 33.3%: 1.746e-09

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=-4.04, p=0.000102
Wilcoxon delta_p: statistic=1592.00, p=8.88e-05
Mean Δp = -0.0879  [-0.1305, -0.0452]
Idea 1 N = 106; 

  Idea 1.5: Calibration Metrics
  NLL: 4.1011, Signed ECE (overconf pos under neg): 0.1191, ECE: 0.1191 (n=145)
  Brier: 0.0299, Reliability (absolute calibration error; lower better): 0.0291, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=145)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.832
Model:                            OLS   Adj. R-squared:                  0.829
Method:                 Least Squares   F-statistic:                     233.4
Date:                Sat, 20 Sep 2025   Prob (F-statistic):           1.80e-54
Time:                        09:26:55   Log-Likelihood:                 70.215
No. Observations:                 145   AIC:                            -132.4
Df Residuals:                     141   BIC:                            -120.5
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.7399      0.063    -11.788      0.000      -0.864      -0.616
p1                    0.8328      0.078     10.685      0.000       0.679       0.987
answer_changed        0.6207      0.119      5.213      0.000       0.385       0.856
p1:answer_changed     0.1869      0.165      1.131      0.260      -0.140       0.514
==============================================================================
Omnibus:                       13.699   Durbin-Watson:                   1.965
Prob(Omnibus):                  0.001   Jarque-Bera (JB):               15.601
Skew:                           0.803   Prob(JB):                     0.000410
Kurtosis:                       2.923   Cond. No.                         21.7
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=6.19, p=1.19e-08
Wilcoxon delta_H: statistic=1051.00, p=1.86e-08
Mean ΔH = 0.2783  [0.1902, 0.3665]
Paired t-test delta_H Changed: statistic=6.91, p=3.29e-08
Wilcoxon delta_H Changed: statistic=42.00, p=4.14e-08
Mean ΔH Changed = 0.4692  [0.3361, 0.6024]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=6.86, p=1.86e-10
Wilcoxon (p_top2_game vs p_top2_base): statistic=1303.00, p=3.42e-15
Mean Δp_top2 = 0.0449  [0.0321, 0.0577] (n=145)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=8.64, p=9.74e-15
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=1553.00, p=1.57e-13
Mean ΔH_unchosen_baseline_set = 0.3297  [0.2549, 0.4045] (n=145)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  145
Model:                          Logit   Df Residuals:                      142
Method:                           MLE   Df Model:                            2
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.07597
Time:                        09:26:55   Log-Likelihood:                -78.010
converged:                       True   LL-Null:                       -84.423
Covariance Type:            nonrobust   LLR p-value:                  0.001640
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.7388      0.268     -2.757      0.006      -1.264      -0.213
p1_z            -0.8031      0.250     -3.214      0.001      -1.293      -0.313
I(p1_z ** 2)    -0.3996      0.225     -1.779      0.075      -0.840       0.041
================================================================================
AUC = 0.672

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  242
Model:                          Logit   Df Residuals:                      240
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.04088
Time:                        09:26:55   Log-Likelihood:                -126.70
converged:                       True   LL-Null:                       -132.10
Covariance Type:            nonrobust   LLR p-value:                  0.001015
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.5815      0.207     -7.633      0.000      -1.988      -1.175
game_entropy     1.0998      0.333      3.305      0.001       0.448       1.752
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=4174.00, p=1.85e-17
Paired t-test (game_entropy vs capabilities_entropy): statistic=-9.39, p=4.89e-18
Mean capabilities_entropy-game_entropy = 0.3148  [0.2490, 0.3805] (n=242)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  242
Model:                          Logit   Df Residuals:                      239
Method:                           MLE   Df Model:                            2
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.09640
Time:                        09:26:55   Log-Likelihood:                -119.37
converged:                       True   LL-Null:                       -132.10
Covariance Type:            nonrobust   LLR p-value:                 2.946e-06
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.2592      0.303     -7.452      0.000      -2.853      -1.665
capabilities_entropy     1.2136      0.325      3.733      0.000       0.576       1.851
game_entropy             0.4998      0.377      1.327      0.185      -0.238       1.238
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['Video games', 'TV shows', 'History']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.812500
                        1                 0.187500
Geography               0                 0.680000
                        1                 0.320000
Misc                    0                 0.647059
                        1                 0.352941
Music                   0                 0.842105
                        1                 0.157895
Other                   0                 0.782609
                        1                 0.217391
Politics                0                 0.775000
                        1                 0.225000
Science and technology  0                 0.730769
                        1                 0.269231
Sports                  0                 1.000000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.734694
                     1                 0.265306
Number               0                 0.804348
                     1                 0.195652
Other                0                 0.784314
                     1                 0.215686
Person               0                 0.765957
                     1                 0.234043
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.833333  0.166667           12
                       Number               0.666667  0.333333            6
                       Other                0.800000  0.200000            5
                       Person               0.888889  0.111111            9
Geography              Date                 0.500000  0.500000           12
                       Number               0.900000  0.100000           10
                       Other                0.666667  0.333333            3
Misc                   Date                 0.615385  0.384615           13
                       Number               0.800000  0.200000            5
                       Other                0.600000  0.400000           10
                       Person               0.666667  0.333333            6
Music                  Date                 0.857143  0.142857            7
                       Number               1.000000  0.000000            2
                       Other                0.875000  0.125000            8
                       Person               0.500000  0.500000            2
Other                  Date                 0.600000  0.400000           10
                       Number               1.000000  0.000000            3
                       Other                1.000000  0.000000            6
                       Person               0.750000  0.250000            4
Politics               Date                 0.823529  0.176471           17
                       Number               0.800000  0.200000            5
                       Other                0.750000  0.250000            8
                       Person               0.700000  0.300000           10
Science and technology Date                 0.772727  0.227273           22
                       Number               0.555556  0.444444            9
                       Other                0.714286  0.285714            7
                       Person               0.785714  0.214286           14
Sports                 Date                 1.000000  0.000000            5
                       Number               1.000000  0.000000            6
                       Other                1.000000  0.000000            4
                       Person               1.000000  0.000000            2

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  242
Model:                          Logit   Df Residuals:                      230
Method:                           MLE   Df Model:                           11
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.05544
Time:                        09:26:55   Log-Likelihood:                -124.78
converged:                      False   LL-Null:                       -132.10
Covariance Type:            nonrobust   LLR p-value:                    0.1992
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.4050      2.045     -0.687      0.492      -5.413       2.603
C(topic_grouped)[T.Geography]                  0.7490      0.645      1.162      0.245      -0.515       2.013
C(topic_grouped)[T.Misc]                       0.8648      0.582      1.485      0.137      -0.276       2.006
C(topic_grouped)[T.Music]                     -0.2015      0.785     -0.257      0.798      -1.741       1.338
C(topic_grouped)[T.Other]                      0.1755      0.683      0.257      0.797      -1.162       1.513
C(topic_grouped)[T.Politics]                   0.2113      0.596      0.354      0.723      -0.958       1.380
C(topic_grouped)[T.Science and technology]     0.4576      0.551      0.830      0.407      -0.623       1.538
C(topic_grouped)[T.Sports]                   -16.5693   2051.804     -0.008      0.994   -4038.032    4004.893
C(answer_type_grouped)[T.Number]              -0.3565      0.454     -0.785      0.432      -1.246       0.533
C(answer_type_grouped)[T.Other]               -0.2061      0.433     -0.476      0.634      -1.054       0.642
C(answer_type_grouped)[T.Person]              -0.1202      0.438     -0.275      0.784      -0.978       0.738
q_length                                       0.0148      0.435      0.034      0.973      -0.838       0.867
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.6324
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  242
Model:                          Logit   Df Residuals:                      229
Method:                           MLE   Df Model:                           12
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1456
Time:                        09:26:55   Log-Likelihood:                -112.87
converged:                      False   LL-Null:                       -132.10
Covariance Type:            nonrobust   LLR p-value:                 0.0001285
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -3.3913      2.264     -1.498      0.134      -7.828       1.046
C(topic_grouped)[T.Geography]                  0.4515      0.682      0.662      0.508      -0.884       1.787
C(topic_grouped)[T.Misc]                       0.7247      0.613      1.183      0.237      -0.476       1.925
C(topic_grouped)[T.Music]                      0.0571      0.819      0.070      0.944      -1.548       1.662
C(topic_grouped)[T.Other]                      0.2612      0.715      0.365      0.715      -1.140       1.662
C(topic_grouped)[T.Politics]                   0.0295      0.618      0.048      0.962      -1.181       1.240
C(topic_grouped)[T.Science and technology]     0.1965      0.580      0.339      0.735      -0.941       1.334
C(topic_grouped)[T.Sports]                   -27.5660    4.3e+05  -6.41e-05      1.000   -8.44e+05    8.43e+05
C(answer_type_grouped)[T.Number]              -0.2866      0.480     -0.597      0.550      -1.227       0.654
C(answer_type_grouped)[T.Other]                0.1263      0.465      0.271      0.786      -0.786       1.038
C(answer_type_grouped)[T.Person]               0.5424      0.488      1.111      0.267      -0.415       1.499
q_length                                       0.1899      0.473      0.401      0.688      -0.737       1.117
capabilities_entropy                           1.5308      0.335      4.572      0.000       0.875       2.187
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  242
Model:                          Logit   Df Residuals:                      229
Method:                           MLE   Df Model:                           12
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.09413
Time:                        09:26:55   Log-Likelihood:                -119.67
converged:                       True   LL-Null:                       -132.10
Covariance Type:            nonrobust   LLR p-value:                   0.01546
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -2.1908      2.105     -1.041      0.298      -6.316       1.935
C(topic_grouped)[T.Geography]                  0.3490      0.677      0.516      0.606      -0.977       1.675
C(topic_grouped)[T.Misc]                       0.8855      0.593      1.494      0.135      -0.276       2.047
C(topic_grouped)[T.Music]                     -0.2827      0.810     -0.349      0.727      -1.870       1.305
C(topic_grouped)[T.Other]                      0.4031      0.693      0.582      0.561      -0.955       1.761
C(topic_grouped)[T.Politics]                   0.0478      0.610      0.078      0.938      -1.148       1.244
C(topic_grouped)[T.Science and technology]     0.3594      0.562      0.639      0.523      -0.742       1.461
C(topic_grouped)[T.Sports]                   -44.3983   2.23e+09  -1.99e-08      1.000   -4.36e+09    4.36e+09
C(answer_type_grouped)[T.Number]              -0.3705      0.464     -0.799      0.424      -1.279       0.538
C(answer_type_grouped)[T.Other]               -0.2805      0.445     -0.630      0.528      -1.153       0.592
C(answer_type_grouped)[T.Person]              -0.0225      0.448     -0.050      0.960      -0.900       0.855
q_length                                       0.1118      0.445      0.251      0.802      -0.761       0.984
game_entropy                                   1.1575      0.364      3.178      0.001       0.444       1.871
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  242
Model:                          Logit   Df Residuals:                      228
Method:                           MLE   Df Model:                           13
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1509
Time:                        09:26:55   Log-Likelihood:                -112.17
converged:                       True   LL-Null:                       -132.10
Covariance Type:            nonrobust   LLR p-value:                 0.0001449
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -3.4367      2.257     -1.523      0.128      -7.860       0.986
C(topic_grouped)[T.Geography]                  0.3006      0.696      0.432      0.666      -1.064       1.666
C(topic_grouped)[T.Misc]                       0.7316      0.614      1.191      0.234      -0.472       1.935
C(topic_grouped)[T.Music]                     -0.0293      0.830     -0.035      0.972      -1.656       1.598
C(topic_grouped)[T.Other]                      0.3550      0.714      0.497      0.619      -1.045       1.755
C(topic_grouped)[T.Politics]                  -0.0267      0.622     -0.043      0.966      -1.246       1.193
C(topic_grouped)[T.Science and technology]     0.1810      0.580      0.312      0.755      -0.956       1.318
C(topic_grouped)[T.Sports]                   -38.8972   1.26e+08  -3.09e-07      1.000   -2.47e+08    2.47e+08
C(answer_type_grouped)[T.Number]              -0.2964      0.480     -0.617      0.537      -1.237       0.644
C(answer_type_grouped)[T.Other]                0.0588      0.472      0.125      0.901      -0.866       0.983
C(answer_type_grouped)[T.Person]               0.5001      0.489      1.022      0.307      -0.459       1.459
q_length                                       0.1988      0.472      0.421      0.674      -0.727       1.125
capabilities_entropy                           1.3574      0.364      3.727      0.000       0.644       2.071
game_entropy                                   0.4911      0.413      1.189      0.234      -0.318       1.300
==============================================================================================================

                  Model 6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length (after removing deterministic categories: defaultdict(<class 'list'>, {'topic_grouped': ['Sports']}))
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  225
Model:                          Logit   Df Residuals:                      214
Method:                           MLE   Df Model:                           10
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.02013
Time:                        09:26:55   Log-Likelihood:                -124.78
converged:                       True   LL-Null:                       -127.34
Covariance Type:            nonrobust   LLR p-value:                    0.8825
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.4050      2.045     -0.687      0.492      -5.413       2.603
C(topic_grouped)[T.Geography]                  0.7490      0.645      1.162      0.245      -0.515       2.013
C(topic_grouped)[T.Misc]                       0.8648      0.582      1.485      0.137      -0.276       2.006
C(topic_grouped)[T.Music]                     -0.2015      0.785     -0.257      0.798      -1.741       1.338
C(topic_grouped)[T.Other]                      0.1755      0.683      0.257      0.797      -1.162       1.513
C(topic_grouped)[T.Politics]                   0.2113      0.596      0.354      0.723      -0.958       1.380
C(topic_grouped)[T.Science and technology]     0.4576      0.551      0.830      0.407      -0.623       1.538
C(answer_type_grouped)[T.Number]              -0.3565      0.454     -0.785      0.432      -1.246       0.533
C(answer_type_grouped)[T.Other]               -0.2061      0.433     -0.476      0.634      -1.054       0.642
C(answer_type_grouped)[T.Person]              -0.1202      0.438     -0.275      0.784      -0.978       0.738
q_length                                       0.0148      0.435      0.034      0.973      -0.838       0.867
==============================================================================================================

                  Model 6.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  225
Model:                          Logit   Df Residuals:                      213
Method:                           MLE   Df Model:                           11
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1137
Time:                        09:26:55   Log-Likelihood:                -112.87
converged:                       True   LL-Null:                       -127.34
Covariance Type:            nonrobust   LLR p-value:                  0.002310
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -3.3913      2.264     -1.498      0.134      -7.828       1.046
C(topic_grouped)[T.Geography]                  0.4515      0.682      0.662      0.508      -0.884       1.787
C(topic_grouped)[T.Misc]                       0.7247      0.613      1.183      0.237      -0.476       1.925
C(topic_grouped)[T.Music]                      0.0571      0.819      0.070      0.944      -1.548       1.662
C(topic_grouped)[T.Other]                      0.2612      0.715      0.365      0.715      -1.140       1.662
C(topic_grouped)[T.Politics]                   0.0295      0.618      0.048      0.962      -1.181       1.240
C(topic_grouped)[T.Science and technology]     0.1965      0.580      0.339      0.735      -0.941       1.334
C(answer_type_grouped)[T.Number]              -0.2866      0.480     -0.597      0.550      -1.227       0.654
C(answer_type_grouped)[T.Other]                0.1263      0.465      0.271      0.786      -0.786       1.038
C(answer_type_grouped)[T.Person]               0.5424      0.488      1.111      0.267      -0.415       1.499
q_length                                       0.1899      0.473      0.401      0.688      -0.737       1.117
capabilities_entropy                           1.5308      0.335      4.572      0.000       0.875       2.187
==============================================================================================================

--- Analyzing gpt-4o-2024-08-06 (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_neutral/gpt-4o-2024-08-06_SimpleMC_neut_redacted_cor_temp1.0_1757986595_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    206
1     27
Name: count, dtype: int64

Answer change%: 0.1159 [0.0747809753138799, 0.1569786813384806] (n=233)
P-value vs 25%: 1.594e-10; P-value vs 0%: 3.272e-08
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=27)
P-value vs 25%: 0; P-value vs 33%: 0

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  233
Model:                          Logit   Df Residuals:                      231
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1988
Time:                        09:26:55   Log-Likelihood:                -66.950
converged:                       True   LL-Null:                       -83.562
Covariance Type:            nonrobust   LLR p-value:                 8.213e-09
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          2.3120      0.786      2.940      0.003       0.771       3.853
p_i_capability    -6.0256      1.186     -5.080      0.000      -8.350      -3.701
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  233
Model:                          Logit   Df Residuals:                      231
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1942
Time:                        09:26:55   Log-Likelihood:                -67.337
converged:                       True   LL-Null:                       -83.562
Covariance Type:            nonrobust   LLR p-value:                 1.223e-08
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -4.0280      0.571     -7.049      0.000      -5.148      -2.908
capabilities_entropy     2.0965      0.437      4.799      0.000       1.240       2.953
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.7778 [0.6210, 0.9346] (n=27)
                  P-value vs 33.3%: 2.777e-08

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=-4.10, p=6.12e-05
Wilcoxon delta_p: statistic=5048.00, p=6.31e-06
Mean Δp = -0.0426  [-0.0629, -0.0222]
Idea 1 N = 181; 

  Idea 1.5: Calibration Metrics
  NLL: 0.2698, Signed ECE (overconf pos under neg): -0.2069, ECE: 0.2069 (n=207)
  Brier: 0.0837, Reliability (absolute calibration error; lower better): 0.0830, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=207)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.615
Model:                            OLS   Adj. R-squared:                  0.609
Method:                 Least Squares   F-statistic:                     108.1
Date:                Sat, 20 Sep 2025   Prob (F-statistic):           7.39e-42
Time:                        09:26:55   Log-Likelihood:                 135.91
No. Observations:                 207   AIC:                            -263.8
Df Residuals:                     203   BIC:                            -250.5
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.3119      0.041     -7.530      0.000      -0.394      -0.230
p1                    0.3274      0.049      6.677      0.000       0.231       0.424
answer_changed        0.0196      0.113      0.174      0.862      -0.203       0.242
p1:answer_changed     0.7938      0.180      4.410      0.000       0.439       1.149
==============================================================================
Omnibus:                       10.199   Durbin-Watson:                   1.803
Prob(Omnibus):                  0.006   Jarque-Bera (JB):               14.095
Skew:                           0.327   Prob(JB):                     0.000870
Kurtosis:                       4.098   Cond. No.                         31.0
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=2.10, p=0.0368
Wilcoxon delta_H: statistic=6069.00, p=0.00215
Mean ΔH = 0.0665  [0.0045, 0.1285]
Paired t-test delta_H Changed: statistic=5.08, p=3.07e-05
Wilcoxon delta_H Changed: statistic=14.00, p=3.28e-06
Mean ΔH Changed = 0.4163  [0.2555, 0.5771]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=4.84, p=2.58e-06
Wilcoxon (p_top2_game vs p_top2_base): statistic=4939.00, p=1.47e-11
Mean Δp_top2 = 0.0223  [0.0133, 0.0314] (n=207)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=3.62, p=0.000373
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=6979.00, p=1.15e-05
Mean ΔH_unchosen_baseline_set = 0.1105  [0.0506, 0.1703] (n=207)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  207
Model:                          Logit   Df Residuals:                      204
Method:                           MLE   Df Model:                            2
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.2122
Time:                        09:26:55   Log-Likelihood:                -61.633
converged:                       True   LL-Null:                       -78.234
Covariance Type:            nonrobust   LLR p-value:                 6.168e-08
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -2.2715      0.368     -6.165      0.000      -2.994      -1.549
p1_z            -1.8587      0.529     -3.514      0.000      -2.895      -0.822
I(p1_z ** 2)    -0.5359      0.331     -1.619      0.106      -1.185       0.113
================================================================================
AUC = 0.821

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  233
Model:                          Logit   Df Residuals:                      231
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1327
Time:                        09:26:55   Log-Likelihood:                -72.471
converged:                       True   LL-Null:                       -83.562
Covariance Type:            nonrobust   LLR p-value:                 2.481e-06
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -3.1870      0.398     -8.001      0.000      -3.968      -2.406
game_entropy     1.6223      0.364      4.457      0.000       0.909       2.336
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=7029.00, p=1.46e-10
Paired t-test (game_entropy vs capabilities_entropy): statistic=-6.47, p=5.86e-10
Mean capabilities_entropy-game_entropy = 0.1553  [0.1082, 0.2024] (n=233)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  233
Model:                          Logit   Df Residuals:                      230
Method:                           MLE   Df Model:                            2
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1953
Time:                        09:26:55   Log-Likelihood:                -67.245
converged:                       True   LL-Null:                       -83.562
Covariance Type:            nonrobust   LLR p-value:                 8.200e-08
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -4.0274      0.571     -7.052      0.000      -5.147      -2.908
capabilities_entropy     1.9180      0.605      3.172      0.002       0.733       3.103
game_entropy             0.2317      0.544      0.426      0.670      -0.835       1.299
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': None
topic_grouped           answer_changed
Art                     0                 0.853659
                        1                 0.146341
Geography               0                 0.941176
                        1                 0.058824
Misc                    0                 0.777778
                        1                 0.222222
Music                   0                 0.833333
                        1                 0.166667
Other                   0                 0.958333
                        1                 0.041667
Politics                0                 0.875000
                        1                 0.125000
Science and technology  0                 0.930233
                        1                 0.069767
Sports                  0                 0.875000
                        1                 0.125000
TV shows                0                 0.875000
                        1                 0.125000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.819672
                     1                 0.180328
Number               0                 0.827586
                     1                 0.172414
Other                0                 0.982456
                     1                 0.017544
Person               0                 0.882353
                     1                 0.117647
Place                0                 0.888889
                     1                 0.111111
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.750000  0.250000            8
                       Number               0.750000  0.250000            4
                       Other                1.000000  0.000000            6
                       Person               0.900000  0.100000           20
                       Place                0.666667  0.333333            3
Geography              Date                 0.800000  0.200000            5
                       Number               1.000000  0.000000            4
                       Other                1.000000  0.000000            3
                       Place                1.000000  0.000000            5
Misc                   Date                 0.875000  0.125000            8
                       Number               0.666667  0.333333            3
                       Other                1.000000  0.000000            3
                       Person               0.500000  0.500000            2
                       Place                0.500000  0.500000            2
Music                  Date                 0.000000  1.000000            2
                       Number               0.666667  0.333333            3
                       Other                1.000000  0.000000            4
                       Person               1.000000  0.000000            9
Other                  Date                 1.000000  0.000000            6
                       Number               1.000000  0.000000            3
                       Other                0.833333  0.166667            6
                       Person               1.000000  0.000000            7
                       Place                1.000000  0.000000            2
Politics               Date                 0.818182  0.181818           11
                       Number               1.000000  0.000000            1
                       Other                1.000000  0.000000            8
                       Person               0.750000  0.250000            8
                       Place                1.000000  0.000000            4
Science and technology Date                 0.866667  0.133333           15
                       Number               1.000000  0.000000            5
                       Other                1.000000  0.000000           11
                       Person               0.916667  0.083333           12
Sports                 Date                 0.800000  0.200000            5
                       Number               0.600000  0.400000            5
                       Other                1.000000  0.000000            6
                       Person               1.000000  0.000000            6
                       Place                1.000000  0.000000            2
TV shows               Date                 1.000000  0.000000            1
                       Number               1.000000  0.000000            1
                       Other                1.000000  0.000000           10
                       Person               0.500000  0.500000            4

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  233
Model:                          Logit   Df Residuals:                      219
Method:                           MLE   Df Model:                           13
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1067
Time:                        09:26:55   Log-Likelihood:                -74.646
converged:                       True   LL-Null:                       -83.562
Covariance Type:            nonrobust   LLR p-value:                    0.1640
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -0.4088      2.774     -0.147      0.883      -5.846       5.028
C(topic_grouped)[T.Geography]                 -1.2232      1.161     -1.054      0.292      -3.499       1.052
C(topic_grouped)[T.Misc]                       0.2858      0.762      0.375      0.708      -1.208       1.780
C(topic_grouped)[T.Music]                      0.2674      0.799      0.335      0.738      -1.299       1.834
C(topic_grouped)[T.Other]                     -1.3812      1.129     -1.224      0.221      -3.594       0.831
C(topic_grouped)[T.Politics]                  -0.1394      0.738     -0.189      0.850      -1.586       1.307
C(topic_grouped)[T.Science and technology]    -0.8729      0.771     -1.132      0.258      -2.385       0.639
C(topic_grouped)[T.Sports]                    -0.1996      0.787     -0.254      0.800      -1.743       1.344
C(topic_grouped)[T.TV shows]                   0.6053      0.976      0.620      0.535      -1.308       2.519
C(answer_type_grouped)[T.Number]              -0.0550      0.645     -0.085      0.932      -1.320       1.210
C(answer_type_grouped)[T.Other]               -2.7674      1.107     -2.499      0.012      -4.938      -0.597
C(answer_type_grouped)[T.Person]              -0.7035      0.547     -1.287      0.198      -1.775       0.368
C(answer_type_grouped)[T.Place]               -0.5052      0.852     -0.593      0.553      -2.174       1.164
q_length                                      -0.1714      0.607     -0.282      0.778      -1.362       1.019
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.6543
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  233
Model:                          Logit   Df Residuals:                      218
Method:                           MLE   Df Model:                           14
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.2731
Time:                        09:26:55   Log-Likelihood:                -60.738
converged:                       True   LL-Null:                       -83.562
Covariance Type:            nonrobust   LLR p-value:                 3.200e-05
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -3.1593      3.153     -1.002      0.316      -9.339       3.020
C(topic_grouped)[T.Geography]                 -1.1381      1.232     -0.924      0.356      -3.553       1.277
C(topic_grouped)[T.Misc]                       0.6947      0.836      0.831      0.406      -0.945       2.334
C(topic_grouped)[T.Music]                      0.3601      0.929      0.388      0.698      -1.460       2.180
C(topic_grouped)[T.Other]                     -1.4835      1.183     -1.254      0.210      -3.802       0.835
C(topic_grouped)[T.Politics]                  -0.1752      0.795     -0.220      0.825      -1.732       1.382
C(topic_grouped)[T.Science and technology]    -0.3896      0.831     -0.469      0.639      -2.018       1.239
C(topic_grouped)[T.Sports]                    -0.0935      0.855     -0.109      0.913      -1.770       1.583
C(topic_grouped)[T.TV shows]                   0.3149      1.149      0.274      0.784      -1.938       2.568
C(answer_type_grouped)[T.Number]              -0.4766      0.743     -0.641      0.521      -1.934       0.981
C(answer_type_grouped)[T.Other]               -1.7599      1.197     -1.471      0.141      -4.105       0.586
C(answer_type_grouped)[T.Person]               0.5529      0.652      0.848      0.396      -0.725       1.830
C(answer_type_grouped)[T.Place]                0.0418      0.918      0.045      0.964      -1.758       1.842
q_length                                      -0.2035      0.674     -0.302      0.763      -1.525       1.118
capabilities_entropy                           2.3756      0.551      4.309      0.000       1.295       3.456
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  233
Model:                          Logit   Df Residuals:                      218
Method:                           MLE   Df Model:                           14
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.2198
Time:                        09:26:55   Log-Likelihood:                -65.199
converged:                       True   LL-Null:                       -83.562
Covariance Type:            nonrobust   LLR p-value:                 0.0008117
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.3738      3.038     -0.452      0.651      -7.327       4.580
C(topic_grouped)[T.Geography]                 -1.3111      1.238     -1.059      0.290      -3.738       1.116
C(topic_grouped)[T.Misc]                       0.5828      0.807      0.723      0.470      -0.998       2.164
C(topic_grouped)[T.Music]                      0.2035      0.881      0.231      0.817      -1.524       1.931
C(topic_grouped)[T.Other]                     -1.7669      1.188     -1.488      0.137      -4.095       0.561
C(topic_grouped)[T.Politics]                   0.1018      0.780      0.130      0.896      -1.428       1.632
C(topic_grouped)[T.Science and technology]    -0.7829      0.815     -0.961      0.337      -2.380       0.815
C(topic_grouped)[T.Sports]                    -0.3479      0.844     -0.412      0.680      -2.002       1.306
C(topic_grouped)[T.TV shows]                   0.6837      1.081      0.633      0.527      -1.434       2.801
C(answer_type_grouped)[T.Number]              -0.1634      0.708     -0.231      0.817      -1.551       1.224
C(answer_type_grouped)[T.Other]               -2.1594      1.207     -1.789      0.074      -4.525       0.206
C(answer_type_grouped)[T.Person]               0.0780      0.619      0.126      0.900      -1.135       1.291
C(answer_type_grouped)[T.Place]               -0.1444      0.910     -0.159      0.874      -1.928       1.639
q_length                                      -0.3206      0.672     -0.477      0.633      -1.637       0.996
game_entropy                                   1.7439      0.431      4.051      0.000       0.900       2.588
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  233
Model:                          Logit   Df Residuals:                      217
Method:                           MLE   Df Model:                           15
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.2772
Time:                        09:26:55   Log-Likelihood:                -60.394
converged:                       True   LL-Null:                       -83.562
Covariance Type:            nonrobust   LLR p-value:                 4.703e-05
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -2.9326      3.180     -0.922      0.356      -9.165       3.300
C(topic_grouped)[T.Geography]                 -1.1793      1.247     -0.946      0.344      -3.622       1.264
C(topic_grouped)[T.Misc]                       0.7388      0.835      0.885      0.376      -0.898       2.375
C(topic_grouped)[T.Music]                      0.3184      0.935      0.340      0.734      -1.515       2.152
C(topic_grouped)[T.Other]                     -1.5768      1.196     -1.318      0.187      -3.921       0.767
C(topic_grouped)[T.Politics]                  -0.0776      0.804     -0.096      0.923      -1.654       1.499
C(topic_grouped)[T.Science and technology]    -0.4436      0.840     -0.528      0.598      -2.091       1.204
C(topic_grouped)[T.Sports]                    -0.1382      0.863     -0.160      0.873      -1.829       1.553
C(topic_grouped)[T.TV shows]                   0.3909      1.146      0.341      0.733      -1.854       2.636
C(answer_type_grouped)[T.Number]              -0.4380      0.746     -0.587      0.557      -1.900       1.024
C(answer_type_grouped)[T.Other]               -1.7583      1.212     -1.450      0.147      -4.134       0.618
C(answer_type_grouped)[T.Person]               0.5948      0.657      0.905      0.366      -0.694       1.883
C(answer_type_grouped)[T.Place]                0.0463      0.925      0.050      0.960      -1.767       1.860
q_length                                      -0.2647      0.684     -0.387      0.699      -1.606       1.076
capabilities_entropy                           2.0293      0.690      2.940      0.003       0.677       3.382
game_entropy                                   0.4807      0.583      0.824      0.410      -0.662       1.624
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing gpt-4o-2024-08-06 (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_neutral/gpt-4o-2024-08-06_SimpleMC_neut_redacted_temp1.0_1757985534_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    186
1     81
Name: count, dtype: int64

Answer change%: 0.3034 [0.2482290827848562, 0.3585124902488517] (n=267)
P-value vs 25%: 0.05783; P-value vs 0%: 4.139e-27
Phase 2 self-accuracy: 0.5556 [0.44734289622511336, 0.6637682148859978] (n=81)
P-value vs 25%: 3.125e-08; P-value vs 33%: 5.555e-05

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  267
Model:                          Logit   Df Residuals:                      265
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1135
Time:                        09:26:55   Log-Likelihood:                -145.26
converged:                       True   LL-Null:                       -163.86
Covariance Type:            nonrobust   LLR p-value:                 1.070e-09
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          1.9081      0.490      3.891      0.000       0.947       2.869
p_i_capability    -4.3115      0.781     -5.519      0.000      -5.843      -2.780
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  267
Model:                          Logit   Df Residuals:                      265
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.08870
Time:                        09:26:55   Log-Likelihood:                -149.32
converged:                       True   LL-Null:                       -163.86
Covariance Type:            nonrobust   LLR p-value:                 6.991e-08
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.5040      0.397     -6.304      0.000      -3.283      -1.726
capabilities_entropy     1.4172      0.292      4.849      0.000       0.844       1.990
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.7901 [0.7014, 0.8788] (n=81)
                  P-value vs 33.3%: 5.781e-24

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=-5.04, p=1.16e-06
Wilcoxon delta_p: statistic=4850.00, p=2.52e-06
Mean Δp = -0.0606  [-0.0841, -0.0370]
Idea 1 N = 180; 

  Idea 1.5: Calibration Metrics
  NLL: 2.8878, Signed ECE (overconf pos under neg): 0.1610, ECE: 0.1610 (n=261)
  Brier: 0.0453, Reliability (absolute calibration error; lower better): 0.0444, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=261)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.740
Model:                            OLS   Adj. R-squared:                  0.737
Method:                 Least Squares   F-statistic:                     243.9
Date:                Sat, 20 Sep 2025   Prob (F-statistic):           7.06e-75
Time:                        09:26:55   Log-Likelihood:                 147.65
No. Observations:                 261   AIC:                            -287.3
Df Residuals:                     257   BIC:                            -273.0
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.3515      0.039     -8.968      0.000      -0.429      -0.274
p1                    0.4073      0.053      7.695      0.000       0.303       0.512
answer_changed        0.1370      0.061      2.233      0.026       0.016       0.258
p1:answer_changed     0.6175      0.096      6.435      0.000       0.429       0.806
==============================================================================
Omnibus:                        2.711   Durbin-Watson:                   1.939
Prob(Omnibus):                  0.258   Jarque-Bera (JB):                2.665
Skew:                           0.246   Prob(JB):                        0.264
Kurtosis:                       2.952   Cond. No.                         17.7
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=3.77, p=0.000226
Wilcoxon delta_H: statistic=5553.00, p=0.000213
Mean ΔH = 0.1104  [0.0529, 0.1679]
Paired t-test delta_H Changed: statistic=8.89, p=1.47e-13
Wilcoxon delta_H Changed: statistic=262.00, p=4.56e-11
Mean ΔH Changed = 0.3624  [0.2824, 0.4423]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=6.66, p=1.66e-10
Wilcoxon (p_top2_game vs p_top2_base): statistic=8256.00, p=4.45e-13
Mean Δp_top2 = 0.0374  [0.0264, 0.0484] (n=261)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=7.58, p=6.16e-13
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=8431.00, p=1.27e-12
Mean ΔH_unchosen_baseline_set = 0.1886  [0.1398, 0.2374] (n=261)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  261
Model:                          Logit   Df Residuals:                      258
Method:                           MLE   Df Model:                            2
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1241
Time:                        09:26:55   Log-Likelihood:                -141.59
converged:                       True   LL-Null:                       -161.66
Covariance Type:            nonrobust   LLR p-value:                 1.933e-09
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.3351      0.229     -5.819      0.000      -1.785      -0.885
p1_z            -0.8802      0.156     -5.654      0.000      -1.185      -0.575
I(p1_z ** 2)     0.4302      0.178      2.414      0.016       0.081       0.780
================================================================================
AUC = 0.707

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  267
Model:                          Logit   Df Residuals:                      265
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.06500
Time:                        09:26:55   Log-Likelihood:                -153.20
converged:                       True   LL-Null:                       -163.86
Covariance Type:            nonrobust   LLR p-value:                 3.922e-06
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.9861      0.315     -6.309      0.000      -2.603      -1.369
game_entropy     1.1958      0.274      4.369      0.000       0.659       1.732
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=9094.00, p=3.31e-12
Paired t-test (game_entropy vs capabilities_entropy): statistic=-7.03, p=1.7e-11
Mean capabilities_entropy-game_entropy = 0.1888  [0.1362, 0.2415] (n=267)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  267
Model:                          Logit   Df Residuals:                      264
Method:                           MLE   Df Model:                            2
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.09430
Time:                        09:26:55   Log-Likelihood:                -148.40
converged:                       True   LL-Null:                       -163.86
Covariance Type:            nonrobust   LLR p-value:                 1.947e-07
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.6051      0.407     -6.398      0.000      -3.403      -1.807
capabilities_entropy     1.1087      0.369      3.008      0.003       0.386       1.831
game_entropy             0.4790      0.355      1.348      0.178      -0.218       1.176
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['Sports', 'Video games', 'TV shows', 'History']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.558824
                        1                 0.441176
Geography               0                 0.666667
                        1                 0.333333
Misc                    0                 0.714286
                        1                 0.285714
Music                   0                 0.818182
                        1                 0.181818
Other                   0                 0.785714
                        1                 0.214286
Politics                0                 0.555556
                        1                 0.444444
Science and technology  0                 0.800000
                        1                 0.200000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.592593
                     1                 0.407407
Number               0                 0.673469
                     1                 0.326531
Other                0                 0.775862
                     1                 0.224138
Person               0                 0.846154
                     1                 0.153846
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.538462  0.461538           13
                       Number               0.800000  0.200000            5
                       Other                0.444444  0.555556            9
                       Person               0.571429  0.428571            7
Geography              Date                 0.400000  0.600000           10
                       Number               0.785714  0.214286           14
                       Other                1.000000  0.000000            3
Misc                   Date                 0.722222  0.277778           18
                       Number               0.454545  0.545455           11
                       Other                0.687500  0.312500           16
                       Person               1.000000  0.000000           11
Music                  Date                 0.700000  0.300000           10
                       Number               1.000000  0.000000            1
                       Other                1.000000  0.000000            8
                       Person               0.666667  0.333333            3
Other                  Date                 0.583333  0.416667           12
                       Number               0.750000  0.250000            4
                       Other                1.000000  0.000000            6
                       Person               1.000000  0.000000            6
Politics               Date                 0.480000  0.520000           25
                       Number               0.200000  0.800000            5
                       Other                0.750000  0.250000            8
                       Person               0.857143  0.142857            7
Science and technology Date                 0.700000  0.300000           20
                       Number               0.888889  0.111111            9
                       Other                0.875000  0.125000            8
                       Person               0.833333  0.166667           18

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  267
Model:                          Logit   Df Residuals:                      256
Method:                           MLE   Df Model:                           10
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.07674
Time:                        09:26:55   Log-Likelihood:                -151.28
converged:                       True   LL-Null:                       -163.86
Covariance Type:            nonrobust   LLR p-value:                  0.005073
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      1.2148      1.781      0.682      0.495      -2.275       4.705
C(topic_grouped)[T.Geography]                 -0.7455      0.564     -1.321      0.186      -1.851       0.360
C(topic_grouped)[T.Misc]                      -0.6646      0.472     -1.409      0.159      -1.589       0.260
C(topic_grouped)[T.Music]                     -1.3761      0.669     -2.056      0.040      -2.688      -0.064
C(topic_grouped)[T.Other]                     -1.1742      0.593     -1.981      0.048      -2.336      -0.012
C(topic_grouped)[T.Politics]                  -0.0947      0.483     -0.196      0.845      -1.042       0.853
C(topic_grouped)[T.Science and technology]    -1.1473      0.500     -2.296      0.022      -2.126      -0.168
C(answer_type_grouped)[T.Number]              -0.3343      0.384     -0.870      0.384      -1.087       0.419
C(answer_type_grouped)[T.Other]               -0.9046      0.387     -2.335      0.020      -1.664      -0.145
C(answer_type_grouped)[T.Person]              -1.3289      0.450     -2.952      0.003      -2.211      -0.447
q_length                                      -0.2047      0.385     -0.532      0.595      -0.959       0.550
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 1.0850
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  267
Model:                          Logit   Df Residuals:                      255
Method:                           MLE   Df Model:                           11
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1472
Time:                        09:26:55   Log-Likelihood:                -139.74
converged:                       True   LL-Null:                       -163.86
Covariance Type:            nonrobust   LLR p-value:                 1.295e-06
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -0.6202      1.892     -0.328      0.743      -4.328       3.088
C(topic_grouped)[T.Geography]                 -0.9938      0.596     -1.668      0.095      -2.161       0.174
C(topic_grouped)[T.Misc]                      -0.8169      0.498     -1.639      0.101      -1.794       0.160
C(topic_grouped)[T.Music]                     -1.4820      0.709     -2.090      0.037      -2.872      -0.092
C(topic_grouped)[T.Other]                     -1.2082      0.630     -1.917      0.055      -2.444       0.027
C(topic_grouped)[T.Politics]                  -0.1614      0.523     -0.308      0.758      -1.187       0.865
C(topic_grouped)[T.Science and technology]    -1.2649      0.529     -2.392      0.017      -2.301      -0.229
C(answer_type_grouped)[T.Number]              -0.4654      0.403     -1.156      0.248      -1.255       0.324
C(answer_type_grouped)[T.Other]               -0.7135      0.403     -1.770      0.077      -1.504       0.077
C(answer_type_grouped)[T.Person]              -0.9564      0.470     -2.034      0.042      -1.878      -0.035
q_length                                      -0.1506      0.402     -0.375      0.708      -0.938       0.637
capabilities_entropy                           1.3781      0.313      4.406      0.000       0.765       1.991
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  267
Model:                          Logit   Df Residuals:                      255
Method:                           MLE   Df Model:                           11
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1228
Time:                        09:26:55   Log-Likelihood:                -143.73
converged:                       True   LL-Null:                       -163.86
Covariance Type:            nonrobust   LLR p-value:                 3.245e-05
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -0.3177      1.872     -0.170      0.865      -3.988       3.352
C(topic_grouped)[T.Geography]                 -0.8886      0.586     -1.516      0.129      -2.037       0.260
C(topic_grouped)[T.Misc]                      -0.7095      0.488     -1.454      0.146      -1.666       0.247
C(topic_grouped)[T.Music]                     -1.3401      0.688     -1.947      0.052      -2.689       0.009
C(topic_grouped)[T.Other]                     -1.0564      0.616     -1.714      0.087      -2.264       0.152
C(topic_grouped)[T.Politics]                  -0.0306      0.508     -0.060      0.952      -1.027       0.965
C(topic_grouped)[T.Science and technology]    -1.0988      0.518     -2.123      0.034      -2.113      -0.084
C(answer_type_grouped)[T.Number]              -0.3578      0.396     -0.903      0.367      -1.135       0.419
C(answer_type_grouped)[T.Other]               -0.7571      0.398     -1.902      0.057      -1.537       0.023
C(answer_type_grouped)[T.Person]              -1.0145      0.465     -2.181      0.029      -1.926      -0.103
q_length                                      -0.1180      0.398     -0.297      0.767      -0.898       0.661
game_entropy                                   1.0951      0.293      3.735      0.000       0.520       1.670
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  267
Model:                          Logit   Df Residuals:                      254
Method:                           MLE   Df Model:                           12
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1507
Time:                        09:26:55   Log-Likelihood:                -139.17
converged:                       True   LL-Null:                       -163.86
Covariance Type:            nonrobust   LLR p-value:                 1.794e-06
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -0.8607      1.914     -0.450      0.653      -4.613       2.891
C(topic_grouped)[T.Geography]                 -1.0150      0.598     -1.697      0.090      -2.187       0.157
C(topic_grouped)[T.Misc]                      -0.8106      0.499     -1.624      0.104      -1.789       0.168
C(topic_grouped)[T.Music]                     -1.4668      0.710     -2.067      0.039      -2.858      -0.076
C(topic_grouped)[T.Other]                     -1.1732      0.634     -1.851      0.064      -2.416       0.069
C(topic_grouped)[T.Politics]                  -0.1411      0.526     -0.268      0.789      -1.173       0.891
C(topic_grouped)[T.Science and technology]    -1.2420      0.531     -2.340      0.019      -2.282      -0.202
C(answer_type_grouped)[T.Number]              -0.4608      0.405     -1.138      0.255      -1.254       0.333
C(answer_type_grouped)[T.Other]               -0.6965      0.404     -1.726      0.084      -1.487       0.094
C(answer_type_grouped)[T.Person]              -0.9139      0.472     -1.936      0.053      -1.839       0.011
q_length                                      -0.1238      0.405     -0.306      0.760      -0.917       0.669
capabilities_entropy                           1.1354      0.385      2.945      0.003       0.380       1.891
game_entropy                                   0.3958      0.371      1.066      0.286      -0.332       1.124
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing gpt-4o-mini (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_neutral/gpt-4o-mini_SimpleMC_neut_redacted_cor_temp1.0_1757986798_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    141
1     31
Name: count, dtype: int64

Answer change%: 0.1802 [0.12278840597970297, 0.23767671029936677] (n=172)
P-value vs 25%: 0.01729; P-value vs 0%: 7.776e-10
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=31)
P-value vs 25%: 0; P-value vs 33%: 0

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  172
Model:                          Logit   Df Residuals:                      170
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1430
Time:                        09:26:55   Log-Likelihood:                -69.534
converged:                       True   LL-Null:                       -81.140
Covariance Type:            nonrobust   LLR p-value:                 1.450e-06
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          2.3553      0.828      2.843      0.004       0.732       3.979
p_i_capability    -5.0430      1.112     -4.534      0.000      -7.223      -2.863
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  172
Model:                          Logit   Df Residuals:                      170
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1172
Time:                        09:26:55   Log-Likelihood:                -71.629
converged:                       True   LL-Null:                       -81.140
Covariance Type:            nonrobust   LLR p-value:                 1.291e-05
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.8179      0.436     -6.467      0.000      -3.672      -1.964
capabilities_entropy     1.6583      0.412      4.030      0.000       0.852       2.465
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.8000 [0.6569, 0.9431] (n=30)
                  P-value vs 33.3%: 1.658e-10

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=-2.98, p=0.00348
Wilcoxon delta_p: statistic=2202.00, p=0.000184
Mean Δp = -0.0417  [-0.0690, -0.0143]
Idea 1 N = 120; 

  Idea 1.5: Calibration Metrics
  NLL: 0.2569, Signed ECE (overconf pos under neg): -0.2008, ECE: 0.2008 (n=149)
  Brier: 0.0756, Reliability (absolute calibration error; lower better): 0.0748, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=149)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.754
Model:                            OLS   Adj. R-squared:                  0.749
Method:                 Least Squares   F-statistic:                     148.3
Date:                Sat, 20 Sep 2025   Prob (F-statistic):           5.56e-44
Time:                        09:26:55   Log-Likelihood:                 90.246
No. Observations:                 149   AIC:                            -172.5
Df Residuals:                     145   BIC:                            -160.5
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.4175      0.061     -6.892      0.000      -0.537      -0.298
p1                    0.4516      0.071      6.335      0.000       0.311       0.592
answer_changed        0.0923      0.108      0.852      0.396      -0.122       0.306
p1:answer_changed     0.7282      0.149      4.903      0.000       0.435       1.022
==============================================================================
Omnibus:                       17.566   Durbin-Watson:                   2.049
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               19.935
Skew:                           0.824   Prob(JB):                     4.69e-05
Kurtosis:                       3.706   Cond. No.                         22.6
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=2.61, p=0.0102
Wilcoxon delta_H: statistic=2733.00, p=0.0188
Mean ΔH = 0.0903  [0.0226, 0.1581]
Paired t-test delta_H Changed: statistic=4.52, p=0.000103
Wilcoxon delta_H Changed: statistic=43.00, p=4.7e-05
Mean ΔH Changed = 0.3596  [0.2036, 0.5156]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=4.38, p=2.2e-05
Wilcoxon (p_top2_game vs p_top2_base): statistic=2744.00, p=7.1e-08
Mean Δp_top2 = 0.0215  [0.0119, 0.0311] (n=149)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=4.33, p=2.69e-05
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=3531.00, p=9.73e-05
Mean ΔH_unchosen_baseline_set = 0.1427  [0.0782, 0.2073] (n=149)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  149
Model:                          Logit   Df Residuals:                      146
Method:                           MLE   Df Model:                            2
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1262
Time:                        09:26:55   Log-Likelihood:                -64.169
converged:                       True   LL-Null:                       -73.437
Covariance Type:            nonrobust   LLR p-value:                 9.438e-05
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.6389      0.311     -5.275      0.000      -2.248      -1.030
p1_z            -0.9107      0.314     -2.903      0.004      -1.526      -0.296
I(p1_z ** 2)    -0.0173      0.237     -0.073      0.942      -0.481       0.447
================================================================================
AUC = 0.753

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  172
Model:                          Logit   Df Residuals:                      170
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1203
Time:                        09:26:55   Log-Likelihood:                -71.377
converged:                       True   LL-Null:                       -81.140
Covariance Type:            nonrobust   LLR p-value:                 9.925e-06
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -2.5457      0.364     -6.986      0.000      -3.260      -1.832
game_entropy     1.6917      0.403      4.202      0.000       0.903       2.481
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=3600.00, p=3.02e-08
Paired t-test (game_entropy vs capabilities_entropy): statistic=-5.28, p=3.88e-07
Mean capabilities_entropy-game_entropy = 0.1602  [0.1007, 0.2196] (n=172)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  172
Model:                          Logit   Df Residuals:                      169
Method:                           MLE   Df Model:                            2
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1394
Time:                        09:26:55   Log-Likelihood:                -69.831
converged:                       True   LL-Null:                       -81.140
Covariance Type:            nonrobust   LLR p-value:                 1.226e-05
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.8964      0.442     -6.557      0.000      -3.762      -2.031
capabilities_entropy     0.9565      0.550      1.740      0.082      -0.121       2.034
game_entropy             1.0309      0.548      1.881      0.060      -0.043       2.105
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.823529
                        1                 0.176471
Geography               0                 0.692308
                        1                 0.307692
Misc                    0                 0.826087
                        1                 0.173913
Music                   0                 0.833333
                        1                 0.166667
Other                   0                 0.941176
                        1                 0.058824
Politics                0                 0.814815
                        1                 0.185185
Science and technology  0                 0.757576
                        1                 0.242424
Sports                  0                 0.923077
                        1                 0.076923
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.756098
                     1                 0.243902
Number               0                 0.833333
                     1                 0.166667
Other                0                 0.851852
                     1                 0.148148
Person               0                 0.829787
                     1                 0.170213
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.666667  0.333333            6
                       Number               0.833333  0.166667            6
                       Other                0.857143  0.142857            7
                       Person               0.866667  0.133333           15
Geography              Date                 0.000000  1.000000            1
                       Number               0.625000  0.375000            8
                       Other                1.000000  0.000000            4
Misc                   Date                 0.666667  0.333333            6
                       Number               1.000000  0.000000            3
                       Other                1.000000  0.000000            9
                       Person               0.600000  0.400000            5
Music                  Date                 0.666667  0.333333            3
                       Number               1.000000  0.000000            1
                       Other                0.750000  0.250000            4
                       Person               1.000000  0.000000            4
Other                  Date                 1.000000  0.000000            4
                       Number               1.000000  0.000000            2
                       Other                1.000000  0.000000            5
                       Person               0.833333  0.166667            6
Politics               Date                 0.750000  0.250000            8
                       Number               1.000000  0.000000            1
                       Other                0.769231  0.230769           13
                       Person               1.000000  0.000000            5
Science and technology Date                 0.833333  0.166667           12
                       Number               0.833333  0.166667            6
                       Other                0.750000  0.250000            8
                       Person               0.571429  0.428571            7
Sports                 Date                 1.000000  0.000000            1
                       Number               1.000000  0.000000            3
                       Other                0.750000  0.250000            4
                       Person               1.000000  0.000000            5

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  172
Model:                          Logit   Df Residuals:                      160
Method:                           MLE   Df Model:                           11
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.04412
Time:                        09:26:55   Log-Likelihood:                -77.560
converged:                       True   LL-Null:                       -81.140
Covariance Type:            nonrobust   LLR p-value:                    0.7860
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.1762      2.838     -0.414      0.679      -6.739       4.386
C(topic_grouped)[T.Geography]                  1.0059      0.827      1.217      0.224      -0.615       2.626
C(topic_grouped)[T.Misc]                      -0.0056      0.725     -0.008      0.994      -1.427       1.416
C(topic_grouped)[T.Music]                     -0.0918      0.904     -0.102      0.919      -1.863       1.680
C(topic_grouped)[T.Other]                     -1.2558      1.131     -1.111      0.267      -3.472       0.960
C(topic_grouped)[T.Politics]                   0.0500      0.695      0.072      0.943      -1.312       1.412
C(topic_grouped)[T.Science and technology]     0.3599      0.629      0.573      0.567      -0.872       1.592
C(topic_grouped)[T.Sports]                    -0.8601      1.147     -0.750      0.453      -3.108       1.388
C(answer_type_grouped)[T.Number]              -0.7383      0.702     -1.052      0.293      -2.114       0.637
C(answer_type_grouped)[T.Other]               -0.6181      0.546     -1.133      0.257      -1.687       0.451
C(answer_type_grouped)[T.Person]              -0.2838      0.557     -0.510      0.610      -1.375       0.807
q_length                                      -0.0005      0.629     -0.001      0.999      -1.233       1.232
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.6319
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  172
Model:                          Logit   Df Residuals:                      159
Method:                           MLE   Df Model:                           12
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1632
Time:                        09:26:55   Log-Likelihood:                -67.897
converged:                       True   LL-Null:                       -81.140
Covariance Type:            nonrobust   LLR p-value:                  0.009154
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -4.5225      3.235     -1.398      0.162     -10.864       1.819
C(topic_grouped)[T.Geography]                  0.9431      0.909      1.038      0.299      -0.838       2.724
C(topic_grouped)[T.Misc]                       0.0039      0.770      0.005      0.996      -1.506       1.514
C(topic_grouped)[T.Music]                     -0.4026      0.982     -0.410      0.682      -2.328       1.523
C(topic_grouped)[T.Other]                     -1.5870      1.182     -1.343      0.179      -3.903       0.729
C(topic_grouped)[T.Politics]                  -0.2294      0.747     -0.307      0.759      -1.693       1.234
C(topic_grouped)[T.Science and technology]     0.2642      0.663      0.398      0.690      -1.036       1.564
C(topic_grouped)[T.Sports]                    -0.6307      1.181     -0.534      0.593      -2.946       1.685
C(answer_type_grouped)[T.Number]              -0.7551      0.760     -0.994      0.320      -2.244       0.734
C(answer_type_grouped)[T.Other]                0.1558      0.611      0.255      0.799      -1.041       1.353
C(answer_type_grouped)[T.Person]               0.6399      0.632      1.012      0.311      -0.599       1.879
q_length                                       0.3307      0.686      0.482      0.630      -1.014       1.675
capabilities_entropy                           1.8923      0.468      4.042      0.000       0.975       2.810
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  172
Model:                          Logit   Df Residuals:                      159
Method:                           MLE   Df Model:                           12
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1630
Time:                        09:26:55   Log-Likelihood:                -67.914
converged:                       True   LL-Null:                       -81.140
Covariance Type:            nonrobust   LLR p-value:                  0.009259
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -3.4695      3.105     -1.117      0.264      -9.556       2.617
C(topic_grouped)[T.Geography]                  0.7559      0.920      0.822      0.411      -1.047       2.559
C(topic_grouped)[T.Misc]                       0.2106      0.784      0.269      0.788      -1.327       1.748
C(topic_grouped)[T.Music]                      0.0408      0.977      0.042      0.967      -1.874       1.955
C(topic_grouped)[T.Other]                     -1.5146      1.184     -1.279      0.201      -3.836       0.806
C(topic_grouped)[T.Politics]                   0.1309      0.742      0.176      0.860      -1.324       1.586
C(topic_grouped)[T.Science and technology]     0.2497      0.671      0.372      0.710      -1.065       1.564
C(topic_grouped)[T.Sports]                    -1.1229      1.207     -0.930      0.352      -3.489       1.243
C(answer_type_grouped)[T.Number]              -0.8045      0.751     -1.071      0.284      -2.276       0.667
C(answer_type_grouped)[T.Other]               -0.3971      0.592     -0.670      0.503      -1.558       0.764
C(answer_type_grouped)[T.Person]               0.1786      0.602      0.297      0.766      -1.000       1.358
q_length                                       0.2316      0.678      0.342      0.733      -1.098       1.561
game_entropy                                   1.7989      0.433      4.155      0.000       0.950       2.647
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  172
Model:                          Logit   Df Residuals:                      158
Method:                           MLE   Df Model:                           13
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1855
Time:                        09:26:55   Log-Likelihood:                -66.086
converged:                       True   LL-Null:                       -81.140
Covariance Type:            nonrobust   LLR p-value:                  0.004542
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -4.7382      3.282     -1.444      0.149     -11.171       1.694
C(topic_grouped)[T.Geography]                  0.8260      0.938      0.881      0.378      -1.011       2.664
C(topic_grouped)[T.Misc]                       0.1349      0.793      0.170      0.865      -1.420       1.690
C(topic_grouped)[T.Music]                     -0.2218      1.012     -0.219      0.827      -2.206       1.763
C(topic_grouped)[T.Other]                     -1.7035      1.210     -1.407      0.159      -4.076       0.669
C(topic_grouped)[T.Politics]                  -0.0415      0.755     -0.055      0.956      -1.522       1.439
C(topic_grouped)[T.Science and technology]     0.2248      0.673      0.334      0.738      -1.094       1.544
C(topic_grouped)[T.Sports]                    -0.8339      1.205     -0.692      0.489      -3.196       1.529
C(answer_type_grouped)[T.Number]              -0.7926      0.765     -1.035      0.300      -2.293       0.708
C(answer_type_grouped)[T.Other]               -0.1027      0.630     -0.163      0.871      -1.338       1.132
C(answer_type_grouped)[T.Person]               0.5674      0.640      0.887      0.375      -0.686       1.821
q_length                                       0.3790      0.697      0.544      0.586      -0.987       1.745
capabilities_entropy                           1.1424      0.607      1.883      0.060      -0.047       2.332
game_entropy                                   1.0795      0.571      1.892      0.059      -0.039       2.198
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing gpt-4o-mini (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_neutral/gpt-4o-mini_SimpleMC_neut_redacted_temp1.0_1757985828_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    240
1     88
Name: count, dtype: int64

Answer change%: 0.2683 [0.220343160898414, 0.3162422049552446] (n=328)
P-value vs 25%: 0.4546; P-value vs 0%: 5.53e-28
Phase 2 self-accuracy: 0.4773 [0.37291427155746926, 0.5816311829879853] (n=88)
P-value vs 25%: 1.969e-05; P-value vs 33%: 0.006737

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  328
Model:                          Logit   Df Residuals:                      326
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1749
Time:                        09:26:55   Log-Likelihood:                -157.40
converged:                       True   LL-Null:                       -190.75
Covariance Type:            nonrobust   LLR p-value:                 3.150e-16
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          3.2839      0.568      5.781      0.000       2.170       4.397
p_i_capability    -5.6292      0.756     -7.442      0.000      -7.112      -4.147
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  328
Model:                          Logit   Df Residuals:                      326
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1674
Time:                        09:26:55   Log-Likelihood:                -158.82
converged:                       True   LL-Null:                       -190.75
Covariance Type:            nonrobust   LLR p-value:                 1.342e-15
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.6521      0.299     -8.881      0.000      -3.237      -2.067
capabilities_entropy     2.0314      0.287      7.075      0.000       1.469       2.594
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.7955 [0.7112, 0.8797] (n=88)
                  P-value vs 33.3%: 6.11e-27

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=-2.85, p=0.00473
Wilcoxon delta_p: statistic=8342.00, p=0.000346
Mean Δp = -0.0309  [-0.0521, -0.0097]
Idea 1 N = 216; 

  Idea 1.5: Calibration Metrics
  NLL: 4.7590, Signed ECE (overconf pos under neg): 0.0880, ECE: 0.0880 (n=303)
  Brier: 0.0234, Reliability (absolute calibration error; lower better): 0.0227, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=303)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.768
Model:                            OLS   Adj. R-squared:                  0.766
Method:                 Least Squares   F-statistic:                     330.3
Date:                Sat, 20 Sep 2025   Prob (F-statistic):           1.46e-94
Time:                        09:26:55   Log-Likelihood:                 168.18
No. Observations:                 303   AIC:                            -328.4
Df Residuals:                     299   BIC:                            -313.5
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.4374      0.048     -9.071      0.000      -0.532      -0.343
p1                    0.4850      0.056      8.599      0.000       0.374       0.596
answer_changed        0.3249      0.076      4.299      0.000       0.176       0.474
p1:answer_changed     0.4056      0.102      3.963      0.000       0.204       0.607
==============================================================================
Omnibus:                       18.963   Durbin-Watson:                   1.898
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               20.978
Skew:                           0.581   Prob(JB):                     2.78e-05
Kurtosis:                       3.559   Cond. No.                         22.3
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=3.21, p=0.00156
Wilcoxon delta_H: statistic=8986.00, p=0.00297
Mean ΔH = 0.0846  [0.0328, 0.1363]
Paired t-test delta_H Changed: statistic=7.24, p=1.81e-10
Wilcoxon delta_H Changed: statistic=457.00, p=6.98e-10
Mean ΔH Changed = 0.3240  [0.2362, 0.4117]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=3.97, p=8.9e-05
Wilcoxon (p_top2_game vs p_top2_base): statistic=15052.00, p=2.58e-07
Mean Δp_top2 = 0.0141  [0.0071, 0.0211] (n=303)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=6.50, p=3.29e-10
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=13987.00, p=3.15e-09
Mean ΔH_unchosen_baseline_set = 0.1533  [0.1071, 0.1995] (n=303)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  303
Model:                          Logit   Df Residuals:                      300
Method:                           MLE   Df Model:                            2
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1592
Time:                        09:26:55   Log-Likelihood:                -152.75
converged:                       True   LL-Null:                       -181.67
Covariance Type:            nonrobust   LLR p-value:                 2.770e-13
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.9634      0.201     -4.800      0.000      -1.357      -0.570
p1_z            -1.1264      0.191     -5.912      0.000      -1.500      -0.753
I(p1_z ** 2)    -0.1693      0.168     -1.007      0.314      -0.499       0.160
================================================================================
AUC = 0.769

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  328
Model:                          Logit   Df Residuals:                      326
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1300
Time:                        09:26:55   Log-Likelihood:                -165.96
converged:                       True   LL-Null:                       -190.75
Covariance Type:            nonrobust   LLR p-value:                 1.903e-12
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -2.1920      0.244     -8.966      0.000      -2.671      -1.713
game_entropy     1.7988      0.274      6.560      0.000       1.261       2.336
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=17167.00, p=1.26e-07
Paired t-test (game_entropy vs capabilities_entropy): statistic=-4.87, p=1.73e-06
Mean capabilities_entropy-game_entropy = 0.1192  [0.0713, 0.1672] (n=328)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  328
Model:                          Logit   Df Residuals:                      325
Method:                           MLE   Df Model:                            2
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1878
Time:                        09:26:55   Log-Likelihood:                -154.92
converged:                       True   LL-Null:                       -190.75
Covariance Type:            nonrobust   LLR p-value:                 2.759e-16
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.8643      0.318     -8.993      0.000      -3.489      -2.240
capabilities_entropy     1.5267      0.337      4.524      0.000       0.865       2.188
game_entropy             0.9295      0.334      2.782      0.005       0.275       1.584
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': None
topic_grouped           answer_changed
Art                     0                 0.804878
                        1                 0.195122
Geography               0                 0.645161
                        1                 0.354839
Misc                    0                 0.784314
                        1                 0.215686
Music                   0                 0.821429
                        1                 0.178571
Other                   0                 0.685714
                        1                 0.314286
Politics                0                 0.580000
                        1                 0.420000
Science and technology  0                 0.784615
                        1                 0.215385
Sports                  0                 0.740741
                        1                 0.259259
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.664062
                     1                 0.335938
Number               0                 0.708333
                     1                 0.291667
Other                0                 0.781818
                     1                 0.218182
Person               0                 0.794521
                     1                 0.205479
Place                0                 0.833333
                     1                 0.166667
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.733333  0.266667           15
                       Number               1.000000  0.000000            3
                       Other                0.714286  0.285714            7
                       Person               0.833333  0.166667           12
                       Place                1.000000  0.000000            4
Geography              Date                 0.500000  0.500000           14
                       Number               0.700000  0.300000           10
                       Place                0.857143  0.142857            7
Misc                   Date                 0.647059  0.352941           17
                       Number               0.833333  0.166667            6
                       Other                0.882353  0.117647           17
                       Person               0.800000  0.200000           10
                       Place                1.000000  0.000000            1
Music                  Date                 0.777778  0.222222            9
                       Number               1.000000  0.000000            3
                       Other                0.666667  0.333333            6
                       Person               0.875000  0.125000            8
                       Place                1.000000  0.000000            2
Other                  Date                 0.642857  0.357143           14
                       Number               0.600000  0.400000            5
                       Other                0.833333  0.166667            6
                       Person               0.857143  0.142857            7
                       Place                0.333333  0.666667            3
Politics               Date                 0.571429  0.428571           28
                       Number               0.400000  0.600000            5
                       Other                0.750000  0.250000            4
                       Person               0.500000  0.500000           10
                       Place                1.000000  0.000000            3
Science and technology Date                 0.826087  0.173913           23
                       Number               0.750000  0.250000            8
                       Other                0.625000  0.375000            8
                       Person               0.826087  0.173913           23
                       Place                0.666667  0.333333            3
Sports                 Date                 0.625000  0.375000            8
                       Number               0.625000  0.375000            8
                       Other                0.857143  0.142857            7
                       Person               1.000000  0.000000            3
                       Place                1.000000  0.000000            1

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  328
Model:                          Logit   Df Residuals:                      315
Method:                           MLE   Df Model:                           12
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.04985
Time:                        09:26:55   Log-Likelihood:                -181.24
converged:                       True   LL-Null:                       -190.75
Covariance Type:            nonrobust   LLR p-value:                   0.08808
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -3.8985      1.599     -2.439      0.015      -7.032      -0.765
C(topic_grouped)[T.Geography]                  0.8653      0.574      1.507      0.132      -0.260       1.991
C(topic_grouped)[T.Misc]                       0.0558      0.530      0.105      0.916      -0.984       1.095
C(topic_grouped)[T.Music]                     -0.0852      0.638     -0.134      0.894      -1.335       1.165
C(topic_grouped)[T.Other]                      0.6580      0.544      1.210      0.226      -0.408       1.724
C(topic_grouped)[T.Politics]                   0.8199      0.506      1.622      0.105      -0.171       1.811
C(topic_grouped)[T.Science and technology]     0.0420      0.504      0.083      0.934      -0.946       1.030
C(topic_grouped)[T.Sports]                     0.2454      0.605      0.405      0.685      -0.941       1.432
C(answer_type_grouped)[T.Number]              -0.1913      0.386     -0.496      0.620      -0.947       0.564
C(answer_type_grouped)[T.Other]               -0.3301      0.397     -0.832      0.406      -1.108       0.448
C(answer_type_grouped)[T.Person]              -0.4200      0.361     -1.163      0.245      -1.128       0.288
C(answer_type_grouped)[T.Place]               -1.0259      0.602     -1.705      0.088      -2.205       0.153
q_length                                       0.6134      0.339      1.807      0.071      -0.052       1.279
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.6848
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  328
Model:                          Logit   Df Residuals:                      314
Method:                           MLE   Df Model:                           13
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.2065
Time:                        09:26:55   Log-Likelihood:                -151.36
converged:                       True   LL-Null:                       -190.75
Covariance Type:            nonrobust   LLR p-value:                 1.875e-11
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -5.1403      1.796     -2.862      0.004      -8.660      -1.620
C(topic_grouped)[T.Geography]                  0.9797      0.654      1.498      0.134      -0.302       2.261
C(topic_grouped)[T.Misc]                      -0.1055      0.590     -0.179      0.858      -1.263       1.052
C(topic_grouped)[T.Music]                     -0.4338      0.721     -0.602      0.547      -1.846       0.979
C(topic_grouped)[T.Other]                      0.4635      0.611      0.759      0.448      -0.734       1.661
C(topic_grouped)[T.Politics]                   0.8119      0.567      1.433      0.152      -0.299       1.922
C(topic_grouped)[T.Science and technology]     0.0037      0.561      0.007      0.995      -1.096       1.103
C(topic_grouped)[T.Sports]                     0.1066      0.672      0.159      0.874      -1.210       1.423
C(answer_type_grouped)[T.Number]              -0.2861      0.429     -0.667      0.505      -1.127       0.554
C(answer_type_grouped)[T.Other]                0.4054      0.454      0.893      0.372      -0.484       1.295
C(answer_type_grouped)[T.Person]              -0.3694      0.403     -0.917      0.359      -1.159       0.420
C(answer_type_grouped)[T.Place]               -0.8696      0.671     -1.297      0.195      -2.184       0.445
q_length                                       0.5013      0.373      1.342      0.179      -0.231       1.233
capabilities_entropy                           2.0985      0.307      6.841      0.000       1.497       2.700
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  328
Model:                          Logit   Df Residuals:                      314
Method:                           MLE   Df Model:                           13
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1635
Time:                        09:26:55   Log-Likelihood:                -159.56
converged:                       True   LL-Null:                       -190.75
Covariance Type:            nonrobust   LLR p-value:                 1.961e-08
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -4.4292      1.718     -2.579      0.010      -7.796      -1.063
C(topic_grouped)[T.Geography]                  0.6851      0.626      1.095      0.274      -0.541       1.912
C(topic_grouped)[T.Misc]                       0.1066      0.575      0.185      0.853      -1.020       1.233
C(topic_grouped)[T.Music]                     -0.2096      0.701     -0.299      0.765      -1.584       1.165
C(topic_grouped)[T.Other]                      0.5414      0.595      0.909      0.363      -0.626       1.708
C(topic_grouped)[T.Politics]                   0.9270      0.547      1.694      0.090      -0.145       1.999
C(topic_grouped)[T.Science and technology]     0.0849      0.547      0.155      0.877      -0.987       1.157
C(topic_grouped)[T.Sports]                     0.3967      0.656      0.604      0.546      -0.890       1.683
C(answer_type_grouped)[T.Number]              -0.0487      0.415     -0.117      0.907      -0.862       0.764
C(answer_type_grouped)[T.Other]                0.0133      0.434      0.031      0.976      -0.836       0.863
C(answer_type_grouped)[T.Person]              -0.3028      0.392     -0.773      0.439      -1.070       0.465
C(answer_type_grouped)[T.Place]               -0.8338      0.655     -1.273      0.203      -2.117       0.450
q_length                                       0.4415      0.359      1.228      0.219      -0.263       1.146
game_entropy                                   1.7784      0.289      6.161      0.000       1.213       2.344
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  328
Model:                          Logit   Df Residuals:                      313
Method:                           MLE   Df Model:                           14
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.2237
Time:                        09:26:55   Log-Likelihood:                -148.09
converged:                       True   LL-Null:                       -190.75
Covariance Type:            nonrobust   LLR p-value:                 2.874e-12
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -5.1918      1.811     -2.867      0.004      -8.741      -1.643
C(topic_grouped)[T.Geography]                  0.9068      0.660      1.375      0.169      -0.386       2.199
C(topic_grouped)[T.Misc]                      -0.0008      0.599     -0.001      0.999      -1.176       1.174
C(topic_grouped)[T.Music]                     -0.4333      0.739     -0.587      0.557      -1.881       1.014
C(topic_grouped)[T.Other]                      0.4470      0.624      0.716      0.474      -0.777       1.671
C(topic_grouped)[T.Politics]                   0.8946      0.573      1.562      0.118      -0.228       2.018
C(topic_grouped)[T.Science and technology]     0.0324      0.573      0.057      0.955      -1.090       1.155
C(topic_grouped)[T.Sports]                     0.2428      0.683      0.356      0.722      -1.096       1.581
C(answer_type_grouped)[T.Number]              -0.1740      0.433     -0.402      0.688      -1.023       0.675
C(answer_type_grouped)[T.Other]                0.4008      0.463      0.867      0.386      -0.506       1.307
C(answer_type_grouped)[T.Person]              -0.3261      0.410     -0.796      0.426      -1.129       0.477
C(answer_type_grouped)[T.Place]               -0.8468      0.682     -1.241      0.215      -2.184       0.490
q_length                                       0.4484      0.375      1.197      0.231      -0.286       1.183
capabilities_entropy                           1.6255      0.355      4.574      0.000       0.929       2.322
game_entropy                                   0.8899      0.350      2.546      0.011       0.205       1.575
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing grok-3-latest (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_neutral/grok-3-latest_SimpleMC_redacted_cor_temp0.0_1751833664_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    273
1     22
Name: count, dtype: int64

Answer change%: 0.0746 [0.0445979208232761, 0.10455462154960526] (n=295)
P-value vs 25%: 1.886e-30; P-value vs 0%: 1.084e-06
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=22)
P-value vs 25%: 0; P-value vs 33%: 0

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  295
Model:                          Logit   Df Residuals:                      293
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1764
Time:                        09:26:55   Log-Likelihood:                -64.459
converged:                       True   LL-Null:                       -78.269
Covariance Type:            nonrobust   LLR p-value:                 1.477e-07
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          1.8206      0.864      2.107      0.035       0.127       3.514
p_i_capability    -5.1578      1.055     -4.887      0.000      -7.226      -3.089
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  295
Model:                          Logit   Df Residuals:                      293
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.2925
Time:                        09:26:55   Log-Likelihood:                -55.373
converged:                       True   LL-Null:                       -78.269
Covariance Type:            nonrobust   LLR p-value:                 1.316e-11
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -4.2083      0.481     -8.741      0.000      -5.152      -3.265
capabilities_entropy     3.0784      0.516      5.967      0.000       2.067       4.090
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.7727 [0.5976, 0.9478] (n=22)
                  P-value vs 33.3%: 8.748e-07

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=-3.73, p=0.000238
Wilcoxon delta_p: statistic=8330.00, p=8.68e-15
Mean Δp = -0.0269  [-0.0411, -0.0128]
Idea 1 N = 270; 

  Idea 1.5: Calibration Metrics
  NLL: 0.0975, Signed ECE (overconf pos under neg): -0.0791, ECE: 0.0791 (n=292)
  Brier: 0.0258, Reliability (absolute calibration error; lower better): 0.0253, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=292)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.728
Model:                            OLS   Adj. R-squared:                  0.725
Method:                 Least Squares   F-statistic:                     257.1
Date:                Sat, 20 Sep 2025   Prob (F-statistic):           4.09e-81
Time:                        09:26:55   Log-Likelihood:                 263.78
No. Observations:                 292   AIC:                            -519.6
Df Residuals:                     288   BIC:                            -504.9
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.6191      0.048    -12.804      0.000      -0.714      -0.524
p1                    0.6298      0.051     12.343      0.000       0.529       0.730
answer_changed        0.5114      0.101      5.075      0.000       0.313       0.710
p1:answer_changed     0.2540      0.136      1.871      0.062      -0.013       0.521
==============================================================================
Omnibus:                      224.285   Durbin-Watson:                   2.136
Prob(Omnibus):                  0.000   Jarque-Bera (JB):             3673.185
Skew:                           2.990   Prob(JB):                         0.00
Kurtosis:                      19.314   Cond. No.                         40.3
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-4.95, p=1.34e-06
Wilcoxon delta_H: statistic=11940.00, p=7.56e-07
Mean ΔH = -0.1541  [-0.2151, -0.0930]
Paired t-test delta_H Changed: statistic=1.73, p=0.0982
Wilcoxon delta_H Changed: statistic=66.00, p=0.0501
Mean ΔH Changed = 0.1439  [-0.0191, 0.3068]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=2.48, p=0.0139
Wilcoxon (p_top2_game vs p_top2_base): statistic=13669.00, p=9e-08
Mean Δp_top2 = 0.0056  [0.0012, 0.0100] (n=292)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=-4.42, p=1.42e-05
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=15080.00, p=1.25e-05
Mean ΔH_unchosen_baseline_set = -0.1316  [-0.1901, -0.0732] (n=292)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  292
Model:                          Logit   Df Residuals:                      289
Method:                           MLE   Df Model:                            2
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.3240
Time:                        09:26:55   Log-Likelihood:                -52.749
converged:                       True   LL-Null:                       -78.035
Covariance Type:            nonrobust   LLR p-value:                 1.043e-11
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -3.1711      0.390     -8.121      0.000      -3.936      -2.406
p1_z            -2.1644      0.517     -4.184      0.000      -3.178      -1.151
I(p1_z ** 2)    -0.3933      0.178     -2.207      0.027      -0.743      -0.044
================================================================================
AUC = 0.894

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  295
Model:                          Logit   Df Residuals:                      293
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.3648
Time:                        09:26:55   Log-Likelihood:                -49.717
converged:                       True   LL-Null:                       -78.269
Covariance Type:            nonrobust   LLR p-value:                 4.132e-14
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -4.0833      0.453     -9.012      0.000      -4.971      -3.195
game_entropy     3.8981      0.596      6.537      0.000       2.729       5.067
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=10022.00, p=8.11e-16
Paired t-test (game_entropy vs capabilities_entropy): statistic=-5.82, p=1.52e-08
Mean capabilities_entropy-game_entropy = 0.1126  [0.0747, 0.1505] (n=295)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  295
Model:                          Logit   Df Residuals:                      292
Method:                           MLE   Df Model:                            2
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.4230
Time:                        09:26:55   Log-Likelihood:                -45.164
converged:                       True   LL-Null:                       -78.269
Covariance Type:            nonrobust   LLR p-value:                 4.193e-15
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -4.7877      0.600     -7.983      0.000      -5.963      -3.612
capabilities_entropy     1.9571      0.650      3.009      0.003       0.682       3.232
game_entropy             2.8182      0.674      4.184      0.000       1.498       4.138
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['Other', 'Sports', 'Music', 'Geography', 'History', 'TV shows', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.937500
                        1                 0.062500
Misc                    0                 0.913907
                        1                 0.086093
Politics                0                 0.937500
                        1                 0.062500
Science and technology  0                 0.937500
                        1                 0.062500
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.950495
                     1                 0.049505
Number               0                 0.925000
                     1                 0.075000
Other                0                 0.912088
                     1                 0.087912
Person               0                 0.904762
                     1                 0.095238
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.857143  0.142857           14
                       Number               1.000000  0.000000            5
                       Other                0.923077  0.076923           13
                       Person               1.000000  0.000000           16
Misc                   Date                 0.956522  0.043478           46
                       Number               0.923077  0.076923           26
                       Other                0.882353  0.117647           51
                       Person               0.892857  0.107143           28
Politics               Date                 1.000000  0.000000           20
                       Number               1.000000  0.000000            4
                       Other                0.923077  0.076923           13
                       Person               0.818182  0.181818           11
Science and technology Date                 0.952381  0.047619           21
                       Number               0.800000  0.200000            5
                       Other                1.000000  0.000000           14
                       Person               0.875000  0.125000            8

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  295
Model:                          Logit   Df Residuals:                      287
Method:                           MLE   Df Model:                            7
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.01405
Time:                        09:26:55   Log-Likelihood:                -77.169
converged:                       True   LL-Null:                       -78.269
Covariance Type:            nonrobust   LLR p-value:                    0.9479
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -2.6888      2.939     -0.915      0.360      -8.449       3.071
C(topic_grouped)[T.Misc]                       0.3934      0.671      0.586      0.558      -0.922       1.709
C(topic_grouped)[T.Politics]                   0.1018      0.859      0.119      0.906      -1.581       1.785
C(topic_grouped)[T.Science and technology]     0.1197      0.856      0.140      0.889      -1.557       1.797
C(answer_type_grouped)[T.Number]               0.3940      0.763      0.516      0.606      -1.102       1.890
C(answer_type_grouped)[T.Other]                0.5834      0.592      0.985      0.325      -0.578       1.744
C(answer_type_grouped)[T.Person]               0.7227      0.634      1.141      0.254      -0.519       1.965
q_length                                      -0.1121      0.647     -0.173      0.862      -1.380       1.155
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.2838
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  295
Model:                          Logit   Df Residuals:                      286
Method:                           MLE   Df Model:                            8
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.2985
Time:                        09:26:55   Log-Likelihood:                -54.906
converged:                       True   LL-Null:                       -78.269
Covariance Type:            nonrobust   LLR p-value:                 1.729e-07
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -5.1940      3.321     -1.564      0.118     -11.703       1.315
C(topic_grouped)[T.Misc]                      -0.3911      0.794     -0.493      0.622      -1.947       1.165
C(topic_grouped)[T.Politics]                  -0.0023      0.958     -0.002      0.998      -1.880       1.875
C(topic_grouped)[T.Science and technology]    -0.4103      0.949     -0.432      0.665      -2.270       1.450
C(answer_type_grouped)[T.Number]               0.0429      0.873      0.049      0.961      -1.668       1.754
C(answer_type_grouped)[T.Other]                0.2684      0.692      0.388      0.698      -1.088       1.625
C(answer_type_grouped)[T.Person]               0.3487      0.724      0.482      0.630      -1.071       1.768
q_length                                       0.2332      0.732      0.319      0.750      -1.201       1.667
capabilities_entropy                           3.1409      0.537      5.853      0.000       2.089       4.193
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  295
Model:                          Logit   Df Residuals:                      286
Method:                           MLE   Df Model:                            8
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.3726
Time:                        09:26:55   Log-Likelihood:                -49.108
converged:                       True   LL-Null:                       -78.269
Covariance Type:            nonrobust   LLR p-value:                 9.935e-10
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -5.7575      3.622     -1.590      0.112     -12.857       1.342
C(topic_grouped)[T.Misc]                      -0.0967      0.854     -0.113      0.910      -1.771       1.578
C(topic_grouped)[T.Politics]                   0.0870      1.047      0.083      0.934      -1.966       2.140
C(topic_grouped)[T.Science and technology]    -0.1426      1.029     -0.139      0.890      -2.159       1.874
C(answer_type_grouped)[T.Number]               0.6384      0.962      0.664      0.507      -1.247       2.524
C(answer_type_grouped)[T.Other]                0.6475      0.734      0.882      0.378      -0.792       2.087
C(answer_type_grouped)[T.Person]               0.5620      0.776      0.724      0.469      -0.959       2.083
q_length                                       0.2812      0.788      0.357      0.721      -1.263       1.825
game_entropy                                   3.9503      0.616      6.409      0.000       2.742       5.158
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  295
Model:                          Logit   Df Residuals:                      285
Method:                           MLE   Df Model:                            9
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.4273
Time:                        09:26:55   Log-Likelihood:                -44.823
converged:                       True   LL-Null:                       -78.269
Covariance Type:            nonrobust   LLR p-value:                 6.175e-11
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -6.5009      3.707     -1.754      0.079     -13.766       0.764
C(topic_grouped)[T.Misc]                      -0.2329      0.936     -0.249      0.803      -2.067       1.601
C(topic_grouped)[T.Politics]                   0.1504      1.097      0.137      0.891      -2.000       2.301
C(topic_grouped)[T.Science and technology]    -0.0421      1.091     -0.039      0.969      -2.179       2.095
C(answer_type_grouped)[T.Number]               0.2799      0.963      0.291      0.771      -1.607       2.167
C(answer_type_grouped)[T.Other]                0.2222      0.797      0.279      0.781      -1.341       1.785
C(answer_type_grouped)[T.Person]               0.3081      0.799      0.386      0.700      -1.257       1.873
q_length                                       0.3583      0.801      0.447      0.655      -1.212       1.928
capabilities_entropy                           1.9711      0.669      2.946      0.003       0.660       3.283
game_entropy                                   2.8508      0.687      4.153      0.000       1.505       4.196
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing grok-3-latest (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_neutral/grok-3-latest_SimpleMC_redacted_temp0.0_1751826103_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    138
1     67
Name: count, dtype: int64

Answer change%: 0.3268 [0.26262051404567455, 0.39103802253969133] (n=205)
P-value vs 25%: 0.01902; P-value vs 0%: 1.933e-23
Phase 2 self-accuracy: 0.5672 [0.4485253957797495, 0.6858029624292057] (n=67)
P-value vs 25%: 1.608e-07; P-value vs 33%: 0.0001095

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  205
Model:                          Logit   Df Residuals:                      203
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1948
Time:                        09:26:55   Log-Likelihood:                -104.31
converged:                       True   LL-Null:                       -129.54
Covariance Type:            nonrobust   LLR p-value:                 1.212e-12
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          4.6087      0.851      5.416      0.000       2.941       6.277
p_i_capability    -6.6450      1.054     -6.303      0.000      -8.711      -4.579
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  205
Model:                          Logit   Df Residuals:                      203
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1697
Time:                        09:26:55   Log-Likelihood:                -107.56
converged:                       True   LL-Null:                       -129.54
Covariance Type:            nonrobust   LLR p-value:                 3.352e-11
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.3172      0.339     -6.845      0.000      -2.981      -1.654
capabilities_entropy     2.3142      0.392      5.904      0.000       1.546       3.082
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.6866 [0.5755, 0.7976] (n=67)
                  P-value vs 33.3%: 4.581e-10

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=-1.90, p=0.0598
Wilcoxon delta_p: statistic=3451.00, p=0.00427
Mean Δp = -0.0232  [-0.0472, 0.0008]
Idea 1 N = 138; 

  Idea 1.5: Calibration Metrics
  NLL: 5.1560, Signed ECE (overconf pos under neg): 0.0779, ECE: 0.0779 (n=205)
  Brier: 0.0196, Reliability (absolute calibration error; lower better): 0.0189, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=205)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.830
Model:                            OLS   Adj. R-squared:                  0.827
Method:                 Least Squares   F-statistic:                     326.1
Date:                Sat, 20 Sep 2025   Prob (F-statistic):           6.21e-77
Time:                        09:26:55   Log-Likelihood:                 114.36
No. Observations:                 205   AIC:                            -220.7
Df Residuals:                     201   BIC:                            -207.4
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.5431      0.077     -7.052      0.000      -0.695      -0.391
p1                    0.5884      0.086      6.832      0.000       0.419       0.758
answer_changed        0.2554      0.106      2.418      0.017       0.047       0.464
p1:answer_changed     0.6181      0.132      4.685      0.000       0.358       0.878
==============================================================================
Omnibus:                       38.316   Durbin-Watson:                   2.228
Prob(Omnibus):                  0.000   Jarque-Bera (JB):              159.898
Skew:                          -0.623   Prob(JB):                     1.90e-35
Kurtosis:                       7.143   Cond. No.                         26.5
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=0.68, p=0.496
Wilcoxon delta_H: statistic=4401.00, p=0.402
Mean ΔH = 0.0295  [-0.0552, 0.1142]
Paired t-test delta_H Changed: statistic=4.45, p=3.41e-05
Wilcoxon delta_H Changed: statistic=450.00, p=1.68e-05
Mean ΔH Changed = 0.2467  [0.1380, 0.3553]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=4.23, p=3.53e-05
Wilcoxon (p_top2_game vs p_top2_base): statistic=5799.00, p=2.2e-08
Mean Δp_top2 = 0.0165  [0.0088, 0.0241] (n=205)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=2.88, p=0.00447
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=7928.00, p=0.00199
Mean ΔH_unchosen_baseline_set = 0.1005  [0.0320, 0.1689] (n=205)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  205
Model:                          Logit   Df Residuals:                      202
Method:                           MLE   Df Model:                            2
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.2020
Time:                        09:26:55   Log-Likelihood:                -103.37
converged:                       True   LL-Null:                       -129.54
Covariance Type:            nonrobust   LLR p-value:                 4.303e-12
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.6750      0.225     -3.005      0.003      -1.115      -0.235
p1_z            -1.3695      0.252     -5.430      0.000      -1.864      -0.875
I(p1_z ** 2)    -0.2584      0.185     -1.393      0.164      -0.622       0.105
================================================================================
AUC = 0.807

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  205
Model:                          Logit   Df Residuals:                      203
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.07394
Time:                        09:26:55   Log-Likelihood:                -119.96
converged:                       True   LL-Null:                       -129.54
Covariance Type:            nonrobust   LLR p-value:                 1.205e-05
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.4666      0.244     -6.003      0.000      -1.945      -0.988
game_entropy     1.5334      0.363      4.228      0.000       0.823       2.244
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=6148.00, p=2.16e-07
Paired t-test (game_entropy vs capabilities_entropy): statistic=-5.30, p=2.96e-07
Mean capabilities_entropy-game_entropy = 0.1686  [0.1063, 0.2310] (n=205)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  205
Model:                          Logit   Df Residuals:                      202
Method:                           MLE   Df Model:                            2
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1784
Time:                        09:26:55   Log-Likelihood:                -106.43
converged:                       True   LL-Null:                       -129.54
Covariance Type:            nonrobust   LLR p-value:                 9.190e-11
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.4502      0.356     -6.888      0.000      -3.147      -1.753
capabilities_entropy     2.0590      0.424      4.852      0.000       1.227       2.891
game_entropy             0.6338      0.421      1.504      0.133      -0.192       1.460
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['Politics', 'Art', 'Geography', 'Other', 'Music', 'Sports', 'TV shows', 'Video games', 'History']
                  Grouped rare answer_type into 'Misc'/'Other': ['Number', 'Other', 'Place']
topic_grouped           answer_changed
Misc                    0                 0.703226
                        1                 0.296774
Science and technology  0                 0.580000
                        1                 0.420000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.691176
                     1                 0.308824
Misc                 0                 0.662500
                     1                 0.337500
Person               0                 0.666667
                     1                 0.333333
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Misc                   Date                 0.759259  0.240741           54
                       Misc                 0.696970  0.303030           66
                       Person               0.628571  0.371429           35
Science and technology Date                 0.428571  0.571429           14
                       Misc                 0.500000  0.500000           14
                       Person               0.727273  0.272727           22

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  205
Model:                          Logit   Df Residuals:                      200
Method:                           MLE   Df Model:                            4
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.01194
Time:                        09:26:55   Log-Likelihood:                -128.00
converged:                       True   LL-Null:                       -129.54
Covariance Type:            nonrobust   LLR p-value:                    0.5425
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.9267      1.774     -1.086      0.277      -5.403       1.549
C(topic_grouped)[T.Science and technology]     0.5487      0.346      1.588      0.112      -0.129       1.226
C(answer_type_grouped)[T.Misc]                 0.1746      0.358      0.487      0.626      -0.528       0.877
C(answer_type_grouped)[T.Person]               0.0682      0.407      0.168      0.867      -0.729       0.866
q_length                                       0.2136      0.375      0.570      0.569      -0.521       0.948
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.6132
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  205
Model:                          Logit   Df Residuals:                      199
Method:                           MLE   Df Model:                            5
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1803
Time:                        09:26:55   Log-Likelihood:                -106.18
converged:                       True   LL-Null:                       -129.54
Covariance Type:            nonrobust   LLR p-value:                 6.469e-09
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -3.3068      1.988     -1.663      0.096      -7.204       0.590
C(topic_grouped)[T.Science and technology]     0.4437      0.393      1.129      0.259      -0.327       1.214
C(answer_type_grouped)[T.Misc]                 0.4086      0.403      1.015      0.310      -0.380       1.198
C(answer_type_grouped)[T.Person]               0.3859      0.458      0.842      0.400      -0.512       1.284
q_length                                       0.1331      0.416      0.320      0.749      -0.682       0.948
capabilities_entropy                           2.3276      0.395      5.896      0.000       1.554       3.101
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  205
Model:                          Logit   Df Residuals:                      199
Method:                           MLE   Df Model:                            5
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.08468
Time:                        09:26:55   Log-Likelihood:                -118.57
converged:                       True   LL-Null:                       -129.54
Covariance Type:            nonrobust   LLR p-value:                 0.0005376
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -2.0007      1.825     -1.096      0.273      -5.578       1.577
C(topic_grouped)[T.Science and technology]     0.4248      0.366      1.161      0.246      -0.293       1.142
C(answer_type_grouped)[T.Misc]                 0.3612      0.380      0.951      0.341      -0.383       1.105
C(answer_type_grouped)[T.Person]               0.3767      0.437      0.863      0.388      -0.479       1.232
q_length                                       0.0341      0.388      0.088      0.930      -0.726       0.795
game_entropy                                   1.5786      0.378      4.179      0.000       0.838       2.319
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  205
Model:                          Logit   Df Residuals:                      198
Method:                           MLE   Df Model:                            6
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1899
Time:                        09:26:55   Log-Likelihood:                -104.94
converged:                       True   LL-Null:                       -129.54
Covariance Type:            nonrobust   LLR p-value:                 6.798e-09
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -3.2025      2.003     -1.599      0.110      -7.128       0.723
C(topic_grouped)[T.Science and technology]     0.3840      0.399      0.963      0.335      -0.397       1.165
C(answer_type_grouped)[T.Misc]                 0.4801      0.410      1.172      0.241      -0.323       1.283
C(answer_type_grouped)[T.Person]               0.4898      0.469      1.044      0.297      -0.430       1.410
q_length                                       0.0666      0.421      0.158      0.874      -0.759       0.892
capabilities_entropy                           2.0671      0.425      4.868      0.000       1.235       2.899
game_entropy                                   0.6832      0.435      1.572      0.116      -0.169       1.535
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing qwen3-235b-a22b-2507 (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_neutral/qwen3-235b-a22b-2507_SimpleMC_neut_redacted_cor_temp0.0_1756222018_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    253
1     54
Name: count, dtype: int64

Answer change%: 0.1759 [0.13330674336364284, 0.21848478758098255] (n=307)
P-value vs 25%: 0.0006489; P-value vs 0%: 5.736e-16
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=54)
P-value vs 25%: 0; P-value vs 33%: 0

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  307
Model:                          Logit   Df Residuals:                      305
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1127
Time:                        09:26:55   Log-Likelihood:                -126.70
converged:                       True   LL-Null:                       -142.79
Covariance Type:            nonrobust   LLR p-value:                 1.400e-08
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          2.4004      0.692      3.470      0.001       1.044       3.756
p_i_capability    -4.5757      0.811     -5.640      0.000      -6.166      -2.985
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  307
Model:                          Logit   Df Residuals:                      305
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.09355
Time:                        09:26:55   Log-Likelihood:                -129.43
converged:                       True   LL-Null:                       -142.79
Covariance Type:            nonrobust   LLR p-value:                 2.356e-07
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.1956      0.221     -9.918      0.000      -2.630      -1.762
capabilities_entropy     1.3640      0.265      5.153      0.000       0.845       1.883
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.7593 [0.6452, 0.8733] (n=54)
                  P-value vs 33.3%: 2.464e-13

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=3.70, p=0.000277
Wilcoxon delta_p: statistic=7025.00, p=2.2e-05
Mean Δp = 0.0556  [0.0261, 0.0850]
Idea 1 N = 207; 

  Idea 1.5: Calibration Metrics
  NLL: 0.1585, Signed ECE (overconf pos under neg): -0.1122, ECE: 0.1122 (n=259)
  Brier: 0.0453, Reliability (absolute calibration error; lower better): 0.0446, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=259)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.512
Model:                            OLS   Adj. R-squared:                  0.506
Method:                 Least Squares   F-statistic:                     88.89
Date:                Sat, 20 Sep 2025   Prob (F-statistic):           2.36e-39
Time:                        09:26:55   Log-Likelihood:                 33.958
No. Observations:                 258   AIC:                            -59.92
Df Residuals:                     254   BIC:                            -45.70
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.2879      0.095     -3.021      0.003      -0.476      -0.100
p1                    0.3723      0.102      3.649      0.000       0.171       0.573
answer_changed       -0.0284      0.149     -0.190      0.849      -0.322       0.265
p1:answer_changed     0.7129      0.176      4.056      0.000       0.367       1.059
==============================================================================
Omnibus:                       79.991   Durbin-Watson:                   1.994
Prob(Omnibus):                  0.000   Jarque-Bera (JB):              242.558
Skew:                           1.343   Prob(JB):                     2.13e-53
Kurtosis:                       6.918   Cond. No.                         25.5
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-6.03, p=7.42e-09
Wilcoxon delta_H: statistic=5923.00, p=2.02e-08
Mean ΔH = -0.2846  [-0.3771, -0.1921]
Paired t-test delta_H Changed: statistic=1.97, p=0.0547
Wilcoxon delta_H Changed: statistic=486.00, p=0.0645
Mean ΔH Changed = 0.1487  [0.0005, 0.2969]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=-1.37, p=0.172
Wilcoxon (p_top2_game vs p_top2_base): statistic=12742.00, p=0.000955
Mean Δp_top2 = -0.0058  [-0.0142, 0.0025] (n=259)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=-4.70, p=4.16e-06
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=11523.00, p=1.07e-05
Mean ΔH_unchosen_baseline_set = -0.1976  [-0.2799, -0.1153] (n=259)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  259
Model:                          Logit   Df Residuals:                      256
Method:                           MLE   Df Model:                            2
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1122
Time:                        09:26:55   Log-Likelihood:                -115.30
converged:                       True   LL-Null:                       -129.88
Covariance Type:            nonrobust   LLR p-value:                 4.671e-07
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.3518      0.235     -5.746      0.000      -1.813      -0.891
p1_z            -1.0702      0.322     -3.321      0.001      -1.702      -0.439
I(p1_z ** 2)    -0.2059      0.182     -1.132      0.258      -0.562       0.151
================================================================================
AUC = 0.734

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  307
Model:                          Logit   Df Residuals:                      305
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1489
Time:                        09:26:55   Log-Likelihood:                -121.53
converged:                       True   LL-Null:                       -142.79
Covariance Type:            nonrobust   LLR p-value:                 7.002e-11
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -2.5518      0.259     -9.867      0.000      -3.059      -2.045
game_entropy     1.8101      0.291      6.221      0.000       1.240       2.380
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=19065.00, p=0.155
Paired t-test (game_entropy vs capabilities_entropy): statistic=1.50, p=0.136
Mean capabilities_entropy-game_entropy = -0.0476  [-0.1101, 0.0148] (n=307)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  307
Model:                          Logit   Df Residuals:                      304
Method:                           MLE   Df Model:                            2
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1778
Time:                        09:26:55   Log-Likelihood:                -117.39
converged:                       True   LL-Null:                       -142.79
Covariance Type:            nonrobust   LLR p-value:                 9.356e-12
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.7944      0.285     -9.806      0.000      -3.353      -2.236
capabilities_entropy     0.8459      0.292      2.897      0.004       0.274       1.418
game_entropy             1.5122      0.311      4.859      0.000       0.902       2.122
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['Sports', 'TV shows', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': None
topic_grouped           answer_changed
Art                     0                 0.836364
                        1                 0.163636
Geography               0                 0.818182
                        1                 0.181818
History                 0                 0.636364
                        1                 0.363636
Misc                    0                 0.844444
                        1                 0.155556
Music                   0                 0.772727
                        1                 0.227273
Other                   0                 0.935484
                        1                 0.064516
Politics                0                 0.803922
                        1                 0.196078
Science and technology  0                 0.847458
                        1                 0.152542
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.737374
                     1                 0.262626
Number               0                 0.818182
                     1                 0.181818
Other                0                 0.892857
                     1                 0.107143
Person               0                 0.896552
                     1                 0.103448
Place                0                 0.761905
                     1                 0.238095
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.583333  0.416667           12
                       Number               0.833333  0.166667            6
                       Other                0.900000  0.100000           10
                       Person               0.956522  0.043478           23
                       Place                0.750000  0.250000            4
Geography              Date                 0.500000  0.500000            4
                       Number               0.818182  0.181818           11
                       Other                1.000000  0.000000            1
                       Place                1.000000  0.000000            6
History                Date                 0.538462  0.461538           13
                       Number               1.000000  0.000000            2
                       Other                0.500000  0.500000            2
                       Person               0.800000  0.200000            5
Misc                   Date                 0.909091  0.090909           11
                       Number               1.000000  0.000000            6
                       Other                0.916667  0.083333           12
                       Person               0.714286  0.285714           14
                       Place                0.500000  0.500000            2
Music                  Date                 0.625000  0.375000            8
                       Number               0.000000  1.000000            2
                       Other                1.000000  0.000000            3
                       Person               1.000000  0.000000            8
                       Place                1.000000  0.000000            1
Other                  Date                 0.888889  0.111111            9
                       Number               1.000000  0.000000            6
                       Other                0.800000  0.200000            5
                       Person               1.000000  0.000000           10
                       Place                1.000000  0.000000            1
Politics               Date                 0.782609  0.217391           23
                       Number               0.750000  0.250000            4
                       Other                0.900000  0.100000           10
                       Person               0.900000  0.100000           10
                       Place                0.500000  0.500000            4
Science and technology Date                 0.842105  0.157895           19
                       Number               0.714286  0.285714            7
                       Other                0.923077  0.076923           13
                       Person               0.882353  0.117647           17
                       Place                0.666667  0.333333            3

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  307
Model:                          Logit   Df Residuals:                      294
Method:                           MLE   Df Model:                           12
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.06321
Time:                        09:26:55   Log-Likelihood:                -133.76
converged:                       True   LL-Null:                       -142.79
Covariance Type:            nonrobust   LLR p-value:                    0.1142
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.8952      1.948     -0.973      0.331      -5.714       1.923
C(topic_grouped)[T.Geography]                 -0.2688      0.704     -0.382      0.703      -1.649       1.111
C(topic_grouped)[T.History]                    0.8155      0.596      1.368      0.171      -0.353       1.984
C(topic_grouped)[T.Misc]                      -0.0866      0.561     -0.154      0.877      -1.187       1.014
C(topic_grouped)[T.Music]                      0.3254      0.642      0.507      0.612      -0.933       1.584
C(topic_grouped)[T.Other]                     -1.1516      0.827     -1.393      0.164      -2.772       0.469
C(topic_grouped)[T.Politics]                  -0.0694      0.545     -0.127      0.899      -1.137       0.999
C(topic_grouped)[T.Science and technology]    -0.2031      0.527     -0.386      0.700      -1.235       0.829
C(answer_type_grouped)[T.Number]              -0.3133      0.484     -0.647      0.517      -1.262       0.635
C(answer_type_grouped)[T.Other]               -0.9645      0.503     -1.917      0.055      -1.951       0.022
C(answer_type_grouped)[T.Person]              -1.0588      0.434     -2.441      0.015      -1.909      -0.209
C(answer_type_grouped)[T.Place]                0.0232      0.589      0.039      0.969      -1.132       1.178
q_length                                       0.1878      0.424      0.443      0.658      -0.643       1.018
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.3605
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  307
Model:                          Logit   Df Residuals:                      293
Method:                           MLE   Df Model:                           13
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1615
Time:                        09:26:55   Log-Likelihood:                -119.73
converged:                       True   LL-Null:                       -142.79
Covariance Type:            nonrobust   LLR p-value:                 1.360e-05
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -4.7520      2.180     -2.179      0.029      -9.026      -0.478
C(topic_grouped)[T.Geography]                 -0.2052      0.757     -0.271      0.786      -1.688       1.278
C(topic_grouped)[T.History]                    0.9843      0.638      1.543      0.123      -0.266       2.234
C(topic_grouped)[T.Misc]                      -0.0958      0.599     -0.160      0.873      -1.269       1.077
C(topic_grouped)[T.Music]                      0.6034      0.691      0.873      0.383      -0.752       1.959
C(topic_grouped)[T.Other]                     -1.1502      0.864     -1.331      0.183      -2.844       0.543
C(topic_grouped)[T.Politics]                  -0.1118      0.574     -0.195      0.846      -1.236       1.012
C(topic_grouped)[T.Science and technology]    -0.3004      0.560     -0.537      0.591      -1.397       0.796
C(answer_type_grouped)[T.Number]              -0.5787      0.538     -1.076      0.282      -1.633       0.476
C(answer_type_grouped)[T.Other]               -0.7500      0.533     -1.406      0.160      -1.795       0.295
C(answer_type_grouped)[T.Person]              -0.9917      0.454     -2.183      0.029      -1.882      -0.101
C(answer_type_grouped)[T.Place]                0.1814      0.606      0.299      0.765      -1.007       1.370
q_length                                       0.6449      0.467      1.382      0.167      -0.269       1.559
capabilities_entropy                           1.5235      0.294      5.175      0.000       0.947       2.101
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  307
Model:                          Logit   Df Residuals:                      293
Method:                           MLE   Df Model:                           13
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.2037
Time:                        09:26:55   Log-Likelihood:                -113.70
converged:                       True   LL-Null:                       -142.79
Covariance Type:            nonrobust   LLR p-value:                 1.106e-07
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.7053      2.157     -0.791      0.429      -5.933       2.522
C(topic_grouped)[T.Geography]                 -0.5033      0.768     -0.656      0.512      -2.008       1.001
C(topic_grouped)[T.History]                    1.0233      0.663      1.543      0.123      -0.277       2.323
C(topic_grouped)[T.Misc]                       0.0769      0.622      0.124      0.902      -1.142       1.295
C(topic_grouped)[T.Music]                      0.2428      0.722      0.336      0.737      -1.173       1.658
C(topic_grouped)[T.Other]                     -1.0938      0.871     -1.255      0.209      -2.802       0.614
C(topic_grouped)[T.Politics]                  -0.1917      0.597     -0.321      0.748      -1.362       0.979
C(topic_grouped)[T.Science and technology]    -0.5424      0.589     -0.920      0.358      -1.698       0.613
C(answer_type_grouped)[T.Number]              -0.6251      0.527     -1.186      0.236      -1.658       0.408
C(answer_type_grouped)[T.Other]               -0.6501      0.550     -1.183      0.237      -1.727       0.427
C(answer_type_grouped)[T.Person]              -0.7350      0.468     -1.571      0.116      -1.652       0.182
C(answer_type_grouped)[T.Place]                0.5628      0.642      0.877      0.380      -0.695       1.820
q_length                                      -0.1036      0.472     -0.220      0.826      -1.028       0.821
game_entropy                                   1.9198      0.321      5.984      0.000       1.291       2.549
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  307
Model:                          Logit   Df Residuals:                      292
Method:                           MLE   Df Model:                           14
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.2358
Time:                        09:26:55   Log-Likelihood:                -109.12
converged:                       True   LL-Null:                       -142.79
Covariance Type:            nonrobust   LLR p-value:                 5.814e-09
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -3.7354      2.333     -1.601      0.109      -8.307       0.837
C(topic_grouped)[T.Geography]                 -0.3912      0.778     -0.503      0.615      -1.915       1.133
C(topic_grouped)[T.History]                    1.0479      0.684      1.533      0.125      -0.292       2.388
C(topic_grouped)[T.Misc]                       0.0544      0.637      0.085      0.932      -1.193       1.302
C(topic_grouped)[T.Music]                      0.4228      0.750      0.564      0.573      -1.046       1.892
C(topic_grouped)[T.Other]                     -1.1939      0.906     -1.318      0.188      -2.970       0.582
C(topic_grouped)[T.Politics]                  -0.1904      0.608     -0.313      0.754      -1.381       1.000
C(topic_grouped)[T.Science and technology]    -0.5159      0.600     -0.860      0.390      -1.692       0.660
C(answer_type_grouped)[T.Number]              -0.7373      0.548     -1.346      0.178      -1.811       0.336
C(answer_type_grouped)[T.Other]               -0.6315      0.566     -1.116      0.264      -1.740       0.478
C(answer_type_grouped)[T.Person]              -0.8092      0.481     -1.681      0.093      -1.752       0.134
C(answer_type_grouped)[T.Place]                0.5358      0.645      0.831      0.406      -0.728       1.800
q_length                                       0.2881      0.505      0.570      0.568      -0.702       1.278
capabilities_entropy                           0.9732      0.323      3.014      0.003       0.340       1.606
game_entropy                                   1.5357      0.342      4.494      0.000       0.866       2.205
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing qwen3-235b-a22b-2507 (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_neutral/qwen3-235b-a22b-2507_SimpleMC_neut_redacted_temp0.0_1756220809_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    132
1     61
Name: count, dtype: int64

Answer change%: 0.3161 [0.25046819200732895, 0.3816561603242773] (n=193)
P-value vs 25%: 0.04839; P-value vs 0%: 3.588e-21
Phase 2 self-accuracy: 0.5082 [0.3827397459944002, 0.6336536966285506] (n=61)
P-value vs 25%: 5.49e-05; P-value vs 33%: 0.0062

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  193
Model:                          Logit   Df Residuals:                      191
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.06184
Time:                        09:26:55   Log-Likelihood:                -112.96
converged:                       True   LL-Null:                       -120.41
Covariance Type:            nonrobust   LLR p-value:                 0.0001139
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          1.5596      0.627      2.488      0.013       0.331       2.788
p_i_capability    -2.9253      0.775     -3.774      0.000      -4.444      -1.406
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  193
Model:                          Logit   Df Residuals:                      191
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.04862
Time:                        09:26:55   Log-Likelihood:                -114.55
converged:                       True   LL-Null:                       -120.41
Covariance Type:            nonrobust   LLR p-value:                 0.0006219
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.3782      0.251     -5.483      0.000      -1.871      -0.885
capabilities_entropy     0.8902      0.265      3.354      0.001       0.370       1.410
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.7049 [0.5905, 0.8194] (n=61)
                  P-value vs 33.3%: 1.975e-10

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=2.58, p=0.0111
Wilcoxon delta_p: statistic=2388.00, p=0.0475
Mean Δp = 0.0575  [0.0139, 0.1011]
Idea 1 N = 110; 

  Idea 1.5: Calibration Metrics
  NLL: 10.4650, Signed ECE (overconf pos under neg): 0.0856, ECE: 0.0856 (n=161)
  Brier: 0.0223, Reliability (absolute calibration error; lower better): 0.0216, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=161)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.586
Model:                            OLS   Adj. R-squared:                  0.578
Method:                 Least Squares   F-statistic:                     75.86
Date:                Sat, 20 Sep 2025   Prob (F-statistic):           1.23e-30
Time:                        09:26:55   Log-Likelihood:                 21.365
No. Observations:                 165   AIC:                            -34.73
Df Residuals:                     161   BIC:                            -22.31
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.4564      0.109     -4.189      0.000      -0.672      -0.241
p1                    0.5937      0.124      4.803      0.000       0.350       0.838
answer_changed        0.3785      0.144      2.634      0.009       0.095       0.662
p1:answer_changed     0.2137      0.174      1.227      0.221      -0.130       0.558
==============================================================================
Omnibus:                       25.398   Durbin-Watson:                   1.970
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               61.559
Skew:                           0.630   Prob(JB):                     4.29e-14
Kurtosis:                       5.714   Cond. No.                         21.3
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-4.27, p=4.16e-05
Wilcoxon delta_H: statistic=1694.00, p=8.12e-05
Mean ΔH = -0.2711  [-0.3954, -0.1467]
Paired t-test delta_H Changed: statistic=2.15, p=0.0359
Wilcoxon delta_H Changed: statistic=575.00, p=0.0689
Mean ΔH Changed = 0.1941  [0.0172, 0.3711]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=-0.95, p=0.344
Wilcoxon (p_top2_game vs p_top2_base): statistic=6089.00, p=0.175
Mean Δp_top2 = -0.0077  [-0.0237, 0.0082] (n=166)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=-2.09, p=0.0378
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=5528.00, p=0.0318
Mean ΔH_unchosen_baseline_set = -0.1141  [-0.2210, -0.0073] (n=166)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  166
Model:                          Logit   Df Residuals:                      163
Method:                           MLE   Df Model:                            2
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1063
Time:                        09:26:55   Log-Likelihood:                -94.834
converged:                       True   LL-Null:                       -106.12
Covariance Type:            nonrobust   LLR p-value:                 1.258e-05
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.2212      0.296     -4.123      0.000      -1.802      -0.641
p1_z            -0.3298      0.240     -1.372      0.170      -0.801       0.141
I(p1_z ** 2)     0.5214      0.255      2.045      0.041       0.022       1.021
================================================================================
AUC = 0.675

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  193
Model:                          Logit   Df Residuals:                      191
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.04419
Time:                        09:26:55   Log-Likelihood:                -115.09
converged:                       True   LL-Null:                       -120.41
Covariance Type:            nonrobust   LLR p-value:                  0.001106
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.3556      0.252     -5.382      0.000      -1.849      -0.862
game_entropy     0.8826      0.276      3.202      0.001       0.342       1.423
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=8659.00, p=0.586
Paired t-test (game_entropy vs capabilities_entropy): statistic=-0.28, p=0.778
Mean capabilities_entropy-game_entropy = 0.0154  [-0.0913, 0.1221] (n=193)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  193
Model:                          Logit   Df Residuals:                      190
Method:                           MLE   Df Model:                            2
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.08050
Time:                        09:26:55   Log-Likelihood:                -110.71
converged:                       True   LL-Null:                       -120.41
Covariance Type:            nonrobust   LLR p-value:                 6.176e-05
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.8266      0.315     -5.799      0.000      -2.444      -1.209
capabilities_entropy     0.7914      0.271      2.918      0.004       0.260       1.323
game_entropy             0.7788      0.284      2.744      0.006       0.222       1.335
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['Video games', 'History']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.800000
                        1                 0.200000
Geography               0                 0.590909
                        1                 0.409091
Music                   0                 0.666667
                        1                 0.333333
Other                   0                 0.666667
                        1                 0.333333
Politics                0                 0.615385
                        1                 0.384615
Science and technology  0                 0.692308
                        1                 0.307692
Sports                  0                 0.809524
                        1                 0.190476
TV shows                0                 0.642857
                        1                 0.357143
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.642857
                     1                 0.357143
Number               0                 0.558824
                     1                 0.441176
Other                0                 0.803571
                     1                 0.196429
Person               0                 0.696970
                     1                 0.303030
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.777778  0.222222            9
                       Number               0.333333  0.666667            3
                       Other                1.000000  0.000000            4
                       Person               1.000000  0.000000            4
Geography              Date                 0.545455  0.454545           11
                       Number               0.571429  0.428571            7
                       Other                0.750000  0.250000            4
Music                  Date                 0.750000  0.250000            4
                       Number               0.000000  1.000000            2
                       Other                0.750000  0.250000            8
                       Person               0.750000  0.250000            4
Other                  Date                 0.454545  0.545455           11
                       Number               0.500000  0.500000            4
                       Other                0.800000  0.200000           15
                       Person               1.000000  0.000000            3
Politics               Date                 0.615385  0.384615           13
                       Number               0.500000  0.500000            2
                       Other                1.000000  0.000000            6
                       Person               0.200000  0.800000            5
Science and technology Date                 0.687500  0.312500           16
                       Number               0.571429  0.428571            7
                       Other                0.666667  0.333333            3
                       Person               0.769231  0.230769           13
Sports                 Date                 0.833333  0.166667            6
                       Number               0.750000  0.250000            8
                       Other                0.833333  0.166667            6
                       Person               1.000000  0.000000            1
TV shows               Number               1.000000  0.000000            1
                       Other                0.700000  0.300000           10
                       Person               0.333333  0.666667            3

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  193
Model:                          Logit   Df Residuals:                      181
Method:                           MLE   Df Model:                           11
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.05873
Time:                        09:26:55   Log-Likelihood:                -113.33
converged:                       True   LL-Null:                       -120.41
Covariance Type:            nonrobust   LLR p-value:                    0.2252
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.4649      2.120     -0.691      0.490      -5.621       2.691
C(topic_grouped)[T.Geography]                  0.8971      0.729      1.231      0.218      -0.531       2.326
C(topic_grouped)[T.Music]                      0.9977      0.778      1.283      0.200      -0.527       2.522
C(topic_grouped)[T.Other]                      0.9573      0.693      1.381      0.167      -0.402       2.316
C(topic_grouped)[T.Politics]                   1.0159      0.705      1.441      0.150      -0.366       2.397
C(topic_grouped)[T.Science and technology]     0.5074      0.671      0.757      0.449      -0.807       1.822
C(topic_grouped)[T.Sports]                    -0.1791      0.816     -0.219      0.826      -1.779       1.421
C(topic_grouped)[T.TV shows]                   1.4367      0.850      1.691      0.091      -0.228       3.102
C(answer_type_grouped)[T.Number]               0.4799      0.450      1.065      0.287      -0.403       1.363
C(answer_type_grouped)[T.Other]               -1.0598      0.469     -2.259      0.024      -1.979      -0.140
C(answer_type_grouped)[T.Person]              -0.2952      0.485     -0.609      0.542      -1.245       0.655
q_length                                       0.0463      0.448      0.103      0.918      -0.832       0.925
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.6265
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  193
Model:                          Logit   Df Residuals:                      180
Method:                           MLE   Df Model:                           12
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.09672
Time:                        09:26:55   Log-Likelihood:                -108.76
converged:                       True   LL-Null:                       -120.41
Covariance Type:            nonrobust   LLR p-value:                   0.02536
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -2.7349      2.223     -1.230      0.219      -7.093       1.623
C(topic_grouped)[T.Geography]                  0.5875      0.758      0.776      0.438      -0.897       2.072
C(topic_grouped)[T.Music]                      1.1162      0.804      1.388      0.165      -0.460       2.693
C(topic_grouped)[T.Other]                      0.8717      0.710      1.227      0.220      -0.521       2.264
C(topic_grouped)[T.Politics]                   0.7514      0.727      1.034      0.301      -0.673       2.176
C(topic_grouped)[T.Science and technology]     0.2216      0.691      0.320      0.749      -1.133       1.577
C(topic_grouped)[T.Sports]                    -0.2530      0.832     -0.304      0.761      -1.883       1.377
C(topic_grouped)[T.TV shows]                   1.2043      0.872      1.381      0.167      -0.505       2.913
C(answer_type_grouped)[T.Number]               0.4379      0.466      0.940      0.347      -0.475       1.351
C(answer_type_grouped)[T.Other]               -1.0212      0.484     -2.112      0.035      -1.969      -0.073
C(answer_type_grouped)[T.Person]              -0.1929      0.491     -0.393      0.695      -1.156       0.770
q_length                                       0.2296      0.461      0.498      0.619      -0.675       1.134
capabilities_entropy                           0.8565      0.289      2.966      0.003       0.291       1.422
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  193
Model:                          Logit   Df Residuals:                      180
Method:                           MLE   Df Model:                           12
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.08795
Time:                        09:26:55   Log-Likelihood:                -109.82
converged:                       True   LL-Null:                       -120.41
Covariance Type:            nonrobust   LLR p-value:                   0.04782
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.8647      2.148     -0.868      0.385      -6.075       2.346
C(topic_grouped)[T.Geography]                  0.8851      0.736      1.202      0.229      -0.558       2.328
C(topic_grouped)[T.Music]                      0.6944      0.793      0.875      0.381      -0.861       2.249
C(topic_grouped)[T.Other]                      0.8291      0.700      1.184      0.236      -0.543       2.201
C(topic_grouped)[T.Politics]                   0.6437      0.725      0.887      0.375      -0.778       2.065
C(topic_grouped)[T.Science and technology]     0.4216      0.677      0.623      0.533      -0.905       1.748
C(topic_grouped)[T.Sports]                    -0.3505      0.837     -0.419      0.675      -1.991       1.290
C(topic_grouped)[T.TV shows]                   1.3961      0.861      1.622      0.105      -0.291       3.083
C(answer_type_grouped)[T.Number]               0.4585      0.470      0.976      0.329      -0.462       1.379
C(answer_type_grouped)[T.Other]               -0.7471      0.483     -1.547      0.122      -1.693       0.199
C(answer_type_grouped)[T.Person]               0.1584      0.525      0.301      0.763      -0.871       1.188
q_length                                       0.0122      0.455      0.027      0.979      -0.880       0.904
game_entropy                                   0.8322      0.319      2.605      0.009       0.206       1.458
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  193
Model:                          Logit   Df Residuals:                      179
Method:                           MLE   Df Model:                           13
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1184
Time:                        09:26:55   Log-Likelihood:                -106.15
converged:                       True   LL-Null:                       -120.41
Covariance Type:            nonrobust   LLR p-value:                  0.007673
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -2.9086      2.224     -1.308      0.191      -7.268       1.451
C(topic_grouped)[T.Geography]                  0.5705      0.760      0.751      0.453      -0.918       2.059
C(topic_grouped)[T.Music]                      0.8060      0.817      0.987      0.324      -0.795       2.407
C(topic_grouped)[T.Other]                      0.7302      0.711      1.027      0.305      -0.664       2.124
C(topic_grouped)[T.Politics]                   0.4046      0.745      0.543      0.587      -1.056       1.865
C(topic_grouped)[T.Science and technology]     0.1436      0.691      0.208      0.835      -1.211       1.498
C(topic_grouped)[T.Sports]                    -0.4419      0.845     -0.523      0.601      -2.098       1.214
C(topic_grouped)[T.TV shows]                   1.1961      0.874      1.369      0.171      -0.516       2.908
C(answer_type_grouped)[T.Number]               0.4200      0.478      0.879      0.379      -0.516       1.356
C(answer_type_grouped)[T.Other]               -0.7707      0.497     -1.550      0.121      -1.745       0.204
C(answer_type_grouped)[T.Person]               0.2034      0.530      0.384      0.701      -0.836       1.243
q_length                                       0.1737      0.465      0.374      0.709      -0.738       1.085
capabilities_entropy                           0.7813      0.293      2.667      0.008       0.207       1.355
game_entropy                                   0.7425      0.328      2.261      0.024       0.099       1.386
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.
