
--- Analyzing claude-3-5-sonnet-20241022 (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_neutral/claude-3-5-sonnet-20241022_SimpleMC_redacted_cor_temp0.0_1751831934_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    260
1     31
Name: count, dtype: int64

Answer change%: 0.1065 [0.07108248360316238, 0.14197593564082386] (n=291)
P-value vs 25%: 2.14e-15; P-value vs 0%: 3.854e-09
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=31)
P-value vs 25%: 0; P-value vs 33%: 0
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.918367
                        1                 0.081633
Geography               0                 0.857143
                        1                 0.142857
Misc                    0                 0.866667
                        1                 0.133333
Music                   0                 0.826087
                        1                 0.173913
Other                   0                 0.857143
                        1                 0.142857
Politics                0                 0.934783
                        1                 0.065217
Science and technology  0                 0.890909
                        1                 0.109091
Sports                  0                 0.958333
                        1                 0.041667
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.891304
                     1                 0.108696
Number               0                 0.833333
                     1                 0.166667
Other                0                 0.883721
                     1                 0.116279
Person               0                 0.935065
                     1                 0.064935
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.900000  0.100000           10
                       Number               0.714286  0.285714            7
                       Other                1.000000  0.000000           12
                       Person               0.950000  0.050000           20
Geography              Date                 0.666667  0.333333            6
                       Number               1.000000  0.000000            8
                       Other                0.857143  0.142857            7
Misc                   Date                 0.866667  0.133333           15
                       Number               0.666667  0.333333            6
                       Other                0.933333  0.066667           15
                       Person               0.888889  0.111111            9
Music                  Date                 0.857143  0.142857            7
                       Other                0.666667  0.333333            6
                       Person               0.900000  0.100000           10
Other                  Date                 0.875000  0.125000            8
                       Number               1.000000  0.000000            2
                       Other                0.818182  0.181818           11
                       Person               0.857143  0.142857            7
Politics               Date                 0.904762  0.095238           21
                       Number               0.500000  0.500000            2
                       Other                1.000000  0.000000           14
                       Person               1.000000  0.000000            9
Science and technology Date                 0.947368  0.052632           19
                       Number               1.000000  0.000000            5
                       Other                0.733333  0.266667           15
                       Person               0.937500  0.062500           16
Sports                 Date                 1.000000  0.000000            6
                       Number               0.833333  0.166667            6
                       Other                1.000000  0.000000            6
                       Person               1.000000  0.000000            6

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  291
Model:                          Logit   Df Residuals:                      279
Method:                           MLE   Df Model:                           11
Date:                Tue, 08 Jul 2025   Pseudo R-squ.:                 0.04265
Time:                        07:27:23   Log-Likelihood:                -94.497
converged:                       True   LL-Null:                       -98.706
Covariance Type:            nonrobust   LLR p-value:                    0.6753
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -0.5528      2.542     -0.217      0.828      -5.535       4.429
C(topic_grouped)[T.Geography]                  0.2218      0.839      0.264      0.791      -1.422       1.866
C(topic_grouped)[T.Misc]                       0.4642      0.691      0.671      0.502      -0.891       1.819
C(topic_grouped)[T.Music]                      0.9874      0.777      1.271      0.204      -0.535       2.510
C(topic_grouped)[T.Other]                      0.5786      0.765      0.756      0.449      -0.921       2.078
C(topic_grouped)[T.Politics]                  -0.1528      0.822     -0.186      0.853      -1.763       1.458
C(topic_grouped)[T.Science and technology]     0.3562      0.690      0.516      0.606      -0.997       1.710
C(topic_grouped)[T.Sports]                    -0.8995      1.155     -0.779      0.436      -3.163       1.364
C(answer_type_grouped)[T.Number]               0.6188      0.593      1.043      0.297      -0.544       1.781
C(answer_type_grouped)[T.Other]                0.0261      0.483      0.054      0.957      -0.920       0.972
C(answer_type_grouped)[T.Person]              -0.6298      0.585     -1.076      0.282      -1.777       0.517
q_length                                      -0.4020      0.554     -0.726      0.468      -1.487       0.683
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing claude-3-5-sonnet-20241022 (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_neutral/claude-3-5-sonnet-20241022_SimpleMC_redacted_temp0.0_1751823700_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    134
1     75
Name: count, dtype: int64

Answer change%: 0.3589 [0.29382198328993747, 0.42388136599235915] (n=209)
P-value vs 25%: 0.001035; P-value vs 0%: 2.903e-27
Phase 2 self-accuracy: 0.5067 [0.39351815224599396, 0.6198151810873395] (n=75)
P-value vs 25%: 8.749e-06; P-value vs 33%: 0.002627
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'Video games', 'History']
                  Grouped rare answer_type into 'Misc'/'Other': None
topic_grouped           answer_changed
Art                     0                 0.615385
                        1                 0.384615
Geography               0                 0.565217
                        1                 0.434783
Misc                    0                 0.689655
                        1                 0.310345
Music                   0                 0.705882
                        1                 0.294118
Other                   0                 0.500000
                        1                 0.500000
Politics                0                 0.709677
                        1                 0.290323
Science and technology  0                 0.674419
                        1                 0.325581
Sports                  0                 0.625000
                        1                 0.375000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.584416
                     1                 0.415584
Number               0                 0.809524
                     1                 0.190476
Other                0                 0.612903
                     1                 0.387097
Person               0                 0.627907
                     1                 0.372093
Place                0                 0.562500
                     1                 0.437500
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.545455  0.454545           11
                       Number               0.500000  0.500000            2
                       Other                1.000000  0.000000            4
                       Person               0.428571  0.571429            7
                       Place                1.000000  0.000000            2
Geography              Date                 0.444444  0.555556            9
                       Number               0.800000  0.200000           10
                       Place                0.250000  0.750000            4
Misc                   Date                 0.875000  0.125000            8
                       Number               1.000000  0.000000            3
                       Other                0.600000  0.400000           10
                       Person               0.666667  0.333333            6
                       Place                0.000000  1.000000            2
Music                  Date                 0.600000  0.400000            5
                       Number               1.000000  0.000000            4
                       Other                0.500000  0.500000            4
                       Person               1.000000  0.000000            2
                       Place                0.500000  0.500000            2
Other                  Date                 0.400000  0.600000           10
                       Number               0.800000  0.200000            5
                       Other                1.000000  0.000000            2
                       Person               0.333333  0.666667            6
                       Place                0.000000  1.000000            1
Politics               Date                 0.600000  0.400000           15
                       Number               0.750000  0.250000            4
                       Other                0.800000  0.200000            5
                       Person               0.833333  0.166667            6
                       Place                1.000000  0.000000            1
Science and technology Date                 0.687500  0.312500           16
                       Number               0.666667  0.333333            9
                       Other                0.000000  1.000000            2
                       Person               0.714286  0.285714           14
                       Place                1.000000  0.000000            2
Sports                 Date                 0.333333  0.666667            3
                       Number               1.000000  0.000000            5
                       Other                0.250000  0.750000            4
                       Person               0.500000  0.500000            2
                       Place                1.000000  0.000000            2

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  209
Model:                          Logit   Df Residuals:                      196
Method:                           MLE   Df Model:                           12
Date:                Tue, 08 Jul 2025   Pseudo R-squ.:                 0.05010
Time:                        07:27:23   Log-Likelihood:                -129.59
converged:                       True   LL-Null:                       -136.43
Covariance Type:            nonrobust   LLR p-value:                    0.3222
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.5019      1.936     -0.776      0.438      -5.296       2.292
C(topic_grouped)[T.Geography]                  0.6168      0.631      0.978      0.328      -0.619       1.853
C(topic_grouped)[T.Misc]                      -0.3364      0.582     -0.578      0.564      -1.478       0.805
C(topic_grouped)[T.Music]                     -0.2654      0.685     -0.387      0.698      -1.608       1.077
C(topic_grouped)[T.Other]                      0.6414      0.590      1.087      0.277      -0.515       1.797
C(topic_grouped)[T.Politics]                  -0.4297      0.577     -0.745      0.457      -1.561       0.701
C(topic_grouped)[T.Science and technology]    -0.1225      0.530     -0.231      0.817      -1.161       0.916
C(topic_grouped)[T.Sports]                     0.1622      0.685      0.237      0.813      -1.181       1.506
C(answer_type_grouped)[T.Number]              -1.2876      0.480     -2.683      0.007      -2.228      -0.347
C(answer_type_grouped)[T.Other]                0.0544      0.463      0.117      0.907      -0.853       0.962
C(answer_type_grouped)[T.Person]              -0.0778      0.410     -0.190      0.850      -0.882       0.727
C(answer_type_grouped)[T.Place]                0.0488      0.585      0.083      0.934      -1.097       1.195
q_length                                       0.2513      0.416      0.604      0.546      -0.564       1.067
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing claude-3-haiku-20240307 (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_neutral/claude-3-haiku-20240307_SimpleMC_redacted_cor_temp0.0_1751845820_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    132
1     16
Name: count, dtype: int64

Answer change%: 0.1081 [0.05808133678563692, 0.1581348794305793] (n=148)
P-value vs 25%: 2.712e-08; P-value vs 0%: 2.281e-05
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=16)
P-value vs 25%: 0; P-value vs 33%: 0
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'Sports', 'History']
                  Grouped rare answer_type into 'Misc'/'Other': None
topic_grouped           answer_changed
Art                     0                 0.956522
                        1                 0.043478
Geography               0                 0.833333
                        1                 0.166667
Misc                    0                 0.809524
                        1                 0.190476
Music                   0                 1.000000
Other                   0                 0.857143
                        1                 0.142857
Politics                0                 0.863636
                        1                 0.136364
Science and technology  0                 0.896552
                        1                 0.103448
Video games             0                 1.000000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.823529
                     1                 0.176471
Number               0                 0.866667
                     1                 0.133333
Other                0                 0.918919
                     1                 0.081081
Person               0                 0.937500
                     1                 0.062500
Place                0                 1.000000
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 1.000000  0.000000            4
                       Number               1.000000  0.000000            2
                       Other                0.800000  0.200000            5
                       Person               1.000000  0.000000           10
                       Place                1.000000  0.000000            2
Geography              Date                 0.666667  0.333333            3
                       Number               0.750000  0.250000            4
                       Other                1.000000  0.000000            3
                       Place                1.000000  0.000000            2
Misc                   Date                 0.666667  0.333333            6
                       Number               1.000000  0.000000            1
                       Other                0.714286  0.285714            7
                       Person               1.000000  0.000000            6
                       Place                1.000000  0.000000            1
Music                  Date                 1.000000  0.000000            4
                       Other                1.000000  0.000000            3
                       Person               1.000000  0.000000            3
Other                  Date                 0.800000  0.200000           10
                       Number               1.000000  0.000000            1
                       Other                1.000000  0.000000            2
                       Person               0.800000  0.200000            5
                       Place                1.000000  0.000000            3
Politics               Date                 0.857143  0.142857            7
                       Number               0.000000  1.000000            1
                       Other                1.000000  0.000000            6
                       Person               0.750000  0.250000            4
                       Place                1.000000  0.000000            4
Science and technology Date                 0.750000  0.250000           12
                       Number               1.000000  0.000000            4
                       Other                1.000000  0.000000            9
                       Person               1.000000  0.000000            4
Video games            Date                 1.000000  0.000000            5
                       Number               1.000000  0.000000            2
                       Other                1.000000  0.000000            2
                       Place                1.000000  0.000000            1

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  148
Model:                          Logit   Df Residuals:                      135
Method:                           MLE   Df Model:                           12
Date:                Tue, 08 Jul 2025   Pseudo R-squ.:                  0.1529
Time:                        07:27:23   Log-Likelihood:                -42.945
converged:                      False   LL-Null:                       -50.696
Covariance Type:            nonrobust   LLR p-value:                    0.2151
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      0.3288      3.615      0.091      0.928      -6.756       7.414
C(topic_grouped)[T.Geography]                  1.2878      1.342      0.959      0.337      -1.343       3.919
C(topic_grouped)[T.Misc]                       1.5567      1.189      1.309      0.191      -0.774       3.887
C(topic_grouped)[T.Music]                    -28.7277   2.29e+06  -1.25e-05      1.000   -4.49e+06    4.49e+06
C(topic_grouped)[T.Other]                      1.0818      1.241      0.872      0.383      -1.351       3.515
C(topic_grouped)[T.Politics]                   1.3772      1.255      1.097      0.272      -1.082       3.837
C(topic_grouped)[T.Science and technology]     0.7270      1.246      0.583      0.560      -1.716       3.170
C(topic_grouped)[T.Video games]               -6.0027     25.681     -0.234      0.815     -56.336      44.330
C(answer_type_grouped)[T.Number]              -0.1766      0.956     -0.185      0.853      -2.051       1.697
C(answer_type_grouped)[T.Other]               -1.0631      0.741     -1.434      0.152      -2.516       0.390
C(answer_type_grouped)[T.Person]              -1.2322      0.859     -1.434      0.152      -2.917       0.452
C(answer_type_grouped)[T.Place]              -19.4161   9322.559     -0.002      0.998   -1.83e+04    1.83e+04
q_length                                      -0.5974      0.802     -0.745      0.456      -2.168       0.974
==============================================================================================================

Possibly complete quasi-separation: A fraction 0.17 of observations can be
perfectly predicted. This might indicate that there is complete
quasi-separation. In this case some parameters will not be identified.

                  Model 6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length (after removing deterministic categories: defaultdict(<class 'list'>, {'topic_grouped': ['Video games', 'Music'], 'answer_type_grouped': ['Place']}))
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  116
Model:                          Logit   Df Residuals:                      106
Method:                           MLE   Df Model:                            9
Date:                Tue, 08 Jul 2025   Pseudo R-squ.:                 0.07725
Time:                        07:27:23   Log-Likelihood:                -42.943
converged:                       True   LL-Null:                       -46.538
Covariance Type:            nonrobust   LLR p-value:                    0.6173
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      0.3288      3.615      0.091      0.928      -6.757       7.414
C(topic_grouped)[T.Geography]                  1.2878      1.342      0.959      0.337      -1.343       3.919
C(topic_grouped)[T.Misc]                       1.5567      1.189      1.309      0.191      -0.774       3.887
C(topic_grouped)[T.Other]                      1.0818      1.241      0.872      0.383      -1.351       3.515
C(topic_grouped)[T.Politics]                   1.3772      1.255      1.097      0.272      -1.082       3.837
C(topic_grouped)[T.Science and technology]     0.7270      1.246      0.583      0.560      -1.716       3.170
C(answer_type_grouped)[T.Number]              -0.1766      0.956     -0.185      0.853      -2.051       1.698
C(answer_type_grouped)[T.Other]               -1.0631      0.741     -1.434      0.152      -2.516       0.390
C(answer_type_grouped)[T.Person]              -1.2322      0.859     -1.434      0.152      -2.917       0.452
q_length                                      -0.5974      0.802     -0.745      0.456      -2.169       0.974
==============================================================================================================

--- Analyzing claude-3-haiku-20240307 (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_neutral/claude-3-haiku-20240307_SimpleMC_redacted_temp0.0_1751827834_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    284
1     68
Name: count, dtype: int64

Answer change%: 0.1932 [0.15193905806353425, 0.2344245783001021] (n=352)
P-value vs 25%: 0.006931; P-value vs 0%: 4.291e-20
Phase 2 self-accuracy: 0.4412 [0.3231614877334133, 0.5591914534430572] (n=68)
P-value vs 25%: 0.001498; P-value vs 33%: 0.0724
                  Grouped rare topic into 'Misc'/'Other': ['History', 'TV shows', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.730769
                        1                 0.269231
Geography               0                 0.906250
                        1                 0.093750
Misc                    0                 0.823529
                        1                 0.176471
Music                   0                 0.800000
                        1                 0.200000
Other                   0                 0.838710
                        1                 0.161290
Politics                0                 0.818182
                        1                 0.181818
Science and technology  0                 0.797101
                        1                 0.202899
Sports                  0                 0.781250
                        1                 0.218750
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.822034
                     1                 0.177966
Number               0                 0.825397
                     1                 0.174603
Other                0                 0.807229
                     1                 0.192771
Person               0                 0.772727
                     1                 0.227273
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.529412  0.470588           17
                       Number               0.714286  0.285714            7
                       Other                0.818182  0.181818           11
                       Person               0.882353  0.117647           17
Geography              Date                 1.000000  0.000000           12
                       Number               0.857143  0.142857           14
                       Other                0.833333  0.166667            6
Misc                   Date                 0.692308  0.307692           13
                       Number               0.833333  0.166667            6
                       Other                0.894737  0.105263           19
                       Person               0.846154  0.153846           13
Music                  Date                 0.750000  0.250000            8
                       Number               0.750000  0.250000            4
                       Other                0.888889  0.111111            9
                       Person               0.777778  0.222222            9
Other                  Date                 1.000000  0.000000            8
                       Number               0.833333  0.166667            6
                       Other                0.666667  0.333333            9
                       Person               0.875000  0.125000            8
Politics               Date                 0.896552  0.103448           29
                       Number               0.600000  0.400000            5
                       Other                1.000000  0.000000           10
                       Person               0.545455  0.454545           11
Science and technology Date                 0.913043  0.086957           23
                       Number               0.800000  0.200000           10
                       Other                0.700000  0.300000           10
                       Person               0.730769  0.269231           26
Sports                 Date                 0.750000  0.250000            8
                       Number               1.000000  0.000000           11
                       Other                0.555556  0.444444            9
                       Person               0.750000  0.250000            4

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  352
Model:                          Logit   Df Residuals:                      340
Method:                           MLE   Df Model:                           11
Date:                Tue, 08 Jul 2025   Pseudo R-squ.:                 0.01556
Time:                        07:27:23   Log-Likelihood:                -170.08
converged:                       True   LL-Null:                       -172.76
Covariance Type:            nonrobust   LLR p-value:                    0.9117
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.9461      1.720     -1.131      0.258      -5.317       1.425
C(topic_grouped)[T.Geography]                 -1.1921      0.698     -1.708      0.088      -2.560       0.176
C(topic_grouped)[T.Misc]                      -0.5362      0.486     -1.103      0.270      -1.489       0.416
C(topic_grouped)[T.Music]                     -0.3750      0.555     -0.675      0.500      -1.464       0.714
C(topic_grouped)[T.Other]                     -0.6305      0.582     -1.083      0.279      -1.772       0.511
C(topic_grouped)[T.Politics]                  -0.5069      0.479     -1.059      0.290      -1.445       0.432
C(topic_grouped)[T.Science and technology]    -0.3769      0.434     -0.868      0.385      -1.228       0.474
C(topic_grouped)[T.Sports]                    -0.2566      0.540     -0.475      0.634      -1.315       0.801
C(answer_type_grouped)[T.Number]               0.0434      0.425      0.102      0.919      -0.790       0.877
C(answer_type_grouped)[T.Other]                0.1143      0.379      0.302      0.763      -0.628       0.857
C(answer_type_grouped)[T.Person]               0.2490      0.362      0.689      0.491      -0.460       0.958
q_length                                       0.1858      0.369      0.504      0.614      -0.537       0.909
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing claude-3-sonnet-20240229 (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_neutral/claude-3-sonnet-20240229_SimpleMC_redacted_cor_temp0.0_1751845655_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    105
1     47
Name: count, dtype: int64

Answer change%: 0.3092 [0.2357377776155138, 0.3826832750160652] (n=152)
P-value vs 25%: 0.1142; P-value vs 0%: 1.604e-16
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=47)
P-value vs 25%: 0; P-value vs 33%: 0
                  Grouped rare topic into 'Misc'/'Other': ['Sports', 'TV shows', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.666667
                        1                 0.333333
Geography               0                 0.642857
                        1                 0.357143
Misc                    0                 0.714286
                        1                 0.285714
Music                   0                 0.857143
                        1                 0.142857
Other                   0                 0.833333
                        1                 0.166667
Politics                0                 0.619048
                        1                 0.380952
Science and technology  0                 0.636364
                        1                 0.363636
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.656716
                     1                 0.343284
Number               1                 0.550000
                     0                 0.450000
Other                0                 0.818182
                     1                 0.181818
Person               0                 0.781250
                     1                 0.218750
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.555556  0.444444            9
                       Number               0.333333  0.666667            3
                       Other                0.833333  0.166667            6
                       Person               0.750000  0.250000           12
Geography              Date                 0.750000  0.250000            4
                       Number               0.571429  0.428571            7
                       Other                0.666667  0.333333            3
Misc                   Date                 0.769231  0.230769           13
                       Number               0.500000  0.500000            4
                       Other                0.666667  0.333333            6
                       Person               0.800000  0.200000            5
Music                  Date                 1.000000  0.000000            5
                       Number               0.000000  1.000000            1
                       Other                0.666667  0.333333            3
                       Person               1.000000  0.000000            5
Other                  Date                 0.833333  0.166667            6
                       Number               0.000000  1.000000            1
                       Other                1.000000  0.000000            3
                       Person               1.000000  0.000000            2
Politics               Date                 0.461538  0.538462           13
                       Other                0.833333  0.166667            6
                       Person               1.000000  0.000000            2
Science and technology Date                 0.588235  0.411765           17
                       Number               0.500000  0.500000            4
                       Other                1.000000  0.000000            6
                       Person               0.500000  0.500000            6

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  152
Model:                          Logit   Df Residuals:                      141
Method:                           MLE   Df Model:                           10
Date:                Tue, 08 Jul 2025   Pseudo R-squ.:                 0.08071
Time:                        07:27:23   Log-Likelihood:                -86.419
converged:                       True   LL-Null:                       -94.007
Covariance Type:            nonrobust   LLR p-value:                    0.1258
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      1.9076      2.436      0.783      0.434      -2.868       6.683
C(topic_grouped)[T.Geography]                 -0.5956      0.775     -0.769      0.442      -2.114       0.923
C(topic_grouped)[T.Misc]                      -0.4138      0.607     -0.682      0.495      -1.603       0.775
C(topic_grouped)[T.Music]                     -1.1595      0.890     -1.303      0.193      -2.904       0.585
C(topic_grouped)[T.Other]                     -1.0858      0.909     -1.194      0.232      -2.868       0.696
C(topic_grouped)[T.Politics]                   0.3837      0.656      0.585      0.559      -0.902       1.669
C(topic_grouped)[T.Science and technology]     0.0698      0.573      0.122      0.903      -1.053       1.192
C(answer_type_grouped)[T.Number]               1.0664      0.575      1.853      0.064      -0.061       2.194
C(answer_type_grouped)[T.Other]               -0.9067      0.533     -1.700      0.089      -1.952       0.139
C(answer_type_grouped)[T.Person]              -0.6505      0.532     -1.223      0.221      -1.693       0.392
q_length                                      -0.5211      0.536     -0.973      0.331      -1.571       0.529
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing claude-3-sonnet-20240229 (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_neutral/claude-3-sonnet-20240229_SimpleMC_redacted_temp0.0_1751827442_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    221
1    127
Name: count, dtype: int64

Answer change%: 0.3649 [0.31436271538025695, 0.41552234209100747] (n=348)
P-value vs 25%: 8.428e-06; P-value vs 0%: 2.108e-45
Phase 2 self-accuracy: 0.3937 [0.30872936773146276, 0.4786722070716869] (n=127)
P-value vs 25%: 0.0009177; P-value vs 33%: 0.1615
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': None
topic_grouped           answer_changed
Art                     0                 0.511111
                        1                 0.488889
Geography               0                 0.600000
                        1                 0.400000
Misc                    0                 0.709091
                        1                 0.290909
Music                   0                 0.807692
                        1                 0.192308
Other                   0                 0.575000
                        1                 0.425000
Politics                0                 0.625000
                        1                 0.375000
Science and technology  0                 0.676923
                        1                 0.323077
Sports                  0                 0.580645
                        1                 0.419355
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.637255
                     1                 0.362745
Number               0                 0.586207
                     1                 0.413793
Other                0                 0.689189
                     1                 0.310811
Person               0                 0.625000
                     1                 0.375000
Place                0                 0.615385
                     1                 0.384615
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.500000  0.500000           12
                       Number               0.333333  0.666667            6
                       Other                0.500000  0.500000           10
                       Person               0.600000  0.400000           15
                       Place                0.500000  0.500000            2
Geography              Date                 0.545455  0.454545           11
                       Number               0.545455  0.454545           11
                       Other                1.000000  0.000000            1
                       Place                0.714286  0.285714            7
Misc                   Date                 0.833333  0.166667           12
                       Number               0.714286  0.285714            7
                       Other                0.714286  0.285714           21
                       Person               0.538462  0.461538           13
                       Place                1.000000  0.000000            2
Music                  Date                 0.571429  0.428571            7
                       Number               1.000000  0.000000            3
                       Other                0.875000  0.125000            8
                       Person               0.857143  0.142857            7
                       Place                1.000000  0.000000            1
Other                  Date                 0.583333  0.416667           12
                       Number               0.833333  0.166667            6
                       Other                0.857143  0.142857            7
                       Person               0.363636  0.636364           11
                       Place                0.250000  0.750000            4
Politics               Date                 0.739130  0.260870           23
                       Number               0.333333  0.666667            6
                       Other                0.666667  0.333333            9
                       Person               0.538462  0.461538           13
                       Place                0.600000  0.400000            5
Science and technology Date                 0.611111  0.388889           18
                       Number               0.600000  0.400000           10
                       Other                0.700000  0.300000           10
                       Person               0.750000  0.250000           24
                       Place                0.666667  0.333333            3
Sports                 Date                 0.571429  0.428571            7
                       Number               0.555556  0.444444            9
                       Other                0.500000  0.500000            8
                       Person               0.800000  0.200000            5
                       Place                0.500000  0.500000            2

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  348
Model:                          Logit   Df Residuals:                      335
Method:                           MLE   Df Model:                           12
Date:                Tue, 08 Jul 2025   Pseudo R-squ.:                 0.02870
Time:                        07:27:23   Log-Likelihood:                -221.81
converged:                       True   LL-Null:                       -228.36
Covariance Type:            nonrobust   LLR p-value:                    0.3614
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      2.0984      1.422      1.476      0.140      -0.689       4.886
C(topic_grouped)[T.Geography]                 -0.4835      0.502     -0.963      0.336      -1.467       0.500
C(topic_grouped)[T.Misc]                      -0.8206      0.425     -1.931      0.053      -1.654       0.012
C(topic_grouped)[T.Music]                     -1.4162      0.583     -2.429      0.015      -2.559      -0.273
C(topic_grouped)[T.Other]                     -0.2972      0.441     -0.674      0.500      -1.161       0.567
C(topic_grouped)[T.Politics]                  -0.3944      0.413     -0.954      0.340      -1.205       0.416
C(topic_grouped)[T.Science and technology]    -0.7153      0.402     -1.778      0.075      -1.504       0.073
C(topic_grouped)[T.Sports]                    -0.2863      0.476     -0.601      0.548      -1.220       0.648
C(answer_type_grouped)[T.Number]               0.2257      0.348      0.649      0.516      -0.456       0.907
C(answer_type_grouped)[T.Other]               -0.2203      0.340     -0.647      0.518      -0.887       0.447
C(answer_type_grouped)[T.Person]               0.0301      0.314      0.096      0.923      -0.584       0.645
C(answer_type_grouped)[T.Place]                0.0682      0.464      0.147      0.883      -0.841       0.977
q_length                                      -0.4762      0.304     -1.567      0.117      -1.072       0.119
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing claude-sonnet-4-20250514 (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_neutral/claude-sonnet-4-20250514_SimpleMC_redacted_cor_temp0.0_1751828378_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    175
1     44
Name: count, dtype: int64

Answer change%: 0.2009 [0.14784590663059066, 0.25398057738767416] (n=219)
P-value vs 25%: 0.06984; P-value vs 0%: 1.167e-13
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=44)
P-value vs 25%: 0; P-value vs 33%: 0
                  Grouped rare topic into 'Misc'/'Other': ['History', 'TV shows', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': None
topic_grouped           answer_changed
Art                     0                 0.894737
                        1                 0.105263
Geography               0                 0.666667
                        1                 0.333333
Misc                    0                 0.914286
                        1                 0.085714
Music                   0                 0.809524
                        1                 0.190476
Other                   0                 0.944444
                        1                 0.055556
Politics                0                 0.806452
                        1                 0.193548
Science and technology  0                 0.625000
                        1                 0.375000
Sports                  0                 0.733333
                        1                 0.266667
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.736842
                     1                 0.263158
Number               0                 0.677419
                     1                 0.322581
Other                0                 0.921569
                     1                 0.078431
Person               0                 0.826087
                     1                 0.173913
Place                0                 0.866667
                     1                 0.133333
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.777778  0.222222            9
                       Number               1.000000  0.000000            3
                       Other                1.000000  0.000000            8
                       Person               0.866667  0.133333           15
                       Place                1.000000  0.000000            3
Geography              Date                 0.250000  0.750000            4
                       Number               0.666667  0.333333            9
                       Other                1.000000  0.000000            3
                       Place                0.800000  0.200000            5
Misc                   Date                 0.846154  0.153846           13
                       Number               1.000000  0.000000            4
                       Other                0.923077  0.076923           13
                       Person               1.000000  0.000000            4
                       Place                1.000000  0.000000            1
Music                  Date                 0.750000  0.250000            8
                       Number               0.666667  0.333333            3
                       Other                0.500000  0.500000            2
                       Person               1.000000  0.000000            7
                       Place                1.000000  0.000000            1
Other                  Date                 1.000000  0.000000            6
                       Number               0.750000  0.250000            4
                       Other                1.000000  0.000000            4
                       Person               1.000000  0.000000            3
                       Place                1.000000  0.000000            1
Politics               Date                 0.800000  0.200000           15
                       Number               0.000000  1.000000            1
                       Other                1.000000  0.000000            5
                       Person               0.714286  0.285714            7
                       Place                1.000000  0.000000            3
Science and technology Date                 0.588235  0.411765           17
                       Number               0.500000  0.500000            4
                       Other                0.833333  0.166667           12
                       Person               0.500000  0.500000            6
                       Place                0.000000  1.000000            1
Sports                 Date                 0.750000  0.250000            4
                       Number               0.333333  0.666667            3
                       Other                1.000000  0.000000            4
                       Person               0.750000  0.250000            4

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  219
Model:                          Logit   Df Residuals:                      206
Method:                           MLE   Df Model:                           12
Date:                Tue, 08 Jul 2025   Pseudo R-squ.:                  0.1295
Time:                        07:27:23   Log-Likelihood:                -95.642
converged:                       True   LL-Null:                       -109.86
Covariance Type:            nonrobust   LLR p-value:                  0.004759
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -2.2083      2.199     -1.004      0.315      -6.519       2.102
C(topic_grouped)[T.Geography]                  1.3091      0.774      1.690      0.091      -0.209       2.827
C(topic_grouped)[T.Misc]                      -0.2224      0.826     -0.269      0.788      -1.840       1.396
C(topic_grouped)[T.Music]                      0.5067      0.779      0.651      0.515      -1.020       2.033
C(topic_grouped)[T.Other]                     -0.8304      1.180     -0.704      0.482      -3.143       1.482
C(topic_grouped)[T.Politics]                   0.6021      0.730      0.825      0.409      -0.829       2.033
C(topic_grouped)[T.Science and technology]     1.6610      0.649      2.559      0.011       0.389       2.933
C(topic_grouped)[T.Sports]                     1.0929      0.815      1.341      0.180      -0.504       2.690
C(answer_type_grouped)[T.Number]               0.2270      0.533      0.425      0.670      -0.819       1.272
C(answer_type_grouped)[T.Other]               -1.5199      0.608     -2.501      0.012      -2.711      -0.329
C(answer_type_grouped)[T.Person]              -0.3652      0.501     -0.728      0.466      -1.348       0.617
C(answer_type_grouped)[T.Place]               -0.9421      0.862     -1.093      0.274      -2.631       0.747
q_length                                       0.1041      0.471      0.221      0.825      -0.820       1.028
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing claude-sonnet-4-20250514 (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_neutral/claude-sonnet-4-20250514_SimpleMC_redacted_temp0.0_1751824015_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
1    149
0    132
Name: count, dtype: int64

Answer change%: 0.5302 [0.47189536831085716, 0.5886028523297121] (n=281)
P-value vs 25%: 4.826e-21; P-value vs 0%: 5.931e-71
Phase 2 self-accuracy: 0.5034 [0.4230742598581297, 0.5836371495378435] (n=149)
P-value vs 25%: 6.197e-10; P-value vs 33%: 3.196e-05
                  Grouped rare topic into 'Misc'/'Other': ['History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     1                 0.594595
                        0                 0.405405
Geography               1                 0.565217
                        0                 0.434783
Misc                    0                 0.550000
                        1                 0.450000
Music                   0                 0.684211
                        1                 0.315789
Other                   1                 0.588235
                        0                 0.411765
Politics                0                 0.521739
                        1                 0.478261
Science and technology  0                 0.534483
                        1                 0.465517
Sports                  1                 0.600000
                        0                 0.400000
TV shows                1                 0.789474
                        0                 0.210526
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.505376
                     1                 0.494624
Number               0                 0.510638
                     1                 0.489362
Other                1                 0.611940
                     0                 0.388060
Person               1                 0.527027
                     0                 0.472973
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.666667  0.333333           12
                       Number               0.333333  0.666667            6
                       Other                0.428571  0.571429            7
                       Person               0.166667  0.833333           12
Geography              Date                 0.272727  0.727273           11
                       Number               0.666667  0.333333            9
                       Other                0.333333  0.666667            3
Misc                   Date                 0.777778  0.222222            9
                       Number               0.000000  1.000000            4
                       Other                0.500000  0.500000            4
                       Person               0.666667  0.333333            3
Music                  Date                 0.750000  0.250000            4
                       Number               1.000000  0.000000            1
                       Other                0.666667  0.333333            9
                       Person               0.600000  0.400000            5
Other                  Date                 0.166667  0.833333           12
                       Number               0.666667  0.333333            3
                       Other                0.444444  0.555556            9
                       Person               0.600000  0.400000           10
Politics               Date                 0.523810  0.476190           21
                       Number               0.600000  0.400000            5
                       Other                0.333333  0.666667           12
                       Person               0.750000  0.250000            8
Science and technology Date                 0.611111  0.388889           18
                       Number               0.600000  0.400000           10
                       Other                0.500000  0.500000            6
                       Person               0.458333  0.541667           24
Sports                 Date                 0.400000  0.600000            5
                       Number               0.500000  0.500000            8
                       Other                0.250000  0.750000            8
                       Person               0.500000  0.500000            4
TV shows               Date                 0.000000  1.000000            1
                       Number               0.000000  1.000000            1
                       Other                0.111111  0.888889            9
                       Person               0.375000  0.625000            8

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  281
Model:                          Logit   Df Residuals:                      268
Method:                           MLE   Df Model:                           12
Date:                Tue, 08 Jul 2025   Pseudo R-squ.:                 0.03866
Time:                        07:27:23   Log-Likelihood:                -186.75
converged:                       True   LL-Null:                       -194.26
Covariance Type:            nonrobust   LLR p-value:                    0.2403
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      0.2911      1.583      0.184      0.854      -2.811       3.393
C(topic_grouped)[T.Geography]                 -0.0493      0.553     -0.089      0.929      -1.134       1.035
C(topic_grouped)[T.Misc]                      -0.5782      0.567     -1.020      0.308      -1.689       0.532
C(topic_grouped)[T.Music]                     -1.3001      0.609     -2.136      0.033      -2.493      -0.107
C(topic_grouped)[T.Other]                     -0.0657      0.487     -0.135      0.893      -1.020       0.888
C(topic_grouped)[T.Politics]                  -0.5022      0.455     -1.103      0.270      -1.394       0.390
C(topic_grouped)[T.Science and technology]    -0.4923      0.429     -1.147      0.251      -1.334       0.349
C(topic_grouped)[T.Sports]                    -0.0040      0.537     -0.008      0.994      -1.057       1.049
C(topic_grouped)[T.TV shows]                   0.8051      0.665      1.210      0.226      -0.499       2.109
C(answer_type_grouped)[T.Number]              -0.1151      0.371     -0.310      0.756      -0.842       0.612
C(answer_type_grouped)[T.Other]                0.4346      0.348      1.250      0.211      -0.247       1.116
C(answer_type_grouped)[T.Person]               0.0623      0.336      0.185      0.853      -0.596       0.720
q_length                                       0.0026      0.339      0.008      0.994      -0.663       0.668
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing deepseek-chat (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_neutral/deepseek-chat_SimpleMC_redacted_cor_temp0.0_1751844247_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    218
1     19
Name: count, dtype: int64

Answer change%: 0.0802 [0.045596289587007954, 0.11474126315560809] (n=237)
P-value vs 25%: 6.092e-22; P-value vs 0%: 5.497e-06
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=19)
P-value vs 25%: 0; P-value vs 33%: 0

  Model 1.4: Answer Changed ~ capabilities_prob
                    Could not fit Model 1.4: Singular matrix

  Model 1.5: Answer Changed ~ capabilities_entropy
                    Could not fit Model 1.5: Singular matrix

  Model 1.6: Answer Changed ~ Game Entropy
                    Could not fit Model 1.6: Singular matrix

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                    Could not fit Model 1.7: Singular matrix
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': None
topic_grouped           answer_changed
Art                     0                 0.972222
                        1                 0.027778
Geography               0                 0.833333
                        1                 0.166667
History                 0                 0.888889
                        1                 0.111111
Misc                    0                 0.958333
                        1                 0.041667
Music                   0                 0.777778
                        1                 0.222222
Other                   0                 0.904762
                        1                 0.095238
Politics                0                 0.972222
                        1                 0.027778
Science and technology  0                 0.930233
                        1                 0.069767
Sports                  0                 0.941176
                        1                 0.058824
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.882979
                     1                 0.117021
Number               0                 0.896552
                     1                 0.103448
Other                0                 0.921569
                     1                 0.078431
Person               0                 1.000000
Place                0                 0.941176
                     1                 0.058824
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.916667  0.083333           12
                       Number               1.000000  0.000000            4
                       Other                1.000000  0.000000            6
                       Person               1.000000  0.000000           12
                       Place                1.000000  0.000000            2
Geography              Date                 0.666667  0.333333            6
                       Number               0.900000  0.100000           10
                       Other                1.000000  0.000000            3
                       Place                0.800000  0.200000            5
History                Date                 0.800000  0.200000           10
                       Number               1.000000  0.000000            2
                       Other                1.000000  0.000000            2
                       Person               1.000000  0.000000            3
                       Place                1.000000  0.000000            1
Misc                   Date                 1.000000  0.000000            6
                       Number               0.750000  0.250000            4
                       Other                1.000000  0.000000            9
                       Person               1.000000  0.000000            4
                       Place                1.000000  0.000000            1
Music                  Date                 0.714286  0.285714            7
                       Number               0.000000  1.000000            1
                       Other                0.800000  0.200000            5
                       Person               1.000000  0.000000            5
Other                  Date                 0.800000  0.200000           10
                       Number               1.000000  0.000000            1
                       Other                1.000000  0.000000            4
                       Person               1.000000  0.000000            4
                       Place                1.000000  0.000000            2
Politics               Date                 0.947368  0.052632           19
                       Number               1.000000  0.000000            1
                       Other                1.000000  0.000000            5
                       Person               1.000000  0.000000            6
                       Place                1.000000  0.000000            5
Science and technology Date                 0.950000  0.050000           20
                       Number               1.000000  0.000000            5
                       Other                0.800000  0.200000           10
                       Person               1.000000  0.000000            7
                       Place                1.000000  0.000000            1
Sports                 Date                 1.000000  0.000000            4
                       Number               1.000000  0.000000            1
                       Other                0.857143  0.142857            7
                       Person               1.000000  0.000000            5

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  237
Model:                          Logit   Df Residuals:                      223
Method:                           MLE   Df Model:                           13
Date:                Tue, 08 Jul 2025   Pseudo R-squ.:                  0.1444
Time:                        07:27:23   Log-Likelihood:                -56.610
converged:                       True   LL-Null:                       -66.166
Covariance Type:            nonrobust   LLR p-value:                    0.1197
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -2.8196      3.383     -0.833      0.405      -9.450       3.811
C(topic_grouped)[T.Geography]                  1.6704      1.189      1.404      0.160      -0.661       4.002
C(topic_grouped)[T.History]                    1.1867      1.278      0.929      0.353      -1.317       3.691
C(topic_grouped)[T.Misc]                       0.2918      1.460      0.200      0.842      -2.570       3.154
C(topic_grouped)[T.Music]                      2.3151      1.194      1.939      0.052      -0.025       4.655
C(topic_grouped)[T.Other]                      1.0976      1.275      0.861      0.389      -1.401       3.596
C(topic_grouped)[T.Politics]                  -0.2639      1.469     -0.180      0.857      -3.143       2.615
C(topic_grouped)[T.Science and technology]     0.7087      1.200      0.591      0.555      -1.643       3.060
C(topic_grouped)[T.Sports]                     0.8227      1.477      0.557      0.578      -2.073       3.718
C(answer_type_grouped)[T.Number]              -0.3969      0.766     -0.518      0.604      -1.898       1.104
C(answer_type_grouped)[T.Other]               -0.5251      0.654     -0.803      0.422      -1.806       0.756
C(answer_type_grouped)[T.Person]            -113.3756   1.63e+24  -6.97e-23      1.000   -3.19e+24    3.19e+24
C(answer_type_grouped)[T.Place]               -0.8054      1.153     -0.699      0.485      -3.065       1.454
q_length                                      -0.0196      0.729     -0.027      0.979      -1.448       1.409
==============================================================================================================

Possibly complete quasi-separation: A fraction 0.19 of observations can be
perfectly predicted. This might indicate that there is complete
quasi-separation. In this case some parameters will not be identified.

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.0000
                    Could not fit Model 4.6: Singular matrix

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                    Could not fit Model 4.8: Singular matrix

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                    Could not fit Model 4.95: Singular matrix

                  Model 6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length (after removing deterministic categories: defaultdict(<class 'list'>, {'answer_type_grouped': ['Person']}))
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  191
Model:                          Logit   Df Residuals:                      178
Method:                           MLE   Df Model:                           12
Date:                Tue, 08 Jul 2025   Pseudo R-squ.:                 0.08503
Time:                        07:27:23   Log-Likelihood:                -56.610
converged:                       True   LL-Null:                       -61.871
Covariance Type:            nonrobust   LLR p-value:                    0.5703
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -2.8196      3.383     -0.833      0.405      -9.450       3.811
C(topic_grouped)[T.Geography]                  1.6704      1.189      1.404      0.160      -0.661       4.002
C(topic_grouped)[T.History]                    1.1867      1.278      0.929      0.353      -1.317       3.691
C(topic_grouped)[T.Misc]                       0.2918      1.460      0.200      0.842      -2.570       3.154
C(topic_grouped)[T.Music]                      2.3151      1.194      1.939      0.052      -0.025       4.655
C(topic_grouped)[T.Other]                      1.0976      1.275      0.861      0.389      -1.401       3.596
C(topic_grouped)[T.Politics]                  -0.2639      1.469     -0.180      0.857      -3.143       2.615
C(topic_grouped)[T.Science and technology]     0.7087      1.200      0.591      0.555      -1.643       3.060
C(topic_grouped)[T.Sports]                     0.8227      1.477      0.557      0.578      -2.073       3.718
C(answer_type_grouped)[T.Number]              -0.3969      0.766     -0.518      0.604      -1.898       1.104
C(answer_type_grouped)[T.Other]               -0.5251      0.654     -0.803      0.422      -1.806       0.756
C(answer_type_grouped)[T.Place]               -0.8054      1.153     -0.699      0.485      -3.065       1.454
q_length                                      -0.0196      0.729     -0.027      0.979      -1.448       1.409
==============================================================================================================

                  Model 6.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
                    Could not fit Model 6.6: Singular matrix

--- Analyzing deepseek-chat (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_neutral/deepseek-chat_SimpleMC_redacted_temp0.0_1751825741_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    178
1     85
Name: count, dtype: int64

Answer change%: 0.3232 [0.2666697803967014, 0.37971805230291833] (n=263)
P-value vs 25%: 0.01115; P-value vs 0%: 3.781e-29
Phase 2 self-accuracy: 0.5882 [0.4836095097688353, 0.6928610784664588] (n=85)
P-value vs 25%: 2.355e-10; P-value vs 33%: 1.741e-06

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  262
Model:                          Logit   Df Residuals:                      260
Method:                           MLE   Df Model:                            1
Date:                Tue, 08 Jul 2025   Pseudo R-squ.:                0.002381
Time:                        07:27:23   Log-Likelihood:                -164.71
converged:                      False   LL-Null:                       -165.10
Covariance Type:            nonrobust   LLR p-value:                    0.3752
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept        -26.1541   4.77e+05  -5.48e-05      1.000   -9.35e+05    9.35e+05
p_i_capability    25.4263   4.77e+05   5.33e-05      1.000   -9.35e+05    9.35e+05
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                    Could not fit Model 1.5: Singular matrix

  Model 1.6: Answer Changed ~ Game Entropy
                    Could not fit Model 1.6: Singular matrix

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                    Could not fit Model 1.7: Singular matrix
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'Video games', 'History']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.564103
                        1                 0.435897
Geography               0                 0.700000
                        1                 0.300000
Misc                    0                 0.781250
                        1                 0.218750
Music                   0                 0.681818
                        1                 0.318182
Other                   0                 0.774194
                        1                 0.225806
Politics                0                 0.658537
                        1                 0.341463
Science and technology  0                 0.672727
                        1                 0.327273
Sports                  0                 0.608696
                        1                 0.391304
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.586667
                     1                 0.413333
Number               0                 0.714286
                     1                 0.285714
Other                0                 0.707692
                     1                 0.292308
Person               0                 0.716216
                     1                 0.283784
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.222222  0.777778            9
                       Number               0.800000  0.200000            5
                       Other                0.700000  0.300000           10
                       Person               0.600000  0.400000           15
Geography              Date                 0.666667  0.333333            9
                       Number               0.625000  0.375000            8
                       Other                1.000000  0.000000            3
Misc                   Date                 0.714286  0.285714            7
                       Number               1.000000  0.000000            3
                       Other                0.785714  0.214286           14
                       Person               0.750000  0.250000            8
Music                  Date                 0.600000  0.400000            5
                       Number               0.666667  0.333333            3
                       Other                0.714286  0.285714            7
                       Person               0.714286  0.285714            7
Other                  Date                 0.875000  0.125000            8
                       Number               0.833333  0.166667            6
                       Other                0.750000  0.250000            8
                       Person               0.666667  0.333333            9
Politics               Date                 0.647059  0.352941           17
                       Number               0.600000  0.400000            5
                       Other                0.600000  0.400000           10
                       Person               0.777778  0.222222            9
Science and technology Date                 0.533333  0.466667           15
                       Number               0.666667  0.333333            9
                       Other                0.625000  0.375000            8
                       Person               0.782609  0.217391           23
Sports                 Date                 0.400000  0.600000            5
                       Number               0.700000  0.300000           10
                       Other                0.600000  0.400000            5
                       Person               0.666667  0.333333            3

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  263
Model:                          Logit   Df Residuals:                      251
Method:                           MLE   Df Model:                           11
Date:                Tue, 08 Jul 2025   Pseudo R-squ.:                 0.03254
Time:                        07:27:23   Log-Likelihood:                -160.11
converged:                       True   LL-Null:                       -165.49
Covariance Type:            nonrobust   LLR p-value:                    0.4626
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      1.6258      1.733      0.938      0.348      -1.771       5.022
C(topic_grouped)[T.Geography]                 -0.7792      0.612     -1.274      0.203      -1.978       0.420
C(topic_grouped)[T.Misc]                      -1.0316      0.544     -1.898      0.058      -2.097       0.034
C(topic_grouped)[T.Music]                     -0.5462      0.566     -0.964      0.335      -1.657       0.564
C(topic_grouped)[T.Other]                     -1.0118      0.543     -1.862      0.063      -2.077       0.053
C(topic_grouped)[T.Politics]                  -0.4651      0.477     -0.976      0.329      -1.399       0.469
C(topic_grouped)[T.Science and technology]    -0.4884      0.438     -1.114      0.265      -1.347       0.371
C(topic_grouped)[T.Sports]                    -0.1703      0.555     -0.307      0.759      -1.258       0.917
C(answer_type_grouped)[T.Number]              -0.5996      0.409     -1.468      0.142      -1.400       0.201
C(answer_type_grouped)[T.Other]               -0.5609      0.376     -1.494      0.135      -1.297       0.175
C(answer_type_grouped)[T.Person]              -0.6941      0.370     -1.878      0.060      -1.419       0.030
q_length                                      -0.3134      0.370     -0.847      0.397      -1.039       0.412
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.0000
                    Could not fit Model 4.6: Singular matrix

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                    Could not fit Model 4.8: Singular matrix

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                    Could not fit Model 4.95: Singular matrix
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing gemini-1.5-pro (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_neutral/gemini-1.5-pro_SimpleMC_redacted_cor_temp0.0_1751845219_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    217
1     23
Name: count, dtype: int64

Answer change%: 0.0958 [0.05859201783934817, 0.1330746488273185] (n=240)
P-value vs 25%: 4.914e-16; P-value vs 0%: 4.569e-07
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=23)
P-value vs 25%: 0; P-value vs 33%: 0
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.968750
                        1                 0.031250
Geography               0                 0.850000
                        1                 0.150000
History                 0                 0.900000
                        1                 0.100000
Misc                    0                 0.818182
                        1                 0.181818
Music                   0                 0.944444
                        1                 0.055556
Other                   0                 0.875000
                        1                 0.125000
Politics                0                 0.951220
                        1                 0.048780
Science and technology  0                 0.860465
                        1                 0.139535
Sports                  0                 0.950000
                        1                 0.050000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.930000
                     1                 0.070000
Number               0                 0.787879
                     1                 0.212121
Other                0                 0.885246
                     1                 0.114754
Person               0                 0.956522
                     1                 0.043478
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 1.000000  0.000000           12
                       Number               0.750000  0.250000            4
                       Other                1.000000  0.000000            7
                       Person               1.000000  0.000000            9
Geography              Date                 0.750000  0.250000            8
                       Number               0.857143  0.142857            7
                       Other                1.000000  0.000000            5
History                Date                 1.000000  0.000000           11
                       Number               0.666667  0.333333            3
                       Other                0.666667  0.333333            3
                       Person               1.000000  0.000000            3
Misc                   Date                 1.000000  0.000000            5
                       Number               0.666667  0.333333            3
                       Other                0.800000  0.200000           10
                       Person               0.750000  0.250000            4
Music                  Date                 1.000000  0.000000            6
                       Other                0.750000  0.250000            4
                       Person               1.000000  0.000000            8
Other                  Date                 0.909091  0.090909           11
                       Number               1.000000  0.000000            4
                       Other                0.714286  0.285714            7
                       Person               1.000000  0.000000            2
Politics               Date                 0.913043  0.086957           23
                       Number               1.000000  0.000000            1
                       Other                1.000000  0.000000           11
                       Person               1.000000  0.000000            6
Science and technology Date                 0.882353  0.117647           17
                       Number               0.571429  0.428571            7
                       Other                0.909091  0.090909           11
                       Person               1.000000  0.000000            8
Sports                 Date                 1.000000  0.000000            7
                       Number               1.000000  0.000000            4
                       Other                1.000000  0.000000            3
                       Person               0.833333  0.166667            6

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  240
Model:                          Logit   Df Residuals:                      227
Method:                           MLE   Df Model:                           12
Date:                Tue, 08 Jul 2025   Pseudo R-squ.:                 0.08547
Time:                        07:27:23   Log-Likelihood:                -69.321
converged:                       True   LL-Null:                       -75.799
Covariance Type:            nonrobust   LLR p-value:                    0.3722
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -6.0134      2.940     -2.045      0.041     -11.777      -0.250
C(topic_grouped)[T.Geography]                  1.4078      1.219      1.154      0.248      -0.982       3.798
C(topic_grouped)[T.History]                    1.1647      1.277      0.912      0.362      -1.339       3.668
C(topic_grouped)[T.Misc]                       1.8210      1.172      1.553      0.120      -0.477       4.119
C(topic_grouped)[T.Music]                      0.8793      1.464      0.600      0.548      -1.991       3.750
C(topic_grouped)[T.Other]                      1.4263      1.203      1.186      0.236      -0.931       3.784
C(topic_grouped)[T.Politics]                   0.4177      1.278      0.327      0.744      -2.087       2.923
C(topic_grouped)[T.Science and technology]     1.4992      1.119      1.340      0.180      -0.694       3.692
C(topic_grouped)[T.Sports]                     0.4064      1.458      0.279      0.780      -2.451       3.264
C(answer_type_grouped)[T.Number]               1.1183      0.608      1.838      0.066      -0.074       2.311
C(answer_type_grouped)[T.Other]                0.4293      0.580      0.741      0.459      -0.707       1.565
C(answer_type_grouped)[T.Person]              -0.4369      0.847     -0.516      0.606      -2.097       1.223
q_length                                       0.5231      0.607      0.862      0.389      -0.666       1.713
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing gemini-1.5-pro (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_neutral/gemini-1.5-pro_SimpleMC_redacted_temp0.0_1751826859_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    192
1     68
Name: count, dtype: int64

Answer change%: 0.2615 [0.20811978306785434, 0.31495714000906877] (n=260)
P-value vs 25%: 0.672; P-value vs 0%: 8.31e-22
Phase 2 self-accuracy: 0.5441 [0.4257408920044083, 0.6624944021132387] (n=68)
P-value vs 25%: 1.118e-06; P-value vs 33%: 0.0004732
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'Video games', 'History']
                  Grouped rare answer_type into 'Misc'/'Other': None
topic_grouped           answer_changed
Art                     0                 0.790698
                        1                 0.209302
Geography               0                 0.708333
                        1                 0.291667
Misc                    0                 0.750000
                        1                 0.250000
Music                   0                 0.636364
                        1                 0.363636
Other                   0                 0.678571
                        1                 0.321429
Politics                0                 0.750000
                        1                 0.250000
Science and technology  0                 0.709091
                        1                 0.290909
Sports                  0                 0.900000
                        1                 0.100000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.782609
                     1                 0.217391
Number               0                 0.800000
                     1                 0.200000
Other                0                 0.722222
                     1                 0.277778
Person               0                 0.716216
                     1                 0.283784
Place                0                 0.555556
                     1                 0.444444
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.888889  0.111111            9
                       Number               0.800000  0.200000            5
                       Other                0.900000  0.100000           10
                       Person               0.722222  0.277778           18
                       Place                0.000000  1.000000            1
Geography              Date                 0.714286  0.285714            7
                       Number               0.727273  0.272727           11
                       Other                1.000000  0.000000            1
                       Place                0.600000  0.400000            5
Misc                   Date                 0.714286  0.285714            7
                       Number               1.000000  0.000000            3
                       Other                0.769231  0.230769           13
                       Person               0.625000  0.375000            8
                       Place                1.000000  0.000000            1
Music                  Date                 0.833333  0.166667            6
                       Number               0.750000  0.250000            4
                       Other                0.285714  0.714286            7
                       Person               1.000000  0.000000            4
                       Place                0.000000  1.000000            1
Other                  Date                 0.857143  0.142857            7
                       Number               1.000000  0.000000            3
                       Other                0.500000  0.500000            4
                       Person               0.636364  0.363636           11
                       Place                0.333333  0.666667            3
Politics               Date                 0.846154  0.153846           13
                       Number               1.000000  0.000000            5
                       Other                0.714286  0.285714            7
                       Person               0.555556  0.444444            9
                       Place                0.500000  0.500000            2
Science and technology Date                 0.666667  0.333333           18
                       Number               0.714286  0.285714            7
                       Other                0.600000  0.400000            5
                       Person               0.772727  0.227273           22
                       Place                0.666667  0.333333            3
Sports                 Date                 1.000000  0.000000            2
                       Number               0.714286  0.285714            7
                       Other                1.000000  0.000000            7
                       Person               1.000000  0.000000            2
                       Place                1.000000  0.000000            2

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  260
Model:                          Logit   Df Residuals:                      247
Method:                           MLE   Df Model:                           12
Date:                Tue, 08 Jul 2025   Pseudo R-squ.:                 0.03908
Time:                        07:27:23   Log-Likelihood:                -143.57
converged:                       True   LL-Null:                       -149.41
Covariance Type:            nonrobust   LLR p-value:                    0.4718
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -0.0832      1.826     -0.046      0.964      -3.662       3.496
C(topic_grouped)[T.Geography]                  0.4775      0.638      0.749      0.454      -0.772       1.727
C(topic_grouped)[T.Misc]                       0.2116      0.563      0.376      0.707      -0.893       1.316
C(topic_grouped)[T.Music]                      0.7647      0.593      1.289      0.197      -0.398       1.927
C(topic_grouped)[T.Other]                      0.5464      0.560      0.975      0.329      -0.552       1.644
C(topic_grouped)[T.Politics]                   0.3281      0.549      0.597      0.550      -0.748       1.404
C(topic_grouped)[T.Science and technology]     0.5049      0.488      1.035      0.301      -0.451       1.461
C(topic_grouped)[T.Sports]                    -0.9096      0.854     -1.066      0.287      -2.583       0.763
C(answer_type_grouped)[T.Number]              -0.0117      0.490     -0.024      0.981      -0.972       0.949
C(answer_type_grouped)[T.Other]                0.4269      0.445      0.959      0.338      -0.446       1.299
C(answer_type_grouped)[T.Person]               0.3425      0.407      0.841      0.400      -0.455       1.140
C(answer_type_grouped)[T.Place]                1.1122      0.578      1.924      0.054      -0.021       2.245
q_length                                      -0.3436      0.388     -0.887      0.375      -1.103       0.416
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing gemini-2.0-flash-001 (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_neutral/gemini-2.0-flash-001_SimpleMC_redacted_cor_temp0.0_1751937952_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    159
1     61
Name: count, dtype: int64

Answer change%: 0.2773 [0.21811962181237052, 0.336425832733084] (n=220)
P-value vs 25%: 0.3662; P-value vs 0%: 4.036e-20
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=61)
P-value vs 25%: 0; P-value vs 33%: 0

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  220
Model:                          Logit   Df Residuals:                      218
Method:                           MLE   Df Model:                            1
Date:                Tue, 08 Jul 2025   Pseudo R-squ.:                 0.07487
Time:                        07:27:23   Log-Likelihood:                -120.15
converged:                       True   LL-Null:                       -129.88
Covariance Type:            nonrobust   LLR p-value:                 1.034e-05
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept         -1.8897      0.298     -6.351      0.000      -2.473      -1.307
p_i_capability     1.6005      0.386      4.146      0.000       0.844       2.357
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  220
Model:                          Logit   Df Residuals:                      218
Method:                           MLE   Df Model:                            1
Date:                Tue, 08 Jul 2025   Pseudo R-squ.:                  0.1427
Time:                        07:27:23   Log-Likelihood:                -111.34
converged:                       True   LL-Null:                       -129.88
Covariance Type:            nonrobust   LLR p-value:                 1.134e-09
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.7088      0.220     -7.779      0.000      -2.139      -1.278
capabilities_entropy     2.3812      0.426      5.591      0.000       1.546       3.216
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.6731 [0.5456, 0.8006] (n=52)
                  P-value vs 33.3%: 1.763e-07

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=1.57, p=0.122
Wilcoxon delta_p: statistic=718.00, p=0.00854
Mean p = 0.0322  [-0.0081, 0.0725]
Idea 1 N = 67; 

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.869
Model:                            OLS   Adj. R-squared:                  0.865
Method:                 Least Squares   F-statistic:                     253.8
Date:                Tue, 08 Jul 2025   Prob (F-statistic):           1.54e-50
Time:                        07:27:23   Log-Likelihood:                 67.933
No. Observations:                 119   AIC:                            -127.9
Df Residuals:                     115   BIC:                            -116.7
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.5792      0.118     -4.926      0.000      -0.812      -0.346
p1                    0.6664      0.127      5.255      0.000       0.415       0.918
answer_changed        0.2331      0.149      1.568      0.120      -0.061       0.528
p1:answer_changed     0.5588      0.166      3.357      0.001       0.229       0.889
==============================================================================
Omnibus:                        6.183   Durbin-Watson:                   2.175
Prob(Omnibus):                  0.045   Jarque-Bera (JB):                5.856
Skew:                           0.536   Prob(JB):                       0.0535
Kurtosis:                       3.177   Cond. No.                         30.7
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-2.95, p=0.00433
Wilcoxon delta_H: statistic=706.00, p=0.00432
Mean H = -0.2049  [-0.3409, -0.0689]
Paired t-test delta_H Changed: statistic=2.88, p=0.00582
Wilcoxon delta_H Changed: statistic=399.00, p=0.00827
Mean H Changed = 0.2223  [0.0710, 0.3737]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=-4.08, p=8.07e-05
Wilcoxon (p_top2_game vs p_top2_base): statistic=1558.00, p=5.75e-08
Mean p_top2 = -0.0280  [-0.0415, -0.0146] (n=120)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=-0.36, p=0.719
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=3433.00, p=0.606
Mean H_unchosen_baseline_set = -0.0198  [-0.1275, 0.0879] (n=120)

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=2204.00, p=0.000188
Paired t-test (game_entropy vs capabilities_entropy): statistic=3.89, p=0.000166
Mean capabilities_entropy-game_entropy = -0.1879  [-0.2826, -0.0932] (n=120)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  120
Model:                          Logit   Df Residuals:                      117
Method:                           MLE   Df Model:                            2
Date:                Tue, 08 Jul 2025   Pseudo R-squ.:                 0.06121
Time:                        07:27:23   Log-Likelihood:                -77.082
converged:                       True   LL-Null:                       -82.108
Covariance Type:            nonrobust   LLR p-value:                  0.006568
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.0756      0.278     -0.272      0.786      -0.620       0.469
p1_z            -0.8360      0.336     -2.488      0.013      -1.495      -0.177
I(p1_z ** 2)    -0.2053      0.209     -0.984      0.325      -0.614       0.204
================================================================================
AUC = 0.709

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  220
Model:                          Logit   Df Residuals:                      218
Method:                           MLE   Df Model:                            1
Date:                Tue, 08 Jul 2025   Pseudo R-squ.:                  0.1786
Time:                        07:27:23   Log-Likelihood:                -106.69
converged:                       True   LL-Null:                       -129.88
Covariance Type:            nonrobust   LLR p-value:                 9.730e-12
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.9426      0.244     -7.957      0.000      -2.421      -1.464
game_entropy     2.0672      0.331      6.255      0.000       1.419       2.715
================================================================================

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  220
Model:                          Logit   Df Residuals:                      217
Method:                           MLE   Df Model:                            2
Date:                Tue, 08 Jul 2025   Pseudo R-squ.:                  0.2180
Time:                        07:27:23   Log-Likelihood:                -101.57
converged:                       True   LL-Null:                       -129.88
Covariance Type:            nonrobust   LLR p-value:                 5.083e-13
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.1834      0.269     -8.121      0.000      -2.710      -1.656
capabilities_entropy     1.5027      0.482      3.120      0.002       0.559       2.447
game_entropy             1.5852      0.365      4.341      0.000       0.869       2.301
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': None
topic_grouped           answer_changed
Art                     0                 0.851852
                        1                 0.148148
Geography               0                 0.571429
                        1                 0.428571
Misc                    0                 0.666667
                        1                 0.333333
Music                   0                 0.777778
                        1                 0.222222
Other                   0                 0.863636
                        1                 0.136364
Politics                0                 0.702703
                        1                 0.297297
Science and technology  0                 0.680851
                        1                 0.319149
Sports                  0                 0.733333
                        1                 0.266667
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.641026
                     1                 0.358974
Number               0                 0.642857
                     1                 0.357143
Other                0                 0.804878
                     1                 0.195122
Person               0                 0.842105
                     1                 0.157895
Place                0                 0.625000
                     1                 0.375000
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 1.000000  0.000000            3
                       Number               0.666667  0.333333            3
                       Other                0.750000  0.250000            4
                       Person               1.000000  0.000000           14
                       Place                0.333333  0.666667            3
Geography              Date                 0.333333  0.666667            6
                       Number               0.714286  0.285714            7
                       Other                1.000000  0.000000            2
                       Place                0.500000  0.500000            6
Misc                   Date                 0.636364  0.363636           11
                       Number               0.500000  0.500000            4
                       Other                0.750000  0.250000           12
                       Person               0.600000  0.400000            5
                       Place                1.000000  0.000000            1
Music                  Date                 0.714286  0.285714            7
                       Other                0.000000  1.000000            2
                       Person               1.000000  0.000000            8
                       Place                1.000000  0.000000            1
Other                  Date                 0.777778  0.222222            9
                       Number               1.000000  0.000000            2
                       Other                0.750000  0.250000            4
                       Person               1.000000  0.000000            6
                       Place                1.000000  0.000000            1
Politics               Date                 0.684211  0.315789           19
                       Number               1.000000  0.000000            2
                       Other                0.857143  0.142857            7
                       Person               0.500000  0.500000            6
                       Place                0.666667  0.333333            3
Science and technology Date                 0.550000  0.450000           20
                       Number               0.666667  0.333333            6
                       Other                1.000000  0.000000            7
                       Person               0.692308  0.307692           13
                       Place                1.000000  0.000000            1
Sports                 Date                 0.666667  0.333333            3
                       Number               0.250000  0.750000            4
                       Other                1.000000  0.000000            3
                       Person               1.000000  0.000000            5

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  220
Model:                          Logit   Df Residuals:                      207
Method:                           MLE   Df Model:                           12
Date:                Tue, 08 Jul 2025   Pseudo R-squ.:                 0.06117
Time:                        07:27:23   Log-Likelihood:                -121.93
converged:                       True   LL-Null:                       -129.88
Covariance Type:            nonrobust   LLR p-value:                    0.1964
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -0.5849      1.995     -0.293      0.769      -4.496       3.326
C(topic_grouped)[T.Geography]                  0.9848      0.733      1.344      0.179      -0.451       2.421
C(topic_grouped)[T.Misc]                       0.9492      0.686      1.383      0.167      -0.396       2.294
C(topic_grouped)[T.Music]                      0.3918      0.807      0.486      0.627      -1.189       1.973
C(topic_grouped)[T.Other]                     -0.3023      0.846     -0.357      0.721      -1.960       1.356
C(topic_grouped)[T.Politics]                   0.6490      0.688      0.943      0.346      -0.699       1.997
C(topic_grouped)[T.Science and technology]     0.8192      0.652      1.257      0.209      -0.458       2.097
C(topic_grouped)[T.Sports]                     0.6260      0.824      0.760      0.447      -0.988       2.240
C(answer_type_grouped)[T.Number]              -0.0631      0.496     -0.127      0.899      -1.036       0.910
C(answer_type_grouped)[T.Other]               -0.8826      0.475     -1.858      0.063      -1.813       0.048
C(answer_type_grouped)[T.Person]              -0.9388      0.454     -2.070      0.038      -1.828      -0.050
C(answer_type_grouped)[T.Place]                0.0763      0.615      0.124      0.901      -1.128       1.281
q_length                                      -0.1373      0.428     -0.321      0.748      -0.977       0.702
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.2653
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  220
Model:                          Logit   Df Residuals:                      206
Method:                           MLE   Df Model:                           13
Date:                Tue, 08 Jul 2025   Pseudo R-squ.:                  0.1985
Time:                        07:27:23   Log-Likelihood:                -104.10
converged:                       True   LL-Null:                       -129.88
Covariance Type:            nonrobust   LLR p-value:                 1.613e-06
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -0.4139      2.206     -0.188      0.851      -4.737       3.910
C(topic_grouped)[T.Geography]                  1.0747      0.803      1.338      0.181      -0.499       2.649
C(topic_grouped)[T.Misc]                       0.9968      0.772      1.290      0.197      -0.517       2.511
C(topic_grouped)[T.Music]                      0.3683      0.906      0.406      0.685      -1.408       2.145
C(topic_grouped)[T.Other]                     -0.4449      0.952     -0.468      0.640      -2.310       1.420
C(topic_grouped)[T.Politics]                   1.1545      0.773      1.494      0.135      -0.360       2.670
C(topic_grouped)[T.Science and technology]     0.9453      0.739      1.280      0.201      -0.502       2.393
C(topic_grouped)[T.Sports]                     0.5146      0.931      0.553      0.580      -1.310       2.339
C(answer_type_grouped)[T.Number]              -0.3785      0.576     -0.657      0.511      -1.508       0.751
C(answer_type_grouped)[T.Other]               -0.8011      0.530     -1.511      0.131      -1.840       0.238
C(answer_type_grouped)[T.Person]              -0.7413      0.487     -1.522      0.128      -1.696       0.213
C(answer_type_grouped)[T.Place]                0.4097      0.656      0.624      0.533      -0.877       1.696
q_length                                      -0.3875      0.476     -0.815      0.415      -1.320       0.545
capabilities_entropy                           2.5410      0.473      5.367      0.000       1.613       3.469
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  220
Model:                          Logit   Df Residuals:                      206
Method:                           MLE   Df Model:                           13
Date:                Tue, 08 Jul 2025   Pseudo R-squ.:                  0.2174
Time:                        07:27:23   Log-Likelihood:                -101.65
converged:                       True   LL-Null:                       -129.88
Covariance Type:            nonrobust   LLR p-value:                 2.237e-07
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.4733      2.277     -0.647      0.518      -5.937       2.990
C(topic_grouped)[T.Geography]                  1.0403      0.811      1.282      0.200      -0.550       2.631
C(topic_grouped)[T.Misc]                       0.7301      0.753      0.969      0.332      -0.746       2.206
C(topic_grouped)[T.Music]                      0.3774      0.888      0.425      0.671      -1.364       2.118
C(topic_grouped)[T.Other]                     -0.8373      0.925     -0.905      0.365      -2.650       0.975
C(topic_grouped)[T.Politics]                   0.3670      0.763      0.481      0.631      -1.129       1.863
C(topic_grouped)[T.Science and technology]     0.3670      0.725      0.506      0.613      -1.054       1.788
C(topic_grouped)[T.Sports]                     0.5720      0.904      0.632      0.527      -1.201       2.345
C(answer_type_grouped)[T.Number]               0.0412      0.593      0.069      0.945      -1.121       1.203
C(answer_type_grouped)[T.Other]               -0.0033      0.547     -0.006      0.995      -1.076       1.069
C(answer_type_grouped)[T.Person]              -0.1252      0.517     -0.242      0.809      -1.139       0.888
C(answer_type_grouped)[T.Place]                0.8699      0.701      1.241      0.215      -0.504       2.244
q_length                                      -0.2127      0.488     -0.436      0.663      -1.169       0.744
game_entropy                                   2.2115      0.386      5.732      0.000       1.455       2.968
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  220
Model:                          Logit   Df Residuals:                      205
Method:                           MLE   Df Model:                           14
Date:                Tue, 08 Jul 2025   Pseudo R-squ.:                  0.2582
Time:                        07:27:23   Log-Likelihood:                -96.347
converged:                       True   LL-Null:                       -129.88
Covariance Type:            nonrobust   LLR p-value:                 6.535e-09
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -0.9102      2.347     -0.388      0.698      -5.509       3.689
C(topic_grouped)[T.Geography]                  1.0651      0.830      1.284      0.199      -0.561       2.691
C(topic_grouped)[T.Misc]                       0.7580      0.785      0.966      0.334      -0.780       2.296
C(topic_grouped)[T.Music]                      0.3372      0.931      0.362      0.717      -1.488       2.162
C(topic_grouped)[T.Other]                     -0.7459      0.947     -0.788      0.431      -2.602       1.110
C(topic_grouped)[T.Politics]                   0.7447      0.800      0.931      0.352      -0.823       2.312
C(topic_grouped)[T.Science and technology]     0.5109      0.765      0.668      0.504      -0.988       2.010
C(topic_grouped)[T.Sports]                     0.4952      0.938      0.528      0.597      -1.343       2.333
C(answer_type_grouped)[T.Number]              -0.1754      0.626     -0.280      0.779      -1.403       1.052
C(answer_type_grouped)[T.Other]               -0.1799      0.570     -0.316      0.752      -1.297       0.937
C(answer_type_grouped)[T.Person]              -0.2407      0.524     -0.459      0.646      -1.267       0.786
C(answer_type_grouped)[T.Place]                0.8522      0.702      1.214      0.225      -0.523       2.228
q_length                                      -0.3951      0.508     -0.778      0.437      -1.391       0.601
capabilities_entropy                           1.6730      0.530      3.158      0.002       0.635       2.711
game_entropy                                   1.6222      0.425      3.816      0.000       0.789       2.455
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing gemini-2.0-flash-001 (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_neutral/gemini-2.0-flash-001_SimpleMC_redacted_temp0.0_1751938051_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    185
1     95
Name: count, dtype: int64

Answer change%: 0.3393 [0.28382841566437644, 0.39474301290705216] (n=280)
P-value vs 25%: 0.001602; P-value vs 0%: 3.962e-33
Phase 2 self-accuracy: 0.5368 [0.43657139081623525, 0.6371128197100806] (n=95)
P-value vs 25%: 2.061e-08; P-value vs 33%: 6.764e-05

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  280
Model:                          Logit   Df Residuals:                      278
Method:                           MLE   Df Model:                            1
Date:                Tue, 08 Jul 2025   Pseudo R-squ.:                0.009946
Time:                        07:27:23   Log-Likelihood:                -177.57
converged:                       True   LL-Null:                       -179.36
Covariance Type:            nonrobust   LLR p-value:                   0.05891
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept         -1.0600      0.252     -4.207      0.000      -1.554      -0.566
p_i_capability     0.6030      0.325      1.858      0.063      -0.033       1.239
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  280
Model:                          Logit   Df Residuals:                      278
Method:                           MLE   Df Model:                            1
Date:                Tue, 08 Jul 2025   Pseudo R-squ.:                 0.07086
Time:                        07:27:23   Log-Likelihood:                -166.65
converged:                       True   LL-Null:                       -179.36
Covariance Type:            nonrobust   LLR p-value:                 4.616e-07
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.2039      0.175     -6.865      0.000      -1.548      -0.860
capabilities_entropy     1.3641      0.279      4.883      0.000       0.817       1.912
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.7531 [0.6592, 0.8470] (n=81)
                  P-value vs 33.3%: 1.939e-18

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=1.80, p=0.0741
Wilcoxon delta_p: statistic=2873.00, p=0.0869
Mean p = 0.0360  [-0.0032, 0.0752]
Idea 1 N = 118; 

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.833
Model:                            OLS   Adj. R-squared:                  0.831
Method:                 Least Squares   F-statistic:                     321.3
Date:                Tue, 08 Jul 2025   Prob (F-statistic):           8.99e-75
Time:                        07:27:23   Log-Likelihood:                 81.694
No. Observations:                 197   AIC:                            -155.4
Df Residuals:                     193   BIC:                            -142.3
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.7802      0.091     -8.566      0.000      -0.960      -0.601
p1                    0.9095      0.100      9.084      0.000       0.712       1.107
answer_changed        0.6177      0.122      5.074      0.000       0.378       0.858
p1:answer_changed     0.1310      0.139      0.942      0.348      -0.143       0.405
==============================================================================
Omnibus:                       24.170   Durbin-Watson:                   2.120
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               33.797
Skew:                           0.744   Prob(JB):                     4.58e-08
Kurtosis:                       4.381   Cond. No.                         26.8
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-2.04, p=0.0433
Wilcoxon delta_H: statistic=2707.00, p=0.0309
Mean H = -0.1163  [-0.2279, -0.0047]
Paired t-test delta_H Changed: statistic=4.79, p=7.53e-06
Wilcoxon delta_H Changed: statistic=758.00, p=2.15e-05
Mean H Changed = 0.3014  [0.1781, 0.4247]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=-1.84, p=0.0672
Wilcoxon (p_top2_game vs p_top2_base): statistic=7672.00, p=0.0051
Mean p_top2 = -0.0097  [-0.0200, 0.0006] (n=199)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=1.20, p=0.231
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=9102.00, p=0.297
Mean H_unchosen_baseline_set = 0.0537  [-0.0339, 0.1414] (n=199)

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=8175.00, p=0.0291
Paired t-test (game_entropy vs capabilities_entropy): statistic=2.29, p=0.0229
Mean capabilities_entropy-game_entropy = -0.0993  [-0.1841, -0.0144] (n=199)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  199
Model:                          Logit   Df Residuals:                      196
Method:                           MLE   Df Model:                            2
Date:                Tue, 08 Jul 2025   Pseudo R-squ.:                 0.04894
Time:                        07:27:23   Log-Likelihood:                -127.90
converged:                       True   LL-Null:                       -134.48
Covariance Type:            nonrobust   LLR p-value:                  0.001387
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.3274      0.225     -1.457      0.145      -0.768       0.113
p1_z            -0.5999      0.248     -2.419      0.016      -1.086      -0.114
I(p1_z ** 2)    -0.0645      0.176     -0.367      0.714      -0.409       0.280
================================================================================
AUC = 0.672

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  280
Model:                          Logit   Df Residuals:                      278
Method:                           MLE   Df Model:                            1
Date:                Tue, 08 Jul 2025   Pseudo R-squ.:                 0.09721
Time:                        07:27:23   Log-Likelihood:                -161.92
converged:                       True   LL-Null:                       -179.36
Covariance Type:            nonrobust   LLR p-value:                 3.525e-09
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.4943      0.206     -7.239      0.000      -1.899      -1.090
game_entropy     1.5676      0.280      5.599      0.000       1.019       2.116
================================================================================

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  280
Model:                          Logit   Df Residuals:                      277
Method:                           MLE   Df Model:                            2
Date:                Tue, 08 Jul 2025   Pseudo R-squ.:                  0.1310
Time:                        07:27:23   Log-Likelihood:                -155.87
converged:                       True   LL-Null:                       -179.36
Covariance Type:            nonrobust   LLR p-value:                 6.296e-11
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.7703      0.231     -7.651      0.000      -2.224      -1.317
capabilities_entropy     1.0245      0.298      3.442      0.001       0.441       1.608
game_entropy             1.3293      0.294      4.519      0.000       0.753       1.906
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.625000
                        1                 0.375000
Geography               0                 0.521739
                        1                 0.478261
Misc                    0                 0.560976
                        1                 0.439024
Music                   0                 0.636364
                        1                 0.363636
Other                   0                 0.733333
                        1                 0.266667
Politics                0                 0.700000
                        1                 0.300000
Science and technology  0                 0.764706
                        1                 0.235294
Sports                  0                 0.680000
                        1                 0.320000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.571429
                     1                 0.428571
Number               0                 0.500000
                     1                 0.500000
Other                0                 0.684211
                     1                 0.315789
Person               0                 0.888889
                     1                 0.111111
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.555556  0.444444           18
                       Number               0.500000  0.500000            6
                       Other                0.545455  0.454545           11
                       Person               0.846154  0.153846           13
Geography              Date                 0.666667  0.333333            9
                       Number               0.454545  0.545455           11
                       Other                0.333333  0.666667            3
Misc                   Date                 0.416667  0.583333           12
                       Number               0.400000  0.600000            5
                       Other                0.500000  0.500000           14
                       Person               0.900000  0.100000           10
Music                  Date                 0.400000  0.600000            5
                       Number               0.250000  0.750000            4
                       Other                0.888889  0.111111            9
                       Person               0.750000  0.250000            4
Other                  Date                 0.666667  0.333333            9
                       Number               1.000000  0.000000            5
                       Other                0.777778  0.222222            9
                       Person               0.571429  0.428571            7
Politics               Date                 0.470588  0.529412           17
                       Number               0.750000  0.250000            4
                       Other                0.800000  0.200000           10
                       Person               1.000000  0.000000            9
Science and technology Date                 0.666667  0.333333           15
                       Number               0.500000  0.500000            8
                       Other                0.727273  0.272727           11
                       Person               1.000000  0.000000           17
Sports                 Date                 0.833333  0.166667            6
                       Number               0.285714  0.714286            7
                       Other                0.777778  0.222222            9
                       Person               1.000000  0.000000            3

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  280
Model:                          Logit   Df Residuals:                      268
Method:                           MLE   Df Model:                           11
Date:                Tue, 08 Jul 2025   Pseudo R-squ.:                 0.09088
Time:                        07:27:23   Log-Likelihood:                -163.06
converged:                       True   LL-Null:                       -179.36
Covariance Type:            nonrobust   LLR p-value:                 0.0006107
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -0.2284      1.715     -0.133      0.894      -3.589       3.132
C(topic_grouped)[T.Geography]                 -0.1306      0.541     -0.241      0.809      -1.191       0.930
C(topic_grouped)[T.Misc]                       0.3169      0.461      0.687      0.492      -0.587       1.221
C(topic_grouped)[T.Music]                     -0.1135      0.564     -0.201      0.840      -1.218       0.991
C(topic_grouped)[T.Other]                     -0.5821      0.534     -1.091      0.275      -1.628       0.464
C(topic_grouped)[T.Politics]                  -0.4331      0.490     -0.884      0.377      -1.394       0.528
C(topic_grouped)[T.Science and technology]    -0.6656      0.471     -1.413      0.158      -1.589       0.258
C(topic_grouped)[T.Sports]                    -0.4873      0.555     -0.879      0.380      -1.574       0.600
C(answer_type_grouped)[T.Number]               0.3129      0.367      0.853      0.394      -0.406       1.032
C(answer_type_grouped)[T.Other]               -0.5124      0.338     -1.516      0.129      -1.175       0.150
C(answer_type_grouped)[T.Person]              -1.8001      0.467     -3.856      0.000      -2.715      -0.885
q_length                                       0.0418      0.373      0.112      0.911      -0.689       0.773
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.3615
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  280
Model:                          Logit   Df Residuals:                      267
Method:                           MLE   Df Model:                           12
Date:                Tue, 08 Jul 2025   Pseudo R-squ.:                  0.1446
Time:                        07:27:23   Log-Likelihood:                -153.42
converged:                       True   LL-Null:                       -179.36
Covariance Type:            nonrobust   LLR p-value:                 6.527e-07
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      0.1876      1.775      0.106      0.916      -3.291       3.666
C(topic_grouped)[T.Geography]                 -0.1234      0.563     -0.219      0.827      -1.227       0.980
C(topic_grouped)[T.Misc]                       0.1375      0.487      0.283      0.778      -0.816       1.091
C(topic_grouped)[T.Music]                     -0.3413      0.588     -0.580      0.562      -1.494       0.812
C(topic_grouped)[T.Other]                     -0.6243      0.552     -1.131      0.258      -1.706       0.457
C(topic_grouped)[T.Politics]                  -0.3876      0.512     -0.758      0.449      -1.390       0.615
C(topic_grouped)[T.Science and technology]    -0.7480      0.491     -1.523      0.128      -1.710       0.214
C(topic_grouped)[T.Sports]                    -0.3341      0.576     -0.580      0.562      -1.464       0.795
C(answer_type_grouped)[T.Number]               0.3071      0.383      0.802      0.423      -0.444       1.058
C(answer_type_grouped)[T.Other]               -0.4553      0.354     -1.288      0.198      -1.148       0.238
C(answer_type_grouped)[T.Person]              -1.6449      0.474     -3.467      0.001      -2.575      -0.715
q_length                                      -0.1603      0.389     -0.412      0.680      -0.923       0.602
capabilities_entropy                           1.2780      0.301      4.250      0.000       0.689       1.867
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  280
Model:                          Logit   Df Residuals:                      267
Method:                           MLE   Df Model:                           12
Date:                Tue, 08 Jul 2025   Pseudo R-squ.:                  0.1579
Time:                        07:27:23   Log-Likelihood:                -151.03
converged:                       True   LL-Null:                       -179.36
Covariance Type:            nonrobust   LLR p-value:                 9.130e-08
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -0.3138      1.783     -0.176      0.860      -3.807       3.180
C(topic_grouped)[T.Geography]                 -0.1198      0.568     -0.211      0.833      -1.232       0.993
C(topic_grouped)[T.Misc]                       0.1841      0.487      0.378      0.706      -0.771       1.139
C(topic_grouped)[T.Music]                     -0.2158      0.583     -0.370      0.711      -1.359       0.927
C(topic_grouped)[T.Other]                     -0.6529      0.549     -1.190      0.234      -1.728       0.423
C(topic_grouped)[T.Politics]                  -0.5773      0.514     -1.123      0.261      -1.585       0.430
C(topic_grouped)[T.Science and technology]    -0.9726      0.503     -1.932      0.053      -1.959       0.014
C(topic_grouped)[T.Sports]                    -0.6727      0.587     -1.146      0.252      -1.823       0.478
C(answer_type_grouped)[T.Number]               0.3605      0.389      0.928      0.354      -0.401       1.122
C(answer_type_grouped)[T.Other]               -0.0963      0.367     -0.262      0.793      -0.815       0.623
C(answer_type_grouped)[T.Person]              -1.2843      0.489     -2.626      0.009      -2.243      -0.326
q_length                                      -0.1314      0.390     -0.337      0.736      -0.896       0.633
game_entropy                                   1.4666      0.315      4.660      0.000       0.850       2.083
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  280
Model:                          Logit   Df Residuals:                      266
Method:                           MLE   Df Model:                           13
Date:                Tue, 08 Jul 2025   Pseudo R-squ.:                  0.1871
Time:                        07:27:23   Log-Likelihood:                -145.80
converged:                       True   LL-Null:                       -179.36
Covariance Type:            nonrobust   LLR p-value:                 2.721e-09
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      0.1480      1.819      0.081      0.935      -3.418       3.714
C(topic_grouped)[T.Geography]                 -0.1269      0.580     -0.219      0.827      -1.264       1.010
C(topic_grouped)[T.Misc]                       0.0479      0.508      0.094      0.925      -0.949       1.044
C(topic_grouped)[T.Music]                     -0.4011      0.595     -0.674      0.500      -1.568       0.766
C(topic_grouped)[T.Other]                     -0.6913      0.563     -1.229      0.219      -1.794       0.411
C(topic_grouped)[T.Politics]                  -0.5029      0.527     -0.954      0.340      -1.536       0.530
C(topic_grouped)[T.Science and technology]    -1.0152      0.515     -1.969      0.049      -2.026      -0.005
C(topic_grouped)[T.Sports]                    -0.5304      0.602     -0.882      0.378      -1.710       0.649
C(answer_type_grouped)[T.Number]               0.3385      0.395      0.857      0.391      -0.435       1.112
C(answer_type_grouped)[T.Other]               -0.1177      0.378     -0.312      0.755      -0.858       0.623
C(answer_type_grouped)[T.Person]              -1.2694      0.494     -2.572      0.010      -2.237      -0.302
q_length                                      -0.2883      0.401     -0.718      0.473      -1.075       0.499
capabilities_entropy                           1.0153      0.318      3.191      0.001       0.392       1.639
game_entropy                                   1.2433      0.329      3.778      0.000       0.598       1.888
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing gemini-2.5-flash-preview-04-17 (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_neutral/gemini-2.5-flash-preview-04-17_SimpleMC_redacted_cor_temp0.0_1751845050_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    288
1     47
Name: count, dtype: int64

Answer change%: 0.1403 [0.10310851817082055, 0.17748849675455258] (n=335)
P-value vs 25%: 7.407e-09; P-value vs 0%: 1.426e-13
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=47)
P-value vs 25%: 0; P-value vs 33%: 0

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  335
Model:                          Logit   Df Residuals:                      333
Method:                           MLE   Df Model:                            1
Date:                Tue, 08 Jul 2025   Pseudo R-squ.:                 0.02297
Time:                        07:27:23   Log-Likelihood:                -132.72
converged:                       True   LL-Null:                       -135.84
Covariance Type:            nonrobust   LLR p-value:                   0.01248
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.9690      0.173    -11.351      0.000      -2.309      -1.629
game_entropy   406.5528    170.056      2.391      0.017      73.249     739.856
================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['Music', 'History', 'TV shows', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': None
topic_grouped           answer_changed
Art                     0                 0.859649
                        1                 0.140351
Geography               0                 0.903226
                        1                 0.096774
Misc                    0                 0.868852
                        1                 0.131148
Other                   0                 0.837838
                        1                 0.162162
Politics                0                 0.928571
                        1                 0.071429
Science and technology  0                 0.815385
                        1                 0.184615
Sports                  0                 0.785714
                        1                 0.214286
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.904348
                     1                 0.095652
Number               0                 0.790698
                     1                 0.209302
Other                0                 0.838235
                     1                 0.161765
Person               0                 0.837209
                     1                 0.162791
Place                0                 0.913043
                     1                 0.086957
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.941176  0.058824           17
                       Number               0.571429  0.428571            7
                       Other                0.777778  0.222222            9
                       Person               0.894737  0.105263           19
                       Place                1.000000  0.000000            5
Geography              Date                 1.000000  0.000000           10
                       Number               0.818182  0.181818           11
                       Other                1.000000  0.000000            3
                       Place                0.857143  0.142857            7
Misc                   Date                 0.894737  0.105263           19
                       Number               1.000000  0.000000            6
                       Other                0.750000  0.250000           16
                       Person               0.894737  0.105263           19
                       Place                1.000000  0.000000            1
Other                  Date                 0.818182  0.181818           11
                       Number               1.000000  0.000000            3
                       Other                1.000000  0.000000            8
                       Person               0.727273  0.272727           11
                       Place                0.750000  0.250000            4
Politics               Date                 0.920000  0.080000           25
                       Number               1.000000  0.000000            4
                       Other                0.909091  0.090909           11
                       Person               0.909091  0.090909           11
                       Place                1.000000  0.000000            5
Science and technology Date                 0.958333  0.041667           24
                       Number               0.571429  0.428571            7
                       Other                0.833333  0.166667           12
                       Person               0.714286  0.285714           21
                       Place                1.000000  0.000000            1
Sports                 Date                 0.666667  0.333333            9
                       Number               0.800000  0.200000            5
                       Other                0.777778  0.222222            9
                       Person               1.000000  0.000000            5

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  335
Model:                          Logit   Df Residuals:                      323
Method:                           MLE   Df Model:                           11
Date:                Tue, 08 Jul 2025   Pseudo R-squ.:                 0.03565
Time:                        07:27:23   Log-Likelihood:                -131.00
converged:                       True   LL-Null:                       -135.84
Covariance Type:            nonrobust   LLR p-value:                    0.5588
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.3973      2.065     -0.677      0.499      -5.444       2.650
C(topic_grouped)[T.Geography]                 -0.4958      0.750     -0.661      0.508      -1.966       0.974
C(topic_grouped)[T.Misc]                      -0.0868      0.544     -0.159      0.873      -1.153       0.980
C(topic_grouped)[T.Other]                      0.2015      0.592      0.340      0.734      -0.959       1.362
C(topic_grouped)[T.Politics]                  -0.6141      0.658     -0.933      0.351      -1.904       0.676
C(topic_grouped)[T.Science and technology]     0.3644      0.506      0.720      0.472      -0.628       1.356
C(topic_grouped)[T.Sports]                     0.4728      0.610      0.775      0.438      -0.723       1.669
C(answer_type_grouped)[T.Number]               0.9687      0.512      1.893      0.058      -0.034       1.972
C(answer_type_grouped)[T.Other]                0.5379      0.464      1.160      0.246      -0.371       1.447
C(answer_type_grouped)[T.Person]               0.5231      0.438      1.194      0.232      -0.336       1.382
C(answer_type_grouped)[T.Place]                0.0906      0.827      0.110      0.913      -1.531       1.712
q_length                                      -0.1889      0.454     -0.416      0.677      -1.079       0.701
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  335
Model:                          Logit   Df Residuals:                      322
Method:                           MLE   Df Model:                           12
Date:                Tue, 08 Jul 2025   Pseudo R-squ.:                 0.06304
Time:                        07:27:23   Log-Likelihood:                -127.28
converged:                       True   LL-Null:                       -135.84
Covariance Type:            nonrobust   LLR p-value:                    0.1449
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.5162      2.102     -0.721      0.471      -5.636       2.604
C(topic_grouped)[T.Geography]                 -0.4083      0.758     -0.538      0.590      -1.895       1.078
C(topic_grouped)[T.Misc]                      -0.2075      0.571     -0.363      0.716      -1.327       0.912
C(topic_grouped)[T.Other]                      0.3102      0.601      0.516      0.606      -0.868       1.488
C(topic_grouped)[T.Politics]                  -0.5510      0.666     -0.827      0.408      -1.856       0.754
C(topic_grouped)[T.Science and technology]     0.4746      0.516      0.920      0.357      -0.536       1.485
C(topic_grouped)[T.Sports]                     0.4896      0.620      0.790      0.430      -0.726       1.705
C(answer_type_grouped)[T.Number]               1.0675      0.521      2.050      0.040       0.047       2.088
C(answer_type_grouped)[T.Other]                0.4532      0.480      0.944      0.345      -0.488       1.395
C(answer_type_grouped)[T.Person]               0.6368      0.447      1.425      0.154      -0.239       1.513
C(answer_type_grouped)[T.Place]                0.1405      0.834      0.169      0.866      -1.493       1.774
q_length                                      -0.2176      0.463     -0.470      0.638      -1.125       0.690
game_entropy                                 470.2804    182.696      2.574      0.010     112.202     828.359
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing gemini-2.5-flash-preview-04-17 (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_neutral/gemini-2.5-flash-preview-04-17_SimpleMC_redacted_temp0.0_1751839721_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    86
1    79
Name: count, dtype: int64

Answer change%: 0.4788 [0.40256507041902645, 0.5550106871567311] (n=165)
P-value vs 25%: 4.03e-09; P-value vs 0%: 7.868e-35
Phase 2 self-accuracy: 0.6709 [0.5672688257264862, 0.774503326172248] (n=79)
P-value vs 25%: 1.703e-15; P-value vs 33%: 1.645e-10

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  165
Model:                          Logit   Df Residuals:                      163
Method:                           MLE   Df Model:                            1
Date:                Tue, 08 Jul 2025   Pseudo R-squ.:                0.008473
Time:                        07:27:23   Log-Likelihood:                -113.25
converged:                       True   LL-Null:                       -114.22
Covariance Type:            nonrobust   LLR p-value:                    0.1642
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.1647      0.173     -0.951      0.342      -0.504       0.175
game_entropy   186.9246    205.488      0.910      0.363    -215.824     589.673
================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['Video games', 'History']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.500000
                        1                 0.500000
Geography               1                 0.538462
                        0                 0.461538
Misc                    1                 0.600000
                        0                 0.400000
Music                   0                 0.666667
                        1                 0.333333
Other                   0                 0.666667
                        1                 0.333333
Politics                1                 0.523810
                        0                 0.476190
Science and technology  0                 0.515152
                        1                 0.484848
Sports                  1                 0.583333
                        0                 0.416667
TV shows                0                 0.600000
                        1                 0.400000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 1                 0.555556
                     0                 0.444444
Number               0                 0.514286
                     1                 0.485714
Other                0                 0.619048
                     1                 0.380952
Person               0                 0.529412
                     1                 0.470588
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.500000  0.500000            4
                       Number               0.500000  0.500000            2
                       Other                0.500000  0.500000            4
                       Person               0.500000  0.500000            8
Geography              Date                 0.200000  0.800000            5
                       Number               0.571429  0.428571            7
                       Other                1.000000  0.000000            1
Misc                   Date                 0.333333  0.666667            9
                       Number               0.333333  0.666667            3
                       Other                0.500000  0.500000            6
                       Person               0.500000  0.500000            2
Music                  Date                 0.800000  0.200000            5
                       Number               0.333333  0.666667            3
                       Other                0.714286  0.285714            7
                       Person               0.666667  0.333333            3
Other                  Date                 0.571429  0.428571            7
                       Number               0.750000  0.250000            4
                       Other                0.500000  0.500000            2
                       Person               1.000000  0.000000            2
Politics               Date                 0.272727  0.727273           11
                       Number               1.000000  0.000000            2
                       Other                1.000000  0.000000            4
                       Person               0.250000  0.750000            4
Science and technology Date                 0.545455  0.454545           11
                       Number               0.428571  0.571429            7
                       Other                0.666667  0.333333            6
                       Person               0.444444  0.555556            9
Sports                 Number               0.500000  0.500000            6
                       Other                0.333333  0.666667            3
                       Person               0.333333  0.666667            3
TV shows               Date                 0.500000  0.500000            2
                       Number               0.000000  1.000000            1
                       Other                0.555556  0.444444            9
                       Person               1.000000  0.000000            3

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  165
Model:                          Logit   Df Residuals:                      152
Method:                           MLE   Df Model:                           12
Date:                Tue, 08 Jul 2025   Pseudo R-squ.:                 0.04248
Time:                        07:27:23   Log-Likelihood:                -109.37
converged:                       True   LL-Null:                       -114.22
Covariance Type:            nonrobust   LLR p-value:                    0.6420
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      2.8798      2.065      1.394      0.163      -1.168       6.928
C(topic_grouped)[T.Geography]                 -0.0352      0.779     -0.045      0.964      -1.562       1.492
C(topic_grouped)[T.Misc]                       0.3934      0.681      0.578      0.563      -0.941       1.728
C(topic_grouped)[T.Music]                     -0.7946      0.712     -1.117      0.264      -2.189       0.600
C(topic_grouped)[T.Other]                     -0.9402      0.752     -1.250      0.211      -2.414       0.534
C(topic_grouped)[T.Politics]                  -0.0142      0.664     -0.021      0.983      -1.315       1.286
C(topic_grouped)[T.Science and technology]    -0.1266      0.599     -0.211      0.833      -1.300       1.047
C(topic_grouped)[T.Sports]                     0.4156      0.780      0.533      0.594      -1.113       1.944
C(topic_grouped)[T.TV shows]                  -0.3439      0.734     -0.468      0.639      -1.783       1.095
C(answer_type_grouped)[T.Number]              -0.4011      0.471     -0.853      0.394      -1.323       0.521
C(answer_type_grouped)[T.Other]               -0.8191      0.457     -1.791      0.073      -1.716       0.077
C(answer_type_grouped)[T.Person]              -0.4716      0.474     -0.996      0.319      -1.400       0.457
q_length                                      -0.5354      0.425     -1.259      0.208      -1.369       0.298
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  165
Model:                          Logit   Df Residuals:                      151
Method:                           MLE   Df Model:                           13
Date:                Tue, 08 Jul 2025   Pseudo R-squ.:                 0.05676
Time:                        07:27:23   Log-Likelihood:                -107.74
converged:                       True   LL-Null:                       -114.22
Covariance Type:            nonrobust   LLR p-value:                    0.4505
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      2.8907      2.080      1.390      0.165      -1.186       6.967
C(topic_grouped)[T.Geography]                 -0.0462      0.780     -0.059      0.953      -1.576       1.483
C(topic_grouped)[T.Misc]                       0.3493      0.684      0.511      0.609      -0.990       1.689
C(topic_grouped)[T.Music]                     -0.7847      0.713     -1.101      0.271      -2.182       0.612
C(topic_grouped)[T.Other]                     -1.0518      0.762     -1.381      0.167      -2.545       0.441
C(topic_grouped)[T.Politics]                  -0.0345      0.666     -0.052      0.959      -1.339       1.270
C(topic_grouped)[T.Science and technology]    -0.1261      0.600     -0.210      0.833      -1.302       1.050
C(topic_grouped)[T.Sports]                     0.4134      0.781      0.529      0.597      -1.117       1.944
C(topic_grouped)[T.TV shows]                  -0.6098      0.771     -0.791      0.429      -2.121       0.901
C(answer_type_grouped)[T.Number]              -0.3891      0.473     -0.822      0.411      -1.317       0.539
C(answer_type_grouped)[T.Other]               -0.8896      0.462     -1.924      0.054      -1.796       0.017
C(answer_type_grouped)[T.Person]              -0.4626      0.476     -0.971      0.331      -1.396       0.471
q_length                                      -0.5525      0.430     -1.286      0.199      -1.395       0.290
game_entropy                                 286.6064    243.881      1.175      0.240    -191.392     764.604
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing gpt-4.1-2025-04-14 (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_neutral/gpt-4.1-2025-04-14_SimpleMC_redacted_cor_temp0.0_1751833247_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    233
1     22
Name: count, dtype: int64

Answer change%: 0.0863 [0.05181356967248026, 0.12073544993536287] (n=255)
P-value vs 25%: 1.256e-20; P-value vs 0%: 9.255e-07
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=22)
P-value vs 25%: 0; P-value vs 33%: 0

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  255
Model:                          Logit   Df Residuals:                      253
Method:                           MLE   Df Model:                            1
Date:                Tue, 08 Jul 2025   Pseudo R-squ.:                 0.08077
Time:                        07:27:23   Log-Likelihood:                -68.875
converged:                       True   LL-Null:                       -74.927
Covariance Type:            nonrobust   LLR p-value:                 0.0005032
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          1.3763      1.004      1.371      0.170      -0.591       3.343
p_i_capability    -4.3106      1.197     -3.603      0.000      -6.656      -1.965
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  255
Model:                          Logit   Df Residuals:                      253
Method:                           MLE   Df Model:                            1
Date:                Tue, 08 Jul 2025   Pseudo R-squ.:                 0.08503
Time:                        07:27:23   Log-Likelihood:                -68.557
converged:                       True   LL-Null:                       -74.927
Covariance Type:            nonrobust   LLR p-value:                 0.0003576
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -3.0138      0.335     -8.984      0.000      -3.671      -2.356
capabilities_entropy     1.4668      0.403      3.637      0.000       0.676       2.257
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.8571 [0.6738, 1.0000] (n=14)
                  P-value vs 33.3%: 2.132e-08

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=-7.20, p=1.07e-09
Wilcoxon delta_p: statistic=55.00, p=1.04e-10
Mean p = -0.1399  [-0.1780, -0.1018]
Idea 1 N = 62; 

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.875
Model:                            OLS   Adj. R-squared:                  0.870
Method:                 Least Squares   F-statistic:                     168.7
Date:                Tue, 08 Jul 2025   Prob (F-statistic):           1.72e-32
Time:                        07:27:23   Log-Likelihood:                 60.139
No. Observations:                  76   AIC:                            -112.3
Df Residuals:                      72   BIC:                            -103.0
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.7081      0.068    -10.465      0.000      -0.843      -0.573
p1                    0.7037      0.082      8.591      0.000       0.540       0.867
answer_changed        0.4925      0.161      3.053      0.003       0.171       0.814
p1:answer_changed     0.2769      0.205      1.350      0.181      -0.132       0.686
==============================================================================
Omnibus:                       13.469   Durbin-Watson:                   2.117
Prob(Omnibus):                  0.001   Jarque-Bera (JB):               20.136
Skew:                           0.696   Prob(JB):                     4.24e-05
Kurtosis:                       5.103   Cond. No.                         26.7
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=3.74, p=0.000403
Wilcoxon delta_H: statistic=463.00, p=0.000318
Mean H = 0.2061  [0.0982, 0.3141]
Paired t-test delta_H Changed: statistic=3.39, p=0.00485
Wilcoxon delta_H Changed: statistic=0.00, p=0.000122
Mean H Changed = 0.4700  [0.1981, 0.7419]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=5.28, p=1.23e-06
Wilcoxon (p_top2_game vs p_top2_base): statistic=94.00, p=1.36e-12
Mean p_top2 = 0.0347  [0.0218, 0.0476] (n=76)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=4.84, p=6.67e-06
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=571.00, p=3.87e-06
Mean H_unchosen_baseline_set = 0.2547  [0.1517, 0.3578] (n=76)

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=245.00, p=2.86e-10
Paired t-test (game_entropy vs capabilities_entropy): statistic=-7.68, p=4.93e-11
Mean capabilities_entropy-game_entropy = 0.4058  [0.3022, 0.5094] (n=76)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                   76
Model:                          Logit   Df Residuals:                       73
Method:                           MLE   Df Model:                            2
Date:                Tue, 08 Jul 2025   Pseudo R-squ.:                 0.02606
Time:                        07:27:23   Log-Likelihood:                -35.361
converged:                       True   LL-Null:                       -36.307
Covariance Type:            nonrobust   LLR p-value:                    0.3883
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.1244      0.457     -2.458      0.014      -2.021      -0.228
p1_z            -0.4617      0.375     -1.230      0.219      -1.197       0.274
I(p1_z ** 2)    -0.4226      0.408     -1.035      0.301      -1.223       0.377
================================================================================
AUC = 0.586

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  255
Model:                          Logit   Df Residuals:                      253
Method:                           MLE   Df Model:                            1
Date:                Tue, 08 Jul 2025   Pseudo R-squ.:                  0.1914
Time:                        07:27:23   Log-Likelihood:                -60.590
converged:                       True   LL-Null:                       -74.927
Covariance Type:            nonrobust   LLR p-value:                 8.559e-08
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -3.1885      0.338     -9.441      0.000      -3.850      -2.527
game_entropy     3.0093      0.562      5.358      0.000       1.909       4.110
================================================================================

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  255
Model:                          Logit   Df Residuals:                      252
Method:                           MLE   Df Model:                            2
Date:                Tue, 08 Jul 2025   Pseudo R-squ.:                  0.1928
Time:                        07:27:23   Log-Likelihood:                -60.482
converged:                       True   LL-Null:                       -74.927
Covariance Type:            nonrobust   LLR p-value:                 5.325e-07
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -3.2518      0.370     -8.799      0.000      -3.976      -2.527
capabilities_entropy     0.2617      0.557      0.470      0.638      -0.830       1.353
game_entropy             2.8045      0.708      3.961      0.000       1.417       4.192
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': None
topic_grouped           answer_changed
Art                     0                 0.975610
                        1                 0.024390
Geography               0                 0.900000
                        1                 0.100000
Misc                    0                 0.891892
                        1                 0.108108
Music                   0                 1.000000
Other                   0                 0.875000
                        1                 0.125000
Politics                0                 0.925000
                        1                 0.075000
Science and technology  0                 0.906977
                        1                 0.093023
Sports                  0                 0.818182
                        1                 0.181818
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.840580
                     1                 0.159420
Number               0                 0.923077
                     1                 0.076923
Other                0                 0.950000
                     1                 0.050000
Person               0                 0.923077
                     1                 0.076923
Place                0                 1.000000
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 1.000000  0.000000            5
                       Number               0.750000  0.250000            4
                       Other                1.000000  0.000000            8
                       Person               1.000000  0.000000           19
                       Place                1.000000  0.000000            5
Geography              Date                 0.714286  0.285714            7
                       Number               1.000000  0.000000            4
                       Other                1.000000  0.000000            3
                       Place                1.000000  0.000000            6
Misc                   Date                 0.777778  0.222222            9
                       Number               1.000000  0.000000            4
                       Other                0.846154  0.153846           13
                       Person               1.000000  0.000000            9
                       Place                1.000000  0.000000            2
Music                  Date                 1.000000  0.000000            6
                       Number               1.000000  0.000000            1
                       Other                1.000000  0.000000            3
                       Person               1.000000  0.000000           10
Other                  Date                 0.625000  0.375000            8
                       Number               1.000000  0.000000            4
                       Other                0.857143  0.142857            7
                       Person               1.000000  0.000000           10
                       Place                1.000000  0.000000            3
Politics               Date                 0.875000  0.125000           16
                       Number               1.000000  0.000000            3
                       Other                1.000000  0.000000            9
                       Person               0.875000  0.125000            8
                       Place                1.000000  0.000000            4
Science and technology Date                 1.000000  0.000000           12
                       Number               1.000000  0.000000            3
                       Other                1.000000  0.000000           11
                       Person               0.764706  0.235294           17
Sports                 Date                 0.666667  0.333333            6
                       Number               0.666667  0.333333            3
                       Other                1.000000  0.000000            6
                       Person               0.800000  0.200000            5
                       Place                1.000000  0.000000            2

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  255
Model:                          Logit   Df Residuals:                      242
Method:                           MLE   Df Model:                           12
Date:                Tue, 08 Jul 2025   Pseudo R-squ.:                  0.1279
Time:                        07:27:23   Log-Likelihood:                -65.344
converged:                      False   LL-Null:                       -74.927
Covariance Type:            nonrobust   LLR p-value:                   0.08459
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.0800      3.041     -0.355      0.722      -7.040       4.880
C(topic_grouped)[T.Geography]                  1.4730      1.320      1.116      0.264      -1.114       4.060
C(topic_grouped)[T.Misc]                       1.5234      1.161      1.313      0.189      -0.751       3.798
C(topic_grouped)[T.Music]                    -24.9610   3.15e+05  -7.92e-05      1.000   -6.18e+05    6.18e+05
C(topic_grouped)[T.Other]                      1.6465      1.160      1.419      0.156      -0.628       3.921
C(topic_grouped)[T.Politics]                   1.0011      1.205      0.831      0.406      -1.361       3.363
C(topic_grouped)[T.Science and technology]     1.2210      1.153      1.059      0.290      -1.038       3.480
C(topic_grouped)[T.Sports]                     2.0897      1.178      1.774      0.076      -0.219       4.398
C(answer_type_grouped)[T.Number]              -0.9268      0.825     -1.123      0.261      -2.544       0.690
C(answer_type_grouped)[T.Other]               -1.4071      0.697     -2.018      0.044      -2.773      -0.041
C(answer_type_grouped)[T.Person]              -0.6516      0.572     -1.139      0.255      -1.773       0.469
C(answer_type_grouped)[T.Place]              -34.9698   1.85e+07  -1.89e-06      1.000   -3.62e+07    3.62e+07
q_length                                      -0.4036      0.632     -0.638      0.523      -1.643       0.836
==============================================================================================================

Possibly complete quasi-separation: A fraction 0.16 of observations can be
perfectly predicted. This might indicate that there is complete
quasi-separation. In this case some parameters will not be identified.

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.2957
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  255
Model:                          Logit   Df Residuals:                      241
Method:                           MLE   Df Model:                           13
Date:                Tue, 08 Jul 2025   Pseudo R-squ.:                  0.1881
Time:                        07:27:23   Log-Likelihood:                -60.831
converged:                      False   LL-Null:                       -74.927
Covariance Type:            nonrobust   LLR p-value:                  0.008509
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -2.6494      3.286     -0.806      0.420      -9.090       3.791
C(topic_grouped)[T.Geography]                  1.2052      1.346      0.896      0.370      -1.432       3.842
C(topic_grouped)[T.Misc]                       1.5819      1.191      1.329      0.184      -0.752       3.916
C(topic_grouped)[T.Music]                    -22.0065   7.37e+04     -0.000      1.000   -1.45e+05    1.44e+05
C(topic_grouped)[T.Other]                      1.6474      1.186      1.389      0.165      -0.677       3.972
C(topic_grouped)[T.Politics]                   1.2391      1.217      1.018      0.309      -1.146       3.624
C(topic_grouped)[T.Science and technology]     1.3134      1.176      1.117      0.264      -0.991       3.618
C(topic_grouped)[T.Sports]                     2.3315      1.206      1.934      0.053      -0.032       4.695
C(answer_type_grouped)[T.Number]              -1.1687      0.877     -1.332      0.183      -2.888       0.551
C(answer_type_grouped)[T.Other]               -1.0008      0.733     -1.366      0.172      -2.437       0.435
C(answer_type_grouped)[T.Person]              -0.2716      0.601     -0.452      0.651      -1.450       0.906
C(answer_type_grouped)[T.Place]              -23.8619   9.39e+04     -0.000      1.000   -1.84e+05    1.84e+05
q_length                                      -0.2501      0.686     -0.365      0.715      -1.595       1.095
capabilities_entropy                           1.3696      0.454      3.017      0.003       0.480       2.259
==============================================================================================================

Possibly complete quasi-separation: A fraction 0.16 of observations can be
perfectly predicted. This might indicate that there is complete
quasi-separation. In this case some parameters will not be identified.

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  255
Model:                          Logit   Df Residuals:                      241
Method:                           MLE   Df Model:                           13
Date:                Tue, 08 Jul 2025   Pseudo R-squ.:                  0.3145
Time:                        07:27:23   Log-Likelihood:                -51.364
converged:                      False   LL-Null:                       -74.927
Covariance Type:            nonrobust   LLR p-value:                 9.196e-06
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -3.1748      3.586     -0.885      0.376     -10.203       3.853
C(topic_grouped)[T.Geography]                  0.0898      1.445      0.062      0.950      -2.742       2.922
C(topic_grouped)[T.Misc]                       1.4091      1.226      1.149      0.251      -0.994       3.812
C(topic_grouped)[T.Music]                    -28.1994   7.24e+05  -3.89e-05      1.000   -1.42e+06    1.42e+06
C(topic_grouped)[T.Other]                      0.9058      1.268      0.714      0.475      -1.580       3.392
C(topic_grouped)[T.Politics]                   0.6496      1.272      0.511      0.609      -1.843       3.142
C(topic_grouped)[T.Science and technology]     1.3056      1.201      1.087      0.277      -1.049       3.660
C(topic_grouped)[T.Sports]                     2.0352      1.226      1.660      0.097      -0.368       4.438
C(answer_type_grouped)[T.Number]              -1.7495      1.045     -1.674      0.094      -3.798       0.299
C(answer_type_grouped)[T.Other]               -0.8976      0.787     -1.141      0.254      -2.440       0.645
C(answer_type_grouped)[T.Person]              -0.3207      0.669     -0.480      0.631      -1.631       0.990
C(answer_type_grouped)[T.Place]              -22.9319   3.63e+04     -0.001      0.999   -7.13e+04    7.12e+04
q_length                                      -0.1227      0.746     -0.164      0.869      -1.586       1.340
game_entropy                                   3.5923      0.739      4.864      0.000       2.145       5.040
==============================================================================================================

Possibly complete quasi-separation: A fraction 0.16 of observations can be
perfectly predicted. This might indicate that there is complete
quasi-separation. In this case some parameters will not be identified.

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  255
Model:                          Logit   Df Residuals:                      240
Method:                           MLE   Df Model:                           14
Date:                Tue, 08 Jul 2025   Pseudo R-squ.:                  0.3145
Time:                        07:27:23   Log-Likelihood:                -51.361
converged:                      False   LL-Null:                       -74.927
Covariance Type:            nonrobust   LLR p-value:                 1.828e-05
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -3.1984      3.602     -0.888      0.375     -10.258       3.861
C(topic_grouped)[T.Geography]                  0.0925      1.445      0.064      0.949      -2.739       2.924
C(topic_grouped)[T.Misc]                       1.4085      1.227      1.148      0.251      -0.997       3.814
C(topic_grouped)[T.Music]                    -29.3002   1.28e+06  -2.28e-05      1.000   -2.51e+06    2.51e+06
C(topic_grouped)[T.Other]                      0.9095      1.270      0.716      0.474      -1.580       3.399
C(topic_grouped)[T.Politics]                   0.6610      1.281      0.516      0.606      -1.850       3.172
C(topic_grouped)[T.Science and technology]     1.3103      1.204      1.089      0.276      -1.049       3.669
C(topic_grouped)[T.Sports]                     2.0459      1.236      1.656      0.098      -0.376       4.468
C(answer_type_grouped)[T.Number]              -1.7528      1.046     -1.676      0.094      -3.803       0.297
C(answer_type_grouped)[T.Other]               -0.8948      0.789     -1.134      0.257      -2.441       0.651
C(answer_type_grouped)[T.Person]              -0.3134      0.676     -0.464      0.643      -1.638       1.011
C(answer_type_grouped)[T.Place]              -23.0302   3.87e+04     -0.001      1.000   -7.58e+04    7.58e+04
q_length                                      -0.1216      0.747     -0.163      0.871      -1.585       1.342
capabilities_entropy                           0.0453      0.634      0.071      0.943      -1.198       1.289
game_entropy                                   3.5558      0.897      3.965      0.000       1.798       5.313
==============================================================================================================

Possibly complete quasi-separation: A fraction 0.16 of observations can be
perfectly predicted. This might indicate that there is complete
quasi-separation. In this case some parameters will not be identified.

                  Model 6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length (after removing deterministic categories: defaultdict(<class 'list'>, {'topic_grouped': ['Music'], 'answer_type_grouped': ['Place']}))
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  213
Model:                          Logit   Df Residuals:                      202
Method:                           MLE   Df Model:                           10
Date:                Tue, 08 Jul 2025   Pseudo R-squ.:                 0.07665
Time:                        07:27:23   Log-Likelihood:                -65.344
converged:                       True   LL-Null:                       -70.768
Covariance Type:            nonrobust   LLR p-value:                    0.3695
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.0800      3.041     -0.355      0.722      -7.040       4.880
C(topic_grouped)[T.Geography]                  1.4730      1.320      1.116      0.264      -1.114       4.060
C(topic_grouped)[T.Misc]                       1.5234      1.161      1.313      0.189      -0.751       3.798
C(topic_grouped)[T.Other]                      1.6465      1.160      1.419      0.156      -0.628       3.921
C(topic_grouped)[T.Politics]                   1.0011      1.205      0.831      0.406      -1.361       3.363
C(topic_grouped)[T.Science and technology]     1.2210      1.153      1.059      0.290      -1.038       3.480
C(topic_grouped)[T.Sports]                     2.0897      1.178      1.774      0.076      -0.219       4.398
C(answer_type_grouped)[T.Number]              -0.9268      0.825     -1.123      0.261      -2.544       0.690
C(answer_type_grouped)[T.Other]               -1.4071      0.697     -2.018      0.044      -2.773      -0.041
C(answer_type_grouped)[T.Person]              -0.6516      0.572     -1.139      0.255      -1.773       0.469
q_length                                      -0.4036      0.632     -0.638      0.523      -1.643       0.836
==============================================================================================================

                  Model 6.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  213
Model:                          Logit   Df Residuals:                      201
Method:                           MLE   Df Model:                           11
Date:                Tue, 08 Jul 2025   Pseudo R-squ.:                  0.1404
Time:                        07:27:23   Log-Likelihood:                -60.831
converged:                       True   LL-Null:                       -70.768
Covariance Type:            nonrobust   LLR p-value:                   0.04711
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -2.6494      3.286     -0.806      0.420      -9.090       3.791
C(topic_grouped)[T.Geography]                  1.2052      1.346      0.896      0.370      -1.432       3.842
C(topic_grouped)[T.Misc]                       1.5819      1.191      1.329      0.184      -0.752       3.916
C(topic_grouped)[T.Other]                      1.6474      1.186      1.389      0.165      -0.677       3.972
C(topic_grouped)[T.Politics]                   1.2391      1.217      1.018      0.309      -1.146       3.624
C(topic_grouped)[T.Science and technology]     1.3134      1.176      1.117      0.264      -0.991       3.618
C(topic_grouped)[T.Sports]                     2.3315      1.206      1.934      0.053      -0.032       4.695
C(answer_type_grouped)[T.Number]              -1.1687      0.877     -1.332      0.183      -2.888       0.551
C(answer_type_grouped)[T.Other]               -1.0008      0.733     -1.366      0.172      -2.437       0.435
C(answer_type_grouped)[T.Person]              -0.2716      0.601     -0.452      0.651      -1.450       0.906
q_length                                      -0.2501      0.686     -0.365      0.715      -1.595       1.095
capabilities_entropy                           1.3696      0.454      3.017      0.003       0.480       2.259
==============================================================================================================

--- Analyzing gpt-4.1-2025-04-14 (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_neutral/gpt-4.1-2025-04-14_SimpleMC_redacted_temp0.0_1751825599_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    169
1     68
Name: count, dtype: int64

Answer change%: 0.2869 [0.2293329736140256, 0.34450668883323177] (n=237)
P-value vs 25%: 0.2089; P-value vs 0%: 1.587e-22
Phase 2 self-accuracy: 0.4118 [0.2947895228807646, 0.5287398888839413] (n=68)
P-value vs 25%: 0.00672; P-value vs 33%: 0.1869

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  237
Model:                          Logit   Df Residuals:                      235
Method:                           MLE   Df Model:                            1
Date:                Tue, 08 Jul 2025   Pseudo R-squ.:                  0.1320
Time:                        07:27:23   Log-Likelihood:                -123.30
converged:                       True   LL-Null:                       -142.05
Covariance Type:            nonrobust   LLR p-value:                 9.154e-10
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          2.6446      0.620      4.268      0.000       1.430       3.859
p_i_capability    -4.5187      0.785     -5.758      0.000      -6.057      -2.980
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  237
Model:                          Logit   Df Residuals:                      235
Method:                           MLE   Df Model:                            1
Date:                Tue, 08 Jul 2025   Pseudo R-squ.:                  0.1463
Time:                        07:27:23   Log-Likelihood:                -121.27
converged:                       True   LL-Null:                       -142.05
Covariance Type:            nonrobust   LLR p-value:                 1.146e-10
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.1280      0.279     -7.634      0.000      -2.674      -1.582
capabilities_entropy     1.7016      0.287      5.920      0.000       1.138       2.265
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.6731 [0.5456, 0.8006] (n=52)
                  P-value vs 33.3%: 1.763e-07

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=-5.15, p=1.83e-06
Wilcoxon delta_p: statistic=579.00, p=3.54e-07
Mean p = -0.1053  [-0.1453, -0.0652]
Idea 1 N = 81; 

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.874
Model:                            OLS   Adj. R-squared:                  0.871
Method:                 Least Squares   F-statistic:                     297.2
Date:                Tue, 08 Jul 2025   Prob (F-statistic):           9.76e-58
Time:                        07:27:23   Log-Likelihood:                 80.355
No. Observations:                 133   AIC:                            -152.7
Df Residuals:                     129   BIC:                            -141.1
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.6409      0.067     -9.637      0.000      -0.772      -0.509
p1                    0.6741      0.082      8.265      0.000       0.513       0.835
answer_changed        0.5447      0.094      5.792      0.000       0.359       0.731
p1:answer_changed     0.2934      0.127      2.308      0.023       0.042       0.545
==============================================================================
Omnibus:                       11.350   Durbin-Watson:                   1.997
Prob(Omnibus):                  0.003   Jarque-Bera (JB):               15.698
Skew:                           0.469   Prob(JB):                     0.000390
Kurtosis:                       4.398   Cond. No.                         20.2
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=4.64, p=1.35e-05
Wilcoxon delta_H: statistic=629.00, p=1.19e-06
Mean H = 0.2381  [0.1375, 0.3388]
Paired t-test delta_H Changed: statistic=8.12, p=9.5e-11
Wilcoxon delta_H Changed: statistic=73.00, p=2.02e-08
Mean H Changed = 0.5435  [0.4123, 0.6747]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=6.49, p=1.59e-09
Wilcoxon (p_top2_game vs p_top2_base): statistic=1176.00, p=1.77e-13
Mean p_top2 = 0.0477  [0.0333, 0.0622] (n=133)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=8.38, p=6.73e-14
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=1167.00, p=1.52e-13
Mean H_unchosen_baseline_set = 0.3575  [0.2739, 0.4411] (n=133)

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=1241.00, p=5.23e-13
Paired t-test (game_entropy vs capabilities_entropy): statistic=-8.54, p=2.81e-14
Mean capabilities_entropy-game_entropy = 0.4120  [0.3175, 0.5066] (n=133)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  133
Model:                          Logit   Df Residuals:                      130
Method:                           MLE   Df Model:                            2
Date:                Tue, 08 Jul 2025   Pseudo R-squ.:                 0.09255
Time:                        07:27:23   Log-Likelihood:                -80.764
converged:                       True   LL-Null:                       -89.001
Covariance Type:            nonrobust   LLR p-value:                 0.0002646
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.3904      0.267     -1.465      0.143      -0.913       0.132
p1_z            -0.7983      0.219     -3.648      0.000      -1.227      -0.369
I(p1_z ** 2)    -0.1162      0.211     -0.550      0.582      -0.530       0.298
================================================================================
AUC = 0.704

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  237
Model:                          Logit   Df Residuals:                      235
Method:                           MLE   Df Model:                            1
Date:                Tue, 08 Jul 2025   Pseudo R-squ.:                  0.1053
Time:                        07:27:23   Log-Likelihood:                -127.09
converged:                       True   LL-Null:                       -142.05
Covariance Type:            nonrobust   LLR p-value:                 4.514e-08
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.5813      0.208     -7.587      0.000      -1.990      -1.173
game_entropy     1.7580      0.339      5.187      0.000       1.094       2.422
================================================================================

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  237
Model:                          Logit   Df Residuals:                      234
Method:                           MLE   Df Model:                            2
Date:                Tue, 08 Jul 2025   Pseudo R-squ.:                  0.1680
Time:                        07:27:23   Log-Likelihood:                -118.18
converged:                       True   LL-Null:                       -142.05
Covariance Type:            nonrobust   LLR p-value:                 4.315e-11
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.2233      0.285     -7.791      0.000      -2.783      -1.664
capabilities_entropy     1.3189      0.323      4.087      0.000       0.686       1.951
game_entropy             0.9816      0.396      2.480      0.013       0.206       1.757
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'Video games', 'History']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.727273
                        1                 0.272727
Geography               0                 0.695652
                        1                 0.304348
Misc                    0                 0.621622
                        1                 0.378378
Music                   0                 0.800000
                        1                 0.200000
Other                   0                 0.631579
                        1                 0.368421
Politics                0                 0.742857
                        1                 0.257143
Science and technology  0                 0.716981
                        1                 0.283019
Sports                  0                 0.823529
                        1                 0.176471
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.739583
                     1                 0.260417
Number               0                 0.686275
                     1                 0.313725
Other                0                 0.740000
                     1                 0.260000
Person               0                 0.650000
                     1                 0.350000
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.733333  0.266667           15
                       Number               0.600000  0.400000            5
                       Other                0.800000  0.200000            5
                       Person               0.750000  0.250000            8
Geography              Date                 0.571429  0.428571            7
                       Number               0.785714  0.214286           14
                       Other                0.500000  0.500000            2
Misc                   Date                 0.714286  0.285714           14
                       Number               0.800000  0.200000            5
                       Other                0.666667  0.333333           12
                       Person               0.166667  0.833333            6
Music                  Date                 1.000000  0.000000            6
                       Number               0.333333  0.666667            3
                       Other                0.777778  0.222222            9
                       Person               1.000000  0.000000            2
Other                  Date                 0.700000  0.300000           10
                       Number               0.333333  0.666667            3
                       Other                1.000000  0.000000            4
                       Person               0.000000  1.000000            2
Politics               Date                 0.736842  0.263158           19
                       Number               0.666667  0.333333            3
                       Other                0.857143  0.142857            7
                       Person               0.666667  0.333333            6
Science and technology Date                 0.772727  0.227273           22
                       Number               0.636364  0.363636           11
                       Other                0.571429  0.428571            7
                       Person               0.769231  0.230769           13
Sports                 Date                 0.666667  0.333333            3
                       Number               0.857143  0.142857            7
                       Other                0.750000  0.250000            4
                       Person               1.000000  0.000000            3

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  237
Model:                          Logit   Df Residuals:                      225
Method:                           MLE   Df Model:                           11
Date:                Tue, 08 Jul 2025   Pseudo R-squ.:                 0.03349
Time:                        07:27:23   Log-Likelihood:                -137.29
converged:                       True   LL-Null:                       -142.05
Covariance Type:            nonrobust   LLR p-value:                    0.5746
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      2.2799      1.909      1.194      0.232      -1.462       6.021
C(topic_grouped)[T.Geography]                  0.1070      0.628      0.170      0.865      -1.123       1.337
C(topic_grouped)[T.Misc]                       0.5642      0.528      1.069      0.285      -0.470       1.598
C(topic_grouped)[T.Music]                     -0.4056      0.698     -0.581      0.561      -1.774       0.963
C(topic_grouped)[T.Other]                      0.4426      0.627      0.706      0.480      -0.787       1.672
C(topic_grouped)[T.Politics]                   0.1189      0.564      0.211      0.833      -0.986       1.223
C(topic_grouped)[T.Science and technology]     0.0558      0.503      0.111      0.912      -0.930       1.041
C(topic_grouped)[T.Sports]                    -0.5254      0.762     -0.690      0.490      -2.018       0.967
C(answer_type_grouped)[T.Number]               0.3484      0.408      0.853      0.394      -0.452       1.149
C(answer_type_grouped)[T.Other]               -0.0605      0.415     -0.146      0.884      -0.874       0.753
C(answer_type_grouped)[T.Person]               0.3323      0.425      0.782      0.434      -0.500       1.165
q_length                                      -0.7623      0.414     -1.842      0.066      -1.574       0.049
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.6136
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  237
Model:                          Logit   Df Residuals:                      224
Method:                           MLE   Df Model:                           12
Date:                Tue, 08 Jul 2025   Pseudo R-squ.:                  0.1966
Time:                        07:27:23   Log-Likelihood:                -114.12
converged:                       True   LL-Null:                       -142.05
Covariance Type:            nonrobust   LLR p-value:                 1.269e-07
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      0.1945      2.129      0.091      0.927      -3.978       4.367
C(topic_grouped)[T.Geography]                  0.0389      0.701      0.055      0.956      -1.335       1.412
C(topic_grouped)[T.Misc]                       0.3622      0.592      0.612      0.541      -0.798       1.522
C(topic_grouped)[T.Music]                     -0.4953      0.789     -0.627      0.530      -2.043       1.052
C(topic_grouped)[T.Other]                      0.7218      0.724      0.997      0.319      -0.697       2.140
C(topic_grouped)[T.Politics]                   0.2432      0.630      0.386      0.699      -0.991       1.477
C(topic_grouped)[T.Science and technology]    -0.1819      0.569     -0.320      0.749      -1.296       0.933
C(topic_grouped)[T.Sports]                    -0.1596      0.823     -0.194      0.846      -1.773       1.453
C(answer_type_grouped)[T.Number]               0.8947      0.462      1.938      0.053      -0.010       1.799
C(answer_type_grouped)[T.Other]                0.3812      0.473      0.806      0.420      -0.546       1.308
C(answer_type_grouped)[T.Person]               1.2510      0.521      2.403      0.016       0.231       2.271
q_length                                      -0.6902      0.458     -1.507      0.132      -1.588       0.208
capabilities_entropy                           1.9866      0.328      6.063      0.000       1.344       2.629
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  237
Model:                          Logit   Df Residuals:                      224
Method:                           MLE   Df Model:                           12
Date:                Tue, 08 Jul 2025   Pseudo R-squ.:                  0.1506
Time:                        07:27:23   Log-Likelihood:                -120.66
converged:                       True   LL-Null:                       -142.05
Covariance Type:            nonrobust   LLR p-value:                 2.463e-05
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      1.0228      2.071      0.494      0.621      -3.037       5.082
C(topic_grouped)[T.Geography]                  0.0657      0.675      0.097      0.923      -1.258       1.389
C(topic_grouped)[T.Misc]                       0.5199      0.562      0.924      0.355      -0.582       1.622
C(topic_grouped)[T.Music]                     -0.9164      0.791     -1.159      0.246      -2.466       0.633
C(topic_grouped)[T.Other]                      0.4341      0.690      0.629      0.529      -0.918       1.786
C(topic_grouped)[T.Politics]                   0.1539      0.602      0.256      0.798      -1.026       1.334
C(topic_grouped)[T.Science and technology]    -0.3299      0.550     -0.599      0.549      -1.409       0.749
C(topic_grouped)[T.Sports]                    -0.6934      0.802     -0.865      0.387      -2.265       0.878
C(answer_type_grouped)[T.Number]               0.4772      0.441      1.083      0.279      -0.386       1.341
C(answer_type_grouped)[T.Other]                0.0789      0.453      0.174      0.862      -0.809       0.967
C(answer_type_grouped)[T.Person]               0.7608      0.473      1.609      0.108      -0.166       1.688
q_length                                      -0.6516      0.449     -1.452      0.146      -1.531       0.228
game_entropy                                   1.9968      0.372      5.372      0.000       1.268       2.725
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  237
Model:                          Logit   Df Residuals:                      223
Method:                           MLE   Df Model:                           13
Date:                Tue, 08 Jul 2025   Pseudo R-squ.:                  0.2238
Time:                        07:27:23   Log-Likelihood:                -110.25
converged:                       True   LL-Null:                       -142.05
Covariance Type:            nonrobust   LLR p-value:                 1.185e-08
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -0.0490      2.190     -0.022      0.982      -4.341       4.243
C(topic_grouped)[T.Geography]                  0.0387      0.719      0.054      0.957      -1.370       1.447
C(topic_grouped)[T.Misc]                       0.4226      0.600      0.705      0.481      -0.753       1.598
C(topic_grouped)[T.Music]                     -0.9251      0.859     -1.077      0.282      -2.609       0.759
C(topic_grouped)[T.Other]                      0.7367      0.725      1.016      0.309      -0.684       2.157
C(topic_grouped)[T.Politics]                   0.2609      0.634      0.411      0.681      -0.982       1.504
C(topic_grouped)[T.Science and technology]    -0.3253      0.584     -0.557      0.578      -1.470       0.819
C(topic_grouped)[T.Sports]                    -0.3316      0.840     -0.395      0.693      -1.978       1.314
C(answer_type_grouped)[T.Number]               0.8546      0.470      1.817      0.069      -0.067       1.776
C(answer_type_grouped)[T.Other]                0.3717      0.487      0.764      0.445      -0.582       1.326
C(answer_type_grouped)[T.Person]               1.3042      0.527      2.476      0.013       0.272       2.336
q_length                                      -0.6558      0.472     -1.390      0.165      -1.581       0.269
capabilities_entropy                           1.5577      0.359      4.340      0.000       0.854       2.261
game_entropy                                   1.1732      0.424      2.769      0.006       0.343       2.004
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing gpt-4o-2024-08-06 (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_neutral/gpt-4o-2024-08-06_SimpleMC_redacted_cor_temp0.0_1751845435_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    220
1     33
Name: count, dtype: int64

Answer change%: 0.1304 [0.08893597486986282, 0.17193359034752848] (n=253)
P-value vs 25%: 1.633e-08; P-value vs 0%: 7.258e-10
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=33)
P-value vs 25%: 0; P-value vs 33%: 0

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  253
Model:                          Logit   Df Residuals:                      251
Method:                           MLE   Df Model:                            1
Date:                Tue, 08 Jul 2025   Pseudo R-squ.:                 0.05712
Time:                        07:27:23   Log-Likelihood:                -92.369
converged:                       True   LL-Null:                       -97.965
Covariance Type:            nonrobust   LLR p-value:                 0.0008215
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept         -0.5857      0.399     -1.469      0.142      -1.367       0.196
p_i_capability    -1.9112      0.561     -3.405      0.001      -3.011      -0.811
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  253
Model:                          Logit   Df Residuals:                      251
Method:                           MLE   Df Model:                            1
Date:                Tue, 08 Jul 2025   Pseudo R-squ.:                  0.2607
Time:                        07:27:23   Log-Likelihood:                -72.423
converged:                       True   LL-Null:                       -97.965
Covariance Type:            nonrobust   LLR p-value:                 8.855e-13
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -4.1187      0.544     -7.567      0.000      -5.185      -3.052
capabilities_entropy     2.3327      0.405      5.758      0.000       1.539       3.127
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.8125 [0.6773, 0.9477] (n=32)
                  P-value vs 33.3%: 3.794e-12

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=-4.40, p=1.8e-05
Wilcoxon delta_p: statistic=5378.00, p=7.26e-07
Mean p = -0.0361  [-0.0522, -0.0200]
Idea 1 N = 191; 

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.695
Model:                            OLS   Adj. R-squared:                  0.691
Method:                 Least Squares   F-statistic:                     166.2
Date:                Tue, 08 Jul 2025   Prob (F-statistic):           3.56e-56
Time:                        07:27:23   Log-Likelihood:                 195.82
No. Observations:                 223   AIC:                            -383.6
Df Residuals:                     219   BIC:                            -370.0
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.2997      0.033     -9.092      0.000      -0.365      -0.235
p1                    0.3133      0.038      8.202      0.000       0.238       0.389
answer_changed        0.0541      0.069      0.783      0.435      -0.082       0.190
p1:answer_changed     0.6735      0.108      6.215      0.000       0.460       0.887
==============================================================================
Omnibus:                       26.351   Durbin-Watson:                   1.845
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               74.121
Skew:                           0.463   Prob(JB):                     8.03e-17
Kurtosis:                       5.669   Cond. No.                         24.6
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-0.59, p=0.559
Wilcoxon delta_H: statistic=8967.00, p=0.793
Mean H = -0.0171  [-0.0744, 0.0401]
Paired t-test delta_H Changed: statistic=5.31, p=8.94e-06
Wilcoxon delta_H Changed: statistic=22.00, p=9.48e-06
Mean H Changed = 0.4030  [0.2541, 0.5519]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=5.75, p=2.92e-08
Wilcoxon (p_top2_game vs p_top2_base): statistic=6868.00, p=5.66e-09
Mean p_top2 = 0.0238  [0.0157, 0.0319] (n=223)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=1.49, p=0.137
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=10825.00, p=0.105
Mean H_unchosen_baseline_set = 0.0432  [-0.0136, 0.1000] (n=223)

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=6851.00, p=5.09e-09
Paired t-test (game_entropy vs capabilities_entropy): statistic=-5.68, p=4.19e-08
Mean capabilities_entropy-game_entropy = 0.1192  [0.0781, 0.1604] (n=223)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  223
Model:                          Logit   Df Residuals:                      220
Method:                           MLE   Df Model:                            2
Date:                Tue, 08 Jul 2025   Pseudo R-squ.:                  0.2341
Time:                        07:27:23   Log-Likelihood:                -70.239
converged:                       True   LL-Null:                       -91.712
Covariance Type:            nonrobust   LLR p-value:                 4.726e-10
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -2.3171      0.337     -6.871      0.000      -2.978      -1.656
p1_z            -1.4773      0.402     -3.677      0.000      -2.265      -0.690
I(p1_z ** 2)    -0.1359      0.273     -0.498      0.618      -0.670       0.398
================================================================================
AUC = 0.842

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  253
Model:                          Logit   Df Residuals:                      251
Method:                           MLE   Df Model:                            1
Date:                Tue, 08 Jul 2025   Pseudo R-squ.:                  0.2419
Time:                        07:27:23   Log-Likelihood:                -74.272
converged:                       True   LL-Null:                       -97.965
Covariance Type:            nonrobust   LLR p-value:                 5.829e-12
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -3.7360      0.465     -8.026      0.000      -4.648      -2.824
game_entropy     2.3456      0.402      5.832      0.000       1.557       3.134
================================================================================

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  253
Model:                          Logit   Df Residuals:                      250
Method:                           MLE   Df Model:                            2
Date:                Tue, 08 Jul 2025   Pseudo R-squ.:                  0.2719
Time:                        07:27:23   Log-Likelihood:                -71.329
converged:                       True   LL-Null:                       -97.965
Covariance Type:            nonrobust   LLR p-value:                 2.707e-12
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -4.1761      0.553     -7.558      0.000      -5.259      -3.093
capabilities_entropy     1.5731      0.654      2.407      0.016       0.292       2.854
game_entropy             0.9777      0.674      1.450      0.147      -0.344       2.299
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': None
topic_grouped           answer_changed
Art                     0                 0.880952
                        1                 0.119048
Geography               0                 0.818182
                        1                 0.181818
Misc                    0                 0.857143
                        1                 0.142857
Music                   0                 0.750000
                        1                 0.250000
Other                   0                 0.925926
                        1                 0.074074
Politics                0                 0.871795
                        1                 0.128205
Science and technology  0                 0.886364
                        1                 0.113636
Sports                  0                 0.904762
                        1                 0.095238
TV shows                0                 0.882353
                        1                 0.117647
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.837838
                     1                 0.162162
Number               0                 0.756757
                     1                 0.243243
Other                0                 0.933333
                     1                 0.066667
Person               0                 0.906250
                     1                 0.093750
Place                0                 0.888889
                     1                 0.111111
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.666667  0.333333            6
                       Number               0.714286  0.285714            7
                       Other                1.000000  0.000000            6
                       Person               0.947368  0.052632           19
                       Place                1.000000  0.000000            4
Geography              Date                 0.833333  0.166667            6
                       Number               0.625000  0.375000            8
                       Other                1.000000  0.000000            3
                       Place                1.000000  0.000000            5
Misc                   Date                 0.727273  0.272727           11
                       Number               1.000000  0.000000            3
                       Other                1.000000  0.000000            3
                       Person               1.000000  0.000000            2
                       Place                1.000000  0.000000            2
Music                  Date                 0.750000  0.250000            4
                       Number               1.000000  0.000000            2
                       Other                0.500000  0.500000            4
                       Person               0.800000  0.200000           10
Other                  Date                 0.900000  0.100000           10
                       Number               1.000000  0.000000            3
                       Other                1.000000  0.000000            4
                       Person               1.000000  0.000000            7
                       Place                0.666667  0.333333            3
Politics               Date                 0.800000  0.200000           15
                       Number               0.800000  0.200000            5
                       Other                1.000000  0.000000           11
                       Person               0.833333  0.166667            6
                       Place                1.000000  0.000000            2
Science and technology Date                 0.941176  0.058824           17
                       Number               0.571429  0.428571            7
                       Other                1.000000  0.000000           10
                       Person               0.900000  0.100000           10
Sports                 Date                 1.000000  0.000000            4
                       Number               1.000000  0.000000            1
                       Other                0.875000  0.125000            8
                       Person               1.000000  0.000000            6
                       Place                0.500000  0.500000            2
TV shows               Date                 1.000000  0.000000            1
                       Number               1.000000  0.000000            1
                       Other                0.909091  0.090909           11
                       Person               0.750000  0.250000            4

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  253
Model:                          Logit   Df Residuals:                      239
Method:                           MLE   Df Model:                           13
Date:                Tue, 08 Jul 2025   Pseudo R-squ.:                 0.06130
Time:                        07:27:23   Log-Likelihood:                -91.959
converged:                       True   LL-Null:                       -97.965
Covariance Type:            nonrobust   LLR p-value:                    0.5267
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.0060      2.383     -0.422      0.673      -5.677       3.665
C(topic_grouped)[T.Geography]                  0.0916      0.767      0.119      0.905      -1.412       1.596
C(topic_grouped)[T.Misc]                      -0.0495      0.818     -0.060      0.952      -1.653       1.555
C(topic_grouped)[T.Music]                      1.0550      0.732      1.442      0.149      -0.379       2.489
C(topic_grouped)[T.Other]                     -0.6466      0.896     -0.722      0.470      -2.402       1.109
C(topic_grouped)[T.Politics]                   0.0234      0.717      0.033      0.974      -1.381       1.428
C(topic_grouped)[T.Science and technology]    -0.1655      0.707     -0.234      0.815      -1.551       1.220
C(topic_grouped)[T.Sports]                    -0.0666      0.909     -0.073      0.942      -1.848       1.715
C(topic_grouped)[T.TV shows]                   0.4118      0.952      0.433      0.665      -1.453       2.277
C(answer_type_grouped)[T.Number]               0.4598      0.517      0.889      0.374      -0.554       1.473
C(answer_type_grouped)[T.Other]               -1.1701      0.648     -1.806      0.071      -2.440       0.100
C(answer_type_grouped)[T.Person]              -0.8503      0.580     -1.467      0.142      -1.986       0.286
C(answer_type_grouped)[T.Place]               -0.3920      0.843     -0.465      0.642      -2.043       1.259
q_length                                      -0.1347      0.513     -0.263      0.793      -1.140       0.871
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.6088
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  253
Model:                          Logit   Df Residuals:                      238
Method:                           MLE   Df Model:                           14
Date:                Tue, 08 Jul 2025   Pseudo R-squ.:                  0.3198
Time:                        07:27:23   Log-Likelihood:                -66.640
converged:                       True   LL-Null:                       -97.965
Covariance Type:            nonrobust   LLR p-value:                 4.003e-08
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -6.2662      3.210     -1.952      0.051     -12.558       0.025
C(topic_grouped)[T.Geography]                  0.4209      0.874      0.482      0.630      -1.292       2.134
C(topic_grouped)[T.Misc]                       0.9342      0.951      0.982      0.326      -0.931       2.799
C(topic_grouped)[T.Music]                      2.3183      0.953      2.433      0.015       0.450       4.186
C(topic_grouped)[T.Other]                     -0.8098      0.995     -0.814      0.416      -2.760       1.141
C(topic_grouped)[T.Politics]                   0.6061      0.857      0.707      0.479      -1.073       2.286
C(topic_grouped)[T.Science and technology]     0.3512      0.840      0.418      0.676      -1.295       1.998
C(topic_grouped)[T.Sports]                     0.3072      1.061      0.290      0.772      -1.772       2.387
C(topic_grouped)[T.TV shows]                   0.6216      1.237      0.502      0.615      -1.803       3.047
C(answer_type_grouped)[T.Number]               0.1866      0.584      0.319      0.749      -0.958       1.332
C(answer_type_grouped)[T.Other]               -0.3061      0.834     -0.367      0.714      -1.941       1.329
C(answer_type_grouped)[T.Person]               0.7943      0.764      1.040      0.298      -0.703       2.292
C(answer_type_grouped)[T.Place]                0.2405      0.996      0.241      0.809      -1.711       2.192
q_length                                       0.1935      0.664      0.292      0.771      -1.107       1.494
capabilities_entropy                           2.8814      0.537      5.365      0.000       1.829       3.934
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  253
Model:                          Logit   Df Residuals:                      238
Method:                           MLE   Df Model:                           14
Date:                Tue, 08 Jul 2025   Pseudo R-squ.:                  0.2805
Time:                        07:27:23   Log-Likelihood:                -70.486
converged:                       True   LL-Null:                       -97.965
Covariance Type:            nonrobust   LLR p-value:                 8.803e-07
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -3.3098      2.845     -1.163      0.245      -8.886       2.266
C(topic_grouped)[T.Geography]                 -0.0404      0.859     -0.047      0.962      -1.723       1.642
C(topic_grouped)[T.Misc]                       0.4453      0.892      0.499      0.618      -1.304       2.194
C(topic_grouped)[T.Music]                      1.8385      0.914      2.011      0.044       0.047       3.630
C(topic_grouped)[T.Other]                     -0.4179      0.980     -0.427      0.670      -2.338       1.502
C(topic_grouped)[T.Politics]                   0.5052      0.822      0.614      0.539      -1.107       2.117
C(topic_grouped)[T.Science and technology]    -0.1196      0.810     -0.148      0.883      -1.707       1.468
C(topic_grouped)[T.Sports]                     0.2694      1.036      0.260      0.795      -1.760       2.299
C(topic_grouped)[T.TV shows]                   0.4802      1.128      0.426      0.670      -1.731       2.691
C(answer_type_grouped)[T.Number]               0.1464      0.575      0.255      0.799      -0.981       1.273
C(answer_type_grouped)[T.Other]               -0.7252      0.823     -0.882      0.378      -2.337       0.887
C(answer_type_grouped)[T.Person]               0.2482      0.692      0.359      0.720      -1.108       1.604
C(answer_type_grouped)[T.Place]               -0.1829      0.965     -0.190      0.850      -2.074       1.708
q_length                                      -0.1911      0.616     -0.310      0.756      -1.399       1.017
game_entropy                                   2.5546      0.474      5.388      0.000       1.625       3.484
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  253
Model:                          Logit   Df Residuals:                      237
Method:                           MLE   Df Model:                           15
Date:                Tue, 08 Jul 2025   Pseudo R-squ.:                  0.3271
Time:                        07:27:23   Log-Likelihood:                -65.919
converged:                       True   LL-Null:                       -97.965
Covariance Type:            nonrobust   LLR p-value:                 4.927e-08
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -5.8343      3.211     -1.817      0.069     -12.128       0.459
C(topic_grouped)[T.Geography]                  0.2595      0.882      0.294      0.769      -1.469       1.988
C(topic_grouped)[T.Misc]                       0.8463      0.942      0.898      0.369      -1.000       2.693
C(topic_grouped)[T.Music]                      2.3311      0.966      2.413      0.016       0.438       4.225
C(topic_grouped)[T.Other]                     -0.7060      0.998     -0.708      0.479      -2.662       1.250
C(topic_grouped)[T.Politics]                   0.5889      0.853      0.690      0.490      -1.084       2.262
C(topic_grouped)[T.Science and technology]     0.2077      0.844      0.246      0.806      -1.447       1.862
C(topic_grouped)[T.Sports]                     0.2956      1.071      0.276      0.782      -1.803       2.394
C(topic_grouped)[T.TV shows]                   0.5339      1.234      0.433      0.665      -1.885       2.953
C(answer_type_grouped)[T.Number]               0.1305      0.590      0.221      0.825      -1.026       1.287
C(answer_type_grouped)[T.Other]               -0.3463      0.865     -0.401      0.689      -2.041       1.348
C(answer_type_grouped)[T.Person]               0.8247      0.757      1.090      0.276      -0.658       2.307
C(answer_type_grouped)[T.Place]                0.1413      1.009      0.140      0.889      -1.835       2.118
q_length                                       0.0967      0.666      0.145      0.885      -1.209       1.402
capabilities_entropy                           2.2225      0.761      2.920      0.003       0.731       3.714
game_entropy                                   0.8750      0.736      1.189      0.234      -0.567       2.317
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing gpt-4o-2024-08-06 (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_neutral/gpt-4o-2024-08-06_SimpleMC_redacted_temp0.0_1751827128_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    171
1     76
Name: count, dtype: int64

Answer change%: 0.3077 [0.25013406679950173, 0.3652505485851137] (n=247)
P-value vs 25%: 0.04947; P-value vs 0%: 1.096e-25
Phase 2 self-accuracy: 0.5263 [0.41405994827462134, 0.638571630672747] (n=76)
P-value vs 25%: 1.404e-06; P-value vs 33%: 0.0007375

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  247
Model:                          Logit   Df Residuals:                      245
Method:                           MLE   Df Model:                            1
Date:                Tue, 08 Jul 2025   Pseudo R-squ.:                 0.09500
Time:                        07:27:23   Log-Likelihood:                -137.98
converged:                       True   LL-Null:                       -152.46
Covariance Type:            nonrobust   LLR p-value:                 7.361e-08
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          1.6559      0.503      3.294      0.001       0.671       2.641
p_i_capability    -3.8150      0.775     -4.923      0.000      -5.334      -2.296
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  247
Model:                          Logit   Df Residuals:                      245
Method:                           MLE   Df Model:                            1
Date:                Tue, 08 Jul 2025   Pseudo R-squ.:                  0.1182
Time:                        07:27:23   Log-Likelihood:                -134.44
converged:                       True   LL-Null:                       -152.46
Covariance Type:            nonrobust   LLR p-value:                 1.929e-09
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.8088      0.437     -6.435      0.000      -3.664      -1.953
capabilities_entropy     1.7251      0.327      5.271      0.000       1.084       2.366
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.7200 [0.6184, 0.8216] (n=75)
                  P-value vs 33.3%: 8.785e-14

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=-4.96, p=1.71e-06
Wilcoxon delta_p: statistic=4061.00, p=2.37e-06
Mean p = -0.0558  [-0.0778, -0.0338]
Idea 1 N = 167; 

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.729
Model:                            OLS   Adj. R-squared:                  0.725
Method:                 Least Squares   F-statistic:                     212.9
Date:                Tue, 08 Jul 2025   Prob (F-statistic):           4.26e-67
Time:                        07:27:23   Log-Likelihood:                 152.50
No. Observations:                 242   AIC:                            -297.0
Df Residuals:                     238   BIC:                            -283.1
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.3232      0.039     -8.206      0.000      -0.401      -0.246
p1                    0.3641      0.052      7.022      0.000       0.262       0.466
answer_changed        0.0943      0.070      1.351      0.178      -0.043       0.232
p1:answer_changed     0.6453      0.111      5.805      0.000       0.426       0.864
==============================================================================
Omnibus:                        0.691   Durbin-Watson:                   1.766
Prob(Omnibus):                  0.708   Jarque-Bera (JB):                0.581
Skew:                           0.120   Prob(JB):                        0.748
Kurtosis:                       3.022   Cond. No.                         20.5
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=3.51, p=0.000577
Wilcoxon delta_H: statistic=4791.00, p=0.000382
Mean H = 0.1084  [0.0479, 0.1689]
Paired t-test delta_H Changed: statistic=7.76, p=3.71e-11
Wilcoxon delta_H Changed: statistic=196.00, p=8.59e-11
Mean H Changed = 0.3137  [0.2344, 0.3929]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=5.73, p=3.02e-08
Wilcoxon (p_top2_game vs p_top2_base): statistic=8084.00, p=1.28e-09
Mean p_top2 = 0.0279  [0.0183, 0.0374] (n=242)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=6.77, p=9.95e-11
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=7469.00, p=3.25e-11
Mean H_unchosen_baseline_set = 0.1720  [0.1222, 0.2218] (n=242)

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=7585.00, p=6.66e-11
Paired t-test (game_entropy vs capabilities_entropy): statistic=-6.87, p=5.57e-11
Mean capabilities_entropy-game_entropy = 0.1732  [0.1238, 0.2227] (n=242)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  242
Model:                          Logit   Df Residuals:                      239
Method:                           MLE   Df Model:                            2
Date:                Tue, 08 Jul 2025   Pseudo R-squ.:                  0.1393
Time:                        07:27:23   Log-Likelihood:                -128.94
converged:                       True   LL-Null:                       -149.81
Covariance Type:            nonrobust   LLR p-value:                 8.676e-10
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.8726      0.220     -3.975      0.000      -1.303      -0.442
p1_z            -1.0474      0.191     -5.470      0.000      -1.423      -0.672
I(p1_z ** 2)    -0.1557      0.195     -0.800      0.424      -0.537       0.226
================================================================================
AUC = 0.745

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  247
Model:                          Logit   Df Residuals:                      245
Method:                           MLE   Df Model:                            1
Date:                Tue, 08 Jul 2025   Pseudo R-squ.:                 0.09316
Time:                        07:27:23   Log-Likelihood:                -138.26
converged:                       True   LL-Null:                       -152.46
Covariance Type:            nonrobust   LLR p-value:                 9.829e-08
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -2.1564      0.330     -6.541      0.000      -2.803      -1.510
game_entropy     1.3881      0.281      4.940      0.000       0.837       1.939
================================================================================

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  247
Model:                          Logit   Df Residuals:                      244
Method:                           MLE   Df Model:                            2
Date:                Tue, 08 Jul 2025   Pseudo R-squ.:                  0.1238
Time:                        07:27:23   Log-Likelihood:                -133.58
converged:                       True   LL-Null:                       -152.46
Covariance Type:            nonrobust   LLR p-value:                 6.321e-09
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.8440      0.438     -6.497      0.000      -3.702      -1.986
capabilities_entropy     1.3253      0.445      2.980      0.003       0.454       2.197
game_entropy             0.5118      0.394      1.300      0.194      -0.260       1.284
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['History', 'TV shows', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.545455
                        1                 0.454545
Geography               0                 0.727273
                        1                 0.272727
Misc                    0                 0.611111
                        1                 0.388889
Music                   0                 0.850000
                        1                 0.150000
Other                   0                 0.680000
                        1                 0.320000
Politics                0                 0.657895
                        1                 0.342105
Science and technology  0                 0.740741
                        1                 0.259259
Sports                  0                 0.842105
                        1                 0.157895
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.642105
                     1                 0.357895
Number               0                 0.780488
                     1                 0.219512
Other                0                 0.690909
                     1                 0.309091
Person               0                 0.714286
                     1                 0.285714
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.400000  0.600000           15
                       Number               1.000000  0.000000            2
                       Other                0.625000  0.375000            8
                       Person               0.625000  0.375000            8
Geography              Date                 0.777778  0.222222            9
                       Number               0.700000  0.300000           10
                       Other                0.666667  0.333333            3
Misc                   Date                 0.636364  0.363636           11
                       Number               0.800000  0.200000            5
                       Other                0.636364  0.363636           11
                       Person               0.444444  0.555556            9
Music                  Date                 0.875000  0.125000            8
                       Number               1.000000  0.000000            2
                       Other                0.875000  0.125000            8
                       Person               0.500000  0.500000            2
Other                  Date                 0.750000  0.250000            8
                       Number               0.500000  0.500000            4
                       Other                0.714286  0.285714            7
                       Person               0.666667  0.333333            6
Politics               Date                 0.523810  0.476190           21
                       Number               1.000000  0.000000            1
                       Other                0.714286  0.285714            7
                       Person               0.888889  0.111111            9
Science and technology Date                 0.777778  0.222222           18
                       Number               0.714286  0.285714            7
                       Other                0.555556  0.444444            9
                       Person               0.800000  0.200000           20
Sports                 Date                 0.600000  0.400000            5
                       Number               0.900000  0.100000           10
                       Other                1.000000  0.000000            2
                       Person               1.000000  0.000000            2

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  247
Model:                          Logit   Df Residuals:                      235
Method:                           MLE   Df Model:                           11
Date:                Tue, 08 Jul 2025   Pseudo R-squ.:                 0.04375
Time:                        07:27:23   Log-Likelihood:                -145.79
converged:                       True   LL-Null:                       -152.46
Covariance Type:            nonrobust   LLR p-value:                    0.2717
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      2.2288      1.860      1.198      0.231      -1.417       5.875
C(topic_grouped)[T.Geography]                 -0.7594      0.619     -1.227      0.220      -1.973       0.454
C(topic_grouped)[T.Misc]                      -0.1574      0.497     -0.317      0.751      -1.131       0.816
C(topic_grouped)[T.Music]                     -1.6003      0.724     -2.210      0.027      -3.019      -0.181
C(topic_grouped)[T.Other]                     -0.5531      0.559     -0.989      0.323      -1.650       0.543
C(topic_grouped)[T.Politics]                  -0.4047      0.500     -0.809      0.418      -1.385       0.575
C(topic_grouped)[T.Science and technology]    -0.7949      0.474     -1.678      0.093      -1.724       0.134
C(topic_grouped)[T.Sports]                    -1.2823      0.748     -1.715      0.086      -2.748       0.183
C(answer_type_grouped)[T.Number]              -0.4921      0.466     -1.057      0.291      -1.405       0.421
C(answer_type_grouped)[T.Other]               -0.2594      0.378     -0.687      0.492      -1.000       0.481
C(answer_type_grouped)[T.Person]              -0.4424      0.384     -1.152      0.249      -1.195       0.310
q_length                                      -0.4975      0.405     -1.230      0.219      -1.290       0.296
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 1.0530
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  247
Model:                          Logit   Df Residuals:                      234
Method:                           MLE   Df Model:                           12
Date:                Tue, 08 Jul 2025   Pseudo R-squ.:                  0.1715
Time:                        07:27:23   Log-Likelihood:                -126.31
converged:                       True   LL-Null:                       -152.46
Covariance Type:            nonrobust   LLR p-value:                 5.499e-07
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      0.1501      2.037      0.074      0.941      -3.843       4.143
C(topic_grouped)[T.Geography]                 -1.1418      0.688     -1.660      0.097      -2.490       0.207
C(topic_grouped)[T.Misc]                      -0.6026      0.551     -1.093      0.274      -1.683       0.478
C(topic_grouped)[T.Music]                     -1.9619      0.783     -2.507      0.012      -3.496      -0.428
C(topic_grouped)[T.Other]                     -0.5460      0.614     -0.889      0.374      -1.749       0.657
C(topic_grouped)[T.Politics]                  -0.7473      0.561     -1.332      0.183      -1.847       0.352
C(topic_grouped)[T.Science and technology]    -1.1325      0.529     -2.140      0.032      -2.170      -0.095
C(topic_grouped)[T.Sports]                    -1.5894      0.803     -1.980      0.048      -3.163      -0.016
C(answer_type_grouped)[T.Number]              -0.3723      0.495     -0.752      0.452      -1.343       0.598
C(answer_type_grouped)[T.Other]                0.2069      0.420      0.492      0.623      -0.617       1.031
C(answer_type_grouped)[T.Person]               0.1967      0.438      0.449      0.653      -0.662       1.055
q_length                                      -0.5485      0.437     -1.256      0.209      -1.405       0.307
capabilities_entropy                           1.9946      0.372      5.357      0.000       1.265       2.724
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  247
Model:                          Logit   Df Residuals:                      234
Method:                           MLE   Df Model:                           12
Date:                Tue, 08 Jul 2025   Pseudo R-squ.:                  0.1387
Time:                        07:27:23   Log-Likelihood:                -131.31
converged:                       True   LL-Null:                       -152.46
Covariance Type:            nonrobust   LLR p-value:                 2.961e-05
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      0.4084      1.999      0.204      0.838      -3.509       4.325
C(topic_grouped)[T.Geography]                 -0.8054      0.655     -1.230      0.219      -2.088       0.477
C(topic_grouped)[T.Misc]                      -0.2457      0.533     -0.461      0.645      -1.290       0.798
C(topic_grouped)[T.Music]                     -1.5930      0.762     -2.092      0.036      -3.086      -0.100
C(topic_grouped)[T.Other]                     -0.6150      0.593     -1.037      0.300      -1.777       0.548
C(topic_grouped)[T.Politics]                  -0.4086      0.534     -0.766      0.444      -1.455       0.637
C(topic_grouped)[T.Science and technology]    -0.8789      0.509     -1.728      0.084      -1.876       0.118
C(topic_grouped)[T.Sports]                    -1.2947      0.785     -1.649      0.099      -2.834       0.244
C(answer_type_grouped)[T.Number]              -0.6172      0.489     -1.261      0.207      -1.577       0.342
C(answer_type_grouped)[T.Other]               -0.0645      0.409     -0.158      0.875      -0.865       0.736
C(answer_type_grouped)[T.Person]               0.0927      0.425      0.218      0.828      -0.741       0.927
q_length                                      -0.4411      0.428     -1.030      0.303      -1.281       0.399
game_entropy                                   1.5118      0.306      4.948      0.000       0.913       2.111
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  247
Model:                          Logit   Df Residuals:                      233
Method:                           MLE   Df Model:                           13
Date:                Tue, 08 Jul 2025   Pseudo R-squ.:                  0.1767
Time:                        07:27:23   Log-Likelihood:                -125.52
converged:                       True   LL-Null:                       -152.46
Covariance Type:            nonrobust   LLR p-value:                 6.356e-07
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -0.0667      2.052     -0.033      0.974      -4.088       3.955
C(topic_grouped)[T.Geography]                 -1.0876      0.689     -1.578      0.114      -2.438       0.263
C(topic_grouped)[T.Misc]                      -0.5460      0.554     -0.985      0.325      -1.633       0.541
C(topic_grouped)[T.Music]                     -1.8830      0.786     -2.397      0.017      -3.423      -0.343
C(topic_grouped)[T.Other]                     -0.5791      0.615     -0.942      0.346      -1.784       0.626
C(topic_grouped)[T.Politics]                  -0.6818      0.562     -1.212      0.225      -1.784       0.421
C(topic_grouped)[T.Science and technology]    -1.1016      0.532     -2.071      0.038      -2.144      -0.059
C(topic_grouped)[T.Sports]                    -1.5455      0.806     -1.917      0.055      -3.125       0.034
C(answer_type_grouped)[T.Number]              -0.4520      0.502     -0.901      0.368      -1.436       0.532
C(answer_type_grouped)[T.Other]                0.1725      0.424      0.407      0.684      -0.658       1.003
C(answer_type_grouped)[T.Person]               0.2579      0.443      0.583      0.560      -0.610       1.125
q_length                                      -0.5157      0.439     -1.176      0.240      -1.375       0.344
capabilities_entropy                           1.5887      0.488      3.259      0.001       0.633       2.544
game_entropy                                   0.5220      0.417      1.250      0.211      -0.296       1.340
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing grok-3-latest (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_neutral/grok-3-latest_SimpleMC_redacted_cor_temp0.0_1751833664_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    273
1     22
Name: count, dtype: int64

Answer change%: 0.0746 [0.0445979208232761, 0.10455462154960526] (n=295)
P-value vs 25%: 1.886e-30; P-value vs 0%: 1.084e-06
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=22)
P-value vs 25%: 0; P-value vs 33%: 0

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  295
Model:                          Logit   Df Residuals:                      293
Method:                           MLE   Df Model:                            1
Date:                Tue, 08 Jul 2025   Pseudo R-squ.:                  0.1764
Time:                        07:27:23   Log-Likelihood:                -64.459
converged:                       True   LL-Null:                       -78.269
Covariance Type:            nonrobust   LLR p-value:                 1.477e-07
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          1.8206      0.864      2.107      0.035       0.127       3.514
p_i_capability    -5.1578      1.055     -4.887      0.000      -7.226      -3.089
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  295
Model:                          Logit   Df Residuals:                      293
Method:                           MLE   Df Model:                            1
Date:                Tue, 08 Jul 2025   Pseudo R-squ.:                  0.2925
Time:                        07:27:23   Log-Likelihood:                -55.373
converged:                       True   LL-Null:                       -78.269
Covariance Type:            nonrobust   LLR p-value:                 1.316e-11
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -4.2083      0.481     -8.741      0.000      -5.152      -3.265
capabilities_entropy     3.0784      0.516      5.967      0.000       2.067       4.090
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.7727 [0.5976, 0.9478] (n=22)
                  P-value vs 33.3%: 8.748e-07

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=-3.73, p=0.000238
Wilcoxon delta_p: statistic=8330.00, p=8.68e-15
Mean p = -0.0269  [-0.0411, -0.0128]
Idea 1 N = 270; 

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.728
Model:                            OLS   Adj. R-squared:                  0.725
Method:                 Least Squares   F-statistic:                     257.1
Date:                Tue, 08 Jul 2025   Prob (F-statistic):           4.09e-81
Time:                        07:27:23   Log-Likelihood:                 263.78
No. Observations:                 292   AIC:                            -519.6
Df Residuals:                     288   BIC:                            -504.9
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.6191      0.048    -12.804      0.000      -0.714      -0.524
p1                    0.6298      0.051     12.343      0.000       0.529       0.730
answer_changed        0.5114      0.101      5.075      0.000       0.313       0.710
p1:answer_changed     0.2540      0.136      1.871      0.062      -0.013       0.521
==============================================================================
Omnibus:                      224.285   Durbin-Watson:                   2.136
Prob(Omnibus):                  0.000   Jarque-Bera (JB):             3673.185
Skew:                           2.990   Prob(JB):                         0.00
Kurtosis:                      19.314   Cond. No.                         40.3
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-4.95, p=1.34e-06
Wilcoxon delta_H: statistic=11940.00, p=7.56e-07
Mean H = -0.1541  [-0.2151, -0.0930]
Paired t-test delta_H Changed: statistic=1.73, p=0.0982
Wilcoxon delta_H Changed: statistic=66.00, p=0.0501
Mean H Changed = 0.1439  [-0.0191, 0.3068]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=2.48, p=0.0139
Wilcoxon (p_top2_game vs p_top2_base): statistic=13669.00, p=9e-08
Mean p_top2 = 0.0056  [0.0012, 0.0100] (n=292)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=-4.42, p=1.42e-05
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=15080.00, p=1.25e-05
Mean H_unchosen_baseline_set = -0.1316  [-0.1901, -0.0732] (n=292)

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=9718.00, p=6.38e-16
Paired t-test (game_entropy vs capabilities_entropy): statistic=-5.83, p=1.51e-08
Mean capabilities_entropy-game_entropy = 0.1138  [0.0755, 0.1521] (n=292)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  292
Model:                          Logit   Df Residuals:                      289
Method:                           MLE   Df Model:                            2
Date:                Tue, 08 Jul 2025   Pseudo R-squ.:                  0.3240
Time:                        07:27:23   Log-Likelihood:                -52.749
converged:                       True   LL-Null:                       -78.035
Covariance Type:            nonrobust   LLR p-value:                 1.043e-11
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -3.1711      0.390     -8.121      0.000      -3.936      -2.406
p1_z            -2.1644      0.517     -4.184      0.000      -3.178      -1.151
I(p1_z ** 2)    -0.3933      0.178     -2.207      0.027      -0.743      -0.044
================================================================================
AUC = 0.894

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  295
Model:                          Logit   Df Residuals:                      293
Method:                           MLE   Df Model:                            1
Date:                Tue, 08 Jul 2025   Pseudo R-squ.:                  0.3648
Time:                        07:27:23   Log-Likelihood:                -49.717
converged:                       True   LL-Null:                       -78.269
Covariance Type:            nonrobust   LLR p-value:                 4.132e-14
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -4.0833      0.453     -9.012      0.000      -4.971      -3.195
game_entropy     3.8981      0.596      6.537      0.000       2.729       5.067
================================================================================

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  295
Model:                          Logit   Df Residuals:                      292
Method:                           MLE   Df Model:                            2
Date:                Tue, 08 Jul 2025   Pseudo R-squ.:                  0.4230
Time:                        07:27:23   Log-Likelihood:                -45.164
converged:                       True   LL-Null:                       -78.269
Covariance Type:            nonrobust   LLR p-value:                 4.193e-15
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -4.7877      0.600     -7.983      0.000      -5.963      -3.612
capabilities_entropy     1.9571      0.650      3.009      0.003       0.682       3.232
game_entropy             2.8182      0.674      4.184      0.000       1.498       4.138
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['Other', 'Sports', 'Music', 'Geography', 'History', 'TV shows', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.937500
                        1                 0.062500
Misc                    0                 0.913907
                        1                 0.086093
Politics                0                 0.937500
                        1                 0.062500
Science and technology  0                 0.937500
                        1                 0.062500
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.950495
                     1                 0.049505
Number               0                 0.925000
                     1                 0.075000
Other                0                 0.912088
                     1                 0.087912
Person               0                 0.904762
                     1                 0.095238
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.857143  0.142857           14
                       Number               1.000000  0.000000            5
                       Other                0.923077  0.076923           13
                       Person               1.000000  0.000000           16
Misc                   Date                 0.956522  0.043478           46
                       Number               0.923077  0.076923           26
                       Other                0.882353  0.117647           51
                       Person               0.892857  0.107143           28
Politics               Date                 1.000000  0.000000           20
                       Number               1.000000  0.000000            4
                       Other                0.923077  0.076923           13
                       Person               0.818182  0.181818           11
Science and technology Date                 0.952381  0.047619           21
                       Number               0.800000  0.200000            5
                       Other                1.000000  0.000000           14
                       Person               0.875000  0.125000            8

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  295
Model:                          Logit   Df Residuals:                      287
Method:                           MLE   Df Model:                            7
Date:                Tue, 08 Jul 2025   Pseudo R-squ.:                 0.01405
Time:                        07:27:23   Log-Likelihood:                -77.169
converged:                       True   LL-Null:                       -78.269
Covariance Type:            nonrobust   LLR p-value:                    0.9479
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -2.6888      2.939     -0.915      0.360      -8.449       3.071
C(topic_grouped)[T.Misc]                       0.3934      0.671      0.586      0.558      -0.922       1.709
C(topic_grouped)[T.Politics]                   0.1018      0.859      0.119      0.906      -1.581       1.785
C(topic_grouped)[T.Science and technology]     0.1197      0.856      0.140      0.889      -1.557       1.797
C(answer_type_grouped)[T.Number]               0.3940      0.763      0.516      0.606      -1.102       1.890
C(answer_type_grouped)[T.Other]                0.5834      0.592      0.985      0.325      -0.578       1.744
C(answer_type_grouped)[T.Person]               0.7227      0.634      1.141      0.254      -0.519       1.965
q_length                                      -0.1121      0.647     -0.173      0.862      -1.380       1.155
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.2838
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  295
Model:                          Logit   Df Residuals:                      286
Method:                           MLE   Df Model:                            8
Date:                Tue, 08 Jul 2025   Pseudo R-squ.:                  0.2985
Time:                        07:27:24   Log-Likelihood:                -54.906
converged:                       True   LL-Null:                       -78.269
Covariance Type:            nonrobust   LLR p-value:                 1.729e-07
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -5.1940      3.321     -1.564      0.118     -11.703       1.315
C(topic_grouped)[T.Misc]                      -0.3911      0.794     -0.493      0.622      -1.947       1.165
C(topic_grouped)[T.Politics]                  -0.0023      0.958     -0.002      0.998      -1.880       1.875
C(topic_grouped)[T.Science and technology]    -0.4103      0.949     -0.432      0.665      -2.270       1.450
C(answer_type_grouped)[T.Number]               0.0429      0.873      0.049      0.961      -1.668       1.754
C(answer_type_grouped)[T.Other]                0.2684      0.692      0.388      0.698      -1.088       1.625
C(answer_type_grouped)[T.Person]               0.3487      0.724      0.482      0.630      -1.071       1.768
q_length                                       0.2332      0.732      0.319      0.750      -1.201       1.667
capabilities_entropy                           3.1409      0.537      5.853      0.000       2.089       4.193
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  295
Model:                          Logit   Df Residuals:                      286
Method:                           MLE   Df Model:                            8
Date:                Tue, 08 Jul 2025   Pseudo R-squ.:                  0.3726
Time:                        07:27:24   Log-Likelihood:                -49.108
converged:                       True   LL-Null:                       -78.269
Covariance Type:            nonrobust   LLR p-value:                 9.935e-10
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -5.7575      3.622     -1.590      0.112     -12.857       1.342
C(topic_grouped)[T.Misc]                      -0.0967      0.854     -0.113      0.910      -1.771       1.578
C(topic_grouped)[T.Politics]                   0.0870      1.047      0.083      0.934      -1.966       2.140
C(topic_grouped)[T.Science and technology]    -0.1426      1.029     -0.139      0.890      -2.159       1.874
C(answer_type_grouped)[T.Number]               0.6384      0.962      0.664      0.507      -1.247       2.524
C(answer_type_grouped)[T.Other]                0.6475      0.734      0.882      0.378      -0.792       2.087
C(answer_type_grouped)[T.Person]               0.5620      0.776      0.724      0.469      -0.959       2.083
q_length                                       0.2812      0.788      0.357      0.721      -1.263       1.825
game_entropy                                   3.9503      0.616      6.409      0.000       2.742       5.158
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  295
Model:                          Logit   Df Residuals:                      285
Method:                           MLE   Df Model:                            9
Date:                Tue, 08 Jul 2025   Pseudo R-squ.:                  0.4273
Time:                        07:27:24   Log-Likelihood:                -44.823
converged:                       True   LL-Null:                       -78.269
Covariance Type:            nonrobust   LLR p-value:                 6.175e-11
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -6.5009      3.707     -1.754      0.079     -13.766       0.764
C(topic_grouped)[T.Misc]                      -0.2329      0.936     -0.249      0.803      -2.067       1.601
C(topic_grouped)[T.Politics]                   0.1504      1.097      0.137      0.891      -2.000       2.301
C(topic_grouped)[T.Science and technology]    -0.0421      1.091     -0.039      0.969      -2.179       2.095
C(answer_type_grouped)[T.Number]               0.2799      0.963      0.291      0.771      -1.607       2.167
C(answer_type_grouped)[T.Other]                0.2222      0.797      0.279      0.781      -1.341       1.785
C(answer_type_grouped)[T.Person]               0.3081      0.799      0.386      0.700      -1.257       1.873
q_length                                       0.3583      0.801      0.447      0.655      -1.212       1.928
capabilities_entropy                           1.9711      0.669      2.946      0.003       0.660       3.283
game_entropy                                   2.8508      0.687      4.153      0.000       1.505       4.196
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing grok-3-latest (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_neutral/grok-3-latest_SimpleMC_redacted_temp0.0_1751826103_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    138
1     67
Name: count, dtype: int64

Answer change%: 0.3268 [0.26262051404567455, 0.39103802253969133] (n=205)
P-value vs 25%: 0.01902; P-value vs 0%: 1.933e-23
Phase 2 self-accuracy: 0.5672 [0.4485253957797495, 0.6858029624292057] (n=67)
P-value vs 25%: 1.608e-07; P-value vs 33%: 0.0001095

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  205
Model:                          Logit   Df Residuals:                      203
Method:                           MLE   Df Model:                            1
Date:                Tue, 08 Jul 2025   Pseudo R-squ.:                  0.1948
Time:                        07:27:24   Log-Likelihood:                -104.31
converged:                       True   LL-Null:                       -129.54
Covariance Type:            nonrobust   LLR p-value:                 1.212e-12
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          4.6087      0.851      5.416      0.000       2.941       6.277
p_i_capability    -6.6450      1.054     -6.303      0.000      -8.711      -4.579
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  205
Model:                          Logit   Df Residuals:                      203
Method:                           MLE   Df Model:                            1
Date:                Tue, 08 Jul 2025   Pseudo R-squ.:                  0.1697
Time:                        07:27:24   Log-Likelihood:                -107.56
converged:                       True   LL-Null:                       -129.54
Covariance Type:            nonrobust   LLR p-value:                 3.352e-11
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.3172      0.339     -6.845      0.000      -2.981      -1.654
capabilities_entropy     2.3142      0.392      5.904      0.000       1.546       3.082
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.6866 [0.5755, 0.7976] (n=67)
                  P-value vs 33.3%: 4.581e-10

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=-1.90, p=0.0598
Wilcoxon delta_p: statistic=3451.00, p=0.00427
Mean p = -0.0232  [-0.0472, 0.0008]
Idea 1 N = 138; 

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.830
Model:                            OLS   Adj. R-squared:                  0.827
Method:                 Least Squares   F-statistic:                     326.1
Date:                Tue, 08 Jul 2025   Prob (F-statistic):           6.21e-77
Time:                        07:27:24   Log-Likelihood:                 114.36
No. Observations:                 205   AIC:                            -220.7
Df Residuals:                     201   BIC:                            -207.4
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.5431      0.077     -7.052      0.000      -0.695      -0.391
p1                    0.5884      0.086      6.832      0.000       0.419       0.758
answer_changed        0.2554      0.106      2.418      0.017       0.047       0.464
p1:answer_changed     0.6181      0.132      4.685      0.000       0.358       0.878
==============================================================================
Omnibus:                       38.316   Durbin-Watson:                   2.228
Prob(Omnibus):                  0.000   Jarque-Bera (JB):              159.898
Skew:                          -0.623   Prob(JB):                     1.90e-35
Kurtosis:                       7.143   Cond. No.                         26.5
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=0.68, p=0.496
Wilcoxon delta_H: statistic=4401.00, p=0.402
Mean H = 0.0295  [-0.0552, 0.1142]
Paired t-test delta_H Changed: statistic=4.45, p=3.41e-05
Wilcoxon delta_H Changed: statistic=450.00, p=1.68e-05
Mean H Changed = 0.2467  [0.1380, 0.3553]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=4.23, p=3.53e-05
Wilcoxon (p_top2_game vs p_top2_base): statistic=5799.00, p=2.2e-08
Mean p_top2 = 0.0165  [0.0088, 0.0241] (n=205)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=2.88, p=0.00447
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=7928.00, p=0.00199
Mean H_unchosen_baseline_set = 0.1005  [0.0320, 0.1689] (n=205)

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=6148.00, p=2.16e-07
Paired t-test (game_entropy vs capabilities_entropy): statistic=-5.30, p=2.96e-07
Mean capabilities_entropy-game_entropy = 0.1686  [0.1063, 0.2310] (n=205)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  205
Model:                          Logit   Df Residuals:                      202
Method:                           MLE   Df Model:                            2
Date:                Tue, 08 Jul 2025   Pseudo R-squ.:                  0.2020
Time:                        07:27:24   Log-Likelihood:                -103.37
converged:                       True   LL-Null:                       -129.54
Covariance Type:            nonrobust   LLR p-value:                 4.303e-12
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.6750      0.225     -3.005      0.003      -1.115      -0.235
p1_z            -1.3695      0.252     -5.430      0.000      -1.864      -0.875
I(p1_z ** 2)    -0.2584      0.185     -1.393      0.164      -0.622       0.105
================================================================================
AUC = 0.807

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  205
Model:                          Logit   Df Residuals:                      203
Method:                           MLE   Df Model:                            1
Date:                Tue, 08 Jul 2025   Pseudo R-squ.:                 0.07394
Time:                        07:27:24   Log-Likelihood:                -119.96
converged:                       True   LL-Null:                       -129.54
Covariance Type:            nonrobust   LLR p-value:                 1.205e-05
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.4666      0.244     -6.003      0.000      -1.945      -0.988
game_entropy     1.5334      0.363      4.228      0.000       0.823       2.244
================================================================================

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  205
Model:                          Logit   Df Residuals:                      202
Method:                           MLE   Df Model:                            2
Date:                Tue, 08 Jul 2025   Pseudo R-squ.:                  0.1784
Time:                        07:27:24   Log-Likelihood:                -106.43
converged:                       True   LL-Null:                       -129.54
Covariance Type:            nonrobust   LLR p-value:                 9.190e-11
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.4502      0.356     -6.888      0.000      -3.147      -1.753
capabilities_entropy     2.0590      0.424      4.852      0.000       1.227       2.891
game_entropy             0.6338      0.421      1.504      0.133      -0.192       1.460
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['Politics', 'Art', 'Geography', 'Other', 'Music', 'Sports', 'TV shows', 'Video games', 'History']
                  Grouped rare answer_type into 'Misc'/'Other': ['Number', 'Other', 'Place']
topic_grouped           answer_changed
Misc                    0                 0.703226
                        1                 0.296774
Science and technology  0                 0.580000
                        1                 0.420000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.691176
                     1                 0.308824
Misc                 0                 0.662500
                     1                 0.337500
Person               0                 0.666667
                     1                 0.333333
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Misc                   Date                 0.759259  0.240741           54
                       Misc                 0.696970  0.303030           66
                       Person               0.628571  0.371429           35
Science and technology Date                 0.428571  0.571429           14
                       Misc                 0.500000  0.500000           14
                       Person               0.727273  0.272727           22

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  205
Model:                          Logit   Df Residuals:                      200
Method:                           MLE   Df Model:                            4
Date:                Tue, 08 Jul 2025   Pseudo R-squ.:                 0.01194
Time:                        07:27:24   Log-Likelihood:                -128.00
converged:                       True   LL-Null:                       -129.54
Covariance Type:            nonrobust   LLR p-value:                    0.5425
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.9267      1.774     -1.086      0.277      -5.403       1.549
C(topic_grouped)[T.Science and technology]     0.5487      0.346      1.588      0.112      -0.129       1.226
C(answer_type_grouped)[T.Misc]                 0.1746      0.358      0.487      0.626      -0.528       0.877
C(answer_type_grouped)[T.Person]               0.0682      0.407      0.168      0.867      -0.729       0.866
q_length                                       0.2136      0.375      0.570      0.569      -0.521       0.948
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.6132
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  205
Model:                          Logit   Df Residuals:                      199
Method:                           MLE   Df Model:                            5
Date:                Tue, 08 Jul 2025   Pseudo R-squ.:                  0.1803
Time:                        07:27:24   Log-Likelihood:                -106.18
converged:                       True   LL-Null:                       -129.54
Covariance Type:            nonrobust   LLR p-value:                 6.469e-09
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -3.3068      1.988     -1.663      0.096      -7.204       0.590
C(topic_grouped)[T.Science and technology]     0.4437      0.393      1.129      0.259      -0.327       1.214
C(answer_type_grouped)[T.Misc]                 0.4086      0.403      1.015      0.310      -0.380       1.198
C(answer_type_grouped)[T.Person]               0.3859      0.458      0.842      0.400      -0.512       1.284
q_length                                       0.1331      0.416      0.320      0.749      -0.682       0.948
capabilities_entropy                           2.3276      0.395      5.896      0.000       1.554       3.101
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  205
Model:                          Logit   Df Residuals:                      199
Method:                           MLE   Df Model:                            5
Date:                Tue, 08 Jul 2025   Pseudo R-squ.:                 0.08468
Time:                        07:27:24   Log-Likelihood:                -118.57
converged:                       True   LL-Null:                       -129.54
Covariance Type:            nonrobust   LLR p-value:                 0.0005376
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -2.0007      1.825     -1.096      0.273      -5.578       1.577
C(topic_grouped)[T.Science and technology]     0.4248      0.366      1.161      0.246      -0.293       1.142
C(answer_type_grouped)[T.Misc]                 0.3612      0.380      0.951      0.341      -0.383       1.105
C(answer_type_grouped)[T.Person]               0.3767      0.437      0.863      0.388      -0.479       1.232
q_length                                       0.0341      0.388      0.088      0.930      -0.726       0.795
game_entropy                                   1.5786      0.378      4.179      0.000       0.838       2.319
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  205
Model:                          Logit   Df Residuals:                      198
Method:                           MLE   Df Model:                            6
Date:                Tue, 08 Jul 2025   Pseudo R-squ.:                  0.1899
Time:                        07:27:24   Log-Likelihood:                -104.94
converged:                       True   LL-Null:                       -129.54
Covariance Type:            nonrobust   LLR p-value:                 6.798e-09
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -3.2025      2.003     -1.599      0.110      -7.128       0.723
C(topic_grouped)[T.Science and technology]     0.3840      0.399      0.963      0.335      -0.397       1.165
C(answer_type_grouped)[T.Misc]                 0.4801      0.410      1.172      0.241      -0.323       1.283
C(answer_type_grouped)[T.Person]               0.4898      0.469      1.044      0.297      -0.430       1.410
q_length                                       0.0666      0.421      0.158      0.874      -0.759       0.892
capabilities_entropy                           2.0671      0.425      4.868      0.000       1.235       2.899
game_entropy                                   0.6832      0.435      1.572      0.116      -0.169       1.535
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.
