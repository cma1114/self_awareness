
--- Analyzing claude-3-5-sonnet-20241022 (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_neutral/claude-3-5-sonnet-20241022_SimpleMC_redacted_cor_temp0.0_1754440066_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    262
1     38
Name: count, dtype: int64

Answer change%: 0.1267 [0.08903021663391511, 0.16430311669941824] (n=300)
P-value vs 25%: 1.338e-10; P-value vs 0%: 4.215e-11
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=38)
P-value vs 25%: 0; P-value vs 33%: 0

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  300
Model:                          Logit   Df Residuals:                      298
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.2304
Time:                        17:34:06   Log-Likelihood:                -87.732
converged:                       True   LL-Null:                       -114.00
Covariance Type:            nonrobust   LLR p-value:                 4.225e-13
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          2.6491      0.669      3.961      0.000       1.338       3.960
p_i_capability    -6.5784      1.043     -6.307      0.000      -8.623      -4.534
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  300
Model:                          Logit   Df Residuals:                      298
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.2541
Time:                        17:34:06   Log-Likelihood:                -85.035
converged:                       True   LL-Null:                       -114.00
Covariance Type:            nonrobust   LLR p-value:                 2.716e-14
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -4.9464      0.623     -7.946      0.000      -6.166      -3.726
capabilities_entropy     2.7038      0.436      6.205      0.000       1.850       3.558
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.6842 [0.5364, 0.8320] (n=38)
                  P-value vs 33.3%: 3.268e-06

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=-0.55, p=0.583
Wilcoxon delta_p: statistic=8195.00, p=0.756
Mean Δp = -0.0049  [-0.0222, 0.0125]
Idea 1 N = 262; 

  Idea 1.5: Calibration Metrics
  NLL: 0.2738, Signed ECE (overconf pos under neg): -0.2103, ECE: 0.2103 (n=300)
  Brier: 0.0822, Reliability (absolute calibration error; lower better): 0.0817, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=300)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.534
Model:                            OLS   Adj. R-squared:                  0.529
Method:                 Least Squares   F-statistic:                     113.0
Date:                Sat, 09 Aug 2025   Prob (F-statistic):           8.92e-49
Time:                        17:34:06   Log-Likelihood:                 192.48
No. Observations:                 300   AIC:                            -377.0
Df Residuals:                     296   BIC:                            -362.1
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.2916      0.037     -7.800      0.000      -0.365      -0.218
p1                    0.3489      0.044      7.848      0.000       0.261       0.436
answer_changed        0.0760      0.087      0.872      0.384      -0.096       0.248
p1:answer_changed     0.6113      0.141      4.334      0.000       0.334       0.889
==============================================================================
Omnibus:                       24.447   Durbin-Watson:                   1.796
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               33.192
Skew:                           0.584   Prob(JB):                     6.20e-08
Kurtosis:                       4.136   Cond. No.                         28.8
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-0.34, p=0.733
Wilcoxon delta_H: statistic=8209.50, p=0.771
Mean ΔH = -0.0080  [-0.0540, 0.0380]
Paired t-test delta_H Changed: statistic=4.65, p=4.13e-05
Wilcoxon delta_H Changed: statistic=111.00, p=7.31e-05
Mean ΔH Changed = 0.2638  [0.1526, 0.3750]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=0.06, p=0.954
Wilcoxon (p_top2_game vs p_top2_base): statistic=12076.50, p=0.934
Mean Δp_top2 = 0.0002  [-0.0079, 0.0084] (n=300)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=1.18, p=0.237
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=10987.50, p=0.179
Mean ΔH_unchosen_baseline_set = 0.0264  [-0.0173, 0.0701] (n=300)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  300
Model:                          Logit   Df Residuals:                      297
Method:                           MLE   Df Model:                            2
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.2468
Time:                        17:34:06   Log-Likelihood:                -85.862
converged:                       True   LL-Null:                       -114.00
Covariance Type:            nonrobust   LLR p-value:                 6.023e-13
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -2.3693      0.304     -7.793      0.000      -2.965      -1.773
p1_z            -1.8807      0.415     -4.536      0.000      -2.693      -1.068
I(p1_z ** 2)    -0.4329      0.231     -1.878      0.060      -0.885       0.019
================================================================================
AUC = 0.847

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  300
Model:                          Logit   Df Residuals:                      298
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.2548
Time:                        17:34:06   Log-Likelihood:                -84.954
converged:                       True   LL-Null:                       -114.00
Covariance Type:            nonrobust   LLR p-value:                 2.502e-14
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -4.9094      0.613     -8.013      0.000      -6.110      -3.709
game_entropy     2.6930      0.431      6.253      0.000       1.849       3.537
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=12140.50, p=0.895
Paired t-test (game_entropy vs capabilities_entropy): statistic=-0.36, p=0.72
Mean capabilities_entropy-game_entropy = 0.0078  [-0.0348, 0.0505] (n=300)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  300
Model:                          Logit   Df Residuals:                      297
Method:                           MLE   Df Model:                            2
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.2930
Time:                        17:34:06   Log-Likelihood:                -80.597
converged:                       True   LL-Null:                       -114.00
Covariance Type:            nonrobust   LLR p-value:                 3.114e-15
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -5.4755      0.691     -7.919      0.000      -6.831      -4.120
capabilities_entropy     1.6207      0.567      2.856      0.004       0.509       2.733
game_entropy             1.5608      0.554      2.817      0.005       0.475       2.647
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.914894
                        1                 0.085106
Geography               0                 0.782609
                        1                 0.217391
Misc                    0                 0.857143
                        1                 0.142857
Music                   0                 0.791667
                        1                 0.208333
Other                   0                 0.843750
                        1                 0.156250
Politics                0                 0.880000
                        1                 0.120000
Science and technology  0                 0.923077
                        1                 0.076923
Sports                  0                 0.913043
                        1                 0.086957
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.810000
                     1                 0.190000
Number               0                 0.857143
                     1                 0.142857
Other                0                 0.909091
                     1                 0.090909
Person               0                 0.922078
                     1                 0.077922
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.900000  0.100000           10
                       Number               0.833333  0.166667            6
                       Other                0.916667  0.083333           12
                       Person               0.947368  0.052632           19
Geography              Date                 0.571429  0.428571            7
                       Number               0.888889  0.111111            9
                       Other                0.857143  0.142857            7
Misc                   Date                 0.750000  0.250000           16
                       Number               0.666667  0.333333            6
                       Other                1.000000  0.000000           17
                       Person               0.900000  0.100000           10
Music                  Date                 0.714286  0.285714            7
                       Other                0.714286  0.285714            7
                       Person               0.900000  0.100000           10
Other                  Date                 0.818182  0.181818           11
                       Number               1.000000  0.000000            2
                       Other                0.900000  0.100000           10
                       Person               0.777778  0.222222            9
Politics               Date                 0.818182  0.181818           22
                       Number               0.666667  0.333333            3
                       Other                0.937500  0.062500           16
                       Person               1.000000  0.000000            9
Science and technology Date                 0.850000  0.150000           20
                       Number               1.000000  0.000000            5
                       Other                0.923077  0.076923           13
                       Person               1.000000  0.000000           14
Sports                 Date                 1.000000  0.000000            7
                       Number               1.000000  0.000000            4
                       Other                0.833333  0.166667            6
                       Person               0.833333  0.166667            6

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  300
Model:                          Logit   Df Residuals:                      288
Method:                           MLE   Df Model:                           11
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.05219
Time:                        17:34:06   Log-Likelihood:                -108.05
converged:                       True   LL-Null:                       -114.00
Covariance Type:            nonrobust   LLR p-value:                    0.3712
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.6310      2.350     -0.694      0.488      -6.236       2.974
C(topic_grouped)[T.Geography]                  0.8666      0.758      1.143      0.253      -0.619       2.352
C(topic_grouped)[T.Misc]                       0.4651      0.674      0.690      0.490      -0.857       1.787
C(topic_grouped)[T.Music]                      1.0505      0.740      1.419      0.156      -0.401       2.502
C(topic_grouped)[T.Other]                      0.5905      0.726      0.813      0.416      -0.832       2.013
C(topic_grouped)[T.Politics]                   0.1860      0.715      0.260      0.795      -1.215       1.587
C(topic_grouped)[T.Science and technology]    -0.2778      0.752     -0.370      0.712      -1.751       1.195
C(topic_grouped)[T.Sports]                    -0.1051      0.916     -0.115      0.909      -1.900       1.690
C(answer_type_grouped)[T.Number]              -0.4042      0.580     -0.697      0.486      -1.541       0.733
C(answer_type_grouped)[T.Other]               -0.9149      0.458     -1.996      0.046      -1.813      -0.017
C(answer_type_grouped)[T.Person]              -1.0292      0.515     -2.000      0.045      -2.038      -0.021
q_length                                      -0.0265      0.510     -0.052      0.958      -1.026       0.973
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.8267
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  300
Model:                          Logit   Df Residuals:                      287
Method:                           MLE   Df Model:                           12
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.2807
Time:                        17:34:06   Log-Likelihood:                -82.000
converged:                       True   LL-Null:                       -114.00
Covariance Type:            nonrobust   LLR p-value:                 4.169e-09
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -6.3699      2.910     -2.189      0.029     -12.073      -0.667
C(topic_grouped)[T.Geography]                  0.6331      0.865      0.732      0.464      -1.062       2.328
C(topic_grouped)[T.Misc]                       0.2771      0.751      0.369      0.712      -1.196       1.750
C(topic_grouped)[T.Music]                      0.4887      0.848      0.576      0.564      -1.174       2.151
C(topic_grouped)[T.Other]                      0.2178      0.839      0.260      0.795      -1.427       1.863
C(topic_grouped)[T.Politics]                   0.2170      0.767      0.283      0.777      -1.287       1.721
C(topic_grouped)[T.Science and technology]    -0.3194      0.824     -0.388      0.698      -1.934       1.295
C(topic_grouped)[T.Sports]                    -0.0529      1.017     -0.052      0.959      -2.046       1.941
C(answer_type_grouped)[T.Number]              -0.9250      0.647     -1.430      0.153      -2.193       0.343
C(answer_type_grouped)[T.Other]               -0.5939      0.523     -1.137      0.256      -1.618       0.430
C(answer_type_grouped)[T.Person]              -0.7702      0.576     -1.337      0.181      -1.899       0.359
q_length                                       0.3763      0.602      0.625      0.532      -0.803       1.555
capabilities_entropy                           2.7023      0.460      5.872      0.000       1.800       3.604
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  300
Model:                          Logit   Df Residuals:                      287
Method:                           MLE   Df Model:                           12
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.2739
Time:                        17:34:06   Log-Likelihood:                -82.781
converged:                       True   LL-Null:                       -114.00
Covariance Type:            nonrobust   LLR p-value:                 8.082e-09
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -7.0874      3.083     -2.299      0.021     -13.129      -1.046
C(topic_grouped)[T.Geography]                  0.7669      0.843      0.909      0.363      -0.886       2.420
C(topic_grouped)[T.Misc]                       0.0823      0.770      0.107      0.915      -1.426       1.591
C(topic_grouped)[T.Music]                      0.1469      0.872      0.168      0.866      -1.562       1.856
C(topic_grouped)[T.Other]                      0.0386      0.813      0.048      0.962      -1.555       1.632
C(topic_grouped)[T.Politics]                   0.6545      0.797      0.821      0.411      -0.907       2.216
C(topic_grouped)[T.Science and technology]    -0.2724      0.859     -0.317      0.751      -1.955       1.411
C(topic_grouped)[T.Sports]                    -0.1263      0.994     -0.127      0.899      -2.074       1.821
C(answer_type_grouped)[T.Number]              -0.7074      0.634     -1.116      0.264      -1.949       0.535
C(answer_type_grouped)[T.Other]                0.1081      0.547      0.197      0.843      -0.964       1.181
C(answer_type_grouped)[T.Person]              -0.0358      0.597     -0.060      0.952      -1.206       1.135
q_length                                       0.4126      0.642      0.643      0.520      -0.845       1.670
game_entropy                                   2.8800      0.502      5.741      0.000       1.897       3.863
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  300
Model:                          Logit   Df Residuals:                      286
Method:                           MLE   Df Model:                           13
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.3145
Time:                        17:34:06   Log-Likelihood:                -78.151
converged:                       True   LL-Null:                       -114.00
Covariance Type:            nonrobust   LLR p-value:                 3.903e-10
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -7.9905      3.163     -2.526      0.012     -14.190      -1.791
C(topic_grouped)[T.Geography]                  0.6453      0.883      0.731      0.465      -1.085       2.376
C(topic_grouped)[T.Misc]                       0.0813      0.783      0.104      0.917      -1.453       1.615
C(topic_grouped)[T.Music]                      0.0648      0.902      0.072      0.943      -1.703       1.833
C(topic_grouped)[T.Other]                      0.0596      0.847      0.070      0.944      -1.601       1.720
C(topic_grouped)[T.Politics]                   0.5120      0.804      0.637      0.524      -1.064       2.088
C(topic_grouped)[T.Science and technology]    -0.3619      0.869     -0.416      0.677      -2.066       1.342
C(topic_grouped)[T.Sports]                    -0.1329      1.044     -0.127      0.899      -2.180       1.914
C(answer_type_grouped)[T.Number]              -0.9779      0.666     -1.468      0.142      -2.284       0.328
C(answer_type_grouped)[T.Other]               -0.1184      0.567     -0.209      0.835      -1.230       0.993
C(answer_type_grouped)[T.Person]              -0.2779      0.615     -0.452      0.651      -1.483       0.927
q_length                                       0.5307      0.647      0.820      0.412      -0.738       1.799
capabilities_entropy                           1.7216      0.585      2.941      0.003       0.574       2.869
game_entropy                                   1.6457      0.623      2.640      0.008       0.424       2.868
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing claude-3-5-sonnet-20241022 (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_neutral/claude-3-5-sonnet-20241022_SimpleMC_redacted_temp0.0_1754435021_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    131
1     69
Name: count, dtype: int64

Answer change%: 0.3450 [0.2791185285149779, 0.410881471485022] (n=200)
P-value vs 25%: 0.00471; P-value vs 0%: 1.027e-24
Phase 2 self-accuracy: 0.5507 [0.4333573413948548, 0.668091933967464] (n=69)
P-value vs 25%: 5.116e-07; P-value vs 33%: 0.000277

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  200
Model:                          Logit   Df Residuals:                      198
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1187
Time:                        17:34:06   Log-Likelihood:                -113.56
converged:                       True   LL-Null:                       -128.86
Covariance Type:            nonrobust   LLR p-value:                 3.176e-08
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          1.9998      0.530      3.772      0.000       0.961       3.039
p_i_capability    -4.5730      0.922     -4.958      0.000      -6.381      -2.765
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  200
Model:                          Logit   Df Residuals:                      198
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1033
Time:                        17:34:06   Log-Likelihood:                -115.54
converged:                       True   LL-Null:                       -128.86
Covariance Type:            nonrobust   LLR p-value:                 2.461e-07
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -3.0700      0.582     -5.278      0.000      -4.210      -1.930
capabilities_entropy     1.7342      0.379      4.580      0.000       0.992       2.476
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.6522 [0.5398, 0.7646] (n=69)
                  P-value vs 33.3%: 2.686e-08

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=0.10, p=0.921
Wilcoxon delta_p: statistic=3612.00, p=0.722
Mean Δp = 0.0014  [-0.0268, 0.0296]
Idea 1 N = 131; 

  Idea 1.5: Calibration Metrics
  NLL: 2.2591, Signed ECE (overconf pos under neg): 0.1590, ECE: 0.1590 (n=200)
  Brier: 0.0387, Reliability (absolute calibration error; lower better): 0.0380, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=200)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.614
Model:                            OLS   Adj. R-squared:                  0.608
Method:                 Least Squares   F-statistic:                     104.1
Date:                Sat, 09 Aug 2025   Prob (F-statistic):           2.46e-40
Time:                        17:34:06   Log-Likelihood:                 118.69
No. Observations:                 200   AIC:                            -229.4
Df Residuals:                     196   BIC:                            -216.2
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.2613      0.041     -6.437      0.000      -0.341      -0.181
p1                    0.3962      0.059      6.764      0.000       0.281       0.512
answer_changed        0.0600      0.067      0.896      0.372      -0.072       0.192
p1:answer_changed     0.5424      0.117      4.654      0.000       0.313       0.772
==============================================================================
Omnibus:                        0.357   Durbin-Watson:                   2.222
Prob(Omnibus):                  0.837   Jarque-Bera (JB):                0.507
Skew:                           0.040   Prob(JB):                        0.776
Kurtosis:                       2.767   Cond. No.                         18.2
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=2.25, p=0.0265
Wilcoxon delta_H: statistic=3176.00, p=0.0813
Mean ΔH = 0.0742  [0.0094, 0.1390]
Paired t-test delta_H Changed: statistic=8.07, p=1.63e-11
Wilcoxon delta_H Changed: statistic=109.00, p=5.1e-11
Mean ΔH Changed = 0.3663  [0.2773, 0.4552]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=3.28, p=0.00123
Wilcoxon (p_top2_game vs p_top2_base): statistic=7087.00, p=0.00343
Mean Δp_top2 = 0.0236  [0.0095, 0.0378] (n=200)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=6.16, p=3.98e-09
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=4956.00, p=1.44e-08
Mean ΔH_unchosen_baseline_set = 0.1750  [0.1193, 0.2306] (n=200)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  200
Model:                          Logit   Df Residuals:                      197
Method:                           MLE   Df Model:                            2
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1188
Time:                        17:34:06   Log-Likelihood:                -113.55
converged:                       True   LL-Null:                       -128.86
Covariance Type:            nonrobust   LLR p-value:                 2.249e-07
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.7586      0.236     -3.219      0.001      -1.220      -0.297
p1_z            -0.9299      0.189     -4.930      0.000      -1.300      -0.560
I(p1_z ** 2)    -0.0270      0.199     -0.135      0.892      -0.418       0.364
================================================================================
AUC = 0.730

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  200
Model:                          Logit   Df Residuals:                      198
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.03538
Time:                        17:34:06   Log-Likelihood:                -124.30
converged:                       True   LL-Null:                       -128.86
Covariance Type:            nonrobust   LLR p-value:                  0.002530
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.8963      0.472     -4.016      0.000      -2.822      -0.971
game_entropy     0.9680      0.334      2.894      0.004       0.312       1.624
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=7553.00, p=0.02
Paired t-test (game_entropy vs capabilities_entropy): statistic=-2.35, p=0.0196
Mean capabilities_entropy-game_entropy = 0.0645  [0.0108, 0.1183] (n=200)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  200
Model:                          Logit   Df Residuals:                      197
Method:                           MLE   Df Model:                            2
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1049
Time:                        17:34:06   Log-Likelihood:                -115.34
converged:                       True   LL-Null:                       -128.86
Covariance Type:            nonrobust   LLR p-value:                 1.339e-06
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.9559      0.604     -4.896      0.000      -4.139      -1.773
capabilities_entropy     1.9263      0.485      3.970      0.000       0.975       2.877
game_entropy            -0.2927      0.456     -0.642      0.521      -1.186       0.600
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'Video games', 'History']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.500000
                        1                 0.500000
Geography               0                 0.619048
                        1                 0.380952
Misc                    0                 0.840000
                        1                 0.160000
Music                   0                 0.812500
                        1                 0.187500
Other                   0                 0.650000
                        1                 0.350000
Politics                0                 0.666667
                        1                 0.333333
Science and technology  0                 0.630435
                        1                 0.369565
Sports                  0                 0.588235
                        1                 0.411765
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.550725
                     1                 0.449275
Number               0                 0.813953
                     1                 0.186047
Other                0                 0.711111
                     1                 0.288889
Person               0                 0.604651
                     1                 0.395349
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.363636  0.636364           11
                       Number               0.666667  0.333333            3
                       Other                0.833333  0.166667            6
                       Person               0.375000  0.625000            8
Geography              Date                 0.500000  0.500000            8
                       Number               0.777778  0.222222            9
                       Other                0.500000  0.500000            4
Misc                   Date                 0.857143  0.142857            7
                       Number               1.000000  0.000000            3
                       Other                0.800000  0.200000           10
                       Person               0.800000  0.200000            5
Music                  Date                 0.600000  0.400000            5
                       Number               1.000000  0.000000            4
                       Other                0.800000  0.200000            5
                       Person               1.000000  0.000000            2
Other                  Date                 0.571429  0.428571            7
                       Number               1.000000  0.000000            5
                       Other                0.500000  0.500000            4
                       Person               0.500000  0.500000            4
Politics               Date                 0.428571  0.571429           14
                       Number               1.000000  0.000000            3
                       Other                1.000000  0.000000            4
                       Person               0.833333  0.166667            6
Science and technology Date                 0.666667  0.333333           15
                       Number               0.555556  0.444444            9
                       Other                0.833333  0.166667            6
                       Person               0.562500  0.437500           16
Sports                 Date                 0.500000  0.500000            2
                       Number               0.857143  0.142857            7
                       Other                0.333333  0.666667            6
                       Person               0.500000  0.500000            2

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  200
Model:                          Logit   Df Residuals:                      188
Method:                           MLE   Df Model:                           11
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.07904
Time:                        17:34:06   Log-Likelihood:                -118.67
converged:                       True   LL-Null:                       -128.86
Covariance Type:            nonrobust   LLR p-value:                   0.04052
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -0.5005      1.962     -0.255      0.799      -4.347       3.346
C(topic_grouped)[T.Geography]                 -0.1351      0.629     -0.215      0.830      -1.367       1.097
C(topic_grouped)[T.Misc]                      -1.5966      0.676     -2.361      0.018      -2.922      -0.271
C(topic_grouped)[T.Music]                     -1.3022      0.763     -1.708      0.088      -2.797       0.193
C(topic_grouped)[T.Other]                     -0.4732      0.623     -0.759      0.448      -1.695       0.749
C(topic_grouped)[T.Politics]                  -0.8039      0.575     -1.399      0.162      -1.930       0.322
C(topic_grouped)[T.Science and technology]    -0.4838      0.501     -0.965      0.334      -1.466       0.499
C(topic_grouped)[T.Sports]                     0.1106      0.662      0.167      0.867      -1.187       1.408
C(answer_type_grouped)[T.Number]              -1.4687      0.492     -2.984      0.003      -2.433      -0.504
C(answer_type_grouped)[T.Other]               -0.6629      0.436     -1.522      0.128      -1.517       0.191
C(answer_type_grouped)[T.Person]              -0.2159      0.419     -0.516      0.606      -1.036       0.605
q_length                                       0.1890      0.420      0.450      0.653      -0.634       1.012
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 1.3228
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  200
Model:                          Logit   Df Residuals:                      187
Method:                           MLE   Df Model:                           12
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1693
Time:                        17:34:06   Log-Likelihood:                -107.04
converged:                       True   LL-Null:                       -128.86
Covariance Type:            nonrobust   LLR p-value:                 1.759e-05
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -2.2884      2.169     -1.055      0.292      -6.540       1.964
C(topic_grouped)[T.Geography]                 -0.3370      0.662     -0.509      0.611      -1.634       0.960
C(topic_grouped)[T.Misc]                      -1.5887      0.716     -2.218      0.027      -2.992      -0.185
C(topic_grouped)[T.Music]                     -1.1865      0.804     -1.477      0.140      -2.761       0.388
C(topic_grouped)[T.Other]                     -0.5332      0.681     -0.783      0.434      -1.868       0.801
C(topic_grouped)[T.Politics]                  -0.5239      0.630     -0.831      0.406      -1.759       0.711
C(topic_grouped)[T.Science and technology]    -0.5728      0.539     -1.062      0.288      -1.630       0.484
C(topic_grouped)[T.Sports]                    -0.0094      0.718     -0.013      0.990      -1.416       1.397
C(answer_type_grouped)[T.Number]              -1.1989      0.509     -2.356      0.018      -2.196      -0.201
C(answer_type_grouped)[T.Other]               -0.4084      0.465     -0.878      0.380      -1.320       0.503
C(answer_type_grouped)[T.Person]               0.3201      0.475      0.674      0.501      -0.611       1.251
q_length                                       0.0055      0.455      0.012      0.990      -0.886       0.897
capabilities_entropy                           1.7309      0.394      4.391      0.000       0.958       2.503
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  200
Model:                          Logit   Df Residuals:                      187
Method:                           MLE   Df Model:                           12
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1195
Time:                        17:34:06   Log-Likelihood:                -113.46
converged:                       True   LL-Null:                       -128.86
Covariance Type:            nonrobust   LLR p-value:                  0.002111
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -2.2073      2.110     -1.046      0.295      -6.343       1.928
C(topic_grouped)[T.Geography]                 -0.1222      0.649     -0.188      0.851      -1.394       1.149
C(topic_grouped)[T.Misc]                      -1.6507      0.694     -2.379      0.017      -3.011      -0.291
C(topic_grouped)[T.Music]                     -1.3551      0.778     -1.742      0.082      -2.880       0.170
C(topic_grouped)[T.Other]                     -0.5197      0.647     -0.803      0.422      -1.789       0.749
C(topic_grouped)[T.Politics]                  -0.6307      0.597     -1.056      0.291      -1.801       0.540
C(topic_grouped)[T.Science and technology]    -0.4703      0.517     -0.911      0.363      -1.483       0.542
C(topic_grouped)[T.Sports]                     0.1826      0.686      0.266      0.790      -1.162       1.527
C(answer_type_grouped)[T.Number]              -1.4429      0.502     -2.875      0.004      -2.427      -0.459
C(answer_type_grouped)[T.Other]               -0.5327      0.451     -1.180      0.238      -1.417       0.352
C(answer_type_grouped)[T.Person]               0.1145      0.449      0.255      0.799      -0.765       0.994
q_length                                       0.2216      0.434      0.511      0.610      -0.629       1.072
game_entropy                                   1.1084      0.359      3.090      0.002       0.405       1.811
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  200
Model:                          Logit   Df Residuals:                      186
Method:                           MLE   Df Model:                           13
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1693
Time:                        17:34:06   Log-Likelihood:                -107.04
converged:                       True   LL-Null:                       -128.86
Covariance Type:            nonrobust   LLR p-value:                 3.521e-05
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -2.2810      2.213     -1.031      0.303      -6.618       2.056
C(topic_grouped)[T.Geography]                 -0.3380      0.664     -0.509      0.611      -1.640       0.964
C(topic_grouped)[T.Misc]                      -1.5882      0.717     -2.216      0.027      -2.993      -0.184
C(topic_grouped)[T.Music]                     -1.1859      0.804     -1.474      0.140      -2.763       0.391
C(topic_grouped)[T.Other]                     -0.5330      0.681     -0.783      0.434      -1.868       0.802
C(topic_grouped)[T.Politics]                  -0.5243      0.631     -0.831      0.406      -1.761       0.712
C(topic_grouped)[T.Science and technology]    -0.5733      0.540     -1.061      0.289      -1.632       0.485
C(topic_grouped)[T.Sports]                    -0.0104      0.720     -0.014      0.989      -1.421       1.400
C(answer_type_grouped)[T.Number]              -1.1982      0.511     -2.346      0.019      -2.199      -0.197
C(answer_type_grouped)[T.Other]               -0.4085      0.465     -0.878      0.380      -1.320       0.503
C(answer_type_grouped)[T.Person]               0.3194      0.477      0.670      0.503      -0.615       1.254
q_length                                       0.0046      0.458      0.010      0.992      -0.893       0.902
capabilities_entropy                           1.7363      0.507      3.427      0.001       0.743       2.729
game_entropy                                  -0.0082      0.480     -0.017      0.986      -0.950       0.933
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing claude-3-haiku-20240307 (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_neutral/claude-3-haiku-20240307_SimpleMC_redacted_cor_temp0.0_1754426360_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    124
1     27
Name: count, dtype: int64

Answer change%: 0.1788 [0.11768906596126844, 0.23992682807846666] (n=151)
P-value vs 25%: 0.02243; P-value vs 0%: 9.808e-09
Phase 2 self-accuracy: 0.1481 [0.014150752226827906, 0.28214554406946835] (n=27)
P-value vs 25%: 0.1363; P-value vs 33%: 0.006855

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  151
Model:                          Logit   Df Residuals:                      149
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1165
Time:                        17:34:07   Log-Likelihood:                -62.643
converged:                       True   LL-Null:                       -70.907
Covariance Type:            nonrobust   LLR p-value:                 4.795e-05
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          3.5527      1.277      2.781      0.005       1.049       6.056
p_i_capability    -5.7869      1.457     -3.971      0.000      -8.643      -2.930
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  151
Model:                          Logit   Df Residuals:                      149
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1390
Time:                        17:34:07   Log-Likelihood:                -61.048
converged:                       True   LL-Null:                       -70.907
Covariance Type:            nonrobust   LLR p-value:                 8.980e-06
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -3.0787      0.458     -6.716      0.000      -3.977      -2.180
capabilities_entropy     3.1237      0.744      4.201      0.000       1.666       4.581
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.5556 [0.3681, 0.7430] (n=27)
                  P-value vs 33.3%: 0.02014

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=0.15, p=0.878
Wilcoxon delta_p: statistic=572.00, p=0.87
Mean Δp = 0.0014  [-0.0161, 0.0189]
Idea 1 N = 124; 

  Idea 1.5: Calibration Metrics
  NLL: 0.1291, Signed ECE (overconf pos under neg): -0.1033, ECE: 0.1033 (n=151)
  Brier: 0.0321, Reliability (absolute calibration error; lower better): 0.0319, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=151)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.869
Model:                            OLS   Adj. R-squared:                  0.867
Method:                 Least Squares   F-statistic:                     326.1
Date:                Sat, 09 Aug 2025   Prob (F-statistic):           9.78e-65
Time:                        17:34:07   Log-Likelihood:                 134.56
No. Observations:                 151   AIC:                            -261.1
Df Residuals:                     147   BIC:                            -249.0
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.5437      0.090     -6.071      0.000      -0.721      -0.367
p1                    0.5894      0.096      6.118      0.000       0.399       0.780
answer_changed        0.5158      0.122      4.232      0.000       0.275       0.757
p1:answer_changed     0.2352      0.139      1.691      0.093      -0.040       0.510
==============================================================================
Omnibus:                       26.219   Durbin-Watson:                   2.003
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               53.663
Skew:                           0.765   Prob(JB):                     2.22e-12
Kurtosis:                       5.488   Cond. No.                         35.4
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-0.47, p=0.638
Wilcoxon delta_H: statistic=517.50, p=0.469
Mean ΔH = -0.0230  [-0.1187, 0.0727]
Paired t-test delta_H Changed: statistic=5.29, p=1.56e-05
Wilcoxon delta_H Changed: statistic=35.00, p=0.000215
Mean ΔH Changed = 0.7751  [0.4880, 1.0622]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=-0.29, p=0.773
Wilcoxon (p_top2_game vs p_top2_base): statistic=1274.50, p=0.825
Mean Δp_top2 = -0.0008  [-0.0065, 0.0048] (n=151)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=2.23, p=0.0276
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=1034.00, p=0.0389
Mean ΔH_unchosen_baseline_set = 0.1197  [0.0143, 0.2251] (n=151)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  151
Model:                          Logit   Df Residuals:                      148
Method:                           MLE   Df Model:                            2
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1166
Time:                        17:34:07   Log-Likelihood:                -62.639
converged:                       True   LL-Null:                       -70.907
Covariance Type:            nonrobust   LLR p-value:                 0.0002567
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.6558      0.295     -5.607      0.000      -2.235      -1.077
p1_z            -0.7767      0.515     -1.507      0.132      -1.787       0.234
I(p1_z ** 2)    -0.0176      0.202     -0.087      0.930      -0.413       0.378
================================================================================
AUC = 0.674

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  151
Model:                          Logit   Df Residuals:                      149
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1458
Time:                        17:34:07   Log-Likelihood:                -60.566
converged:                       True   LL-Null:                       -70.907
Covariance Type:            nonrobust   LLR p-value:                 5.423e-06
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -3.0964      0.458     -6.764      0.000      -3.994      -2.199
game_entropy     2.9748      0.689      4.314      0.000       1.623       4.326
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=1140.50, p=0.33
Paired t-test (game_entropy vs capabilities_entropy): statistic=0.89, p=0.375
Mean capabilities_entropy-game_entropy = -0.0217  [-0.0695, 0.0261] (n=151)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  151
Model:                          Logit   Df Residuals:                      148
Method:                           MLE   Df Model:                            2
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.2058
Time:                        17:34:07   Log-Likelihood:                -56.315
converged:                       True   LL-Null:                       -70.907
Covariance Type:            nonrobust   LLR p-value:                 4.604e-07
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -3.9018      0.588     -6.640      0.000      -5.054      -2.750
capabilities_entropy     2.3286      0.796      2.926      0.003       0.769       3.889
game_entropy             2.3445      0.774      3.029      0.002       0.827       3.862
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['Video games', 'Sports', 'History', 'TV shows']
                  Grouped rare answer_type into 'Misc'/'Other': None
topic_grouped           answer_changed
Art                     0                 0.840000
                        1                 0.160000
Geography               0                 0.857143
                        1                 0.142857
Misc                    0                 0.851852
                        1                 0.148148
Music                   0                 1.000000
Other                   0                 0.714286
                        1                 0.285714
Politics                0                 0.739130
                        1                 0.260870
Science and technology  0                 0.833333
                        1                 0.166667
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.730769
                     1                 0.269231
Number               0                 0.866667
                     1                 0.133333
Other                0                 0.846154
                     1                 0.153846
Person               0                 0.870968
                     1                 0.129032
Place                0                 0.928571
                     1                 0.071429
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.666667  0.333333            6
                       Number               1.000000  0.000000            1
                       Other                0.800000  0.200000            5
                       Person               0.909091  0.090909           11
                       Place                1.000000  0.000000            2
Geography              Date                 1.000000  0.000000            2
                       Number               0.833333  0.166667            6
                       Other                1.000000  0.000000            3
                       Place                0.666667  0.333333            3
Misc                   Date                 0.777778  0.222222            9
                       Number               1.000000  0.000000            3
                       Other                0.750000  0.250000            8
                       Person               1.000000  0.000000            5
                       Place                1.000000  0.000000            2
Music                  Date                 1.000000  0.000000            5
                       Other                1.000000  0.000000            3
                       Person               1.000000  0.000000            3
Other                  Date                 0.800000  0.200000           10
                       Number               1.000000  0.000000            1
                       Other                0.500000  0.500000            4
                       Person               0.500000  0.500000            4
                       Place                1.000000  0.000000            2
Politics               Date                 0.500000  0.500000            8
                       Number               0.000000  1.000000            1
                       Other                1.000000  0.000000            6
                       Person               0.750000  0.250000            4
                       Place                1.000000  0.000000            4
Science and technology Date                 0.666667  0.333333           12
                       Number               1.000000  0.000000            3
                       Other                0.900000  0.100000           10
                       Person               1.000000  0.000000            4
                       Place                1.000000  0.000000            1

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  151
Model:                          Logit   Df Residuals:                      139
Method:                           MLE   Df Model:                           11
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1020
Time:                        17:34:07   Log-Likelihood:                -63.677
converged:                      False   LL-Null:                       -70.907
Covariance Type:            nonrobust   LLR p-value:                    0.2086
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      2.9720      2.894      1.027      0.304      -2.700       8.644
C(topic_grouped)[T.Geography]                 -0.0315      1.038     -0.030      0.976      -2.066       2.003
C(topic_grouped)[T.Misc]                      -0.1640      0.795     -0.206      0.837      -1.723       1.395
C(topic_grouped)[T.Music]                    -23.7330   8.83e+04     -0.000      1.000   -1.73e+05    1.73e+05
C(topic_grouped)[T.Other]                      0.5413      0.763      0.710      0.478      -0.954       2.036
C(topic_grouped)[T.Politics]                   0.8263      0.773      1.069      0.285      -0.688       2.341
C(topic_grouped)[T.Science and technology]     0.0315      0.779      0.040      0.968      -1.496       1.559
C(answer_type_grouped)[T.Number]              -0.6179      0.917     -0.674      0.500      -2.414       1.179
C(answer_type_grouped)[T.Other]               -0.8335      0.571     -1.459      0.145      -1.953       0.286
C(answer_type_grouped)[T.Person]              -0.9065      0.656     -1.381      0.167      -2.193       0.380
C(answer_type_grouped)[T.Place]               -1.6378      1.106     -1.480      0.139      -3.806       0.531
q_length                                      -0.9044      0.642     -1.410      0.159      -2.162       0.353
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.4401
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  151
Model:                          Logit   Df Residuals:                      138
Method:                           MLE   Df Model:                           12
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.2578
Time:                        17:34:07   Log-Likelihood:                -52.627
converged:                      False   LL-Null:                       -70.907
Covariance Type:            nonrobust   LLR p-value:                 0.0002633
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.3627      3.469     -0.393      0.694      -8.162       5.437
C(topic_grouped)[T.Geography]                 -0.5492      1.307     -0.420      0.674      -3.111       2.012
C(topic_grouped)[T.Misc]                      -0.3643      0.923     -0.395      0.693      -2.174       1.445
C(topic_grouped)[T.Music]                    -21.0662   1.23e+04     -0.002      0.999   -2.42e+04    2.42e+04
C(topic_grouped)[T.Other]                      0.3339      0.858      0.389      0.697      -1.348       2.016
C(topic_grouped)[T.Politics]                   0.6934      0.876      0.792      0.428      -1.023       2.410
C(topic_grouped)[T.Science and technology]    -0.2833      0.893     -0.317      0.751      -2.034       1.467
C(answer_type_grouped)[T.Number]              -1.5232      1.245     -1.223      0.221      -3.964       0.918
C(answer_type_grouped)[T.Other]               -0.6115      0.639     -0.957      0.338      -1.864       0.641
C(answer_type_grouped)[T.Person]              -0.8466      0.716     -1.182      0.237      -2.251       0.558
C(answer_type_grouped)[T.Place]               -2.4705      1.240     -1.993      0.046      -4.900      -0.041
q_length                                      -0.3238      0.744     -0.435      0.663      -1.782       1.134
capabilities_entropy                           4.0773      1.023      3.987      0.000       2.073       6.082
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  151
Model:                          Logit   Df Residuals:                      138
Method:                           MLE   Df Model:                           12
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.2496
Time:                        17:34:07   Log-Likelihood:                -53.206
converged:                      False   LL-Null:                       -70.907
Covariance Type:            nonrobust   LLR p-value:                 0.0004042
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -0.0286      3.222     -0.009      0.993      -6.343       6.286
C(topic_grouped)[T.Geography]                 -0.7856      1.289     -0.609      0.542      -3.312       1.741
C(topic_grouped)[T.Misc]                      -0.5829      0.892     -0.654      0.513      -2.331       1.165
C(topic_grouped)[T.Music]                    -18.3050   2651.326     -0.007      0.994   -5214.808    5178.198
C(topic_grouped)[T.Other]                     -0.0866      0.834     -0.104      0.917      -1.722       1.548
C(topic_grouped)[T.Politics]                   0.6287      0.833      0.755      0.451      -1.005       2.262
C(topic_grouped)[T.Science and technology]    -0.5222      0.862     -0.606      0.544      -2.211       1.166
C(answer_type_grouped)[T.Number]              -0.7824      1.170     -0.669      0.504      -3.076       1.511
C(answer_type_grouped)[T.Other]               -0.6455      0.639     -1.010      0.313      -1.898       0.608
C(answer_type_grouped)[T.Person]              -0.7995      0.713     -1.122      0.262      -2.196       0.597
C(answer_type_grouped)[T.Place]               -1.6741      1.205     -1.389      0.165      -4.036       0.688
q_length                                      -0.5624      0.703     -0.800      0.424      -1.941       0.816
game_entropy                                   3.4527      0.812      4.251      0.000       1.861       5.045
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  151
Model:                          Logit   Df Residuals:                      137
Method:                           MLE   Df Model:                           13
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.3349
Time:                        17:34:07   Log-Likelihood:                -47.159
converged:                      False   LL-Null:                       -70.907
Covariance Type:            nonrobust   LLR p-value:                 7.967e-06
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -2.8929      3.632     -0.796      0.426     -10.012       4.226
C(topic_grouped)[T.Geography]                 -1.0376      1.577     -0.658      0.511      -4.129       2.054
C(topic_grouped)[T.Misc]                      -0.5456      0.979     -0.557      0.578      -2.465       1.374
C(topic_grouped)[T.Music]                    -34.2216   5.72e+06  -5.98e-06      1.000   -1.12e+07    1.12e+07
C(topic_grouped)[T.Other]                     -0.0279      0.887     -0.032      0.975      -1.766       1.710
C(topic_grouped)[T.Politics]                   0.7056      0.923      0.764      0.445      -1.104       2.515
C(topic_grouped)[T.Science and technology]    -0.5079      0.921     -0.552      0.581      -2.313       1.297
C(answer_type_grouped)[T.Number]              -1.6992      1.532     -1.109      0.267      -4.702       1.304
C(answer_type_grouped)[T.Other]               -0.5018      0.685     -0.733      0.464      -1.844       0.841
C(answer_type_grouped)[T.Person]              -0.7951      0.739     -1.076      0.282      -2.244       0.653
C(answer_type_grouped)[T.Place]               -2.7209      1.421     -1.915      0.055      -5.505       0.063
q_length                                      -0.2151      0.773     -0.278      0.781      -1.730       1.299
capabilities_entropy                           3.4250      1.119      3.061      0.002       1.232       5.618
game_entropy                                   2.8916      0.903      3.200      0.001       1.121       4.662
==============================================================================================================

                  Model 6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length (after removing deterministic categories: defaultdict(<class 'list'>, {'topic_grouped': ['Music']}))
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  140
Model:                          Logit   Df Residuals:                      129
Method:                           MLE   Df Model:                           10
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.07241
Time:                        17:34:07   Log-Likelihood:                -63.677
converged:                       True   LL-Null:                       -68.648
Covariance Type:            nonrobust   LLR p-value:                    0.4456
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      2.9720      2.894      1.027      0.304      -2.700       8.644
C(topic_grouped)[T.Geography]                 -0.0315      1.038     -0.030      0.976      -2.066       2.003
C(topic_grouped)[T.Misc]                      -0.1640      0.795     -0.206      0.837      -1.723       1.395
C(topic_grouped)[T.Other]                      0.5413      0.763      0.710      0.478      -0.954       2.036
C(topic_grouped)[T.Politics]                   0.8263      0.773      1.069      0.285      -0.688       2.341
C(topic_grouped)[T.Science and technology]     0.0315      0.779      0.040      0.968      -1.496       1.559
C(answer_type_grouped)[T.Number]              -0.6179      0.917     -0.674      0.500      -2.414       1.179
C(answer_type_grouped)[T.Other]               -0.8335      0.571     -1.459      0.145      -1.953       0.286
C(answer_type_grouped)[T.Person]              -0.9065      0.656     -1.381      0.167      -2.193       0.380
C(answer_type_grouped)[T.Place]               -1.6378      1.106     -1.480      0.139      -3.806       0.531
q_length                                      -0.9044      0.642     -1.410      0.159      -2.162       0.353
==============================================================================================================

                  Model 6.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  140
Model:                          Logit   Df Residuals:                      128
Method:                           MLE   Df Model:                           11
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.2334
Time:                        17:34:07   Log-Likelihood:                -52.627
converged:                       True   LL-Null:                       -68.648
Covariance Type:            nonrobust   LLR p-value:                 0.0007514
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.3627      3.469     -0.393      0.694      -8.162       5.437
C(topic_grouped)[T.Geography]                 -0.5492      1.307     -0.420      0.674      -3.111       2.012
C(topic_grouped)[T.Misc]                      -0.3643      0.923     -0.395      0.693      -2.174       1.445
C(topic_grouped)[T.Other]                      0.3339      0.858      0.389      0.697      -1.348       2.016
C(topic_grouped)[T.Politics]                   0.6934      0.876      0.792      0.428      -1.023       2.410
C(topic_grouped)[T.Science and technology]    -0.2833      0.893     -0.317      0.751      -2.034       1.467
C(answer_type_grouped)[T.Number]              -1.5232      1.245     -1.223      0.221      -3.964       0.918
C(answer_type_grouped)[T.Other]               -0.6115      0.639     -0.957      0.338      -1.864       0.641
C(answer_type_grouped)[T.Person]              -0.8466      0.716     -1.182      0.237      -2.251       0.558
C(answer_type_grouped)[T.Place]               -2.4705      1.240     -1.993      0.046      -4.900      -0.041
q_length                                      -0.3238      0.744     -0.435      0.663      -1.782       1.134
capabilities_entropy                           4.0773      1.023      3.987      0.000       2.073       6.082
==============================================================================================================

--- Analyzing claude-3-haiku-20240307 (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_neutral/claude-3-haiku-20240307_SimpleMC_redacted_temp0.0_1754368901_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    268
1     81
Name: count, dtype: int64

Answer change%: 0.2321 [0.18780024475464002, 0.2763831363341852] (n=349)
P-value vs 25%: 0.4281; P-value vs 0%: 9.58e-25
Phase 2 self-accuracy: 0.4815 [0.3726693014451997, 0.5902936615177632] (n=81)
P-value vs 25%: 3.052e-05; P-value vs 33%: 0.007484

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  349
Model:                          Logit   Df Residuals:                      347
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.07032
Time:                        17:34:07   Log-Likelihood:                -175.79
converged:                       True   LL-Null:                       -189.09
Covariance Type:            nonrobust   LLR p-value:                 2.513e-07
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          2.9155      0.809      3.603      0.000       1.329       4.502
p_i_capability    -4.6346      0.908     -5.102      0.000      -6.415      -2.854
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  349
Model:                          Logit   Df Residuals:                      347
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.07144
Time:                        17:34:07   Log-Likelihood:                -175.58
converged:                       True   LL-Null:                       -189.09
Covariance Type:            nonrobust   LLR p-value:                 2.016e-07
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.2038      0.244     -9.019      0.000      -2.683      -1.725
capabilities_entropy     2.1052      0.411      5.117      0.000       1.299       2.912
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.5062 [0.3973, 0.6151] (n=81)
                  P-value vs 33.3%: 0.001862

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=2.81, p=0.0054
Wilcoxon delta_p: statistic=2885.00, p=0.00211
Mean Δp = 0.0227  [0.0068, 0.0386]
Idea 1 N = 268; 

  Idea 1.5: Calibration Metrics
  NLL: 4.1953, Signed ECE (overconf pos under neg): 0.0394, ECE: 0.0394 (n=349)
  Brier: 0.0097, Reliability (absolute calibration error; lower better): 0.0095, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=349)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.869
Model:                            OLS   Adj. R-squared:                  0.867
Method:                 Least Squares   F-statistic:                     760.4
Date:                Sat, 09 Aug 2025   Prob (F-statistic):          1.20e-151
Time:                        17:34:07   Log-Likelihood:                 253.87
No. Observations:                 349   AIC:                            -499.7
Df Residuals:                     345   BIC:                            -484.3
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.6231      0.069     -8.980      0.000      -0.760      -0.487
p1                    0.6993      0.075      9.358      0.000       0.552       0.846
answer_changed        0.5712      0.093      6.150      0.000       0.389       0.754
p1:answer_changed     0.1976      0.104      1.900      0.058      -0.007       0.402
==============================================================================
Omnibus:                       99.452   Durbin-Watson:                   2.114
Prob(Omnibus):                  0.000   Jarque-Bera (JB):              250.869
Skew:                           1.370   Prob(JB):                     3.35e-55
Kurtosis:                       6.121   Cond. No.                         35.6
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=1.73, p=0.085
Wilcoxon delta_H: statistic=3483.00, p=0.0953
Mean ΔH = 0.0618  [-0.0083, 0.1319]
Paired t-test delta_H Changed: statistic=8.21, p=3.09e-12
Wilcoxon delta_H Changed: statistic=393.00, p=2.39e-09
Mean ΔH Changed = 0.6737  [0.5129, 0.8344]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=-4.52, p=8.34e-06
Wilcoxon (p_top2_game vs p_top2_base): statistic=7335.50, p=0.000651
Mean Δp_top2 = -0.0137  [-0.0196, -0.0077] (n=349)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=5.64, p=3.43e-08
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=6375.50, p=9.63e-08
Mean ΔH_unchosen_baseline_set = 0.2038  [0.1330, 0.2746] (n=349)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  349
Model:                          Logit   Df Residuals:                      346
Method:                           MLE   Df Model:                            2
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.07308
Time:                        17:34:07   Log-Likelihood:                -175.27
converged:                       True   LL-Null:                       -189.09
Covariance Type:            nonrobust   LLR p-value:                 9.973e-07
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.4122      0.198     -7.130      0.000      -1.800      -1.024
p1_z            -0.2495      0.357     -0.699      0.484      -0.949       0.450
I(p1_z ** 2)     0.1522      0.153      0.995      0.320      -0.148       0.452
================================================================================
AUC = 0.644

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  349
Model:                          Logit   Df Residuals:                      347
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1260
Time:                        17:34:07   Log-Likelihood:                -165.26
converged:                       True   LL-Null:                       -189.09
Covariance Type:            nonrobust   LLR p-value:                 5.109e-12
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -2.5147      0.255     -9.845      0.000      -3.015      -2.014
game_entropy     2.1041      0.323      6.521      0.000       1.472       2.737
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=5887.50, p=2.42e-07
Paired t-test (game_entropy vs capabilities_entropy): statistic=5.18, p=3.7e-07
Mean capabilities_entropy-game_entropy = -0.1161  [-0.1600, -0.0722] (n=349)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  349
Model:                          Logit   Df Residuals:                      346
Method:                           MLE   Df Model:                            2
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1616
Time:                        17:34:07   Log-Likelihood:                -158.52
converged:                       True   LL-Null:                       -189.09
Covariance Type:            nonrobust   LLR p-value:                 5.332e-14
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -3.1663      0.331     -9.556      0.000      -3.816      -2.517
capabilities_entropy     1.6661      0.453      3.681      0.000       0.779       2.553
game_entropy             1.8879      0.335      5.643      0.000       1.232       2.544
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.740000
                        1                 0.260000
Geography               0                 0.800000
                        1                 0.200000
Misc                    0                 0.800000
                        1                 0.200000
Music                   0                 0.758621
                        1                 0.241379
Other                   0                 0.806452
                        1                 0.193548
Politics                0                 0.814815
                        1                 0.185185
Science and technology  0                 0.720588
                        1                 0.279412
Sports                  0                 0.750000
                        1                 0.250000
TV shows                0                 0.760000
                        1                 0.240000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.786325
                     1                 0.213675
Number               0                 0.746032
                     1                 0.253968
Other                0                 0.762500
                     1                 0.237500
Person               0                 0.764045
                     1                 0.235955
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.733333  0.266667           15
                       Number               0.750000  0.250000            8
                       Other                0.636364  0.363636           11
                       Person               0.812500  0.187500           16
Geography              Date                 0.846154  0.153846           13
                       Number               0.750000  0.250000           12
                       Other                0.800000  0.200000            5
Misc                   Date                 0.615385  0.384615           13
                       Number               1.000000  0.000000            5
                       Other                1.000000  0.000000            7
                       Person               0.800000  0.200000            5
Music                  Date                 0.571429  0.428571            7
                       Number               1.000000  0.000000            4
                       Other                0.777778  0.222222            9
                       Person               0.777778  0.222222            9
Other                  Date                 1.000000  0.000000            8
                       Number               0.833333  0.166667            6
                       Other                0.625000  0.375000            8
                       Person               0.777778  0.222222            9
Politics               Date                 0.821429  0.178571           28
                       Number               0.800000  0.200000            5
                       Other                0.900000  0.100000           10
                       Person               0.727273  0.272727           11
Science and technology Date                 0.826087  0.173913           23
                       Number               0.454545  0.545455           11
                       Other                0.750000  0.250000            8
                       Person               0.730769  0.269231           26
Sports                 Date                 1.000000  0.000000            8
                       Number               0.727273  0.272727           11
                       Other                0.555556  0.444444            9
                       Person               0.750000  0.250000            4
TV shows               Date                 0.000000  1.000000            2
                       Number               1.000000  0.000000            1
                       Other                0.846154  0.153846           13
                       Person               0.777778  0.222222            9

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  349
Model:                          Logit   Df Residuals:                      336
Method:                           MLE   Df Model:                           12
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.01483
Time:                        17:34:07   Log-Likelihood:                -186.28
converged:                       True   LL-Null:                       -189.09
Covariance Type:            nonrobust   LLR p-value:                    0.9345
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -3.7329      1.605     -2.326      0.020      -6.879      -0.587
C(topic_grouped)[T.Geography]                 -0.3320      0.575     -0.577      0.564      -1.459       0.795
C(topic_grouped)[T.Misc]                      -0.3772      0.563     -0.669      0.503      -1.481       0.727
C(topic_grouped)[T.Music]                     -0.0610      0.544     -0.112      0.911      -1.127       1.005
C(topic_grouped)[T.Other]                     -0.3763      0.559     -0.673      0.501      -1.472       0.720
C(topic_grouped)[T.Politics]                  -0.5354      0.489     -1.095      0.274      -1.494       0.423
C(topic_grouped)[T.Science and technology]     0.0799      0.424      0.188      0.851      -0.752       0.911
C(topic_grouped)[T.Sports]                    -0.1252      0.530     -0.236      0.813      -1.164       0.913
C(topic_grouped)[T.TV shows]                  -0.0588      0.582     -0.101      0.920      -1.199       1.081
C(answer_type_grouped)[T.Number]               0.2032      0.380      0.535      0.593      -0.541       0.947
C(answer_type_grouped)[T.Other]                0.1535      0.363      0.423      0.672      -0.557       0.864
C(answer_type_grouped)[T.Person]               0.1089      0.352      0.309      0.757      -0.581       0.799
q_length                                       0.5760      0.342      1.682      0.093      -0.095       1.247
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.4433
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  349
Model:                          Logit   Df Residuals:                      335
Method:                           MLE   Df Model:                           13
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.08910
Time:                        17:34:07   Log-Likelihood:                -172.24
converged:                       True   LL-Null:                       -189.09
Covariance Type:            nonrobust   LLR p-value:                  0.001339
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -5.4930      1.746     -3.146      0.002      -8.916      -2.070
C(topic_grouped)[T.Geography]                 -0.2437      0.600     -0.406      0.685      -1.421       0.933
C(topic_grouped)[T.Misc]                      -0.4428      0.592     -0.748      0.455      -1.603       0.718
C(topic_grouped)[T.Music]                     -0.1573      0.582     -0.270      0.787      -1.298       0.983
C(topic_grouped)[T.Other]                     -0.4361      0.587     -0.742      0.458      -1.587       0.715
C(topic_grouped)[T.Politics]                  -0.4660      0.508     -0.918      0.359      -1.461       0.529
C(topic_grouped)[T.Science and technology]     0.0574      0.446      0.129      0.898      -0.816       0.931
C(topic_grouped)[T.Sports]                    -0.2828      0.563     -0.503      0.615      -1.386       0.820
C(topic_grouped)[T.TV shows]                  -0.0700      0.607     -0.115      0.908      -1.260       1.120
C(answer_type_grouped)[T.Number]               0.3105      0.401      0.775      0.439      -0.475       1.096
C(answer_type_grouped)[T.Other]                0.2260      0.379      0.596      0.551      -0.517       0.969
C(answer_type_grouped)[T.Person]               0.2913      0.375      0.778      0.437      -0.443       1.026
q_length                                       0.7181      0.363      1.978      0.048       0.007       1.430
capabilities_entropy                           2.2015      0.425      5.178      0.000       1.368       3.035
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  349
Model:                          Logit   Df Residuals:                      335
Method:                           MLE   Df Model:                           13
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1465
Time:                        17:34:07   Log-Likelihood:                -161.39
converged:                       True   LL-Null:                       -189.09
Covariance Type:            nonrobust   LLR p-value:                 3.452e-07
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -5.8667      1.796     -3.267      0.001      -9.387      -2.347
C(topic_grouped)[T.Geography]                 -0.1868      0.626     -0.298      0.765      -1.415       1.041
C(topic_grouped)[T.Misc]                      -0.1322      0.613     -0.216      0.829      -1.334       1.069
C(topic_grouped)[T.Music]                      0.1613      0.607      0.266      0.790      -1.028       1.351
C(topic_grouped)[T.Other]                     -0.0813      0.600     -0.135      0.892      -1.258       1.095
C(topic_grouped)[T.Politics]                  -0.4175      0.538     -0.776      0.438      -1.471       0.636
C(topic_grouped)[T.Science and technology]     0.4270      0.469      0.909      0.363      -0.493       1.347
C(topic_grouped)[T.Sports]                    -0.1568      0.608     -0.258      0.796      -1.348       1.034
C(topic_grouped)[T.TV shows]                  -0.1697      0.654     -0.259      0.795      -1.452       1.112
C(answer_type_grouped)[T.Number]               0.2270      0.414      0.548      0.584      -0.584       1.038
C(answer_type_grouped)[T.Other]                0.4089      0.399      1.024      0.306      -0.374       1.192
C(answer_type_grouped)[T.Person]               0.0094      0.387      0.024      0.981      -0.750       0.769
q_length                                       0.6964      0.376      1.850      0.064      -0.041       1.434
game_entropy                                   2.2248      0.339      6.569      0.000       1.561       2.889
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  349
Model:                          Logit   Df Residuals:                      334
Method:                           MLE   Df Model:                           14
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1828
Time:                        17:34:07   Log-Likelihood:                -154.52
converged:                       True   LL-Null:                       -189.09
Covariance Type:            nonrobust   LLR p-value:                 2.764e-09
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -6.9830      1.880     -3.714      0.000     -10.668      -3.298
C(topic_grouped)[T.Geography]                 -0.1412      0.642     -0.220      0.826      -1.399       1.116
C(topic_grouped)[T.Misc]                      -0.2319      0.628     -0.369      0.712      -1.462       0.998
C(topic_grouped)[T.Music]                      0.0530      0.609      0.087      0.931      -1.141       1.247
C(topic_grouped)[T.Other]                     -0.1822      0.623     -0.292      0.770      -1.403       1.039
C(topic_grouped)[T.Politics]                  -0.3802      0.542     -0.702      0.483      -1.442       0.681
C(topic_grouped)[T.Science and technology]     0.3906      0.474      0.825      0.410      -0.538       1.319
C(topic_grouped)[T.Sports]                    -0.3300      0.625     -0.528      0.598      -1.556       0.896
C(topic_grouped)[T.TV shows]                  -0.1752      0.674     -0.260      0.795      -1.495       1.145
C(answer_type_grouped)[T.Number]               0.3070      0.423      0.725      0.468      -0.523       1.137
C(answer_type_grouped)[T.Other]                0.4143      0.402      1.030      0.303      -0.374       1.203
C(answer_type_grouped)[T.Person]               0.1241      0.400      0.310      0.757      -0.661       0.909
q_length                                       0.7920      0.387      2.048      0.041       0.034       1.550
capabilities_entropy                           1.7437      0.473      3.690      0.000       0.818       2.670
game_entropy                                   1.9898      0.349      5.698      0.000       1.305       2.674
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing claude-3-sonnet-20240229 (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_neutral/claude-3-sonnet-20240229_SimpleMC_redacted_cor_temp0.0_1751845655_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    69
1    34
Name: count, dtype: int64

Answer change%: 0.3301 [0.23928236537365372, 0.4209118093836279] (n=103)
P-value vs 25%: 0.08387; P-value vs 0%: 1.047e-12
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=47)
P-value vs 25%: 0; P-value vs 33%: 0

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  103
Model:                          Logit   Df Residuals:                      101
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.3154
Time:                        17:34:07   Log-Likelihood:                -44.726
converged:                       True   LL-Null:                       -65.327
Covariance Type:            nonrobust   LLR p-value:                 1.373e-10
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          4.8837      1.075      4.543      0.000       2.777       6.991
p_i_capability    -8.5969      1.702     -5.052      0.000     -11.932      -5.262
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  103
Model:                          Logit   Df Residuals:                      101
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.3088
Time:                        17:34:07   Log-Likelihood:                -45.154
converged:                       True   LL-Null:                       -65.327
Covariance Type:            nonrobust   LLR p-value:                 2.127e-10
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -5.1415      1.062     -4.840      0.000      -7.224      -3.059
capabilities_entropy     3.6820      0.782      4.707      0.000       2.149       5.215
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.3529 [0.1923, 0.5136] (n=34)
                  P-value vs 33.3%: 0.8109
                  Grouped rare topic into 'Misc'/'Other': ['History', 'Video games', 'TV shows']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.625000
                        1                 0.375000
Geography               0                 0.636364
                        1                 0.363636
Misc                    0                 0.900000
                        1                 0.100000
Music                   0                 0.777778
                        1                 0.222222
Other                   0                 1.000000
Politics                0                 0.642857
                        1                 0.357143
Science and technology  0                 0.571429
                        1                 0.428571
Sports                  1                 0.571429
                        0                 0.428571
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.615385
                     1                 0.384615
Number               0                 0.500000
                     1                 0.500000
Other                0                 0.807692
                     1                 0.192308
Person               0                 0.727273
                     1                 0.272727
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.500000  0.500000            6
                       Number               0.333333  0.666667            3
                       Other                0.750000  0.250000            4
                       Person               0.727273  0.272727           11
Geography              Date                 0.666667  0.333333            3
                       Number               0.600000  0.400000            5
                       Other                0.666667  0.333333            3
Misc                   Date                 0.833333  0.166667            6
                       Number               1.000000  0.000000            2
                       Other                1.000000  0.000000            2
Music                  Date                 1.000000  0.000000            3
                       Number               0.000000  1.000000            1
                       Other                0.666667  0.333333            3
                       Person               1.000000  0.000000            2
Other                  Date                 1.000000  0.000000            3
                       Other                1.000000  0.000000            3
                       Person               1.000000  0.000000            1
Politics               Date                 0.428571  0.571429            7
                       Other                0.800000  0.200000            5
                       Person               1.000000  0.000000            2
Science and technology Date                 0.500000  0.500000           10
                       Number               0.500000  0.500000            4
                       Other                1.000000  0.000000            4
                       Person               0.333333  0.666667            3
Sports                 Date                 0.000000  1.000000            1
                       Number               0.000000  1.000000            1
                       Other                0.500000  0.500000            2
                       Person               0.666667  0.333333            3

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  103
Model:                          Logit   Df Residuals:                       91
Method:                           MLE   Df Model:                           11
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1663
Time:                        17:34:07   Log-Likelihood:                -54.464
converged:                      False   LL-Null:                       -65.327
Covariance Type:            nonrobust   LLR p-value:                   0.02657
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      5.1743      3.051      1.696      0.090      -0.805      11.154
C(topic_grouped)[T.Geography]                 -0.5763      0.856     -0.673      0.501      -2.255       1.102
C(topic_grouped)[T.Misc]                      -2.3681      1.203     -1.969      0.049      -4.726      -0.010
C(topic_grouped)[T.Music]                     -1.1096      1.003     -1.106      0.269      -3.076       0.857
C(topic_grouped)[T.Other]                    -37.9069   7.91e+07  -4.79e-07      1.000   -1.55e+08    1.55e+08
C(topic_grouped)[T.Politics]                   0.1082      0.782      0.138      0.890      -1.423       1.640
C(topic_grouped)[T.Science and technology]     0.0410      0.686      0.060      0.952      -1.303       1.385
C(topic_grouped)[T.Sports]                     0.9372      0.935      1.003      0.316      -0.895       2.769
C(answer_type_grouped)[T.Number]               0.4844      0.689      0.703      0.482      -0.867       1.835
C(answer_type_grouped)[T.Other]               -1.3536      0.668     -2.026      0.043      -2.663      -0.044
C(answer_type_grouped)[T.Person]              -1.2966      0.697     -1.862      0.063      -2.662       0.069
q_length                                      -1.1179      0.658     -1.700      0.089      -2.407       0.171
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 1.0570
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  103
Model:                          Logit   Df Residuals:                       90
Method:                           MLE   Df Model:                           12
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.4163
Time:                        17:34:07   Log-Likelihood:                -38.135
converged:                      False   LL-Null:                       -65.327
Covariance Type:            nonrobust   LLR p-value:                 2.332e-07
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      1.5377      3.665      0.420      0.675      -5.645       8.720
C(topic_grouped)[T.Geography]                  0.1693      1.046      0.162      0.871      -1.882       2.220
C(topic_grouped)[T.Misc]                      -1.8408      1.289     -1.428      0.153      -4.367       0.686
C(topic_grouped)[T.Music]                     -0.0480      1.259     -0.038      0.970      -2.515       2.419
C(topic_grouped)[T.Other]                    -23.1086   7.74e+04     -0.000      1.000   -1.52e+05    1.52e+05
C(topic_grouped)[T.Politics]                   1.2313      1.054      1.168      0.243      -0.834       3.297
C(topic_grouped)[T.Science and technology]     0.6756      0.868      0.778      0.437      -1.026       2.377
C(topic_grouped)[T.Sports]                     1.1261      1.097      1.026      0.305      -1.024       3.276
C(answer_type_grouped)[T.Number]               0.5467      0.862      0.634      0.526      -1.142       2.236
C(answer_type_grouped)[T.Other]               -0.6182      0.867     -0.713      0.476      -2.317       1.080
C(answer_type_grouped)[T.Person]              -0.8388      0.813     -1.031      0.302      -2.433       0.755
q_length                                      -1.5752      0.822     -1.917      0.055      -3.185       0.035
capabilities_entropy                           3.9775      0.961      4.139      0.000       2.094       5.861
==============================================================================================================

                  Model 6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length (after removing deterministic categories: defaultdict(<class 'list'>, {'topic_grouped': ['Other']}))
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                   96
Model:                          Logit   Df Residuals:                       85
Method:                           MLE   Df Model:                           10
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1272
Time:                        17:34:07   Log-Likelihood:                -54.464
converged:                       True   LL-Null:                       -62.399
Covariance Type:            nonrobust   LLR p-value:                    0.1034
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      5.1743      3.051      1.696      0.090      -0.805      11.154
C(topic_grouped)[T.Geography]                 -0.5763      0.856     -0.673      0.501      -2.255       1.102
C(topic_grouped)[T.Misc]                      -2.3681      1.203     -1.969      0.049      -4.726      -0.010
C(topic_grouped)[T.Music]                     -1.1096      1.003     -1.106      0.269      -3.076       0.857
C(topic_grouped)[T.Politics]                   0.1082      0.782      0.138      0.890      -1.423       1.640
C(topic_grouped)[T.Science and technology]     0.0410      0.686      0.060      0.952      -1.303       1.385
C(topic_grouped)[T.Sports]                     0.9372      0.935      1.003      0.316      -0.895       2.769
C(answer_type_grouped)[T.Number]               0.4844      0.689      0.703      0.482      -0.867       1.835
C(answer_type_grouped)[T.Other]               -1.3536      0.668     -2.026      0.043      -2.663      -0.044
C(answer_type_grouped)[T.Person]              -1.2966      0.697     -1.862      0.063      -2.662       0.069
q_length                                      -1.1179      0.658     -1.700      0.089      -2.407       0.171
==============================================================================================================

                  Model 6.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                   96
Model:                          Logit   Df Residuals:                       84
Method:                           MLE   Df Model:                           11
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.3889
Time:                        17:34:07   Log-Likelihood:                -38.135
converged:                       True   LL-Null:                       -62.399
Covariance Type:            nonrobust   LLR p-value:                 1.149e-06
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      1.5377      3.665      0.420      0.675      -5.645       8.720
C(topic_grouped)[T.Geography]                  0.1693      1.046      0.162      0.871      -1.882       2.220
C(topic_grouped)[T.Misc]                      -1.8408      1.289     -1.428      0.153      -4.367       0.686
C(topic_grouped)[T.Music]                     -0.0480      1.259     -0.038      0.970      -2.515       2.419
C(topic_grouped)[T.Politics]                   1.2313      1.054      1.168      0.243      -0.834       3.297
C(topic_grouped)[T.Science and technology]     0.6756      0.868      0.778      0.437      -1.026       2.377
C(topic_grouped)[T.Sports]                     1.1261      1.097      1.026      0.305      -1.024       3.276
C(answer_type_grouped)[T.Number]               0.5467      0.862      0.634      0.526      -1.142       2.236
C(answer_type_grouped)[T.Other]               -0.6182      0.867     -0.713      0.476      -2.317       1.080
C(answer_type_grouped)[T.Person]              -0.8388      0.813     -1.031      0.302      -2.433       0.755
q_length                                      -1.5752      0.822     -1.917      0.055      -3.185       0.035
capabilities_entropy                           3.9775      0.961      4.139      0.000       2.094       5.861
==============================================================================================================

--- Analyzing claude-3-sonnet-20240229 (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_neutral/claude-3-sonnet-20240229_SimpleMC_redacted_temp0.0_1751827442_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    141
1     86
Name: count, dtype: int64

Answer change%: 0.3789 [0.31574899839716775, 0.44196025270415384] (n=227)
P-value vs 25%: 6.28e-05; P-value vs 0%: 5.799e-32
Phase 2 self-accuracy: 0.3937 [0.30872936773146276, 0.4786722070716869] (n=127)
P-value vs 25%: 0.0009177; P-value vs 33%: 0.1615

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  227
Model:                          Logit   Df Residuals:                      225
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.07562
Time:                        17:34:07   Log-Likelihood:                -139.23
converged:                       True   LL-Null:                       -150.61
Covariance Type:            nonrobust   LLR p-value:                 1.819e-06
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          1.9389      0.544      3.565      0.000       0.873       3.005
p_i_capability    -3.5947      0.791     -4.547      0.000      -5.144      -2.045
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  227
Model:                          Logit   Df Residuals:                      225
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.08414
Time:                        17:34:07   Log-Likelihood:                -137.94
converged:                       True   LL-Null:                       -150.61
Covariance Type:            nonrobust   LLR p-value:                 4.795e-07
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.1919      0.401     -5.462      0.000      -2.978      -1.405
capabilities_entropy     1.4962      0.317      4.720      0.000       0.875       2.118
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.2791 [0.1843, 0.3739] (n=86)
                  P-value vs 33.3%: 0.2619
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': None
topic_grouped           answer_changed
Art                     1                 0.580645
                        0                 0.419355
Geography               0                 0.555556
                        1                 0.444444
Misc                    0                 0.764706
                        1                 0.235294
Music                   0                 0.777778
                        1                 0.222222
Other                   0                 0.500000
                        1                 0.500000
Politics                0                 0.702703
                        1                 0.297297
Science and technology  0                 0.674419
                        1                 0.325581
Sports                  0                 0.500000
                        1                 0.500000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.605634
                     1                 0.394366
Number               0                 0.533333
                     1                 0.466667
Other                0                 0.692308
                     1                 0.307692
Person               0                 0.607143
                     1                 0.392857
Place                0                 0.666667
                     1                 0.333333
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.454545  0.545455           11
                       Number               0.400000  0.600000            5
                       Other                0.571429  0.428571            7
                       Person               0.285714  0.714286            7
                       Place                0.000000  1.000000            1
Geography              Date                 0.571429  0.428571            7
                       Number               0.250000  0.750000            4
                       Other                1.000000  0.000000            1
                       Place                0.666667  0.333333            6
Misc                   Date                 0.777778  0.222222            9
                       Number               1.000000  0.000000            2
                       Other                0.750000  0.250000           12
                       Person               0.700000  0.300000           10
                       Place                1.000000  0.000000            1
Music                  Date                 0.400000  0.600000            5
                       Number               1.000000  0.000000            2
                       Other                0.800000  0.200000            5
                       Person               1.000000  0.000000            5
                       Place                1.000000  0.000000            1
Other                  Date                 0.333333  0.666667            6
                       Number               0.500000  0.500000            2
                       Other                0.833333  0.166667            6
                       Person               0.375000  0.625000            8
                       Place                0.500000  0.500000            2
Politics               Date                 0.866667  0.133333           15
                       Number               1.000000  0.000000            2
                       Other                0.714286  0.285714            7
                       Person               0.375000  0.625000            8
                       Place                0.600000  0.400000            5
Science and technology Date                 0.583333  0.416667           12
                       Number               0.400000  0.600000            5
                       Other                0.750000  0.250000            8
                       Person               0.750000  0.250000           16
                       Place                1.000000  0.000000            2
Sports                 Date                 0.500000  0.500000            6
                       Number               0.500000  0.500000            8
                       Other                0.333333  0.666667            6
                       Person               1.000000  0.000000            2

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  227
Model:                          Logit   Df Residuals:                      214
Method:                           MLE   Df Model:                           12
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.06914
Time:                        17:34:07   Log-Likelihood:                -140.20
converged:                       True   LL-Null:                       -150.61
Covariance Type:            nonrobust   LLR p-value:                   0.05299
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      4.0378      1.892      2.134      0.033       0.330       7.746
C(topic_grouped)[T.Geography]                 -0.5688      0.632     -0.899      0.368      -1.808       0.671
C(topic_grouped)[T.Misc]                      -1.4519      0.554     -2.621      0.009      -2.538      -0.366
C(topic_grouped)[T.Music]                     -1.6714      0.683     -2.447      0.014      -3.010      -0.333
C(topic_grouped)[T.Other]                     -0.3179      0.556     -0.572      0.567      -1.407       0.771
C(topic_grouped)[T.Politics]                  -1.0139      0.526     -1.928      0.054      -2.045       0.017
C(topic_grouped)[T.Science and technology]    -1.1431      0.500     -2.285      0.022      -2.123      -0.163
C(topic_grouped)[T.Sports]                    -0.2952      0.576     -0.512      0.608      -1.425       0.834
C(answer_type_grouped)[T.Number]               0.2506      0.474      0.529      0.597      -0.679       1.180
C(answer_type_grouped)[T.Other]               -0.4707      0.416     -1.131      0.258      -1.287       0.345
C(answer_type_grouped)[T.Person]               0.0446      0.392      0.114      0.909      -0.723       0.812
C(answer_type_grouped)[T.Place]               -0.2242      0.591     -0.379      0.704      -1.382       0.934
q_length                                      -0.8106      0.407     -1.990      0.047      -1.609      -0.012
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 1.0886
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  227
Model:                          Logit   Df Residuals:                      213
Method:                           MLE   Df Model:                           13
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1667
Time:                        17:34:07   Log-Likelihood:                -125.51
converged:                       True   LL-Null:                       -150.61
Covariance Type:            nonrobust   LLR p-value:                 2.741e-06
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      3.1410      2.061      1.524      0.128      -0.899       7.181
C(topic_grouped)[T.Geography]                 -0.3480      0.679     -0.513      0.608      -1.678       0.982
C(topic_grouped)[T.Misc]                      -1.5106      0.596     -2.536      0.011      -2.678      -0.343
C(topic_grouped)[T.Music]                     -1.7325      0.738     -2.347      0.019      -3.179      -0.286
C(topic_grouped)[T.Other]                     -0.2553      0.600     -0.426      0.670      -1.431       0.920
C(topic_grouped)[T.Politics]                  -0.9096      0.580     -1.569      0.117      -2.046       0.226
C(topic_grouped)[T.Science and technology]    -1.2388      0.548     -2.261      0.024      -2.313      -0.165
C(topic_grouped)[T.Sports]                    -0.7655      0.630     -1.215      0.224      -2.000       0.469
C(answer_type_grouped)[T.Number]               0.5399      0.506      1.068      0.286      -0.451       1.531
C(answer_type_grouped)[T.Other]               -0.4810      0.443     -1.085      0.278      -1.350       0.388
C(answer_type_grouped)[T.Person]               0.6232      0.443      1.408      0.159      -0.245       1.491
C(answer_type_grouped)[T.Place]               -0.2931      0.636     -0.461      0.645      -1.539       0.953
q_length                                      -1.0977      0.452     -2.429      0.015      -1.984      -0.212
capabilities_entropy                           1.8116      0.363      4.992      0.000       1.100       2.523
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing claude-sonnet-4-20250514 (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_neutral/claude-sonnet-4-20250514_SimpleMC_redacted_cor_temp0.0_1751828378_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    175
1     44
Name: count, dtype: int64

Answer change%: 0.2009 [0.14784590663059066, 0.25398057738767416] (n=219)
P-value vs 25%: 0.06984; P-value vs 0%: 1.167e-13
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=44)
P-value vs 25%: 0; P-value vs 33%: 0
                  Grouped rare topic into 'Misc'/'Other': ['History', 'TV shows', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': None
topic_grouped           answer_changed
Art                     0                 0.894737
                        1                 0.105263
Geography               0                 0.666667
                        1                 0.333333
Misc                    0                 0.914286
                        1                 0.085714
Music                   0                 0.809524
                        1                 0.190476
Other                   0                 0.944444
                        1                 0.055556
Politics                0                 0.806452
                        1                 0.193548
Science and technology  0                 0.625000
                        1                 0.375000
Sports                  0                 0.733333
                        1                 0.266667
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.736842
                     1                 0.263158
Number               0                 0.677419
                     1                 0.322581
Other                0                 0.921569
                     1                 0.078431
Person               0                 0.826087
                     1                 0.173913
Place                0                 0.866667
                     1                 0.133333
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.777778  0.222222            9
                       Number               1.000000  0.000000            3
                       Other                1.000000  0.000000            8
                       Person               0.866667  0.133333           15
                       Place                1.000000  0.000000            3
Geography              Date                 0.250000  0.750000            4
                       Number               0.666667  0.333333            9
                       Other                1.000000  0.000000            3
                       Place                0.800000  0.200000            5
Misc                   Date                 0.846154  0.153846           13
                       Number               1.000000  0.000000            4
                       Other                0.923077  0.076923           13
                       Person               1.000000  0.000000            4
                       Place                1.000000  0.000000            1
Music                  Date                 0.750000  0.250000            8
                       Number               0.666667  0.333333            3
                       Other                0.500000  0.500000            2
                       Person               1.000000  0.000000            7
                       Place                1.000000  0.000000            1
Other                  Date                 1.000000  0.000000            6
                       Number               0.750000  0.250000            4
                       Other                1.000000  0.000000            4
                       Person               1.000000  0.000000            3
                       Place                1.000000  0.000000            1
Politics               Date                 0.800000  0.200000           15
                       Number               0.000000  1.000000            1
                       Other                1.000000  0.000000            5
                       Person               0.714286  0.285714            7
                       Place                1.000000  0.000000            3
Science and technology Date                 0.588235  0.411765           17
                       Number               0.500000  0.500000            4
                       Other                0.833333  0.166667           12
                       Person               0.500000  0.500000            6
                       Place                0.000000  1.000000            1
Sports                 Date                 0.750000  0.250000            4
                       Number               0.333333  0.666667            3
                       Other                1.000000  0.000000            4
                       Person               0.750000  0.250000            4

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  219
Model:                          Logit   Df Residuals:                      206
Method:                           MLE   Df Model:                           12
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1295
Time:                        17:34:07   Log-Likelihood:                -95.642
converged:                       True   LL-Null:                       -109.86
Covariance Type:            nonrobust   LLR p-value:                  0.004759
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -2.2083      2.199     -1.004      0.315      -6.519       2.102
C(topic_grouped)[T.Geography]                  1.3091      0.774      1.690      0.091      -0.209       2.827
C(topic_grouped)[T.Misc]                      -0.2224      0.826     -0.269      0.788      -1.840       1.396
C(topic_grouped)[T.Music]                      0.5067      0.779      0.651      0.515      -1.020       2.033
C(topic_grouped)[T.Other]                     -0.8304      1.180     -0.704      0.482      -3.143       1.482
C(topic_grouped)[T.Politics]                   0.6021      0.730      0.825      0.409      -0.829       2.033
C(topic_grouped)[T.Science and technology]     1.6610      0.649      2.559      0.011       0.389       2.933
C(topic_grouped)[T.Sports]                     1.0929      0.815      1.341      0.180      -0.504       2.690
C(answer_type_grouped)[T.Number]               0.2270      0.533      0.425      0.670      -0.819       1.272
C(answer_type_grouped)[T.Other]               -1.5199      0.608     -2.501      0.012      -2.711      -0.329
C(answer_type_grouped)[T.Person]              -0.3652      0.501     -0.728      0.466      -1.348       0.617
C(answer_type_grouped)[T.Place]               -0.9421      0.862     -1.093      0.274      -2.631       0.747
q_length                                       0.1041      0.471      0.221      0.825      -0.820       1.028
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing claude-sonnet-4-20250514 (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_neutral/claude-sonnet-4-20250514_SimpleMC_redacted_temp0.0_1751824015_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
1    149
0    132
Name: count, dtype: int64

Answer change%: 0.5302 [0.47189536831085716, 0.5886028523297121] (n=281)
P-value vs 25%: 4.826e-21; P-value vs 0%: 5.931e-71
Phase 2 self-accuracy: 0.5034 [0.4230742598581297, 0.5836371495378435] (n=149)
P-value vs 25%: 6.197e-10; P-value vs 33%: 3.196e-05
                  Grouped rare topic into 'Misc'/'Other': ['History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     1                 0.594595
                        0                 0.405405
Geography               1                 0.565217
                        0                 0.434783
Misc                    0                 0.550000
                        1                 0.450000
Music                   0                 0.684211
                        1                 0.315789
Other                   1                 0.588235
                        0                 0.411765
Politics                0                 0.521739
                        1                 0.478261
Science and technology  0                 0.534483
                        1                 0.465517
Sports                  1                 0.600000
                        0                 0.400000
TV shows                1                 0.789474
                        0                 0.210526
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.505376
                     1                 0.494624
Number               0                 0.510638
                     1                 0.489362
Other                1                 0.611940
                     0                 0.388060
Person               1                 0.527027
                     0                 0.472973
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.666667  0.333333           12
                       Number               0.333333  0.666667            6
                       Other                0.428571  0.571429            7
                       Person               0.166667  0.833333           12
Geography              Date                 0.272727  0.727273           11
                       Number               0.666667  0.333333            9
                       Other                0.333333  0.666667            3
Misc                   Date                 0.777778  0.222222            9
                       Number               0.000000  1.000000            4
                       Other                0.500000  0.500000            4
                       Person               0.666667  0.333333            3
Music                  Date                 0.750000  0.250000            4
                       Number               1.000000  0.000000            1
                       Other                0.666667  0.333333            9
                       Person               0.600000  0.400000            5
Other                  Date                 0.166667  0.833333           12
                       Number               0.666667  0.333333            3
                       Other                0.444444  0.555556            9
                       Person               0.600000  0.400000           10
Politics               Date                 0.523810  0.476190           21
                       Number               0.600000  0.400000            5
                       Other                0.333333  0.666667           12
                       Person               0.750000  0.250000            8
Science and technology Date                 0.611111  0.388889           18
                       Number               0.600000  0.400000           10
                       Other                0.500000  0.500000            6
                       Person               0.458333  0.541667           24
Sports                 Date                 0.400000  0.600000            5
                       Number               0.500000  0.500000            8
                       Other                0.250000  0.750000            8
                       Person               0.500000  0.500000            4
TV shows               Date                 0.000000  1.000000            1
                       Number               0.000000  1.000000            1
                       Other                0.111111  0.888889            9
                       Person               0.375000  0.625000            8

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  281
Model:                          Logit   Df Residuals:                      268
Method:                           MLE   Df Model:                           12
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.03866
Time:                        17:34:07   Log-Likelihood:                -186.75
converged:                       True   LL-Null:                       -194.26
Covariance Type:            nonrobust   LLR p-value:                    0.2403
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      0.2911      1.583      0.184      0.854      -2.811       3.393
C(topic_grouped)[T.Geography]                 -0.0493      0.553     -0.089      0.929      -1.134       1.035
C(topic_grouped)[T.Misc]                      -0.5782      0.567     -1.020      0.308      -1.689       0.532
C(topic_grouped)[T.Music]                     -1.3001      0.609     -2.136      0.033      -2.493      -0.107
C(topic_grouped)[T.Other]                     -0.0657      0.487     -0.135      0.893      -1.020       0.888
C(topic_grouped)[T.Politics]                  -0.5022      0.455     -1.103      0.270      -1.394       0.390
C(topic_grouped)[T.Science and technology]    -0.4923      0.429     -1.147      0.251      -1.334       0.349
C(topic_grouped)[T.Sports]                    -0.0040      0.537     -0.008      0.994      -1.057       1.049
C(topic_grouped)[T.TV shows]                   0.8051      0.665      1.210      0.226      -0.499       2.109
C(answer_type_grouped)[T.Number]              -0.1151      0.371     -0.310      0.756      -0.842       0.612
C(answer_type_grouped)[T.Other]                0.4346      0.348      1.250      0.211      -0.247       1.116
C(answer_type_grouped)[T.Person]               0.0623      0.336      0.185      0.853      -0.596       0.720
q_length                                       0.0026      0.339      0.008      0.994      -0.663       0.668
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing deepseek-chat (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_neutral/deepseek-chat_SimpleMC_redacted_cor_temp0.0_1754439842_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    231
1     30
Name: count, dtype: int64

Answer change%: 0.1149 [0.07624760925184973, 0.15363744821941464] (n=261)
P-value vs 25%: 7.87e-12; P-value vs 0%: 5.814e-09
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=30)
P-value vs 25%: 0; P-value vs 33%: 0

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  261
Model:                          Logit   Df Residuals:                      259
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1896
Time:                        17:34:07   Log-Likelihood:                -75.449
converged:                       True   LL-Null:                       -93.105
Covariance Type:            nonrobust   LLR p-value:                 2.807e-09
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          4.6094      1.121      4.113      0.000       2.413       6.806
p_i_capability    -7.6406      1.312     -5.825      0.000     -10.211      -5.070
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  261
Model:                          Logit   Df Residuals:                      259
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.2188
Time:                        17:34:07   Log-Likelihood:                -72.737
converged:                       True   LL-Null:                       -93.105
Covariance Type:            nonrobust   LLR p-value:                 1.742e-10
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -3.9547      0.427     -9.257      0.000      -4.792      -3.117
capabilities_entropy     3.5919      0.601      5.980      0.000       2.415       4.769
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.7000 [0.5360, 0.8640] (n=30)
                  P-value vs 33.3%: 1.173e-05

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=-1.13, p=0.258
Wilcoxon delta_p: statistic=750.50, p=0.226
Mean Δp = -0.0079  [-0.0214, 0.0057]
Idea 1 N = 231; 

  Idea 1.5: Calibration Metrics
  NLL: 0.1026, Signed ECE (overconf pos under neg): -0.0880, ECE: 0.0880 (n=261)
  Brier: 0.0210, Reliability (absolute calibration error; lower better): 0.0208, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=261)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.882
Model:                            OLS   Adj. R-squared:                  0.881
Method:                 Least Squares   F-statistic:                     641.8
Date:                Sat, 09 Aug 2025   Prob (F-statistic):          5.09e-119
Time:                        17:34:07   Log-Likelihood:                 280.87
No. Observations:                 261   AIC:                            -553.7
Df Residuals:                     257   BIC:                            -539.5
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.8010      0.057    -14.128      0.000      -0.913      -0.689
p1                    0.8523      0.061     14.056      0.000       0.733       0.972
answer_changed        0.6686      0.090      7.434      0.000       0.491       0.846
p1:answer_changed     0.1494      0.107      1.391      0.165      -0.062       0.361
==============================================================================
Omnibus:                      146.885   Durbin-Watson:                   1.748
Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1683.575
Skew:                           1.986   Prob(JB):                         0.00
Kurtosis:                      14.791   Cond. No.                         39.7
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-0.41, p=0.682
Wilcoxon delta_H: statistic=856.00, p=0.664
Mean ΔH = -0.0121  [-0.0701, 0.0458]
Paired t-test delta_H Changed: statistic=5.27, p=1.2e-05
Wilcoxon delta_H Changed: statistic=34.00, p=4.45e-05
Mean ΔH Changed = 0.5783  [0.3632, 0.7933]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=1.22, p=0.224
Wilcoxon (p_top2_game vs p_top2_base): statistic=1689.50, p=0.264
Mean Δp_top2 = 0.0024  [-0.0015, 0.0064] (n=261)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=1.79, p=0.0754
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=1614.00, p=0.0811
Mean ΔH_unchosen_baseline_set = 0.0557  [-0.0055, 0.1169] (n=261)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  261
Model:                          Logit   Df Residuals:                      258
Method:                           MLE   Df Model:                            2
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.2293
Time:                        17:34:07   Log-Likelihood:                -71.757
converged:                       True   LL-Null:                       -93.105
Covariance Type:            nonrobust   LLR p-value:                 5.351e-10
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -2.0746      0.269     -7.716      0.000      -2.602      -1.548
p1_z            -2.0076      0.446     -4.503      0.000      -2.881      -1.134
I(p1_z ** 2)    -0.4175      0.155     -2.697      0.007      -0.721      -0.114
================================================================================
AUC = 0.812

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  261
Model:                          Logit   Df Residuals:                      259
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1454
Time:                        17:34:07   Log-Likelihood:                -79.568
converged:                       True   LL-Null:                       -93.105
Covariance Type:            nonrobust   LLR p-value:                 1.958e-07
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -3.6616      0.413     -8.863      0.000      -4.471      -2.852
game_entropy     3.5067      0.703      4.989      0.000       2.129       4.884
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=1530.50, p=0.0753
Paired t-test (game_entropy vs capabilities_entropy): statistic=-1.86, p=0.0643
Mean capabilities_entropy-game_entropy = 0.0316  [-0.0017, 0.0649] (n=261)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  261
Model:                          Logit   Df Residuals:                      258
Method:                           MLE   Df Model:                            2
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.2736
Time:                        17:34:07   Log-Likelihood:                -67.628
converged:                       True   LL-Null:                       -93.105
Covariance Type:            nonrobust   LLR p-value:                 8.614e-12
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -4.8289      0.554     -8.710      0.000      -5.916      -3.742
capabilities_entropy     3.0552      0.630      4.847      0.000       1.820       4.291
game_entropy             2.5047      0.780      3.213      0.001       0.977       4.033
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['Music', 'TV shows', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.975000
                        1                 0.025000
Geography               0                 0.800000
                        1                 0.200000
History                 0                 0.894737
                        1                 0.105263
Misc                    0                 0.900000
                        1                 0.100000
Other                   0                 0.956522
                        1                 0.043478
Politics                0                 0.795455
                        1                 0.204545
Science and technology  0                 0.872340
                        1                 0.127660
Sports                  0                 0.944444
                        1                 0.055556
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.880000
                     1                 0.120000
Number               0                 0.857143
                     1                 0.142857
Other                0                 0.863014
                     1                 0.136986
Person               0                 0.943396
                     1                 0.056604
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 1.000000  0.000000           13
                       Number               1.000000  0.000000            5
                       Other                0.875000  0.125000            8
                       Person               1.000000  0.000000           14
Geography              Date                 0.700000  0.300000           10
                       Number               0.916667  0.083333           12
                       Other                0.750000  0.250000            8
History                Date                 0.818182  0.181818           11
                       Number               1.000000  0.000000            2
                       Other                1.000000  0.000000            3
                       Person               1.000000  0.000000            3
Misc                   Date                 1.000000  0.000000           11
                       Number               0.666667  0.333333            3
                       Other                0.882353  0.117647           17
                       Person               0.888889  0.111111            9
Other                  Date                 0.888889  0.111111            9
                       Number               1.000000  0.000000            2
                       Other                1.000000  0.000000            7
                       Person               1.000000  0.000000            5
Politics               Date                 0.850000  0.150000           20
                       Number               0.333333  0.666667            3
                       Other                0.846154  0.153846           13
                       Person               0.750000  0.250000            8
Science and technology Date                 0.904762  0.095238           21
                       Number               0.833333  0.166667            6
                       Other                0.727273  0.272727           11
                       Person               1.000000  0.000000            9
Sports                 Date                 0.800000  0.200000            5
                       Number               1.000000  0.000000            2
                       Other                1.000000  0.000000            6
                       Person               1.000000  0.000000            5

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  261
Model:                          Logit   Df Residuals:                      249
Method:                           MLE   Df Model:                           11
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.07163
Time:                        17:34:07   Log-Likelihood:                -86.436
converged:                       True   LL-Null:                       -93.105
Covariance Type:            nonrobust   LLR p-value:                    0.2718
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -2.0083      2.644     -0.760      0.448      -7.191       3.174
C(topic_grouped)[T.Geography]                  2.0659      1.129      1.830      0.067      -0.146       4.278
C(topic_grouped)[T.History]                    1.4525      1.266      1.147      0.251      -1.029       3.934
C(topic_grouped)[T.Misc]                       1.3734      1.148      1.196      0.232      -0.877       3.624
C(topic_grouped)[T.Other]                      0.4928      1.443      0.341      0.733      -2.336       3.322
C(topic_grouped)[T.Politics]                   2.3320      1.096      2.128      0.033       0.184       4.480
C(topic_grouped)[T.Science and technology]     1.7438      1.113      1.567      0.117      -0.438       3.925
C(topic_grouped)[T.Sports]                     0.7434      1.448      0.513      0.608      -2.095       3.582
C(answer_type_grouped)[T.Number]               0.1474      0.612      0.241      0.810      -1.053       1.347
C(answer_type_grouped)[T.Other]                0.1901      0.478      0.398      0.691      -0.746       1.126
C(answer_type_grouped)[T.Person]              -0.5996      0.693     -0.865      0.387      -1.959       0.759
q_length                                      -0.3516      0.548     -0.642      0.521      -1.425       0.722
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.4285
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  261
Model:                          Logit   Df Residuals:                      248
Method:                           MLE   Df Model:                           12
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.2979
Time:                        17:34:07   Log-Likelihood:                -65.366
converged:                       True   LL-Null:                       -93.105
Covariance Type:            nonrobust   LLR p-value:                 1.486e-07
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -4.4759      3.184     -1.406      0.160     -10.717       1.765
C(topic_grouped)[T.Geography]                  2.1824      1.319      1.655      0.098      -0.402       4.767
C(topic_grouped)[T.History]                    1.5458      1.480      1.044      0.296      -1.355       4.447
C(topic_grouped)[T.Misc]                       0.9871      1.308      0.754      0.451      -1.577       3.551
C(topic_grouped)[T.Other]                     -0.4988      1.648     -0.303      0.762      -3.729       2.731
C(topic_grouped)[T.Politics]                   2.1403      1.259      1.701      0.089      -0.327       4.607
C(topic_grouped)[T.Science and technology]     2.3006      1.297      1.774      0.076      -0.241       4.842
C(topic_grouped)[T.Sports]                     1.6834      1.578      1.067      0.286      -1.409       4.776
C(answer_type_grouped)[T.Number]               0.0783      0.750      0.104      0.917      -1.392       1.548
C(answer_type_grouped)[T.Other]                0.4960      0.573      0.866      0.386      -0.626       1.618
C(answer_type_grouped)[T.Person]              -0.7590      0.856     -0.887      0.375      -2.436       0.918
q_length                                      -0.3317      0.669     -0.496      0.620      -1.642       0.979
capabilities_entropy                           4.1530      0.726      5.722      0.000       2.730       5.576
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  261
Model:                          Logit   Df Residuals:                      248
Method:                           MLE   Df Model:                           12
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.2168
Time:                        17:34:07   Log-Likelihood:                -72.920
converged:                       True   LL-Null:                       -93.105
Covariance Type:            nonrobust   LLR p-value:                 6.241e-05
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -3.8908      2.928     -1.329      0.184      -9.629       1.847
C(topic_grouped)[T.Geography]                  1.6852      1.208      1.395      0.163      -0.682       4.053
C(topic_grouped)[T.History]                    0.6938      1.382      0.502      0.616      -2.016       3.403
C(topic_grouped)[T.Misc]                       1.0844      1.196      0.907      0.364      -1.259       3.428
C(topic_grouped)[T.Other]                      0.2615      1.550      0.169      0.866      -2.775       3.299
C(topic_grouped)[T.Politics]                   2.3087      1.153      2.003      0.045       0.049       4.568
C(topic_grouped)[T.Science and technology]     1.7883      1.160      1.541      0.123      -0.486       4.063
C(topic_grouped)[T.Sports]                     1.1168      1.483      0.753      0.451      -1.790       4.024
C(answer_type_grouped)[T.Number]               0.1200      0.741      0.162      0.871      -1.332       1.572
C(answer_type_grouped)[T.Other]                0.2158      0.523      0.413      0.680      -0.809       1.241
C(answer_type_grouped)[T.Person]              -1.0095      0.784     -1.288      0.198      -2.546       0.527
q_length                                      -0.2949      0.611     -0.482      0.629      -1.493       0.903
game_entropy                                   3.9459      0.835      4.728      0.000       2.310       5.582
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  261
Model:                          Logit   Df Residuals:                      247
Method:                           MLE   Df Model:                           13
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.3514
Time:                        17:34:07   Log-Likelihood:                -60.384
converged:                       True   LL-Null:                       -93.105
Covariance Type:            nonrobust   LLR p-value:                 5.479e-09
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -5.2735      3.379     -1.561      0.119     -11.896       1.349
C(topic_grouped)[T.Geography]                  1.8349      1.376      1.333      0.182      -0.862       4.532
C(topic_grouped)[T.History]                    0.9210      1.633      0.564      0.573      -2.280       4.122
C(topic_grouped)[T.Misc]                       0.9837      1.340      0.734      0.463      -1.642       3.610
C(topic_grouped)[T.Other]                     -0.8426      1.908     -0.442      0.659      -4.583       2.898
C(topic_grouped)[T.Politics]                   2.2606      1.320      1.712      0.087      -0.327       4.849
C(topic_grouped)[T.Science and technology]     2.3334      1.350      1.729      0.084      -0.312       4.979
C(topic_grouped)[T.Sports]                     1.8682      1.622      1.152      0.249      -1.310       5.047
C(answer_type_grouped)[T.Number]               0.0539      0.855      0.063      0.950      -1.621       1.729
C(answer_type_grouped)[T.Other]                0.4473      0.583      0.767      0.443      -0.696       1.590
C(answer_type_grouped)[T.Person]              -0.9918      0.868     -1.142      0.253      -2.694       0.710
q_length                                      -0.3336      0.711     -0.469      0.639      -1.728       1.061
capabilities_entropy                           3.5589      0.767      4.642      0.000       2.056       5.062
game_entropy                                   2.6433      0.876      3.016      0.003       0.926       4.361
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing deepseek-chat (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_neutral/deepseek-chat_SimpleMC_redacted_temp0.0_1754433214_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    178
1     61
Name: count, dtype: int64

Answer change%: 0.2552 [0.19995545554622418, 0.3105047954998009] (n=239)
P-value vs 25%: 0.8529; P-value vs 0%: 1.428e-19
Phase 2 self-accuracy: 0.6066 [0.48396602880304085, 0.7291487252953198] (n=61)
P-value vs 25%: 1.194e-08; P-value vs 33%: 1.222e-05

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  239
Model:                          Logit   Df Residuals:                      237
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1771
Time:                        17:34:07   Log-Likelihood:                -111.71
converged:                       True   LL-Null:                       -135.75
Covariance Type:            nonrobust   LLR p-value:                 4.063e-12
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          5.6149      1.119      5.019      0.000       3.422       7.808
p_i_capability    -7.6959      1.272     -6.050      0.000     -10.189      -5.203
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  239
Model:                          Logit   Df Residuals:                      237
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1825
Time:                        17:34:07   Log-Likelihood:                -110.98
converged:                       True   LL-Null:                       -135.75
Covariance Type:            nonrobust   LLR p-value:                 1.935e-12
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.8952      0.344     -8.428      0.000      -3.568      -2.222
capabilities_entropy     3.3128      0.530      6.251      0.000       2.274       4.351
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.7705 [0.6650, 0.8760] (n=61)
                  P-value vs 33.3%: 4.687e-16

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=0.64, p=0.525
Wilcoxon delta_p: statistic=1396.00, p=0.592
Mean Δp = 0.0055  [-0.0115, 0.0225]
Idea 1 N = 178; 

  Idea 1.5: Calibration Metrics
  NLL: 3.9693, Signed ECE (overconf pos under neg): 0.0518, ECE: 0.0518 (n=239)
  Brier: 0.0123, Reliability (absolute calibration error; lower better): 0.0120, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=239)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.892
Model:                            OLS   Adj. R-squared:                  0.890
Method:                 Least Squares   F-statistic:                     645.7
Date:                Sat, 09 Aug 2025   Prob (F-statistic):          3.83e-113
Time:                        17:34:07   Log-Likelihood:                 197.16
No. Observations:                 239   AIC:                            -386.3
Df Residuals:                     235   BIC:                            -372.4
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.5978      0.082     -7.270      0.000      -0.760      -0.436
p1                    0.6540      0.089      7.372      0.000       0.479       0.829
answer_changed        0.5318      0.103      5.144      0.000       0.328       0.736
p1:answer_changed     0.2885      0.119      2.434      0.016       0.055       0.522
==============================================================================
Omnibus:                       68.413   Durbin-Watson:                   2.034
Prob(Omnibus):                  0.000   Jarque-Bera (JB):              248.541
Skew:                           1.143   Prob(JB):                     1.07e-54
Kurtosis:                       7.442   Cond. No.                         37.3
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=0.40, p=0.69
Wilcoxon delta_H: statistic=1438.00, p=0.747
Mean ΔH = 0.0163  [-0.0638, 0.0964]
Paired t-test delta_H Changed: statistic=6.97, p=2.78e-09
Wilcoxon delta_H Changed: statistic=196.00, p=7.3e-08
Mean ΔH Changed = 0.5313  [0.3820, 0.6806]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=0.45, p=0.65
Wilcoxon (p_top2_game vs p_top2_base): statistic=4627.50, p=0.721
Mean Δp_top2 = 0.0010  [-0.0034, 0.0055] (n=239)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=3.80, p=0.000183
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=3060.00, p=0.000226
Mean ΔH_unchosen_baseline_set = 0.1478  [0.0716, 0.2239] (n=239)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  239
Model:                          Logit   Df Residuals:                      236
Method:                           MLE   Df Model:                            2
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1933
Time:                        17:34:07   Log-Likelihood:                -109.51
converged:                       True   LL-Null:                       -135.75
Covariance Type:            nonrobust   LLR p-value:                 4.022e-12
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.9507      0.208     -4.575      0.000      -1.358      -0.543
p1_z            -1.6206      0.331     -4.899      0.000      -2.269      -0.972
I(p1_z ** 2)    -0.3166      0.145     -2.184      0.029      -0.601      -0.033
================================================================================
AUC = 0.819

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  239
Model:                          Logit   Df Residuals:                      237
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.07352
Time:                        17:34:07   Log-Likelihood:                -125.77
converged:                       True   LL-Null:                       -135.75
Covariance Type:            nonrobust   LLR p-value:                 7.903e-06
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -2.1319      0.297     -7.175      0.000      -2.714      -1.550
game_entropy     2.0850      0.482      4.330      0.000       1.141       3.029
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=4303.00, p=0.295
Paired t-test (game_entropy vs capabilities_entropy): statistic=-1.22, p=0.226
Mean capabilities_entropy-game_entropy = 0.0270  [-0.0166, 0.0707] (n=239)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  239
Model:                          Logit   Df Residuals:                      236
Method:                           MLE   Df Model:                            2
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.2018
Time:                        17:34:07   Log-Likelihood:                -108.35
converged:                       True   LL-Null:                       -135.75
Covariance Type:            nonrobust   LLR p-value:                 1.259e-12
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -3.3697      0.423     -7.965      0.000      -4.199      -2.540
capabilities_entropy     3.0070      0.548      5.488      0.000       1.933       4.081
game_entropy             1.2886      0.566      2.278      0.023       0.180       2.398
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'Geography', 'Video games', 'History']
                  Grouped rare answer_type into 'Misc'/'Other': None
topic_grouped           answer_changed
Art                     0                 0.742857
                        1                 0.257143
Misc                    0                 0.739130
                        1                 0.260870
Music                   0                 0.782609
                        1                 0.217391
Other                   0                 0.827586
                        1                 0.172414
Politics                0                 0.696970
                        1                 0.303030
Science and technology  0                 0.725490
                        1                 0.274510
Sports                  0                 0.727273
                        1                 0.272727
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.666667
                     1                 0.333333
Number               0                 0.790698
                     1                 0.209302
Other                0                 0.750000
                     1                 0.250000
Person               0                 0.805970
                     1                 0.194030
Place                0                 0.687500
                     1                 0.312500
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.625000  0.375000            8
                       Number               1.000000  0.000000            4
                       Other                0.714286  0.285714            7
                       Person               0.769231  0.230769           13
                       Place                0.666667  0.333333            3
Misc                   Date                 0.909091  0.090909           11
                       Number               0.800000  0.200000           10
                       Other                0.727273  0.272727           11
                       Person               0.600000  0.400000           10
                       Place                0.500000  0.500000            4
Music                  Date                 0.857143  0.142857            7
                       Number               0.750000  0.250000            4
                       Other                0.800000  0.200000            5
                       Person               0.800000  0.200000            5
                       Place                0.500000  0.500000            2
Other                  Date                 0.666667  0.333333            9
                       Number               1.000000  0.000000            5
                       Other                0.800000  0.200000            5
                       Person               0.875000  0.125000            8
                       Place                1.000000  0.000000            2
Politics               Date                 0.625000  0.375000           16
                       Number               0.666667  0.333333            3
                       Other                0.833333  0.166667            6
                       Person               0.714286  0.285714            7
                       Place                1.000000  0.000000            1
Science and technology Date                 0.500000  0.500000           14
                       Number               0.750000  0.250000            8
                       Other                0.666667  0.333333            6
                       Person               0.904762  0.095238           21
                       Place                0.500000  0.500000            2
Sports                 Date                 0.500000  0.500000            4
                       Number               0.666667  0.333333            9
                       Other                0.750000  0.250000            4
                       Person               1.000000  0.000000            3
                       Place                1.000000  0.000000            2

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  239
Model:                          Logit   Df Residuals:                      227
Method:                           MLE   Df Model:                           11
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.02482
Time:                        17:34:07   Log-Likelihood:                -132.38
converged:                       True   LL-Null:                       -135.75
Covariance Type:            nonrobust   LLR p-value:                    0.8199
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -2.0166      1.885     -1.070      0.285      -5.711       1.678
C(topic_grouped)[T.Misc]                      -0.0138      0.521     -0.027      0.979      -1.035       1.007
C(topic_grouped)[T.Music]                     -0.2631      0.646     -0.407      0.684      -1.530       1.004
C(topic_grouped)[T.Other]                     -0.5376      0.634     -0.848      0.397      -1.780       0.705
C(topic_grouped)[T.Politics]                   0.0406      0.559      0.073      0.942      -1.055       1.136
C(topic_grouped)[T.Science and technology]     0.1216      0.507      0.240      0.810      -0.871       1.114
C(topic_grouped)[T.Sports]                     0.0786      0.634      0.124      0.901      -1.164       1.322
C(answer_type_grouped)[T.Number]              -0.6745      0.471     -1.431      0.152      -1.598       0.249
C(answer_type_grouped)[T.Other]               -0.3902      0.439     -0.889      0.374      -1.251       0.470
C(answer_type_grouped)[T.Person]              -0.7200      0.412     -1.749      0.080      -1.527       0.087
C(answer_type_grouped)[T.Place]               -0.0212      0.611     -0.035      0.972      -1.218       1.176
q_length                                       0.3014      0.401      0.751      0.453      -0.485       1.088
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.5031
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  239
Model:                          Logit   Df Residuals:                      226
Method:                           MLE   Df Model:                           12
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.2101
Time:                        17:34:07   Log-Likelihood:                -107.23
converged:                       True   LL-Null:                       -135.75
Covariance Type:            nonrobust   LLR p-value:                 7.742e-08
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -4.5430      2.198     -2.067      0.039      -8.851      -0.235
C(topic_grouped)[T.Misc]                       0.4390      0.595      0.738      0.460      -0.726       1.604
C(topic_grouped)[T.Music]                      0.0625      0.726      0.086      0.931      -1.360       1.485
C(topic_grouped)[T.Other]                     -0.5883      0.760     -0.774      0.439      -2.078       0.901
C(topic_grouped)[T.Politics]                   0.2828      0.629      0.450      0.653      -0.949       1.515
C(topic_grouped)[T.Science and technology]     0.3328      0.588      0.566      0.571      -0.819       1.485
C(topic_grouped)[T.Sports]                    -0.1367      0.764     -0.179      0.858      -1.633       1.360
C(answer_type_grouped)[T.Number]              -0.7867      0.557     -1.411      0.158      -1.879       0.306
C(answer_type_grouped)[T.Other]               -0.2889      0.483     -0.599      0.549      -1.235       0.657
C(answer_type_grouped)[T.Person]              -0.7458      0.476     -1.567      0.117      -1.679       0.187
C(answer_type_grouped)[T.Place]               -0.3358      0.689     -0.487      0.626      -1.686       1.015
q_length                                       0.4020      0.450      0.893      0.372      -0.480       1.284
capabilities_entropy                           3.4321      0.545      6.293      0.000       2.363       4.501
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  239
Model:                          Logit   Df Residuals:                      226
Method:                           MLE   Df Model:                           12
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.09915
Time:                        17:34:07   Log-Likelihood:                -122.29
converged:                       True   LL-Null:                       -135.75
Covariance Type:            nonrobust   LLR p-value:                  0.007937
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -2.4495      1.973     -1.241      0.214      -6.317       1.418
C(topic_grouped)[T.Misc]                    8.081e-05      0.547      0.000      1.000      -1.073       1.073
C(topic_grouped)[T.Music]                     -0.3483      0.680     -0.512      0.608      -1.680       0.984
C(topic_grouped)[T.Other]                     -0.6955      0.688     -1.011      0.312      -2.044       0.653
C(topic_grouped)[T.Politics]                   0.3189      0.584      0.546      0.585      -0.825       1.463
C(topic_grouped)[T.Science and technology]     0.2720      0.534      0.509      0.611      -0.775       1.319
C(topic_grouped)[T.Sports]                     0.0805      0.677      0.119      0.905      -1.246       1.407
C(answer_type_grouped)[T.Number]              -0.6711      0.516     -1.299      0.194      -1.683       0.341
C(answer_type_grouped)[T.Other]               -0.1473      0.460     -0.320      0.749      -1.050       0.755
C(answer_type_grouped)[T.Person]              -0.4144      0.437     -0.949      0.343      -1.271       0.442
C(answer_type_grouped)[T.Place]                0.4585      0.634      0.723      0.470      -0.785       1.702
q_length                                       0.0967      0.417      0.232      0.817      -0.722       0.915
game_entropy                                   2.2297      0.514      4.340      0.000       1.223       3.237
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  239
Model:                          Logit   Df Residuals:                      225
Method:                           MLE   Df Model:                           13
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.2273
Time:                        17:34:07   Log-Likelihood:                -104.89
converged:                       True   LL-Null:                       -135.75
Covariance Type:            nonrobust   LLR p-value:                 2.583e-08
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -4.4770      2.238     -2.000      0.045      -8.864      -0.090
C(topic_grouped)[T.Misc]                       0.4335      0.602      0.720      0.471      -0.746       1.613
C(topic_grouped)[T.Music]                     -0.0054      0.733     -0.007      0.994      -1.442       1.432
C(topic_grouped)[T.Other]                     -0.6767      0.786     -0.861      0.389      -2.217       0.863
C(topic_grouped)[T.Politics]                   0.4198      0.635      0.661      0.508      -0.824       1.664
C(topic_grouped)[T.Science and technology]     0.3910      0.601      0.651      0.515      -0.786       1.568
C(topic_grouped)[T.Sports]                    -0.1379      0.791     -0.174      0.862      -1.689       1.413
C(answer_type_grouped)[T.Number]              -0.7813      0.585     -1.335      0.182      -1.929       0.366
C(answer_type_grouped)[T.Other]               -0.1456      0.487     -0.299      0.765      -1.100       0.809
C(answer_type_grouped)[T.Person]              -0.5690      0.486     -1.171      0.242      -1.522       0.384
C(answer_type_grouped)[T.Place]               -0.0181      0.699     -0.026      0.979      -1.388       1.351
q_length                                       0.2591      0.464      0.559      0.576      -0.650       1.168
capabilities_entropy                           3.1011      0.567      5.465      0.000       1.989       4.213
game_entropy                                   1.2838      0.598      2.148      0.032       0.112       2.455
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing gemini-1.5-pro (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_neutral/gemini-1.5-pro_SimpleMC_redacted_cor_temp0.0_1751845219_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    217
1     23
Name: count, dtype: int64

Answer change%: 0.0958 [0.05859201783934817, 0.1330746488273185] (n=240)
P-value vs 25%: 4.914e-16; P-value vs 0%: 4.569e-07
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=23)
P-value vs 25%: 0; P-value vs 33%: 0
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.968750
                        1                 0.031250
Geography               0                 0.850000
                        1                 0.150000
History                 0                 0.900000
                        1                 0.100000
Misc                    0                 0.818182
                        1                 0.181818
Music                   0                 0.944444
                        1                 0.055556
Other                   0                 0.875000
                        1                 0.125000
Politics                0                 0.951220
                        1                 0.048780
Science and technology  0                 0.860465
                        1                 0.139535
Sports                  0                 0.950000
                        1                 0.050000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.930000
                     1                 0.070000
Number               0                 0.787879
                     1                 0.212121
Other                0                 0.885246
                     1                 0.114754
Person               0                 0.956522
                     1                 0.043478
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 1.000000  0.000000           12
                       Number               0.750000  0.250000            4
                       Other                1.000000  0.000000            7
                       Person               1.000000  0.000000            9
Geography              Date                 0.750000  0.250000            8
                       Number               0.857143  0.142857            7
                       Other                1.000000  0.000000            5
History                Date                 1.000000  0.000000           11
                       Number               0.666667  0.333333            3
                       Other                0.666667  0.333333            3
                       Person               1.000000  0.000000            3
Misc                   Date                 1.000000  0.000000            5
                       Number               0.666667  0.333333            3
                       Other                0.800000  0.200000           10
                       Person               0.750000  0.250000            4
Music                  Date                 1.000000  0.000000            6
                       Other                0.750000  0.250000            4
                       Person               1.000000  0.000000            8
Other                  Date                 0.909091  0.090909           11
                       Number               1.000000  0.000000            4
                       Other                0.714286  0.285714            7
                       Person               1.000000  0.000000            2
Politics               Date                 0.913043  0.086957           23
                       Number               1.000000  0.000000            1
                       Other                1.000000  0.000000           11
                       Person               1.000000  0.000000            6
Science and technology Date                 0.882353  0.117647           17
                       Number               0.571429  0.428571            7
                       Other                0.909091  0.090909           11
                       Person               1.000000  0.000000            8
Sports                 Date                 1.000000  0.000000            7
                       Number               1.000000  0.000000            4
                       Other                1.000000  0.000000            3
                       Person               0.833333  0.166667            6

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  240
Model:                          Logit   Df Residuals:                      227
Method:                           MLE   Df Model:                           12
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.08547
Time:                        17:34:07   Log-Likelihood:                -69.321
converged:                       True   LL-Null:                       -75.799
Covariance Type:            nonrobust   LLR p-value:                    0.3722
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -6.0134      2.940     -2.045      0.041     -11.777      -0.250
C(topic_grouped)[T.Geography]                  1.4078      1.219      1.154      0.248      -0.982       3.798
C(topic_grouped)[T.History]                    1.1647      1.277      0.912      0.362      -1.339       3.668
C(topic_grouped)[T.Misc]                       1.8210      1.172      1.553      0.120      -0.477       4.119
C(topic_grouped)[T.Music]                      0.8793      1.464      0.600      0.548      -1.991       3.750
C(topic_grouped)[T.Other]                      1.4263      1.203      1.186      0.236      -0.931       3.784
C(topic_grouped)[T.Politics]                   0.4177      1.278      0.327      0.744      -2.087       2.923
C(topic_grouped)[T.Science and technology]     1.4992      1.119      1.340      0.180      -0.694       3.692
C(topic_grouped)[T.Sports]                     0.4064      1.458      0.279      0.780      -2.451       3.264
C(answer_type_grouped)[T.Number]               1.1183      0.608      1.838      0.066      -0.074       2.311
C(answer_type_grouped)[T.Other]                0.4293      0.580      0.741      0.459      -0.707       1.565
C(answer_type_grouped)[T.Person]              -0.4369      0.847     -0.516      0.606      -2.097       1.223
q_length                                       0.5231      0.607      0.862      0.389      -0.666       1.713
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing gemini-1.5-pro (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_neutral/gemini-1.5-pro_SimpleMC_redacted_temp0.0_1751826859_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    192
1     68
Name: count, dtype: int64

Answer change%: 0.2615 [0.20811978306785434, 0.31495714000906877] (n=260)
P-value vs 25%: 0.672; P-value vs 0%: 8.31e-22
Phase 2 self-accuracy: 0.5441 [0.4257408920044083, 0.6624944021132387] (n=68)
P-value vs 25%: 1.118e-06; P-value vs 33%: 0.0004732
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'Video games', 'History']
                  Grouped rare answer_type into 'Misc'/'Other': None
topic_grouped           answer_changed
Art                     0                 0.790698
                        1                 0.209302
Geography               0                 0.708333
                        1                 0.291667
Misc                    0                 0.750000
                        1                 0.250000
Music                   0                 0.636364
                        1                 0.363636
Other                   0                 0.678571
                        1                 0.321429
Politics                0                 0.750000
                        1                 0.250000
Science and technology  0                 0.709091
                        1                 0.290909
Sports                  0                 0.900000
                        1                 0.100000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.782609
                     1                 0.217391
Number               0                 0.800000
                     1                 0.200000
Other                0                 0.722222
                     1                 0.277778
Person               0                 0.716216
                     1                 0.283784
Place                0                 0.555556
                     1                 0.444444
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.888889  0.111111            9
                       Number               0.800000  0.200000            5
                       Other                0.900000  0.100000           10
                       Person               0.722222  0.277778           18
                       Place                0.000000  1.000000            1
Geography              Date                 0.714286  0.285714            7
                       Number               0.727273  0.272727           11
                       Other                1.000000  0.000000            1
                       Place                0.600000  0.400000            5
Misc                   Date                 0.714286  0.285714            7
                       Number               1.000000  0.000000            3
                       Other                0.769231  0.230769           13
                       Person               0.625000  0.375000            8
                       Place                1.000000  0.000000            1
Music                  Date                 0.833333  0.166667            6
                       Number               0.750000  0.250000            4
                       Other                0.285714  0.714286            7
                       Person               1.000000  0.000000            4
                       Place                0.000000  1.000000            1
Other                  Date                 0.857143  0.142857            7
                       Number               1.000000  0.000000            3
                       Other                0.500000  0.500000            4
                       Person               0.636364  0.363636           11
                       Place                0.333333  0.666667            3
Politics               Date                 0.846154  0.153846           13
                       Number               1.000000  0.000000            5
                       Other                0.714286  0.285714            7
                       Person               0.555556  0.444444            9
                       Place                0.500000  0.500000            2
Science and technology Date                 0.666667  0.333333           18
                       Number               0.714286  0.285714            7
                       Other                0.600000  0.400000            5
                       Person               0.772727  0.227273           22
                       Place                0.666667  0.333333            3
Sports                 Date                 1.000000  0.000000            2
                       Number               0.714286  0.285714            7
                       Other                1.000000  0.000000            7
                       Person               1.000000  0.000000            2
                       Place                1.000000  0.000000            2

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  260
Model:                          Logit   Df Residuals:                      247
Method:                           MLE   Df Model:                           12
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.03908
Time:                        17:34:07   Log-Likelihood:                -143.57
converged:                       True   LL-Null:                       -149.41
Covariance Type:            nonrobust   LLR p-value:                    0.4718
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -0.0832      1.826     -0.046      0.964      -3.662       3.496
C(topic_grouped)[T.Geography]                  0.4775      0.638      0.749      0.454      -0.772       1.727
C(topic_grouped)[T.Misc]                       0.2116      0.563      0.376      0.707      -0.893       1.316
C(topic_grouped)[T.Music]                      0.7647      0.593      1.289      0.197      -0.398       1.927
C(topic_grouped)[T.Other]                      0.5464      0.560      0.975      0.329      -0.552       1.644
C(topic_grouped)[T.Politics]                   0.3281      0.549      0.597      0.550      -0.748       1.404
C(topic_grouped)[T.Science and technology]     0.5049      0.488      1.035      0.301      -0.451       1.461
C(topic_grouped)[T.Sports]                    -0.9096      0.854     -1.066      0.287      -2.583       0.763
C(answer_type_grouped)[T.Number]              -0.0117      0.490     -0.024      0.981      -0.972       0.949
C(answer_type_grouped)[T.Other]                0.4269      0.445      0.959      0.338      -0.446       1.299
C(answer_type_grouped)[T.Person]               0.3425      0.407      0.841      0.400      -0.455       1.140
C(answer_type_grouped)[T.Place]                1.1122      0.578      1.924      0.054      -0.021       2.245
q_length                                      -0.3436      0.388     -0.887      0.375      -1.103       0.416
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing gemini-2.0-flash-001 (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_neutral/gemini-2.0-flash-001_SimpleMC_redacted_cor_temp0.0_1754341330_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    178
1     35
Name: count, dtype: int64

Answer change%: 0.1643 [0.11455439770057133, 0.21408409995201086] (n=213)
P-value vs 25%: 0.0007395; P-value vs 0%: 9.695e-11
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=35)
P-value vs 25%: 0; P-value vs 33%: 0

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  213
Model:                          Logit   Df Residuals:                      211
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.05283
Time:                        17:34:07   Log-Likelihood:                -90.133
converged:                       True   LL-Null:                       -95.161
Covariance Type:            nonrobust   LLR p-value:                  0.001520
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          2.2469      1.184      1.897      0.058      -0.074       4.568
p_i_capability    -4.2024      1.291     -3.256      0.001      -6.732      -1.673
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  213
Model:                          Logit   Df Residuals:                      211
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.04627
Time:                        17:34:07   Log-Likelihood:                -90.757
converged:                       True   LL-Null:                       -95.161
Covariance Type:            nonrobust   LLR p-value:                  0.003002
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.9998      0.240     -8.345      0.000      -2.470      -1.530
capabilities_entropy     1.3304      0.438      3.040      0.002       0.473       2.188
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.6552 [0.4822, 0.8282] (n=29)
                  P-value vs 33.3%: 0.000266

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=3.02, p=0.0033
Wilcoxon delta_p: statistic=1451.00, p=0.00738
Mean Δp = 0.0522  [0.0183, 0.0861]
Idea 1 N = 92; 

  Idea 1.5: Calibration Metrics
  NLL: 0.1052, Signed ECE (overconf pos under neg): -0.0864, ECE: 0.0864 (n=120)
  Brier: 0.0268, Reliability (absolute calibration error; lower better): 0.0262, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=120)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.807
Model:                            OLS   Adj. R-squared:                  0.802
Method:                 Least Squares   F-statistic:                     161.4
Date:                Sat, 09 Aug 2025   Prob (F-statistic):           3.07e-41
Time:                        17:34:07   Log-Likelihood:                 57.431
No. Observations:                 120   AIC:                            -106.9
Df Residuals:                     116   BIC:                            -95.71
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.3714      0.122     -3.035      0.003      -0.614      -0.129
p1                    0.4563      0.131      3.491      0.001       0.197       0.715
answer_changed        0.0586      0.189      0.310      0.757      -0.315       0.432
p1:answer_changed     0.7418      0.209      3.557      0.001       0.329       1.155
==============================================================================
Omnibus:                       12.203   Durbin-Watson:                   1.831
Prob(Omnibus):                  0.002   Jarque-Bera (JB):               13.574
Skew:                           0.824   Prob(JB):                      0.00113
Kurtosis:                       3.017   Cond. No.                         30.9
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-2.66, p=0.00921
Wilcoxon delta_H: statistic=1491.00, p=0.0116
Mean ΔH = -0.1618  [-0.2811, -0.0426]
Paired t-test delta_H Changed: statistic=1.29, p=0.208
Wilcoxon delta_H Changed: statistic=139.00, p=0.15
Mean ΔH Changed = 0.1389  [-0.0723, 0.3501]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=-3.51, p=0.000628
Wilcoxon (p_top2_game vs p_top2_base): statistic=1836.00, p=2.62e-06
Mean Δp_top2 = -0.0186  [-0.0289, -0.0082] (n=120)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=-1.70, p=0.0924
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=3030.00, p=0.116
Mean ΔH_unchosen_baseline_set = -0.0917  [-0.1976, 0.0142] (n=120)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  120
Model:                          Logit   Df Residuals:                      117
Method:                           MLE   Df Model:                            2
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.03166
Time:                        17:34:07   Log-Likelihood:                -63.129
converged:                       True   LL-Null:                       -65.193
Covariance Type:            nonrobust   LLR p-value:                    0.1269
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.3299      0.303     -4.392      0.000      -1.923      -0.736
p1_z            -0.1854      0.447     -0.415      0.678      -1.062       0.691
I(p1_z ** 2)     0.1061      0.208      0.511      0.609      -0.301       0.513
================================================================================
AUC = 0.611

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  213
Model:                          Logit   Df Residuals:                      211
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1089
Time:                        17:34:07   Log-Likelihood:                -84.802
converged:                       True   LL-Null:                       -95.161
Covariance Type:            nonrobust   LLR p-value:                 5.325e-06
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -2.3581      0.282     -8.364      0.000      -2.911      -1.806
game_entropy     1.6087      0.357      4.508      0.000       0.909       2.308
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=7299.00, p=5.39e-06
Paired t-test (game_entropy vs capabilities_entropy): statistic=3.74, p=0.000235
Mean capabilities_entropy-game_entropy = -0.1119  [-0.1705, -0.0533] (n=213)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  213
Model:                          Logit   Df Residuals:                      210
Method:                           MLE   Df Model:                            2
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1134
Time:                        17:34:07   Log-Likelihood:                -84.366
converged:                       True   LL-Null:                       -95.161
Covariance Type:            nonrobust   LLR p-value:                 2.052e-05
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.4177      0.292     -8.285      0.000      -2.990      -1.846
capabilities_entropy     0.4867      0.516      0.943      0.346      -0.525       1.499
game_entropy             1.4387      0.401      3.590      0.000       0.653       2.224
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': None
topic_grouped           answer_changed
Art                     0                 0.852941
                        1                 0.147059
Geography               0                 0.777778
                        1                 0.222222
Misc                    0                 0.833333
                        1                 0.166667
Music                   0                 0.782609
                        1                 0.217391
Other                   0                 0.750000
                        1                 0.250000
Politics                0                 0.970588
                        1                 0.029412
Science and technology  0                 0.860465
                        1                 0.139535
Sports                  0                 0.666667
                        1                 0.333333
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.835443
                     1                 0.164557
Number               0                 0.739130
                     1                 0.260870
Other                0                 0.772727
                     1                 0.227273
Person               0                 0.903846
                     1                 0.096154
Place                0                 0.933333
                     1                 0.066667
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.875000  0.125000            8
                       Number               0.500000  0.500000            2
                       Other                0.571429  0.428571            7
                       Person               1.000000  0.000000           15
                       Place                1.000000  0.000000            2
Geography              Date                 0.600000  0.400000            5
                       Number               0.833333  0.166667            6
                       Other                1.000000  0.000000            2
                       Place                0.800000  0.200000            5
Misc                   Date                 0.769231  0.230769           13
                       Number               1.000000  0.000000            2
                       Other                0.800000  0.200000           10
                       Person               1.000000  0.000000            4
                       Place                1.000000  0.000000            1
Music                  Date                 0.750000  0.250000            8
                       Number               1.000000  0.000000            2
                       Other                0.666667  0.333333            3
                       Person               0.777778  0.222222            9
                       Place                1.000000  0.000000            1
Other                  Date                 0.714286  0.285714            7
                       Other                0.666667  0.333333            3
                       Person               0.750000  0.250000            4
                       Place                1.000000  0.000000            2
Politics               Date                 0.947368  0.052632           19
                       Number               1.000000  0.000000            2
                       Other                1.000000  0.000000            6
                       Person               1.000000  0.000000            4
                       Place                1.000000  0.000000            3
Science and technology Date                 0.937500  0.062500           16
                       Number               0.600000  0.400000            5
                       Other                0.800000  0.200000           10
                       Person               0.916667  0.083333           12
Sports                 Date                 0.666667  0.333333            3
                       Number               0.500000  0.500000            4
                       Other                0.666667  0.333333            3
                       Person               0.750000  0.250000            4
                       Place                1.000000  0.000000            1

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  213
Model:                          Logit   Df Residuals:                      200
Method:                           MLE   Df Model:                           12
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.09197
Time:                        17:34:07   Log-Likelihood:                -86.409
converged:                       True   LL-Null:                       -95.161
Covariance Type:            nonrobust   LLR p-value:                    0.1316
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.5249      2.762     -0.552      0.581      -6.939       3.889
C(topic_grouped)[T.Geography]                  0.3531      0.814      0.434      0.665      -1.243       1.949
C(topic_grouped)[T.Misc]                      -0.1466      0.712     -0.206      0.837      -1.541       1.248
C(topic_grouped)[T.Music]                      0.4620      0.717      0.644      0.519      -0.943       1.867
C(topic_grouped)[T.Other]                      0.6324      0.778      0.813      0.416      -0.893       2.158
C(topic_grouped)[T.Politics]                  -1.9566      1.159     -1.688      0.091      -4.228       0.315
C(topic_grouped)[T.Science and technology]    -0.2721      0.688     -0.395      0.693      -1.621       1.077
C(topic_grouped)[T.Sports]                     0.9178      0.762      1.204      0.229      -0.576       2.412
C(answer_type_grouped)[T.Number]               0.2764      0.624      0.443      0.658      -0.946       1.499
C(answer_type_grouped)[T.Other]                0.3277      0.497      0.660      0.509      -0.646       1.301
C(answer_type_grouped)[T.Person]              -0.8682      0.586     -1.481      0.139      -2.018       0.281
C(answer_type_grouped)[T.Place]               -1.3237      1.116     -1.186      0.235      -3.510       0.863
q_length                                       0.0075      0.612      0.012      0.990      -1.192       1.207
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.2219
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  213
Model:                          Logit   Df Residuals:                      199
Method:                           MLE   Df Model:                           13
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1267
Time:                        17:34:07   Log-Likelihood:                -83.102
converged:                       True   LL-Null:                       -95.161
Covariance Type:            nonrobust   LLR p-value:                   0.03006
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.2692      2.832     -0.448      0.654      -6.820       4.281
C(topic_grouped)[T.Geography]                  0.3373      0.822      0.410      0.681      -1.273       1.948
C(topic_grouped)[T.Misc]                      -0.2604      0.729     -0.357      0.721      -1.688       1.167
C(topic_grouped)[T.Music]                      0.3185      0.733      0.435      0.664      -1.118       1.755
C(topic_grouped)[T.Other]                      0.3909      0.796      0.491      0.623      -1.169       1.951
C(topic_grouped)[T.Politics]                  -2.1471      1.173     -1.831      0.067      -4.445       0.151
C(topic_grouped)[T.Science and technology]    -0.3633      0.696     -0.522      0.602      -1.728       1.001
C(topic_grouped)[T.Sports]                     0.6618      0.803      0.825      0.410      -0.911       2.235
C(answer_type_grouped)[T.Number]               0.0273      0.647      0.042      0.966      -1.242       1.296
C(answer_type_grouped)[T.Other]                0.1615      0.523      0.309      0.758      -0.864       1.187
C(answer_type_grouped)[T.Person]              -0.7981      0.589     -1.356      0.175      -1.952       0.356
C(answer_type_grouped)[T.Place]               -1.3084      1.115     -1.173      0.241      -3.494       0.877
q_length                                      -0.0865      0.629     -0.138      0.891      -1.318       1.145
capabilities_entropy                           1.2729      0.491      2.591      0.010       0.310       2.236
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  213
Model:                          Logit   Df Residuals:                      199
Method:                           MLE   Df Model:                           13
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.2100
Time:                        17:34:07   Log-Likelihood:                -75.174
converged:                       True   LL-Null:                       -95.161
Covariance Type:            nonrobust   LLR p-value:                 0.0001396
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.0714      2.971     -0.361      0.718      -6.895       4.752
C(topic_grouped)[T.Geography]                  0.0959      0.849      0.113      0.910      -1.568       1.760
C(topic_grouped)[T.Misc]                      -0.3925      0.764     -0.514      0.608      -1.891       1.106
C(topic_grouped)[T.Music]                      0.2983      0.767      0.389      0.697      -1.205       1.802
C(topic_grouped)[T.Other]                      0.3216      0.842      0.382      0.703      -1.329       1.973
C(topic_grouped)[T.Politics]                  -2.7168      1.226     -2.217      0.027      -5.119      -0.315
C(topic_grouped)[T.Science and technology]    -0.5919      0.753     -0.786      0.432      -2.068       0.884
C(topic_grouped)[T.Sports]                     0.6695      0.822      0.814      0.416      -0.943       2.282
C(answer_type_grouped)[T.Number]               0.3898      0.658      0.593      0.553      -0.900       1.679
C(answer_type_grouped)[T.Other]                0.4734      0.560      0.845      0.398      -0.624       1.571
C(answer_type_grouped)[T.Person]              -0.6146      0.633     -0.971      0.331      -1.855       0.626
C(answer_type_grouped)[T.Place]               -0.6448      1.141     -0.565      0.572      -2.881       1.592
q_length                                      -0.2588      0.665     -0.389      0.697      -1.562       1.044
game_entropy                                   1.9188      0.428      4.480      0.000       1.079       2.758
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  213
Model:                          Logit   Df Residuals:                      198
Method:                           MLE   Df Model:                           14
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.2104
Time:                        17:34:07   Log-Likelihood:                -75.141
converged:                       True   LL-Null:                       -95.161
Covariance Type:            nonrobust   LLR p-value:                 0.0002515
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.0547      2.974     -0.355      0.723      -6.883       4.774
C(topic_grouped)[T.Geography]                  0.1066      0.851      0.125      0.900      -1.561       1.775
C(topic_grouped)[T.Misc]                      -0.3974      0.767     -0.518      0.604      -1.901       1.106
C(topic_grouped)[T.Music]                      0.2930      0.768      0.381      0.703      -1.213       1.799
C(topic_grouped)[T.Other]                      0.3024      0.846      0.357      0.721      -1.356       1.961
C(topic_grouped)[T.Politics]                  -2.7093      1.226     -2.210      0.027      -5.112      -0.307
C(topic_grouped)[T.Science and technology]    -0.5802      0.752     -0.771      0.441      -2.055       0.894
C(topic_grouped)[T.Sports]                     0.6495      0.828      0.784      0.433      -0.974       2.273
C(answer_type_grouped)[T.Number]               0.3559      0.672      0.530      0.596      -0.961       1.673
C(answer_type_grouped)[T.Other]                0.4510      0.568      0.794      0.427      -0.662       1.564
C(answer_type_grouped)[T.Person]              -0.6049      0.632     -0.957      0.338      -1.843       0.633
C(answer_type_grouped)[T.Place]               -0.6648      1.145     -0.581      0.561      -2.909       1.579
q_length                                      -0.2635      0.665     -0.396      0.692      -1.567       1.040
capabilities_entropy                           0.1559      0.606      0.257      0.797      -1.033       1.345
game_entropy                                   1.8609      0.483      3.850      0.000       0.913       2.808
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing gemini-2.0-flash-001 (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_neutral/gemini-2.0-flash-001_SimpleMC_redacted_temp0.0_1754341125_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    195
1     92
Name: count, dtype: int64

Answer change%: 0.3206 [0.2665646148004187, 0.37455036777797845] (n=287)
P-value vs 25%: 0.01043; P-value vs 0%: 2.692e-31
Phase 2 self-accuracy: 0.5870 [0.48634330638443024, 0.6875697370938307] (n=92)
P-value vs 25%: 5.239e-11; P-value vs 33%: 7.532e-07

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  287
Model:                          Logit   Df Residuals:                      285
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.04839
Time:                        17:34:07   Log-Likelihood:                -171.32
converged:                       True   LL-Null:                       -180.03
Covariance Type:            nonrobust   LLR p-value:                 2.989e-05
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          2.1972      0.726      3.026      0.002       0.774       3.620
p_i_capability    -3.3539      0.818     -4.098      0.000      -4.958      -1.750
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  287
Model:                          Logit   Df Residuals:                      285
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.04880
Time:                        17:34:07   Log-Likelihood:                -171.25
converged:                       True   LL-Null:                       -180.03
Covariance Type:            nonrobust   LLR p-value:                 2.767e-05
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.2394      0.181     -6.831      0.000      -1.595      -0.884
capabilities_entropy     1.1250      0.272      4.130      0.000       0.591       1.659
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.7467 [0.6482, 0.8451] (n=75)
                  P-value vs 33.3%: 1.866e-16

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=1.42, p=0.158
Wilcoxon delta_p: statistic=3983.00, p=0.289
Mean Δp = 0.0224  [-0.0085, 0.0532]
Idea 1 N = 133; 

  Idea 1.5: Calibration Metrics
  NLL: 5.4881, Signed ECE (overconf pos under neg): 0.0655, ECE: 0.0655 (n=206)
  Brier: 0.0163, Reliability (absolute calibration error; lower better): 0.0157, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=206)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.841
Model:                            OLS   Adj. R-squared:                  0.839
Method:                 Least Squares   F-statistic:                     356.4
Date:                Sat, 09 Aug 2025   Prob (F-statistic):           2.14e-80
Time:                        17:34:07   Log-Likelihood:                 99.246
No. Observations:                 206   AIC:                            -190.5
Df Residuals:                     202   BIC:                            -177.2
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.5340      0.081     -6.607      0.000      -0.693      -0.375
p1                    0.6266      0.090      6.976      0.000       0.449       0.804
answer_changed        0.4033      0.114      3.527      0.001       0.178       0.629
p1:answer_changed     0.3797      0.132      2.870      0.005       0.119       0.641
==============================================================================
Omnibus:                       17.363   Durbin-Watson:                   2.200
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               19.443
Skew:                           0.670   Prob(JB):                     6.00e-05
Kurtosis:                       3.684   Cond. No.                         26.5
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-1.70, p=0.091
Wilcoxon delta_H: statistic=3934.00, p=0.191
Mean ΔH = -0.0756  [-0.1625, 0.0114]
Paired t-test delta_H Changed: statistic=4.37, p=4.16e-05
Wilcoxon delta_H Changed: statistic=644.00, p=0.000103
Mean ΔH Changed = 0.2685  [0.1479, 0.3890]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=-1.05, p=0.296
Wilcoxon (p_top2_game vs p_top2_base): statistic=9042.00, p=0.046
Mean Δp_top2 = -0.0048  [-0.0139, 0.0042] (n=207)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=1.21, p=0.226
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=9611.00, p=0.181
Mean ΔH_unchosen_baseline_set = 0.0458  [-0.0281, 0.1196] (n=207)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  207
Model:                          Logit   Df Residuals:                      204
Method:                           MLE   Df Model:                            2
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.03454
Time:                        17:34:07   Log-Likelihood:                -129.72
converged:                       True   LL-Null:                       -134.36
Covariance Type:            nonrobust   LLR p-value:                  0.009656
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.6325      0.210     -3.017      0.003      -1.043      -0.222
p1_z            -0.4356      0.219     -1.986      0.047      -0.866      -0.006
I(p1_z ** 2)     0.0032      0.154      0.021      0.983      -0.298       0.304
================================================================================
AUC = 0.650

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  287
Model:                          Logit   Df Residuals:                      285
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.05305
Time:                        17:34:07   Log-Likelihood:                -170.48
converged:                       True   LL-Null:                       -180.03
Covariance Type:            nonrobust   LLR p-value:                 1.240e-05
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.3101      0.191     -6.861      0.000      -1.684      -0.936
game_entropy     1.1292      0.263      4.287      0.000       0.613       1.646
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=18075.00, p=0.0658
Paired t-test (game_entropy vs capabilities_entropy): statistic=1.84, p=0.067
Mean capabilities_entropy-game_entropy = -0.0568  [-0.1174, 0.0038] (n=287)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  287
Model:                          Logit   Df Residuals:                      284
Method:                           MLE   Df Model:                            2
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.07437
Time:                        17:34:07   Log-Likelihood:                -166.64
converged:                       True   LL-Null:                       -180.03
Covariance Type:            nonrobust   LLR p-value:                 1.532e-06
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.5319      0.214     -7.151      0.000      -1.952      -1.112
capabilities_entropy     0.8127      0.293      2.776      0.005       0.239       1.386
game_entropy             0.8580      0.283      3.032      0.002       0.303       1.413
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'Music', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.682927
                        1                 0.317073
Geography               0                 0.576923
                        1                 0.423077
Misc                    0                 0.704918
                        1                 0.295082
Other                   0                 0.666667
                        1                 0.333333
Politics                0                 0.767442
                        1                 0.232558
Science and technology  0                 0.618182
                        1                 0.381818
Sports                  0                 0.720000
                        1                 0.280000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.666667
                     1                 0.333333
Number               0                 0.618182
                     1                 0.381818
Other                0                 0.702703
                     1                 0.297297
Person               0                 0.720588
                     1                 0.279412
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.538462  0.461538           13
                       Number               0.571429  0.428571            7
                       Other                0.777778  0.222222            9
                       Person               0.833333  0.166667           12
Geography              Date                 0.700000  0.300000           10
                       Number               0.583333  0.416667           12
                       Other                0.250000  0.750000            4
Misc                   Date                 0.785714  0.214286           14
                       Number               0.666667  0.333333            9
                       Other                0.708333  0.291667           24
                       Person               0.642857  0.357143           14
Other                  Date                 0.636364  0.363636           11
                       Number               0.714286  0.285714            7
                       Other                0.777778  0.222222            9
                       Person               0.555556  0.444444            9
Politics               Date                 0.647059  0.352941           17
                       Number               0.750000  0.250000            4
                       Other                1.000000  0.000000           11
                       Person               0.727273  0.272727           11
Science and technology Date                 0.684211  0.315789           19
                       Number               0.555556  0.444444            9
                       Other                0.333333  0.666667            9
                       Person               0.722222  0.277778           18
Sports                 Date                 0.666667  0.333333            6
                       Number               0.571429  0.428571            7
                       Other                0.750000  0.250000            8
                       Person               1.000000  0.000000            4

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  287
Model:                          Logit   Df Residuals:                      276
Method:                           MLE   Df Model:                           10
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.01516
Time:                        17:34:07   Log-Likelihood:                -177.30
converged:                       True   LL-Null:                       -180.03
Covariance Type:            nonrobust   LLR p-value:                    0.8585
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      0.0396      1.571      0.025      0.980      -3.040       3.120
C(topic_grouped)[T.Geography]                  0.3392      0.533      0.636      0.525      -0.706       1.385
C(topic_grouped)[T.Misc]                      -0.0939      0.442     -0.213      0.832      -0.959       0.772
C(topic_grouped)[T.Other]                      0.0555      0.489      0.113      0.910      -0.904       1.015
C(topic_grouped)[T.Politics]                  -0.3904      0.498     -0.783      0.433      -1.367       0.586
C(topic_grouped)[T.Science and technology]     0.2938      0.437      0.672      0.502      -0.563       1.151
C(topic_grouped)[T.Sports]                    -0.2172      0.562     -0.387      0.699      -1.318       0.884
C(answer_type_grouped)[T.Number]               0.1617      0.365      0.443      0.658      -0.554       0.877
C(answer_type_grouped)[T.Other]               -0.1219      0.348     -0.351      0.726      -0.803       0.559
C(answer_type_grouped)[T.Person]              -0.2685      0.362     -0.742      0.458      -0.978       0.441
q_length                                      -0.1641      0.337     -0.487      0.626      -0.825       0.497
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.3977
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  287
Model:                          Logit   Df Residuals:                      275
Method:                           MLE   Df Model:                           11
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.06051
Time:                        17:34:07   Log-Likelihood:                -169.14
converged:                       True   LL-Null:                       -180.03
Covariance Type:            nonrobust   LLR p-value:                   0.02607
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      0.1988      1.619      0.123      0.902      -2.973       3.371
C(topic_grouped)[T.Geography]                  0.2815      0.553      0.509      0.611      -0.803       1.366
C(topic_grouped)[T.Misc]                      -0.1952      0.459     -0.425      0.671      -1.096       0.705
C(topic_grouped)[T.Other]                     -0.1058      0.506     -0.209      0.834      -1.097       0.885
C(topic_grouped)[T.Politics]                  -0.3175      0.514     -0.618      0.536      -1.324       0.689
C(topic_grouped)[T.Science and technology]     0.2632      0.452      0.582      0.561      -0.624       1.150
C(topic_grouped)[T.Sports]                     0.0356      0.579      0.061      0.951      -1.099       1.170
C(answer_type_grouped)[T.Number]               0.0821      0.378      0.217      0.828      -0.659       0.823
C(answer_type_grouped)[T.Other]               -0.1161      0.360     -0.322      0.747      -0.823       0.590
C(answer_type_grouped)[T.Person]              -0.1628      0.375     -0.434      0.664      -0.898       0.573
q_length                                      -0.3057      0.350     -0.873      0.383      -0.992       0.381
capabilities_entropy                           1.1312      0.285      3.964      0.000       0.572       1.690
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  287
Model:                          Logit   Df Residuals:                      275
Method:                           MLE   Df Model:                           11
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.06393
Time:                        17:34:07   Log-Likelihood:                -168.52
converged:                       True   LL-Null:                       -180.03
Covariance Type:            nonrobust   LLR p-value:                   0.01757
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -0.4520      1.630     -0.277      0.782      -3.647       2.743
C(topic_grouped)[T.Geography]                  0.2200      0.551      0.399      0.690      -0.860       1.300
C(topic_grouped)[T.Misc]                      -0.1834      0.459     -0.400      0.689      -1.082       0.715
C(topic_grouped)[T.Other]                      0.0364      0.504      0.072      0.942      -0.952       1.025
C(topic_grouped)[T.Politics]                  -0.4301      0.514     -0.837      0.403      -1.438       0.577
C(topic_grouped)[T.Science and technology]     0.2926      0.452      0.648      0.517      -0.593       1.178
C(topic_grouped)[T.Sports]                    -0.0145      0.579     -0.025      0.980      -1.149       1.120
C(answer_type_grouped)[T.Number]               0.1500      0.380      0.395      0.693      -0.594       0.894
C(answer_type_grouped)[T.Other]                0.1471      0.367      0.401      0.688      -0.572       0.866
C(answer_type_grouped)[T.Person]               0.0021      0.380      0.006      0.996      -0.742       0.746
q_length                                      -0.2040      0.349     -0.585      0.558      -0.887       0.479
game_entropy                                   1.1395      0.277      4.115      0.000       0.597       1.682
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  287
Model:                          Logit   Df Residuals:                      274
Method:                           MLE   Df Model:                           12
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.08505
Time:                        17:34:07   Log-Likelihood:                -164.72
converged:                       True   LL-Null:                       -180.03
Covariance Type:            nonrobust   LLR p-value:                  0.002249
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -0.2328      1.650     -0.141      0.888      -3.466       3.001
C(topic_grouped)[T.Geography]                  0.2127      0.561      0.379      0.704      -0.886       1.311
C(topic_grouped)[T.Misc]                      -0.2408      0.468     -0.514      0.607      -1.159       0.677
C(topic_grouped)[T.Other]                     -0.0850      0.515     -0.165      0.869      -1.095       0.925
C(topic_grouped)[T.Politics]                  -0.3579      0.520     -0.689      0.491      -1.376       0.661
C(topic_grouped)[T.Science and technology]     0.2714      0.459      0.591      0.555      -0.629       1.172
C(topic_grouped)[T.Sports]                     0.1322      0.587      0.225      0.822      -1.019       1.283
C(answer_type_grouped)[T.Number]               0.0922      0.387      0.238      0.812      -0.666       0.850
C(answer_type_grouped)[T.Other]                0.0867      0.374      0.232      0.817      -0.646       0.820
C(answer_type_grouped)[T.Person]               0.0206      0.385      0.053      0.957      -0.734       0.775
q_length                                      -0.2982      0.355     -0.839      0.401      -0.995       0.398
capabilities_entropy                           0.8352      0.303      2.756      0.006       0.241       1.429
game_entropy                                   0.8793      0.296      2.968      0.003       0.299       1.460
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing gemini-2.5-flash-preview-04-17 (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_neutral/gemini-2.5-flash-preview-04-17_SimpleMC_redacted_cor_temp0.0_1751845050_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    288
1     47
Name: count, dtype: int64

Answer change%: 0.1403 [0.10310851817082055, 0.17748849675455258] (n=335)
P-value vs 25%: 7.407e-09; P-value vs 0%: 1.426e-13
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=47)
P-value vs 25%: 0; P-value vs 33%: 0

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  335
Model:                          Logit   Df Residuals:                      333
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.02297
Time:                        17:34:07   Log-Likelihood:                -132.72
converged:                       True   LL-Null:                       -135.84
Covariance Type:            nonrobust   LLR p-value:                   0.01248
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.9690      0.173    -11.351      0.000      -2.309      -1.629
game_entropy   406.5528    170.056      2.391      0.017      73.249     739.856
================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['Music', 'History', 'TV shows', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': None
topic_grouped           answer_changed
Art                     0                 0.859649
                        1                 0.140351
Geography               0                 0.903226
                        1                 0.096774
Misc                    0                 0.868852
                        1                 0.131148
Other                   0                 0.837838
                        1                 0.162162
Politics                0                 0.928571
                        1                 0.071429
Science and technology  0                 0.815385
                        1                 0.184615
Sports                  0                 0.785714
                        1                 0.214286
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.904348
                     1                 0.095652
Number               0                 0.790698
                     1                 0.209302
Other                0                 0.838235
                     1                 0.161765
Person               0                 0.837209
                     1                 0.162791
Place                0                 0.913043
                     1                 0.086957
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.941176  0.058824           17
                       Number               0.571429  0.428571            7
                       Other                0.777778  0.222222            9
                       Person               0.894737  0.105263           19
                       Place                1.000000  0.000000            5
Geography              Date                 1.000000  0.000000           10
                       Number               0.818182  0.181818           11
                       Other                1.000000  0.000000            3
                       Place                0.857143  0.142857            7
Misc                   Date                 0.894737  0.105263           19
                       Number               1.000000  0.000000            6
                       Other                0.750000  0.250000           16
                       Person               0.894737  0.105263           19
                       Place                1.000000  0.000000            1
Other                  Date                 0.818182  0.181818           11
                       Number               1.000000  0.000000            3
                       Other                1.000000  0.000000            8
                       Person               0.727273  0.272727           11
                       Place                0.750000  0.250000            4
Politics               Date                 0.920000  0.080000           25
                       Number               1.000000  0.000000            4
                       Other                0.909091  0.090909           11
                       Person               0.909091  0.090909           11
                       Place                1.000000  0.000000            5
Science and technology Date                 0.958333  0.041667           24
                       Number               0.571429  0.428571            7
                       Other                0.833333  0.166667           12
                       Person               0.714286  0.285714           21
                       Place                1.000000  0.000000            1
Sports                 Date                 0.666667  0.333333            9
                       Number               0.800000  0.200000            5
                       Other                0.777778  0.222222            9
                       Person               1.000000  0.000000            5

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  335
Model:                          Logit   Df Residuals:                      323
Method:                           MLE   Df Model:                           11
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.03565
Time:                        17:34:07   Log-Likelihood:                -131.00
converged:                       True   LL-Null:                       -135.84
Covariance Type:            nonrobust   LLR p-value:                    0.5588
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.3973      2.065     -0.677      0.499      -5.444       2.650
C(topic_grouped)[T.Geography]                 -0.4958      0.750     -0.661      0.508      -1.966       0.974
C(topic_grouped)[T.Misc]                      -0.0868      0.544     -0.159      0.873      -1.153       0.980
C(topic_grouped)[T.Other]                      0.2015      0.592      0.340      0.734      -0.959       1.362
C(topic_grouped)[T.Politics]                  -0.6141      0.658     -0.933      0.351      -1.904       0.676
C(topic_grouped)[T.Science and technology]     0.3644      0.506      0.720      0.472      -0.628       1.356
C(topic_grouped)[T.Sports]                     0.4728      0.610      0.775      0.438      -0.723       1.669
C(answer_type_grouped)[T.Number]               0.9687      0.512      1.893      0.058      -0.034       1.972
C(answer_type_grouped)[T.Other]                0.5379      0.464      1.160      0.246      -0.371       1.447
C(answer_type_grouped)[T.Person]               0.5231      0.438      1.194      0.232      -0.336       1.382
C(answer_type_grouped)[T.Place]                0.0906      0.827      0.110      0.913      -1.531       1.712
q_length                                      -0.1889      0.454     -0.416      0.677      -1.079       0.701
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  335
Model:                          Logit   Df Residuals:                      322
Method:                           MLE   Df Model:                           12
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.06304
Time:                        17:34:07   Log-Likelihood:                -127.28
converged:                       True   LL-Null:                       -135.84
Covariance Type:            nonrobust   LLR p-value:                    0.1449
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.5162      2.102     -0.721      0.471      -5.636       2.604
C(topic_grouped)[T.Geography]                 -0.4083      0.758     -0.538      0.590      -1.895       1.078
C(topic_grouped)[T.Misc]                      -0.2075      0.571     -0.363      0.716      -1.327       0.912
C(topic_grouped)[T.Other]                      0.3102      0.601      0.516      0.606      -0.868       1.488
C(topic_grouped)[T.Politics]                  -0.5510      0.666     -0.827      0.408      -1.856       0.754
C(topic_grouped)[T.Science and technology]     0.4746      0.516      0.920      0.357      -0.536       1.485
C(topic_grouped)[T.Sports]                     0.4896      0.620      0.790      0.430      -0.726       1.705
C(answer_type_grouped)[T.Number]               1.0675      0.521      2.050      0.040       0.047       2.088
C(answer_type_grouped)[T.Other]                0.4532      0.480      0.944      0.345      -0.488       1.395
C(answer_type_grouped)[T.Person]               0.6368      0.447      1.425      0.154      -0.239       1.513
C(answer_type_grouped)[T.Place]                0.1405      0.834      0.169      0.866      -1.493       1.774
q_length                                      -0.2176      0.463     -0.470      0.638      -1.125       0.690
game_entropy                                 470.2804    182.696      2.574      0.010     112.202     828.359
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing gemini-2.5-flash-preview-04-17 (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_neutral/gemini-2.5-flash-preview-04-17_SimpleMC_redacted_temp0.0_1751839721_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    86
1    79
Name: count, dtype: int64

Answer change%: 0.4788 [0.40256507041902645, 0.5550106871567311] (n=165)
P-value vs 25%: 4.03e-09; P-value vs 0%: 7.868e-35
Phase 2 self-accuracy: 0.6709 [0.5672688257264862, 0.774503326172248] (n=79)
P-value vs 25%: 1.703e-15; P-value vs 33%: 1.645e-10

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  165
Model:                          Logit   Df Residuals:                      163
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                0.008473
Time:                        17:34:07   Log-Likelihood:                -113.25
converged:                       True   LL-Null:                       -114.22
Covariance Type:            nonrobust   LLR p-value:                    0.1642
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.1647      0.173     -0.951      0.342      -0.504       0.175
game_entropy   186.9246    205.488      0.910      0.363    -215.824     589.673
================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['Video games', 'History']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.500000
                        1                 0.500000
Geography               1                 0.538462
                        0                 0.461538
Misc                    1                 0.600000
                        0                 0.400000
Music                   0                 0.666667
                        1                 0.333333
Other                   0                 0.666667
                        1                 0.333333
Politics                1                 0.523810
                        0                 0.476190
Science and technology  0                 0.515152
                        1                 0.484848
Sports                  1                 0.583333
                        0                 0.416667
TV shows                0                 0.600000
                        1                 0.400000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 1                 0.555556
                     0                 0.444444
Number               0                 0.514286
                     1                 0.485714
Other                0                 0.619048
                     1                 0.380952
Person               0                 0.529412
                     1                 0.470588
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.500000  0.500000            4
                       Number               0.500000  0.500000            2
                       Other                0.500000  0.500000            4
                       Person               0.500000  0.500000            8
Geography              Date                 0.200000  0.800000            5
                       Number               0.571429  0.428571            7
                       Other                1.000000  0.000000            1
Misc                   Date                 0.333333  0.666667            9
                       Number               0.333333  0.666667            3
                       Other                0.500000  0.500000            6
                       Person               0.500000  0.500000            2
Music                  Date                 0.800000  0.200000            5
                       Number               0.333333  0.666667            3
                       Other                0.714286  0.285714            7
                       Person               0.666667  0.333333            3
Other                  Date                 0.571429  0.428571            7
                       Number               0.750000  0.250000            4
                       Other                0.500000  0.500000            2
                       Person               1.000000  0.000000            2
Politics               Date                 0.272727  0.727273           11
                       Number               1.000000  0.000000            2
                       Other                1.000000  0.000000            4
                       Person               0.250000  0.750000            4
Science and technology Date                 0.545455  0.454545           11
                       Number               0.428571  0.571429            7
                       Other                0.666667  0.333333            6
                       Person               0.444444  0.555556            9
Sports                 Number               0.500000  0.500000            6
                       Other                0.333333  0.666667            3
                       Person               0.333333  0.666667            3
TV shows               Date                 0.500000  0.500000            2
                       Number               0.000000  1.000000            1
                       Other                0.555556  0.444444            9
                       Person               1.000000  0.000000            3

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  165
Model:                          Logit   Df Residuals:                      152
Method:                           MLE   Df Model:                           12
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.04248
Time:                        17:34:07   Log-Likelihood:                -109.37
converged:                       True   LL-Null:                       -114.22
Covariance Type:            nonrobust   LLR p-value:                    0.6420
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      2.8798      2.065      1.394      0.163      -1.168       6.928
C(topic_grouped)[T.Geography]                 -0.0352      0.779     -0.045      0.964      -1.562       1.492
C(topic_grouped)[T.Misc]                       0.3934      0.681      0.578      0.563      -0.941       1.728
C(topic_grouped)[T.Music]                     -0.7946      0.712     -1.117      0.264      -2.189       0.600
C(topic_grouped)[T.Other]                     -0.9402      0.752     -1.250      0.211      -2.414       0.534
C(topic_grouped)[T.Politics]                  -0.0142      0.664     -0.021      0.983      -1.315       1.286
C(topic_grouped)[T.Science and technology]    -0.1266      0.599     -0.211      0.833      -1.300       1.047
C(topic_grouped)[T.Sports]                     0.4156      0.780      0.533      0.594      -1.113       1.944
C(topic_grouped)[T.TV shows]                  -0.3439      0.734     -0.468      0.639      -1.783       1.095
C(answer_type_grouped)[T.Number]              -0.4011      0.471     -0.853      0.394      -1.323       0.521
C(answer_type_grouped)[T.Other]               -0.8191      0.457     -1.791      0.073      -1.716       0.077
C(answer_type_grouped)[T.Person]              -0.4716      0.474     -0.996      0.319      -1.400       0.457
q_length                                      -0.5354      0.425     -1.259      0.208      -1.369       0.298
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  165
Model:                          Logit   Df Residuals:                      151
Method:                           MLE   Df Model:                           13
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.05676
Time:                        17:34:07   Log-Likelihood:                -107.74
converged:                       True   LL-Null:                       -114.22
Covariance Type:            nonrobust   LLR p-value:                    0.4505
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      2.8907      2.080      1.390      0.165      -1.186       6.967
C(topic_grouped)[T.Geography]                 -0.0462      0.780     -0.059      0.953      -1.576       1.483
C(topic_grouped)[T.Misc]                       0.3493      0.684      0.511      0.609      -0.990       1.689
C(topic_grouped)[T.Music]                     -0.7847      0.713     -1.101      0.271      -2.182       0.612
C(topic_grouped)[T.Other]                     -1.0518      0.762     -1.381      0.167      -2.545       0.441
C(topic_grouped)[T.Politics]                  -0.0345      0.666     -0.052      0.959      -1.339       1.270
C(topic_grouped)[T.Science and technology]    -0.1261      0.600     -0.210      0.833      -1.302       1.050
C(topic_grouped)[T.Sports]                     0.4134      0.781      0.529      0.597      -1.117       1.944
C(topic_grouped)[T.TV shows]                  -0.6098      0.771     -0.791      0.429      -2.121       0.901
C(answer_type_grouped)[T.Number]              -0.3891      0.473     -0.822      0.411      -1.317       0.539
C(answer_type_grouped)[T.Other]               -0.8896      0.462     -1.924      0.054      -1.796       0.017
C(answer_type_grouped)[T.Person]              -0.4626      0.476     -0.971      0.331      -1.396       0.471
q_length                                      -0.5525      0.430     -1.286      0.199      -1.395       0.290
game_entropy                                 286.6064    243.881      1.175      0.240    -191.392     764.604
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing gpt-4.1-2025-04-14 (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_neutral/gpt-4.1-2025-04-14_SimpleMC_redacted_cor_temp0.0_1751833247_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    233
1     22
Name: count, dtype: int64

Answer change%: 0.0863 [0.05181356967248026, 0.12073544993536287] (n=255)
P-value vs 25%: 1.256e-20; P-value vs 0%: 9.255e-07
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=22)
P-value vs 25%: 0; P-value vs 33%: 0

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  255
Model:                          Logit   Df Residuals:                      253
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.08077
Time:                        17:34:07   Log-Likelihood:                -68.875
converged:                       True   LL-Null:                       -74.927
Covariance Type:            nonrobust   LLR p-value:                 0.0005032
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          1.3763      1.004      1.371      0.170      -0.591       3.343
p_i_capability    -4.3106      1.197     -3.603      0.000      -6.656      -1.965
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  255
Model:                          Logit   Df Residuals:                      253
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.08503
Time:                        17:34:07   Log-Likelihood:                -68.557
converged:                       True   LL-Null:                       -74.927
Covariance Type:            nonrobust   LLR p-value:                 0.0003576
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -3.0138      0.335     -8.984      0.000      -3.671      -2.356
capabilities_entropy     1.4668      0.403      3.637      0.000       0.676       2.257
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.8889 [0.7437, 1.0000] (n=18)
                  P-value vs 33.3%: 6.382e-14

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=-7.20, p=1.07e-09
Wilcoxon delta_p: statistic=55.00, p=1.04e-10
Mean Δp = -0.1399  [-0.1780, -0.1018]
Idea 1 N = 62; 

  Idea 1.5: Calibration Metrics
  NLL: 0.2503, Signed ECE (overconf pos under neg): -0.2010, ECE: 0.2010 (n=76)
  Brier: 0.0703, Reliability (absolute calibration error; lower better): 0.0696, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=76)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.875
Model:                            OLS   Adj. R-squared:                  0.870
Method:                 Least Squares   F-statistic:                     168.7
Date:                Sat, 09 Aug 2025   Prob (F-statistic):           1.72e-32
Time:                        17:34:07   Log-Likelihood:                 60.139
No. Observations:                  76   AIC:                            -112.3
Df Residuals:                      72   BIC:                            -103.0
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.7081      0.068    -10.465      0.000      -0.843      -0.573
p1                    0.7037      0.082      8.591      0.000       0.540       0.867
answer_changed        0.4925      0.161      3.053      0.003       0.171       0.814
p1:answer_changed     0.2769      0.205      1.350      0.181      -0.132       0.686
==============================================================================
Omnibus:                       13.469   Durbin-Watson:                   2.117
Prob(Omnibus):                  0.001   Jarque-Bera (JB):               20.136
Skew:                           0.696   Prob(JB):                     4.24e-05
Kurtosis:                       5.103   Cond. No.                         26.7
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=3.74, p=0.000403
Wilcoxon delta_H: statistic=463.00, p=0.000318
Mean ΔH = 0.2061  [0.0982, 0.3141]
Paired t-test delta_H Changed: statistic=3.39, p=0.00485
Wilcoxon delta_H Changed: statistic=0.00, p=0.000122
Mean ΔH Changed = 0.4700  [0.1981, 0.7419]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=5.28, p=1.23e-06
Wilcoxon (p_top2_game vs p_top2_base): statistic=94.00, p=1.36e-12
Mean Δp_top2 = 0.0347  [0.0218, 0.0476] (n=76)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=4.84, p=6.67e-06
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=571.00, p=3.87e-06
Mean ΔH_unchosen_baseline_set = 0.2547  [0.1517, 0.3578] (n=76)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                   76
Model:                          Logit   Df Residuals:                       73
Method:                           MLE   Df Model:                            2
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.02606
Time:                        17:34:07   Log-Likelihood:                -35.361
converged:                       True   LL-Null:                       -36.307
Covariance Type:            nonrobust   LLR p-value:                    0.3883
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.1244      0.457     -2.458      0.014      -2.021      -0.228
p1_z            -0.4617      0.375     -1.230      0.219      -1.197       0.274
I(p1_z ** 2)    -0.4226      0.408     -1.035      0.301      -1.223       0.377
================================================================================
AUC = 0.586

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  255
Model:                          Logit   Df Residuals:                      253
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1914
Time:                        17:34:07   Log-Likelihood:                -60.590
converged:                       True   LL-Null:                       -74.927
Covariance Type:            nonrobust   LLR p-value:                 8.559e-08
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -3.1885      0.338     -9.441      0.000      -3.850      -2.527
game_entropy     3.0093      0.562      5.358      0.000       1.909       4.110
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=1879.00, p=7.83e-15
Paired t-test (game_entropy vs capabilities_entropy): statistic=-6.78, p=8.58e-11
Mean capabilities_entropy-game_entropy = 0.1566  [0.1113, 0.2019] (n=255)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  255
Model:                          Logit   Df Residuals:                      252
Method:                           MLE   Df Model:                            2
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1928
Time:                        17:34:07   Log-Likelihood:                -60.482
converged:                       True   LL-Null:                       -74.927
Covariance Type:            nonrobust   LLR p-value:                 5.325e-07
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -3.2518      0.370     -8.799      0.000      -3.976      -2.527
capabilities_entropy     0.2617      0.557      0.470      0.638      -0.830       1.353
game_entropy             2.8045      0.708      3.961      0.000       1.417       4.192
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': None
topic_grouped           answer_changed
Art                     0                 0.975610
                        1                 0.024390
Geography               0                 0.900000
                        1                 0.100000
Misc                    0                 0.891892
                        1                 0.108108
Music                   0                 1.000000
Other                   0                 0.875000
                        1                 0.125000
Politics                0                 0.925000
                        1                 0.075000
Science and technology  0                 0.906977
                        1                 0.093023
Sports                  0                 0.818182
                        1                 0.181818
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.840580
                     1                 0.159420
Number               0                 0.923077
                     1                 0.076923
Other                0                 0.950000
                     1                 0.050000
Person               0                 0.923077
                     1                 0.076923
Place                0                 1.000000
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 1.000000  0.000000            5
                       Number               0.750000  0.250000            4
                       Other                1.000000  0.000000            8
                       Person               1.000000  0.000000           19
                       Place                1.000000  0.000000            5
Geography              Date                 0.714286  0.285714            7
                       Number               1.000000  0.000000            4
                       Other                1.000000  0.000000            3
                       Place                1.000000  0.000000            6
Misc                   Date                 0.777778  0.222222            9
                       Number               1.000000  0.000000            4
                       Other                0.846154  0.153846           13
                       Person               1.000000  0.000000            9
                       Place                1.000000  0.000000            2
Music                  Date                 1.000000  0.000000            6
                       Number               1.000000  0.000000            1
                       Other                1.000000  0.000000            3
                       Person               1.000000  0.000000           10
Other                  Date                 0.625000  0.375000            8
                       Number               1.000000  0.000000            4
                       Other                0.857143  0.142857            7
                       Person               1.000000  0.000000           10
                       Place                1.000000  0.000000            3
Politics               Date                 0.875000  0.125000           16
                       Number               1.000000  0.000000            3
                       Other                1.000000  0.000000            9
                       Person               0.875000  0.125000            8
                       Place                1.000000  0.000000            4
Science and technology Date                 1.000000  0.000000           12
                       Number               1.000000  0.000000            3
                       Other                1.000000  0.000000           11
                       Person               0.764706  0.235294           17
Sports                 Date                 0.666667  0.333333            6
                       Number               0.666667  0.333333            3
                       Other                1.000000  0.000000            6
                       Person               0.800000  0.200000            5
                       Place                1.000000  0.000000            2

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  255
Model:                          Logit   Df Residuals:                      242
Method:                           MLE   Df Model:                           12
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1279
Time:                        17:34:07   Log-Likelihood:                -65.344
converged:                      False   LL-Null:                       -74.927
Covariance Type:            nonrobust   LLR p-value:                   0.08459
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.0800      3.041     -0.355      0.722      -7.040       4.880
C(topic_grouped)[T.Geography]                  1.4730      1.320      1.116      0.264      -1.114       4.060
C(topic_grouped)[T.Misc]                       1.5234      1.161      1.313      0.189      -0.751       3.798
C(topic_grouped)[T.Music]                    -24.9610   3.15e+05  -7.92e-05      1.000   -6.18e+05    6.18e+05
C(topic_grouped)[T.Other]                      1.6465      1.160      1.419      0.156      -0.628       3.921
C(topic_grouped)[T.Politics]                   1.0011      1.205      0.831      0.406      -1.361       3.363
C(topic_grouped)[T.Science and technology]     1.2210      1.153      1.059      0.290      -1.038       3.480
C(topic_grouped)[T.Sports]                     2.0897      1.178      1.774      0.076      -0.219       4.398
C(answer_type_grouped)[T.Number]              -0.9268      0.825     -1.123      0.261      -2.544       0.690
C(answer_type_grouped)[T.Other]               -1.4071      0.697     -2.018      0.044      -2.773      -0.041
C(answer_type_grouped)[T.Person]              -0.6516      0.572     -1.139      0.255      -1.773       0.469
C(answer_type_grouped)[T.Place]              -34.9698   1.85e+07  -1.89e-06      1.000   -3.62e+07    3.62e+07
q_length                                      -0.4036      0.632     -0.638      0.523      -1.643       0.836
==============================================================================================================

Possibly complete quasi-separation: A fraction 0.16 of observations can be
perfectly predicted. This might indicate that there is complete
quasi-separation. In this case some parameters will not be identified.

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.2957
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  255
Model:                          Logit   Df Residuals:                      241
Method:                           MLE   Df Model:                           13
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1881
Time:                        17:34:07   Log-Likelihood:                -60.831
converged:                      False   LL-Null:                       -74.927
Covariance Type:            nonrobust   LLR p-value:                  0.008509
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -2.6494      3.286     -0.806      0.420      -9.090       3.791
C(topic_grouped)[T.Geography]                  1.2052      1.346      0.896      0.370      -1.432       3.842
C(topic_grouped)[T.Misc]                       1.5819      1.191      1.329      0.184      -0.752       3.916
C(topic_grouped)[T.Music]                    -22.0065   7.37e+04     -0.000      1.000   -1.45e+05    1.44e+05
C(topic_grouped)[T.Other]                      1.6474      1.186      1.389      0.165      -0.677       3.972
C(topic_grouped)[T.Politics]                   1.2391      1.217      1.018      0.309      -1.146       3.624
C(topic_grouped)[T.Science and technology]     1.3134      1.176      1.117      0.264      -0.991       3.618
C(topic_grouped)[T.Sports]                     2.3315      1.206      1.934      0.053      -0.032       4.695
C(answer_type_grouped)[T.Number]              -1.1687      0.877     -1.332      0.183      -2.888       0.551
C(answer_type_grouped)[T.Other]               -1.0008      0.733     -1.366      0.172      -2.437       0.435
C(answer_type_grouped)[T.Person]              -0.2716      0.601     -0.452      0.651      -1.450       0.906
C(answer_type_grouped)[T.Place]              -23.8619   9.39e+04     -0.000      1.000   -1.84e+05    1.84e+05
q_length                                      -0.2501      0.686     -0.365      0.715      -1.595       1.095
capabilities_entropy                           1.3696      0.454      3.017      0.003       0.480       2.259
==============================================================================================================

Possibly complete quasi-separation: A fraction 0.16 of observations can be
perfectly predicted. This might indicate that there is complete
quasi-separation. In this case some parameters will not be identified.

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  255
Model:                          Logit   Df Residuals:                      241
Method:                           MLE   Df Model:                           13
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.3145
Time:                        17:34:07   Log-Likelihood:                -51.364
converged:                      False   LL-Null:                       -74.927
Covariance Type:            nonrobust   LLR p-value:                 9.196e-06
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -3.1748      3.586     -0.885      0.376     -10.203       3.853
C(topic_grouped)[T.Geography]                  0.0898      1.445      0.062      0.950      -2.742       2.922
C(topic_grouped)[T.Misc]                       1.4091      1.226      1.149      0.251      -0.994       3.812
C(topic_grouped)[T.Music]                    -28.1994   7.24e+05  -3.89e-05      1.000   -1.42e+06    1.42e+06
C(topic_grouped)[T.Other]                      0.9058      1.268      0.714      0.475      -1.580       3.392
C(topic_grouped)[T.Politics]                   0.6496      1.272      0.511      0.609      -1.843       3.142
C(topic_grouped)[T.Science and technology]     1.3056      1.201      1.087      0.277      -1.049       3.660
C(topic_grouped)[T.Sports]                     2.0352      1.226      1.660      0.097      -0.368       4.438
C(answer_type_grouped)[T.Number]              -1.7495      1.045     -1.674      0.094      -3.798       0.299
C(answer_type_grouped)[T.Other]               -0.8976      0.787     -1.141      0.254      -2.440       0.645
C(answer_type_grouped)[T.Person]              -0.3207      0.669     -0.480      0.631      -1.631       0.990
C(answer_type_grouped)[T.Place]              -22.9319   3.63e+04     -0.001      0.999   -7.13e+04    7.12e+04
q_length                                      -0.1227      0.746     -0.164      0.869      -1.586       1.340
game_entropy                                   3.5923      0.739      4.864      0.000       2.145       5.040
==============================================================================================================

Possibly complete quasi-separation: A fraction 0.16 of observations can be
perfectly predicted. This might indicate that there is complete
quasi-separation. In this case some parameters will not be identified.

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  255
Model:                          Logit   Df Residuals:                      240
Method:                           MLE   Df Model:                           14
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.3145
Time:                        17:34:07   Log-Likelihood:                -51.361
converged:                      False   LL-Null:                       -74.927
Covariance Type:            nonrobust   LLR p-value:                 1.828e-05
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -3.1984      3.602     -0.888      0.375     -10.258       3.861
C(topic_grouped)[T.Geography]                  0.0925      1.445      0.064      0.949      -2.739       2.924
C(topic_grouped)[T.Misc]                       1.4085      1.227      1.148      0.251      -0.997       3.814
C(topic_grouped)[T.Music]                    -29.3002   1.28e+06  -2.28e-05      1.000   -2.51e+06    2.51e+06
C(topic_grouped)[T.Other]                      0.9095      1.270      0.716      0.474      -1.580       3.399
C(topic_grouped)[T.Politics]                   0.6610      1.281      0.516      0.606      -1.850       3.172
C(topic_grouped)[T.Science and technology]     1.3103      1.204      1.089      0.276      -1.049       3.669
C(topic_grouped)[T.Sports]                     2.0459      1.236      1.656      0.098      -0.376       4.468
C(answer_type_grouped)[T.Number]              -1.7528      1.046     -1.676      0.094      -3.803       0.297
C(answer_type_grouped)[T.Other]               -0.8948      0.789     -1.134      0.257      -2.441       0.651
C(answer_type_grouped)[T.Person]              -0.3134      0.676     -0.464      0.643      -1.638       1.011
C(answer_type_grouped)[T.Place]              -23.0302   3.87e+04     -0.001      1.000   -7.58e+04    7.58e+04
q_length                                      -0.1216      0.747     -0.163      0.871      -1.585       1.342
capabilities_entropy                           0.0453      0.634      0.071      0.943      -1.198       1.289
game_entropy                                   3.5558      0.897      3.965      0.000       1.798       5.313
==============================================================================================================

Possibly complete quasi-separation: A fraction 0.16 of observations can be
perfectly predicted. This might indicate that there is complete
quasi-separation. In this case some parameters will not be identified.

                  Model 6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length (after removing deterministic categories: defaultdict(<class 'list'>, {'topic_grouped': ['Music'], 'answer_type_grouped': ['Place']}))
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  213
Model:                          Logit   Df Residuals:                      202
Method:                           MLE   Df Model:                           10
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.07665
Time:                        17:34:07   Log-Likelihood:                -65.344
converged:                       True   LL-Null:                       -70.768
Covariance Type:            nonrobust   LLR p-value:                    0.3695
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.0800      3.041     -0.355      0.722      -7.040       4.880
C(topic_grouped)[T.Geography]                  1.4730      1.320      1.116      0.264      -1.114       4.060
C(topic_grouped)[T.Misc]                       1.5234      1.161      1.313      0.189      -0.751       3.798
C(topic_grouped)[T.Other]                      1.6465      1.160      1.419      0.156      -0.628       3.921
C(topic_grouped)[T.Politics]                   1.0011      1.205      0.831      0.406      -1.361       3.363
C(topic_grouped)[T.Science and technology]     1.2210      1.153      1.059      0.290      -1.038       3.480
C(topic_grouped)[T.Sports]                     2.0897      1.178      1.774      0.076      -0.219       4.398
C(answer_type_grouped)[T.Number]              -0.9268      0.825     -1.123      0.261      -2.544       0.690
C(answer_type_grouped)[T.Other]               -1.4071      0.697     -2.018      0.044      -2.773      -0.041
C(answer_type_grouped)[T.Person]              -0.6516      0.572     -1.139      0.255      -1.773       0.469
q_length                                      -0.4036      0.632     -0.638      0.523      -1.643       0.836
==============================================================================================================

                  Model 6.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  213
Model:                          Logit   Df Residuals:                      201
Method:                           MLE   Df Model:                           11
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1404
Time:                        17:34:07   Log-Likelihood:                -60.831
converged:                       True   LL-Null:                       -70.768
Covariance Type:            nonrobust   LLR p-value:                   0.04711
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -2.6494      3.286     -0.806      0.420      -9.090       3.791
C(topic_grouped)[T.Geography]                  1.2052      1.346      0.896      0.370      -1.432       3.842
C(topic_grouped)[T.Misc]                       1.5819      1.191      1.329      0.184      -0.752       3.916
C(topic_grouped)[T.Other]                      1.6474      1.186      1.389      0.165      -0.677       3.972
C(topic_grouped)[T.Politics]                   1.2391      1.217      1.018      0.309      -1.146       3.624
C(topic_grouped)[T.Science and technology]     1.3134      1.176      1.117      0.264      -0.991       3.618
C(topic_grouped)[T.Sports]                     2.3315      1.206      1.934      0.053      -0.032       4.695
C(answer_type_grouped)[T.Number]              -1.1687      0.877     -1.332      0.183      -2.888       0.551
C(answer_type_grouped)[T.Other]               -1.0008      0.733     -1.366      0.172      -2.437       0.435
C(answer_type_grouped)[T.Person]              -0.2716      0.601     -0.452      0.651      -1.450       0.906
q_length                                      -0.2501      0.686     -0.365      0.715      -1.595       1.095
capabilities_entropy                           1.3696      0.454      3.017      0.003       0.480       2.259
==============================================================================================================

--- Analyzing gpt-4.1-2025-04-14 (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_neutral/gpt-4.1-2025-04-14_SimpleMC_redacted_temp0.0_1751825599_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    169
1     68
Name: count, dtype: int64

Answer change%: 0.2869 [0.2293329736140256, 0.34450668883323177] (n=237)
P-value vs 25%: 0.2089; P-value vs 0%: 1.587e-22
Phase 2 self-accuracy: 0.4118 [0.2947895228807646, 0.5287398888839413] (n=68)
P-value vs 25%: 0.00672; P-value vs 33%: 0.1869

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  237
Model:                          Logit   Df Residuals:                      235
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1320
Time:                        17:34:07   Log-Likelihood:                -123.30
converged:                       True   LL-Null:                       -142.05
Covariance Type:            nonrobust   LLR p-value:                 9.154e-10
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          2.6446      0.620      4.268      0.000       1.430       3.859
p_i_capability    -4.5187      0.785     -5.758      0.000      -6.057      -2.980
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  237
Model:                          Logit   Df Residuals:                      235
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1463
Time:                        17:34:07   Log-Likelihood:                -121.27
converged:                       True   LL-Null:                       -142.05
Covariance Type:            nonrobust   LLR p-value:                 1.146e-10
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.1280      0.279     -7.634      0.000      -2.674      -1.582
capabilities_entropy     1.7016      0.287      5.920      0.000       1.138       2.265
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.7031 [0.5912, 0.8151] (n=64)
                  P-value vs 33.3%: 9.477e-11

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=-5.15, p=1.83e-06
Wilcoxon delta_p: statistic=579.00, p=3.54e-07
Mean Δp = -0.1053  [-0.1453, -0.0652]
Idea 1 N = 81; 

  Idea 1.5: Calibration Metrics
  NLL: 4.3381, Signed ECE (overconf pos under neg): 0.1122, ECE: 0.1122 (n=133)
  Brier: 0.0278, Reliability (absolute calibration error; lower better): 0.0269, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=133)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.874
Model:                            OLS   Adj. R-squared:                  0.871
Method:                 Least Squares   F-statistic:                     297.2
Date:                Sat, 09 Aug 2025   Prob (F-statistic):           9.76e-58
Time:                        17:34:07   Log-Likelihood:                 80.355
No. Observations:                 133   AIC:                            -152.7
Df Residuals:                     129   BIC:                            -141.1
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.6409      0.067     -9.637      0.000      -0.772      -0.509
p1                    0.6741      0.082      8.265      0.000       0.513       0.835
answer_changed        0.5447      0.094      5.792      0.000       0.359       0.731
p1:answer_changed     0.2934      0.127      2.308      0.023       0.042       0.545
==============================================================================
Omnibus:                       11.350   Durbin-Watson:                   1.997
Prob(Omnibus):                  0.003   Jarque-Bera (JB):               15.698
Skew:                           0.469   Prob(JB):                     0.000390
Kurtosis:                       4.398   Cond. No.                         20.2
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=4.64, p=1.35e-05
Wilcoxon delta_H: statistic=629.00, p=1.19e-06
Mean ΔH = 0.2381  [0.1375, 0.3388]
Paired t-test delta_H Changed: statistic=8.12, p=9.5e-11
Wilcoxon delta_H Changed: statistic=73.00, p=2.02e-08
Mean ΔH Changed = 0.5435  [0.4123, 0.6747]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=6.49, p=1.59e-09
Wilcoxon (p_top2_game vs p_top2_base): statistic=1176.00, p=1.77e-13
Mean Δp_top2 = 0.0477  [0.0333, 0.0622] (n=133)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=8.38, p=6.73e-14
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=1167.00, p=1.52e-13
Mean ΔH_unchosen_baseline_set = 0.3575  [0.2739, 0.4411] (n=133)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  133
Model:                          Logit   Df Residuals:                      130
Method:                           MLE   Df Model:                            2
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.09255
Time:                        17:34:07   Log-Likelihood:                -80.764
converged:                       True   LL-Null:                       -89.001
Covariance Type:            nonrobust   LLR p-value:                 0.0002646
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.3904      0.267     -1.465      0.143      -0.913       0.132
p1_z            -0.7983      0.219     -3.648      0.000      -1.227      -0.369
I(p1_z ** 2)    -0.1162      0.211     -0.550      0.582      -0.530       0.298
================================================================================
AUC = 0.704

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  237
Model:                          Logit   Df Residuals:                      235
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1053
Time:                        17:34:07   Log-Likelihood:                -127.09
converged:                       True   LL-Null:                       -142.05
Covariance Type:            nonrobust   LLR p-value:                 4.514e-08
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.5813      0.208     -7.587      0.000      -1.990      -1.173
game_entropy     1.7580      0.339      5.187      0.000       1.094       2.422
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=4087.00, p=2.31e-17
Paired t-test (game_entropy vs capabilities_entropy): statistic=-8.80, p=2.86e-16
Mean capabilities_entropy-game_entropy = 0.2854  [0.2219, 0.3489] (n=237)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  237
Model:                          Logit   Df Residuals:                      234
Method:                           MLE   Df Model:                            2
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1680
Time:                        17:34:07   Log-Likelihood:                -118.18
converged:                       True   LL-Null:                       -142.05
Covariance Type:            nonrobust   LLR p-value:                 4.315e-11
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.2233      0.285     -7.791      0.000      -2.783      -1.664
capabilities_entropy     1.3189      0.323      4.087      0.000       0.686       1.951
game_entropy             0.9816      0.396      2.480      0.013       0.206       1.757
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'Video games', 'History']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.727273
                        1                 0.272727
Geography               0                 0.695652
                        1                 0.304348
Misc                    0                 0.621622
                        1                 0.378378
Music                   0                 0.800000
                        1                 0.200000
Other                   0                 0.631579
                        1                 0.368421
Politics                0                 0.742857
                        1                 0.257143
Science and technology  0                 0.716981
                        1                 0.283019
Sports                  0                 0.823529
                        1                 0.176471
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.739583
                     1                 0.260417
Number               0                 0.686275
                     1                 0.313725
Other                0                 0.740000
                     1                 0.260000
Person               0                 0.650000
                     1                 0.350000
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.733333  0.266667           15
                       Number               0.600000  0.400000            5
                       Other                0.800000  0.200000            5
                       Person               0.750000  0.250000            8
Geography              Date                 0.571429  0.428571            7
                       Number               0.785714  0.214286           14
                       Other                0.500000  0.500000            2
Misc                   Date                 0.714286  0.285714           14
                       Number               0.800000  0.200000            5
                       Other                0.666667  0.333333           12
                       Person               0.166667  0.833333            6
Music                  Date                 1.000000  0.000000            6
                       Number               0.333333  0.666667            3
                       Other                0.777778  0.222222            9
                       Person               1.000000  0.000000            2
Other                  Date                 0.700000  0.300000           10
                       Number               0.333333  0.666667            3
                       Other                1.000000  0.000000            4
                       Person               0.000000  1.000000            2
Politics               Date                 0.736842  0.263158           19
                       Number               0.666667  0.333333            3
                       Other                0.857143  0.142857            7
                       Person               0.666667  0.333333            6
Science and technology Date                 0.772727  0.227273           22
                       Number               0.636364  0.363636           11
                       Other                0.571429  0.428571            7
                       Person               0.769231  0.230769           13
Sports                 Date                 0.666667  0.333333            3
                       Number               0.857143  0.142857            7
                       Other                0.750000  0.250000            4
                       Person               1.000000  0.000000            3

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  237
Model:                          Logit   Df Residuals:                      225
Method:                           MLE   Df Model:                           11
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.03349
Time:                        17:34:07   Log-Likelihood:                -137.29
converged:                       True   LL-Null:                       -142.05
Covariance Type:            nonrobust   LLR p-value:                    0.5746
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      2.2799      1.909      1.194      0.232      -1.462       6.021
C(topic_grouped)[T.Geography]                  0.1070      0.628      0.170      0.865      -1.123       1.337
C(topic_grouped)[T.Misc]                       0.5642      0.528      1.069      0.285      -0.470       1.598
C(topic_grouped)[T.Music]                     -0.4056      0.698     -0.581      0.561      -1.774       0.963
C(topic_grouped)[T.Other]                      0.4426      0.627      0.706      0.480      -0.787       1.672
C(topic_grouped)[T.Politics]                   0.1189      0.564      0.211      0.833      -0.986       1.223
C(topic_grouped)[T.Science and technology]     0.0558      0.503      0.111      0.912      -0.930       1.041
C(topic_grouped)[T.Sports]                    -0.5254      0.762     -0.690      0.490      -2.018       0.967
C(answer_type_grouped)[T.Number]               0.3484      0.408      0.853      0.394      -0.452       1.149
C(answer_type_grouped)[T.Other]               -0.0605      0.415     -0.146      0.884      -0.874       0.753
C(answer_type_grouped)[T.Person]               0.3323      0.425      0.782      0.434      -0.500       1.165
q_length                                      -0.7623      0.414     -1.842      0.066      -1.574       0.049
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.6136
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  237
Model:                          Logit   Df Residuals:                      224
Method:                           MLE   Df Model:                           12
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1966
Time:                        17:34:07   Log-Likelihood:                -114.12
converged:                       True   LL-Null:                       -142.05
Covariance Type:            nonrobust   LLR p-value:                 1.269e-07
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      0.1945      2.129      0.091      0.927      -3.978       4.367
C(topic_grouped)[T.Geography]                  0.0389      0.701      0.055      0.956      -1.335       1.412
C(topic_grouped)[T.Misc]                       0.3622      0.592      0.612      0.541      -0.798       1.522
C(topic_grouped)[T.Music]                     -0.4953      0.789     -0.627      0.530      -2.043       1.052
C(topic_grouped)[T.Other]                      0.7218      0.724      0.997      0.319      -0.697       2.140
C(topic_grouped)[T.Politics]                   0.2432      0.630      0.386      0.699      -0.991       1.477
C(topic_grouped)[T.Science and technology]    -0.1819      0.569     -0.320      0.749      -1.296       0.933
C(topic_grouped)[T.Sports]                    -0.1596      0.823     -0.194      0.846      -1.773       1.453
C(answer_type_grouped)[T.Number]               0.8947      0.462      1.938      0.053      -0.010       1.799
C(answer_type_grouped)[T.Other]                0.3812      0.473      0.806      0.420      -0.546       1.308
C(answer_type_grouped)[T.Person]               1.2510      0.521      2.403      0.016       0.231       2.271
q_length                                      -0.6902      0.458     -1.507      0.132      -1.588       0.208
capabilities_entropy                           1.9866      0.328      6.063      0.000       1.344       2.629
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  237
Model:                          Logit   Df Residuals:                      224
Method:                           MLE   Df Model:                           12
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1506
Time:                        17:34:07   Log-Likelihood:                -120.66
converged:                       True   LL-Null:                       -142.05
Covariance Type:            nonrobust   LLR p-value:                 2.463e-05
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      1.0228      2.071      0.494      0.621      -3.037       5.082
C(topic_grouped)[T.Geography]                  0.0657      0.675      0.097      0.923      -1.258       1.389
C(topic_grouped)[T.Misc]                       0.5199      0.562      0.924      0.355      -0.582       1.622
C(topic_grouped)[T.Music]                     -0.9164      0.791     -1.159      0.246      -2.466       0.633
C(topic_grouped)[T.Other]                      0.4341      0.690      0.629      0.529      -0.918       1.786
C(topic_grouped)[T.Politics]                   0.1539      0.602      0.256      0.798      -1.026       1.334
C(topic_grouped)[T.Science and technology]    -0.3299      0.550     -0.599      0.549      -1.409       0.749
C(topic_grouped)[T.Sports]                    -0.6934      0.802     -0.865      0.387      -2.265       0.878
C(answer_type_grouped)[T.Number]               0.4772      0.441      1.083      0.279      -0.386       1.341
C(answer_type_grouped)[T.Other]                0.0789      0.453      0.174      0.862      -0.809       0.967
C(answer_type_grouped)[T.Person]               0.7608      0.473      1.609      0.108      -0.166       1.688
q_length                                      -0.6516      0.449     -1.452      0.146      -1.531       0.228
game_entropy                                   1.9968      0.372      5.372      0.000       1.268       2.725
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  237
Model:                          Logit   Df Residuals:                      223
Method:                           MLE   Df Model:                           13
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.2238
Time:                        17:34:07   Log-Likelihood:                -110.25
converged:                       True   LL-Null:                       -142.05
Covariance Type:            nonrobust   LLR p-value:                 1.185e-08
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -0.0490      2.190     -0.022      0.982      -4.341       4.243
C(topic_grouped)[T.Geography]                  0.0387      0.719      0.054      0.957      -1.370       1.447
C(topic_grouped)[T.Misc]                       0.4226      0.600      0.705      0.481      -0.753       1.598
C(topic_grouped)[T.Music]                     -0.9251      0.859     -1.077      0.282      -2.609       0.759
C(topic_grouped)[T.Other]                      0.7367      0.725      1.016      0.309      -0.684       2.157
C(topic_grouped)[T.Politics]                   0.2609      0.634      0.411      0.681      -0.982       1.504
C(topic_grouped)[T.Science and technology]    -0.3253      0.584     -0.557      0.578      -1.470       0.819
C(topic_grouped)[T.Sports]                    -0.3316      0.840     -0.395      0.693      -1.978       1.314
C(answer_type_grouped)[T.Number]               0.8546      0.470      1.817      0.069      -0.067       1.776
C(answer_type_grouped)[T.Other]                0.3717      0.487      0.764      0.445      -0.582       1.326
C(answer_type_grouped)[T.Person]               1.3042      0.527      2.476      0.013       0.272       2.336
q_length                                      -0.6558      0.472     -1.390      0.165      -1.581       0.269
capabilities_entropy                           1.5577      0.359      4.340      0.000       0.854       2.261
game_entropy                                   1.1732      0.424      2.769      0.006       0.343       2.004
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing gpt-4o-2024-08-06 (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_neutral/gpt-4o-2024-08-06_SimpleMC_redacted_cor_temp0.0_1751845435_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    220
1     33
Name: count, dtype: int64

Answer change%: 0.1304 [0.08893597486986282, 0.17193359034752848] (n=253)
P-value vs 25%: 1.633e-08; P-value vs 0%: 7.258e-10
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=33)
P-value vs 25%: 0; P-value vs 33%: 0

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  253
Model:                          Logit   Df Residuals:                      251
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.05712
Time:                        17:34:07   Log-Likelihood:                -92.369
converged:                       True   LL-Null:                       -97.965
Covariance Type:            nonrobust   LLR p-value:                 0.0008215
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept         -0.5857      0.399     -1.469      0.142      -1.367       0.196
p_i_capability    -1.9112      0.561     -3.405      0.001      -3.011      -0.811
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  253
Model:                          Logit   Df Residuals:                      251
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.2607
Time:                        17:34:07   Log-Likelihood:                -72.423
converged:                       True   LL-Null:                       -97.965
Covariance Type:            nonrobust   LLR p-value:                 8.855e-13
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -4.1187      0.544     -7.567      0.000      -5.185      -3.052
capabilities_entropy     2.3327      0.405      5.758      0.000       1.539       3.127
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.8182 [0.6866, 0.9498] (n=33)
                  P-value vs 33.3%: 5.147e-13

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=-4.40, p=1.8e-05
Wilcoxon delta_p: statistic=5378.00, p=7.26e-07
Mean Δp = -0.0361  [-0.0522, -0.0200]
Idea 1 N = 191; 

  Idea 1.5: Calibration Metrics
  NLL: 0.2622, Signed ECE (overconf pos under neg): -0.1972, ECE: 0.1972 (n=223)
  Brier: 0.0839, Reliability (absolute calibration error; lower better): 0.0832, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=223)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.695
Model:                            OLS   Adj. R-squared:                  0.691
Method:                 Least Squares   F-statistic:                     166.2
Date:                Sat, 09 Aug 2025   Prob (F-statistic):           3.56e-56
Time:                        17:34:07   Log-Likelihood:                 195.82
No. Observations:                 223   AIC:                            -383.6
Df Residuals:                     219   BIC:                            -370.0
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.2997      0.033     -9.092      0.000      -0.365      -0.235
p1                    0.3133      0.038      8.202      0.000       0.238       0.389
answer_changed        0.0541      0.069      0.783      0.435      -0.082       0.190
p1:answer_changed     0.6735      0.108      6.215      0.000       0.460       0.887
==============================================================================
Omnibus:                       26.351   Durbin-Watson:                   1.845
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               74.121
Skew:                           0.463   Prob(JB):                     8.03e-17
Kurtosis:                       5.669   Cond. No.                         24.6
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-0.59, p=0.559
Wilcoxon delta_H: statistic=8967.00, p=0.793
Mean ΔH = -0.0171  [-0.0744, 0.0401]
Paired t-test delta_H Changed: statistic=5.31, p=8.94e-06
Wilcoxon delta_H Changed: statistic=22.00, p=9.48e-06
Mean ΔH Changed = 0.4030  [0.2541, 0.5519]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=5.75, p=2.92e-08
Wilcoxon (p_top2_game vs p_top2_base): statistic=6868.00, p=5.66e-09
Mean Δp_top2 = 0.0238  [0.0157, 0.0319] (n=223)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=1.49, p=0.137
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=10825.00, p=0.105
Mean ΔH_unchosen_baseline_set = 0.0432  [-0.0136, 0.1000] (n=223)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  223
Model:                          Logit   Df Residuals:                      220
Method:                           MLE   Df Model:                            2
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.2341
Time:                        17:34:07   Log-Likelihood:                -70.239
converged:                       True   LL-Null:                       -91.712
Covariance Type:            nonrobust   LLR p-value:                 4.726e-10
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -2.3171      0.337     -6.871      0.000      -2.978      -1.656
p1_z            -1.4773      0.402     -3.677      0.000      -2.265      -0.690
I(p1_z ** 2)    -0.1359      0.273     -0.498      0.618      -0.670       0.398
================================================================================
AUC = 0.842

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  253
Model:                          Logit   Df Residuals:                      251
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.2419
Time:                        17:34:07   Log-Likelihood:                -74.272
converged:                       True   LL-Null:                       -97.965
Covariance Type:            nonrobust   LLR p-value:                 5.829e-12
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -3.7360      0.465     -8.026      0.000      -4.648      -2.824
game_entropy     2.3456      0.402      5.832      0.000       1.557       3.134
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=9188.00, p=3.57e-09
Paired t-test (game_entropy vs capabilities_entropy): statistic=-5.80, p=2.03e-08
Mean capabilities_entropy-game_entropy = 0.1090  [0.0721, 0.1458] (n=253)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  253
Model:                          Logit   Df Residuals:                      250
Method:                           MLE   Df Model:                            2
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.2719
Time:                        17:34:07   Log-Likelihood:                -71.329
converged:                       True   LL-Null:                       -97.965
Covariance Type:            nonrobust   LLR p-value:                 2.707e-12
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -4.1761      0.553     -7.558      0.000      -5.259      -3.093
capabilities_entropy     1.5731      0.654      2.407      0.016       0.292       2.854
game_entropy             0.9777      0.674      1.450      0.147      -0.344       2.299
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': None
topic_grouped           answer_changed
Art                     0                 0.880952
                        1                 0.119048
Geography               0                 0.818182
                        1                 0.181818
Misc                    0                 0.857143
                        1                 0.142857
Music                   0                 0.750000
                        1                 0.250000
Other                   0                 0.925926
                        1                 0.074074
Politics                0                 0.871795
                        1                 0.128205
Science and technology  0                 0.886364
                        1                 0.113636
Sports                  0                 0.904762
                        1                 0.095238
TV shows                0                 0.882353
                        1                 0.117647
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.837838
                     1                 0.162162
Number               0                 0.756757
                     1                 0.243243
Other                0                 0.933333
                     1                 0.066667
Person               0                 0.906250
                     1                 0.093750
Place                0                 0.888889
                     1                 0.111111
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.666667  0.333333            6
                       Number               0.714286  0.285714            7
                       Other                1.000000  0.000000            6
                       Person               0.947368  0.052632           19
                       Place                1.000000  0.000000            4
Geography              Date                 0.833333  0.166667            6
                       Number               0.625000  0.375000            8
                       Other                1.000000  0.000000            3
                       Place                1.000000  0.000000            5
Misc                   Date                 0.727273  0.272727           11
                       Number               1.000000  0.000000            3
                       Other                1.000000  0.000000            3
                       Person               1.000000  0.000000            2
                       Place                1.000000  0.000000            2
Music                  Date                 0.750000  0.250000            4
                       Number               1.000000  0.000000            2
                       Other                0.500000  0.500000            4
                       Person               0.800000  0.200000           10
Other                  Date                 0.900000  0.100000           10
                       Number               1.000000  0.000000            3
                       Other                1.000000  0.000000            4
                       Person               1.000000  0.000000            7
                       Place                0.666667  0.333333            3
Politics               Date                 0.800000  0.200000           15
                       Number               0.800000  0.200000            5
                       Other                1.000000  0.000000           11
                       Person               0.833333  0.166667            6
                       Place                1.000000  0.000000            2
Science and technology Date                 0.941176  0.058824           17
                       Number               0.571429  0.428571            7
                       Other                1.000000  0.000000           10
                       Person               0.900000  0.100000           10
Sports                 Date                 1.000000  0.000000            4
                       Number               1.000000  0.000000            1
                       Other                0.875000  0.125000            8
                       Person               1.000000  0.000000            6
                       Place                0.500000  0.500000            2
TV shows               Date                 1.000000  0.000000            1
                       Number               1.000000  0.000000            1
                       Other                0.909091  0.090909           11
                       Person               0.750000  0.250000            4

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  253
Model:                          Logit   Df Residuals:                      239
Method:                           MLE   Df Model:                           13
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.06130
Time:                        17:34:07   Log-Likelihood:                -91.959
converged:                       True   LL-Null:                       -97.965
Covariance Type:            nonrobust   LLR p-value:                    0.5267
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.0060      2.383     -0.422      0.673      -5.677       3.665
C(topic_grouped)[T.Geography]                  0.0916      0.767      0.119      0.905      -1.412       1.596
C(topic_grouped)[T.Misc]                      -0.0495      0.818     -0.060      0.952      -1.653       1.555
C(topic_grouped)[T.Music]                      1.0550      0.732      1.442      0.149      -0.379       2.489
C(topic_grouped)[T.Other]                     -0.6466      0.896     -0.722      0.470      -2.402       1.109
C(topic_grouped)[T.Politics]                   0.0234      0.717      0.033      0.974      -1.381       1.428
C(topic_grouped)[T.Science and technology]    -0.1655      0.707     -0.234      0.815      -1.551       1.220
C(topic_grouped)[T.Sports]                    -0.0666      0.909     -0.073      0.942      -1.848       1.715
C(topic_grouped)[T.TV shows]                   0.4118      0.952      0.433      0.665      -1.453       2.277
C(answer_type_grouped)[T.Number]               0.4598      0.517      0.889      0.374      -0.554       1.473
C(answer_type_grouped)[T.Other]               -1.1701      0.648     -1.806      0.071      -2.440       0.100
C(answer_type_grouped)[T.Person]              -0.8503      0.580     -1.467      0.142      -1.986       0.286
C(answer_type_grouped)[T.Place]               -0.3920      0.843     -0.465      0.642      -2.043       1.259
q_length                                      -0.1347      0.513     -0.263      0.793      -1.140       0.871
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.6088
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  253
Model:                          Logit   Df Residuals:                      238
Method:                           MLE   Df Model:                           14
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.3198
Time:                        17:34:07   Log-Likelihood:                -66.640
converged:                       True   LL-Null:                       -97.965
Covariance Type:            nonrobust   LLR p-value:                 4.003e-08
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -6.2662      3.210     -1.952      0.051     -12.558       0.025
C(topic_grouped)[T.Geography]                  0.4209      0.874      0.482      0.630      -1.292       2.134
C(topic_grouped)[T.Misc]                       0.9342      0.951      0.982      0.326      -0.931       2.799
C(topic_grouped)[T.Music]                      2.3183      0.953      2.433      0.015       0.450       4.186
C(topic_grouped)[T.Other]                     -0.8098      0.995     -0.814      0.416      -2.760       1.141
C(topic_grouped)[T.Politics]                   0.6061      0.857      0.707      0.479      -1.073       2.286
C(topic_grouped)[T.Science and technology]     0.3512      0.840      0.418      0.676      -1.295       1.998
C(topic_grouped)[T.Sports]                     0.3072      1.061      0.290      0.772      -1.772       2.387
C(topic_grouped)[T.TV shows]                   0.6216      1.237      0.502      0.615      -1.803       3.047
C(answer_type_grouped)[T.Number]               0.1866      0.584      0.319      0.749      -0.958       1.332
C(answer_type_grouped)[T.Other]               -0.3061      0.834     -0.367      0.714      -1.941       1.329
C(answer_type_grouped)[T.Person]               0.7943      0.764      1.040      0.298      -0.703       2.292
C(answer_type_grouped)[T.Place]                0.2405      0.996      0.241      0.809      -1.711       2.192
q_length                                       0.1935      0.664      0.292      0.771      -1.107       1.494
capabilities_entropy                           2.8814      0.537      5.365      0.000       1.829       3.934
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  253
Model:                          Logit   Df Residuals:                      238
Method:                           MLE   Df Model:                           14
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.2805
Time:                        17:34:07   Log-Likelihood:                -70.486
converged:                       True   LL-Null:                       -97.965
Covariance Type:            nonrobust   LLR p-value:                 8.803e-07
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -3.3098      2.845     -1.163      0.245      -8.886       2.266
C(topic_grouped)[T.Geography]                 -0.0404      0.859     -0.047      0.962      -1.723       1.642
C(topic_grouped)[T.Misc]                       0.4453      0.892      0.499      0.618      -1.304       2.194
C(topic_grouped)[T.Music]                      1.8385      0.914      2.011      0.044       0.047       3.630
C(topic_grouped)[T.Other]                     -0.4179      0.980     -0.427      0.670      -2.338       1.502
C(topic_grouped)[T.Politics]                   0.5052      0.822      0.614      0.539      -1.107       2.117
C(topic_grouped)[T.Science and technology]    -0.1196      0.810     -0.148      0.883      -1.707       1.468
C(topic_grouped)[T.Sports]                     0.2694      1.036      0.260      0.795      -1.760       2.299
C(topic_grouped)[T.TV shows]                   0.4802      1.128      0.426      0.670      -1.731       2.691
C(answer_type_grouped)[T.Number]               0.1464      0.575      0.255      0.799      -0.981       1.273
C(answer_type_grouped)[T.Other]               -0.7252      0.823     -0.882      0.378      -2.337       0.887
C(answer_type_grouped)[T.Person]               0.2482      0.692      0.359      0.720      -1.108       1.604
C(answer_type_grouped)[T.Place]               -0.1829      0.965     -0.190      0.850      -2.074       1.708
q_length                                      -0.1911      0.616     -0.310      0.756      -1.399       1.017
game_entropy                                   2.5546      0.474      5.388      0.000       1.625       3.484
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  253
Model:                          Logit   Df Residuals:                      237
Method:                           MLE   Df Model:                           15
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.3271
Time:                        17:34:07   Log-Likelihood:                -65.919
converged:                       True   LL-Null:                       -97.965
Covariance Type:            nonrobust   LLR p-value:                 4.927e-08
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -5.8343      3.211     -1.817      0.069     -12.128       0.459
C(topic_grouped)[T.Geography]                  0.2595      0.882      0.294      0.769      -1.469       1.988
C(topic_grouped)[T.Misc]                       0.8463      0.942      0.898      0.369      -1.000       2.693
C(topic_grouped)[T.Music]                      2.3311      0.966      2.413      0.016       0.438       4.225
C(topic_grouped)[T.Other]                     -0.7060      0.998     -0.708      0.479      -2.662       1.250
C(topic_grouped)[T.Politics]                   0.5889      0.853      0.690      0.490      -1.084       2.262
C(topic_grouped)[T.Science and technology]     0.2077      0.844      0.246      0.806      -1.447       1.862
C(topic_grouped)[T.Sports]                     0.2956      1.071      0.276      0.782      -1.803       2.394
C(topic_grouped)[T.TV shows]                   0.5339      1.234      0.433      0.665      -1.885       2.953
C(answer_type_grouped)[T.Number]               0.1305      0.590      0.221      0.825      -1.026       1.287
C(answer_type_grouped)[T.Other]               -0.3463      0.865     -0.401      0.689      -2.041       1.348
C(answer_type_grouped)[T.Person]               0.8247      0.757      1.090      0.276      -0.658       2.307
C(answer_type_grouped)[T.Place]                0.1413      1.009      0.140      0.889      -1.835       2.118
q_length                                       0.0967      0.666      0.145      0.885      -1.209       1.402
capabilities_entropy                           2.2225      0.761      2.920      0.003       0.731       3.714
game_entropy                                   0.8750      0.736      1.189      0.234      -0.567       2.317
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing gpt-4o-2024-08-06 (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_neutral/gpt-4o-2024-08-06_SimpleMC_redacted_temp0.0_1751827128_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    171
1     76
Name: count, dtype: int64

Answer change%: 0.3077 [0.25013406679950173, 0.3652505485851137] (n=247)
P-value vs 25%: 0.04947; P-value vs 0%: 1.096e-25
Phase 2 self-accuracy: 0.5263 [0.41405994827462134, 0.638571630672747] (n=76)
P-value vs 25%: 1.404e-06; P-value vs 33%: 0.0007375

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  247
Model:                          Logit   Df Residuals:                      245
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.09500
Time:                        17:34:07   Log-Likelihood:                -137.98
converged:                       True   LL-Null:                       -152.46
Covariance Type:            nonrobust   LLR p-value:                 7.361e-08
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          1.6559      0.503      3.294      0.001       0.671       2.641
p_i_capability    -3.8150      0.775     -4.923      0.000      -5.334      -2.296
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  247
Model:                          Logit   Df Residuals:                      245
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1182
Time:                        17:34:07   Log-Likelihood:                -134.44
converged:                       True   LL-Null:                       -152.46
Covariance Type:            nonrobust   LLR p-value:                 1.929e-09
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.8088      0.437     -6.435      0.000      -3.664      -1.953
capabilities_entropy     1.7251      0.327      5.271      0.000       1.084       2.366
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.7237 [0.6231, 0.8242] (n=76)
                  P-value vs 33.3%: 2.741e-14

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=-4.96, p=1.71e-06
Wilcoxon delta_p: statistic=4061.00, p=2.37e-06
Mean Δp = -0.0558  [-0.0778, -0.0338]
Idea 1 N = 167; 

  Idea 1.5: Calibration Metrics
  NLL: 3.1002, Signed ECE (overconf pos under neg): 0.1415, ECE: 0.1415 (n=242)
  Brier: 0.0369, Reliability (absolute calibration error; lower better): 0.0359, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=242)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.729
Model:                            OLS   Adj. R-squared:                  0.725
Method:                 Least Squares   F-statistic:                     212.9
Date:                Sat, 09 Aug 2025   Prob (F-statistic):           4.26e-67
Time:                        17:34:07   Log-Likelihood:                 152.50
No. Observations:                 242   AIC:                            -297.0
Df Residuals:                     238   BIC:                            -283.1
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.3232      0.039     -8.206      0.000      -0.401      -0.246
p1                    0.3641      0.052      7.022      0.000       0.262       0.466
answer_changed        0.0943      0.070      1.351      0.178      -0.043       0.232
p1:answer_changed     0.6453      0.111      5.805      0.000       0.426       0.864
==============================================================================
Omnibus:                        0.691   Durbin-Watson:                   1.766
Prob(Omnibus):                  0.708   Jarque-Bera (JB):                0.581
Skew:                           0.120   Prob(JB):                        0.748
Kurtosis:                       3.022   Cond. No.                         20.5
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=3.51, p=0.000577
Wilcoxon delta_H: statistic=4791.00, p=0.000382
Mean ΔH = 0.1084  [0.0479, 0.1689]
Paired t-test delta_H Changed: statistic=7.76, p=3.71e-11
Wilcoxon delta_H Changed: statistic=196.00, p=8.59e-11
Mean ΔH Changed = 0.3137  [0.2344, 0.3929]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=5.73, p=3.02e-08
Wilcoxon (p_top2_game vs p_top2_base): statistic=8084.00, p=1.28e-09
Mean Δp_top2 = 0.0279  [0.0183, 0.0374] (n=242)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=6.77, p=9.95e-11
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=7469.00, p=3.25e-11
Mean ΔH_unchosen_baseline_set = 0.1720  [0.1222, 0.2218] (n=242)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  242
Model:                          Logit   Df Residuals:                      239
Method:                           MLE   Df Model:                            2
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1393
Time:                        17:34:08   Log-Likelihood:                -128.94
converged:                       True   LL-Null:                       -149.81
Covariance Type:            nonrobust   LLR p-value:                 8.676e-10
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.8726      0.220     -3.975      0.000      -1.303      -0.442
p1_z            -1.0474      0.191     -5.470      0.000      -1.423      -0.672
I(p1_z ** 2)    -0.1557      0.195     -0.800      0.424      -0.537       0.226
================================================================================
AUC = 0.745

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  247
Model:                          Logit   Df Residuals:                      245
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.09316
Time:                        17:34:08   Log-Likelihood:                -138.26
converged:                       True   LL-Null:                       -152.46
Covariance Type:            nonrobust   LLR p-value:                 9.829e-08
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -2.1564      0.330     -6.541      0.000      -2.803      -1.510
game_entropy     1.3881      0.281      4.940      0.000       0.837       1.939
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=7981.00, p=6.85e-11
Paired t-test (game_entropy vs capabilities_entropy): statistic=-6.87, p=5.18e-11
Mean capabilities_entropy-game_entropy = 0.1703  [0.1217, 0.2188] (n=247)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  247
Model:                          Logit   Df Residuals:                      244
Method:                           MLE   Df Model:                            2
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1238
Time:                        17:34:08   Log-Likelihood:                -133.58
converged:                       True   LL-Null:                       -152.46
Covariance Type:            nonrobust   LLR p-value:                 6.321e-09
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.8440      0.438     -6.497      0.000      -3.702      -1.986
capabilities_entropy     1.3253      0.445      2.980      0.003       0.454       2.197
game_entropy             0.5118      0.394      1.300      0.194      -0.260       1.284
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['History', 'TV shows', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.545455
                        1                 0.454545
Geography               0                 0.727273
                        1                 0.272727
Misc                    0                 0.611111
                        1                 0.388889
Music                   0                 0.850000
                        1                 0.150000
Other                   0                 0.680000
                        1                 0.320000
Politics                0                 0.657895
                        1                 0.342105
Science and technology  0                 0.740741
                        1                 0.259259
Sports                  0                 0.842105
                        1                 0.157895
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.642105
                     1                 0.357895
Number               0                 0.780488
                     1                 0.219512
Other                0                 0.690909
                     1                 0.309091
Person               0                 0.714286
                     1                 0.285714
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.400000  0.600000           15
                       Number               1.000000  0.000000            2
                       Other                0.625000  0.375000            8
                       Person               0.625000  0.375000            8
Geography              Date                 0.777778  0.222222            9
                       Number               0.700000  0.300000           10
                       Other                0.666667  0.333333            3
Misc                   Date                 0.636364  0.363636           11
                       Number               0.800000  0.200000            5
                       Other                0.636364  0.363636           11
                       Person               0.444444  0.555556            9
Music                  Date                 0.875000  0.125000            8
                       Number               1.000000  0.000000            2
                       Other                0.875000  0.125000            8
                       Person               0.500000  0.500000            2
Other                  Date                 0.750000  0.250000            8
                       Number               0.500000  0.500000            4
                       Other                0.714286  0.285714            7
                       Person               0.666667  0.333333            6
Politics               Date                 0.523810  0.476190           21
                       Number               1.000000  0.000000            1
                       Other                0.714286  0.285714            7
                       Person               0.888889  0.111111            9
Science and technology Date                 0.777778  0.222222           18
                       Number               0.714286  0.285714            7
                       Other                0.555556  0.444444            9
                       Person               0.800000  0.200000           20
Sports                 Date                 0.600000  0.400000            5
                       Number               0.900000  0.100000           10
                       Other                1.000000  0.000000            2
                       Person               1.000000  0.000000            2

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  247
Model:                          Logit   Df Residuals:                      235
Method:                           MLE   Df Model:                           11
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.04375
Time:                        17:34:08   Log-Likelihood:                -145.79
converged:                       True   LL-Null:                       -152.46
Covariance Type:            nonrobust   LLR p-value:                    0.2717
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      2.2288      1.860      1.198      0.231      -1.417       5.875
C(topic_grouped)[T.Geography]                 -0.7594      0.619     -1.227      0.220      -1.973       0.454
C(topic_grouped)[T.Misc]                      -0.1574      0.497     -0.317      0.751      -1.131       0.816
C(topic_grouped)[T.Music]                     -1.6003      0.724     -2.210      0.027      -3.019      -0.181
C(topic_grouped)[T.Other]                     -0.5531      0.559     -0.989      0.323      -1.650       0.543
C(topic_grouped)[T.Politics]                  -0.4047      0.500     -0.809      0.418      -1.385       0.575
C(topic_grouped)[T.Science and technology]    -0.7949      0.474     -1.678      0.093      -1.724       0.134
C(topic_grouped)[T.Sports]                    -1.2823      0.748     -1.715      0.086      -2.748       0.183
C(answer_type_grouped)[T.Number]              -0.4921      0.466     -1.057      0.291      -1.405       0.421
C(answer_type_grouped)[T.Other]               -0.2594      0.378     -0.687      0.492      -1.000       0.481
C(answer_type_grouped)[T.Person]              -0.4424      0.384     -1.152      0.249      -1.195       0.310
q_length                                      -0.4975      0.405     -1.230      0.219      -1.290       0.296
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 1.0530
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  247
Model:                          Logit   Df Residuals:                      234
Method:                           MLE   Df Model:                           12
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1715
Time:                        17:34:08   Log-Likelihood:                -126.31
converged:                       True   LL-Null:                       -152.46
Covariance Type:            nonrobust   LLR p-value:                 5.499e-07
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      0.1501      2.037      0.074      0.941      -3.843       4.143
C(topic_grouped)[T.Geography]                 -1.1418      0.688     -1.660      0.097      -2.490       0.207
C(topic_grouped)[T.Misc]                      -0.6026      0.551     -1.093      0.274      -1.683       0.478
C(topic_grouped)[T.Music]                     -1.9619      0.783     -2.507      0.012      -3.496      -0.428
C(topic_grouped)[T.Other]                     -0.5460      0.614     -0.889      0.374      -1.749       0.657
C(topic_grouped)[T.Politics]                  -0.7473      0.561     -1.332      0.183      -1.847       0.352
C(topic_grouped)[T.Science and technology]    -1.1325      0.529     -2.140      0.032      -2.170      -0.095
C(topic_grouped)[T.Sports]                    -1.5894      0.803     -1.980      0.048      -3.163      -0.016
C(answer_type_grouped)[T.Number]              -0.3723      0.495     -0.752      0.452      -1.343       0.598
C(answer_type_grouped)[T.Other]                0.2069      0.420      0.492      0.623      -0.617       1.031
C(answer_type_grouped)[T.Person]               0.1967      0.438      0.449      0.653      -0.662       1.055
q_length                                      -0.5485      0.437     -1.256      0.209      -1.405       0.307
capabilities_entropy                           1.9946      0.372      5.357      0.000       1.265       2.724
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  247
Model:                          Logit   Df Residuals:                      234
Method:                           MLE   Df Model:                           12
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1387
Time:                        17:34:08   Log-Likelihood:                -131.31
converged:                       True   LL-Null:                       -152.46
Covariance Type:            nonrobust   LLR p-value:                 2.961e-05
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      0.4084      1.999      0.204      0.838      -3.509       4.325
C(topic_grouped)[T.Geography]                 -0.8054      0.655     -1.230      0.219      -2.088       0.477
C(topic_grouped)[T.Misc]                      -0.2457      0.533     -0.461      0.645      -1.290       0.798
C(topic_grouped)[T.Music]                     -1.5930      0.762     -2.092      0.036      -3.086      -0.100
C(topic_grouped)[T.Other]                     -0.6150      0.593     -1.037      0.300      -1.777       0.548
C(topic_grouped)[T.Politics]                  -0.4086      0.534     -0.766      0.444      -1.455       0.637
C(topic_grouped)[T.Science and technology]    -0.8789      0.509     -1.728      0.084      -1.876       0.118
C(topic_grouped)[T.Sports]                    -1.2947      0.785     -1.649      0.099      -2.834       0.244
C(answer_type_grouped)[T.Number]              -0.6172      0.489     -1.261      0.207      -1.577       0.342
C(answer_type_grouped)[T.Other]               -0.0645      0.409     -0.158      0.875      -0.865       0.736
C(answer_type_grouped)[T.Person]               0.0927      0.425      0.218      0.828      -0.741       0.927
q_length                                      -0.4411      0.428     -1.030      0.303      -1.281       0.399
game_entropy                                   1.5118      0.306      4.948      0.000       0.913       2.111
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  247
Model:                          Logit   Df Residuals:                      233
Method:                           MLE   Df Model:                           13
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1767
Time:                        17:34:08   Log-Likelihood:                -125.52
converged:                       True   LL-Null:                       -152.46
Covariance Type:            nonrobust   LLR p-value:                 6.356e-07
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -0.0667      2.052     -0.033      0.974      -4.088       3.955
C(topic_grouped)[T.Geography]                 -1.0876      0.689     -1.578      0.114      -2.438       0.263
C(topic_grouped)[T.Misc]                      -0.5460      0.554     -0.985      0.325      -1.633       0.541
C(topic_grouped)[T.Music]                     -1.8830      0.786     -2.397      0.017      -3.423      -0.343
C(topic_grouped)[T.Other]                     -0.5791      0.615     -0.942      0.346      -1.784       0.626
C(topic_grouped)[T.Politics]                  -0.6818      0.562     -1.212      0.225      -1.784       0.421
C(topic_grouped)[T.Science and technology]    -1.1016      0.532     -2.071      0.038      -2.144      -0.059
C(topic_grouped)[T.Sports]                    -1.5455      0.806     -1.917      0.055      -3.125       0.034
C(answer_type_grouped)[T.Number]              -0.4520      0.502     -0.901      0.368      -1.436       0.532
C(answer_type_grouped)[T.Other]                0.1725      0.424      0.407      0.684      -0.658       1.003
C(answer_type_grouped)[T.Person]               0.2579      0.443      0.583      0.560      -0.610       1.125
q_length                                      -0.5157      0.439     -1.176      0.240      -1.375       0.344
capabilities_entropy                           1.5887      0.488      3.259      0.001       0.633       2.544
game_entropy                                   0.5220      0.417      1.250      0.211      -0.296       1.340
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing grok-3-latest (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_neutral/grok-3-latest_SimpleMC_redacted_cor_temp0.0_1751833664_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    273
1     22
Name: count, dtype: int64

Answer change%: 0.0746 [0.0445979208232761, 0.10455462154960526] (n=295)
P-value vs 25%: 1.886e-30; P-value vs 0%: 1.084e-06
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=22)
P-value vs 25%: 0; P-value vs 33%: 0

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  295
Model:                          Logit   Df Residuals:                      293
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1764
Time:                        17:34:08   Log-Likelihood:                -64.459
converged:                       True   LL-Null:                       -78.269
Covariance Type:            nonrobust   LLR p-value:                 1.477e-07
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          1.8206      0.864      2.107      0.035       0.127       3.514
p_i_capability    -5.1578      1.055     -4.887      0.000      -7.226      -3.089
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  295
Model:                          Logit   Df Residuals:                      293
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.2925
Time:                        17:34:08   Log-Likelihood:                -55.373
converged:                       True   LL-Null:                       -78.269
Covariance Type:            nonrobust   LLR p-value:                 1.316e-11
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -4.2083      0.481     -8.741      0.000      -5.152      -3.265
capabilities_entropy     3.0784      0.516      5.967      0.000       2.067       4.090
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.7727 [0.5976, 0.9478] (n=22)
                  P-value vs 33.3%: 8.748e-07

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=-3.73, p=0.000238
Wilcoxon delta_p: statistic=8330.00, p=8.68e-15
Mean Δp = -0.0269  [-0.0411, -0.0128]
Idea 1 N = 270; 

  Idea 1.5: Calibration Metrics
  NLL: 0.0975, Signed ECE (overconf pos under neg): -0.0791, ECE: 0.0791 (n=292)
  Brier: 0.0258, Reliability (absolute calibration error; lower better): 0.0253, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=292)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.728
Model:                            OLS   Adj. R-squared:                  0.725
Method:                 Least Squares   F-statistic:                     257.1
Date:                Sat, 09 Aug 2025   Prob (F-statistic):           4.09e-81
Time:                        17:34:08   Log-Likelihood:                 263.78
No. Observations:                 292   AIC:                            -519.6
Df Residuals:                     288   BIC:                            -504.9
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.6191      0.048    -12.804      0.000      -0.714      -0.524
p1                    0.6298      0.051     12.343      0.000       0.529       0.730
answer_changed        0.5114      0.101      5.075      0.000       0.313       0.710
p1:answer_changed     0.2540      0.136      1.871      0.062      -0.013       0.521
==============================================================================
Omnibus:                      224.285   Durbin-Watson:                   2.136
Prob(Omnibus):                  0.000   Jarque-Bera (JB):             3673.185
Skew:                           2.990   Prob(JB):                         0.00
Kurtosis:                      19.314   Cond. No.                         40.3
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-4.95, p=1.34e-06
Wilcoxon delta_H: statistic=11940.00, p=7.56e-07
Mean ΔH = -0.1541  [-0.2151, -0.0930]
Paired t-test delta_H Changed: statistic=1.73, p=0.0982
Wilcoxon delta_H Changed: statistic=66.00, p=0.0501
Mean ΔH Changed = 0.1439  [-0.0191, 0.3068]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=2.48, p=0.0139
Wilcoxon (p_top2_game vs p_top2_base): statistic=13669.00, p=9e-08
Mean Δp_top2 = 0.0056  [0.0012, 0.0100] (n=292)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=-4.42, p=1.42e-05
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=15080.00, p=1.25e-05
Mean ΔH_unchosen_baseline_set = -0.1316  [-0.1901, -0.0732] (n=292)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  292
Model:                          Logit   Df Residuals:                      289
Method:                           MLE   Df Model:                            2
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.3240
Time:                        17:34:08   Log-Likelihood:                -52.749
converged:                       True   LL-Null:                       -78.035
Covariance Type:            nonrobust   LLR p-value:                 1.043e-11
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -3.1711      0.390     -8.121      0.000      -3.936      -2.406
p1_z            -2.1644      0.517     -4.184      0.000      -3.178      -1.151
I(p1_z ** 2)    -0.3933      0.178     -2.207      0.027      -0.743      -0.044
================================================================================
AUC = 0.894

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  295
Model:                          Logit   Df Residuals:                      293
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.3648
Time:                        17:34:08   Log-Likelihood:                -49.717
converged:                       True   LL-Null:                       -78.269
Covariance Type:            nonrobust   LLR p-value:                 4.132e-14
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -4.0833      0.453     -9.012      0.000      -4.971      -3.195
game_entropy     3.8981      0.596      6.537      0.000       2.729       5.067
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=10022.00, p=8.11e-16
Paired t-test (game_entropy vs capabilities_entropy): statistic=-5.82, p=1.52e-08
Mean capabilities_entropy-game_entropy = 0.1126  [0.0747, 0.1505] (n=295)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  295
Model:                          Logit   Df Residuals:                      292
Method:                           MLE   Df Model:                            2
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.4230
Time:                        17:34:08   Log-Likelihood:                -45.164
converged:                       True   LL-Null:                       -78.269
Covariance Type:            nonrobust   LLR p-value:                 4.193e-15
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -4.7877      0.600     -7.983      0.000      -5.963      -3.612
capabilities_entropy     1.9571      0.650      3.009      0.003       0.682       3.232
game_entropy             2.8182      0.674      4.184      0.000       1.498       4.138
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['Other', 'Sports', 'Music', 'Geography', 'History', 'TV shows', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.937500
                        1                 0.062500
Misc                    0                 0.913907
                        1                 0.086093
Politics                0                 0.937500
                        1                 0.062500
Science and technology  0                 0.937500
                        1                 0.062500
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.950495
                     1                 0.049505
Number               0                 0.925000
                     1                 0.075000
Other                0                 0.912088
                     1                 0.087912
Person               0                 0.904762
                     1                 0.095238
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.857143  0.142857           14
                       Number               1.000000  0.000000            5
                       Other                0.923077  0.076923           13
                       Person               1.000000  0.000000           16
Misc                   Date                 0.956522  0.043478           46
                       Number               0.923077  0.076923           26
                       Other                0.882353  0.117647           51
                       Person               0.892857  0.107143           28
Politics               Date                 1.000000  0.000000           20
                       Number               1.000000  0.000000            4
                       Other                0.923077  0.076923           13
                       Person               0.818182  0.181818           11
Science and technology Date                 0.952381  0.047619           21
                       Number               0.800000  0.200000            5
                       Other                1.000000  0.000000           14
                       Person               0.875000  0.125000            8

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  295
Model:                          Logit   Df Residuals:                      287
Method:                           MLE   Df Model:                            7
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.01405
Time:                        17:34:08   Log-Likelihood:                -77.169
converged:                       True   LL-Null:                       -78.269
Covariance Type:            nonrobust   LLR p-value:                    0.9479
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -2.6888      2.939     -0.915      0.360      -8.449       3.071
C(topic_grouped)[T.Misc]                       0.3934      0.671      0.586      0.558      -0.922       1.709
C(topic_grouped)[T.Politics]                   0.1018      0.859      0.119      0.906      -1.581       1.785
C(topic_grouped)[T.Science and technology]     0.1197      0.856      0.140      0.889      -1.557       1.797
C(answer_type_grouped)[T.Number]               0.3940      0.763      0.516      0.606      -1.102       1.890
C(answer_type_grouped)[T.Other]                0.5834      0.592      0.985      0.325      -0.578       1.744
C(answer_type_grouped)[T.Person]               0.7227      0.634      1.141      0.254      -0.519       1.965
q_length                                      -0.1121      0.647     -0.173      0.862      -1.380       1.155
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.2838
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  295
Model:                          Logit   Df Residuals:                      286
Method:                           MLE   Df Model:                            8
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.2985
Time:                        17:34:08   Log-Likelihood:                -54.906
converged:                       True   LL-Null:                       -78.269
Covariance Type:            nonrobust   LLR p-value:                 1.729e-07
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -5.1940      3.321     -1.564      0.118     -11.703       1.315
C(topic_grouped)[T.Misc]                      -0.3911      0.794     -0.493      0.622      -1.947       1.165
C(topic_grouped)[T.Politics]                  -0.0023      0.958     -0.002      0.998      -1.880       1.875
C(topic_grouped)[T.Science and technology]    -0.4103      0.949     -0.432      0.665      -2.270       1.450
C(answer_type_grouped)[T.Number]               0.0429      0.873      0.049      0.961      -1.668       1.754
C(answer_type_grouped)[T.Other]                0.2684      0.692      0.388      0.698      -1.088       1.625
C(answer_type_grouped)[T.Person]               0.3487      0.724      0.482      0.630      -1.071       1.768
q_length                                       0.2332      0.732      0.319      0.750      -1.201       1.667
capabilities_entropy                           3.1409      0.537      5.853      0.000       2.089       4.193
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  295
Model:                          Logit   Df Residuals:                      286
Method:                           MLE   Df Model:                            8
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.3726
Time:                        17:34:08   Log-Likelihood:                -49.108
converged:                       True   LL-Null:                       -78.269
Covariance Type:            nonrobust   LLR p-value:                 9.935e-10
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -5.7575      3.622     -1.590      0.112     -12.857       1.342
C(topic_grouped)[T.Misc]                      -0.0967      0.854     -0.113      0.910      -1.771       1.578
C(topic_grouped)[T.Politics]                   0.0870      1.047      0.083      0.934      -1.966       2.140
C(topic_grouped)[T.Science and technology]    -0.1426      1.029     -0.139      0.890      -2.159       1.874
C(answer_type_grouped)[T.Number]               0.6384      0.962      0.664      0.507      -1.247       2.524
C(answer_type_grouped)[T.Other]                0.6475      0.734      0.882      0.378      -0.792       2.087
C(answer_type_grouped)[T.Person]               0.5620      0.776      0.724      0.469      -0.959       2.083
q_length                                       0.2812      0.788      0.357      0.721      -1.263       1.825
game_entropy                                   3.9503      0.616      6.409      0.000       2.742       5.158
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  295
Model:                          Logit   Df Residuals:                      285
Method:                           MLE   Df Model:                            9
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.4273
Time:                        17:34:08   Log-Likelihood:                -44.823
converged:                       True   LL-Null:                       -78.269
Covariance Type:            nonrobust   LLR p-value:                 6.175e-11
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -6.5009      3.707     -1.754      0.079     -13.766       0.764
C(topic_grouped)[T.Misc]                      -0.2329      0.936     -0.249      0.803      -2.067       1.601
C(topic_grouped)[T.Politics]                   0.1504      1.097      0.137      0.891      -2.000       2.301
C(topic_grouped)[T.Science and technology]    -0.0421      1.091     -0.039      0.969      -2.179       2.095
C(answer_type_grouped)[T.Number]               0.2799      0.963      0.291      0.771      -1.607       2.167
C(answer_type_grouped)[T.Other]                0.2222      0.797      0.279      0.781      -1.341       1.785
C(answer_type_grouped)[T.Person]               0.3081      0.799      0.386      0.700      -1.257       1.873
q_length                                       0.3583      0.801      0.447      0.655      -1.212       1.928
capabilities_entropy                           1.9711      0.669      2.946      0.003       0.660       3.283
game_entropy                                   2.8508      0.687      4.153      0.000       1.505       4.196
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing grok-3-latest (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_neutral/grok-3-latest_SimpleMC_redacted_temp0.0_1751826103_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    138
1     67
Name: count, dtype: int64

Answer change%: 0.3268 [0.26262051404567455, 0.39103802253969133] (n=205)
P-value vs 25%: 0.01902; P-value vs 0%: 1.933e-23
Phase 2 self-accuracy: 0.5672 [0.4485253957797495, 0.6858029624292057] (n=67)
P-value vs 25%: 1.608e-07; P-value vs 33%: 0.0001095

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  205
Model:                          Logit   Df Residuals:                      203
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1948
Time:                        17:34:08   Log-Likelihood:                -104.31
converged:                       True   LL-Null:                       -129.54
Covariance Type:            nonrobust   LLR p-value:                 1.212e-12
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          4.6087      0.851      5.416      0.000       2.941       6.277
p_i_capability    -6.6450      1.054     -6.303      0.000      -8.711      -4.579
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  205
Model:                          Logit   Df Residuals:                      203
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1697
Time:                        17:34:08   Log-Likelihood:                -107.56
converged:                       True   LL-Null:                       -129.54
Covariance Type:            nonrobust   LLR p-value:                 3.352e-11
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.3172      0.339     -6.845      0.000      -2.981      -1.654
capabilities_entropy     2.3142      0.392      5.904      0.000       1.546       3.082
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.6866 [0.5755, 0.7976] (n=67)
                  P-value vs 33.3%: 4.581e-10

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=-1.90, p=0.0598
Wilcoxon delta_p: statistic=3451.00, p=0.00427
Mean Δp = -0.0232  [-0.0472, 0.0008]
Idea 1 N = 138; 

  Idea 1.5: Calibration Metrics
  NLL: 5.1560, Signed ECE (overconf pos under neg): 0.0779, ECE: 0.0779 (n=205)
  Brier: 0.0196, Reliability (absolute calibration error; lower better): 0.0189, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=205)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.830
Model:                            OLS   Adj. R-squared:                  0.827
Method:                 Least Squares   F-statistic:                     326.1
Date:                Sat, 09 Aug 2025   Prob (F-statistic):           6.21e-77
Time:                        17:34:08   Log-Likelihood:                 114.36
No. Observations:                 205   AIC:                            -220.7
Df Residuals:                     201   BIC:                            -207.4
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.5431      0.077     -7.052      0.000      -0.695      -0.391
p1                    0.5884      0.086      6.832      0.000       0.419       0.758
answer_changed        0.2554      0.106      2.418      0.017       0.047       0.464
p1:answer_changed     0.6181      0.132      4.685      0.000       0.358       0.878
==============================================================================
Omnibus:                       38.316   Durbin-Watson:                   2.228
Prob(Omnibus):                  0.000   Jarque-Bera (JB):              159.898
Skew:                          -0.623   Prob(JB):                     1.90e-35
Kurtosis:                       7.143   Cond. No.                         26.5
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=0.68, p=0.496
Wilcoxon delta_H: statistic=4401.00, p=0.402
Mean ΔH = 0.0295  [-0.0552, 0.1142]
Paired t-test delta_H Changed: statistic=4.45, p=3.41e-05
Wilcoxon delta_H Changed: statistic=450.00, p=1.68e-05
Mean ΔH Changed = 0.2467  [0.1380, 0.3553]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=4.23, p=3.53e-05
Wilcoxon (p_top2_game vs p_top2_base): statistic=5799.00, p=2.2e-08
Mean Δp_top2 = 0.0165  [0.0088, 0.0241] (n=205)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=2.88, p=0.00447
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=7928.00, p=0.00199
Mean ΔH_unchosen_baseline_set = 0.1005  [0.0320, 0.1689] (n=205)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  205
Model:                          Logit   Df Residuals:                      202
Method:                           MLE   Df Model:                            2
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.2020
Time:                        17:34:08   Log-Likelihood:                -103.37
converged:                       True   LL-Null:                       -129.54
Covariance Type:            nonrobust   LLR p-value:                 4.303e-12
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.6750      0.225     -3.005      0.003      -1.115      -0.235
p1_z            -1.3695      0.252     -5.430      0.000      -1.864      -0.875
I(p1_z ** 2)    -0.2584      0.185     -1.393      0.164      -0.622       0.105
================================================================================
AUC = 0.807

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  205
Model:                          Logit   Df Residuals:                      203
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.07394
Time:                        17:34:08   Log-Likelihood:                -119.96
converged:                       True   LL-Null:                       -129.54
Covariance Type:            nonrobust   LLR p-value:                 1.205e-05
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.4666      0.244     -6.003      0.000      -1.945      -0.988
game_entropy     1.5334      0.363      4.228      0.000       0.823       2.244
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=6148.00, p=2.16e-07
Paired t-test (game_entropy vs capabilities_entropy): statistic=-5.30, p=2.96e-07
Mean capabilities_entropy-game_entropy = 0.1686  [0.1063, 0.2310] (n=205)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  205
Model:                          Logit   Df Residuals:                      202
Method:                           MLE   Df Model:                            2
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1784
Time:                        17:34:08   Log-Likelihood:                -106.43
converged:                       True   LL-Null:                       -129.54
Covariance Type:            nonrobust   LLR p-value:                 9.190e-11
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.4502      0.356     -6.888      0.000      -3.147      -1.753
capabilities_entropy     2.0590      0.424      4.852      0.000       1.227       2.891
game_entropy             0.6338      0.421      1.504      0.133      -0.192       1.460
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['Politics', 'Art', 'Geography', 'Other', 'Music', 'Sports', 'TV shows', 'Video games', 'History']
                  Grouped rare answer_type into 'Misc'/'Other': ['Number', 'Other', 'Place']
topic_grouped           answer_changed
Misc                    0                 0.703226
                        1                 0.296774
Science and technology  0                 0.580000
                        1                 0.420000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.691176
                     1                 0.308824
Misc                 0                 0.662500
                     1                 0.337500
Person               0                 0.666667
                     1                 0.333333
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Misc                   Date                 0.759259  0.240741           54
                       Misc                 0.696970  0.303030           66
                       Person               0.628571  0.371429           35
Science and technology Date                 0.428571  0.571429           14
                       Misc                 0.500000  0.500000           14
                       Person               0.727273  0.272727           22

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  205
Model:                          Logit   Df Residuals:                      200
Method:                           MLE   Df Model:                            4
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.01194
Time:                        17:34:08   Log-Likelihood:                -128.00
converged:                       True   LL-Null:                       -129.54
Covariance Type:            nonrobust   LLR p-value:                    0.5425
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.9267      1.774     -1.086      0.277      -5.403       1.549
C(topic_grouped)[T.Science and technology]     0.5487      0.346      1.588      0.112      -0.129       1.226
C(answer_type_grouped)[T.Misc]                 0.1746      0.358      0.487      0.626      -0.528       0.877
C(answer_type_grouped)[T.Person]               0.0682      0.407      0.168      0.867      -0.729       0.866
q_length                                       0.2136      0.375      0.570      0.569      -0.521       0.948
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.6132
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  205
Model:                          Logit   Df Residuals:                      199
Method:                           MLE   Df Model:                            5
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1803
Time:                        17:34:08   Log-Likelihood:                -106.18
converged:                       True   LL-Null:                       -129.54
Covariance Type:            nonrobust   LLR p-value:                 6.469e-09
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -3.3068      1.988     -1.663      0.096      -7.204       0.590
C(topic_grouped)[T.Science and technology]     0.4437      0.393      1.129      0.259      -0.327       1.214
C(answer_type_grouped)[T.Misc]                 0.4086      0.403      1.015      0.310      -0.380       1.198
C(answer_type_grouped)[T.Person]               0.3859      0.458      0.842      0.400      -0.512       1.284
q_length                                       0.1331      0.416      0.320      0.749      -0.682       0.948
capabilities_entropy                           2.3276      0.395      5.896      0.000       1.554       3.101
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  205
Model:                          Logit   Df Residuals:                      199
Method:                           MLE   Df Model:                            5
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.08468
Time:                        17:34:08   Log-Likelihood:                -118.57
converged:                       True   LL-Null:                       -129.54
Covariance Type:            nonrobust   LLR p-value:                 0.0005376
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -2.0007      1.825     -1.096      0.273      -5.578       1.577
C(topic_grouped)[T.Science and technology]     0.4248      0.366      1.161      0.246      -0.293       1.142
C(answer_type_grouped)[T.Misc]                 0.3612      0.380      0.951      0.341      -0.383       1.105
C(answer_type_grouped)[T.Person]               0.3767      0.437      0.863      0.388      -0.479       1.232
q_length                                       0.0341      0.388      0.088      0.930      -0.726       0.795
game_entropy                                   1.5786      0.378      4.179      0.000       0.838       2.319
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  205
Model:                          Logit   Df Residuals:                      198
Method:                           MLE   Df Model:                            6
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1899
Time:                        17:34:08   Log-Likelihood:                -104.94
converged:                       True   LL-Null:                       -129.54
Covariance Type:            nonrobust   LLR p-value:                 6.798e-09
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -3.2025      2.003     -1.599      0.110      -7.128       0.723
C(topic_grouped)[T.Science and technology]     0.3840      0.399      0.963      0.335      -0.397       1.165
C(answer_type_grouped)[T.Misc]                 0.4801      0.410      1.172      0.241      -0.323       1.283
C(answer_type_grouped)[T.Person]               0.4898      0.469      1.044      0.297      -0.430       1.410
q_length                                       0.0666      0.421      0.158      0.874      -0.759       0.892
capabilities_entropy                           2.0671      0.425      4.868      0.000       1.235       2.899
game_entropy                                   0.6832      0.435      1.572      0.116      -0.169       1.535
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.
