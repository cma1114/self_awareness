
--- Analyzing claude-3-5-sonnet-20241022 (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/claude-3-5-sonnet-20241022_SimpleQA_redacted_cor_temp0.0_1754619595_game_data_evaluated.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    127
1     16
Name: count, dtype: int64

Answer change%: 0.1119 [0.0602219873295895, 0.16355423644663428] (n=143)
P-value vs 25%: 1.612e-07; P-value vs 0%: 2.191e-05
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=16)
P-value vs 25%: 0; P-value vs 33%: 0
                  Grouped rare topic into 'Misc'/'Other': ['Music', 'History', 'TV shows', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': None
topic_grouped           answer_changed
Art                     0                 0.952381
                        1                 0.047619
Geography               0                 0.727273
                        1                 0.272727
Misc                    0                 0.800000
                        1                 0.200000
Other                   0                 1.000000
Politics                0                 0.909091
                        1                 0.090909
Science and technology  0                 0.862069
                        1                 0.137931
Sports                  0                 1.000000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.912281
                     1                 0.087719
Number               0                 0.833333
                     1                 0.166667
Other                0                 0.806452
                     1                 0.193548
Person               0                 0.935484
                     1                 0.064516
Place                0                 0.916667
                     1                 0.083333
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.888889  0.111111            9
                       Number               1.000000  0.000000            1
                       Other                1.000000  0.000000            3
                       Person               1.000000  0.000000            7
                       Place                1.000000  0.000000            1
Geography              Date                 1.000000  0.000000            5
                       Number               0.500000  0.500000            2
                       Other                0.000000  1.000000            1
                       Place                0.666667  0.333333            3
Misc                   Date                 0.750000  0.250000            8
                       Number               0.750000  0.250000            4
                       Other                0.833333  0.166667            6
                       Person               0.800000  0.200000            5
                       Place                1.000000  0.000000            2
Other                  Date                 1.000000  0.000000            4
                       Number               1.000000  0.000000            2
                       Other                1.000000  0.000000            2
                       Person               1.000000  0.000000            3
                       Place                1.000000  0.000000            2
Politics               Date                 1.000000  0.000000           14
                       Number               1.000000  0.000000            1
                       Other                0.700000  0.300000           10
                       Person               1.000000  0.000000            4
                       Place                1.000000  0.000000            4
Science and technology Date                 0.846154  0.153846           13
                       Number               1.000000  0.000000            1
                       Other                0.833333  0.166667            6
                       Person               0.888889  0.111111            9
Sports                 Date                 1.000000  0.000000            4
                       Number               1.000000  0.000000            1
                       Other                1.000000  0.000000            3
                       Person               1.000000  0.000000            3

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  143
Model:                          Logit   Df Residuals:                      131
Method:                           MLE   Df Model:                           11
Date:                Sat, 23 Aug 2025   Pseudo R-squ.:                  0.1544
Time:                        11:35:43   Log-Likelihood:                -42.377
converged:                      False   LL-Null:                       -50.114
Covariance Type:            nonrobust   LLR p-value:                    0.1618
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -7.1044      3.817     -1.861      0.063     -14.585       0.377
C(topic_grouped)[T.Geography]                  2.2124      1.300      1.701      0.089      -0.336       4.761
C(topic_grouped)[T.Misc]                       1.4727      1.160      1.270      0.204      -0.801       3.746
C(topic_grouped)[T.Other]                    -18.1625   1.01e+04     -0.002      0.999   -1.97e+04    1.97e+04
C(topic_grouped)[T.Politics]                   0.1744      1.266      0.138      0.890      -2.307       2.656
C(topic_grouped)[T.Science and technology]     0.9573      1.181      0.810      0.418      -1.358       3.273
C(topic_grouped)[T.Sports]                   -27.6932   1.13e+06  -2.45e-05      1.000   -2.22e+06    2.22e+06
C(answer_type_grouped)[T.Number]               0.5739      0.973      0.590      0.555      -1.334       2.482
C(answer_type_grouped)[T.Other]                1.2236      0.715      1.711      0.087      -0.178       2.625
C(answer_type_grouped)[T.Person]              -0.1200      0.919     -0.131      0.896      -1.921       1.681
C(answer_type_grouped)[T.Place]               -0.2400      1.224     -0.196      0.845      -2.639       2.159
q_length                                       0.8684      0.810      1.073      0.283      -0.718       2.455
==============================================================================================================

Possibly complete quasi-separation: A fraction 0.17 of observations can be
perfectly predicted. This might indicate that there is complete
quasi-separation. In this case some parameters will not be identified.

                  Model 6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length (after removing deterministic categories: defaultdict(<class 'list'>, {'topic_grouped': ['Sports', 'Other']}))
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  119
Model:                          Logit   Df Residuals:                      109
Method:                           MLE   Df Model:                            9
Date:                Sat, 23 Aug 2025   Pseudo R-squ.:                 0.09793
Time:                        11:35:43   Log-Likelihood:                -42.377
converged:                       True   LL-Null:                       -46.977
Covariance Type:            nonrobust   LLR p-value:                    0.4189
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -7.1044      3.817     -1.861      0.063     -14.585       0.377
C(topic_grouped)[T.Geography]                  2.2124      1.300      1.701      0.089      -0.336       4.761
C(topic_grouped)[T.Misc]                       1.4727      1.160      1.270      0.204      -0.801       3.746
C(topic_grouped)[T.Politics]                   0.1744      1.266      0.138      0.890      -2.307       2.656
C(topic_grouped)[T.Science and technology]     0.9573      1.181      0.810      0.418      -1.358       3.273
C(answer_type_grouped)[T.Number]               0.5739      0.973      0.590      0.555      -1.334       2.482
C(answer_type_grouped)[T.Other]                1.2236      0.715      1.711      0.087      -0.178       2.625
C(answer_type_grouped)[T.Person]              -0.1200      0.919     -0.131      0.896      -1.921       1.681
C(answer_type_grouped)[T.Place]               -0.2400      1.224     -0.196      0.845      -2.639       2.159
q_length                                       0.8684      0.810      1.073      0.283      -0.718       2.455
==============================================================================================================

--- Analyzing claude-3-5-sonnet-20241022 (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/claude-3-5-sonnet-20241022_SimpleQA_redacted_temp0.0_1754612549_game_data_evaluated.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    179
1    178
Name: count, dtype: int64

Answer change%: 0.4986 [0.4467334961700464, 0.5504653833817744] (n=357)
P-value vs 25%: 5.758e-21; P-value vs 0%: 3.444e-79
Phase 2 self-accuracy: 0.1011 [0.056832713239462325, 0.14541447777177363] (n=178)
P-value vs 25%: 4.455e-11; P-value vs 33%: 1.056e-24
                  Grouped rare topic into 'Misc'/'Other': ['History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.500000
                        1                 0.500000
Geography               0                 0.515152
                        1                 0.484848
Misc                    1                 0.531250
                        0                 0.468750
Music                   1                 0.531250
                        0                 0.468750
Other                   1                 0.641026
                        0                 0.358974
Politics                0                 0.545455
                        1                 0.454545
Science and technology  0                 0.608696
                        1                 0.391304
Sports                  1                 0.517241
                        0                 0.482759
TV shows                1                 0.560000
                        0                 0.440000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.508929
                     1                 0.491071
Number               0                 0.515152
                     1                 0.484848
Other                1                 0.522222
                     0                 0.477778
Person               0                 0.505618
                     1                 0.494382
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.500000  0.500000           12
                       Number               0.375000  0.625000            8
                       Other                0.714286  0.285714           14
                       Person               0.400000  0.600000           20
Geography              Date                 0.500000  0.500000           10
                       Number               0.562500  0.437500           16
                       Other                0.428571  0.571429            7
Misc                   Date                 0.428571  0.571429           14
                       Number               0.500000  0.500000            6
                       Other                0.375000  0.625000            8
                       Person               0.750000  0.250000            4
Music                  Date                 0.400000  0.600000           10
                       Number               0.333333  0.666667            3
                       Other                0.400000  0.600000           10
                       Person               0.666667  0.333333            9
Other                  Date                 0.357143  0.642857           14
                       Number               0.600000  0.400000            5
                       Other                0.400000  0.600000           10
                       Person               0.200000  0.800000           10
Politics               Date                 0.454545  0.545455           22
                       Number               0.600000  0.400000            5
                       Other                0.833333  0.166667            6
                       Person               0.545455  0.454545           11
Science and technology Date                 0.727273  0.272727           22
                       Number               0.461538  0.538462           13
                       Other                0.384615  0.615385           13
                       Person               0.714286  0.285714           21
Sports                 Date                 0.600000  0.400000            5
                       Number               0.600000  0.400000           10
                       Other                0.333333  0.666667            9
                       Person               0.400000  0.600000            5
TV shows               Date                 0.666667  0.333333            3
                       Other                0.461538  0.538462           13
                       Person               0.333333  0.666667            9

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  357
Model:                          Logit   Df Residuals:                      344
Method:                           MLE   Df Model:                           12
Date:                Sat, 23 Aug 2025   Pseudo R-squ.:                 0.01563
Time:                        11:35:43   Log-Likelihood:                -243.58
converged:                       True   LL-Null:                       -247.45
Covariance Type:            nonrobust   LLR p-value:                    0.8053
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -0.6314      1.356     -0.466      0.641      -3.288       2.026
C(topic_grouped)[T.Geography]                 -0.0474      0.460     -0.103      0.918      -0.948       0.853
C(topic_grouped)[T.Misc]                       0.1146      0.453      0.253      0.800      -0.774       1.003
C(topic_grouped)[T.Music]                      0.1316      0.448      0.294      0.769      -0.747       1.010
C(topic_grouped)[T.Other]                      0.5920      0.433      1.367      0.172      -0.257       1.441
C(topic_grouped)[T.Politics]                  -0.1936      0.415     -0.467      0.641      -1.007       0.620
C(topic_grouped)[T.Science and technology]    -0.4472      0.369     -1.210      0.226      -1.171       0.277
C(topic_grouped)[T.Sports]                     0.0709      0.466      0.152      0.879      -0.843       0.984
C(topic_grouped)[T.TV shows]                   0.2298      0.492      0.467      0.640      -0.734       1.194
C(answer_type_grouped)[T.Number]              -0.0087      0.325     -0.027      0.979      -0.646       0.629
C(answer_type_grouped)[T.Other]                0.0685      0.296      0.232      0.817      -0.511       0.648
C(answer_type_grouped)[T.Person]               0.0282      0.298      0.095      0.925      -0.556       0.612
q_length                                       0.1350      0.290      0.465      0.642      -0.434       0.704
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing claude-3-haiku-20240307 (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/claude-3-haiku-20240307_SimpleQA_redacted_cor_temp0.0_1754619854_game_data_evaluated.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
1    17
0    14
Name: count, dtype: int64

Answer change%: 0.5484 [0.3732032620080114, 0.7235709315403756] (n=31)
P-value vs 25%: 0.0008427; P-value vs 0%: 8.496e-10
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=17)
P-value vs 25%: 0; P-value vs 33%: 0
                  Grouped rare topic into 'Misc'/'Other': ['Video games', 'History', 'Geography', 'TV shows']
                  Grouped rare answer_type into 'Misc'/'Other': ['Person']
topic_grouped           answer_changed
Art                     1                 0.666667
                        0                 0.333333
Misc                    0                 0.714286
                        1                 0.285714
Politics                1                 0.714286
                        0                 0.285714
Science and technology  1                 0.700000
                        0                 0.300000
Sports                  0                 0.750000
                        1                 0.250000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 1                 0.818182
                     0                 0.181818
Number               1                 0.666667
                     0                 0.333333
Other                0                 0.692308
                     1                 0.307692
Place                0                 0.500000
                     1                 0.500000
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.000000  1.000000            1
                       Other                0.500000  0.500000            2
Misc                   Date                 0.000000  1.000000            1
                       Number               1.000000  0.000000            1
                       Other                1.000000  0.000000            2
                       Place                0.666667  0.333333            3
Politics               Date                 0.000000  1.000000            3
                       Other                0.666667  0.333333            3
                       Place                0.000000  1.000000            1
Science and technology Date                 0.400000  0.600000            5
                       Number               0.000000  1.000000            2
                       Other                0.333333  0.666667            3
Sports                 Date                 0.000000  1.000000            1
                       Other                1.000000  0.000000            3

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                   31
Model:                          Logit   Df Residuals:                       22
Method:                           MLE   Df Model:                            8
Date:                Sat, 23 Aug 2025   Pseudo R-squ.:                  0.2965
Time:                        11:35:43   Log-Likelihood:                -15.014
converged:                       True   LL-Null:                       -21.342
Covariance Type:            nonrobust   LLR p-value:                    0.1242
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -4.1924      8.271     -0.507      0.612     -20.404      12.019
C(topic_grouped)[T.Misc]                      -3.2439      2.088     -1.554      0.120      -7.336       0.848
C(topic_grouped)[T.Politics]                  -0.8201      1.783     -0.460      0.646      -4.315       2.675
C(topic_grouped)[T.Science and technology]    -1.0217      1.661     -0.615      0.539      -4.278       2.234
C(topic_grouped)[T.Sports]                    -2.7045      2.032     -1.331      0.183      -6.687       1.278
C(answer_type_grouped)[T.Number]              -0.3545      1.677     -0.211      0.833      -3.642       2.933
C(answer_type_grouped)[T.Other]               -2.4504      1.159     -2.114      0.034      -4.722      -0.179
C(answer_type_grouped)[T.Place]               -0.0748      1.878     -0.040      0.968      -3.755       3.606
q_length                                       1.6132      1.963      0.822      0.411      -2.234       5.460
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing claude-3-haiku-20240307 (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/claude-3-haiku-20240307_SimpleQA_redacted_temp0.0_1754613331_game_data_evaluated.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    377
1     92
Name: count, dtype: int64

Answer change%: 0.1962 [0.16022408734228344, 0.2321000064743477] (n=469)
P-value vs 25%: 0.003323; P-value vs 0%: 1.038e-26
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=92)
P-value vs 25%: 0; P-value vs 33%: 0
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.805556
                        1                 0.194444
Geography               0                 0.619048
                        1                 0.380952
Misc                    0                 0.797101
                        1                 0.202899
Music                   0                 0.825000
                        1                 0.175000
Other                   0                 0.923077
                        1                 0.076923
Politics                0                 0.871429
                        1                 0.128571
Science and technology  0                 0.761364
                        1                 0.238636
Sports                  0                 0.805556
                        1                 0.194444
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.886076
                     1                 0.113924
Number               0                 0.613333
                     1                 0.386667
Other                0                 0.745763
                     1                 0.254237
Person               0                 0.872881
                     1                 0.127119
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.900000  0.100000           20
                       Number               0.666667  0.333333            9
                       Other                0.647059  0.352941           17
                       Person               0.884615  0.115385           26
Geography              Date                 0.933333  0.066667           15
                       Number               0.444444  0.555556           18
                       Other                0.444444  0.555556            9
Misc                   Date                 0.863636  0.136364           22
                       Number               0.375000  0.625000            8
                       Other                0.791667  0.208333           24
                       Person               0.933333  0.066667           15
Music                  Date                 0.916667  0.083333           12
                       Number               0.250000  0.750000            4
                       Other                0.833333  0.166667           12
                       Person               0.916667  0.083333           12
Other                  Date                 0.888889  0.111111           18
                       Number               1.000000  0.000000            7
                       Other                0.857143  0.142857           14
                       Person               1.000000  0.000000           13
Politics               Date                 0.939394  0.060606           33
                       Number               0.833333  0.166667            6
                       Other                0.875000  0.125000           16
                       Person               0.733333  0.266667           15
Science and technology Date                 0.800000  0.200000           30
                       Number               0.666667  0.333333           12
                       Other                0.625000  0.375000           16
                       Person               0.833333  0.166667           30
Sports                 Date                 0.875000  0.125000            8
                       Number               0.727273  0.272727           11
                       Other                0.800000  0.200000           10
                       Person               0.857143  0.142857            7

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  469
Model:                          Logit   Df Residuals:                      457
Method:                           MLE   Df Model:                           11
Date:                Sat, 23 Aug 2025   Pseudo R-squ.:                  0.1091
Time:                        11:35:44   Log-Likelihood:                -206.84
converged:                       True   LL-Null:                       -232.17
Covariance Type:            nonrobust   LLR p-value:                 4.735e-07
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -6.6157      1.579     -4.191      0.000      -9.710      -3.521
C(topic_grouped)[T.Geography]                  0.6490      0.476      1.363      0.173      -0.284       1.582
C(topic_grouped)[T.Misc]                      -0.0641      0.439     -0.146      0.884      -0.925       0.797
C(topic_grouped)[T.Music]                     -0.0849      0.527     -0.161      0.872      -1.119       0.949
C(topic_grouped)[T.Other]                     -1.0919      0.612     -1.783      0.075      -2.292       0.108
C(topic_grouped)[T.Politics]                  -0.6789      0.492     -1.380      0.168      -1.643       0.285
C(topic_grouped)[T.Science and technology]     0.1835      0.409      0.449      0.654      -0.618       0.985
C(topic_grouped)[T.Sports]                    -0.3636      0.547     -0.665      0.506      -1.435       0.708
C(answer_type_grouped)[T.Number]               1.4611      0.365      4.003      0.000       0.746       2.176
C(answer_type_grouped)[T.Other]                1.0976      0.339      3.234      0.001       0.432       1.763
C(answer_type_grouped)[T.Person]               0.2395      0.387      0.620      0.536      -0.518       0.997
q_length                                       1.0190      0.335      3.045      0.002       0.363       1.675
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing claude-sonnet-4-20250514 (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/claude-sonnet-4-20250514_SimpleQA_redacted_cor_temp0.0_1754666949_game_data_evaluated.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    66
1    14
Name: count, dtype: int64

Answer change%: 0.1750 [0.09173756720182004, 0.25826243279817995] (n=80)
P-value vs 25%: 0.07748; P-value vs 0%: 3.798e-05
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=14)
P-value vs 25%: 0; P-value vs 33%: 0
                  Grouped rare topic into 'Misc'/'Other': ['Geography', 'Video games', 'TV shows', 'History']
                  Grouped rare answer_type into 'Misc'/'Other': None
topic_grouped           answer_changed
Art                     0                 0.750000
                        1                 0.250000
Misc                    0                 0.846154
                        1                 0.153846
Music                   0                 0.714286
                        1                 0.285714
Other                   0                 1.000000
Politics                0                 0.882353
                        1                 0.117647
Science and technology  0                 0.722222
                        1                 0.277778
Sports                  0                 1.000000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.807692
                     1                 0.192308
Number               0                 0.692308
                     1                 0.307692
Other                0                 0.882353
                     1                 0.117647
Person               0                 0.823529
                     1                 0.176471
Place                0                 1.000000
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 1.000000  0.000000            2
                       Number               0.333333  0.666667            3
                       Other                1.000000  0.000000            3
                       Person               0.666667  0.333333            3
                       Place                1.000000  0.000000            1
Misc                   Date                 0.666667  0.333333            3
                       Number               0.800000  0.200000            5
                       Other                1.000000  0.000000            2
                       Person               1.000000  0.000000            1
                       Place                1.000000  0.000000            2
Music                  Date                 1.000000  0.000000            2
                       Other                0.000000  1.000000            1
                       Person               0.750000  0.250000            4
Other                  Date                 1.000000  0.000000            2
                       Number               1.000000  0.000000            1
                       Other                1.000000  0.000000            2
                       Place                1.000000  0.000000            1
Politics               Date                 0.777778  0.222222            9
                       Other                1.000000  0.000000            3
                       Person               1.000000  0.000000            2
                       Place                1.000000  0.000000            3
Science and technology Date                 0.666667  0.333333            6
                       Number               0.666667  0.333333            3
                       Other                0.800000  0.200000            5
                       Person               0.750000  0.250000            4
Sports                 Date                 1.000000  0.000000            2
                       Number               1.000000  0.000000            1
                       Other                1.000000  0.000000            1
                       Person               1.000000  0.000000            3

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                   80
Model:                          Logit   Df Residuals:                       68
Method:                           MLE   Df Model:                           11
Date:                Sat, 23 Aug 2025   Pseudo R-squ.:                  0.1951
Time:                        11:35:44   Log-Likelihood:                -29.861
converged:                      False   LL-Null:                       -37.098
Covariance Type:            nonrobust   LLR p-value:                    0.2079
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -7.8836      4.552     -1.732      0.083     -16.806       1.039
C(topic_grouped)[T.Misc]                      -0.7276      1.116     -0.652      0.515      -2.916       1.460
C(topic_grouped)[T.Music]                      0.3632      1.161      0.313      0.754      -1.913       2.639
C(topic_grouped)[T.Other]                    -23.9748   1.26e+05     -0.000      1.000   -2.47e+05    2.47e+05
C(topic_grouped)[T.Politics]                  -1.6269      1.380     -1.179      0.238      -4.331       1.078
C(topic_grouped)[T.Science and technology]     0.1257      0.915      0.137      0.891      -1.668       1.919
C(topic_grouped)[T.Sports]                   -13.5730    546.029     -0.025      0.980   -1083.769    1056.623
C(answer_type_grouped)[T.Number]               0.7444      0.975      0.763      0.445      -1.167       2.656
C(answer_type_grouped)[T.Other]               -0.7010      0.978     -0.717      0.473      -2.618       1.216
C(answer_type_grouped)[T.Person]              -0.3705      0.921     -0.402      0.687      -2.175       1.434
C(answer_type_grouped)[T.Place]              -20.5646   2.62e+04     -0.001      0.999   -5.14e+04    5.14e+04
q_length                                       1.5520      0.995      1.561      0.119      -0.397       3.501
==============================================================================================================

Possibly complete quasi-separation: A fraction 0.24 of observations can be
perfectly predicted. This might indicate that there is complete
quasi-separation. In this case some parameters will not be identified.

                  Model 6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length (after removing deterministic categories: defaultdict(<class 'list'>, {'topic_grouped': ['Other', 'Sports'], 'answer_type_grouped': ['Place']}))
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                   61
Model:                          Logit   Df Residuals:                       52
Method:                           MLE   Df Model:                            8
Date:                Sat, 23 Aug 2025   Pseudo R-squ.:                 0.09125
Time:                        11:35:44   Log-Likelihood:                -29.861
converged:                       True   LL-Null:                       -32.860
Covariance Type:            nonrobust   LLR p-value:                    0.6476
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -7.8836      4.552     -1.732      0.083     -16.806       1.039
C(topic_grouped)[T.Misc]                      -0.7276      1.116     -0.652      0.515      -2.916       1.460
C(topic_grouped)[T.Music]                      0.3632      1.161      0.313      0.754      -1.913       2.639
C(topic_grouped)[T.Politics]                  -1.6269      1.380     -1.179      0.238      -4.331       1.078
C(topic_grouped)[T.Science and technology]     0.1257      0.915      0.137      0.891      -1.668       1.919
C(answer_type_grouped)[T.Number]               0.7444      0.975      0.763      0.445      -1.167       2.656
C(answer_type_grouped)[T.Other]               -0.7010      0.978     -0.717      0.473      -2.618       1.216
C(answer_type_grouped)[T.Person]              -0.3705      0.921     -0.402      0.687      -2.175       1.434
q_length                                       1.5520      0.995      1.561      0.119      -0.397       3.501
==============================================================================================================

--- Analyzing claude-sonnet-4-20250514 (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/claude-sonnet-4-20250514_SimpleQA_redacted_temp0.0_1754665065_game_data_evaluated.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    229
1    191
Name: count, dtype: int64

Answer change%: 0.4548 [0.4071398006425459, 0.5023840088812636] (n=420)
P-value vs 25%: 3.537e-17; P-value vs 0%: 3.636e-78
Phase 2 self-accuracy: 0.0576 [0.024552338412879723, 0.0906309076604187] (n=191)
P-value vs 25%: 3.556e-30; P-value vs 33%: 5.31e-60
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.571429
                        1                 0.428571
Geography               1                 0.550000
                        0                 0.450000
Misc                    0                 0.553846
                        1                 0.446154
Music                   0                 0.575758
                        1                 0.424242
Other                   0                 0.630435
                        1                 0.369565
Politics                0                 0.583333
                        1                 0.416667
Science and technology  1                 0.525000
                        0                 0.475000
Sports                  0                 0.545455
                        1                 0.454545
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.587413
                     1                 0.412587
Number               1                 0.584615
                     0                 0.415385
Other                1                 0.513761
                     0                 0.486239
Person               0                 0.631068
                     1                 0.368932
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.473684  0.526316           19
                       Number               0.500000  0.500000            6
                       Other                0.500000  0.500000           14
                       Person               0.708333  0.291667           24
Geography              Date                 0.500000  0.500000           14
                       Number               0.437500  0.562500           16
                       Other                0.400000  0.600000           10
Misc                   Date                 0.571429  0.428571           21
                       Number               0.500000  0.500000            6
                       Other                0.500000  0.500000           24
                       Person               0.642857  0.357143           14
Music                  Date                 0.600000  0.400000           10
                       Number               0.250000  0.750000            4
                       Other                0.545455  0.454545           11
                       Person               0.750000  0.250000            8
Other                  Date                 0.625000  0.375000           16
                       Number               0.333333  0.666667            6
                       Other                0.636364  0.363636           11
                       Person               0.769231  0.230769           13
Politics               Date                 0.555556  0.444444           27
                       Number               0.500000  0.500000            6
                       Other                0.428571  0.571429           14
                       Person               0.846154  0.153846           13
Science and technology Date                 0.689655  0.310345           29
                       Number               0.545455  0.454545           11
                       Other                0.285714  0.714286           14
                       Person               0.307692  0.692308           26
Sports                 Date                 0.714286  0.285714            7
                       Number               0.200000  0.800000           10
                       Other                0.636364  0.363636           11
                       Person               0.800000  0.200000            5

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  420
Model:                          Logit   Df Residuals:                      408
Method:                           MLE   Df Model:                           11
Date:                Sat, 23 Aug 2025   Pseudo R-squ.:                 0.02560
Time:                        11:35:44   Log-Likelihood:                -281.99
converged:                       True   LL-Null:                       -289.40
Covariance Type:            nonrobust   LLR p-value:                    0.1910
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.0689      1.270     -0.841      0.400      -3.559       1.421
C(topic_grouped)[T.Geography]                  0.2204      0.427      0.516      0.606      -0.617       1.058
C(topic_grouped)[T.Misc]                      -0.0277      0.363     -0.076      0.939      -0.740       0.685
C(topic_grouped)[T.Music]                     -0.1013      0.442     -0.229      0.819      -0.967       0.764
C(topic_grouped)[T.Other]                     -0.2971      0.403     -0.737      0.461      -1.087       0.493
C(topic_grouped)[T.Politics]                  -0.1085      0.374     -0.290      0.772      -0.841       0.624
C(topic_grouped)[T.Science and technology]     0.3649      0.345      1.059      0.290      -0.310       1.040
C(topic_grouped)[T.Sports]                    -0.1297      0.446     -0.291      0.771      -1.003       0.743
C(answer_type_grouped)[T.Number]               0.6673      0.315      2.121      0.034       0.051       1.284
C(answer_type_grouped)[T.Other]                0.4590      0.262      1.754      0.079      -0.054       0.972
C(answer_type_grouped)[T.Person]              -0.1711      0.273     -0.627      0.531      -0.706       0.364
q_length                                       0.1510      0.273      0.553      0.580      -0.384       0.686
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing deepseek-chat (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/deepseek-chat_SimpleQA_redacted_cor_temp0.0_1754619990_game_data_evaluated.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    75
1    19
Name: count, dtype: int64

Answer change%: 0.2021 [0.12094491253019467, 0.28331040661874146] (n=94)
P-value vs 25%: 0.2478; P-value vs 0%: 1.061e-06
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=19)
P-value vs 25%: 0; P-value vs 33%: 0

  Model 1.4: Answer Changed ~ capabilities_prob
                    Could not fit Model 1.4: Singular matrix

  Model 1.5: Answer Changed ~ capabilities_entropy
                    Could not fit Model 1.5: Singular matrix

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                   94
Model:                          Logit   Df Residuals:                       92
Method:                           MLE   Df Model:                            1
Date:                Sat, 23 Aug 2025   Pseudo R-squ.:                 0.03425
Time:                        11:35:44   Log-Likelihood:                -45.693
converged:                      False   LL-Null:                       -47.314
Covariance Type:            nonrobust   LLR p-value:                   0.07183
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.4271      0.262     -5.437      0.000      -1.942      -0.913
game_entropy    22.4016   3.59e+04      0.001      1.000   -7.03e+04    7.03e+04
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=0.00, p=0.317
Paired t-test (game_entropy vs capabilities_entropy): statistic=1.00, p=0.32
Mean capabilities_entropy-game_entropy = -0.0106  [-0.0315, 0.0102] (n=94)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                    Could not fit Model 1.7: Singular matrix
                  Grouped rare topic into 'Misc'/'Other': ['Geography', 'Sports', 'TV shows', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': None
topic_grouped           answer_changed
Art                     0                 1.000000
Misc                    0                 0.809524
                        1                 0.190476
Music                   1                 0.571429
                        0                 0.428571
Other                   0                 0.600000
                        1                 0.400000
Politics                0                 0.809524
                        1                 0.190476
Science and technology  0                 0.842105
                        1                 0.157895
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.944444
                     1                 0.055556
Number               0                 0.687500
                     1                 0.312500
Other                0                 0.882353
                     1                 0.117647
Person               0                 0.555556
                     1                 0.444444
Place                0                 0.714286
                     1                 0.285714
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 1.000000  0.000000            6
                       Number               1.000000  0.000000            3
                       Other                1.000000  0.000000            2
                       Person               1.000000  0.000000            3
                       Place                1.000000  0.000000            2
Misc                   Date                 1.000000  0.000000            7
                       Number               0.800000  0.200000            5
                       Other                0.750000  0.250000            4
                       Person               0.666667  0.333333            3
                       Place                0.500000  0.500000            2
Music                  Date                 0.500000  0.500000            2
                       Number               0.000000  1.000000            1
                       Other                0.000000  1.000000            1
                       Person               0.666667  0.333333            3
Other                  Date                 1.000000  0.000000            2
                       Number               0.250000  0.750000            4
                       Other                1.000000  0.000000            2
                       Person               0.000000  1.000000            1
                       Place                1.000000  0.000000            1
Politics               Date                 0.888889  0.111111            9
                       Number               1.000000  0.000000            2
                       Other                1.000000  0.000000            4
                       Person               0.500000  0.500000            4
                       Place                0.500000  0.500000            2
Science and technology Date                 1.000000  0.000000           10
                       Number               1.000000  0.000000            1
                       Other                1.000000  0.000000            4
                       Person               0.250000  0.750000            4

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                   94
Model:                          Logit   Df Residuals:                       83
Method:                           MLE   Df Model:                           10
Date:                Sat, 23 Aug 2025   Pseudo R-squ.:                  0.2927
Time:                        11:35:44   Log-Likelihood:                -33.467
converged:                      False   LL-Null:                       -47.314
Covariance Type:            nonrobust   LLR p-value:                  0.002021
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                    -16.0543    637.349     -0.025      0.980   -1265.235    1233.127
C(topic_grouped)[T.Misc]                      14.5330    637.337      0.023      0.982   -1234.624    1263.690
C(topic_grouped)[T.Music]                     16.2997    637.337      0.026      0.980   -1232.858    1265.458
C(topic_grouped)[T.Other]                     15.5083    637.337      0.024      0.981   -1233.649    1264.666
C(topic_grouped)[T.Politics]                  14.7038    637.337      0.023      0.982   -1234.454    1263.861
C(topic_grouped)[T.Science and technology]    14.6590    637.337      0.023      0.982   -1234.499    1263.817
C(answer_type_grouped)[T.Number]               2.0159      1.002      2.011      0.044       0.051       3.981
C(answer_type_grouped)[T.Other]                0.7130      1.083      0.658      0.510      -1.410       2.836
C(answer_type_grouped)[T.Person]               2.7289      0.927      2.945      0.003       0.913       4.545
C(answer_type_grouped)[T.Place]                2.3856      1.244      1.918      0.055      -0.052       4.823
q_length                                      -0.3309      0.884     -0.374      0.708      -2.064       1.402
==============================================================================================================

Possibly complete quasi-separation: A fraction 0.17 of observations can be
perfectly predicted. This might indicate that there is complete
quasi-separation. In this case some parameters will not be identified.

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.0000
                    Could not fit Model 4.6: Singular matrix

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                   94
Model:                          Logit   Df Residuals:                       82
Method:                           MLE   Df Model:                           11
Date:                Sat, 23 Aug 2025   Pseudo R-squ.:                  0.3343
Time:                        11:35:44   Log-Likelihood:                -31.497
converged:                      False   LL-Null:                       -47.314
Covariance Type:            nonrobust   LLR p-value:                 0.0008733
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                    -26.0857   8.75e+04     -0.000      1.000   -1.72e+05    1.72e+05
C(topic_grouped)[T.Misc]                      24.4214   8.75e+04      0.000      1.000   -1.72e+05    1.72e+05
C(topic_grouped)[T.Music]                     25.4445   8.75e+04      0.000      1.000   -1.72e+05    1.72e+05
C(topic_grouped)[T.Other]                     25.3782   8.75e+04      0.000      1.000   -1.72e+05    1.72e+05
C(topic_grouped)[T.Politics]                  24.6184   8.75e+04      0.000      1.000   -1.72e+05    1.72e+05
C(topic_grouped)[T.Science and technology]    24.6047   8.75e+04      0.000      1.000   -1.72e+05    1.72e+05
C(answer_type_grouped)[T.Number]               2.6299      1.214      2.166      0.030       0.250       5.010
C(answer_type_grouped)[T.Other]                1.3559      1.281      1.059      0.290      -1.155       3.867
C(answer_type_grouped)[T.Person]               3.3965      1.161      2.926      0.003       1.122       5.671
C(answer_type_grouped)[T.Place]                2.9573      1.425      2.076      0.038       0.165       5.750
q_length                                      -0.4246      0.919     -0.462      0.644      -2.227       1.377
game_entropy                                  23.5119   3.59e+04      0.001      0.999   -7.03e+04    7.03e+04
==============================================================================================================

Possibly complete quasi-separation: A fraction 0.18 of observations can be
perfectly predicted. This might indicate that there is complete
quasi-separation. In this case some parameters will not be identified.

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                    Could not fit Model 4.95: Singular matrix

                  Model 6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length (after removing deterministic categories: defaultdict(<class 'list'>, {'topic_grouped': ['Art']}))
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                   78
Model:                          Logit   Df Residuals:                       68
Method:                           MLE   Df Model:                            9
Date:                Sat, 23 Aug 2025   Pseudo R-squ.:                  0.2272
Time:                        11:35:44   Log-Likelihood:                -33.467
converged:                       True   LL-Null:                       -43.304
Covariance Type:            nonrobust   LLR p-value:                   0.02003
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.5213      4.113     -0.370      0.711      -9.582       6.539
C(topic_grouped)[T.Music]                      1.7667      1.119      1.579      0.114      -0.426       3.959
C(topic_grouped)[T.Other]                      0.9753      0.947      1.030      0.303      -0.880       2.831
C(topic_grouped)[T.Politics]                   0.1708      0.880      0.194      0.846      -1.553       1.895
C(topic_grouped)[T.Science and technology]     0.1261      0.964      0.131      0.896      -1.763       2.015
C(answer_type_grouped)[T.Number]               2.0159      1.002      2.011      0.044       0.051       3.981
C(answer_type_grouped)[T.Other]                0.7130      1.083      0.658      0.510      -1.410       2.836
C(answer_type_grouped)[T.Person]               2.7289      0.927      2.945      0.003       0.913       4.545
C(answer_type_grouped)[T.Place]                2.3856      1.244      1.918      0.055      -0.052       4.823
q_length                                      -0.3309      0.884     -0.374      0.708      -2.064       1.402
==============================================================================================================

                  Model 6.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
                    Could not fit Model 6.6: Singular matrix

--- Analyzing deepseek-chat (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/deepseek-chat_SimpleQA_redacted_temp0.0_1754614187_game_data_evaluated.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
1    216
0    178
Name: count, dtype: int64

Answer change%: 0.5482 [0.4990827298687295, 0.5973639706388847] (n=394)
P-value vs 25%: 1.263e-32; P-value vs 0%: 5.502e-106
Phase 2 self-accuracy: 0.0556 [0.025008231572725158, 0.08610287953838594] (n=216)
P-value vs 25%: 1.011e-35; P-value vs 33%: 6.909e-71

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  394
Model:                          Logit   Df Residuals:                      392
Method:                           MLE   Df Model:                            1
Date:                Sat, 23 Aug 2025   Pseudo R-squ.:                0.002220
Time:                        11:35:44   Log-Likelihood:                -270.66
converged:                      False   LL-Null:                       -271.26
Covariance Type:            nonrobust   LLR p-value:                    0.2725
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept         19.5850   1.79e+04      0.001      0.999   -3.51e+04    3.51e+04
p_i_capability   -19.3961   1.79e+04     -0.001      0.999   -3.51e+04    3.51e+04
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                    Could not fit Model 1.5: Singular matrix

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  394
Model:                          Logit   Df Residuals:                      392
Method:                           MLE   Df Model:                            1
Date:                Sat, 23 Aug 2025   Pseudo R-squ.:               6.454e-07
Time:                        11:35:44   Log-Likelihood:                -271.26
converged:                       True   LL-Null:                       -271.26
Covariance Type:            nonrobust   LLR p-value:                    0.9851
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept        0.1938      0.103      1.888      0.059      -0.007       0.395
game_entropy    -0.0115      0.614     -0.019      0.985      -1.215       1.192
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=0.00, p=0.000911
Paired t-test (game_entropy vs capabilities_entropy): statistic=3.36, p=0.000857
Mean capabilities_entropy-game_entropy = -0.0280  [-0.0443, -0.0117] (n=393)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                    Could not fit Model 1.7: Singular matrix
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     1                 0.578947
                        0                 0.421053
Geography               0                 0.694444
                        1                 0.305556
Misc                    1                 0.555556
                        0                 0.444444
Music                   1                 0.545455
                        0                 0.454545
Other                   1                 0.621622
                        0                 0.378378
Politics                1                 0.518519
                        0                 0.481481
Science and technology  1                 0.594937
                        0                 0.405063
Sports                  1                 0.600000
                        0                 0.400000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 1                 0.596899
                     0                 0.403101
Number               0                 0.500000
                     1                 0.500000
Other                1                 0.504673
                     0                 0.495327
Person               1                 0.561224
                     0                 0.438776
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.466667  0.533333           15
                       Number               0.166667  0.833333            6
                       Other                0.500000  0.500000           14
                       Person               0.409091  0.590909           22
Geography              Date                 0.500000  0.500000           12
                       Number               0.733333  0.266667           15
                       Other                0.888889  0.111111            9
Misc                   Date                 0.368421  0.631579           19
                       Number               0.714286  0.285714            7
                       Other                0.391304  0.608696           23
                       Person               0.500000  0.500000           14
Music                  Date                 0.400000  0.600000           10
                       Number               0.666667  0.333333            3
                       Other                0.363636  0.636364           11
                       Person               0.555556  0.444444            9
Other                  Date                 0.285714  0.714286           14
                       Number               0.333333  0.666667            3
                       Other                0.400000  0.600000           10
                       Person               0.500000  0.500000           10
Politics               Date                 0.384615  0.615385           26
                       Number               0.666667  0.333333            3
                       Other                0.642857  0.357143           14
                       Person               0.454545  0.545455           11
Science and technology Date                 0.440000  0.560000           25
                       Number               0.384615  0.615385           13
                       Other                0.400000  0.600000           15
                       Person               0.384615  0.615385           26
Sports                 Date                 0.375000  0.625000            8
                       Number               0.300000  0.700000           10
                       Other                0.545455  0.454545           11
                       Person               0.333333  0.666667            6

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  394
Model:                          Logit   Df Residuals:                      382
Method:                           MLE   Df Model:                           11
Date:                Sat, 23 Aug 2025   Pseudo R-squ.:                 0.02611
Time:                        11:35:44   Log-Likelihood:                -264.18
converged:                       True   LL-Null:                       -271.26
Covariance Type:            nonrobust   LLR p-value:                    0.2238
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -0.5150      1.311     -0.393      0.694      -3.084       2.054
C(topic_grouped)[T.Geography]                 -1.1408      0.468     -2.435      0.015      -2.059      -0.223
C(topic_grouped)[T.Misc]                      -0.0877      0.373     -0.235      0.814      -0.819       0.643
C(topic_grouped)[T.Music]                     -0.1159      0.444     -0.261      0.794      -0.987       0.755
C(topic_grouped)[T.Other]                      0.1700      0.436      0.390      0.697      -0.684       1.024
C(topic_grouped)[T.Politics]                  -0.3370      0.390     -0.864      0.388      -1.102       0.428
C(topic_grouped)[T.Science and technology]     0.0342      0.355      0.096      0.923      -0.662       0.731
C(topic_grouped)[T.Sports]                     0.1187      0.444      0.267      0.789      -0.752       0.990
C(answer_type_grouped)[T.Number]              -0.2973      0.334     -0.891      0.373      -0.951       0.356
C(answer_type_grouped)[T.Other]               -0.3869      0.271     -1.426      0.154      -0.919       0.145
C(answer_type_grouped)[T.Person]              -0.2565      0.282     -0.910      0.363      -0.809       0.296
q_length                                       0.2356      0.279      0.846      0.398      -0.310       0.782
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.0000
                    Could not fit Model 4.6: Singular matrix

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  394
Model:                          Logit   Df Residuals:                      381
Method:                           MLE   Df Model:                           12
Date:                Sat, 23 Aug 2025   Pseudo R-squ.:                 0.02615
Time:                        11:35:44   Log-Likelihood:                -264.17
converged:                       True   LL-Null:                       -271.26
Covariance Type:            nonrobust   LLR p-value:                    0.2888
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -0.5166      1.311     -0.394      0.693      -3.086       2.052
C(topic_grouped)[T.Geography]                 -1.1444      0.469     -2.440      0.015      -2.064      -0.225
C(topic_grouped)[T.Misc]                      -0.0902      0.373     -0.242      0.809      -0.822       0.642
C(topic_grouped)[T.Music]                     -0.1195      0.445     -0.269      0.788      -0.992       0.753
C(topic_grouped)[T.Other]                      0.1718      0.436      0.394      0.694      -0.683       1.027
C(topic_grouped)[T.Politics]                  -0.3366      0.390     -0.863      0.388      -1.101       0.428
C(topic_grouped)[T.Science and technology]     0.0335      0.355      0.094      0.925      -0.663       0.730
C(topic_grouped)[T.Sports]                     0.1202      0.444      0.270      0.787      -0.751       0.991
C(answer_type_grouped)[T.Number]              -0.2950      0.334     -0.883      0.377      -0.950       0.360
C(answer_type_grouped)[T.Other]               -0.3856      0.271     -1.421      0.155      -0.917       0.146
C(answer_type_grouped)[T.Person]              -0.2550      0.282     -0.904      0.366      -0.808       0.298
q_length                                       0.2353      0.279      0.845      0.398      -0.311       0.781
game_entropy                                   0.0911      0.635      0.144      0.886      -1.153       1.335
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                    Could not fit Model 4.95: Singular matrix
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing gemini-1.5-pro (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/gemini-1.5-pro_SimpleQA_redacted_cor_temp0.0_1754619869_game_data_evaluated.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    79
1     9
Name: count, dtype: int64

Answer change%: 0.1023 [0.038964685075756955, 0.1655807694696976] (n=88)
P-value vs 25%: 4.796e-06; P-value vs 0%: 0.001544
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=9)
P-value vs 25%: 0; P-value vs 33%: 0
                  Grouped rare topic into 'Misc'/'Other': ['History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': None
topic_grouped           answer_changed
Art                     0                 1.000000
Geography               0                 0.857143
                        1                 0.142857
Music                   0                 0.714286
                        1                 0.285714
Other                   0                 0.923077
                        1                 0.076923
Politics                0                 0.944444
                        1                 0.055556
Science and technology  0                 1.000000
Sports                  0                 0.625000
                        1                 0.375000
TV shows                0                 0.833333
                        1                 0.166667
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.870968
                     1                 0.129032
Number               0                 0.750000
                     1                 0.250000
Other                0                 1.000000
Person               0                 0.923077
                     1                 0.076923
Place                0                 1.000000
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 1.000000  0.000000            6
                       Other                1.000000  0.000000            1
                       Person               1.000000  0.000000            5
                       Place                1.000000  0.000000            2
Geography              Date                 0.750000  0.250000            4
                       Number               1.000000  0.000000            2
                       Place                1.000000  0.000000            1
Music                  Date                 0.500000  0.500000            2
                       Number               1.000000  0.000000            1
                       Other                1.000000  0.000000            1
                       Person               0.666667  0.333333            3
Other                  Date                 1.000000  0.000000            4
                       Number               0.800000  0.200000            5
                       Other                1.000000  0.000000            1
                       Person               1.000000  0.000000            2
                       Place                1.000000  0.000000            1
Politics               Date                 0.875000  0.125000            8
                       Number               1.000000  0.000000            1
                       Other                1.000000  0.000000            4
                       Person               1.000000  0.000000            4
                       Place                1.000000  0.000000            1
Science and technology Date                 1.000000  0.000000            4
                       Number               1.000000  0.000000            1
                       Other                1.000000  0.000000            2
                       Person               1.000000  0.000000            8
Sports                 Date                 0.500000  0.500000            2
                       Number               0.000000  1.000000            1
                       Other                1.000000  0.000000            2
                       Person               0.500000  0.500000            2
                       Place                1.000000  0.000000            1
TV shows               Date                 1.000000  0.000000            1
                       Number               0.000000  1.000000            1
                       Other                1.000000  0.000000            2
                       Person               1.000000  0.000000            2

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                   88
Model:                          Logit   Df Residuals:                       75
Method:                           MLE   Df Model:                           12
Date:                Sat, 23 Aug 2025   Pseudo R-squ.:                  0.4453
Time:                        11:35:44   Log-Likelihood:                -16.112
converged:                      False   LL-Null:                       -29.044
Covariance Type:            nonrobust   LLR p-value:                   0.01122
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                    -11.4994   5.65e+04     -0.000      1.000   -1.11e+05    1.11e+05
C(topic_grouped)[T.Geography]                 21.9377   5.65e+04      0.000      1.000   -1.11e+05    1.11e+05
C(topic_grouped)[T.Music]                     23.9202   5.65e+04      0.000      1.000   -1.11e+05    1.11e+05
C(topic_grouped)[T.Other]                     21.7660   5.65e+04      0.000      1.000   -1.11e+05    1.11e+05
C(topic_grouped)[T.Politics]                  22.2202   5.65e+04      0.000      1.000   -1.11e+05    1.11e+05
C(topic_grouped)[T.Science and technology]    -6.0781   1.19e+06  -5.11e-06      1.000   -2.33e+06    2.33e+06
C(topic_grouped)[T.Sports]                    24.9071   5.65e+04      0.000      1.000   -1.11e+05    1.11e+05
C(topic_grouped)[T.TV shows]                  22.9010   5.65e+04      0.000      1.000   -1.11e+05    1.11e+05
C(answer_type_grouped)[T.Number]               0.2637      1.096      0.241      0.810      -1.884       2.411
C(answer_type_grouped)[T.Other]              -30.8118   2.02e+06  -1.53e-05      1.000   -3.96e+06    3.96e+06
C(answer_type_grouped)[T.Person]              -1.1460      1.225     -0.936      0.349      -3.546       1.254
C(answer_type_grouped)[T.Place]              -30.0287   2.87e+06  -1.05e-05      1.000   -5.62e+06    5.62e+06
q_length                                      -2.8771      1.613     -1.783      0.075      -6.039       0.285
==============================================================================================================

Possibly complete quasi-separation: A fraction 0.49 of observations can be
perfectly predicted. This might indicate that there is complete
quasi-separation. In this case some parameters will not be identified.

                  Model 6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length (after removing deterministic categories: defaultdict(<class 'list'>, {'topic_grouped': ['Science and technology', 'Art'], 'answer_type_grouped': ['Place', 'Other']}))
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                   45
Model:                          Logit   Df Residuals:                       36
Method:                           MLE   Df Model:                            8
Date:                Sat, 23 Aug 2025   Pseudo R-squ.:                  0.2845
Time:                        11:35:44   Log-Likelihood:                -16.112
converged:                       True   LL-Null:                       -22.518
Covariance Type:            nonrobust   LLR p-value:                    0.1185
====================================================================================================
                                       coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------------------
Intercept                           10.4383      6.851      1.524      0.128      -2.989      23.866
C(topic_grouped)[T.Music]            1.9824      1.625      1.220      0.222      -1.202       5.167
C(topic_grouped)[T.Other]           -0.1717      1.690     -0.102      0.919      -3.485       3.141
C(topic_grouped)[T.Politics]         0.2825      1.670      0.169      0.866      -2.992       3.556
C(topic_grouped)[T.Sports]           2.9693      1.698      1.749      0.080      -0.359       6.297
C(topic_grouped)[T.TV shows]         0.9632      1.838      0.524      0.600      -2.639       4.566
C(answer_type_grouped)[T.Number]     0.2637      1.096      0.241      0.810      -1.884       2.411
C(answer_type_grouped)[T.Person]    -1.1460      1.225     -0.936      0.349      -3.546       1.254
q_length                            -2.8771      1.613     -1.783      0.075      -6.039       0.285
====================================================================================================

--- Analyzing gemini-1.5-pro (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/gemini-1.5-pro_SimpleQA_redacted_temp0.0_1754613578_game_data_evaluated.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
1    216
0    196
Name: count, dtype: int64

Answer change%: 0.5243 [0.476048516714336, 0.5724951726060523] (n=412)
P-value vs 25%: 7.376e-29; P-value vs 0%: 9.522e-101
Phase 2 self-accuracy: 0.0463 [0.018274170750797132, 0.07431842184179546] (n=216)
P-value vs 25%: 4.63e-46; P-value vs 33%: 1.899e-89
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.524590
                        1                 0.475410
Geography               1                 0.540541
                        0                 0.459459
Misc                    1                 0.546875
                        0                 0.453125
Music                   0                 0.666667
                        1                 0.333333
Other                   1                 0.627907
                        0                 0.372093
Politics                1                 0.610169
                        0                 0.389831
Science and technology  1                 0.554217
                        0                 0.445783
Sports                  0                 0.625000
                        1                 0.375000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 1                 0.615942
                     0                 0.384058
Number               1                 0.575758
                     0                 0.424242
Other                0                 0.578947
                     1                 0.421053
Person               0                 0.521277
                     1                 0.478723
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.400000  0.600000           15
                       Number               0.444444  0.555556            9
                       Other                0.733333  0.266667           15
                       Person               0.500000  0.500000           22
Geography              Date                 0.363636  0.636364           11
                       Number               0.375000  0.625000           16
                       Other                0.700000  0.300000           10
Misc                   Date                 0.333333  0.666667           21
                       Number               0.600000  0.400000            5
                       Other                0.360000  0.640000           25
                       Person               0.769231  0.230769           13
Music                  Date                 0.600000  0.400000           10
                       Number               0.333333  0.666667            3
                       Other                0.818182  0.181818           11
                       Person               0.666667  0.333333            9
Other                  Date                 0.266667  0.733333           15
                       Number               0.400000  0.600000            5
                       Other                0.583333  0.416667           12
                       Person               0.272727  0.727273           11
Politics               Date                 0.250000  0.750000           28
                       Number               0.200000  0.800000            5
                       Other                0.600000  0.400000           15
                       Person               0.545455  0.454545           11
Science and technology Date                 0.483871  0.516129           31
                       Number               0.461538  0.538462           13
                       Other                0.411765  0.588235           17
                       Person               0.409091  0.590909           22
Sports                 Date                 0.571429  0.428571            7
                       Number               0.500000  0.500000           10
                       Other                0.777778  0.222222            9
                       Person               0.666667  0.333333            6

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  412
Model:                          Logit   Df Residuals:                      400
Method:                           MLE   Df Model:                           11
Date:                Sat, 23 Aug 2025   Pseudo R-squ.:                 0.04035
Time:                        11:35:44   Log-Likelihood:                -273.59
converged:                       True   LL-Null:                       -285.09
Covariance Type:            nonrobust   LLR p-value:                   0.01765
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -0.5061      1.289     -0.393      0.695      -3.032       2.020
C(topic_grouped)[T.Geography]                  0.1276      0.438      0.291      0.771      -0.731       0.986
C(topic_grouped)[T.Misc]                       0.3158      0.367      0.860      0.390      -0.404       1.036
C(topic_grouped)[T.Music]                     -0.5809      0.456     -1.273      0.203      -1.476       0.314
C(topic_grouped)[T.Other]                      0.6222      0.413      1.505      0.132      -0.188       1.432
C(topic_grouped)[T.Politics]                   0.4414      0.382      1.154      0.248      -0.308       1.191
C(topic_grouped)[T.Science and technology]     0.2327      0.344      0.676      0.499      -0.442       0.907
C(topic_grouped)[T.Sports]                    -0.4753      0.456     -1.041      0.298      -1.370       0.419
C(answer_type_grouped)[T.Number]              -0.0568      0.320     -0.178      0.859      -0.684       0.570
C(answer_type_grouped)[T.Other]               -0.7429      0.264     -2.812      0.005      -1.261      -0.225
C(answer_type_grouped)[T.Person]              -0.4880      0.280     -1.741      0.082      -1.037       0.061
q_length                                       0.1722      0.276      0.623      0.533      -0.370       0.714
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing gemini-2.0-flash-001 (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/gemini-2.0-flash-001_SimpleQA_redacted_cor_temp0.0_1754581102_game_data_evaluated.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    93
1    23
Name: count, dtype: int64

Answer change%: 0.1983 [0.1257210035685147, 0.27083072056941637] (n=116)
P-value vs 25%: 0.1623; P-value vs 0%: 8.502e-08
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=24)
P-value vs 25%: 0; P-value vs 33%: 0

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  116
Model:                          Logit   Df Residuals:                      114
Method:                           MLE   Df Model:                            1
Date:                Sat, 23 Aug 2025   Pseudo R-squ.:                  0.2297
Time:                        11:35:44   Log-Likelihood:                -44.499
converged:                       True   LL-Null:                       -57.768
Covariance Type:            nonrobust   LLR p-value:                 2.583e-07
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          2.4439      0.861      2.838      0.005       0.756       4.132
p_i_capability    -5.1947      1.170     -4.439      0.000      -7.488      -2.901
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  116
Model:                          Logit   Df Residuals:                      114
Method:                           MLE   Df Model:                            1
Date:                Sat, 23 Aug 2025   Pseudo R-squ.:                  0.2297
Time:                        11:35:44   Log-Likelihood:                -44.499
converged:                       True   LL-Null:                       -57.768
Covariance Type:            nonrobust   LLR p-value:                 2.583e-07
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.7508      0.445     -6.184      0.000      -3.623      -1.879
capabilities_entropy     5.1947      1.170      4.439      0.000       2.901       7.488
========================================================================================

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  116
Model:                          Logit   Df Residuals:                      114
Method:                           MLE   Df Model:                            1
Date:                Sat, 23 Aug 2025   Pseudo R-squ.:                  0.1765
Time:                        11:35:44   Log-Likelihood:                -47.574
converged:                       True   LL-Null:                       -57.768
Covariance Type:            nonrobust   LLR p-value:                 6.318e-06
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -2.4501      0.396     -6.184      0.000      -3.227      -1.674
game_entropy     4.0487      0.957      4.231      0.000       2.173       5.924
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=3250.00, p=0.694
Paired t-test (game_entropy vs capabilities_entropy): statistic=-0.05, p=0.958
Mean capabilities_entropy-game_entropy = 0.0011  [-0.0409, 0.0432] (n=116)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  116
Model:                          Logit   Df Residuals:                      113
Method:                           MLE   Df Model:                            2
Date:                Sat, 23 Aug 2025   Pseudo R-squ.:                  0.2774
Time:                        11:35:44   Log-Likelihood:                -41.746
converged:                       True   LL-Null:                       -57.768
Covariance Type:            nonrobust   LLR p-value:                 1.101e-07
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -3.1453      0.517     -6.086      0.000      -4.158      -2.132
capabilities_entropy     4.0406      1.255      3.219      0.001       1.581       6.501
game_entropy             2.6475      1.114      2.377      0.017       0.464       4.831
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': None
topic_grouped           answer_changed
Art                     0                 0.750000
                        1                 0.250000
Geography               0                 0.846154
                        1                 0.153846
Misc                    0                 0.733333
                        1                 0.266667
Music                   0                 0.909091
                        1                 0.090909
Other                   0                 0.888889
                        1                 0.111111
Politics                0                 0.900000
                        1                 0.100000
Science and technology  0                 0.761905
                        1                 0.238095
Sports                  0                 0.636364
                        1                 0.363636
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.860465
                     1                 0.139535
Number               0                 0.666667
                     1                 0.333333
Other                0                 0.703704
                     1                 0.296296
Person               0                 0.800000
                     1                 0.200000
Place                0                 1.000000
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.833333  0.166667            6
                       Number               0.000000  1.000000            1
                       Other                0.600000  0.400000            5
                       Person               1.000000  0.000000            4
Geography              Date                 0.800000  0.200000            5
                       Number               0.750000  0.250000            4
                       Other                1.000000  0.000000            1
                       Place                1.000000  0.000000            3
Misc                   Date                 1.000000  0.000000            3
                       Number               1.000000  0.000000            2
                       Other                0.400000  0.600000            5
                       Person               0.666667  0.333333            3
                       Place                1.000000  0.000000            2
Music                  Date                 1.000000  0.000000            2
                       Number               1.000000  0.000000            1
                       Other                1.000000  0.000000            1
                       Person               0.833333  0.166667            6
                       Place                1.000000  0.000000            1
Other                  Date                 1.000000  0.000000            3
                       Number               1.000000  0.000000            2
                       Other                0.666667  0.333333            3
                       Place                1.000000  0.000000            1
Politics               Date                 0.900000  0.100000           10
                       Other                1.000000  0.000000            4
                       Person               0.750000  0.250000            4
                       Place                1.000000  0.000000            2
Science and technology Date                 0.818182  0.181818           11
                       Number               0.000000  1.000000            2
                       Other                1.000000  0.000000            4
                       Person               0.750000  0.250000            4
Sports                 Date                 0.666667  0.333333            3
                       Other                0.500000  0.500000            4
                       Person               0.750000  0.250000            4

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  116
Model:                          Logit   Df Residuals:                      103
Method:                           MLE   Df Model:                           12
Date:                Sat, 23 Aug 2025   Pseudo R-squ.:                  0.1058
Time:                        11:35:44   Log-Likelihood:                -51.655
converged:                      False   LL-Null:                       -57.768
Covariance Type:            nonrobust   LLR p-value:                    0.4276
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -0.4504      3.408     -0.132      0.895      -7.130       6.229
C(topic_grouped)[T.Geography]                 -0.5655      1.089     -0.519      0.603      -2.699       1.568
C(topic_grouped)[T.Misc]                       0.1101      0.853      0.129      0.897      -1.563       1.783
C(topic_grouped)[T.Music]                     -1.1563      1.241     -0.932      0.352      -3.589       1.276
C(topic_grouped)[T.Other]                     -1.1764      1.286     -0.915      0.360      -3.697       1.344
C(topic_grouped)[T.Politics]                  -0.7534      0.980     -0.769      0.442      -2.674       1.167
C(topic_grouped)[T.Science and technology]     0.0183      0.794      0.023      0.982      -1.537       1.573
C(topic_grouped)[T.Sports]                     0.5470      0.869      0.629      0.529      -1.157       2.251
C(answer_type_grouped)[T.Number]               1.3054      0.835      1.563      0.118      -0.331       2.942
C(answer_type_grouped)[T.Other]                0.8398      0.638      1.316      0.188      -0.411       2.091
C(answer_type_grouped)[T.Person]               0.3899      0.709      0.550      0.582      -1.000       1.780
C(answer_type_grouped)[T.Place]              -19.3447   1.46e+04     -0.001      0.999   -2.87e+04    2.86e+04
q_length                                      -0.2551      0.756     -0.337      0.736      -1.737       1.227
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.1951
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  116
Model:                          Logit   Df Residuals:                      102
Method:                           MLE   Df Model:                           13
Date:                Sat, 23 Aug 2025   Pseudo R-squ.:                  0.3017
Time:                        11:35:44   Log-Likelihood:                -40.341
converged:                      False   LL-Null:                       -57.768
Covariance Type:            nonrobust   LLR p-value:                 0.0008916
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -4.0419      4.062     -0.995      0.320     -12.002       3.918
C(topic_grouped)[T.Geography]                 -1.1159      1.478     -0.755      0.450      -4.013       1.781
C(topic_grouped)[T.Misc]                       0.2115      1.064      0.199      0.842      -1.874       2.297
C(topic_grouped)[T.Music]                     -1.0113      1.366     -0.740      0.459      -3.689       1.666
C(topic_grouped)[T.Other]                     -0.7096      1.485     -0.478      0.633      -3.621       2.201
C(topic_grouped)[T.Politics]                  -0.4995      1.107     -0.451      0.652      -2.669       1.670
C(topic_grouped)[T.Science and technology]     0.4194      0.956      0.439      0.661      -1.454       2.293
C(topic_grouped)[T.Sports]                     1.2739      1.060      1.202      0.230      -0.804       3.352
C(answer_type_grouped)[T.Number]               0.6747      1.035      0.652      0.514      -1.353       2.703
C(answer_type_grouped)[T.Other]                0.1835      0.751      0.244      0.807      -1.288       1.655
C(answer_type_grouped)[T.Person]               0.1703      0.804      0.212      0.832      -1.406       1.746
C(answer_type_grouped)[T.Place]              -22.0691   7.43e+04     -0.000      1.000   -1.46e+05    1.46e+05
q_length                                       0.2560      0.878      0.292      0.771      -1.464       1.976
capabilities_entropy                           5.3680      1.320      4.066      0.000       2.781       7.955
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                    Could not fit Model 4.8: Singular matrix

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  116
Model:                          Logit   Df Residuals:                      101
Method:                           MLE   Df Model:                           14
Date:                Sat, 23 Aug 2025   Pseudo R-squ.:                  0.3414
Time:                        11:35:44   Log-Likelihood:                -38.048
converged:                      False   LL-Null:                       -57.768
Covariance Type:            nonrobust   LLR p-value:                 0.0003117
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -3.2167      4.208     -0.764      0.445     -11.465       5.031
C(topic_grouped)[T.Geography]                 -0.5858      1.442     -0.406      0.685      -3.411       2.240
C(topic_grouped)[T.Misc]                      -0.0431      1.122     -0.038      0.969      -2.241       2.155
C(topic_grouped)[T.Music]                     -1.2434      1.538     -0.809      0.419      -4.257       1.770
C(topic_grouped)[T.Other]                     -0.3566      1.522     -0.234      0.815      -3.339       2.626
C(topic_grouped)[T.Politics]                  -0.2777      1.182     -0.235      0.814      -2.594       2.039
C(topic_grouped)[T.Science and technology]     0.6811      1.007      0.677      0.499      -1.292       2.654
C(topic_grouped)[T.Sports]                     1.0863      1.126      0.965      0.335      -1.120       3.293
C(answer_type_grouped)[T.Number]               0.3258      1.099      0.296      0.767      -1.829       2.481
C(answer_type_grouped)[T.Other]               -0.4408      0.836     -0.528      0.598      -2.078       1.197
C(answer_type_grouped)[T.Person]              -0.1539      0.872     -0.176      0.860      -1.864       1.556
C(answer_type_grouped)[T.Place]              -19.1930   1.33e+04     -0.001      0.999   -2.61e+04     2.6e+04
q_length                                       0.0253      0.924      0.027      0.978      -1.786       1.837
capabilities_entropy                           4.0593      1.456      2.788      0.005       1.205       6.913
game_entropy                                   3.0168      1.474      2.046      0.041       0.127       5.907
==============================================================================================================

                  Model 6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length (after removing deterministic categories: defaultdict(<class 'list'>, {'answer_type_grouped': ['Place']}))
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  107
Model:                          Logit   Df Residuals:                       95
Method:                           MLE   Df Model:                           11
Date:                Sat, 23 Aug 2025   Pseudo R-squ.:                 0.07242
Time:                        11:35:44   Log-Likelihood:                -51.655
converged:                       True   LL-Null:                       -55.688
Covariance Type:            nonrobust   LLR p-value:                    0.7074
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -0.4504      3.408     -0.132      0.895      -7.130       6.229
C(topic_grouped)[T.Geography]                 -0.5655      1.089     -0.519      0.603      -2.699       1.568
C(topic_grouped)[T.Misc]                       0.1101      0.853      0.129      0.897      -1.563       1.783
C(topic_grouped)[T.Music]                     -1.1563      1.241     -0.932      0.352      -3.589       1.276
C(topic_grouped)[T.Other]                     -1.1764      1.286     -0.915      0.360      -3.697       1.344
C(topic_grouped)[T.Politics]                  -0.7534      0.980     -0.769      0.442      -2.674       1.167
C(topic_grouped)[T.Science and technology]     0.0183      0.794      0.023      0.982      -1.537       1.573
C(topic_grouped)[T.Sports]                     0.5470      0.869      0.629      0.529      -1.157       2.251
C(answer_type_grouped)[T.Number]               1.3054      0.835      1.563      0.118      -0.331       2.942
C(answer_type_grouped)[T.Other]                0.8398      0.638      1.316      0.188      -0.411       2.091
C(answer_type_grouped)[T.Person]               0.3899      0.709      0.550      0.582      -1.000       1.780
q_length                                      -0.2551      0.756     -0.337      0.736      -1.737       1.227
==============================================================================================================

                  Model 6.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  107
Model:                          Logit   Df Residuals:                       94
Method:                           MLE   Df Model:                           12
Date:                Sat, 23 Aug 2025   Pseudo R-squ.:                  0.2756
Time:                        11:35:44   Log-Likelihood:                -40.341
converged:                       True   LL-Null:                       -55.688
Covariance Type:            nonrobust   LLR p-value:                  0.002194
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -4.0419      4.062     -0.995      0.320     -12.002       3.918
C(topic_grouped)[T.Geography]                 -1.1159      1.478     -0.755      0.450      -4.013       1.781
C(topic_grouped)[T.Misc]                       0.2115      1.064      0.199      0.842      -1.874       2.297
C(topic_grouped)[T.Music]                     -1.0113      1.366     -0.740      0.459      -3.689       1.666
C(topic_grouped)[T.Other]                     -0.7096      1.485     -0.478      0.633      -3.621       2.201
C(topic_grouped)[T.Politics]                  -0.4995      1.107     -0.451      0.652      -2.669       1.670
C(topic_grouped)[T.Science and technology]     0.4194      0.956      0.439      0.661      -1.454       2.293
C(topic_grouped)[T.Sports]                     1.2739      1.060      1.202      0.230      -0.804       3.352
C(answer_type_grouped)[T.Number]               0.6747      1.035      0.652      0.514      -1.353       2.703
C(answer_type_grouped)[T.Other]                0.1835      0.751      0.244      0.807      -1.288       1.655
C(answer_type_grouped)[T.Person]               0.1703      0.804      0.212      0.832      -1.406       1.746
q_length                                       0.2560      0.878      0.292      0.771      -1.464       1.976
capabilities_entropy                           5.3680      1.320      4.066      0.000       2.781       7.955
==============================================================================================================

--- Analyzing gemini-2.0-flash-001 (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/gemini-2.0-flash-001_SimpleQA_redacted_temp0.0_1754580925_game_data_evaluated.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
1    177
0    160
Name: count, dtype: int64

Answer change%: 0.5252 [0.4719074966023817, 0.5785376072551851] (n=337)
P-value vs 25%: 4.611e-24; P-value vs 0%: 4.583e-83
Phase 2 self-accuracy: 0.0703 [0.03343817731349223, 0.10710236322704832] (n=185)
P-value vs 25%: 1.132e-21; P-value vs 33%: 2.043e-44

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  337
Model:                          Logit   Df Residuals:                      335
Method:                           MLE   Df Model:                            1
Date:                Sat, 23 Aug 2025   Pseudo R-squ.:                 0.06606
Time:                        11:35:44   Log-Likelihood:                -217.76
converged:                       True   LL-Null:                       -233.16
Covariance Type:            nonrobust   LLR p-value:                 2.853e-08
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          1.1405      0.227      5.019      0.000       0.695       1.586
p_i_capability    -2.0517      0.386     -5.321      0.000      -2.807      -1.296
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  337
Model:                          Logit   Df Residuals:                      335
Method:                           MLE   Df Model:                            1
Date:                Sat, 23 Aug 2025   Pseudo R-squ.:                 0.06606
Time:                        11:35:44   Log-Likelihood:                -217.76
converged:                       True   LL-Null:                       -233.16
Covariance Type:            nonrobust   LLR p-value:                 2.853e-08
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -0.9112      0.221     -4.123      0.000      -1.344      -0.478
capabilities_entropy     2.0517      0.386      5.321      0.000       1.296       2.807
========================================================================================

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  337
Model:                          Logit   Df Residuals:                      335
Method:                           MLE   Df Model:                            1
Date:                Sat, 23 Aug 2025   Pseudo R-squ.:                 0.07229
Time:                        11:35:44   Log-Likelihood:                -216.31
converged:                       True   LL-Null:                       -233.16
Covariance Type:            nonrobust   LLR p-value:                 6.396e-09
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.8503      0.204     -4.161      0.000      -1.251      -0.450
game_entropy     2.1673      0.391      5.537      0.000       1.400       2.934
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=22496.00, p=0.000834
Paired t-test (game_entropy vs capabilities_entropy): statistic=-3.42, p=0.0007
Mean capabilities_entropy-game_entropy = 0.0520  [0.0222, 0.0817] (n=337)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  337
Model:                          Logit   Df Residuals:                      334
Method:                           MLE   Df Model:                            2
Date:                Sat, 23 Aug 2025   Pseudo R-squ.:                 0.08832
Time:                        11:35:44   Log-Likelihood:                -212.57
converged:                       True   LL-Null:                       -233.16
Covariance Type:            nonrobust   LLR p-value:                 1.139e-09
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.1644      0.240     -4.847      0.000      -1.635      -0.694
capabilities_entropy     1.2496      0.460      2.719      0.007       0.349       2.151
game_entropy             1.4788      0.464      3.188      0.001       0.570       2.388
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': None
topic_grouped           answer_changed
Art                     1                 0.596154
                        0                 0.403846
Geography               1                 0.612903
                        0                 0.387097
Misc                    1                 0.549020
                        0                 0.450980
Music                   1                 0.565217
                        0                 0.434783
Other                   0                 0.527778
                        1                 0.472222
Politics                1                 0.595745
                        0                 0.404255
Science and technology  0                 0.597222
                        1                 0.402778
Sports                  0                 0.520000
                        1                 0.480000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 1                 0.598214
                     0                 0.401786
Number               0                 0.557377
                     1                 0.442623
Other                0                 0.538462
                     1                 0.461538
Person               0                 0.513158
                     1                 0.486842
Place                1                 0.695652
                     0                 0.304348
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.428571  0.571429           14
                       Number               0.500000  0.500000            8
                       Other                0.500000  0.500000            8
                       Person               0.411765  0.588235           17
                       Place                0.000000  1.000000            5
Geography              Date                 0.400000  0.600000           10
                       Number               0.357143  0.642857           14
                       Other                0.500000  0.500000            2
                       Place                0.400000  0.600000            5
Misc                   Date                 0.375000  0.625000           16
                       Number               0.571429  0.428571            7
                       Other                0.421053  0.578947           19
                       Person               0.555556  0.444444            9
Music                  Date                 0.333333  0.666667            9
                       Number               0.333333  0.666667            3
                       Other                0.500000  0.500000            6
                       Person               0.500000  0.500000            4
                       Place                1.000000  0.000000            1
Other                  Date                 0.615385  0.384615           13
                       Number               0.800000  0.200000            5
                       Other                0.600000  0.400000            5
                       Person               0.222222  0.777778            9
                       Place                0.500000  0.500000            4
Politics               Date                 0.238095  0.761905           21
                       Number               0.750000  0.250000            4
                       Other                0.400000  0.600000           10
                       Person               0.875000  0.125000            8
                       Place                0.000000  1.000000            4
Science and technology Date                 0.458333  0.541667           24
                       Number               0.600000  0.400000           10
                       Other                1.000000  0.000000           11
                       Person               0.520000  0.480000           25
                       Place                1.000000  0.000000            2
Sports                 Date                 0.400000  0.600000            5
                       Number               0.700000  0.300000           10
                       Other                0.250000  0.750000            4
                       Person               0.750000  0.250000            4
                       Place                0.000000  1.000000            2

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  337
Model:                          Logit   Df Residuals:                      324
Method:                           MLE   Df Model:                           12
Date:                Sat, 23 Aug 2025   Pseudo R-squ.:                 0.03481
Time:                        11:35:44   Log-Likelihood:                -225.05
converged:                       True   LL-Null:                       -233.16
Covariance Type:            nonrobust   LLR p-value:                    0.1809
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      0.8540      1.398      0.611      0.541      -1.886       3.594
C(topic_grouped)[T.Geography]                  0.0854      0.490      0.174      0.862      -0.875       1.046
C(topic_grouped)[T.Misc]                      -0.1002      0.411     -0.244      0.807      -0.906       0.705
C(topic_grouped)[T.Music]                     -0.1214      0.516     -0.235      0.814      -1.133       0.890
C(topic_grouped)[T.Other]                     -0.5673      0.444     -1.276      0.202      -1.438       0.304
C(topic_grouped)[T.Politics]                  -0.0628      0.422     -0.149      0.882      -0.890       0.765
C(topic_grouped)[T.Science and technology]    -0.7772      0.377     -2.060      0.039      -1.517      -0.038
C(topic_grouped)[T.Sports]                    -0.3627      0.503     -0.721      0.471      -1.349       0.623
C(answer_type_grouped)[T.Number]              -0.6861      0.339     -2.026      0.043      -1.350      -0.022
C(answer_type_grouped)[T.Other]               -0.6010      0.325     -1.851      0.064      -1.237       0.035
C(answer_type_grouped)[T.Person]              -0.3754      0.311     -1.208      0.227      -0.985       0.234
C(answer_type_grouped)[T.Place]                0.3560      0.505      0.706      0.480      -0.633       1.345
q_length                                      -0.0372      0.299     -0.124      0.901      -0.623       0.549
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.4972
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  337
Model:                          Logit   Df Residuals:                      323
Method:                           MLE   Df Model:                           13
Date:                Sat, 23 Aug 2025   Pseudo R-squ.:                  0.1126
Time:                        11:35:44   Log-Likelihood:                -206.90
converged:                       True   LL-Null:                       -233.16
Covariance Type:            nonrobust   LLR p-value:                 1.097e-06
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      0.7709      1.479      0.521      0.602      -2.127       3.669
C(topic_grouped)[T.Geography]                  0.1393      0.513      0.271      0.786      -0.867       1.145
C(topic_grouped)[T.Misc]                      -0.0892      0.434     -0.206      0.837      -0.939       0.761
C(topic_grouped)[T.Music]                     -0.0134      0.542     -0.025      0.980      -1.075       1.048
C(topic_grouped)[T.Other]                     -0.5238      0.471     -1.112      0.266      -1.447       0.399
C(topic_grouped)[T.Politics]                   0.1624      0.453      0.358      0.720      -0.726       1.051
C(topic_grouped)[T.Science and technology]    -0.6195      0.400     -1.547      0.122      -1.404       0.165
C(topic_grouped)[T.Sports]                    -0.1393      0.534     -0.261      0.794      -1.186       0.908
C(answer_type_grouped)[T.Number]              -1.0904      0.368     -2.965      0.003      -1.811      -0.370
C(answer_type_grouped)[T.Other]               -0.9226      0.351     -2.626      0.009      -1.611      -0.234
C(answer_type_grouped)[T.Person]              -0.4478      0.330     -1.358      0.174      -1.094       0.198
C(answer_type_grouped)[T.Place]                0.3354      0.525      0.639      0.523      -0.693       1.364
q_length                                      -0.2663      0.320     -0.832      0.405      -0.893       0.361
capabilities_entropy                           2.3871      0.420      5.680      0.000       1.563       3.211
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  337
Model:                          Logit   Df Residuals:                      323
Method:                           MLE   Df Model:                           13
Date:                Sat, 23 Aug 2025   Pseudo R-squ.:                  0.1238
Time:                        11:35:44   Log-Likelihood:                -204.29
converged:                       True   LL-Null:                       -233.16
Covariance Type:            nonrobust   LLR p-value:                 1.324e-07
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      0.8638      1.476      0.585      0.558      -2.029       3.757
C(topic_grouped)[T.Geography]                  0.1765      0.517      0.342      0.733      -0.836       1.189
C(topic_grouped)[T.Misc]                      -0.0067      0.434     -0.015      0.988      -0.857       0.844
C(topic_grouped)[T.Music]                     -0.1149      0.539     -0.213      0.831      -1.172       0.942
C(topic_grouped)[T.Other]                     -0.6061      0.473     -1.283      0.200      -1.532       0.320
C(topic_grouped)[T.Politics]                   0.1404      0.453      0.310      0.756      -0.747       1.028
C(topic_grouped)[T.Science and technology]    -0.7107      0.401     -1.770      0.077      -1.497       0.076
C(topic_grouped)[T.Sports]                    -0.1705      0.544     -0.313      0.754      -1.237       0.896
C(answer_type_grouped)[T.Number]              -1.1743      0.374     -3.140      0.002      -1.907      -0.441
C(answer_type_grouped)[T.Other]               -0.9218      0.353     -2.610      0.009      -1.614      -0.230
C(answer_type_grouped)[T.Person]              -0.2874      0.329     -0.872      0.383      -0.933       0.358
C(answer_type_grouped)[T.Place]                0.3762      0.536      0.702      0.482      -0.674       1.426
q_length                                      -0.2803      0.319     -0.878      0.380      -0.906       0.345
game_entropy                                   2.6058      0.432      6.028      0.000       1.759       3.453
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  337
Model:                          Logit   Df Residuals:                      322
Method:                           MLE   Df Model:                           14
Date:                Sat, 23 Aug 2025   Pseudo R-squ.:                  0.1434
Time:                        11:35:44   Log-Likelihood:                -199.72
converged:                       True   LL-Null:                       -233.16
Covariance Type:            nonrobust   LLR p-value:                 7.064e-09
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      0.8252      1.500      0.550      0.582      -2.115       3.765
C(topic_grouped)[T.Geography]                  0.1737      0.522      0.333      0.739      -0.850       1.197
C(topic_grouped)[T.Misc]                      -0.0255      0.440     -0.058      0.954      -0.889       0.838
C(topic_grouped)[T.Music]                     -0.0599      0.550     -0.109      0.913      -1.138       1.018
C(topic_grouped)[T.Other]                     -0.5562      0.481     -1.156      0.248      -1.500       0.387
C(topic_grouped)[T.Politics]                   0.2315      0.463      0.500      0.617      -0.677       1.140
C(topic_grouped)[T.Science and technology]    -0.6366      0.409     -1.555      0.120      -1.439       0.166
C(topic_grouped)[T.Sports]                    -0.0844      0.550     -0.153      0.878      -1.162       0.993
C(answer_type_grouped)[T.Number]              -1.2643      0.379     -3.334      0.001      -2.008      -0.521
C(answer_type_grouped)[T.Other]               -1.0318      0.362     -2.849      0.004      -1.742      -0.322
C(answer_type_grouped)[T.Person]              -0.3512      0.337     -1.043      0.297      -1.011       0.309
C(answer_type_grouped)[T.Place]                0.3534      0.539      0.656      0.512      -0.703       1.410
q_length                                      -0.3542      0.326     -1.086      0.278      -0.993       0.285
capabilities_entropy                           1.4692      0.491      2.994      0.003       0.508       2.431
game_entropy                                   1.8438      0.497      3.708      0.000       0.869       2.818
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing gpt-4.1-2025-04-14 (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/gpt-4.1-2025-04-14_SimpleQA_redacted_cor_temp0.0_1754536300_game_data_evaluated.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    166
1     20
Name: count, dtype: int64

Answer change%: 0.1075 [0.06300764430591885, 0.15204611913494137] (n=186)
P-value vs 25%: 3.555e-10; P-value vs 0%: 2.203e-06
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=20)
P-value vs 25%: 0; P-value vs 33%: 0

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  186
Model:                          Logit   Df Residuals:                      184
Method:                           MLE   Df Model:                            1
Date:                Sat, 23 Aug 2025   Pseudo R-squ.:                 0.03773
Time:                        11:35:44   Log-Likelihood:                -61.089
converged:                       True   LL-Null:                       -63.484
Covariance Type:            nonrobust   LLR p-value:                   0.02861
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept         -1.0487      0.510     -2.058      0.040      -2.047      -0.050
p_i_capability    -1.8538      0.865     -2.144      0.032      -3.548      -0.159
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  186
Model:                          Logit   Df Residuals:                      184
Method:                           MLE   Df Model:                            1
Date:                Sat, 23 Aug 2025   Pseudo R-squ.:                 0.03773
Time:                        11:35:44   Log-Likelihood:                -61.089
converged:                       True   LL-Null:                       -63.484
Covariance Type:            nonrobust   LLR p-value:                   0.02861
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.9025      0.479     -6.055      0.000      -3.842      -1.963
capabilities_entropy     1.8538      0.865      2.144      0.032       0.159       3.548
========================================================================================

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  186
Model:                          Logit   Df Residuals:                      184
Method:                           MLE   Df Model:                            1
Date:                Sat, 23 Aug 2025   Pseudo R-squ.:                  0.2818
Time:                        11:35:44   Log-Likelihood:                -45.596
converged:                       True   LL-Null:                       -63.484
Covariance Type:            nonrobust   LLR p-value:                 2.214e-09
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -3.3389      0.415     -8.040      0.000      -4.153      -2.525
game_entropy    13.0991      2.624      4.992      0.000       7.956      18.242
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=499.00, p=7.31e-29
Paired t-test (game_entropy vs capabilities_entropy): statistic=-16.09, p=5.24e-37
Mean capabilities_entropy-game_entropy = 0.3120  [0.2740, 0.3500] (n=186)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  186
Model:                          Logit   Df Residuals:                      183
Method:                           MLE   Df Model:                            2
Date:                Sat, 23 Aug 2025   Pseudo R-squ.:                  0.2819
Time:                        11:35:44   Log-Likelihood:                -45.587
converged:                       True   LL-Null:                       -63.484
Covariance Type:            nonrobust   LLR p-value:                 1.688e-08
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -3.3881      0.555     -6.106      0.000      -4.476      -2.301
capabilities_entropy     0.1405      1.034      0.136      0.892      -1.885       2.166
game_entropy            12.9813      2.755      4.711      0.000       7.581      18.382
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['Music', 'TV shows', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': None
topic_grouped           answer_changed
Art                     0                 0.928571
                        1                 0.071429
Geography               0                 1.000000
Misc                    0                 0.971429
                        1                 0.028571
Other                   0                 0.904762
                        1                 0.095238
Politics                0                 0.894737
                        1                 0.105263
Science and technology  0                 0.703704
                        1                 0.296296
Sports                  0                 0.823529
                        1                 0.176471
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.913043
                     1                 0.086957
Number               0                 0.906250
                     1                 0.093750
Other                0                 0.806452
                     1                 0.193548
Person               0                 0.878049
                     1                 0.121951
Place                0                 1.000000
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.909091  0.090909           11
                       Number               1.000000  0.000000            3
                       Other                1.000000  0.000000            1
                       Person               0.909091  0.090909           11
                       Place                1.000000  0.000000            2
Geography              Date                 1.000000  0.000000            6
                       Number               1.000000  0.000000            9
                       Other                1.000000  0.000000            2
                       Place                1.000000  0.000000            3
Misc                   Date                 0.888889  0.111111            9
                       Number               1.000000  0.000000            6
                       Other                1.000000  0.000000            9
                       Person               1.000000  0.000000           11
Other                  Date                 1.000000  0.000000            5
                       Number               1.000000  0.000000            4
                       Other                0.800000  0.200000            5
                       Person               0.666667  0.333333            3
                       Place                1.000000  0.000000            4
Politics               Date                 1.000000  0.000000           18
                       Number               0.333333  0.666667            3
                       Other                0.750000  0.250000            8
                       Person               1.000000  0.000000            6
                       Place                1.000000  0.000000            3
Science and technology Date                 0.714286  0.285714           14
                       Number               0.750000  0.250000            4
                       Other                1.000000  0.000000            3
                       Person               0.500000  0.500000            6
Sports                 Date                 1.000000  0.000000            6
                       Number               1.000000  0.000000            3
                       Other                0.000000  1.000000            3
                       Person               1.000000  0.000000            4
                       Place                1.000000  0.000000            1

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  186
Model:                          Logit   Df Residuals:                      174
Method:                           MLE   Df Model:                           11
Date:                Sat, 23 Aug 2025   Pseudo R-squ.:                  0.1883
Time:                        11:35:44   Log-Likelihood:                -51.530
converged:                      False   LL-Null:                       -63.484
Covariance Type:            nonrobust   LLR p-value:                   0.01313
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -6.6553      3.086     -2.156      0.031     -12.705      -0.606
C(topic_grouped)[T.Geography]                -21.4324   3.61e+04     -0.001      1.000   -7.07e+04    7.07e+04
C(topic_grouped)[T.Misc]                      -1.3891      1.290     -1.077      0.282      -3.918       1.140
C(topic_grouped)[T.Other]                      0.0838      1.098      0.076      0.939      -2.068       2.236
C(topic_grouped)[T.Politics]                   0.0692      0.971      0.071      0.943      -1.833       1.972
C(topic_grouped)[T.Science and technology]     1.5693      0.873      1.797      0.072      -0.142       3.281
C(topic_grouped)[T.Sports]                     0.8710      1.011      0.862      0.389      -1.110       2.852
C(answer_type_grouped)[T.Number]               0.5538      0.803      0.690      0.490      -1.020       2.127
C(answer_type_grouped)[T.Other]                1.4776      0.709      2.085      0.037       0.089       2.867
C(answer_type_grouped)[T.Person]               0.5973      0.690      0.865      0.387      -0.756       1.950
C(answer_type_grouped)[T.Place]              -25.7026   4.32e+05  -5.95e-05      1.000   -8.47e+05    8.47e+05
q_length                                       0.8385      0.654      1.282      0.200      -0.443       2.120
==============================================================================================================

Possibly complete quasi-separation: A fraction 0.16 of observations can be
perfectly predicted. This might indicate that there is complete
quasi-separation. In this case some parameters will not be identified.

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.3669
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  186
Model:                          Logit   Df Residuals:                      173
Method:                           MLE   Df Model:                           12
Date:                Sat, 23 Aug 2025   Pseudo R-squ.:                  0.2222
Time:                        11:35:44   Log-Likelihood:                -49.376
converged:                      False   LL-Null:                       -63.484
Covariance Type:            nonrobust   LLR p-value:                  0.005144
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -7.8939      3.318     -2.379      0.017     -14.398      -1.390
C(topic_grouped)[T.Geography]                -21.0867   3.36e+04     -0.001      0.999   -6.58e+04    6.58e+04
C(topic_grouped)[T.Misc]                      -1.2371      1.308     -0.946      0.344      -3.801       1.327
C(topic_grouped)[T.Other]                      0.0013      1.120      0.001      0.999      -2.195       2.197
C(topic_grouped)[T.Politics]                   0.3416      0.987      0.346      0.729      -1.592       2.276
C(topic_grouped)[T.Science and technology]     1.8331      0.906      2.023      0.043       0.057       3.609
C(topic_grouped)[T.Sports]                     1.1291      1.032      1.094      0.274      -0.894       3.152
C(answer_type_grouped)[T.Number]               0.2609      0.826      0.316      0.752      -1.359       1.880
C(answer_type_grouped)[T.Other]                1.0359      0.763      1.358      0.174      -0.459       2.531
C(answer_type_grouped)[T.Person]               0.3263      0.721      0.453      0.651      -1.087       1.739
C(answer_type_grouped)[T.Place]              -11.2098    274.507     -0.041      0.967    -549.234     526.815
q_length                                       0.9325      0.689      1.353      0.176      -0.418       2.283
capabilities_entropy                           1.9971      0.991      2.014      0.044       0.054       3.940
==============================================================================================================

Possibly complete quasi-separation: A fraction 0.16 of observations can be
perfectly predicted. This might indicate that there is complete
quasi-separation. In this case some parameters will not be identified.

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  186
Model:                          Logit   Df Residuals:                      173
Method:                           MLE   Df Model:                           12
Date:                Sat, 23 Aug 2025   Pseudo R-squ.:                  0.3858
Time:                        11:35:44   Log-Likelihood:                -38.994
converged:                      False   LL-Null:                       -63.484
Covariance Type:            nonrobust   LLR p-value:                 2.108e-06
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -9.9340      3.771     -2.634      0.008     -17.325      -2.543
C(topic_grouped)[T.Geography]                -19.5052   2.43e+04     -0.001      0.999   -4.77e+04    4.76e+04
C(topic_grouped)[T.Misc]                      -0.7289      1.397     -0.522      0.602      -3.468       2.010
C(topic_grouped)[T.Other]                      0.0495      1.217      0.041      0.968      -2.337       2.436
C(topic_grouped)[T.Politics]                   0.1882      1.051      0.179      0.858      -1.872       2.248
C(topic_grouped)[T.Science and technology]     1.2915      0.995      1.298      0.194      -0.658       3.241
C(topic_grouped)[T.Sports]                     0.6435      1.226      0.525      0.600      -1.759       3.046
C(answer_type_grouped)[T.Number]              -0.4193      1.039     -0.404      0.687      -2.456       1.617
C(answer_type_grouped)[T.Other]                0.8237      0.842      0.978      0.328      -0.826       2.474
C(answer_type_grouped)[T.Person]               0.5236      0.794      0.660      0.510      -1.032       2.079
C(answer_type_grouped)[T.Place]              -19.4050   2.07e+04     -0.001      0.999   -4.06e+04    4.06e+04
q_length                                       1.3557      0.790      1.717      0.086      -0.192       2.903
game_entropy                                  12.7857      3.091      4.137      0.000       6.728      18.843
==============================================================================================================

Possibly complete quasi-separation: A fraction 0.16 of observations can be
perfectly predicted. This might indicate that there is complete
quasi-separation. In this case some parameters will not be identified.

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  186
Model:                          Logit   Df Residuals:                      172
Method:                           MLE   Df Model:                           13
Date:                Sat, 23 Aug 2025   Pseudo R-squ.:                  0.3868
Time:                        11:35:44   Log-Likelihood:                -38.926
converged:                      False   LL-Null:                       -63.484
Covariance Type:            nonrobust   LLR p-value:                 4.223e-06
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                    -10.1228      3.831     -2.642      0.008     -17.632      -2.614
C(topic_grouped)[T.Geography]                -19.4585   2.42e+04     -0.001      0.999   -4.75e+04    4.74e+04
C(topic_grouped)[T.Misc]                      -0.7032      1.402     -0.502      0.616      -3.451       2.044
C(topic_grouped)[T.Other]                      0.0700      1.217      0.058      0.954      -2.315       2.455
C(topic_grouped)[T.Politics]                   0.2608      1.068      0.244      0.807      -1.833       2.355
C(topic_grouped)[T.Science and technology]     1.3578      1.019      1.333      0.183      -0.639       3.354
C(topic_grouped)[T.Sports]                     0.7151      1.234      0.580      0.562      -1.703       3.133
C(answer_type_grouped)[T.Number]              -0.4613      1.043     -0.442      0.658      -2.505       1.583
C(answer_type_grouped)[T.Other]                0.7494      0.867      0.864      0.388      -0.951       2.449
C(answer_type_grouped)[T.Person]               0.4995      0.799      0.625      0.532      -1.067       2.066
C(answer_type_grouped)[T.Place]              -20.4081   3.26e+04     -0.001      1.000    -6.4e+04    6.39e+04
q_length                                       1.3612      0.794      1.715      0.086      -0.195       2.917
capabilities_entropy                           0.4191      1.134      0.370      0.712      -1.803       2.641
game_entropy                                  12.4806      3.192      3.910      0.000       6.224      18.737
==============================================================================================================

Possibly complete quasi-separation: A fraction 0.16 of observations can be
perfectly predicted. This might indicate that there is complete
quasi-separation. In this case some parameters will not be identified.

                  Model 6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length (after removing deterministic categories: defaultdict(<class 'list'>, {'topic_grouped': ['Geography'], 'answer_type_grouped': ['Place']}))
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  156
Model:                          Logit   Df Residuals:                      146
Method:                           MLE   Df Model:                            9
Date:                Sat, 23 Aug 2025   Pseudo R-squ.:                  0.1374
Time:                        11:35:44   Log-Likelihood:                -51.530
converged:                       True   LL-Null:                       -59.742
Covariance Type:            nonrobust   LLR p-value:                   0.05856
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -6.6553      3.086     -2.156      0.031     -12.705      -0.606
C(topic_grouped)[T.Misc]                      -1.3891      1.290     -1.077      0.282      -3.918       1.140
C(topic_grouped)[T.Other]                      0.0838      1.098      0.076      0.939      -2.068       2.236
C(topic_grouped)[T.Politics]                   0.0692      0.971      0.071      0.943      -1.833       1.972
C(topic_grouped)[T.Science and technology]     1.5693      0.873      1.797      0.072      -0.142       3.281
C(topic_grouped)[T.Sports]                     0.8710      1.011      0.862      0.389      -1.110       2.852
C(answer_type_grouped)[T.Number]               0.5538      0.803      0.690      0.490      -1.020       2.127
C(answer_type_grouped)[T.Other]                1.4776      0.709      2.085      0.037       0.089       2.867
C(answer_type_grouped)[T.Person]               0.5973      0.690      0.865      0.387      -0.756       1.950
q_length                                       0.8385      0.654      1.282      0.200      -0.443       2.120
==============================================================================================================

                  Model 6.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  156
Model:                          Logit   Df Residuals:                      145
Method:                           MLE   Df Model:                           10
Date:                Sat, 23 Aug 2025   Pseudo R-squ.:                  0.1735
Time:                        11:35:44   Log-Likelihood:                -49.376
converged:                       True   LL-Null:                       -59.742
Covariance Type:            nonrobust   LLR p-value:                   0.02305
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -7.8939      3.318     -2.379      0.017     -14.398      -1.390
C(topic_grouped)[T.Misc]                      -1.2371      1.308     -0.946      0.344      -3.801       1.327
C(topic_grouped)[T.Other]                      0.0013      1.120      0.001      0.999      -2.195       2.197
C(topic_grouped)[T.Politics]                   0.3416      0.987      0.346      0.729      -1.592       2.276
C(topic_grouped)[T.Science and technology]     1.8331      0.906      2.023      0.043       0.057       3.609
C(topic_grouped)[T.Sports]                     1.1291      1.032      1.094      0.274      -0.894       3.152
C(answer_type_grouped)[T.Number]               0.2609      0.826      0.316      0.752      -1.359       1.880
C(answer_type_grouped)[T.Other]                1.0359      0.763      1.358      0.174      -0.459       2.531
C(answer_type_grouped)[T.Person]               0.3263      0.721      0.453      0.651      -1.087       1.739
q_length                                       0.9325      0.689      1.353      0.176      -0.418       2.283
capabilities_entropy                           1.9971      0.991      2.014      0.044       0.054       3.940
==============================================================================================================

--- Analyzing gpt-4.1-2025-04-14 (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/gpt-4.1-2025-04-14_SimpleQA_redacted_temp0.0_1754535978_game_data_evaluated.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    174
1    139
Name: count, dtype: int64

Answer change%: 0.4441 [0.38904499770213324, 0.4991339160358859] (n=313)
P-value vs 25%: 4.815e-12; P-value vs 0%: 2.545e-56
Phase 2 self-accuracy: 0.1071 [0.05590904476368383, 0.15837666952203044] (n=140)
P-value vs 25%: 4.628e-08; P-value vs 33%: 5.61e-18

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  313
Model:                          Logit   Df Residuals:                      311
Method:                           MLE   Df Model:                            1
Date:                Sat, 23 Aug 2025   Pseudo R-squ.:                 0.08519
Time:                        11:35:44   Log-Likelihood:                -196.68
converged:                       True   LL-Null:                       -214.99
Covariance Type:            nonrobust   LLR p-value:                 1.427e-09
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          0.7314      0.201      3.643      0.000       0.338       1.125
p_i_capability    -2.5832      0.460     -5.611      0.000      -3.486      -1.681
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  312
Model:                          Logit   Df Residuals:                      310
Method:                           MLE   Df Model:                            1
Date:                Sat, 23 Aug 2025   Pseudo R-squ.:                 0.08356
Time:                        11:35:44   Log-Likelihood:                -196.28
converged:                       True   LL-Null:                       -214.18
Covariance Type:            nonrobust   LLR p-value:                 2.193e-09
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.8408      0.323     -5.697      0.000      -2.474      -1.208
capabilities_entropy     2.5590      0.461      5.553      0.000       1.656       3.462
========================================================================================

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  313
Model:                          Logit   Df Residuals:                      311
Method:                           MLE   Df Model:                            1
Date:                Sat, 23 Aug 2025   Pseudo R-squ.:                  0.1132
Time:                        11:35:44   Log-Likelihood:                -190.67
converged:                       True   LL-Null:                       -214.99
Covariance Type:            nonrobust   LLR p-value:                 3.053e-12
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.1963      0.196     -6.110      0.000      -1.580      -0.813
game_entropy     5.4218      0.885      6.126      0.000       3.687       7.156
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=325.00, p=1.49e-51
Paired t-test (game_entropy vs capabilities_entropy): statistic=-30.57, p=1.02e-95
Mean capabilities_entropy-game_entropy = 0.4314  [0.4038, 0.4591] (n=312)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  312
Model:                          Logit   Df Residuals:                      309
Method:                           MLE   Df Model:                            2
Date:                Sat, 23 Aug 2025   Pseudo R-squ.:                  0.1301
Time:                        11:35:44   Log-Likelihood:                -186.31
converged:                       True   LL-Null:                       -214.18
Covariance Type:            nonrobust   LLR p-value:                 7.839e-13
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.9056      0.330     -5.777      0.000      -2.552      -1.259
capabilities_entropy     1.5043      0.522      2.885      0.004       0.482       2.526
game_entropy             4.0459      0.973      4.160      0.000       2.140       5.952
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.531915
                        1                 0.468085
Geography               0                 0.625000
                        1                 0.375000
Misc                    0                 0.549020
                        1                 0.450980
Music                   0                 0.642857
                        1                 0.357143
Other                   1                 0.548387
                        0                 0.451613
Politics                1                 0.538462
                        0                 0.461538
Science and technology  0                 0.557143
                        1                 0.442857
Sports                  0                 0.739130
                        1                 0.260870
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 1                 0.520000
                     0                 0.480000
Number               0                 0.673913
                     1                 0.326087
Other                0                 0.647727
                     1                 0.352273
Person               1                 0.518987
                     0                 0.481013
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.700000  0.300000           10
                       Number               0.666667  0.333333            6
                       Other                0.600000  0.400000           15
                       Person               0.312500  0.687500           16
Geography              Date                 0.555556  0.444444            9
                       Number               0.666667  0.333333            9
                       Other                0.666667  0.333333            6
Misc                   Date                 0.411765  0.588235           17
                       Number               0.750000  0.250000            4
                       Other                0.600000  0.400000           20
                       Person               0.600000  0.400000           10
Music                  Date                 0.666667  0.333333            9
                       Number               0.666667  0.333333            3
                       Other                0.600000  0.400000           10
                       Person               0.666667  0.333333            6
Other                  Date                 0.307692  0.692308           13
                       Number               1.000000  0.000000            3
                       Other                0.600000  0.400000            5
                       Person               0.400000  0.600000           10
Politics               Date                 0.277778  0.722222           18
                       Number               0.333333  0.666667            3
                       Other                0.666667  0.333333            9
                       Person               0.666667  0.333333            9
Science and technology Date                 0.571429  0.428571           21
                       Number               0.600000  0.400000           10
                       Other                0.666667  0.333333           15
                       Person               0.458333  0.541667           24
Sports                 Date                 0.666667  0.333333            3
                       Number               0.750000  0.250000            8
                       Other                0.875000  0.125000            8
                       Person               0.500000  0.500000            4

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  313
Model:                          Logit   Df Residuals:                      301
Method:                           MLE   Df Model:                           11
Date:                Sat, 23 Aug 2025   Pseudo R-squ.:                 0.04362
Time:                        11:35:44   Log-Likelihood:                -205.62
converged:                       True   LL-Null:                       -214.99
Covariance Type:            nonrobust   LLR p-value:                   0.06561
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -2.9470      1.556     -1.893      0.058      -5.998       0.104
C(topic_grouped)[T.Geography]                 -0.2198      0.536     -0.410      0.682      -1.270       0.830
C(topic_grouped)[T.Misc]                      -0.0679      0.417     -0.163      0.871      -0.886       0.750
C(topic_grouped)[T.Music]                     -0.4267      0.503     -0.849      0.396      -1.412       0.558
C(topic_grouped)[T.Other]                      0.2947      0.481      0.613      0.540      -0.648       1.237
C(topic_grouped)[T.Politics]                   0.0650      0.451      0.144      0.886      -0.820       0.950
C(topic_grouped)[T.Science and technology]    -0.1950      0.389     -0.502      0.616      -0.957       0.567
C(topic_grouped)[T.Sports]                    -0.7982      0.572     -1.396      0.163      -1.919       0.323
C(answer_type_grouped)[T.Number]              -0.6973      0.389     -1.792      0.073      -1.460       0.065
C(answer_type_grouped)[T.Other]               -0.5443      0.310     -1.756      0.079      -1.152       0.063
C(answer_type_grouped)[T.Person]               0.0956      0.315      0.304      0.761      -0.521       0.712
q_length                                       0.6756      0.331      2.042      0.041       0.027       1.324
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.6108
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  312
Model:                          Logit   Df Residuals:                      299
Method:                           MLE   Df Model:                           12
Date:                Sat, 23 Aug 2025   Pseudo R-squ.:                  0.1408
Time:                        11:35:44   Log-Likelihood:                -184.02
converged:                       True   LL-Null:                       -214.18
Covariance Type:            nonrobust   LLR p-value:                 1.970e-08
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -4.0610      1.700     -2.389      0.017      -7.392      -0.730
C(topic_grouped)[T.Geography]                 -0.2515      0.574     -0.438      0.661      -1.376       0.873
C(topic_grouped)[T.Misc]                      -0.2006      0.440     -0.456      0.649      -1.064       0.662
C(topic_grouped)[T.Music]                     -0.3433      0.530     -0.647      0.517      -1.383       0.696
C(topic_grouped)[T.Other]                      0.4466      0.525      0.850      0.395      -0.583       1.476
C(topic_grouped)[T.Politics]                   0.3462      0.488      0.709      0.478      -0.611       1.303
C(topic_grouped)[T.Science and technology]    -0.1388      0.416     -0.334      0.739      -0.954       0.677
C(topic_grouped)[T.Sports]                    -0.5012      0.616     -0.813      0.416      -1.709       0.707
C(answer_type_grouped)[T.Number]              -1.3077      0.432     -3.025      0.002      -2.155      -0.460
C(answer_type_grouped)[T.Other]               -0.8860      0.341     -2.602      0.009      -1.553      -0.219
C(answer_type_grouped)[T.Person]              -0.2572      0.344     -0.748      0.454      -0.931       0.416
q_length                                       0.5478      0.356      1.539      0.124      -0.150       1.246
capabilities_entropy                           2.9959      0.513      5.844      0.000       1.991       4.001
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  313
Model:                          Logit   Df Residuals:                      300
Method:                           MLE   Df Model:                           12
Date:                Sat, 23 Aug 2025   Pseudo R-squ.:                  0.1796
Time:                        11:35:44   Log-Likelihood:                -176.39
converged:                       True   LL-Null:                       -214.99
Covariance Type:            nonrobust   LLR p-value:                 1.401e-11
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -2.1830      1.716     -1.272      0.203      -5.546       1.180
C(topic_grouped)[T.Geography]                 -0.3210      0.607     -0.529      0.597      -1.511       0.869
C(topic_grouped)[T.Misc]                       0.0204      0.453      0.045      0.964      -0.868       0.909
C(topic_grouped)[T.Music]                     -0.7033      0.562     -1.251      0.211      -1.805       0.398
C(topic_grouped)[T.Other]                     -0.0916      0.546     -0.168      0.867      -1.162       0.979
C(topic_grouped)[T.Politics]                   0.5556      0.499      1.114      0.265      -0.422       1.533
C(topic_grouped)[T.Science and technology]    -0.1792      0.437     -0.411      0.681      -1.035       0.676
C(topic_grouped)[T.Sports]                    -0.6068      0.613     -0.991      0.322      -1.807       0.594
C(answer_type_grouped)[T.Number]              -1.7587      0.489     -3.596      0.000      -2.717      -0.800
C(answer_type_grouped)[T.Other]               -0.8107      0.337     -2.403      0.016      -1.472      -0.149
C(answer_type_grouped)[T.Person]              -0.4004      0.353     -1.135      0.256      -1.092       0.291
q_length                                       0.3063      0.365      0.838      0.402      -0.410       1.022
game_entropy                                   6.8199      1.030      6.622      0.000       4.801       8.839
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  312
Model:                          Logit   Df Residuals:                      298
Method:                           MLE   Df Model:                           13
Date:                Sat, 23 Aug 2025   Pseudo R-squ.:                  0.2002
Time:                        11:35:44   Log-Likelihood:                -171.30
converged:                       True   LL-Null:                       -214.18
Covariance Type:            nonrobust   LLR p-value:                 9.000e-13
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -3.0066      1.769     -1.699      0.089      -6.474       0.461
C(topic_grouped)[T.Geography]                 -0.3653      0.609     -0.600      0.549      -1.559       0.828
C(topic_grouped)[T.Misc]                      -0.1184      0.459     -0.258      0.797      -1.019       0.782
C(topic_grouped)[T.Music]                     -0.6297      0.572     -1.100      0.271      -1.752       0.492
C(topic_grouped)[T.Other]                      0.0423      0.557      0.076      0.940      -1.050       1.135
C(topic_grouped)[T.Politics]                   0.5932      0.507      1.171      0.242      -0.400       1.586
C(topic_grouped)[T.Science and technology]    -0.1857      0.441     -0.421      0.674      -1.050       0.678
C(topic_grouped)[T.Sports]                    -0.5075      0.629     -0.807      0.420      -1.741       0.726
C(answer_type_grouped)[T.Number]              -1.8548      0.487     -3.807      0.000      -2.810      -0.900
C(answer_type_grouped)[T.Other]               -0.9372      0.350     -2.678      0.007      -1.623      -0.251
C(answer_type_grouped)[T.Person]              -0.4863      0.361     -1.345      0.179      -1.195       0.222
q_length                                       0.3184      0.371      0.857      0.391      -0.409       1.046
capabilities_entropy                           1.7746      0.573      3.095      0.002       0.651       2.898
game_entropy                                   5.1774      1.117      4.634      0.000       2.987       7.367
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing gpt-4o-2024-08-06 (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/gpt-4o-2024-08-06_SimpleQA_redacted_cor_temp0.0_1754577480_game_data_evaluated.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    115
1     14
Name: count, dtype: int64

Answer change%: 0.1085 [0.054851586683555865, 0.1622026768823356] (n=129)
P-value vs 25%: 2.393e-07; P-value vs 0%: 7.405e-05
Phase 2 self-accuracy: 0.0714 [0.0, 0.20633346810620642] (n=14)
P-value vs 25%: 0.009476; P-value vs 33%: 0.0001446

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  129
Model:                          Logit   Df Residuals:                      127
Method:                           MLE   Df Model:                            1
Date:                Sat, 23 Aug 2025   Pseudo R-squ.:                 0.07514
Time:                        11:35:44   Log-Likelihood:                -40.973
converged:                       True   LL-Null:                       -44.302
Covariance Type:            nonrobust   LLR p-value:                  0.009872
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept         -0.9339      0.499     -1.871      0.061      -1.912       0.044
p_i_capability    -2.6968      1.142     -2.361      0.018      -4.935      -0.458
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  129
Model:                          Logit   Df Residuals:                      127
Method:                           MLE   Df Model:                            1
Date:                Sat, 23 Aug 2025   Pseudo R-squ.:                 0.07514
Time:                        11:35:44   Log-Likelihood:                -40.973
converged:                       True   LL-Null:                       -44.302
Covariance Type:            nonrobust   LLR p-value:                  0.009872
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -3.6307      0.792     -4.586      0.000      -5.182      -2.079
capabilities_entropy     2.6968      1.142      2.361      0.018       0.458       4.935
========================================================================================

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  129
Model:                          Logit   Df Residuals:                      127
Method:                           MLE   Df Model:                            1
Date:                Sat, 23 Aug 2025   Pseudo R-squ.:                  0.1253
Time:                        11:35:44   Log-Likelihood:                -38.752
converged:                       True   LL-Null:                       -44.302
Covariance Type:            nonrobust   LLR p-value:                 0.0008631
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -3.6228      0.679     -5.339      0.000      -4.953      -2.293
game_entropy     3.1757      1.040      3.053      0.002       1.137       5.215
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=2748.00, p=0.000685
Paired t-test (game_entropy vs capabilities_entropy): statistic=-3.69, p=0.000334
Mean capabilities_entropy-game_entropy = 0.1161  [0.0544, 0.1779] (n=129)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  129
Model:                          Logit   Df Residuals:                      126
Method:                           MLE   Df Model:                            2
Date:                Sat, 23 Aug 2025   Pseudo R-squ.:                  0.1519
Time:                        11:35:44   Log-Likelihood:                -37.571
converged:                       True   LL-Null:                       -44.302
Covariance Type:            nonrobust   LLR p-value:                  0.001193
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -4.3412      0.890     -4.879      0.000      -6.085      -2.597
capabilities_entropy     1.7740      1.208      1.468      0.142      -0.594       4.142
game_entropy             2.5999      1.071      2.427      0.015       0.500       4.700
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': None
topic_grouped           answer_changed
Art                     0                 1.000000
Geography               0                 0.909091
                        1                 0.090909
Misc                    0                 0.937500
                        1                 0.062500
Music                   0                 1.000000
Other                   0                 0.933333
                        1                 0.066667
Politics                0                 0.843750
                        1                 0.156250
Science and technology  0                 0.687500
                        1                 0.312500
Sports                  0                 0.888889
                        1                 0.111111
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.942308
                     1                 0.057692
Number               0                 0.937500
                     1                 0.062500
Other                0                 0.875000
                     1                 0.125000
Person               0                 0.777778
                     1                 0.222222
Place                0                 0.900000
                     1                 0.100000
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 1.000000  0.000000            9
                       Number               1.000000  0.000000            2
                       Other                1.000000  0.000000            2
                       Person               1.000000  0.000000            5
                       Place                1.000000  0.000000            1
Geography              Date                 1.000000  0.000000            3
                       Number               0.833333  0.166667            6
                       Place                1.000000  0.000000            2
Misc                   Date                 1.000000  0.000000            5
                       Number               1.000000  0.000000            4
                       Other                1.000000  0.000000            3
                       Person               0.666667  0.333333            3
                       Place                1.000000  0.000000            1
Music                  Date                 1.000000  0.000000            3
                       Other                1.000000  0.000000            3
                       Person               1.000000  0.000000            5
Other                  Date                 1.000000  0.000000            5
                       Number               1.000000  0.000000            2
                       Other                1.000000  0.000000            3
                       Person               0.666667  0.333333            3
                       Place                1.000000  0.000000            2
Politics               Date                 0.937500  0.062500           16
                       Number               1.000000  0.000000            1
                       Other                0.714286  0.285714            7
                       Person               0.800000  0.200000            5
                       Place                0.666667  0.333333            3
Science and technology Date                 0.714286  0.285714            7
                       Number               1.000000  0.000000            1
                       Other                0.800000  0.200000            5
                       Person               0.333333  0.666667            3
Sports                 Date                 1.000000  0.000000            4
                       Other                1.000000  0.000000            1
                       Person               0.666667  0.333333            3
                       Place                1.000000  0.000000            1

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                    Could not fit Model 4: Singular matrix

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.4767
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  129
Model:                          Logit   Df Residuals:                      115
Method:                           MLE   Df Model:                           13
Date:                Sat, 23 Aug 2025   Pseudo R-squ.:                  0.3334
Time:                        11:35:44   Log-Likelihood:                -29.533
converged:                      False   LL-Null:                       -44.302
Covariance Type:            nonrobust   LLR p-value:                  0.005488
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                    -22.5983    113.764     -0.199      0.843    -245.571     200.374
C(topic_grouped)[T.Geography]                 10.8942    113.684      0.096      0.924    -211.922     233.710
C(topic_grouped)[T.Misc]                      10.3016    113.680      0.091      0.928    -212.507     233.111
C(topic_grouped)[T.Music]                     -5.8327   3056.584     -0.002      0.998   -5996.628    5984.963
C(topic_grouped)[T.Other]                     10.0730    113.679      0.089      0.929    -212.734     232.880
C(topic_grouped)[T.Politics]                  10.7823    113.676      0.095      0.924    -212.019     233.584
C(topic_grouped)[T.Science and technology]    12.4042    113.677      0.109      0.913    -210.399     235.207
C(topic_grouped)[T.Sports]                    10.7872    113.680      0.095      0.924    -212.022     233.597
C(answer_type_grouped)[T.Number]               0.2971      1.599      0.186      0.853      -2.838       3.432
C(answer_type_grouped)[T.Other]                0.6257      1.118      0.560      0.576      -1.565       2.817
C(answer_type_grouped)[T.Person]               1.9437      1.025      1.896      0.058      -0.065       3.953
C(answer_type_grouped)[T.Place]                0.8051      1.377      0.585      0.559      -1.893       3.504
q_length                                       1.6902      0.930      1.818      0.069      -0.132       3.513
capabilities_entropy                           2.2065      1.357      1.625      0.104      -0.454       4.867
==============================================================================================================

Possibly complete quasi-separation: A fraction 0.23 of observations can be
perfectly predicted. This might indicate that there is complete
quasi-separation. In this case some parameters will not be identified.

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  129
Model:                          Logit   Df Residuals:                      115
Method:                           MLE   Df Model:                           13
Date:                Sat, 23 Aug 2025   Pseudo R-squ.:                  0.5006
Time:                        11:35:44   Log-Likelihood:                -22.124
converged:                      False   LL-Null:                       -44.302
Covariance Type:            nonrobust   LLR p-value:                 2.679e-05
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                    -42.8469   2.95e+04     -0.001      0.999   -5.79e+04    5.78e+04
C(topic_grouped)[T.Geography]                 18.7821   2.95e+04      0.001      0.999   -5.78e+04    5.78e+04
C(topic_grouped)[T.Misc]                      19.4147   2.95e+04      0.001      0.999   -5.78e+04    5.78e+04
C(topic_grouped)[T.Music]                     -6.6448   3.36e+05  -1.98e-05      1.000   -6.59e+05    6.59e+05
C(topic_grouped)[T.Other]                     18.6677   2.95e+04      0.001      0.999   -5.78e+04    5.78e+04
C(topic_grouped)[T.Politics]                  19.0312   2.95e+04      0.001      0.999   -5.78e+04    5.78e+04
C(topic_grouped)[T.Science and technology]    22.1014   2.95e+04      0.001      0.999   -5.78e+04    5.78e+04
C(topic_grouped)[T.Sports]                    22.1237   2.95e+04      0.001      0.999   -5.78e+04    5.78e+04
C(answer_type_grouped)[T.Number]              -0.6761      2.861     -0.236      0.813      -6.284       4.932
C(answer_type_grouped)[T.Other]                0.2972      1.245      0.239      0.811      -2.143       2.738
C(answer_type_grouped)[T.Person]               1.7496      1.158      1.511      0.131      -0.520       4.019
C(answer_type_grouped)[T.Place]                0.4141      1.630      0.254      0.800      -2.782       3.610
q_length                                       3.7873      1.266      2.993      0.003       1.307       6.268
game_entropy                                   6.2354      1.886      3.305      0.001       2.538       9.933
==============================================================================================================

Possibly complete quasi-separation: A fraction 0.23 of observations can be
perfectly predicted. This might indicate that there is complete
quasi-separation. In this case some parameters will not be identified.

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  129
Model:                          Logit   Df Residuals:                      114
Method:                           MLE   Df Model:                           14
Date:                Sat, 23 Aug 2025   Pseudo R-squ.:                  0.5064
Time:                        11:35:44   Log-Likelihood:                -21.869
converged:                      False   LL-Null:                       -44.302
Covariance Type:            nonrobust   LLR p-value:                 4.289e-05
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                    -42.6175   3.77e+04     -0.001      0.999   -7.39e+04    7.38e+04
C(topic_grouped)[T.Geography]                 19.1177   3.77e+04      0.001      1.000   -7.38e+04    7.39e+04
C(topic_grouped)[T.Misc]                      19.9418   3.77e+04      0.001      1.000   -7.38e+04    7.39e+04
C(topic_grouped)[T.Music]                     14.6358   3.77e+04      0.000      1.000   -7.38e+04    7.38e+04
C(topic_grouped)[T.Other]                     19.1644   3.77e+04      0.001      1.000   -7.38e+04    7.39e+04
C(topic_grouped)[T.Politics]                  19.5704   3.77e+04      0.001      1.000   -7.38e+04    7.39e+04
C(topic_grouped)[T.Science and technology]    22.7549   3.77e+04      0.001      1.000   -7.38e+04    7.39e+04
C(topic_grouped)[T.Sports]                    22.7251   3.77e+04      0.001      1.000   -7.38e+04    7.39e+04
C(answer_type_grouped)[T.Number]              -0.6445      2.605     -0.247      0.805      -5.751       4.462
C(answer_type_grouped)[T.Other]               -0.1005      1.365     -0.074      0.941      -2.777       2.576
C(answer_type_grouped)[T.Person]               1.3820      1.281      1.079      0.281      -1.128       3.892
C(answer_type_grouped)[T.Place]                0.4922      1.625      0.303      0.762      -2.692       3.677
q_length                                       3.5285      1.277      2.762      0.006       1.025       6.032
capabilities_entropy                           1.2187      1.693      0.720      0.472      -2.101       4.538
game_entropy                                   6.0461      1.898      3.186      0.001       2.327       9.766
==============================================================================================================

Possibly complete quasi-separation: A fraction 0.19 of observations can be
perfectly predicted. This might indicate that there is complete
quasi-separation. In this case some parameters will not be identified.

                  Model 6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length (after removing deterministic categories: defaultdict(<class 'list'>, {'topic_grouped': ['Music', 'Art']}))
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                   99
Model:                          Logit   Df Residuals:                       88
Method:                           MLE   Df Model:                           10
Date:                Sat, 23 Aug 2025   Pseudo R-squ.:                  0.2326
Time:                        11:35:44   Log-Likelihood:                -30.961
converged:                       True   LL-Null:                       -40.345
Covariance Type:            nonrobust   LLR p-value:                   0.04331
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                    -12.0832      4.616     -2.618      0.009     -21.130      -3.037
C(topic_grouped)[T.Misc]                      -0.9213      1.764     -0.522      0.601      -4.379       2.536
C(topic_grouped)[T.Other]                     -1.1844      1.845     -0.642      0.521      -4.802       2.433
C(topic_grouped)[T.Politics]                  -0.3805      1.615     -0.236      0.814      -3.545       2.784
C(topic_grouped)[T.Science and technology]     1.0382      1.658      0.626      0.531      -2.212       4.288
C(topic_grouped)[T.Sports]                    -0.6365      1.952     -0.326      0.744      -4.463       3.190
C(answer_type_grouped)[T.Number]               0.6180      1.612      0.383      0.701      -2.541       3.777
C(answer_type_grouped)[T.Other]                1.3219      0.991      1.334      0.182      -0.620       3.264
C(answer_type_grouped)[T.Person]               2.4989      0.962      2.598      0.009       0.614       4.384
C(answer_type_grouped)[T.Place]                0.8685      1.347      0.645      0.519      -1.771       3.508
q_length                                       2.0388      0.912      2.235      0.025       0.251       3.826
==============================================================================================================

                  Model 6.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                   99
Model:                          Logit   Df Residuals:                       87
Method:                           MLE   Df Model:                           11
Date:                Sat, 23 Aug 2025   Pseudo R-squ.:                  0.2680
Time:                        11:35:44   Log-Likelihood:                -29.533
converged:                       True   LL-Null:                       -40.345
Covariance Type:            nonrobust   LLR p-value:                   0.02746
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                    -11.7040      4.678     -2.502      0.012     -20.873      -2.535
C(topic_grouped)[T.Misc]                      -0.5926      1.796     -0.330      0.741      -4.113       2.928
C(topic_grouped)[T.Other]                     -0.8212      1.831     -0.449      0.654      -4.410       2.768
C(topic_grouped)[T.Politics]                  -0.1119      1.577     -0.071      0.943      -3.203       2.979
C(topic_grouped)[T.Science and technology]     1.5099      1.673      0.903      0.367      -1.768       4.788
C(topic_grouped)[T.Sports]                    -0.1070      1.965     -0.054      0.957      -3.959       3.745
C(answer_type_grouped)[T.Number]               0.2971      1.599      0.186      0.853      -2.838       3.432
C(answer_type_grouped)[T.Other]                0.6257      1.118      0.560      0.576      -1.565       2.817
C(answer_type_grouped)[T.Person]               1.9437      1.025      1.896      0.058      -0.065       3.953
C(answer_type_grouped)[T.Place]                0.8051      1.377      0.585      0.559      -1.893       3.504
q_length                                       1.6902      0.930      1.818      0.069      -0.132       3.513
capabilities_entropy                           2.2065      1.357      1.625      0.104      -0.454       4.867
==============================================================================================================

--- Analyzing gpt-4o-2024-08-06 (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/gpt-4o-2024-08-06_SimpleQA_redacted_temp0.0_1754577242_game_data_evaluated.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    150
1    138
Name: count, dtype: int64

Answer change%: 0.4792 [0.4214708224904875, 0.5368625108428459] (n=288)
P-value vs 25%: 6.975e-15; P-value vs 0%: 1.424e-59
Phase 2 self-accuracy: 0.0588 [0.021540306663598137, 0.09610675215993128] (n=153)
P-value vs 25%: 9.18e-24; P-value vs 33%: 4.265e-47

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  288
Model:                          Logit   Df Residuals:                      286
Method:                           MLE   Df Model:                            1
Date:                Sat, 23 Aug 2025   Pseudo R-squ.:                 0.04938
Time:                        11:35:44   Log-Likelihood:                -189.53
converged:                       True   LL-Null:                       -199.38
Covariance Type:            nonrobust   LLR p-value:                 9.109e-06
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          0.5026      0.181      2.780      0.005       0.148       0.857
p_i_capability    -2.4327      0.583     -4.176      0.000      -3.574      -1.291
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  287
Model:                          Logit   Df Residuals:                      285
Method:                           MLE   Df Model:                            1
Date:                Sat, 23 Aug 2025   Pseudo R-squ.:                 0.04824
Time:                        11:35:44   Log-Likelihood:                -189.06
converged:                       True   LL-Null:                       -198.64
Covariance Type:            nonrobust   LLR p-value:                 1.199e-05
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.9130      0.465     -4.114      0.000      -2.824      -1.002
capabilities_entropy     2.4032      0.583      4.125      0.000       1.261       3.545
========================================================================================

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  288
Model:                          Logit   Df Residuals:                      286
Method:                           MLE   Df Model:                            1
Date:                Sat, 23 Aug 2025   Pseudo R-squ.:                 0.04357
Time:                        11:35:44   Log-Likelihood:                -190.69
converged:                       True   LL-Null:                       -199.38
Covariance Type:            nonrobust   LLR p-value:                 3.069e-05
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.1571      0.296     -3.909      0.000      -1.737      -0.577
game_entropy     1.7230      0.427      4.032      0.000       0.885       2.561
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=9993.00, p=3.38e-14
Paired t-test (game_entropy vs capabilities_entropy): statistic=-8.62, p=4.59e-16
Mean capabilities_entropy-game_entropy = 0.1337  [0.1033, 0.1641] (n=287)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  287
Model:                          Logit   Df Residuals:                      284
Method:                           MLE   Df Model:                            2
Date:                Sat, 23 Aug 2025   Pseudo R-squ.:                 0.06023
Time:                        11:35:44   Log-Likelihood:                -186.67
converged:                       True   LL-Null:                       -198.64
Covariance Type:            nonrobust   LLR p-value:                 6.368e-06
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.0322      0.468     -4.338      0.000      -2.950      -1.114
capabilities_entropy     1.6881      0.661      2.552      0.011       0.392       2.984
game_entropy             1.0631      0.491      2.166      0.030       0.101       2.025
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     1                 0.531915
                        0                 0.468085
Geography               0                 0.518519
                        1                 0.481481
Misc                    0                 0.562500
                        1                 0.437500
Music                   0                 0.560000
                        1                 0.440000
Other                   1                 0.535714
                        0                 0.464286
Politics                0                 0.633333
                        1                 0.366667
Science and technology  1                 0.566667
                        0                 0.433333
Sports                  0                 0.652174
                        1                 0.347826
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 1                 0.505155
                     0                 0.494845
Number               0                 0.531915
                     1                 0.468085
Other                0                 0.575342
                     1                 0.424658
Person               1                 0.507042
                     0                 0.492958
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.500000  0.500000           12
                       Number               0.200000  0.800000            5
                       Other                0.461538  0.538462           13
                       Person               0.529412  0.470588           17
Geography              Date                 0.363636  0.636364           11
                       Number               0.636364  0.363636           11
                       Other                0.600000  0.400000            5
Misc                   Date                 0.500000  0.500000           16
                       Number               0.800000  0.200000            5
                       Other                0.625000  0.375000           16
                       Person               0.454545  0.545455           11
Music                  Date                 0.428571  0.571429            7
                       Number               0.250000  0.750000            4
                       Other                0.625000  0.375000            8
                       Person               0.833333  0.166667            6
Other                  Date                 0.454545  0.545455           11
                       Number               0.500000  0.500000            4
                       Other                0.666667  0.333333            6
                       Person               0.285714  0.714286            7
Politics               Date                 0.714286  0.285714           14
                       Number               0.333333  0.666667            3
                       Other                0.714286  0.285714            7
                       Person               0.500000  0.500000            6
Science and technology Date                 0.454545  0.545455           22
                       Number               0.375000  0.625000            8
                       Other                0.500000  0.500000           10
                       Person               0.400000  0.600000           20
Sports                 Date                 0.500000  0.500000            4
                       Number               0.857143  0.142857            7
                       Other                0.500000  0.500000            8
                       Person               0.750000  0.250000            4

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  288
Model:                          Logit   Df Residuals:                      276
Method:                           MLE   Df Model:                           11
Date:                Sat, 23 Aug 2025   Pseudo R-squ.:                 0.01892
Time:                        11:35:44   Log-Likelihood:                -195.61
converged:                       True   LL-Null:                       -199.38
Covariance Type:            nonrobust   LLR p-value:                    0.7536
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -0.6294      1.541     -0.408      0.683      -3.650       2.391
C(topic_grouped)[T.Geography]                 -0.2016      0.503     -0.401      0.689      -1.188       0.785
C(topic_grouped)[T.Misc]                      -0.3724      0.415     -0.897      0.370      -1.186       0.441
C(topic_grouped)[T.Music]                     -0.3545      0.500     -0.709      0.479      -1.335       0.626
C(topic_grouped)[T.Other]                      0.0173      0.483      0.036      0.971      -0.930       0.964
C(topic_grouped)[T.Politics]                  -0.7224      0.486     -1.488      0.137      -1.674       0.229
C(topic_grouped)[T.Science and technology]     0.1028      0.394      0.261      0.794      -0.670       0.876
C(topic_grouped)[T.Sports]                    -0.7214      0.534     -1.352      0.176      -1.767       0.324
C(answer_type_grouped)[T.Number]              -0.1286      0.369     -0.349      0.727      -0.852       0.594
C(answer_type_grouped)[T.Other]               -0.2705      0.320     -0.845      0.398      -0.898       0.357
C(answer_type_grouped)[T.Person]              -0.0334      0.324     -0.103      0.918      -0.669       0.602
q_length                                       0.1900      0.329      0.577      0.564      -0.455       0.835
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.7503
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  287
Model:                          Logit   Df Residuals:                      274
Method:                           MLE   Df Model:                           12
Date:                Sat, 23 Aug 2025   Pseudo R-squ.:                 0.07771
Time:                        11:35:44   Log-Likelihood:                -183.20
converged:                       True   LL-Null:                       -198.64
Covariance Type:            nonrobust   LLR p-value:                  0.002061
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.6882      1.618     -1.044      0.297      -4.859       1.483
C(topic_grouped)[T.Geography]                 -0.3182      0.528     -0.603      0.547      -1.353       0.717
C(topic_grouped)[T.Misc]                      -0.5424      0.433     -1.252      0.210      -1.391       0.306
C(topic_grouped)[T.Music]                     -0.1372      0.527     -0.260      0.794      -1.170       0.895
C(topic_grouped)[T.Other]                      0.1141      0.509      0.224      0.823      -0.883       1.111
C(topic_grouped)[T.Politics]                  -0.7366      0.507     -1.452      0.146      -1.731       0.258
C(topic_grouped)[T.Science and technology]     0.2148      0.414      0.519      0.604      -0.597       1.026
C(topic_grouped)[T.Sports]                    -0.7545      0.557     -1.354      0.176      -1.847       0.338
C(answer_type_grouped)[T.Number]              -0.4525      0.394     -1.150      0.250      -1.224       0.319
C(answer_type_grouped)[T.Other]               -0.5988      0.346     -1.733      0.083      -1.276       0.078
C(answer_type_grouped)[T.Person]              -0.4386      0.348     -1.259      0.208      -1.121       0.244
q_length                                      -0.0158      0.344     -0.046      0.963      -0.690       0.658
capabilities_entropy                           2.9114      0.650      4.477      0.000       1.637       4.186
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  288
Model:                          Logit   Df Residuals:                      275
Method:                           MLE   Df Model:                           12
Date:                Sat, 23 Aug 2025   Pseudo R-squ.:                 0.07332
Time:                        11:35:44   Log-Likelihood:                -184.76
converged:                       True   LL-Null:                       -199.38
Covariance Type:            nonrobust   LLR p-value:                  0.003635
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.9244      1.617     -1.190      0.234      -5.094       1.245
C(topic_grouped)[T.Geography]                 -0.2306      0.523     -0.441      0.659      -1.255       0.794
C(topic_grouped)[T.Misc]                      -0.4028      0.430     -0.936      0.349      -1.246       0.441
C(topic_grouped)[T.Music]                     -0.3405      0.521     -0.654      0.513      -1.361       0.680
C(topic_grouped)[T.Other]                      0.0021      0.505      0.004      0.997      -0.989       0.993
C(topic_grouped)[T.Politics]                  -0.7774      0.504     -1.542      0.123      -1.766       0.211
C(topic_grouped)[T.Science and technology]     0.2371      0.412      0.576      0.565      -0.570       1.044
C(topic_grouped)[T.Sports]                    -0.7038      0.555     -1.269      0.205      -1.791       0.384
C(answer_type_grouped)[T.Number]              -0.5849      0.395     -1.483      0.138      -1.358       0.188
C(answer_type_grouped)[T.Other]               -0.5181      0.339     -1.527      0.127      -1.183       0.147
C(answer_type_grouped)[T.Person]              -0.1591      0.340     -0.468      0.640      -0.825       0.507
q_length                                       0.2253      0.339      0.664      0.507      -0.440       0.891
game_entropy                                   2.0602      0.465      4.435      0.000       1.150       2.971
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  287
Model:                          Logit   Df Residuals:                      273
Method:                           MLE   Df Model:                           13
Date:                Sat, 23 Aug 2025   Pseudo R-squ.:                 0.09346
Time:                        11:35:44   Log-Likelihood:                -180.07
converged:                       True   LL-Null:                       -198.64
Covariance Type:            nonrobust   LLR p-value:                 0.0003956
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -2.2253      1.647     -1.352      0.177      -5.452       1.002
C(topic_grouped)[T.Geography]                 -0.2887      0.533     -0.541      0.588      -1.334       0.757
C(topic_grouped)[T.Misc]                      -0.4965      0.438     -1.134      0.257      -1.355       0.362
C(topic_grouped)[T.Music]                     -0.1785      0.533     -0.335      0.738      -1.224       0.867
C(topic_grouped)[T.Other]                      0.0878      0.518      0.169      0.865      -0.928       1.103
C(topic_grouped)[T.Politics]                  -0.7422      0.511     -1.452      0.146      -1.744       0.259
C(topic_grouped)[T.Science and technology]     0.2817      0.420      0.671      0.502      -0.541       1.105
C(topic_grouped)[T.Sports]                    -0.7221      0.564     -1.280      0.200      -1.828       0.383
C(answer_type_grouped)[T.Number]              -0.6529      0.404     -1.615      0.106      -1.445       0.139
C(answer_type_grouped)[T.Other]               -0.6673      0.352     -1.896      0.058      -1.357       0.023
C(answer_type_grouped)[T.Person]              -0.4068      0.354     -1.150      0.250      -1.100       0.287
q_length                                       0.0726      0.348      0.209      0.835      -0.610       0.755
capabilities_entropy                           2.0491      0.731      2.804      0.005       0.617       3.481
game_entropy                                   1.3012      0.527      2.469      0.014       0.268       2.334
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing grok-3-latest (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/grok-3-latest_SimpleQA_redacted_cor_temp0.0_1754572688_game_data_evaluated.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    137
1     16
Name: count, dtype: int64

Answer change%: 0.1046 [0.056087504068492236, 0.15306282272889338] (n=153)
P-value vs 25%: 4.144e-09; P-value vs 0%: 2.367e-05
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=16)
P-value vs 25%: 0; P-value vs 33%: 0

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  153
Model:                          Logit   Df Residuals:                      151
Method:                           MLE   Df Model:                            1
Date:                Sat, 23 Aug 2025   Pseudo R-squ.:                 0.06886
Time:                        11:35:44   Log-Likelihood:                -47.729
converged:                       True   LL-Null:                       -51.258
Covariance Type:            nonrobust   LLR p-value:                  0.007887
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept         -0.5500      0.591     -0.930      0.352      -1.709       0.609
p_i_capability    -2.2389      0.821     -2.726      0.006      -3.849      -0.629
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  153
Model:                          Logit   Df Residuals:                      151
Method:                           MLE   Df Model:                            1
Date:                Sat, 23 Aug 2025   Pseudo R-squ.:                 0.06886
Time:                        11:35:44   Log-Likelihood:                -47.729
converged:                       True   LL-Null:                       -51.258
Covariance Type:            nonrobust   LLR p-value:                  0.007887
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.7890      0.402     -6.932      0.000      -3.578      -2.000
capabilities_entropy     2.2389      0.821      2.726      0.006       0.629       3.849
========================================================================================

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  153
Model:                          Logit   Df Residuals:                      151
Method:                           MLE   Df Model:                            1
Date:                Sat, 23 Aug 2025   Pseudo R-squ.:                 0.05465
Time:                        11:35:44   Log-Likelihood:                -48.457
converged:                       True   LL-Null:                       -51.258
Covariance Type:            nonrobust   LLR p-value:                   0.01793
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -2.6382      0.367     -7.188      0.000      -3.357      -1.919
game_entropy     2.9272      1.196      2.447      0.014       0.582       5.272
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=3798.00, p=0.000209
Paired t-test (game_entropy vs capabilities_entropy): statistic=-4.09, p=6.99e-05
Mean capabilities_entropy-game_entropy = 0.0869  [0.0452, 0.1285] (n=153)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  153
Model:                          Logit   Df Residuals:                      150
Method:                           MLE   Df Model:                            2
Date:                Sat, 23 Aug 2025   Pseudo R-squ.:                 0.09287
Time:                        11:35:44   Log-Likelihood:                -46.498
converged:                       True   LL-Null:                       -51.258
Covariance Type:            nonrobust   LLR p-value:                  0.008562
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -3.0270      0.450     -6.723      0.000      -3.909      -2.144
capabilities_entropy     1.8096      0.888      2.038      0.042       0.069       3.550
game_entropy             2.1022      1.284      1.638      0.102      -0.414       4.618
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['Science and technology', 'Politics', 'Other', 'Art', 'Geography', 'Sports', 'Music', 'Video games', 'TV shows', 'History']
                  Grouped rare answer_type into 'Misc'/'Other': ['Person', 'Other', 'Number', 'Place']
topic_grouped  answer_changed
Misc           0                 0.895425
               1                 0.104575
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.954545
                     1                 0.045455
Misc                 0                 0.871560
                     1                 0.128440
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                            0         1  total_count
topic_grouped answer_type_grouped                                 
Misc          Date                 0.954545  0.045455           44
              Misc                 0.871560  0.128440          109

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  153
Model:                          Logit   Df Residuals:                      150
Method:                           MLE   Df Model:                            2
Date:                Sat, 23 Aug 2025   Pseudo R-squ.:                 0.04544
Time:                        11:35:44   Log-Likelihood:                -48.929
converged:                       True   LL-Null:                       -51.258
Covariance Type:            nonrobust   LLR p-value:                   0.09736
==================================================================================================
                                     coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------
Intercept                          1.8497      3.599      0.514      0.607      -5.203       8.903
C(answer_type_grouped)[T.Misc]     1.1230      0.781      1.438      0.150      -0.408       2.654
q_length                          -1.1037      0.804     -1.373      0.170      -2.680       0.472
==================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.2144
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  153
Model:                          Logit   Df Residuals:                      149
Method:                           MLE   Df Model:                            3
Date:                Sat, 23 Aug 2025   Pseudo R-squ.:                  0.1094
Time:                        11:35:44   Log-Likelihood:                -45.650
converged:                       True   LL-Null:                       -51.258
Covariance Type:            nonrobust   LLR p-value:                   0.01061
==================================================================================================
                                     coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------
Intercept                          2.8732      3.908      0.735      0.462      -4.787      10.533
C(answer_type_grouped)[T.Misc]     0.8033      0.803      1.001      0.317      -0.770       2.377
q_length                          -1.4217      0.884     -1.608      0.108      -3.155       0.312
capabilities_entropy               2.2192      0.858      2.588      0.010       0.538       3.900
==================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  153
Model:                          Logit   Df Residuals:                      149
Method:                           MLE   Df Model:                            3
Date:                Sat, 23 Aug 2025   Pseudo R-squ.:                  0.1159
Time:                        11:35:44   Log-Likelihood:                -45.315
converged:                       True   LL-Null:                       -51.258
Covariance Type:            nonrobust   LLR p-value:                  0.007786
==================================================================================================
                                     coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------
Intercept                          4.1016      3.940      1.041      0.298      -3.620      11.824
C(answer_type_grouped)[T.Misc]     0.9970      0.796      1.253      0.210      -0.562       2.556
q_length                          -1.7354      0.904     -1.919      0.055      -3.508       0.037
game_entropy                       3.7165      1.371      2.711      0.007       1.030       6.403
==================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  153
Model:                          Logit   Df Residuals:                      148
Method:                           MLE   Df Model:                            4
Date:                Sat, 23 Aug 2025   Pseudo R-squ.:                  0.1545
Time:                        11:35:44   Log-Likelihood:                -43.337
converged:                       True   LL-Null:                       -51.258
Covariance Type:            nonrobust   LLR p-value:                  0.003238
==================================================================================================
                                     coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------
Intercept                          4.9711      4.159      1.195      0.232      -3.181      13.123
C(answer_type_grouped)[T.Misc]     0.7891      0.813      0.970      0.332      -0.805       2.383
q_length                          -1.9999      0.965     -2.073      0.038      -3.891      -0.109
capabilities_entropy               1.8433      0.912      2.020      0.043       0.055       3.632
game_entropy                       3.1914      1.434      2.226      0.026       0.381       6.002
==================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing grok-3-latest (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/grok-3-latest_SimpleQA_redacted_temp0.0_1754572366_game_data_evaluated.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    164
1    123
Name: count, dtype: int64

Answer change%: 0.4286 [0.371318233798006, 0.4858246233448511] (n=287)
P-value vs 25%: 9.772e-10; P-value vs 0%: 9.829e-49
Phase 2 self-accuracy: 0.0930 [0.04289909906250702, 0.14314741256539995] (n=129)
P-value vs 25%: 8.35e-10; P-value vs 33%: 6.375e-21

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  287
Model:                          Logit   Df Residuals:                      285
Method:                           MLE   Df Model:                            1
Date:                Sat, 23 Aug 2025   Pseudo R-squ.:                 0.08879
Time:                        11:35:44   Log-Likelihood:                -178.59
converged:                       True   LL-Null:                       -195.99
Covariance Type:            nonrobust   LLR p-value:                 3.645e-09
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          1.0364      0.265      3.915      0.000       0.518       1.555
p_i_capability    -2.4184      0.434     -5.566      0.000      -3.270      -1.567
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  287
Model:                          Logit   Df Residuals:                      285
Method:                           MLE   Df Model:                            1
Date:                Sat, 23 Aug 2025   Pseudo R-squ.:                 0.08879
Time:                        11:35:44   Log-Likelihood:                -178.59
converged:                       True   LL-Null:                       -195.99
Covariance Type:            nonrobust   LLR p-value:                 3.645e-09
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.3820      0.239     -5.789      0.000      -1.850      -0.914
capabilities_entropy     2.4184      0.434      5.566      0.000       1.567       3.270
========================================================================================

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  287
Model:                          Logit   Df Residuals:                      285
Method:                           MLE   Df Model:                            1
Date:                Sat, 23 Aug 2025   Pseudo R-squ.:                 0.09614
Time:                        11:35:44   Log-Likelihood:                -177.15
converged:                       True   LL-Null:                       -195.99
Covariance Type:            nonrobust   LLR p-value:                 8.304e-10
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.2229      0.208     -5.886      0.000      -1.630      -0.816
game_entropy     2.6987      0.470      5.739      0.000       1.777       3.620
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=12315.00, p=2.98e-09
Paired t-test (game_entropy vs capabilities_entropy): statistic=-5.79, p=1.87e-08
Mean capabilities_entropy-game_entropy = 0.0997  [0.0660, 0.1335] (n=287)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  287
Model:                          Logit   Df Residuals:                      284
Method:                           MLE   Df Model:                            2
Date:                Sat, 23 Aug 2025   Pseudo R-squ.:                  0.1238
Time:                        11:35:44   Log-Likelihood:                -171.73
converged:                       True   LL-Null:                       -195.99
Covariance Type:            nonrobust   LLR p-value:                 2.888e-11
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.6687      0.260     -6.422      0.000      -2.178      -1.159
capabilities_entropy     1.5916      0.489      3.252      0.001       0.632       2.551
game_entropy             1.9087      0.526      3.632      0.000       0.879       2.939
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['Geography', 'Sports', 'Other', 'Music', 'TV shows', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Number', 'Place']
topic_grouped           answer_changed
Art                     0                 0.640000
                        1                 0.360000
Misc                    0                 0.535714
                        1                 0.464286
Politics                0                 0.625000
                        1                 0.375000
Science and technology  0                 0.561404
                        1                 0.438596
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.587629
                     1                 0.412371
Misc                 0                 0.550000
                     1                 0.450000
Other                0                 0.629630
                     1                 0.370370
Person               0                 0.526316
                     1                 0.473684
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.666667  0.333333           15
                       Misc                 0.200000  0.800000            5
                       Other                0.857143  0.142857            7
                       Person               0.652174  0.347826           23
Misc                   Date                 0.521739  0.478261           46
                       Misc                 0.578947  0.421053           38
                       Other                0.562500  0.437500           32
                       Person               0.458333  0.541667           24
Politics               Date                 0.647059  0.352941           17
                       Misc                 0.571429  0.428571            7
                       Other                0.500000  0.500000            6
                       Person               0.700000  0.300000           10
Science and technology Date                 0.631579  0.368421           19
                       Misc                 0.600000  0.400000           10
                       Other                0.777778  0.222222            9
                       Person               0.368421  0.631579           19

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  287
Model:                          Logit   Df Residuals:                      279
Method:                           MLE   Df Model:                            7
Date:                Sat, 23 Aug 2025   Pseudo R-squ.:                 0.01194
Time:                        11:35:44   Log-Likelihood:                -193.65
converged:                       True   LL-Null:                       -195.99
Covariance Type:            nonrobust   LLR p-value:                    0.6990
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -0.0546      1.502     -0.036      0.971      -2.998       2.888
C(topic_grouped)[T.Misc]                       0.5248      0.355      1.480      0.139      -0.170       1.220
C(topic_grouped)[T.Politics]                   0.1421      0.447      0.318      0.751      -0.734       1.018
C(topic_grouped)[T.Science and technology]     0.3752      0.402      0.934      0.350      -0.412       1.163
C(answer_type_grouped)[T.Misc]                 0.0966      0.336      0.288      0.774      -0.562       0.755
C(answer_type_grouped)[T.Other]               -0.2348      0.354     -0.664      0.507      -0.928       0.458
C(answer_type_grouped)[T.Person]               0.3048      0.318      0.957      0.339      -0.319       0.929
q_length                                      -0.1426      0.319     -0.447      0.655      -0.768       0.483
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.4379
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  287
Model:                          Logit   Df Residuals:                      278
Method:                           MLE   Df Model:                            8
Date:                Sat, 23 Aug 2025   Pseudo R-squ.:                  0.1013
Time:                        11:35:44   Log-Likelihood:                -176.14
converged:                       True   LL-Null:                       -195.99
Covariance Type:            nonrobust   LLR p-value:                 3.631e-06
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -0.6495      1.601     -0.406      0.685      -3.787       2.488
C(topic_grouped)[T.Misc]                       0.4881      0.379      1.287      0.198      -0.255       1.231
C(topic_grouped)[T.Politics]                   0.3482      0.476      0.732      0.464      -0.584       1.280
C(topic_grouped)[T.Science and technology]     0.4224      0.430      0.981      0.326      -0.421       1.266
C(answer_type_grouped)[T.Misc]                -0.0448      0.356     -0.126      0.900      -0.743       0.654
C(answer_type_grouped)[T.Other]               -0.5763      0.383     -1.504      0.133      -1.327       0.175
C(answer_type_grouped)[T.Person]               0.0700      0.344      0.204      0.839      -0.604       0.744
q_length                                      -0.2311      0.340     -0.681      0.496      -0.897       0.434
capabilities_entropy                           2.4995      0.449      5.572      0.000       1.620       3.379
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  287
Model:                          Logit   Df Residuals:                      278
Method:                           MLE   Df Model:                            8
Date:                Sat, 23 Aug 2025   Pseudo R-squ.:                  0.1072
Time:                        11:35:44   Log-Likelihood:                -174.99
converged:                       True   LL-Null:                       -195.99
Covariance Type:            nonrobust   LLR p-value:                 1.347e-06
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -0.1036      1.599     -0.065      0.948      -3.237       3.030
C(topic_grouped)[T.Misc]                       0.4678      0.383      1.222      0.222      -0.282       1.218
C(topic_grouped)[T.Politics]                   0.3400      0.478      0.711      0.477      -0.597       1.277
C(topic_grouped)[T.Science and technology]     0.4899      0.432      1.134      0.257      -0.357       1.337
C(answer_type_grouped)[T.Misc]                 0.1434      0.356      0.403      0.687      -0.553       0.840
C(answer_type_grouped)[T.Other]               -0.3678      0.383     -0.960      0.337      -1.119       0.383
C(answer_type_grouped)[T.Person]               0.1074      0.344      0.312      0.755      -0.567       0.782
q_length                                      -0.3323      0.343     -0.970      0.332      -1.004       0.339
game_entropy                                   2.7458      0.480      5.718      0.000       1.805       3.687
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  287
Model:                          Logit   Df Residuals:                      277
Method:                           MLE   Df Model:                            9
Date:                Sat, 23 Aug 2025   Pseudo R-squ.:                  0.1368
Time:                        11:35:44   Log-Likelihood:                -169.19
converged:                       True   LL-Null:                       -195.99
Covariance Type:            nonrobust   LLR p-value:                 2.230e-08
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -0.4442      1.631     -0.272      0.785      -3.640       2.752
C(topic_grouped)[T.Misc]                       0.4774      0.390      1.224      0.221      -0.287       1.242
C(topic_grouped)[T.Politics]                   0.4421      0.489      0.904      0.366      -0.516       1.400
C(topic_grouped)[T.Science and technology]     0.5009      0.443      1.131      0.258      -0.367       1.369
C(answer_type_grouped)[T.Misc]                 0.0489      0.364      0.135      0.893      -0.664       0.762
C(answer_type_grouped)[T.Other]               -0.5510      0.395     -1.395      0.163      -1.325       0.223
C(answer_type_grouped)[T.Person]               0.0055      0.355      0.015      0.988      -0.690       0.701
q_length                                      -0.3512      0.349     -1.008      0.314      -1.034       0.332
capabilities_entropy                           1.6850      0.502      3.359      0.001       0.702       2.668
game_entropy                                   1.9486      0.533      3.656      0.000       0.904       2.993
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.
