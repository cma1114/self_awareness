
--- Analyzing claude-3-5-sonnet-20241022 (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_new/claude-3-5-sonnet-20241022_GPQA_redacted_cor_temp0.0_1753836130_game_data.json', './sc_logs_new/claude-3-5-sonnet-20241022_GPQA_redacted_temp0.0_1753884209_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    324
1    123
Name: count, dtype: int64

Answer change%: 0.2752 [0.23376668647873367, 0.316568883991065] (n=447)
P-value vs 25%: 0.2335; P-value vs 0%: 8.628e-39
Phase 2 self-accuracy: 0.2602 [0.1826296872038196, 0.33769551604821296] (n=123)
P-value vs 25%: 0.7973; P-value vs 33%: 0.06558

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.2050
Time:                        16:14:02   Log-Likelihood:                -209.06
converged:                       True   LL-Null:                       -262.98
Covariance Type:            nonrobust   LLR p-value:                 2.913e-25
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          2.8057      0.404      6.950      0.000       2.015       3.597
p_i_capability    -5.5970      0.612     -9.151      0.000      -6.796      -4.398
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.2096
Time:                        16:14:02   Log-Likelihood:                -207.86
converged:                       True   LL-Null:                       -262.98
Covariance Type:            nonrobust   LLR p-value:                 8.630e-26
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -3.4591      0.331    -10.443      0.000      -4.108      -2.810
capabilities_entropy     2.1974      0.243      9.037      0.000       1.721       2.674
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.6341 [0.5490, 0.7193] (n=123)
                  P-value vs 33.3%: 4.32e-12

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=-3.78, p=0.000185
Wilcoxon delta_p: statistic=9139.00, p=2.8e-05
Mean Δp = -0.0325  [-0.0494, -0.0157]
Idea 1 N = 324; 

  Idea 1.5: Calibration Metrics
  NLL: 1.6241, Signed ECE (overconf pos under neg): -0.0105, ECE: 0.1124 (n=447)
  Brier: 0.0494, Reliability (absolute calibration error; lower better): 0.0241, Resolution (relative calibration quality; higher better): 0.2211, Uncertainty: 0.2459 (n=447)
  AUROC: 0.9959

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.696
Model:                            OLS   Adj. R-squared:                  0.694
Method:                 Least Squares   F-statistic:                     338.1
Date:                Wed, 24 Sep 2025   Prob (F-statistic):          4.00e-114
Time:                        16:14:02   Log-Likelihood:                 267.93
No. Observations:                 447   AIC:                            -527.9
Df Residuals:                     443   BIC:                            -511.4
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.3523      0.031    -11.506      0.000      -0.412      -0.292
p1                    0.4044      0.038     10.764      0.000       0.331       0.478
answer_changed        0.1134      0.052      2.175      0.030       0.011       0.216
p1:answer_changed     0.6334      0.082      7.752      0.000       0.473       0.794
==============================================================================
Omnibus:                       25.809   Durbin-Watson:                   2.026
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               30.060
Skew:                           0.542   Prob(JB):                     2.97e-07
Kurtosis:                       3.664   Cond. No.                         20.2
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=0.29, p=0.77
Wilcoxon delta_H: statistic=13407.50, p=0.829
Mean ΔH = 0.0071  [-0.0403, 0.0545]
Paired t-test delta_H Changed: statistic=9.44, p=3.28e-16
Wilcoxon delta_H Changed: statistic=737.00, p=8.24e-15
Mean ΔH Changed = 0.3288  [0.2605, 0.3971]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=5.95, p=5.51e-09
Wilcoxon (p_top2_game vs p_top2_base): statistic=20658.50, p=1.07e-08
Mean Δp_top2 = 0.0232  [0.0155, 0.0308] (n=447)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=4.54, p=7.39e-06
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=22645.50, p=2.64e-06
Mean ΔH_unchosen_baseline_set = 0.0956  [0.0543, 0.1369] (n=447)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      444
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.2294
Time:                        16:14:02   Log-Likelihood:                -202.67
converged:                       True   LL-Null:                       -262.98
Covariance Type:            nonrobust   LLR p-value:                 6.380e-27
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.8792      0.173     -5.068      0.000      -1.219      -0.539
p1_z            -1.6293      0.202     -8.068      0.000      -2.025      -1.233
I(p1_z ** 2)    -0.5733      0.165     -3.483      0.000      -0.896      -0.251
================================================================================
AUC = 0.805

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1888
Time:                        16:14:02   Log-Likelihood:                -213.33
converged:                       True   LL-Null:                       -262.98
Covariance Type:            nonrobust   LLR p-value:                 2.159e-23
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -3.0396      0.283    -10.742      0.000      -3.594      -2.485
game_entropy     2.0871      0.233      8.944      0.000       1.630       2.544
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=19918.50, p=1.06e-09
Paired t-test (game_entropy vs capabilities_entropy): statistic=-6.15, p=1.71e-09
Mean game_entropy-capabilities_entropy = -0.1118  [-0.1475, -0.0762] (n=447)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      444
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.2295
Time:                        16:14:02   Log-Likelihood:                -202.62
converged:                       True   LL-Null:                       -262.98
Covariance Type:            nonrobust   LLR p-value:                 6.073e-27
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -3.6616      0.343    -10.681      0.000      -4.333      -2.990
capabilities_entropy     1.4754      0.325      4.533      0.000       0.837       2.113
game_entropy             1.0243      0.320      3.204      0.001       0.398       1.651
========================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:               0.0009190
Time:                        16:14:02   Log-Likelihood:                -262.74
converged:                       True   LL-Null:                       -262.98
Covariance Type:            nonrobust   LLR p-value:                    0.4869
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -0.6637      0.450     -1.473      0.141      -1.547       0.219
human_difficulty    -0.1291      0.186     -0.693      0.488      -0.494       0.236
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      440
Method:                           MLE   Df Model:                            6
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.03029
Time:                        16:14:02   Log-Likelihood:                -255.02
converged:                       True   LL-Null:                       -262.98
Covariance Type:            nonrobust   LLR p-value:                   0.01413
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                             0.1836      1.685      0.109      0.913      -3.119       3.486
C(domain_grouped)[T.chemistry]        0.8987      0.396      2.267      0.023       0.122       1.676
C(domain_grouped)[T.physics]          0.8852      0.398      2.225      0.026       0.105       1.665
human_difficulty                      0.0176      0.193      0.092      0.927      -0.360       0.395
q_length                             -0.0294      0.180     -0.163      0.870      -0.382       0.323
avg_word_length                      -0.3730      0.204     -1.830      0.067      -0.772       0.026
percent_non_alphabetic_whitespace    -0.0110      0.020     -0.550      0.582      -0.050       0.028
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 0.9810
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      439
Method:                           MLE   Df Model:                            7
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.2199
Time:                        16:14:02   Log-Likelihood:                -205.17
converged:                       True   LL-Null:                       -262.98
Covariance Type:            nonrobust   LLR p-value:                 6.202e-22
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -2.9717      1.922     -1.546      0.122      -6.739       0.796
C(domain_grouped)[T.chemistry]       -0.0246      0.456     -0.054      0.957      -0.919       0.869
C(domain_grouped)[T.physics]          0.4377      0.459      0.953      0.340      -0.462       1.337
human_difficulty                      0.0270      0.221      0.122      0.903      -0.406       0.460
q_length                             -0.1574      0.208     -0.758      0.449      -0.565       0.250
avg_word_length                      -0.0059      0.223     -0.027      0.979      -0.443       0.431
percent_non_alphabetic_whitespace     0.0206      0.023      0.915      0.360      -0.024       0.065
capabilities_entropy                  2.2264      0.257      8.670      0.000       1.723       2.730
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      439
Method:                           MLE   Df Model:                            7
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1979
Time:                        16:14:02   Log-Likelihood:                -210.94
converged:                       True   LL-Null:                       -262.98
Covariance Type:            nonrobust   LLR p-value:                 1.547e-19
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -2.5689      1.894     -1.356      0.175      -6.281       1.144
C(domain_grouped)[T.chemistry]        0.0107      0.445      0.024      0.981      -0.862       0.883
C(domain_grouped)[T.physics]          0.4344      0.447      0.971      0.332      -0.442       1.311
human_difficulty                     -0.0108      0.220     -0.049      0.961      -0.442       0.420
q_length                             -0.1117      0.200     -0.557      0.577      -0.505       0.281
avg_word_length                      -0.0282      0.219     -0.129      0.898      -0.457       0.400
percent_non_alphabetic_whitespace     0.0164      0.022      0.751      0.453      -0.026       0.059
game_entropy                          2.0882      0.247      8.462      0.000       1.605       2.572
=====================================================================================================

                  Model 4.95: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      438
Method:                           MLE   Df Model:                            8
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.2399
Time:                        16:14:02   Log-Likelihood:                -199.90
converged:                       True   LL-Null:                       -262.98
Covariance Type:            nonrobust   LLR p-value:                 1.766e-23
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -3.3567      1.948     -1.723      0.085      -7.175       0.461
C(domain_grouped)[T.chemistry]       -0.2390      0.461     -0.519      0.604      -1.142       0.664
C(domain_grouped)[T.physics]          0.2988      0.460      0.650      0.516      -0.603       1.200
human_difficulty                      0.0056      0.226      0.025      0.980      -0.438       0.449
q_length                             -0.1497      0.210     -0.714      0.475      -0.560       0.261
avg_word_length                       0.0506      0.225      0.225      0.822      -0.391       0.492
percent_non_alphabetic_whitespace     0.0249      0.023      1.097      0.273      -0.020       0.069
capabilities_entropy                  1.5272      0.332      4.602      0.000       0.877       2.178
game_entropy                          1.0462      0.325      3.214      0.001       0.408       1.684
=====================================================================================================

--- Analyzing claude-3-haiku-20240307 (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_new/claude-3-haiku-20240307_GPQA_redacted_cor_temp0.0_1751757100_game_data.json', './sc_logs_new/claude-3-haiku-20240307_GPQA_redacted_temp0.0_1754158953_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    337
1     94
Name: count, dtype: int64

Answer change%: 0.2181 [0.1791112337366507, 0.25708366185499665] (n=431)
P-value vs 25%: 0.1087; P-value vs 0%: 5.663e-28
Phase 2 self-accuracy: 0.1596 [0.0855431493217682, 0.23360578684844457] (n=94)
P-value vs 25%: 0.01667; P-value vs 33%: 4.403e-06

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  431
Model:                          Logit   Df Residuals:                      429
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.06110
Time:                        16:14:02   Log-Likelihood:                -212.24
converged:                       True   LL-Null:                       -226.05
Covariance Type:            nonrobust   LLR p-value:                 1.474e-07
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          2.2976      0.675      3.402      0.001       0.974       3.621
p_i_capability    -4.0707      0.768     -5.299      0.000      -5.576      -2.565
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  431
Model:                          Logit   Df Residuals:                      429
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.07496
Time:                        16:14:03   Log-Likelihood:                -209.11
converged:                       True   LL-Null:                       -226.05
Covariance Type:            nonrobust   LLR p-value:                 5.835e-09
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.3394      0.230    -10.185      0.000      -2.790      -1.889
capabilities_entropy     2.1546      0.372      5.790      0.000       1.425       2.884
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.3511 [0.2546, 0.4476] (n=94)
                  P-value vs 33.3%: 0.7187

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=-0.11, p=0.916
Wilcoxon delta_p: statistic=1719.00, p=0.409
Mean Δp = -0.0009  [-0.0172, 0.0154]
Idea 1 N = 238; 

  Idea 1.5: Calibration Metrics
  NLL: 4.2117, Signed ECE (overconf pos under neg): 0.0400, ECE: 0.0400 (n=295)
  Brier: 0.0110, Reliability (absolute calibration error; lower better): 0.0108, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=295)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.896
Model:                            OLS   Adj. R-squared:                  0.894
Method:                 Least Squares   F-statistic:                     831.8
Date:                Wed, 24 Sep 2025   Prob (F-statistic):          2.27e-142
Time:                        16:14:03   Log-Likelihood:                 262.11
No. Observations:                 295   AIC:                            -516.2
Df Residuals:                     291   BIC:                            -501.5
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.7563      0.054    -13.998      0.000      -0.863      -0.650
p1                    0.8219      0.058     14.084      0.000       0.707       0.937
answer_changed        0.7436      0.078      9.484      0.000       0.589       0.898
p1:answer_changed     0.0617      0.091      0.676      0.500      -0.118       0.241
==============================================================================
Omnibus:                       64.875   Durbin-Watson:                   1.936
Prob(Omnibus):                  0.000   Jarque-Bera (JB):              199.051
Skew:                           0.954   Prob(JB):                     5.98e-44
Kurtosis:                       6.543   Cond. No.                         31.3
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=2.25, p=0.0253
Wilcoxon delta_H: statistic=1417.50, p=0.0356
Mean ΔH = 0.0856  [0.0111, 0.1601]
Paired t-test delta_H Changed: statistic=6.66, p=1.28e-08
Wilcoxon delta_H Changed: statistic=179.00, p=2.65e-07
Mean ΔH Changed = 0.5699  [0.4021, 0.7378]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=1.28, p=0.202
Wilcoxon (p_top2_game vs p_top2_base): statistic=3725.00, p=0.0575
Mean Δp_top2 = 0.0025  [-0.0013, 0.0063] (n=295)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=4.90, p=1.55e-06
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=2810.50, p=1.54e-06
Mean ΔH_unchosen_baseline_set = 0.1792  [0.1076, 0.2508] (n=295)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  295
Model:                          Logit   Df Residuals:                      292
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1285
Time:                        16:14:03   Log-Likelihood:                -126.20
converged:                       True   LL-Null:                       -144.80
Covariance Type:            nonrobust   LLR p-value:                 8.328e-09
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.2894      0.222     -5.802      0.000      -1.725      -0.854
p1_z            -1.4134      0.374     -3.778      0.000      -2.147      -0.680
I(p1_z ** 2)    -0.3189      0.167     -1.913      0.056      -0.646       0.008
================================================================================
AUC = 0.741

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  295
Model:                          Logit   Df Residuals:                      293
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.09078
Time:                        16:14:03   Log-Likelihood:                -131.66
converged:                       True   LL-Null:                       -144.80
Covariance Type:            nonrobust   LLR p-value:                 2.939e-07
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -2.7137      0.313     -8.680      0.000      -3.326      -2.101
game_entropy     2.5620      0.503      5.089      0.000       1.575       3.549
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=4529.00, p=0.893
Paired t-test (game_entropy vs capabilities_entropy): statistic=-0.16, p=0.873
Mean game_entropy-capabilities_entropy = -0.0033  [-0.0436, 0.0370] (n=295)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  295
Model:                          Logit   Df Residuals:                      292
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.2039
Time:                        16:14:03   Log-Likelihood:                -115.28
converged:                       True   LL-Null:                       -144.80
Covariance Type:            nonrobust   LLR p-value:                 1.501e-13
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -4.0098      0.441     -9.086      0.000      -4.875      -3.145
capabilities_entropy     2.7036      0.487      5.554      0.000       1.749       3.658
game_entropy             2.3242      0.538      4.319      0.000       1.270       3.379
========================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  431
Model:                          Logit   Df Residuals:                      429
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                0.004529
Time:                        16:14:03   Log-Likelihood:                -225.03
converged:                       True   LL-Null:                       -226.05
Covariance Type:            nonrobust   LLR p-value:                    0.1525
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -0.5818      0.498     -1.168      0.243      -1.558       0.395
human_difficulty    -0.2957      0.208     -1.418      0.156      -0.704       0.113
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None
                    Model 4: Using clustered standard errors by q_id.

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  431
Model:                          Logit   Df Residuals:                      424
Method:                           MLE   Df Model:                            6
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.01897
Time:                        16:14:03   Log-Likelihood:                -221.77
converged:                       True   LL-Null:                       -226.05
Covariance Type:              cluster   LLR p-value:                    0.1988
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -2.5983      1.702     -1.526      0.127      -5.935       0.739
C(domain_grouped)[T.chemistry]        0.9333      0.416      2.243      0.025       0.118       1.749
C(domain_grouped)[T.physics]          0.5637      0.419      1.345      0.179      -0.258       1.385
human_difficulty                     -0.2274      0.198     -1.148      0.251      -0.616       0.161
q_length                              0.1577      0.197      0.798      0.425      -0.229       0.545
avg_word_length                       0.0677      0.189      0.358      0.720      -0.303       0.438
percent_non_alphabetic_whitespace    -0.0041      0.025     -0.162      0.872      -0.053       0.045
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 0.4517
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  431
Model:                          Logit   Df Residuals:                      423
Method:                           MLE   Df Model:                            7
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.09177
Time:                        16:14:03   Log-Likelihood:                -205.31
converged:                       True   LL-Null:                       -226.05
Covariance Type:            nonrobust   LLR p-value:                 6.512e-07
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -3.9883      1.793     -2.225      0.026      -7.502      -0.474
C(domain_grouped)[T.chemistry]        0.9206      0.425      2.167      0.030       0.088       1.753
C(domain_grouped)[T.physics]          0.6108      0.442      1.382      0.167      -0.255       1.477
human_difficulty                     -0.1869      0.227     -0.824      0.410      -0.631       0.258
q_length                              0.0922      0.200      0.460      0.645      -0.300       0.485
avg_word_length                       0.2072      0.194      1.067      0.286      -0.173       0.588
percent_non_alphabetic_whitespace    -0.0109      0.023     -0.479      0.632      -0.056       0.034
capabilities_entropy                  2.1986      0.389      5.649      0.000       1.436       2.961
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  295
Model:                          Logit   Df Residuals:                      287
Method:                           MLE   Df Model:                            7
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1181
Time:                        16:14:03   Log-Likelihood:                -127.70
converged:                       True   LL-Null:                       -144.80
Covariance Type:            nonrobust   LLR p-value:                 1.571e-05
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -2.8860      2.463     -1.172      0.241      -7.713       1.941
C(domain_grouped)[T.chemistry]        0.6304      0.563      1.119      0.263      -0.474       1.735
C(domain_grouped)[T.physics]          0.1193      0.587      0.203      0.839      -1.031       1.269
human_difficulty                     -0.3807      0.298     -1.276      0.202      -0.965       0.204
q_length                              0.4127      0.261      1.581      0.114      -0.099       0.924
avg_word_length                      -0.3518      0.302     -1.166      0.244      -0.943       0.240
percent_non_alphabetic_whitespace    -0.0155      0.028     -0.555      0.579      -0.070       0.039
game_entropy                          2.5382      0.525      4.835      0.000       1.509       3.567
=====================================================================================================

                  Model 4.95: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  295
Model:                          Logit   Df Residuals:                      286
Method:                           MLE   Df Model:                            8
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.2209
Time:                        16:14:03   Log-Likelihood:                -112.82
converged:                       True   LL-Null:                       -144.80
Covariance Type:            nonrobust   LLR p-value:                 7.702e-11
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -4.3852      2.679     -1.637      0.102      -9.635       0.865
C(domain_grouped)[T.chemistry]        0.4202      0.599      0.701      0.483      -0.754       1.594
C(domain_grouped)[T.physics]          0.0378      0.629      0.060      0.952      -1.195       1.270
human_difficulty                     -0.4127      0.317     -1.302      0.193      -1.034       0.209
q_length                              0.3660      0.278      1.317      0.188      -0.179       0.911
avg_word_length                      -0.1907      0.323     -0.590      0.555      -0.824       0.442
percent_non_alphabetic_whitespace    -0.0181      0.029     -0.620      0.536      -0.075       0.039
capabilities_entropy                  2.6347      0.499      5.275      0.000       1.656       3.614
game_entropy                          2.3412      0.559      4.188      0.000       1.245       3.437
=====================================================================================================

--- Analyzing claude-3-sonnet-20240229 (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_new/claude-3-sonnet-20240229_GPQA_redacted_cor_temp0.0_1751757247_game_data.json', './sc_logs_new/claude-3-sonnet-20240229_GPQA_redacted_temp0.0_1751717405_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    330
1    117
Name: count, dtype: int64

Answer change%: 0.2617 [0.2209941131354173, 0.3024958197504888] (n=447)
P-value vs 25%: 0.5721; P-value vs 0%: 2.429e-36
Phase 2 self-accuracy: 0.2393 [0.16200487855195683, 0.3166276000805218] (n=117)
P-value vs 25%: 0.7865; P-value vs 33%: 0.01755

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:               2.631e-06
Time:                        16:14:03   Log-Likelihood:                -256.97
converged:                       True   LL-Null:                       -256.97
Covariance Type:            nonrobust   LLR p-value:                    0.9707
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -1.0205      0.458     -2.228      0.026      -1.918      -0.123
human_difficulty    -0.0069      0.188     -0.037      0.971      -0.375       0.361
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      440
Method:                           MLE   Df Model:                            6
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.01053
Time:                        16:14:03   Log-Likelihood:                -254.26
converged:                       True   LL-Null:                       -256.97
Covariance Type:            nonrobust   LLR p-value:                    0.4925
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -0.2722      1.631     -0.167      0.867      -3.469       2.925
C(domain_grouped)[T.chemistry]        0.6042      0.354      1.705      0.088      -0.090       1.299
C(domain_grouped)[T.physics]          0.3561      0.360      0.988      0.323      -0.350       1.063
human_difficulty                      0.0504      0.194      0.260      0.795      -0.330       0.431
q_length                              0.0065      0.177      0.036      0.971      -0.341       0.354
avg_word_length                      -0.2332      0.191     -1.218      0.223      -0.608       0.142
percent_non_alphabetic_whitespace    -0.0304      0.021     -1.439      0.150      -0.072       0.011
=====================================================================================================

--- Analyzing claude-sonnet-4-20250514 (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_new/claude-sonnet-4-20250514_GPQA_redacted_cor_temp0.0_1751759117_game_data.json', './sc_logs_new/claude-sonnet-4-20250514_GPQA_redacted_temp0.0_1751718415_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    302
1    145
Name: count, dtype: int64

Answer change%: 0.3244 [0.2809863314563348, 0.36778324348773683] (n=447)
P-value vs 25%: 0.0007812; P-value vs 0%: 1.349e-48
Phase 2 self-accuracy: 0.3034 [0.22861700639943466, 0.37827954532470326] (n=145)
P-value vs 25%: 0.1615; P-value vs 33%: 0.4389

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                0.001427
Time:                        16:14:03   Log-Likelihood:                -281.27
converged:                       True   LL-Null:                       -281.67
Covariance Type:            nonrobust   LLR p-value:                    0.3699
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -0.3584      0.430     -0.833      0.405      -1.202       0.485
human_difficulty    -0.1589      0.178     -0.894      0.371      -0.507       0.190
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      440
Method:                           MLE   Df Model:                            6
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.01484
Time:                        16:14:03   Log-Likelihood:                -277.49
converged:                       True   LL-Null:                       -281.67
Covariance Type:            nonrobust   LLR p-value:                    0.2129
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -1.4790      1.499     -0.986      0.324      -4.418       1.460
C(domain_grouped)[T.chemistry]        0.5197      0.320      1.623      0.104      -0.108       1.147
C(domain_grouped)[T.physics]         -0.0058      0.331     -0.018      0.986      -0.654       0.642
human_difficulty                     -0.1558      0.186     -0.836      0.403      -0.521       0.210
q_length                              0.2446      0.169      1.449      0.147      -0.086       0.575
avg_word_length                      -0.0935      0.168     -0.556      0.579      -0.423       0.236
percent_non_alphabetic_whitespace    -0.0146      0.019     -0.759      0.448      -0.052       0.023
=====================================================================================================

--- Analyzing deepseek-chat (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_new/deepseek-chat_GPQA_redacted_cor_temp0.0_1753813587_game_data.json', './sc_logs_new/deepseek-chat_GPQA_redacted_temp0.0_1753995526_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    372
1     70
Name: count, dtype: int64

Answer change%: 0.1584 [0.1243353023278091, 0.1924067791201547] (n=442)
P-value vs 25%: 1.317e-07; P-value vs 0%: 7.521e-20
Phase 2 self-accuracy: 0.3521 [0.24101384534522574, 0.46321150676745027] (n=71)
P-value vs 25%: 0.07163; P-value vs 33%: 0.736

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  442
Model:                          Logit   Df Residuals:                      440
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.02324
Time:                        16:14:03   Log-Likelihood:                -188.65
converged:                       True   LL-Null:                       -193.14
Covariance Type:            nonrobust   LLR p-value:                  0.002733
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept         -0.1931      0.491     -0.393      0.694      -1.155       0.769
p_i_capability    -1.8982      0.628     -3.021      0.003      -3.129      -0.667
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  442
Model:                          Logit   Df Residuals:                      440
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.03471
Time:                        16:14:03   Log-Likelihood:                -186.43
converged:                       True   LL-Null:                       -193.14
Covariance Type:            nonrobust   LLR p-value:                 0.0002505
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.3103      0.238     -9.713      0.000      -2.777      -1.844
capabilities_entropy     0.8176      0.226      3.619      0.000       0.375       1.260
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.3000 [0.1926, 0.4074] (n=70)
                  P-value vs 33.3%: 0.5428

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=21.82, p=2.62e-68
Wilcoxon delta_p: statistic=5185.00, p=2.93e-45
Mean Δp = 0.5235  [0.4764, 0.5705]
Idea 1 N = 369; 

  Idea 1.5: Calibration Metrics
  NLL: 3.6864, Signed ECE (overconf pos under neg): -0.1617, ECE: 0.3741 (n=399)
  Brier: 0.3991, Reliability (absolute calibration error; lower better): 0.1686, Resolution (relative calibration quality; higher better): 0.0162, Uncertainty: 0.2449 (n=399)
  AUROC: 0.4180

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.192
Model:                            OLS   Adj. R-squared:                  0.187
Method:                 Least Squares   F-statistic:                     34.51
Date:                Wed, 24 Sep 2025   Prob (F-statistic):           5.00e-20
Time:                        16:14:03   Log-Likelihood:                -227.80
No. Observations:                 439   AIC:                             463.6
Df Residuals:                     435   BIC:                             479.9
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.2908      0.090     -3.218      0.001      -0.468      -0.113
p1                    0.9991      0.108      9.271      0.000       0.787       1.211
answer_changed       -0.0123      0.218     -0.056      0.955      -0.442       0.417
p1:answer_changed     0.0926      0.283      0.327      0.744      -0.463       0.648
==============================================================================
Omnibus:                      148.836   Durbin-Watson:                   2.038
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               83.713
Skew:                          -0.938   Prob(JB):                     6.64e-19
Kurtosis:                       1.971   Cond. No.                         24.1
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=8.12, p=7e-15
Wilcoxon delta_H: statistic=18367.00, p=3.71e-14
Mean ΔH = 0.3172  [0.2407, 0.3938]
Paired t-test delta_H Changed: statistic=5.39, p=9.29e-07
Wilcoxon delta_H Changed: statistic=416.00, p=2.22e-06
Mean ΔH Changed = 0.3789  [0.2411, 0.5167]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=9.07, p=4.12e-18
Wilcoxon (p_top2_game vs p_top2_base): statistic=35713.00, p=2.26e-06
Mean Δp_top2 = 0.0437  [0.0342, 0.0531] (n=439)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=9.43, p=2.39e-19
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=24556.00, p=1.85e-18
Mean ΔH_unchosen_baseline_set = 0.3270  [0.2591, 0.3950] (n=439)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  439
Model:                          Logit   Df Residuals:                      436
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.04192
Time:                        16:14:03   Log-Likelihood:                -184.54
converged:                       True   LL-Null:                       -192.62
Covariance Type:            nonrobust   LLR p-value:                 0.0003112
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.3401      0.187     -7.180      0.000      -1.706      -0.974
p1_z            -0.7221      0.188     -3.845      0.000      -1.090      -0.354
I(p1_z ** 2)    -0.4229      0.160     -2.640      0.008      -0.737      -0.109
================================================================================
AUC = 0.654

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  442
Model:                          Logit   Df Residuals:                      440
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.08544
Time:                        16:14:03   Log-Likelihood:                -176.63
converged:                       True   LL-Null:                       -193.14
Covariance Type:            nonrobust   LLR p-value:                 9.206e-09
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -2.9285      0.274    -10.704      0.000      -3.465      -2.392
game_entropy     2.6190      0.453      5.787      0.000       1.732       3.506
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=28731.00, p=5.27e-14
Paired t-test (game_entropy vs capabilities_entropy): statistic=-9.71, p=2.44e-20
Mean game_entropy-capabilities_entropy = -0.2602  [-0.3127, -0.2077] (n=442)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  442
Model:                          Logit   Df Residuals:                      439
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.09737
Time:                        16:14:03   Log-Likelihood:                -174.33
converged:                       True   LL-Null:                       -193.14
Covariance Type:            nonrobust   LLR p-value:                 6.806e-09
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -3.1930      0.311    -10.273      0.000      -3.802      -2.584
capabilities_entropy     0.5233      0.243      2.149      0.032       0.046       1.001
game_entropy             2.3199      0.469      4.945      0.000       1.400       3.239
========================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  442
Model:                          Logit   Df Residuals:                      440
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.01104
Time:                        16:14:03   Log-Likelihood:                -191.00
converged:                       True   LL-Null:                       -193.14
Covariance Type:            nonrobust   LLR p-value:                   0.03896
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -0.5536      0.554     -0.999      0.318      -1.640       0.533
human_difficulty    -0.4823      0.238     -2.027      0.043      -0.949      -0.016
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  442
Model:                          Logit   Df Residuals:                      435
Method:                           MLE   Df Model:                            6
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.03793
Time:                        16:14:03   Log-Likelihood:                -185.81
converged:                       True   LL-Null:                       -193.14
Covariance Type:            nonrobust   LLR p-value:                   0.02314
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -1.6767      1.936     -0.866      0.387      -5.472       2.118
C(domain_grouped)[T.chemistry]        0.7517      0.420      1.789      0.074      -0.072       1.575
C(domain_grouped)[T.physics]          0.0894      0.450      0.198      0.843      -0.793       0.972
human_difficulty                     -0.5311      0.250     -2.122      0.034      -1.022      -0.041
q_length                              0.1776      0.220      0.807      0.419      -0.254       0.609
avg_word_length                       0.0404      0.213      0.189      0.850      -0.377       0.458
percent_non_alphabetic_whitespace    -0.0474      0.028     -1.697      0.090      -0.102       0.007
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 0.6891
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  442
Model:                          Logit   Df Residuals:                      434
Method:                           MLE   Df Model:                            7
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.07088
Time:                        16:14:03   Log-Likelihood:                -179.45
converged:                       True   LL-Null:                       -193.14
Covariance Type:            nonrobust   LLR p-value:                 0.0002846
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -1.5011      1.928     -0.779      0.436      -5.279       2.277
C(domain_grouped)[T.chemistry]        0.4738      0.437      1.085      0.278      -0.382       1.330
C(domain_grouped)[T.physics]         -0.1005      0.468     -0.215      0.830      -1.018       0.817
human_difficulty                     -0.5667      0.256     -2.212      0.027      -1.069      -0.065
q_length                              0.0905      0.222      0.408      0.684      -0.345       0.526
avg_word_length                       0.0444      0.209      0.213      0.831      -0.364       0.453
percent_non_alphabetic_whitespace    -0.0551      0.029     -1.929      0.054      -0.111       0.001
capabilities_entropy                  0.8459      0.240      3.522      0.000       0.375       1.317
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  442
Model:                          Logit   Df Residuals:                      434
Method:                           MLE   Df Model:                            7
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1159
Time:                        16:14:03   Log-Likelihood:                -170.75
converged:                       True   LL-Null:                       -193.14
Covariance Type:            nonrobust   LLR p-value:                 1.509e-07
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -2.0860      1.963     -1.062      0.288      -5.934       1.762
C(domain_grouped)[T.chemistry]        0.3535      0.441      0.802      0.422      -0.510       1.217
C(domain_grouped)[T.physics]         -0.2294      0.470     -0.488      0.626      -1.151       0.693
human_difficulty                     -0.5689      0.263     -2.161      0.031      -1.085      -0.053
q_length                              0.0777      0.232      0.335      0.738      -0.377       0.533
avg_word_length                       0.0687      0.210      0.328      0.743      -0.342       0.480
percent_non_alphabetic_whitespace    -0.0458      0.029     -1.553      0.120      -0.103       0.012
game_entropy                          2.5880      0.472      5.483      0.000       1.663       3.513
=====================================================================================================

                  Model 4.95: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  442
Model:                          Logit   Df Residuals:                      433
Method:                           MLE   Df Model:                            8
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1286
Time:                        16:14:03   Log-Likelihood:                -168.30
converged:                       True   LL-Null:                       -193.14
Covariance Type:            nonrobust   LLR p-value:                 4.723e-08
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -1.8536      1.976     -0.938      0.348      -5.727       2.019
C(domain_grouped)[T.chemistry]        0.2098      0.450      0.466      0.641      -0.672       1.092
C(domain_grouped)[T.physics]         -0.3512      0.482     -0.728      0.467      -1.297       0.594
human_difficulty                     -0.5805      0.267     -2.178      0.029      -1.103      -0.058
q_length                              0.0294      0.233      0.126      0.900      -0.428       0.487
avg_word_length                       0.0532      0.209      0.255      0.799      -0.356       0.462
percent_non_alphabetic_whitespace    -0.0504      0.030     -1.688      0.091      -0.109       0.008
capabilities_entropy                  0.5657      0.256      2.209      0.027       0.064       1.068
game_entropy                          2.2975      0.486      4.726      0.000       1.345       3.250
=====================================================================================================

--- Analyzing gemini-1.5-pro (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_new/gemini-1.5-pro_GPQA_redacted_cor_temp0.0_1751757449_game_data.json', './sc_logs_new/gemini-1.5-pro_GPQA_redacted_temp0.0_1751722268_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    369
1     78
Name: count, dtype: int64

Answer change%: 0.1745 [0.13931247588832357, 0.20968081270228045] (n=447)
P-value vs 25%: 2.6e-05; P-value vs 0%: 2.466e-22
Phase 2 self-accuracy: 0.3846 [0.27664927985302107, 0.4925814893777482] (n=78)
P-value vs 25%: 0.01454; P-value vs 33%: 0.3488

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:               0.0004983
Time:                        16:14:03   Log-Likelihood:                -206.83
converged:                       True   LL-Null:                       -206.94
Covariance Type:            nonrobust   LLR p-value:                    0.6497
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -1.7884      0.532     -3.360      0.001      -2.832      -0.745
human_difficulty     0.0984      0.216      0.455      0.649      -0.326       0.522
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      440
Method:                           MLE   Df Model:                            6
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                0.004551
Time:                        16:14:03   Log-Likelihood:                -205.99
converged:                       True   LL-Null:                       -206.94
Covariance Type:            nonrobust   LLR p-value:                    0.9301
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -0.9685      1.864     -0.520      0.603      -4.622       2.685
C(domain_grouped)[T.chemistry]        0.0932      0.389      0.240      0.811      -0.669       0.856
C(domain_grouped)[T.physics]         -0.0727      0.395     -0.184      0.854      -0.847       0.701
human_difficulty                      0.1193      0.225      0.531      0.595      -0.321       0.560
q_length                              0.0643      0.205      0.314      0.753      -0.337       0.466
avg_word_length                      -0.2482      0.220     -1.129      0.259      -0.679       0.183
percent_non_alphabetic_whitespace    -0.0143      0.024     -0.605      0.545      -0.061       0.032
=====================================================================================================

--- Analyzing gemini-2.0-flash-001 (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_new/gemini-2.0-flash-001_GPQA_redacted_cor_temp1.0_1757989025_game_data.json', './sc_logs_new/gemini-2.0-flash-001_GPQA_redacted_temp1.0_1757988130_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    326
1    121
Name: count, dtype: int64

Answer change%: 0.2707 [0.22950384429701254, 0.31188318031148854] (n=447)
P-value vs 25%: 0.3248; P-value vs 0%: 5.785e-38
Phase 2 self-accuracy: 0.2314 [0.15626161337460054, 0.3065483039807714] (n=121)
P-value vs 25%: 0.6277; P-value vs 33%: 0.008051

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.07685
Time:                        16:14:03   Log-Likelihood:                -240.97
converged:                       True   LL-Null:                       -261.02
Covariance Type:            nonrobust   LLR p-value:                 2.392e-10
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          3.7691      0.800      4.710      0.000       2.201       5.337
p_i_capability    -5.1306      0.856     -5.996      0.000      -6.808      -3.453
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1046
Time:                        16:14:03   Log-Likelihood:                -233.73
converged:                       True   LL-Null:                       -261.02
Covariance Type:            nonrobust   LLR p-value:                 1.480e-13
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.5220      0.140    -10.871      0.000      -1.796      -1.248
capabilities_entropy     2.0048      0.287      6.992      0.000       1.443       2.567
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.5000 [0.4057, 0.5943] (n=108)
                  P-value vs 33.3%: 0.000532

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=6.41, p=1.53e-09
Wilcoxon delta_p: statistic=2671.00, p=1.79e-11
Mean Δp = 0.0954  [0.0662, 0.1246]
Idea 1 N = 164; 

  Idea 1.5: Calibration Metrics
  NLL: 4.9030, Signed ECE (overconf pos under neg): -0.0274, ECE: 0.0410 (n=270)
  Brier: 0.0396, Reliability (absolute calibration error; lower better): 0.0087, Resolution (relative calibration quality; higher better): 0.2094, Uncertainty: 0.2414 (n=270)
  AUROC: 0.9914

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.698
Model:                            OLS   Adj. R-squared:                  0.694
Method:                 Least Squares   F-statistic:                     205.5
Date:                Wed, 24 Sep 2025   Prob (F-statistic):           4.58e-69
Time:                        16:14:03   Log-Likelihood:                 42.485
No. Observations:                 271   AIC:                            -76.97
Df Residuals:                     267   BIC:                            -62.56
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept             0.0966      0.117      0.822      0.412      -0.135       0.328
p1                   -0.0013      0.125     -0.010      0.992      -0.248       0.246
answer_changed       -0.8334      0.160     -5.202      0.000      -1.149      -0.518
p1:answer_changed     1.5975      0.176      9.071      0.000       1.251       1.944
==============================================================================
Omnibus:                        8.349   Durbin-Watson:                   2.038
Prob(Omnibus):                  0.015   Jarque-Bera (JB):               14.968
Skew:                           0.027   Prob(JB):                     0.000562
Kurtosis:                       4.150   Cond. No.                         31.8
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-2.98, p=0.00337
Wilcoxon delta_H: statistic=5133.00, p=0.00737
Mean ΔH = -0.1337  [-0.2218, -0.0456]
Paired t-test delta_H Changed: statistic=0.08, p=0.937
Wilcoxon delta_H Changed: statistic=2910.00, p=0.919
Mean ΔH Changed = 0.0045  [-0.1074, 0.1165]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=-6.83, p=5.71e-11
Wilcoxon (p_top2_game vs p_top2_base): statistic=6491.00, p=1.44e-20
Mean Δp_top2 = -0.0300  [-0.0386, -0.0214] (n=272)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=-2.22, p=0.0273
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=15923.00, p=0.042
Mean ΔH_unchosen_baseline_set = -0.0788  [-0.1484, -0.0092] (n=272)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  272
Model:                          Logit   Df Residuals:                      269
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.03684
Time:                        16:14:03   Log-Likelihood:                -176.00
converged:                       True   LL-Null:                       -182.73
Covariance Type:            nonrobust   LLR p-value:                  0.001192
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.2399      0.176     -1.360      0.174      -0.586       0.106
p1_z            -0.7216      0.239     -3.018      0.003      -1.190      -0.253
I(p1_z ** 2)    -0.1927      0.126     -1.530      0.126      -0.440       0.054
================================================================================
AUC = 0.660

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1610
Time:                        16:14:03   Log-Likelihood:                -219.01
converged:                       True   LL-Null:                       -261.02
Covariance Type:            nonrobust   LLR p-value:                 4.864e-20
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.9764      0.177    -11.175      0.000      -2.323      -1.630
game_entropy     1.8374      0.216      8.503      0.000       1.414       2.261
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=19287.00, p=2.01e-29
Paired t-test (game_entropy vs capabilities_entropy): statistic=9.44, p=2.02e-19
Mean game_entropy-capabilities_entropy = 0.2175  [0.1724, 0.2627] (n=447)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      444
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1883
Time:                        16:14:03   Log-Likelihood:                -211.88
converged:                       True   LL-Null:                       -261.02
Covariance Type:            nonrobust   LLR p-value:                 4.523e-22
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.1191      0.187    -11.347      0.000      -2.485      -1.753
capabilities_entropy     1.2168      0.324      3.753      0.000       0.581       1.852
game_entropy             1.5005      0.233      6.439      0.000       1.044       1.957
========================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:               0.0004758
Time:                        16:14:03   Log-Likelihood:                -260.90
converged:                       True   LL-Null:                       -261.02
Covariance Type:            nonrobust   LLR p-value:                    0.6182
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -0.7715      0.453     -1.704      0.088      -1.659       0.116
human_difficulty    -0.0929      0.187     -0.498      0.619      -0.459       0.273
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      440
Method:                           MLE   Df Model:                            6
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.02056
Time:                        16:14:03   Log-Likelihood:                -255.66
converged:                       True   LL-Null:                       -261.02
Covariance Type:            nonrobust   LLR p-value:                   0.09697
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -1.1406      1.656     -0.689      0.491      -4.386       2.105
C(domain_grouped)[T.chemistry]        0.8988      0.366      2.454      0.014       0.181       1.617
C(domain_grouped)[T.physics]          0.5167      0.374      1.383      0.167      -0.216       1.249
human_difficulty                     -0.0231      0.194     -0.119      0.905      -0.404       0.357
q_length                              0.1851      0.180      1.029      0.304      -0.168       0.538
avg_word_length                      -0.2770      0.195     -1.418      0.156      -0.660       0.106
percent_non_alphabetic_whitespace    -0.0267      0.021     -1.279      0.201      -0.068       0.014
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 0.2220
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      439
Method:                           MLE   Df Model:                            7
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1155
Time:                        16:14:03   Log-Likelihood:                -230.88
converged:                       True   LL-Null:                       -261.02
Covariance Type:            nonrobust   LLR p-value:                 1.320e-10
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -0.9894      1.753     -0.565      0.572      -4.424       2.446
C(domain_grouped)[T.chemistry]        0.6612      0.384      1.721      0.085      -0.092       1.414
C(domain_grouped)[T.physics]          0.3330      0.393      0.847      0.397      -0.438       1.104
human_difficulty                     -0.0441      0.209     -0.211      0.833      -0.454       0.366
q_length                              0.0517      0.192      0.270      0.787      -0.324       0.427
avg_word_length                      -0.1823      0.204     -0.895      0.371      -0.582       0.217
percent_non_alphabetic_whitespace    -0.0370      0.023     -1.632      0.103      -0.081       0.007
capabilities_entropy                  1.9681      0.295      6.669      0.000       1.390       2.546
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      439
Method:                           MLE   Df Model:                            7
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1677
Time:                        16:14:03   Log-Likelihood:                -217.24
converged:                       True   LL-Null:                       -261.02
Covariance Type:            nonrobust   LLR p-value:                 3.912e-16
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -2.2999      1.807     -1.273      0.203      -5.841       1.241
C(domain_grouped)[T.chemistry]        0.3148      0.397      0.793      0.428      -0.463       1.093
C(domain_grouped)[T.physics]         -0.0550      0.412     -0.134      0.894      -0.862       0.752
human_difficulty                     -0.1594      0.220     -0.724      0.469      -0.591       0.272
q_length                              0.1632      0.195      0.839      0.402      -0.218       0.545
avg_word_length                      -0.0474      0.205     -0.232      0.817      -0.448       0.354
percent_non_alphabetic_whitespace    -0.0195      0.023     -0.843      0.399      -0.065       0.026
game_entropy                          1.8451      0.228      8.101      0.000       1.399       2.291
=====================================================================================================

                  Model 4.95: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      438
Method:                           MLE   Df Model:                            8
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1950
Time:                        16:14:03   Log-Likelihood:                -210.13
converged:                       True   LL-Null:                       -261.02
Covariance Type:            nonrobust   LLR p-value:                 1.832e-18
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -1.9890      1.848     -1.076      0.282      -5.611       1.633
C(domain_grouped)[T.chemistry]        0.2543      0.400      0.636      0.525      -0.530       1.039
C(domain_grouped)[T.physics]         -0.0911      0.417     -0.218      0.827      -0.908       0.726
human_difficulty                     -0.1393      0.227     -0.615      0.539      -0.583       0.305
q_length                              0.0867      0.199      0.435      0.664      -0.304       0.478
avg_word_length                      -0.0360      0.208     -0.173      0.863      -0.444       0.372
percent_non_alphabetic_whitespace    -0.0280      0.024     -1.166      0.244      -0.075       0.019
capabilities_entropy                  1.2318      0.329      3.741      0.000       0.586       1.877
game_entropy                          1.5180      0.243      6.235      0.000       1.041       1.995
=====================================================================================================

--- Analyzing gemini-2.5-flash-lite_nothink (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_new/gemini-2.5-flash-lite_nothink_GPQA_redacted_cor_temp1.0_1757983987_game_data.json', './sc_logs_new/gemini-2.5-flash-lite_nothink_GPQA_redacted_temp1.0_1757983795_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    289
1    158
Name: count, dtype: int64

Answer change%: 0.3535 [0.30915118218300114, 0.39778394085950447] (n=447)
P-value vs 25%: 4.739e-06; P-value vs 0%: 4.361e-55
Phase 2 self-accuracy: 0.3544 [0.2798445097312725, 0.4290162497623984] (n=158)
P-value vs 25%: 0.006066; P-value vs 33%: 0.5733

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.06107
Time:                        16:14:03   Log-Likelihood:                -272.63
converged:                       True   LL-Null:                       -290.36
Covariance Type:            nonrobust   LLR p-value:                 2.600e-09
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          1.5461      0.379      4.075      0.000       0.802       2.290
p_i_capability    -2.8803      0.498     -5.779      0.000      -3.857      -1.904
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.07511
Time:                        16:14:03   Log-Likelihood:                -268.55
converged:                       True   LL-Null:                       -290.36
Covariance Type:            nonrobust   LLR p-value:                 3.995e-11
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.5985      0.197     -8.112      0.000      -1.985      -1.212
capabilities_entropy     1.1151      0.177      6.305      0.000       0.768       1.462
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.2722 [0.2028, 0.3415] (n=158)
                  P-value vs 33.3%: 0.084

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=17.40, p=8.71e-46
Wilcoxon delta_p: statistic=3111.00, p=1.26e-31
Mean Δp = 0.4707  [0.4177, 0.5238]
Idea 1 N = 267; 

  Idea 1.5: Calibration Metrics
  NLL: 3.3372, Signed ECE (overconf pos under neg): -0.1322, ECE: 0.3501 (n=445)
  Brier: 0.3722, Reliability (absolute calibration error; lower better): 0.1402, Resolution (relative calibration quality; higher better): 0.0086, Uncertainty: 0.2371 (n=445)
  AUROC: 0.4285

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.214
Model:                            OLS   Adj. R-squared:                  0.208
Method:                 Least Squares   F-statistic:                     37.68
Date:                Wed, 24 Sep 2025   Prob (F-statistic):           1.50e-21
Time:                        16:14:03   Log-Likelihood:                -174.08
No. Observations:                 419   AIC:                             356.2
Df Residuals:                     415   BIC:                             372.3
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.2130      0.092     -2.310      0.021      -0.394      -0.032
p1                    0.8572      0.112      7.648      0.000       0.637       1.077
answer_changed       -0.0863      0.140     -0.617      0.538      -0.362       0.189
p1:answer_changed     0.2418      0.187      1.294      0.196      -0.126       0.609
==============================================================================
Omnibus:                       96.450   Durbin-Watson:                   1.980
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               61.046
Skew:                          -0.810   Prob(JB):                     5.55e-14
Kurtosis:                       2.068   Cond. No.                         18.8
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=10.41, p=9.59e-22
Wilcoxon delta_H: statistic=8076.00, p=1.36e-19
Mean ΔH = 0.3722  [0.3021, 0.4423]
Paired t-test delta_H Changed: statistic=5.92, p=1.93e-08
Wilcoxon delta_H Changed: statistic=3173.00, p=6.87e-08
Mean ΔH Changed = 0.2569  [0.1719, 0.3420]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=6.45, p=2.91e-10
Wilcoxon (p_top2_game vs p_top2_base): statistic=35640.00, p=1.3e-07
Mean Δp_top2 = 0.0297  [0.0206, 0.0387] (n=447)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=11.91, p=1.4e-28
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=21294.00, p=6.43e-26
Mean ΔH_unchosen_baseline_set = 0.3315  [0.2769, 0.3860] (n=447)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      444
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.06834
Time:                        16:14:03   Log-Likelihood:                -270.51
converged:                       True   LL-Null:                       -290.36
Covariance Type:            nonrobust   LLR p-value:                 2.412e-09
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.4205      0.152     -2.767      0.006      -0.718      -0.123
p1_z            -0.7302      0.124     -5.875      0.000      -0.974      -0.487
I(p1_z ** 2)    -0.2493      0.121     -2.054      0.040      -0.487      -0.011
================================================================================
AUC = 0.682

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1437
Time:                        16:14:03   Log-Likelihood:                -248.64
converged:                       True   LL-Null:                       -290.36
Covariance Type:            nonrobust   LLR p-value:                 6.592e-20
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.9225      0.200     -9.616      0.000      -2.314      -1.531
game_entropy     1.8290      0.219      8.363      0.000       1.400       2.258
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=34053.00, p=4.66e-09
Paired t-test (game_entropy vs capabilities_entropy): statistic=-6.59, p=1.23e-10
Mean game_entropy-capabilities_entropy = -0.1722  [-0.2234, -0.1210] (n=447)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      444
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1530
Time:                        16:14:03   Log-Likelihood:                -245.94
converged:                       True   LL-Null:                       -290.36
Covariance Type:            nonrobust   LLR p-value:                 5.139e-20
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.1685      0.234     -9.285      0.000      -2.626      -1.711
capabilities_entropy     0.4803      0.207      2.320      0.020       0.075       0.886
game_entropy             1.5700      0.244      6.430      0.000       1.091       2.049
========================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:               0.0009934
Time:                        16:14:03   Log-Likelihood:                -290.07
converged:                       True   LL-Null:                       -290.36
Covariance Type:            nonrobust   LLR p-value:                    0.4475
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -0.2926      0.421     -0.695      0.487      -1.118       0.533
human_difficulty    -0.1316      0.174     -0.758      0.449      -0.472       0.209
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      440
Method:                           MLE   Df Model:                            6
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.03413
Time:                        16:14:03   Log-Likelihood:                -280.45
converged:                       True   LL-Null:                       -290.36
Covariance Type:            nonrobust   LLR p-value:                  0.002978
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -3.6170      1.534     -2.358      0.018      -6.624      -0.610
C(domain_grouped)[T.chemistry]        1.1081      0.365      3.039      0.002       0.393       1.823
C(domain_grouped)[T.physics]          1.2139      0.370      3.279      0.001       0.488       1.939
human_difficulty                     -0.0104      0.181     -0.057      0.954      -0.365       0.344
q_length                              0.2491      0.169      1.474      0.141      -0.082       0.580
avg_word_length                       0.0750      0.168      0.446      0.656      -0.255       0.405
percent_non_alphabetic_whitespace     0.0257      0.018      1.406      0.160      -0.010       0.062
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 0.8340
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      439
Method:                           MLE   Df Model:                            7
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.09443
Time:                        16:14:03   Log-Likelihood:                -262.94
converged:                       True   LL-Null:                       -290.36
Covariance Type:            nonrobust   LLR p-value:                 1.605e-09
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -4.6271      1.591     -2.908      0.004      -7.746      -1.509
C(domain_grouped)[T.chemistry]        0.5880      0.388      1.517      0.129      -0.172       1.348
C(domain_grouped)[T.physics]          0.9604      0.388      2.478      0.013       0.201       1.720
human_difficulty                      0.0335      0.189      0.177      0.859      -0.337       0.404
q_length                              0.1755      0.175      1.004      0.315      -0.167       0.518
avg_word_length                       0.2102      0.171      1.227      0.220      -0.126       0.546
percent_non_alphabetic_whitespace     0.0367      0.019      1.928      0.054      -0.001       0.074
capabilities_entropy                  1.0684      0.188      5.675      0.000       0.699       1.437
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      439
Method:                           MLE   Df Model:                            7
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1663
Time:                        16:14:03   Log-Likelihood:                -242.07
converged:                       True   LL-Null:                       -290.36
Covariance Type:            nonrobust   LLR p-value:                 5.503e-18
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -4.4595      1.689     -2.640      0.008      -7.770      -1.149
C(domain_grouped)[T.chemistry]        0.7466      0.401      1.864      0.062      -0.038       1.532
C(domain_grouped)[T.physics]          1.1092      0.410      2.708      0.007       0.306       1.912
human_difficulty                      0.0500      0.201      0.249      0.803      -0.344       0.444
q_length                              0.1116      0.183      0.611      0.541      -0.246       0.469
avg_word_length                       0.1418      0.182      0.778      0.436      -0.215       0.499
percent_non_alphabetic_whitespace     0.0362      0.021      1.767      0.077      -0.004       0.076
game_entropy                          1.8161      0.226      8.035      0.000       1.373       2.259
=====================================================================================================

                  Model 4.95: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      438
Method:                           MLE   Df Model:                            8
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1727
Time:                        16:14:03   Log-Likelihood:                -240.21
converged:                       True   LL-Null:                       -290.36
Covariance Type:            nonrobust   LLR p-value:                 3.728e-18
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -4.7648      1.698     -2.806      0.005      -8.093      -1.437
C(domain_grouped)[T.chemistry]        0.5878      0.411      1.431      0.152      -0.217       1.393
C(domain_grouped)[T.physics]          1.0229      0.414      2.470      0.014       0.211       1.835
human_difficulty                      0.0624      0.202      0.309      0.757      -0.333       0.458
q_length                              0.0969      0.183      0.528      0.598      -0.263       0.456
avg_word_length                       0.1887      0.183      1.034      0.301      -0.169       0.547
percent_non_alphabetic_whitespace     0.0392      0.021      1.905      0.057      -0.001       0.080
capabilities_entropy                  0.4207      0.218      1.926      0.054      -0.008       0.849
game_entropy                          1.6031      0.250      6.411      0.000       1.113       2.093
=====================================================================================================

--- Analyzing gemini-2.5-flash-lite_think (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_new/gemini-2.5-flash-lite_think_GPQA_redacted_cor_temp1.0_1758169794_game_data.json', './sc_logs_new/gemini-2.5-flash-lite_think_GPQA_redacted_temp1.0_1758161989_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
1    229
0    218
Name: count, dtype: int64

Answer change%: 0.5123 [0.4659667297261465, 0.5586417713924217] (n=447)
P-value vs 25%: 1.329e-28; P-value vs 0%: 4.005e-104
Phase 2 self-accuracy: 0.2096 [0.15688949091449972, 0.2623244828846269] (n=229)
P-value vs 25%: 0.1332; P-value vs 33%: 4.484e-06

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.02319
Time:                        16:14:03   Log-Likelihood:                -302.52
converged:                       True   LL-Null:                       -309.70
Covariance Type:            nonrobust   LLR p-value:                 0.0001508
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept         90.1323     39.243      2.297      0.022      13.218     167.047
p_i_capability   -90.1944     39.275     -2.296      0.022    -167.172     -13.217
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.02171
Time:                        16:14:03   Log-Likelihood:                -302.98
converged:                       True   LL-Null:                       -309.70
Covariance Type:            nonrobust   LLR p-value:                 0.0002450
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -0.0687      0.102     -0.672      0.501      -0.269       0.132
capabilities_entropy    11.0512      4.640      2.382      0.017       1.957      20.146
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.1505 [0.1017, 0.1993] (n=206)
                  P-value vs 33.3%: 2.137e-13

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=2.21, p=0.0284
Wilcoxon delta_p: statistic=5494.00, p=3.06e-05
Mean Δp = 0.0083  [0.0009, 0.0157]
Idea 1 N = 184; 

  Idea 1.5: Calibration Metrics
  NLL: 1.9179, Signed ECE (overconf pos under neg): -0.0009, ECE: 0.0025 (n=308)
  Brier: 0.0002, Reliability (absolute calibration error; lower better): 0.0001, Resolution (relative calibration quality; higher better): 0.1627, Uncertainty: 0.1627 (n=308)
  AUROC: 1.0000

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.992
Model:                            OLS   Adj. R-squared:                  0.992
Method:                 Least Squares   F-statistic:                 1.329e+04
Date:                Wed, 24 Sep 2025   Prob (F-statistic):               0.00
Time:                        16:14:03   Log-Likelihood:                 548.90
No. Observations:                 318   AIC:                            -1090.
Df Residuals:                     314   BIC:                            -1075.
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -1.9835      1.965     -1.010      0.313      -5.849       1.882
p1                    1.9932      1.966      1.014      0.311      -1.875       5.862
answer_changed        1.4645      1.972      0.743      0.458      -2.415       5.344
p1:answer_changed    -0.4788      1.973     -0.243      0.808      -4.361       3.403
==============================================================================
Omnibus:                      454.198   Durbin-Watson:                   2.052
Prob(Omnibus):                  0.000   Jarque-Bera (JB):            99401.033
Skew:                           6.769   Prob(JB):                         0.00
Kurtosis:                      88.549   Cond. No.                     2.53e+03
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The condition number is large, 2.53e+03. This might indicate that there are
strong multicollinearity or other numerical problems.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-4.83, p=2.92e-06
Wilcoxon delta_H: statistic=4993.00, p=1.17e-06
Mean ΔH = -0.2016  [-0.2835, -0.1197]
Paired t-test delta_H Changed: statistic=30.83, p=1.07e-76
Wilcoxon delta_H Changed: statistic=47.00, p=1.96e-33
Mean ΔH Changed = 1.0049  [0.9410, 1.0688]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=-1.36, p=0.176
Wilcoxon (p_top2_game vs p_top2_base): statistic=18547.00, p=2.83e-16
Mean Δp_top2 = -0.0016  [-0.0040, 0.0007] (n=379)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=10.31, p=3.95e-22
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=16862.00, p=2.97e-19
Mean ΔH_unchosen_baseline_set = 0.4191  [0.3395, 0.4988] (n=379)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  379
Model:                          Logit   Df Residuals:                      376
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.03375
Time:                        16:14:03   Log-Likelihood:                -253.68
converged:                       True   LL-Null:                       -262.54
Covariance Type:            nonrobust   LLR p-value:                 0.0001419
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.1581      0.318     -0.496      0.620      -0.782       0.466
p1_z            -0.5930      1.785     -0.332      0.740      -4.092       2.906
I(p1_z ** 2)    13.3325      9.865      1.351      0.177      -6.003      32.668
================================================================================
AUC = 0.580

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                0.005086
Time:                        16:14:03   Log-Likelihood:                -308.13
converged:                       True   LL-Null:                       -309.70
Covariance Type:            nonrobust   LLR p-value:                   0.07592
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept        0.0034      0.098      0.035      0.972      -0.189       0.196
game_entropy     0.9773      0.593      1.648      0.099      -0.185       2.139
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=30769.00, p=1.66e-12
Paired t-test (game_entropy vs capabilities_entropy): statistic=3.53, p=0.000466
Mean game_entropy-capabilities_entropy = 0.0309  [0.0137, 0.0481] (n=447)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      444
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.02274
Time:                        16:14:03   Log-Likelihood:                -302.66
converged:                       True   LL-Null:                       -309.70
Covariance Type:            nonrobust   LLR p-value:                 0.0008745
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -0.0858      0.105     -0.820      0.412      -0.291       0.119
capabilities_entropy    10.6543      4.694      2.270      0.023       1.453      19.855
game_entropy             0.4986      0.641      0.778      0.437      -0.757       1.755
========================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                0.009490
Time:                        16:14:03   Log-Likelihood:                -306.76
converged:                       True   LL-Null:                       -309.70
Covariance Type:            nonrobust   LLR p-value:                   0.01533
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -0.9086      0.410     -2.218      0.027      -1.711      -0.106
human_difficulty     0.4045      0.168      2.401      0.016       0.074       0.735
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      440
Method:                           MLE   Df Model:                            6
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.01680
Time:                        16:14:03   Log-Likelihood:                -304.50
converged:                       True   LL-Null:                       -309.70
Covariance Type:            nonrobust   LLR p-value:                    0.1087
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -1.2941      1.377     -0.940      0.347      -3.994       1.405
C(domain_grouped)[T.chemistry]        0.2231      0.297      0.750      0.453      -0.360       0.806
C(domain_grouped)[T.physics]         -0.1944      0.301     -0.645      0.519      -0.785       0.396
human_difficulty                      0.4400      0.175      2.516      0.012       0.097       0.783
q_length                              0.0537      0.155      0.346      0.729      -0.250       0.357
avg_word_length                      -0.0226      0.153     -0.147      0.883      -0.323       0.278
percent_non_alphabetic_whitespace     0.0091      0.017      0.520      0.603      -0.025       0.043
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 0.0189
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      439
Method:                           MLE   Df Model:                            7
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.03315
Time:                        16:14:03   Log-Likelihood:                -299.43
converged:                       True   LL-Null:                       -309.70
Covariance Type:            nonrobust   LLR p-value:                  0.004526
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -0.9763      1.396     -0.699      0.484      -3.713       1.761
C(domain_grouped)[T.chemistry]        0.0718      0.303      0.237      0.813      -0.523       0.667
C(domain_grouped)[T.physics]         -0.2334      0.302     -0.772      0.440      -0.826       0.359
human_difficulty                      0.3761      0.177      2.125      0.034       0.029       0.723
q_length                              0.0002      0.159      0.001      0.999      -0.311       0.312
avg_word_length                      -0.0002      0.154     -0.001      0.999      -0.303       0.302
percent_non_alphabetic_whitespace     0.0117      0.018      0.668      0.504      -0.023       0.046
capabilities_entropy                  9.4208      4.655      2.024      0.043       0.298      18.544
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      439
Method:                           MLE   Df Model:                            7
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.02058
Time:                        16:14:03   Log-Likelihood:                -303.33
converged:                       True   LL-Null:                       -309.70
Covariance Type:            nonrobust   LLR p-value:                   0.07855
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -1.2353      1.379     -0.896      0.370      -3.938       1.468
C(domain_grouped)[T.chemistry]        0.1952      0.298      0.655      0.513      -0.389       0.780
C(domain_grouped)[T.physics]         -0.2159      0.302     -0.715      0.474      -0.807       0.376
human_difficulty                      0.4151      0.176      2.359      0.018       0.070       0.760
q_length                              0.0403      0.155      0.259      0.795      -0.264       0.344
avg_word_length                      -0.0111      0.154     -0.072      0.942      -0.313       0.291
percent_non_alphabetic_whitespace     0.0099      0.018      0.563      0.573      -0.024       0.044
game_entropy                          0.8501      0.588      1.446      0.148      -0.302       2.003
=====================================================================================================

                  Model 4.95: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      438
Method:                           MLE   Df Model:                            8
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.03393
Time:                        16:14:03   Log-Likelihood:                -299.19
converged:                       True   LL-Null:                       -309.70
Covariance Type:            nonrobust   LLR p-value:                  0.007099
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -0.9304      1.399     -0.665      0.506      -3.672       1.811
C(domain_grouped)[T.chemistry]        0.0648      0.304      0.213      0.831      -0.530       0.660
C(domain_grouped)[T.physics]         -0.2427      0.303     -0.802      0.423      -0.836       0.350
human_difficulty                      0.3668      0.178      2.065      0.039       0.019       0.715
q_length                             -0.0069      0.159     -0.043      0.966      -0.319       0.306
avg_word_length                       0.0016      0.154      0.011      0.992      -0.301       0.304
percent_non_alphabetic_whitespace     0.0118      0.018      0.669      0.503      -0.023       0.046
capabilities_entropy                  9.1255      4.721      1.933      0.053      -0.127      18.378
game_entropy                          0.4396      0.641      0.686      0.493      -0.817       1.696
=====================================================================================================

--- Analyzing gemini-2.5-flash-preview-04-17 (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_new/gemini-2.5-flash-preview-04-17_GPQA_redacted_cor_temp0.0_1751803003_game_data.json', './sc_logs_new/gemini-2.5-flash-preview-04-17_GPQA_redacted_temp0.0_1751720035_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    291
1    152
Name: count, dtype: int64

Answer change%: 0.3431 [0.29890611409609097, 0.3873241342109068] (n=443)
P-value vs 25%: 3.657e-05; P-value vs 0%: 2.959e-52
Phase 2 self-accuracy: 0.3026 [0.22959934965651124, 0.3756638082382256] (n=152)
P-value vs 25%: 0.1578; P-value vs 33%: 0.4151

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  441
Model:                          Logit   Df Residuals:                      439
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                0.009313
Time:                        16:14:03   Log-Likelihood:                -281.40
converged:                       True   LL-Null:                       -284.04
Covariance Type:            nonrobust   LLR p-value:                   0.02144
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.7305      0.108     -6.750      0.000      -0.943      -0.518
game_entropy     0.6934      0.302      2.297      0.022       0.102       1.285
================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  443
Model:                          Logit   Df Residuals:                      441
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                0.001021
Time:                        16:14:03   Log-Likelihood:                -284.59
converged:                       True   LL-Null:                       -284.88
Covariance Type:            nonrobust   LLR p-value:                    0.4457
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -0.9664      0.428     -2.256      0.024      -1.806      -0.127
human_difficulty     0.1335      0.175      0.763      0.446      -0.209       0.476
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  443
Model:                          Logit   Df Residuals:                      436
Method:                           MLE   Df Model:                            6
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.02280
Time:                        16:14:03   Log-Likelihood:                -278.39
converged:                       True   LL-Null:                       -284.88
Covariance Type:            nonrobust   LLR p-value:                   0.04321
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -1.8807      1.509     -1.246      0.213      -4.838       1.077
C(domain_grouped)[T.chemistry]        0.6391      0.339      1.883      0.060      -0.026       1.304
C(domain_grouped)[T.physics]          0.6613      0.344      1.920      0.055      -0.014       1.336
human_difficulty                      0.2821      0.183      1.539      0.124      -0.077       0.641
q_length                             -0.0299      0.166     -0.180      0.857      -0.356       0.296
avg_word_length                      -0.0149      0.168     -0.089      0.929      -0.344       0.314
percent_non_alphabetic_whitespace     0.0295      0.018      1.600      0.110      -0.007       0.066
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  441
Model:                          Logit   Df Residuals:                      433
Method:                           MLE   Df Model:                            7
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.02789
Time:                        16:14:03   Log-Likelihood:                -276.12
converged:                       True   LL-Null:                       -284.04
Covariance Type:            nonrobust   LLR p-value:                   0.02658
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -1.7155      1.516     -1.131      0.258      -4.688       1.257
C(domain_grouped)[T.chemistry]        0.5435      0.346      1.572      0.116      -0.134       1.221
C(domain_grouped)[T.physics]          0.6176      0.346      1.785      0.074      -0.060       1.296
human_difficulty                      0.2419      0.185      1.305      0.192      -0.121       0.605
q_length                             -0.0335      0.167     -0.201      0.841      -0.361       0.294
avg_word_length                      -0.0215      0.169     -0.127      0.899      -0.353       0.310
percent_non_alphabetic_whitespace     0.0271      0.019      1.464      0.143      -0.009       0.063
game_entropy                          0.5319      0.312      1.706      0.088      -0.079       1.143
=====================================================================================================

--- Analyzing gemini-2.5-flash_nothink (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_new/gemini-2.5-flash_nothink_GPQA_redacted_cor_temp1.0_1758161812_game_data.json', './sc_logs_new/gemini-2.5-flash_nothink_GPQA_redacted_temp1.0_1758161699_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    314
1    133
Name: count, dtype: int64

Answer change%: 0.2975 [0.2551575398784204, 0.33992075989786597] (n=447)
P-value vs 25%: 0.02792; P-value vs 0%: 4.442e-43
Phase 2 self-accuracy: 0.3233 [0.2438157786328595, 0.4028007627205239] (n=133)
P-value vs 25%: 0.07069; P-value vs 33%: 0.8111

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.08157
Time:                        16:14:03   Log-Likelihood:                -249.92
converged:                       True   LL-Null:                       -272.12
Covariance Type:            nonrobust   LLR p-value:                 2.687e-11
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          1.4010      0.356      3.935      0.000       0.703       2.099
p_i_capability    -3.0989      0.482     -6.429      0.000      -4.044      -2.154
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.08474
Time:                        16:14:03   Log-Likelihood:                -249.06
converged:                       True   LL-Null:                       -272.12
Covariance Type:            nonrobust   LLR p-value:                 1.113e-11
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.8872      0.206     -9.170      0.000      -2.291      -1.484
capabilities_entropy     1.1000      0.170      6.462      0.000       0.766       1.434
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.6466 [0.5654, 0.7279] (n=133)
                  P-value vs 33.3%: 4.088e-14

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=13.72, p=7.88e-34
Wilcoxon delta_p: statistic=5433.00, p=7.05e-33
Mean Δp = 0.1317  [0.1129, 0.1505]
Idea 1 N = 313; 

  Idea 1.5: Calibration Metrics
  NLL: 1.7304, Signed ECE (overconf pos under neg): -0.0255, ECE: 0.1049 (n=447)
  Brier: 0.0489, Reliability (absolute calibration error; lower better): 0.0242, Resolution (relative calibration quality; higher better): 0.2253, Uncertainty: 0.2498 (n=447)
  AUROC: 0.9964

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.578
Model:                            OLS   Adj. R-squared:                  0.575
Method:                 Least Squares   F-statistic:                     200.4
Date:                Wed, 24 Sep 2025   Prob (F-statistic):           7.61e-82
Time:                        16:14:03   Log-Likelihood:                 213.19
No. Observations:                 443   AIC:                            -418.4
Df Residuals:                     439   BIC:                            -402.0
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.0011      0.033     -0.034      0.973      -0.066       0.064
p1                    0.1647      0.040      4.168      0.000       0.087       0.242
answer_changed       -0.1938      0.054     -3.566      0.000      -0.301      -0.087
p1:answer_changed     0.7938      0.075     10.625      0.000       0.647       0.941
==============================================================================
Omnibus:                       10.643   Durbin-Watson:                   1.820
Prob(Omnibus):                  0.005   Jarque-Bera (JB):               10.887
Skew:                           0.383   Prob(JB):                      0.00433
Kurtosis:                       3.053   Cond. No.                         17.8
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-7.95, p=3.39e-14
Wilcoxon delta_H: statistic=12324.00, p=1.32e-14
Mean ΔH = -0.2012  [-0.2508, -0.1516]
Paired t-test delta_H Changed: statistic=-2.81, p=0.00573
Wilcoxon delta_H Changed: statistic=3132.00, p=0.00296
Mean ΔH Changed = -0.0939  [-0.1594, -0.0284]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=-19.30, p=8.53e-61
Wilcoxon (p_top2_game vs p_top2_base): statistic=5265.00, p=2.13e-60
Mean Δp_top2 = -0.0977  [-0.1076, -0.0878] (n=447)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=-8.27, p=1.61e-15
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=27821.00, p=3.97e-16
Mean ΔH_unchosen_baseline_set = -0.1693  [-0.2094, -0.1291] (n=447)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      444
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.09863
Time:                        16:14:03   Log-Likelihood:                -245.28
converged:                       True   LL-Null:                       -272.12
Covariance Type:            nonrobust   LLR p-value:                 2.208e-12
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.5730      0.165     -3.467      0.001      -0.897      -0.249
p1_z            -0.9594      0.145     -6.624      0.000      -1.243      -0.676
I(p1_z ** 2)    -0.4266      0.141     -3.023      0.002      -0.703      -0.150
================================================================================
AUC = 0.717

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1109
Time:                        16:14:03   Log-Likelihood:                -241.94
converged:                       True   LL-Null:                       -272.12
Covariance Type:            nonrobust   LLR p-value:                 7.908e-15
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -3.0068      0.362     -8.305      0.000      -3.716      -2.297
game_entropy     1.5789      0.234      6.753      0.000       1.121       2.037
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=7824.00, p=6.77e-54
Paired t-test (game_entropy vs capabilities_entropy): statistic=18.61, p=1.29e-57
Mean game_entropy-capabilities_entropy = 0.4000  [0.3578, 0.4421] (n=447)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      444
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1156
Time:                        16:14:03   Log-Likelihood:                -240.65
converged:                       True   LL-Null:                       -272.12
Covariance Type:            nonrobust   LLR p-value:                 2.155e-14
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.9011      0.362     -8.011      0.000      -3.611      -2.191
capabilities_entropy     0.3814      0.239      1.596      0.111      -0.087       0.850
game_entropy             1.2381      0.313      3.958      0.000       0.625       1.851
========================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:               8.731e-05
Time:                        16:14:03   Log-Likelihood:                -272.09
converged:                       True   LL-Null:                       -272.12
Covariance Type:            nonrobust   LLR p-value:                    0.8274
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -0.9524      0.441     -2.161      0.031      -1.816      -0.088
human_difficulty     0.0393      0.180      0.218      0.827      -0.314       0.393
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      440
Method:                           MLE   Df Model:                            6
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.01810
Time:                        16:14:03   Log-Likelihood:                -267.19
converged:                       True   LL-Null:                       -272.12
Covariance Type:            nonrobust   LLR p-value:                    0.1311
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -3.1940      1.549     -2.063      0.039      -6.229      -0.159
C(domain_grouped)[T.chemistry]        0.7539      0.339      2.227      0.026       0.090       1.418
C(domain_grouped)[T.physics]          0.5028      0.346      1.455      0.146      -0.174       1.180
human_difficulty                      0.0344      0.187      0.184      0.854      -0.332       0.401
q_length                              0.3443      0.174      1.981      0.048       0.004       0.685
avg_word_length                      -0.0229      0.172     -0.134      0.894      -0.359       0.313
percent_non_alphabetic_whitespace    -0.0252      0.020     -1.234      0.217      -0.065       0.015
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 0.8397
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      439
Method:                           MLE   Df Model:                            7
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.09357
Time:                        16:14:03   Log-Likelihood:                -246.66
converged:                       True   LL-Null:                       -272.12
Covariance Type:            nonrobust   LLR p-value:                 9.513e-09
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -3.9154      1.601     -2.445      0.014      -7.053      -0.777
C(domain_grouped)[T.chemistry]        0.1778      0.365      0.488      0.626      -0.537       0.893
C(domain_grouped)[T.physics]          0.0275      0.373      0.074      0.941      -0.704       0.759
human_difficulty                     -0.0225      0.197     -0.114      0.909      -0.409       0.364
q_length                              0.2458      0.183      1.344      0.179      -0.113       0.604
avg_word_length                       0.1366      0.177      0.771      0.441      -0.211       0.484
percent_non_alphabetic_whitespace    -0.0123      0.021     -0.577      0.564      -0.054       0.029
capabilities_entropy                  1.1094      0.182      6.092      0.000       0.753       1.466
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      439
Method:                           MLE   Df Model:                            7
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1223
Time:                        16:14:03   Log-Likelihood:                -238.84
converged:                       True   LL-Null:                       -272.12
Covariance Type:            nonrobust   LLR p-value:                 7.323e-12
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -4.7180      1.643     -2.872      0.004      -7.938      -1.498
C(domain_grouped)[T.chemistry]       -0.0461      0.377     -0.122      0.903      -0.785       0.693
C(domain_grouped)[T.physics]         -0.0961      0.386     -0.249      0.803      -0.853       0.661
human_difficulty                     -0.0077      0.199     -0.039      0.969      -0.398       0.383
q_length                              0.2377      0.184      1.290      0.197      -0.124       0.599
avg_word_length                       0.0992      0.177      0.561      0.575      -0.247       0.446
percent_non_alphabetic_whitespace    -0.0221      0.021     -1.046      0.296      -0.064       0.019
game_entropy                          1.6551      0.253      6.549      0.000       1.160       2.150
=====================================================================================================

                  Model 4.95: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      438
Method:                           MLE   Df Model:                            8
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1269
Time:                        16:14:03   Log-Likelihood:                -237.58
converged:                       True   LL-Null:                       -272.12
Covariance Type:            nonrobust   LLR p-value:                 7.506e-12
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -4.6606      1.651     -2.823      0.005      -7.896      -1.425
C(domain_grouped)[T.chemistry]       -0.0909      0.379     -0.240      0.810      -0.833       0.651
C(domain_grouped)[T.physics]         -0.1546      0.389     -0.398      0.691      -0.917       0.607
human_difficulty                     -0.0203      0.200     -0.101      0.919      -0.413       0.372
q_length                              0.2252      0.185      1.215      0.224      -0.138       0.588
avg_word_length                       0.1310      0.180      0.729      0.466      -0.221       0.483
percent_non_alphabetic_whitespace    -0.0187      0.021     -0.873      0.382      -0.061       0.023
capabilities_entropy                  0.3857      0.244      1.578      0.115      -0.093       0.865
game_entropy                          1.3260      0.324      4.091      0.000       0.691       1.961
=====================================================================================================

--- Analyzing gemini-2.5-flash_think (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_new/gemini-2.5-flash_think_GPQA_redacted_cor_temp1.0_1758262922_game_data.json', './sc_logs_new/gemini-2.5-flash_think_GPQA_redacted_temp1.0_1758250419_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    343
1    104
Name: count, dtype: int64

Answer change%: 0.2327 [0.19349246617632646, 0.27183191861114553] (n=447)
P-value vs 25%: 0.3856; P-value vs 0%: 2.524e-31
Phase 2 self-accuracy: 0.3654 [0.2728377213136525, 0.4579315094555782] (n=104)
P-value vs 25%: 0.01454; P-value vs 33%: 0.4928

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  411
Model:                          Logit   Df Residuals:                      409
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                0.005893
Time:                        16:14:03   Log-Likelihood:                -222.09
converged:                       True   LL-Null:                       -223.40
Covariance Type:            nonrobust   LLR p-value:                    0.1046
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept         -0.0091      0.716     -0.013      0.990      -1.413       1.395
p_i_capability    -1.2816      0.773     -1.657      0.097      -2.797       0.234
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                0.008234
Time:                        16:14:03   Log-Likelihood:                -240.49
converged:                       True   LL-Null:                       -242.49
Covariance Type:            nonrobust   LLR p-value:                   0.04568
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.3494      0.140     -9.667      0.000      -1.623      -1.076
capabilities_entropy     0.4606      0.227      2.029      0.042       0.016       0.906
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.0938 [0.0354, 0.1521] (n=96)
                  P-value vs 33.3%: 8.048e-16

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=4.73, p=3.47e-06
Wilcoxon delta_p: statistic=19948.00, p=0.118
Mean Δp = 0.0605  [0.0354, 0.0856]
Idea 1 N = 299; 

  Idea 1.5: Calibration Metrics
  NLL: 1.5508, Signed ECE (overconf pos under neg): -0.1299, ECE: 0.1299 (n=347)
  Brier: 0.1043, Reliability (absolute calibration error; lower better): 0.0600, Resolution (relative calibration quality; higher better): 0.0512, Uncertainty: 0.0975 (n=347)
  AUROC: 0.9946

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.735
Model:                            OLS   Adj. R-squared:                  0.733
Method:                 Least Squares   F-statistic:                     329.6
Date:                Wed, 24 Sep 2025   Prob (F-statistic):          2.30e-102
Time:                        16:14:03   Log-Likelihood:                 78.325
No. Observations:                 360   AIC:                            -148.7
Df Residuals:                     356   BIC:                            -133.1
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept             0.5611      0.088      6.400      0.000       0.389       0.733
p1                   -0.5301      0.092     -5.758      0.000      -0.711      -0.349
answer_changed       -0.7413      0.194     -3.827      0.000      -1.122      -0.360
p1:answer_changed     1.7012      0.208      8.180      0.000       1.292       2.110
==============================================================================
Omnibus:                      123.608   Durbin-Watson:                   1.980
Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1020.509
Skew:                           1.194   Prob(JB):                    2.51e-222
Kurtosis:                      10.895   Cond. No.                         39.3
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=2.41, p=0.0166
Wilcoxon delta_H: statistic=20716.00, p=0.0127
Mean ΔH = 0.0826  [0.0154, 0.1498]
Paired t-test delta_H Changed: statistic=9.98, p=1.79e-16
Wilcoxon delta_H Changed: statistic=389.00, p=1.38e-12
Mean ΔH Changed = 0.6432  [0.5169, 0.7695]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=3.16, p=0.00168
Wilcoxon (p_top2_game vs p_top2_base): statistic=30836.00, p=2.56e-06
Mean Δp_top2 = 0.0084  [0.0032, 0.0135] (n=410)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=6.59, p=1.35e-10
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=27269.00, p=6.07e-10
Mean ΔH_unchosen_baseline_set = 0.2138  [0.1502, 0.2774] (n=410)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  410
Model:                          Logit   Df Residuals:                      407
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.01144
Time:                        16:14:03   Log-Likelihood:                -220.58
converged:                       True   LL-Null:                       -223.14
Covariance Type:            nonrobust   LLR p-value:                   0.07784
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.0405      0.153     -6.808      0.000      -1.340      -0.741
p1_z            -0.5125      0.239     -2.147      0.032      -0.980      -0.045
I(p1_z ** 2)    -0.1609      0.107     -1.508      0.132      -0.370       0.048
================================================================================
AUC = 0.608

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.01575
Time:                        16:14:03   Log-Likelihood:                -238.67
converged:                       True   LL-Null:                       -242.49
Covariance Type:            nonrobust   LLR p-value:                  0.005710
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.3633      0.131    -10.401      0.000      -1.620      -1.106
game_entropy     0.8394      0.297      2.827      0.005       0.257       1.421
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=36703.00, p=1.01e-06
Paired t-test (game_entropy vs capabilities_entropy): statistic=-5.74, p=1.74e-08
Mean game_entropy-capabilities_entropy = -0.1342  [-0.1800, -0.0884] (n=447)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      444
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.01915
Time:                        16:14:03   Log-Likelihood:                -237.84
converged:                       True   LL-Null:                       -242.49
Covariance Type:            nonrobust   LLR p-value:                  0.009625
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.4464      0.148     -9.768      0.000      -1.737      -1.156
capabilities_entropy     0.3122      0.240      1.300      0.194      -0.158       0.783
game_entropy             0.7264      0.310      2.345      0.019       0.119       1.334
========================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:               8.599e-05
Time:                        16:14:03   Log-Likelihood:                -242.46
converged:                       True   LL-Null:                       -242.49
Covariance Type:            nonrobust   LLR p-value:                    0.8382
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -1.0988      0.476     -2.307      0.021      -2.032      -0.165
human_difficulty    -0.0400      0.196     -0.204      0.838      -0.424       0.344
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      440
Method:                           MLE   Df Model:                            6
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.03349
Time:                        16:14:03   Log-Likelihood:                -234.37
converged:                       True   LL-Null:                       -242.49
Covariance Type:            nonrobust   LLR p-value:                   0.01253
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -0.1591      1.631     -0.098      0.922      -3.355       3.037
C(domain_grouped)[T.chemistry]        0.5155      0.360      1.433      0.152      -0.190       1.221
C(domain_grouped)[T.physics]         -0.1556      0.382     -0.407      0.684      -0.904       0.593
human_difficulty                      0.0927      0.211      0.440      0.660      -0.321       0.506
q_length                             -0.3550      0.183     -1.938      0.053      -0.714       0.004
avg_word_length                       0.1053      0.178      0.590      0.555      -0.244       0.455
percent_non_alphabetic_whitespace     0.0185      0.020      0.936      0.349      -0.020       0.057
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 0.3126
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      439
Method:                           MLE   Df Model:                            7
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.03843
Time:                        16:14:03   Log-Likelihood:                -233.17
converged:                       True   LL-Null:                       -242.49
Covariance Type:            nonrobust   LLR p-value:                  0.009408
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                             0.0455      1.628      0.028      0.978      -3.145       3.236
C(domain_grouped)[T.chemistry]        0.3437      0.379      0.907      0.364      -0.399       1.086
C(domain_grouped)[T.physics]         -0.2250      0.388     -0.579      0.562      -0.986       0.536
human_difficulty                      0.0405      0.214      0.189      0.850      -0.379       0.460
q_length                             -0.3963      0.186     -2.130      0.033      -0.761      -0.032
avg_word_length                       0.1314      0.177      0.743      0.457      -0.215       0.478
percent_non_alphabetic_whitespace     0.0198      0.020      1.003      0.316      -0.019       0.059
capabilities_entropy                  0.3925      0.251      1.564      0.118      -0.099       0.884
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      439
Method:                           MLE   Df Model:                            7
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.04279
Time:                        16:14:03   Log-Likelihood:                -232.11
converged:                       True   LL-Null:                       -242.49
Covariance Type:            nonrobust   LLR p-value:                  0.004158
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                             0.3886      1.668      0.233      0.816      -2.881       3.658
C(domain_grouped)[T.chemistry]        0.3254      0.374      0.871      0.384      -0.407       1.058
C(domain_grouped)[T.physics]         -0.2336      0.387     -0.603      0.546      -0.993       0.526
human_difficulty                      0.0472      0.213      0.221      0.825      -0.371       0.465
q_length                             -0.4020      0.186     -2.156      0.031      -0.767      -0.037
avg_word_length                       0.0721      0.181      0.399      0.690      -0.282       0.426
percent_non_alphabetic_whitespace     0.0145      0.020      0.726      0.468      -0.025       0.054
game_entropy                          0.6899      0.320      2.156      0.031       0.063       1.317
=====================================================================================================

                  Model 4.95: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      438
Method:                           MLE   Df Model:                            8
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.04539
Time:                        16:14:03   Log-Likelihood:                -231.48
converged:                       True   LL-Null:                       -242.49
Covariance Type:            nonrobust   LLR p-value:                  0.004892
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                             0.4734      1.661      0.285      0.776      -2.781       3.728
C(domain_grouped)[T.chemistry]        0.2167      0.388      0.559      0.576      -0.543       0.976
C(domain_grouped)[T.physics]         -0.2768      0.392     -0.707      0.480      -1.044       0.491
human_difficulty                      0.0127      0.216      0.059      0.953      -0.410       0.435
q_length                             -0.4264      0.188     -2.265      0.024      -0.795      -0.057
avg_word_length                       0.0955      0.180      0.531      0.596      -0.257       0.448
percent_non_alphabetic_whitespace     0.0160      0.020      0.800      0.424      -0.023       0.055
capabilities_entropy                  0.2957      0.261      1.135      0.256      -0.215       0.806
game_entropy                          0.6121      0.328      1.864      0.062      -0.032       1.256
=====================================================================================================

--- Analyzing gpt-4.1-2025-04-14 (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_new/gpt-4.1-2025-04-14_GPQA_redacted_cor_temp1.0_1757988295_game_data.json', './sc_logs_new/gpt-4.1-2025-04-14_GPQA_redacted_temp1.0_1757987232_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    273
1    174
Name: count, dtype: int64

Answer change%: 0.3893 [0.34406129543835273, 0.43446219449453316] (n=447)
P-value vs 25%: 1.554e-09; P-value vs 0%: 6.421e-64
Phase 2 self-accuracy: 0.2931 [0.2254699483016363, 0.3607369482500878] (n=174)
P-value vs 25%: 0.2116; P-value vs 33%: 0.2476

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.04530
Time:                        16:14:03   Log-Likelihood:                -285.25
converged:                       True   LL-Null:                       -298.78
Covariance Type:            nonrobust   LLR p-value:                 1.965e-07
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          2.3889      0.575      4.153      0.000       1.262       3.516
p_i_capability    -3.1402      0.625     -5.022      0.000      -4.366      -1.915
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.05649
Time:                        16:14:03   Log-Likelihood:                -281.90
converged:                       True   LL-Null:                       -298.78
Covariance Type:            nonrobust   LLR p-value:                 6.246e-09
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -0.8267      0.121     -6.833      0.000      -1.064      -0.590
capabilities_entropy     1.1886      0.213      5.593      0.000       0.772       1.605
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.3364 [0.2469, 0.4260] (n=107)
                  P-value vs 33.3%: 0.9456

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=9.31, p=2.03e-12
Wilcoxon delta_p: statistic=64.00, p=4.87e-08
Mean Δp = 0.5380  [0.4248, 0.6512]
Idea 1 N = 50; 

  Idea 1.5: Calibration Metrics
  NLL: 4.6241, Signed ECE (overconf pos under neg): 0.0232, ECE: 0.3165 (n=121)
  Brier: 0.3155, Reliability (absolute calibration error; lower better): 0.1356, Resolution (relative calibration quality; higher better): 0.0183, Uncertainty: 0.1983 (n=121)
  AUROC: 0.5043

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.235
Model:                            OLS   Adj. R-squared:                  0.215
Method:                 Least Squares   F-statistic:                     11.96
Date:                Wed, 24 Sep 2025   Prob (F-statistic):           6.88e-07
Time:                        16:14:03   Log-Likelihood:                -48.675
No. Observations:                 121   AIC:                             105.4
Df Residuals:                     117   BIC:                             116.5
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept             0.2422      0.237      1.022      0.309      -0.227       0.711
p1                    0.3561      0.278      1.280      0.203      -0.195       0.907
answer_changed       -0.7077      0.297     -2.387      0.019      -1.295      -0.121
p1:answer_changed     0.9823      0.360      2.728      0.007       0.269       1.696
==============================================================================
Omnibus:                       18.335   Durbin-Watson:                   1.840
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               23.092
Skew:                          -1.064   Prob(JB):                     9.68e-06
Kurtosis:                       2.778   Cond. No.                         25.2
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=1.75, p=0.0858
Wilcoxon delta_H: statistic=454.00, p=0.0772
Mean ΔH = 0.1565  [-0.0184, 0.3314]
Paired t-test delta_H Changed: statistic=3.95, p=0.000184
Wilcoxon delta_H Changed: statistic=690.00, p=0.000754
Mean ΔH Changed = 0.2656  [0.1338, 0.3973]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=4.53, p=1.4e-05
Wilcoxon (p_top2_game vs p_top2_base): statistic=1718.00, p=3.36e-07
Mean Δp_top2 = 0.0310  [0.0176, 0.0444] (n=121)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=4.08, p=8.04e-05
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=2227.00, p=0.000153
Mean ΔH_unchosen_baseline_set = 0.2205  [0.1147, 0.3263] (n=121)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  121
Model:                          Logit   Df Residuals:                      118
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.03363
Time:                        16:14:03   Log-Likelihood:                -79.280
converged:                       True   LL-Null:                       -82.039
Covariance Type:            nonrobust   LLR p-value:                   0.06337
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept        0.6166      0.315      1.957      0.050      -0.001       1.234
p1_z            -0.4975      0.215     -2.316      0.021      -0.918      -0.077
I(p1_z ** 2)    -0.2508      0.248     -1.012      0.311      -0.737       0.235
================================================================================
AUC = 0.597

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.05933
Time:                        16:14:03   Log-Likelihood:                -281.06
converged:                       True   LL-Null:                       -298.78
Covariance Type:            nonrobust   LLR p-value:                 2.614e-09
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.7952      0.117     -6.803      0.000      -1.024      -0.566
game_entropy     1.6218      0.288      5.629      0.000       1.057       2.186
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=24816.50, p=0.00019
Paired t-test (game_entropy vs capabilities_entropy): statistic=-4.35, p=1.69e-05
Mean game_entropy-capabilities_entropy = -0.0972  [-0.1410, -0.0534] (n=447)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      444
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.08434
Time:                        16:14:03   Log-Likelihood:                -273.58
converged:                       True   LL-Null:                       -298.78
Covariance Type:            nonrobust   LLR p-value:                 1.139e-11
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -0.9838      0.130     -7.581      0.000      -1.238      -0.729
capabilities_entropy     0.8728      0.228      3.826      0.000       0.426       1.320
game_entropy             1.2283      0.309      3.978      0.000       0.623       1.833
========================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                0.001197
Time:                        16:14:03   Log-Likelihood:                -298.42
converged:                       True   LL-Null:                       -298.78
Covariance Type:            nonrobust   LLR p-value:                    0.3977
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -0.1106      0.413     -0.268      0.789      -0.921       0.699
human_difficulty    -0.1437      0.170     -0.844      0.399      -0.477       0.190
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      440
Method:                           MLE   Df Model:                            6
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.01936
Time:                        16:14:03   Log-Likelihood:                -293.00
converged:                       True   LL-Null:                       -298.78
Covariance Type:            nonrobust   LLR p-value:                   0.07236
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -0.7414      1.476     -0.502      0.615      -3.635       2.152
C(domain_grouped)[T.chemistry]        0.7224      0.317      2.280      0.023       0.101       1.343
C(domain_grouped)[T.physics]          0.3283      0.322      1.019      0.308      -0.303       0.959
human_difficulty                     -0.0874      0.178     -0.492      0.623      -0.435       0.261
q_length                              0.2399      0.163      1.472      0.141      -0.080       0.559
avg_word_length                      -0.2604      0.171     -1.524      0.127      -0.595       0.074
percent_non_alphabetic_whitespace    -0.0194      0.018     -1.050      0.294      -0.056       0.017
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 0.3030
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      439
Method:                           MLE   Df Model:                            7
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.06469
Time:                        16:14:03   Log-Likelihood:                -279.46
converged:                       True   LL-Null:                       -298.78
Covariance Type:            nonrobust   LLR p-value:                 2.275e-06
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -1.7623      1.514     -1.164      0.244      -4.730       1.205
C(domain_grouped)[T.chemistry]        0.4082      0.329      1.242      0.214      -0.236       1.052
C(domain_grouped)[T.physics]          0.1037      0.333      0.312      0.755      -0.548       0.756
human_difficulty                     -0.0753      0.184     -0.409      0.683      -0.437       0.286
q_length                              0.2546      0.169      1.510      0.131      -0.076       0.585
avg_word_length                      -0.1155      0.173     -0.668      0.504      -0.454       0.223
percent_non_alphabetic_whitespace    -0.0061      0.019     -0.325      0.745      -0.043       0.031
capabilities_entropy                  1.1134      0.221      5.037      0.000       0.680       1.547
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      439
Method:                           MLE   Df Model:                            7
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.06635
Time:                        16:14:03   Log-Likelihood:                -278.96
converged:                       True   LL-Null:                       -298.78
Covariance Type:            nonrobust   LLR p-value:                 1.470e-06
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -1.1128      1.505     -0.739      0.460      -4.063       1.837
C(domain_grouped)[T.chemistry]        0.5073      0.326      1.554      0.120      -0.132       1.147
C(domain_grouped)[T.physics]          0.2061      0.331      0.622      0.534      -0.443       0.855
human_difficulty                     -0.0469      0.185     -0.254      0.799      -0.409       0.315
q_length                              0.1411      0.168      0.841      0.400      -0.188       0.470
avg_word_length                      -0.1253      0.173     -0.726      0.468      -0.464       0.213
percent_non_alphabetic_whitespace    -0.0119      0.019     -0.631      0.528      -0.049       0.025
game_entropy                          1.4937      0.295      5.059      0.000       0.915       2.072
=====================================================================================================

                  Model 4.95: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      438
Method:                           MLE   Df Model:                            8
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.08846
Time:                        16:14:03   Log-Likelihood:                -272.35
converged:                       True   LL-Null:                       -298.78
Covariance Type:            nonrobust   LLR p-value:                 1.148e-08
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -1.7787      1.533     -1.161      0.246      -4.783       1.225
C(domain_grouped)[T.chemistry]        0.3241      0.333      0.973      0.331      -0.329       0.977
C(domain_grouped)[T.physics]          0.0667      0.337      0.198      0.843      -0.594       0.727
human_difficulty                     -0.0483      0.189     -0.256      0.798      -0.418       0.321
q_length                              0.1743      0.172      1.016      0.310      -0.162       0.511
avg_word_length                      -0.0490      0.174     -0.283      0.778      -0.389       0.291
percent_non_alphabetic_whitespace    -0.0042      0.019     -0.218      0.827      -0.042       0.033
capabilities_entropy                  0.8437      0.235      3.597      0.000       0.384       1.303
game_entropy                          1.1557      0.313      3.687      0.000       0.541       1.770
=====================================================================================================

--- Analyzing gpt-4o-2024-08-06 (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_new/gpt-4o-2024-08-06_GPQA_redacted_cor_temp1.0_1757988603_game_data.json', './sc_logs_new/gpt-4o-2024-08-06_GPQA_redacted_temp1.0_1757987499_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    322
1    125
Name: count, dtype: int64

Answer change%: 0.2796 [0.23803473762474414, 0.32124937870635206] (n=447)
P-value vs 25%: 0.1626; P-value vs 0%: 1.257e-39
Phase 2 self-accuracy: 0.3680 [0.2834574130189166, 0.4525425869810834] (n=125)
P-value vs 25%: 0.006226; P-value vs 33%: 0.4171

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1448
Time:                        16:14:03   Log-Likelihood:                -226.54
converged:                       True   LL-Null:                       -264.90
Covariance Type:            nonrobust   LLR p-value:                 1.963e-18
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          2.2201      0.389      5.701      0.000       1.457       2.983
p_i_capability    -4.4775      0.557     -8.039      0.000      -5.569      -3.386
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1373
Time:                        16:14:03   Log-Likelihood:                -228.54
converged:                       True   LL-Null:                       -264.90
Covariance Type:            nonrobust   LLR p-value:                 1.494e-17
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.4539      0.249     -9.857      0.000      -2.942      -1.966
capabilities_entropy     1.5265      0.198      7.700      0.000       1.138       1.915
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.5600 [0.4730, 0.6470] (n=125)
                  P-value vs 33.3%: 3.302e-07

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=-0.54, p=0.588
Wilcoxon delta_p: statistic=18913.00, p=0.213
Mean Δp = -0.0060  [-0.0279, 0.0158]
Idea 1 N = 287; 

  Idea 1.5: Calibration Metrics
  NLL: 2.1674, Signed ECE (overconf pos under neg): -0.0088, ECE: 0.1037 (n=412)
  Brier: 0.0520, Reliability (absolute calibration error; lower better): 0.0224, Resolution (relative calibration quality; higher better): 0.2070, Uncertainty: 0.2375 (n=412)
  AUROC: 0.9958

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.380
Model:                            OLS   Adj. R-squared:                  0.376
Method:                 Least Squares   F-statistic:                     83.48
Date:                Wed, 24 Sep 2025   Prob (F-statistic):           3.96e-42
Time:                        16:14:03   Log-Likelihood:                 56.224
No. Observations:                 412   AIC:                            -104.4
Df Residuals:                     408   BIC:                            -88.36
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.1897      0.049     -3.891      0.000      -0.286      -0.094
p1                    0.2341      0.060      3.898      0.000       0.116       0.352
answer_changed       -0.0221      0.082     -0.269      0.788      -0.184       0.139
p1:answer_changed     0.5965      0.121      4.948      0.000       0.359       0.833
==============================================================================
Omnibus:                       18.637   Durbin-Watson:                   1.939
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               37.335
Skew:                          -0.233   Prob(JB):                     7.81e-09
Kurtosis:                       4.399   Cond. No.                         18.8
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=5.12, p=5.5e-07
Wilcoxon delta_H: statistic=13478.00, p=3.28e-07
Mean ΔH = 0.1440  [0.0889, 0.1991]
Paired t-test delta_H Changed: statistic=7.66, p=4.54e-12
Wilcoxon delta_H Changed: statistic=1145.00, p=5.96e-12
Mean ΔH Changed = 0.3111  [0.2315, 0.3907]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=7.48, p=4.42e-13
Wilcoxon (p_top2_game vs p_top2_base): statistic=22909.00, p=4.79e-16
Mean Δp_top2 = 0.0341  [0.0252, 0.0431] (n=412)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=8.32, p=1.34e-15
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=22848.00, p=3.89e-16
Mean ΔH_unchosen_baseline_set = 0.1947  [0.1488, 0.2406] (n=412)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  412
Model:                          Logit   Df Residuals:                      409
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1318
Time:                        16:14:03   Log-Likelihood:                -219.52
converged:                       True   LL-Null:                       -252.85
Covariance Type:            nonrobust   LLR p-value:                 3.331e-15
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.6766      0.171     -3.965      0.000      -1.011      -0.342
p1_z            -1.0451      0.148     -7.060      0.000      -1.335      -0.755
I(p1_z ** 2)    -0.3652      0.149     -2.456      0.014      -0.657      -0.074
================================================================================
AUC = 0.745

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1039
Time:                        16:14:03   Log-Likelihood:                -237.39
converged:                       True   LL-Null:                       -264.90
Covariance Type:            nonrobust   LLR p-value:                 1.191e-13
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -2.0701      0.212     -9.756      0.000      -2.486      -1.654
game_entropy     1.3915      0.200      6.972      0.000       1.000       1.783
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=32742.00, p=2.32e-10
Paired t-test (game_entropy vs capabilities_entropy): statistic=-6.49, p=2.33e-10
Mean game_entropy-capabilities_entropy = -0.1447  [-0.1885, -0.1010] (n=447)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      444
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1456
Time:                        16:14:03   Log-Likelihood:                -226.32
converged:                       True   LL-Null:                       -264.90
Covariance Type:            nonrobust   LLR p-value:                 1.763e-17
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.5604      0.257     -9.958      0.000      -3.064      -2.056
capabilities_entropy     1.1752      0.257      4.579      0.000       0.672       1.678
game_entropy             0.5580      0.266      2.100      0.036       0.037       1.079
========================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                0.006466
Time:                        16:14:03   Log-Likelihood:                -263.19
converged:                       True   LL-Null:                       -264.90
Covariance Type:            nonrobust   LLR p-value:                   0.06420
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -0.1353      0.451     -0.300      0.764      -1.018       0.748
human_difficulty    -0.3457      0.189     -1.832      0.067      -0.716       0.024
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      440
Method:                           MLE   Df Model:                            6
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.02134
Time:                        16:14:03   Log-Likelihood:                -259.25
converged:                       True   LL-Null:                       -264.90
Covariance Type:            nonrobust   LLR p-value:                   0.07937
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                             1.0894      1.640      0.664      0.506      -2.124       4.303
C(domain_grouped)[T.chemistry]        0.6284      0.367      1.711      0.087      -0.091       1.348
C(domain_grouped)[T.physics]          0.6056      0.370      1.635      0.102      -0.120       1.332
human_difficulty                     -0.2558      0.193     -1.323      0.186      -0.635       0.123
q_length                             -0.0635      0.177     -0.359      0.719      -0.410       0.283
avg_word_length                      -0.2979      0.195     -1.524      0.127      -0.681       0.085
percent_non_alphabetic_whitespace    -0.0263      0.020     -1.290      0.197      -0.066       0.014
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 0.8514
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      439
Method:                           MLE   Df Model:                            7
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1424
Time:                        16:14:03   Log-Likelihood:                -227.18
converged:                       True   LL-Null:                       -264.90
Covariance Type:            nonrobust   LLR p-value:                 1.167e-13
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -0.1998      1.677     -0.119      0.905      -3.486       3.087
C(domain_grouped)[T.chemistry]       -0.2961      0.415     -0.713      0.476      -1.110       0.518
C(domain_grouped)[T.physics]         -0.1769      0.421     -0.421      0.674      -1.002       0.648
human_difficulty                     -0.1909      0.209     -0.913      0.361      -0.600       0.219
q_length                             -0.1527      0.188     -0.811      0.417      -0.522       0.216
avg_word_length                      -0.1288      0.188     -0.684      0.494      -0.498       0.240
percent_non_alphabetic_whitespace    -0.0156      0.020     -0.765      0.445      -0.055       0.024
capabilities_entropy                  1.5453      0.212      7.306      0.000       1.131       1.960
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      439
Method:                           MLE   Df Model:                            7
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1095
Time:                        16:14:03   Log-Likelihood:                -235.88
converged:                       True   LL-Null:                       -264.90
Covariance Type:            nonrobust   LLR p-value:                 3.720e-10
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -0.0953      1.680     -0.057      0.955      -3.388       3.197
C(domain_grouped)[T.chemistry]       -0.0042      0.395     -0.011      0.992      -0.779       0.771
C(domain_grouped)[T.physics]          0.1348      0.400      0.337      0.736      -0.649       0.919
human_difficulty                     -0.1990      0.204     -0.974      0.330      -0.599       0.201
q_length                             -0.1500      0.187     -0.803      0.422      -0.516       0.216
avg_word_length                      -0.1144      0.191     -0.599      0.549      -0.489       0.260
percent_non_alphabetic_whitespace    -0.0150      0.021     -0.726      0.468      -0.055       0.025
game_entropy                          1.3596      0.210      6.473      0.000       0.948       1.771
=====================================================================================================

                  Model 4.95: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      438
Method:                           MLE   Df Model:                            8
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1508
Time:                        16:14:03   Log-Likelihood:                -224.96
converged:                       True   LL-Null:                       -264.90
Covariance Type:            nonrobust   LLR p-value:                 5.152e-14
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -0.3759      1.686     -0.223      0.824      -3.681       2.929
C(domain_grouped)[T.chemistry]       -0.3597      0.418     -0.861      0.390      -1.179       0.460
C(domain_grouped)[T.physics]         -0.2191      0.424     -0.517      0.605      -1.050       0.612
human_difficulty                     -0.1867      0.210     -0.888      0.375      -0.599       0.226
q_length                             -0.1662      0.190     -0.877      0.381      -0.538       0.205
avg_word_length                      -0.0949      0.189     -0.502      0.616      -0.465       0.276
percent_non_alphabetic_whitespace    -0.0140      0.021     -0.682      0.495      -0.054       0.026
capabilities_entropy                  1.2044      0.264      4.554      0.000       0.686       1.723
game_entropy                          0.5668      0.270      2.103      0.035       0.038       1.095
=====================================================================================================

--- Analyzing gpt-4o-mini (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_new/gpt-4o-mini_GPQA_redacted_cor_temp1.0_1757988839_game_data.json', './sc_logs_new/gpt-4o-mini_GPQA_redacted_temp1.0_1757987785_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    303
1    144
Name: count, dtype: int64

Answer change%: 0.3221 [0.2788275593713588, 0.365467742642064] (n=447)
P-value vs 25%: 0.001098; P-value vs 0%: 4.041e-48
Phase 2 self-accuracy: 0.3611 [0.28265984836243213, 0.4395623738597901] (n=144)
P-value vs 25%: 0.005505; P-value vs 33%: 0.4825

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.02665
Time:                        16:14:03   Log-Likelihood:                -273.44
converged:                       True   LL-Null:                       -280.93
Covariance Type:            nonrobust   LLR p-value:                 0.0001091
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          0.8336      0.417      1.999      0.046       0.016       1.651
p_i_capability    -1.9821      0.515     -3.849      0.000      -2.991      -0.973
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.03106
Time:                        16:14:03   Log-Likelihood:                -272.20
converged:                       True   LL-Null:                       -280.93
Covariance Type:            nonrobust   LLR p-value:                 2.949e-05
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.2632      0.168     -7.498      0.000      -1.593      -0.933
capabilities_entropy     0.7447      0.181      4.122      0.000       0.391       1.099
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.2979 [0.2224, 0.3734] (n=141)
                  P-value vs 33.3%: 0.3572

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=15.28, p=2.33e-38
Wilcoxon delta_p: statistic=4598.00, p=1.51e-26
Mean Δp = 0.4412  [0.3846, 0.4978]
Idea 1 N = 270; 

  Idea 1.5: Calibration Metrics
  NLL: 4.5774, Signed ECE (overconf pos under neg): -0.0441, ECE: 0.3423 (n=411)
  Brier: 0.3383, Reliability (absolute calibration error; lower better): 0.1338, Resolution (relative calibration quality; higher better): 0.0065, Uncertainty: 0.2107 (n=411)
  AUROC: 0.4386

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.273
Model:                            OLS   Adj. R-squared:                  0.268
Method:                 Least Squares   F-statistic:                     50.93
Date:                Wed, 24 Sep 2025   Prob (F-statistic):           5.70e-28
Time:                        16:14:03   Log-Likelihood:                -190.86
No. Observations:                 411   AIC:                             389.7
Df Residuals:                     407   BIC:                             405.8
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.5190      0.104     -4.978      0.000      -0.724      -0.314
p1                    1.1803      0.125      9.455      0.000       0.935       1.426
answer_changed        0.0297      0.163      0.183      0.855      -0.290       0.349
p1:answer_changed     0.0932      0.203      0.459      0.647      -0.306       0.493
==============================================================================
Omnibus:                      458.341   Durbin-Watson:                   1.999
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               51.336
Skew:                          -0.586   Prob(JB):                     7.12e-12
Kurtosis:                       1.726   Cond. No.                         20.2
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=5.87, p=1.27e-08
Wilcoxon delta_H: statistic=11067.00, p=1.84e-08
Mean ΔH = 0.1982  [0.1320, 0.2643]
Paired t-test delta_H Changed: statistic=4.17, p=5.27e-05
Wilcoxon delta_H Changed: statistic=3066.00, p=6.56e-05
Mean ΔH Changed = 0.2061  [0.1093, 0.3029]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=4.36, p=1.68e-05
Wilcoxon (p_top2_game vs p_top2_base): statistic=30917.00, p=2.16e-06
Mean Δp_top2 = 0.0173  [0.0095, 0.0251] (n=411)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=7.21, p=2.77e-12
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=25682.00, p=4.85e-12
Mean ΔH_unchosen_baseline_set = 0.2009  [0.1462, 0.2555] (n=411)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  411
Model:                          Logit   Df Residuals:                      408
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.01784
Time:                        16:14:04   Log-Likelihood:                -259.58
converged:                       True   LL-Null:                       -264.29
Covariance Type:            nonrobust   LLR p-value:                  0.008958
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.6931      0.169     -4.103      0.000      -1.024      -0.362
p1_z            -0.3018      0.125     -2.410      0.016      -0.547      -0.056
I(p1_z ** 2)     0.0291      0.134      0.218      0.828      -0.233       0.291
================================================================================
AUC = 0.599

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1143
Time:                        16:14:04   Log-Likelihood:                -248.81
converged:                       True   LL-Null:                       -280.93
Covariance Type:            nonrobust   LLR p-value:                 1.103e-15
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.8383      0.193     -9.537      0.000      -2.216      -1.460
game_entropy     1.7128      0.229      7.474      0.000       1.264       2.162
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=39755.00, p=0.000477
Paired t-test (game_entropy vs capabilities_entropy): statistic=-3.08, p=0.00217
Mean game_entropy-capabilities_entropy = -0.0818  [-0.1338, -0.0298] (n=447)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      444
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1155
Time:                        16:14:04   Log-Likelihood:                -248.48
converged:                       True   LL-Null:                       -280.93
Covariance Type:            nonrobust   LLR p-value:                 8.082e-15
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.9072      0.212     -8.978      0.000      -2.324      -1.491
capabilities_entropy     0.1694      0.208      0.815      0.415      -0.238       0.577
game_entropy             1.6329      0.249      6.564      0.000       1.145       2.120
========================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                0.007932
Time:                        16:14:04   Log-Likelihood:                -278.70
converged:                       True   LL-Null:                       -280.93
Covariance Type:            nonrobust   LLR p-value:                   0.03477
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept            0.1459      0.434      0.336      0.737      -0.705       0.997
human_difficulty    -0.3789      0.182     -2.087      0.037      -0.735      -0.023
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      440
Method:                           MLE   Df Model:                            6
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.01566
Time:                        16:14:04   Log-Likelihood:                -276.53
converged:                       True   LL-Null:                       -280.93
Covariance Type:            nonrobust   LLR p-value:                    0.1853
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -0.9536      1.512     -0.631      0.528      -3.917       2.009
C(domain_grouped)[T.chemistry]        0.1312      0.324      0.405      0.686      -0.504       0.767
C(domain_grouped)[T.physics]          0.1738      0.329      0.528      0.597      -0.471       0.819
human_difficulty                     -0.4029      0.188     -2.146      0.032      -0.771      -0.035
q_length                              0.2821      0.171      1.654      0.098      -0.052       0.616
avg_word_length                      -0.1178      0.172     -0.684      0.494      -0.455       0.220
percent_non_alphabetic_whitespace    -0.0119      0.019     -0.624      0.533      -0.049       0.026
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 0.6558
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      439
Method:                           MLE   Df Model:                            7
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.04376
Time:                        16:14:04   Log-Likelihood:                -268.64
converged:                       True   LL-Null:                       -280.93
Covariance Type:            nonrobust   LLR p-value:                 0.0008976
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -1.3665      1.507     -0.907      0.364      -4.320       1.587
C(domain_grouped)[T.chemistry]       -0.1990      0.341     -0.584      0.560      -0.867       0.469
C(domain_grouped)[T.physics]         -0.0521      0.342     -0.152      0.879      -0.723       0.619
human_difficulty                     -0.3674      0.191     -1.928      0.054      -0.741       0.006
q_length                              0.2598      0.171      1.519      0.129      -0.075       0.595
avg_word_length                      -0.0866      0.169     -0.512      0.608      -0.418       0.245
percent_non_alphabetic_whitespace    -0.0084      0.019     -0.432      0.666      -0.047       0.030
capabilities_entropy                  0.7459      0.190      3.929      0.000       0.374       1.118
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      439
Method:                           MLE   Df Model:                            7
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1237
Time:                        16:14:04   Log-Likelihood:                -246.19
converged:                       True   LL-Null:                       -280.93
Covariance Type:            nonrobust   LLR p-value:                 1.881e-12
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -1.7949      1.615     -1.112      0.266      -4.959       1.370
C(domain_grouped)[T.chemistry]       -0.4286      0.357     -1.200      0.230      -1.129       0.271
C(domain_grouped)[T.physics]         -0.2710      0.363     -0.747      0.455      -0.982       0.440
human_difficulty                     -0.3034      0.203     -1.498      0.134      -0.700       0.094
q_length                              0.2265      0.186      1.215      0.224      -0.139       0.592
avg_word_length                      -0.0895      0.177     -0.505      0.613      -0.437       0.258
percent_non_alphabetic_whitespace     0.0023      0.021      0.111      0.911      -0.038       0.043
game_entropy                          1.7277      0.237      7.279      0.000       1.262       2.193
=====================================================================================================

                  Model 4.95: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      438
Method:                           MLE   Df Model:                            8
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1253
Time:                        16:14:04   Log-Likelihood:                -245.73
converged:                       True   LL-Null:                       -280.93
Covariance Type:            nonrobust   LLR p-value:                 4.090e-12
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -1.8809      1.611     -1.168      0.243      -5.038       1.276
C(domain_grouped)[T.chemistry]       -0.4881      0.363     -1.344      0.179      -1.200       0.224
C(domain_grouped)[T.physics]         -0.3149      0.367     -0.857      0.391      -1.035       0.405
human_difficulty                     -0.2991      0.203     -1.475      0.140      -0.697       0.098
q_length                              0.2264      0.186      1.219      0.223      -0.137       0.590
avg_word_length                      -0.0837      0.176     -0.475      0.635      -0.429       0.262
percent_non_alphabetic_whitespace     0.0028      0.021      0.136      0.892      -0.038       0.043
capabilities_entropy                  0.2054      0.214      0.961      0.337      -0.214       0.625
game_entropy                          1.6394      0.254      6.453      0.000       1.141       2.137
=====================================================================================================

--- Analyzing grok-3-latest (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_new/grok-3-latest_GPQA_redacted_cor_temp0.0_1751718817_game_data.json', './sc_logs_new/grok-3-latest_GPQA_redacted_temp0.0_1751719817_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    328
1    119
Name: count, dtype: int64

Answer change%: 0.2662 [0.22524629171821187, 0.30719218702899176] (n=447)
P-value vs 25%: 0.4378; P-value vs 0%: 3.791e-37
Phase 2 self-accuracy: 0.3193 [0.2355628537906747, 0.4030926083941992] (n=119)
P-value vs 25%: 0.1048; P-value vs 33%: 0.749

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.01139
Time:                        16:14:04   Log-Likelihood:                -256.07
converged:                       True   LL-Null:                       -259.02
Covariance Type:            nonrobust   LLR p-value:                   0.01512
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept         -0.1112      0.377     -0.295      0.768      -0.850       0.628
p_i_capability    -1.0426      0.422     -2.472      0.013      -1.869      -0.216
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  433
Model:                          Logit   Df Residuals:                      431
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.09024
Time:                        16:14:04   Log-Likelihood:                -228.01
converged:                       True   LL-Null:                       -250.63
Covariance Type:            nonrobust   LLR p-value:                 1.750e-11
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.6296      0.155    -10.523      0.000      -1.933      -1.326
capabilities_entropy     1.7688      0.271      6.518      0.000       1.237       2.301
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.7105 [0.6273, 0.7938] (n=114)
                  P-value vs 33.3%: 6.676e-19

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=3.61, p=0.000353
Wilcoxon delta_p: statistic=15077.00, p=5.69e-08
Mean Δp = 0.0328  [0.0150, 0.0506]
Idea 1 N = 306; 

  Idea 1.5: Calibration Metrics
  NLL: 3.7898, Signed ECE (overconf pos under neg): 0.0021, ECE: 0.0384 (n=420)
  Brier: 0.0094, Reliability (absolute calibration error; lower better): 0.0079, Resolution (relative calibration quality; higher better): 0.2470, Uncertainty: 0.2482 (n=420)
  AUROC: 1.0000

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.832
Model:                            OLS   Adj. R-squared:                  0.831
Method:                 Least Squares   F-statistic:                     685.9
Date:                Wed, 24 Sep 2025   Prob (F-statistic):          1.34e-160
Time:                        16:14:04   Log-Likelihood:                 212.81
No. Observations:                 420   AIC:                            -417.6
Df Residuals:                     416   BIC:                            -401.5
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.4708      0.071     -6.644      0.000      -0.610      -0.332
p1                    0.5330      0.074      7.157      0.000       0.387       0.679
answer_changed        0.3702      0.105      3.519      0.000       0.163       0.577
p1:answer_changed     0.4340      0.116      3.740      0.000       0.206       0.662
==============================================================================
Omnibus:                      162.477   Durbin-Watson:                   2.048
Prob(Omnibus):                  0.000   Jarque-Bera (JB):              790.761
Skew:                           1.619   Prob(JB):                    1.94e-172
Kurtosis:                       8.891   Cond. No.                         34.3
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=0.30, p=0.766
Wilcoxon delta_H: statistic=22815.00, p=0.665
Mean ΔH = 0.0083  [-0.0462, 0.0628]
Paired t-test delta_H Changed: statistic=4.18, p=5.87e-05
Wilcoxon delta_H Changed: statistic=1943.00, p=0.000161
Mean ΔH Changed = 0.1632  [0.0866, 0.2398]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=-1.52, p=0.13
Wilcoxon (p_top2_game vs p_top2_base): statistic=30870.00, p=8.45e-08
Mean Δp_top2 = -0.0037  [-0.0085, 0.0011] (n=420)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=2.18, p=0.0299
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=38731.00, p=0.0279
Mean ΔH_unchosen_baseline_set = 0.0503  [0.0051, 0.0956] (n=420)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  420
Model:                          Logit   Df Residuals:                      417
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.08826
Time:                        16:14:04   Log-Likelihood:                -223.89
converged:                       True   LL-Null:                       -245.56
Covariance Type:            nonrobust   LLR p-value:                 3.863e-10
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.7482      0.146     -5.128      0.000      -1.034      -0.462
p1_z            -1.2350      0.222     -5.572      0.000      -1.669      -0.801
I(p1_z ** 2)    -0.3323      0.100     -3.334      0.001      -0.528      -0.137
================================================================================
AUC = 0.780

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1186
Time:                        16:14:04   Log-Likelihood:                -228.29
converged:                       True   LL-Null:                       -259.02
Covariance Type:            nonrobust   LLR p-value:                 4.535e-15
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.8881      0.175    -10.795      0.000      -2.231      -1.545
game_entropy     1.8730      0.251      7.459      0.000       1.381       2.365
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=33000.00, p=8.06e-08
Paired t-test (game_entropy vs capabilities_entropy): statistic=4.68, p=3.86e-06
Mean game_entropy-capabilities_entropy = 0.0993  [0.0577, 0.1409] (n=433)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  433
Model:                          Logit   Df Residuals:                      430
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1421
Time:                        16:14:04   Log-Likelihood:                -215.01
converged:                       True   LL-Null:                       -250.63
Covariance Type:            nonrobust   LLR p-value:                 3.395e-16
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.0785      0.193    -10.793      0.000      -2.456      -1.701
capabilities_entropy     1.1812      0.297      3.973      0.000       0.598       1.764
game_entropy             1.3938      0.275      5.062      0.000       0.854       1.933
========================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                0.002963
Time:                        16:14:04   Log-Likelihood:                -258.25
converged:                       True   LL-Null:                       -259.02
Covariance Type:            nonrobust   LLR p-value:                    0.2154
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -0.4642      0.456     -1.018      0.308      -1.357       0.429
human_difficulty    -0.2337      0.190     -1.231      0.218      -0.606       0.138
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      440
Method:                           MLE   Df Model:                            6
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.01363
Time:                        16:14:04   Log-Likelihood:                -255.49
converged:                       True   LL-Null:                       -259.02
Covariance Type:            nonrobust   LLR p-value:                    0.3152
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -1.5351      1.571     -0.977      0.329      -4.614       1.544
C(domain_grouped)[T.chemistry]        0.7490      0.364      2.060      0.039       0.036       1.461
C(domain_grouped)[T.physics]          0.6567      0.373      1.760      0.078      -0.075       1.388
human_difficulty                     -0.1816      0.195     -0.932      0.352      -0.564       0.200
q_length                             -0.0636      0.175     -0.362      0.717      -0.407       0.280
avg_word_length                       0.1690      0.173      0.979      0.328      -0.169       0.507
percent_non_alphabetic_whitespace    -0.0061      0.020     -0.307      0.759      -0.045       0.033
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 0.2951
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  433
Model:                          Logit   Df Residuals:                      425
Method:                           MLE   Df Model:                            7
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.09956
Time:                        16:14:04   Log-Likelihood:                -225.68
converged:                       True   LL-Null:                       -250.63
Covariance Type:            nonrobust   LLR p-value:                 1.506e-08
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -2.6184      1.648     -1.589      0.112      -5.848       0.611
C(domain_grouped)[T.chemistry]        0.3177      0.388      0.818      0.413      -0.443       1.079
C(domain_grouped)[T.physics]          0.1536      0.405      0.379      0.705      -0.640       0.947
human_difficulty                     -0.2012      0.208     -0.965      0.334      -0.610       0.207
q_length                             -0.0101      0.187     -0.054      0.957      -0.376       0.356
avg_word_length                       0.2747      0.178      1.542      0.123      -0.074       0.624
percent_non_alphabetic_whitespace     0.0043      0.021      0.207      0.836      -0.036       0.045
capabilities_entropy                  1.8090      0.282      6.423      0.000       1.257       2.361
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      439
Method:                           MLE   Df Model:                            7
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1340
Time:                        16:14:04   Log-Likelihood:                -224.30
converged:                       True   LL-Null:                       -259.02
Covariance Type:            nonrobust   LLR p-value:                 1.923e-12
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -3.5498      1.701     -2.087      0.037      -6.883      -0.216
C(domain_grouped)[T.chemistry]        0.5342      0.392      1.363      0.173      -0.234       1.302
C(domain_grouped)[T.physics]          0.6967      0.409      1.704      0.088      -0.105       1.498
human_difficulty                     -0.2388      0.211     -1.133      0.257      -0.652       0.174
q_length                             -0.0574      0.189     -0.304      0.761      -0.427       0.312
avg_word_length                       0.4145      0.187      2.213      0.027       0.047       0.782
percent_non_alphabetic_whitespace     0.0100      0.021      0.466      0.641      -0.032       0.052
game_entropy                          1.9507      0.261      7.487      0.000       1.440       2.461
=====================================================================================================

                  Model 4.95: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  433
Model:                          Logit   Df Residuals:                      424
Method:                           MLE   Df Model:                            8
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1549
Time:                        16:14:04   Log-Likelihood:                -211.80
converged:                       True   LL-Null:                       -250.63
Covariance Type:            nonrobust   LLR p-value:                 1.442e-13
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -3.6297      1.717     -2.114      0.035      -6.996      -0.264
C(domain_grouped)[T.chemistry]        0.2344      0.407      0.576      0.564      -0.563       1.032
C(domain_grouped)[T.physics]          0.2972      0.427      0.696      0.487      -0.540       1.134
human_difficulty                     -0.2522      0.216     -1.167      0.243      -0.676       0.171
q_length                             -0.0291      0.193     -0.151      0.880      -0.407       0.348
avg_word_length                       0.4153      0.188      2.205      0.027       0.046       0.785
percent_non_alphabetic_whitespace     0.0138      0.022      0.640      0.522      -0.029       0.056
capabilities_entropy                  1.2169      0.309      3.934      0.000       0.611       1.823
game_entropy                          1.4784      0.284      5.205      0.000       0.922       2.035
=====================================================================================================

--- Analyzing qwen3-235b-a22b-2507 (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_new/qwen3-235b-a22b-2507_GPQA_redacted_cor_temp0.0_1756235281_game_data.json', './sc_logs_new/qwen3-235b-a22b-2507_GPQA_redacted_temp0.0_1756233720_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    326
1    121
Name: count, dtype: int64

Answer change%: 0.2707 [0.22950384429701254, 0.31188318031148854] (n=447)
P-value vs 25%: 0.3248; P-value vs 0%: 5.785e-38
Phase 2 self-accuracy: 0.2975 [0.21606322273406486, 0.37897809957998474] (n=121)
P-value vs 25%: 0.2529; P-value vs 33%: 0.3933

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.05636
Time:                        16:14:04   Log-Likelihood:                -246.31
converged:                       True   LL-Null:                       -261.02
Covariance Type:            nonrobust   LLR p-value:                 5.816e-08
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          1.9413      0.548      3.540      0.000       0.866       3.016
p_i_capability    -3.3458      0.622     -5.383      0.000      -4.564      -2.128
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.05771
Time:                        16:14:04   Log-Likelihood:                -245.96
converged:                       True   LL-Null:                       -261.02
Covariance Type:            nonrobust   LLR p-value:                 4.047e-08
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.4749      0.148     -9.966      0.000      -1.765      -1.185
capabilities_entropy     1.1150      0.205      5.439      0.000       0.713       1.517
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.7190 [0.6389, 0.7991] (n=121)
                  P-value vs 33.3%: 3.784e-21

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=2.52, p=0.0125
Wilcoxon delta_p: statistic=11675.00, p=1.31e-05
Mean Δp = 0.0297  [0.0066, 0.0529]
Idea 1 N = 263; 

  Idea 1.5: Calibration Metrics
  NLL: 6.4714, Signed ECE (overconf pos under neg): -0.0125, ECE: 0.0522 (n=367)
  Brier: 0.0243, Reliability (absolute calibration error; lower better): 0.0126, Resolution (relative calibration quality; higher better): 0.2376, Uncertainty: 0.2492 (n=367)
  AUROC: 0.9972

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.786
Model:                            OLS   Adj. R-squared:                  0.784
Method:                 Least Squares   F-statistic:                     453.8
Date:                Wed, 24 Sep 2025   Prob (F-statistic):          9.51e-124
Time:                        16:14:04   Log-Likelihood:                 135.81
No. Observations:                 375   AIC:                            -263.6
Df Residuals:                     371   BIC:                            -247.9
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.6154      0.064     -9.607      0.000      -0.741      -0.489
p1                    0.7082      0.069     10.207      0.000       0.572       0.845
answer_changed        0.2825      0.096      2.952      0.003       0.094       0.471
p1:answer_changed     0.4813      0.109      4.426      0.000       0.267       0.695
==============================================================================
Omnibus:                       51.559   Durbin-Watson:                   1.941
Prob(Omnibus):                  0.000   Jarque-Bera (JB):              190.597
Skew:                           0.541   Prob(JB):                     4.10e-42
Kurtosis:                       6.321   Cond. No.                         25.6
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-8.01, p=3.68e-14
Wilcoxon delta_H: statistic=8575.00, p=2.95e-12
Mean ΔH = -0.2971  [-0.3698, -0.2244]
Paired t-test delta_H Changed: statistic=0.38, p=0.703
Wilcoxon delta_H Changed: statistic=3218.00, p=0.994
Mean ΔH Changed = 0.0205  [-0.0847, 0.1257]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=-1.11, p=0.268
Wilcoxon (p_top2_game vs p_top2_base): statistic=22832.00, p=3.38e-09
Mean Δp_top2 = -0.0033  [-0.0092, 0.0026] (n=376)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=-6.42, p=4.14e-10
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=22718.00, p=3.62e-09
Mean ΔH_unchosen_baseline_set = -0.2017  [-0.2632, -0.1401] (n=376)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  376
Model:                          Logit   Df Residuals:                      373
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.04544
Time:                        16:14:04   Log-Likelihood:                -219.41
converged:                       True   LL-Null:                       -229.85
Covariance Type:            nonrobust   LLR p-value:                 2.910e-05
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.7592      0.170     -4.478      0.000      -1.091      -0.427
p1_z            -0.6640      0.212     -3.139      0.002      -1.079      -0.249
I(p1_z ** 2)    -0.1297      0.130     -0.997      0.319      -0.385       0.125
================================================================================
AUC = 0.642

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1319
Time:                        16:14:04   Log-Likelihood:                -226.60
converged:                       True   LL-Null:                       -261.02
Covariance Type:            nonrobust   LLR p-value:                 1.064e-16
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.9869      0.185    -10.730      0.000      -2.350      -1.624
game_entropy     1.8372      0.236      7.792      0.000       1.375       2.299
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=35325.00, p=0.000207
Paired t-test (game_entropy vs capabilities_entropy): statistic=2.88, p=0.00416
Mean game_entropy-capabilities_entropy = 0.0788  [0.0252, 0.1325] (n=447)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      444
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1508
Time:                        16:14:04   Log-Likelihood:                -221.66
converged:                       True   LL-Null:                       -261.02
Covariance Type:            nonrobust   LLR p-value:                 8.060e-18
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.1830      0.201    -10.854      0.000      -2.577      -1.789
capabilities_entropy     0.7147      0.226      3.159      0.002       0.271       1.158
game_entropy             1.6364      0.244      6.693      0.000       1.157       2.116
========================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:               0.0001198
Time:                        16:14:04   Log-Likelihood:                -260.99
converged:                       True   LL-Null:                       -261.02
Covariance Type:            nonrobust   LLR p-value:                    0.8025
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -0.8809      0.453     -1.945      0.052      -1.769       0.007
human_difficulty    -0.0465      0.186     -0.250      0.803      -0.412       0.318
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      440
Method:                           MLE   Df Model:                            6
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.01733
Time:                        16:14:04   Log-Likelihood:                -256.50
converged:                       True   LL-Null:                       -261.02
Covariance Type:            nonrobust   LLR p-value:                    0.1710
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -1.5412      1.580     -0.975      0.329      -4.638       1.556
C(domain_grouped)[T.chemistry]        0.8367      0.359      2.329      0.020       0.132       1.541
C(domain_grouped)[T.physics]          0.4021      0.372      1.080      0.280      -0.328       1.132
human_difficulty                      0.0656      0.195      0.336      0.737      -0.317       0.448
q_length                             -0.0826      0.175     -0.471      0.637      -0.426       0.261
avg_word_length                       0.0607      0.175      0.348      0.728      -0.281       0.403
percent_non_alphabetic_whitespace     0.0080      0.019      0.414      0.679      -0.030       0.046
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 0.3771
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      439
Method:                           MLE   Df Model:                            7
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.06690
Time:                        16:14:04   Log-Likelihood:                -243.56
converged:                       True   LL-Null:                       -261.02
Covariance Type:            nonrobust   LLR p-value:                 1.156e-05
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -2.0818      1.611     -1.292      0.196      -5.239       1.076
C(domain_grouped)[T.chemistry]        0.5207      0.373      1.395      0.163      -0.211       1.252
C(domain_grouped)[T.physics]          0.1727      0.385      0.449      0.653      -0.581       0.927
human_difficulty                      0.0933      0.202      0.461      0.645      -0.303       0.490
q_length                             -0.0685      0.180     -0.380      0.704      -0.421       0.284
avg_word_length                       0.0865      0.178      0.487      0.626      -0.261       0.434
percent_non_alphabetic_whitespace     0.0134      0.020      0.670      0.503      -0.026       0.052
capabilities_entropy                  1.0589      0.210      5.042      0.000       0.647       1.470
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      439
Method:                           MLE   Df Model:                            7
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1478
Time:                        16:14:04   Log-Likelihood:                -222.44
converged:                       True   LL-Null:                       -261.02
Covariance Type:            nonrobust   LLR p-value:                 5.183e-14
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -3.0384      1.699     -1.789      0.074      -6.367       0.291
C(domain_grouped)[T.chemistry]        0.4808      0.388      1.238      0.216      -0.280       1.242
C(domain_grouped)[T.physics]          0.1368      0.402      0.340      0.734      -0.652       0.925
human_difficulty                      0.1027      0.209      0.492      0.623      -0.307       0.512
q_length                             -0.1786      0.192     -0.928      0.353      -0.556       0.199
avg_word_length                       0.2922      0.184      1.585      0.113      -0.069       0.654
percent_non_alphabetic_whitespace     0.0241      0.021      1.145      0.252      -0.017       0.065
game_entropy                          1.9040      0.247      7.694      0.000       1.419       2.389
=====================================================================================================

                  Model 4.95: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      438
Method:                           MLE   Df Model:                            8
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1642
Time:                        16:14:04   Log-Likelihood:                -218.16
converged:                       True   LL-Null:                       -261.02
Covariance Type:            nonrobust   LLR p-value:                 3.426e-15
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -3.2410      1.712     -1.893      0.058      -6.597       0.115
C(domain_grouped)[T.chemistry]        0.3227      0.395      0.816      0.414      -0.452       1.097
C(domain_grouped)[T.physics]          0.0168      0.409      0.041      0.967      -0.785       0.818
human_difficulty                      0.1190      0.212      0.561      0.574      -0.296       0.534
q_length                             -0.1648      0.195     -0.844      0.399      -0.548       0.218
avg_word_length                       0.2909      0.185      1.569      0.117      -0.072       0.654
percent_non_alphabetic_whitespace     0.0255      0.021      1.192      0.233      -0.016       0.067
capabilities_entropy                  0.6792      0.231      2.937      0.003       0.226       1.132
game_entropy                          1.7315      0.255      6.779      0.000       1.231       2.232
=====================================================================================================
