
--- Analyzing claude-3-5-sonnet-20241022 (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_new/claude-3-5-sonnet-20241022_GPQA_redacted_cor_temp0.0_1753836130_game_data.json', './sc_logs_new/claude-3-5-sonnet-20241022_GPQA_redacted_temp0.0_1753884209_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    324
1    123
Name: count, dtype: int64

Answer change%: 0.2752 [0.23376668647873367, 0.316568883991065] (n=447)
P-value vs 25%: 0.2335; P-value vs 0%: 8.628e-39
Phase 2 self-accuracy: 0.2602 [0.1826296872038196, 0.33769551604821296] (n=123)
P-value vs 25%: 0.7973; P-value vs 33%: 0.06558

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:                  0.2050
Time:                        20:46:32   Log-Likelihood:                -209.06
converged:                       True   LL-Null:                       -262.98
Covariance Type:            nonrobust   LLR p-value:                 2.913e-25
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          2.8057      0.404      6.950      0.000       2.015       3.597
p_i_capability    -5.5970      0.612     -9.151      0.000      -6.796      -4.398
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:                  0.2096
Time:                        20:46:32   Log-Likelihood:                -207.86
converged:                       True   LL-Null:                       -262.98
Covariance Type:            nonrobust   LLR p-value:                 8.630e-26
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -3.4591      0.331    -10.443      0.000      -4.108      -2.810
capabilities_entropy     2.1974      0.243      9.037      0.000       1.721       2.674
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.6341 [0.5490, 0.7193] (n=123)
                  P-value vs 33.3%: 4.32e-12

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=-3.78, p=0.000185
Wilcoxon delta_p: statistic=9139.00, p=2.8e-05
Mean Δp = -0.0325  [-0.0494, -0.0157]
Idea 1 N = 324; 

  Idea 1.5: Calibration Metrics
  NLL: 1.6241, Signed ECE (overconf pos under neg): -0.0105, ECE: 0.1124 (n=447)
  Brier: 0.0494, Reliability (absolute calibration error; lower better): 0.0241, Resolution (relative calibration quality; higher better): 0.2211, Uncertainty: 0.2459 (n=447)
  AUROC: 0.9959

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.696
Model:                            OLS   Adj. R-squared:                  0.694
Method:                 Least Squares   F-statistic:                     338.1
Date:                Thu, 18 Sep 2025   Prob (F-statistic):          4.00e-114
Time:                        20:46:32   Log-Likelihood:                 267.93
No. Observations:                 447   AIC:                            -527.9
Df Residuals:                     443   BIC:                            -511.4
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.3523      0.031    -11.506      0.000      -0.412      -0.292
p1                    0.4044      0.038     10.764      0.000       0.331       0.478
answer_changed        0.1134      0.052      2.175      0.030       0.011       0.216
p1:answer_changed     0.6334      0.082      7.752      0.000       0.473       0.794
==============================================================================
Omnibus:                       25.809   Durbin-Watson:                   2.026
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               30.060
Skew:                           0.542   Prob(JB):                     2.97e-07
Kurtosis:                       3.664   Cond. No.                         20.2
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=0.29, p=0.77
Wilcoxon delta_H: statistic=13407.50, p=0.829
Mean ΔH = 0.0071  [-0.0403, 0.0545]
Paired t-test delta_H Changed: statistic=9.44, p=3.28e-16
Wilcoxon delta_H Changed: statistic=737.00, p=8.24e-15
Mean ΔH Changed = 0.3288  [0.2605, 0.3971]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=5.95, p=5.51e-09
Wilcoxon (p_top2_game vs p_top2_base): statistic=20658.50, p=1.07e-08
Mean Δp_top2 = 0.0232  [0.0155, 0.0308] (n=447)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=4.54, p=7.39e-06
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=22645.50, p=2.64e-06
Mean ΔH_unchosen_baseline_set = 0.0956  [0.0543, 0.1369] (n=447)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      444
Method:                           MLE   Df Model:                            2
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:                  0.2294
Time:                        20:46:32   Log-Likelihood:                -202.67
converged:                       True   LL-Null:                       -262.98
Covariance Type:            nonrobust   LLR p-value:                 6.380e-27
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.8792      0.173     -5.068      0.000      -1.219      -0.539
p1_z            -1.6293      0.202     -8.068      0.000      -2.025      -1.233
I(p1_z ** 2)    -0.5733      0.165     -3.483      0.000      -0.896      -0.251
================================================================================
AUC = 0.805

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:                  0.1888
Time:                        20:46:32   Log-Likelihood:                -213.33
converged:                       True   LL-Null:                       -262.98
Covariance Type:            nonrobust   LLR p-value:                 2.159e-23
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -3.0396      0.283    -10.742      0.000      -3.594      -2.485
game_entropy     2.0871      0.233      8.944      0.000       1.630       2.544
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=19918.50, p=1.06e-09
Paired t-test (game_entropy vs capabilities_entropy): statistic=-6.15, p=1.71e-09
Mean capabilities_entropy-game_entropy = 0.1118  [0.0762, 0.1475] (n=447)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      444
Method:                           MLE   Df Model:                            2
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:                  0.2295
Time:                        20:46:32   Log-Likelihood:                -202.62
converged:                       True   LL-Null:                       -262.98
Covariance Type:            nonrobust   LLR p-value:                 6.073e-27
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -3.6616      0.343    -10.681      0.000      -4.333      -2.990
capabilities_entropy     1.4754      0.325      4.533      0.000       0.837       2.113
game_entropy             1.0243      0.320      3.204      0.001       0.398       1.651
========================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:               0.0009190
Time:                        20:46:32   Log-Likelihood:                -262.74
converged:                       True   LL-Null:                       -262.98
Covariance Type:            nonrobust   LLR p-value:                    0.4869
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -0.6637      0.450     -1.473      0.141      -1.547       0.219
human_difficulty    -0.1291      0.186     -0.693      0.488      -0.494       0.236
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      440
Method:                           MLE   Df Model:                            6
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:                 0.03029
Time:                        20:46:32   Log-Likelihood:                -255.02
converged:                       True   LL-Null:                       -262.98
Covariance Type:            nonrobust   LLR p-value:                   0.01413
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                             0.1836      1.685      0.109      0.913      -3.119       3.486
C(domain_grouped)[T.chemistry]        0.8987      0.396      2.267      0.023       0.122       1.676
C(domain_grouped)[T.physics]          0.8852      0.398      2.225      0.026       0.105       1.665
human_difficulty                      0.0176      0.193      0.092      0.927      -0.360       0.395
q_length                             -0.0294      0.180     -0.163      0.870      -0.382       0.323
avg_word_length                      -0.3730      0.204     -1.830      0.067      -0.772       0.026
percent_non_alphabetic_whitespace    -0.0110      0.020     -0.550      0.582      -0.050       0.028
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 0.9810
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      439
Method:                           MLE   Df Model:                            7
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:                  0.2199
Time:                        20:46:32   Log-Likelihood:                -205.17
converged:                       True   LL-Null:                       -262.98
Covariance Type:            nonrobust   LLR p-value:                 6.202e-22
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -2.9717      1.922     -1.546      0.122      -6.739       0.796
C(domain_grouped)[T.chemistry]       -0.0246      0.456     -0.054      0.957      -0.919       0.869
C(domain_grouped)[T.physics]          0.4377      0.459      0.953      0.340      -0.462       1.337
human_difficulty                      0.0270      0.221      0.122      0.903      -0.406       0.460
q_length                             -0.1574      0.208     -0.758      0.449      -0.565       0.250
avg_word_length                      -0.0059      0.223     -0.027      0.979      -0.443       0.431
percent_non_alphabetic_whitespace     0.0206      0.023      0.915      0.360      -0.024       0.065
capabilities_entropy                  2.2264      0.257      8.670      0.000       1.723       2.730
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      439
Method:                           MLE   Df Model:                            7
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:                  0.1979
Time:                        20:46:32   Log-Likelihood:                -210.94
converged:                       True   LL-Null:                       -262.98
Covariance Type:            nonrobust   LLR p-value:                 1.547e-19
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -2.5689      1.894     -1.356      0.175      -6.281       1.144
C(domain_grouped)[T.chemistry]        0.0107      0.445      0.024      0.981      -0.862       0.883
C(domain_grouped)[T.physics]          0.4344      0.447      0.971      0.332      -0.442       1.311
human_difficulty                     -0.0108      0.220     -0.049      0.961      -0.442       0.420
q_length                             -0.1117      0.200     -0.557      0.577      -0.505       0.281
avg_word_length                      -0.0282      0.219     -0.129      0.898      -0.457       0.400
percent_non_alphabetic_whitespace     0.0164      0.022      0.751      0.453      -0.026       0.059
game_entropy                          2.0882      0.247      8.462      0.000       1.605       2.572
=====================================================================================================

                  Model 4.95: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      438
Method:                           MLE   Df Model:                            8
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:                  0.2399
Time:                        20:46:32   Log-Likelihood:                -199.90
converged:                       True   LL-Null:                       -262.98
Covariance Type:            nonrobust   LLR p-value:                 1.766e-23
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -3.3567      1.948     -1.723      0.085      -7.175       0.461
C(domain_grouped)[T.chemistry]       -0.2390      0.461     -0.519      0.604      -1.142       0.664
C(domain_grouped)[T.physics]          0.2988      0.460      0.650      0.516      -0.603       1.200
human_difficulty                      0.0056      0.226      0.025      0.980      -0.438       0.449
q_length                             -0.1497      0.210     -0.714      0.475      -0.560       0.261
avg_word_length                       0.0506      0.225      0.225      0.822      -0.391       0.492
percent_non_alphabetic_whitespace     0.0249      0.023      1.097      0.273      -0.020       0.069
capabilities_entropy                  1.5272      0.332      4.602      0.000       0.877       2.178
game_entropy                          1.0462      0.325      3.214      0.001       0.408       1.684
=====================================================================================================

--- Analyzing claude-3-haiku-20240307 (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_new/claude-3-haiku-20240307_GPQA_redacted_cor_temp0.0_1751757100_game_data.json', './sc_logs_new/claude-3-haiku-20240307_GPQA_redacted_temp0.0_1754158953_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    337
1     94
Name: count, dtype: int64

Answer change%: 0.2181 [0.1791112337366507, 0.25708366185499665] (n=431)
P-value vs 25%: 0.1087; P-value vs 0%: 5.663e-28
Phase 2 self-accuracy: 0.1596 [0.0855431493217682, 0.23360578684844457] (n=94)
P-value vs 25%: 0.01667; P-value vs 33%: 4.403e-06

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  431
Model:                          Logit   Df Residuals:                      429
Method:                           MLE   Df Model:                            1
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:                 0.06110
Time:                        20:46:32   Log-Likelihood:                -212.24
converged:                       True   LL-Null:                       -226.05
Covariance Type:            nonrobust   LLR p-value:                 1.474e-07
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          2.2976      0.675      3.402      0.001       0.974       3.621
p_i_capability    -4.0707      0.768     -5.299      0.000      -5.576      -2.565
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  431
Model:                          Logit   Df Residuals:                      429
Method:                           MLE   Df Model:                            1
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:                 0.07496
Time:                        20:46:32   Log-Likelihood:                -209.11
converged:                       True   LL-Null:                       -226.05
Covariance Type:            nonrobust   LLR p-value:                 5.835e-09
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.3394      0.230    -10.185      0.000      -2.790      -1.889
capabilities_entropy     2.1546      0.372      5.790      0.000       1.425       2.884
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.3511 [0.2546, 0.4476] (n=94)
                  P-value vs 33.3%: 0.7187

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=-0.11, p=0.916
Wilcoxon delta_p: statistic=1719.00, p=0.409
Mean Δp = -0.0009  [-0.0172, 0.0154]
Idea 1 N = 238; 

  Idea 1.5: Calibration Metrics
  NLL: 4.2117, Signed ECE (overconf pos under neg): 0.0400, ECE: 0.0400 (n=295)
  Brier: 0.0110, Reliability (absolute calibration error; lower better): 0.0108, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=295)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.896
Model:                            OLS   Adj. R-squared:                  0.894
Method:                 Least Squares   F-statistic:                     831.8
Date:                Thu, 18 Sep 2025   Prob (F-statistic):          2.27e-142
Time:                        20:46:32   Log-Likelihood:                 262.11
No. Observations:                 295   AIC:                            -516.2
Df Residuals:                     291   BIC:                            -501.5
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.7563      0.054    -13.998      0.000      -0.863      -0.650
p1                    0.8219      0.058     14.084      0.000       0.707       0.937
answer_changed        0.7436      0.078      9.484      0.000       0.589       0.898
p1:answer_changed     0.0617      0.091      0.676      0.500      -0.118       0.241
==============================================================================
Omnibus:                       64.875   Durbin-Watson:                   1.936
Prob(Omnibus):                  0.000   Jarque-Bera (JB):              199.051
Skew:                           0.954   Prob(JB):                     5.98e-44
Kurtosis:                       6.543   Cond. No.                         31.3
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=2.25, p=0.0253
Wilcoxon delta_H: statistic=1417.50, p=0.0356
Mean ΔH = 0.0856  [0.0111, 0.1601]
Paired t-test delta_H Changed: statistic=6.66, p=1.28e-08
Wilcoxon delta_H Changed: statistic=179.00, p=2.65e-07
Mean ΔH Changed = 0.5699  [0.4021, 0.7378]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=1.28, p=0.202
Wilcoxon (p_top2_game vs p_top2_base): statistic=3725.00, p=0.0575
Mean Δp_top2 = 0.0025  [-0.0013, 0.0063] (n=295)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=4.90, p=1.55e-06
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=2810.50, p=1.54e-06
Mean ΔH_unchosen_baseline_set = 0.1792  [0.1076, 0.2508] (n=295)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  295
Model:                          Logit   Df Residuals:                      292
Method:                           MLE   Df Model:                            2
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:                  0.1285
Time:                        20:46:32   Log-Likelihood:                -126.20
converged:                       True   LL-Null:                       -144.80
Covariance Type:            nonrobust   LLR p-value:                 8.328e-09
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.2894      0.222     -5.802      0.000      -1.725      -0.854
p1_z            -1.4134      0.374     -3.778      0.000      -2.147      -0.680
I(p1_z ** 2)    -0.3189      0.167     -1.913      0.056      -0.646       0.008
================================================================================
AUC = 0.741

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  295
Model:                          Logit   Df Residuals:                      293
Method:                           MLE   Df Model:                            1
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:                 0.09078
Time:                        20:46:32   Log-Likelihood:                -131.66
converged:                       True   LL-Null:                       -144.80
Covariance Type:            nonrobust   LLR p-value:                 2.939e-07
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -2.7137      0.313     -8.680      0.000      -3.326      -2.101
game_entropy     2.5620      0.503      5.089      0.000       1.575       3.549
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=4529.00, p=0.893
Paired t-test (game_entropy vs capabilities_entropy): statistic=-0.16, p=0.873
Mean capabilities_entropy-game_entropy = 0.0033  [-0.0370, 0.0436] (n=295)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  295
Model:                          Logit   Df Residuals:                      292
Method:                           MLE   Df Model:                            2
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:                  0.2039
Time:                        20:46:32   Log-Likelihood:                -115.28
converged:                       True   LL-Null:                       -144.80
Covariance Type:            nonrobust   LLR p-value:                 1.501e-13
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -4.0098      0.441     -9.086      0.000      -4.875      -3.145
capabilities_entropy     2.7036      0.487      5.554      0.000       1.749       3.658
game_entropy             2.3242      0.538      4.319      0.000       1.270       3.379
========================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  431
Model:                          Logit   Df Residuals:                      429
Method:                           MLE   Df Model:                            1
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:                0.004529
Time:                        20:46:32   Log-Likelihood:                -225.03
converged:                       True   LL-Null:                       -226.05
Covariance Type:            nonrobust   LLR p-value:                    0.1525
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -0.5818      0.498     -1.168      0.243      -1.558       0.395
human_difficulty    -0.2957      0.208     -1.418      0.156      -0.704       0.113
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None
                    Model 4: Using clustered standard errors by q_id.

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  431
Model:                          Logit   Df Residuals:                      424
Method:                           MLE   Df Model:                            6
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:                 0.01897
Time:                        20:46:32   Log-Likelihood:                -221.77
converged:                       True   LL-Null:                       -226.05
Covariance Type:              cluster   LLR p-value:                    0.1988
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -2.5983      1.702     -1.526      0.127      -5.935       0.739
C(domain_grouped)[T.chemistry]        0.9333      0.416      2.243      0.025       0.118       1.749
C(domain_grouped)[T.physics]          0.5637      0.419      1.345      0.179      -0.258       1.385
human_difficulty                     -0.2274      0.198     -1.148      0.251      -0.616       0.161
q_length                              0.1577      0.197      0.798      0.425      -0.229       0.545
avg_word_length                       0.0677      0.189      0.358      0.720      -0.303       0.438
percent_non_alphabetic_whitespace    -0.0041      0.025     -0.162      0.872      -0.053       0.045
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 0.4517
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  431
Model:                          Logit   Df Residuals:                      423
Method:                           MLE   Df Model:                            7
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:                 0.09177
Time:                        20:46:33   Log-Likelihood:                -205.31
converged:                       True   LL-Null:                       -226.05
Covariance Type:            nonrobust   LLR p-value:                 6.512e-07
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -3.9883      1.793     -2.225      0.026      -7.502      -0.474
C(domain_grouped)[T.chemistry]        0.9206      0.425      2.167      0.030       0.088       1.753
C(domain_grouped)[T.physics]          0.6108      0.442      1.382      0.167      -0.255       1.477
human_difficulty                     -0.1869      0.227     -0.824      0.410      -0.631       0.258
q_length                              0.0922      0.200      0.460      0.645      -0.300       0.485
avg_word_length                       0.2072      0.194      1.067      0.286      -0.173       0.588
percent_non_alphabetic_whitespace    -0.0109      0.023     -0.479      0.632      -0.056       0.034
capabilities_entropy                  2.1986      0.389      5.649      0.000       1.436       2.961
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  295
Model:                          Logit   Df Residuals:                      287
Method:                           MLE   Df Model:                            7
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:                  0.1181
Time:                        20:46:33   Log-Likelihood:                -127.70
converged:                       True   LL-Null:                       -144.80
Covariance Type:            nonrobust   LLR p-value:                 1.571e-05
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -2.8860      2.463     -1.172      0.241      -7.713       1.941
C(domain_grouped)[T.chemistry]        0.6304      0.563      1.119      0.263      -0.474       1.735
C(domain_grouped)[T.physics]          0.1193      0.587      0.203      0.839      -1.031       1.269
human_difficulty                     -0.3807      0.298     -1.276      0.202      -0.965       0.204
q_length                              0.4127      0.261      1.581      0.114      -0.099       0.924
avg_word_length                      -0.3518      0.302     -1.166      0.244      -0.943       0.240
percent_non_alphabetic_whitespace    -0.0155      0.028     -0.555      0.579      -0.070       0.039
game_entropy                          2.5382      0.525      4.835      0.000       1.509       3.567
=====================================================================================================

                  Model 4.95: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  295
Model:                          Logit   Df Residuals:                      286
Method:                           MLE   Df Model:                            8
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:                  0.2209
Time:                        20:46:33   Log-Likelihood:                -112.82
converged:                       True   LL-Null:                       -144.80
Covariance Type:            nonrobust   LLR p-value:                 7.702e-11
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -4.3852      2.679     -1.637      0.102      -9.635       0.865
C(domain_grouped)[T.chemistry]        0.4202      0.599      0.701      0.483      -0.754       1.594
C(domain_grouped)[T.physics]          0.0378      0.629      0.060      0.952      -1.195       1.270
human_difficulty                     -0.4127      0.317     -1.302      0.193      -1.034       0.209
q_length                              0.3660      0.278      1.317      0.188      -0.179       0.911
avg_word_length                      -0.1907      0.323     -0.590      0.555      -0.824       0.442
percent_non_alphabetic_whitespace    -0.0181      0.029     -0.620      0.536      -0.075       0.039
capabilities_entropy                  2.6347      0.499      5.275      0.000       1.656       3.614
game_entropy                          2.3412      0.559      4.188      0.000       1.245       3.437
=====================================================================================================

--- Analyzing claude-3-sonnet-20240229 (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_new/claude-3-sonnet-20240229_GPQA_redacted_cor_temp0.0_1751757247_game_data.json', './sc_logs_new/claude-3-sonnet-20240229_GPQA_redacted_temp0.0_1751717405_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    330
1    117
Name: count, dtype: int64

Answer change%: 0.2617 [0.2209941131354173, 0.3024958197504888] (n=447)
P-value vs 25%: 0.5721; P-value vs 0%: 2.429e-36
Phase 2 self-accuracy: 0.2393 [0.16200487855195683, 0.3166276000805218] (n=117)
P-value vs 25%: 0.7865; P-value vs 33%: 0.01755

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:               2.631e-06
Time:                        20:46:33   Log-Likelihood:                -256.97
converged:                       True   LL-Null:                       -256.97
Covariance Type:            nonrobust   LLR p-value:                    0.9707
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -1.0205      0.458     -2.228      0.026      -1.918      -0.123
human_difficulty    -0.0069      0.188     -0.037      0.971      -0.375       0.361
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      440
Method:                           MLE   Df Model:                            6
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:                 0.01053
Time:                        20:46:33   Log-Likelihood:                -254.26
converged:                       True   LL-Null:                       -256.97
Covariance Type:            nonrobust   LLR p-value:                    0.4925
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -0.2722      1.631     -0.167      0.867      -3.469       2.925
C(domain_grouped)[T.chemistry]        0.6042      0.354      1.705      0.088      -0.090       1.299
C(domain_grouped)[T.physics]          0.3561      0.360      0.988      0.323      -0.350       1.063
human_difficulty                      0.0504      0.194      0.260      0.795      -0.330       0.431
q_length                              0.0065      0.177      0.036      0.971      -0.341       0.354
avg_word_length                      -0.2332      0.191     -1.218      0.223      -0.608       0.142
percent_non_alphabetic_whitespace    -0.0304      0.021     -1.439      0.150      -0.072       0.011
=====================================================================================================

--- Analyzing claude-sonnet-4-20250514 (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_new/claude-sonnet-4-20250514_GPQA_redacted_cor_temp0.0_1751759117_game_data.json', './sc_logs_new/claude-sonnet-4-20250514_GPQA_redacted_temp0.0_1751718415_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    302
1    145
Name: count, dtype: int64

Answer change%: 0.3244 [0.2809863314563348, 0.36778324348773683] (n=447)
P-value vs 25%: 0.0007812; P-value vs 0%: 1.349e-48
Phase 2 self-accuracy: 0.3034 [0.22861700639943466, 0.37827954532470326] (n=145)
P-value vs 25%: 0.1615; P-value vs 33%: 0.4389

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:                0.001427
Time:                        20:46:33   Log-Likelihood:                -281.27
converged:                       True   LL-Null:                       -281.67
Covariance Type:            nonrobust   LLR p-value:                    0.3699
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -0.3584      0.430     -0.833      0.405      -1.202       0.485
human_difficulty    -0.1589      0.178     -0.894      0.371      -0.507       0.190
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      440
Method:                           MLE   Df Model:                            6
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:                 0.01484
Time:                        20:46:33   Log-Likelihood:                -277.49
converged:                       True   LL-Null:                       -281.67
Covariance Type:            nonrobust   LLR p-value:                    0.2129
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -1.4790      1.499     -0.986      0.324      -4.418       1.460
C(domain_grouped)[T.chemistry]        0.5197      0.320      1.623      0.104      -0.108       1.147
C(domain_grouped)[T.physics]         -0.0058      0.331     -0.018      0.986      -0.654       0.642
human_difficulty                     -0.1558      0.186     -0.836      0.403      -0.521       0.210
q_length                              0.2446      0.169      1.449      0.147      -0.086       0.575
avg_word_length                      -0.0935      0.168     -0.556      0.579      -0.423       0.236
percent_non_alphabetic_whitespace    -0.0146      0.019     -0.759      0.448      -0.052       0.023
=====================================================================================================

--- Analyzing deepseek-chat (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_new/deepseek-chat_GPQA_redacted_cor_temp0.0_1753813587_game_data.json', './sc_logs_new/deepseek-chat_GPQA_redacted_temp0.0_1753995526_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    372
1     70
Name: count, dtype: int64

Answer change%: 0.1584 [0.1243353023278091, 0.1924067791201547] (n=442)
P-value vs 25%: 1.317e-07; P-value vs 0%: 7.521e-20
Phase 2 self-accuracy: 0.3521 [0.24101384534522574, 0.46321150676745027] (n=71)
P-value vs 25%: 0.07163; P-value vs 33%: 0.736

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  442
Model:                          Logit   Df Residuals:                      440
Method:                           MLE   Df Model:                            1
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:                 0.02324
Time:                        20:46:33   Log-Likelihood:                -188.65
converged:                       True   LL-Null:                       -193.14
Covariance Type:            nonrobust   LLR p-value:                  0.002733
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept         -0.1931      0.491     -0.393      0.694      -1.155       0.769
p_i_capability    -1.8982      0.628     -3.021      0.003      -3.129      -0.667
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  442
Model:                          Logit   Df Residuals:                      440
Method:                           MLE   Df Model:                            1
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:                 0.03471
Time:                        20:46:33   Log-Likelihood:                -186.43
converged:                       True   LL-Null:                       -193.14
Covariance Type:            nonrobust   LLR p-value:                 0.0002505
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.3103      0.238     -9.713      0.000      -2.777      -1.844
capabilities_entropy     0.8176      0.226      3.619      0.000       0.375       1.260
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.3000 [0.1926, 0.4074] (n=70)
                  P-value vs 33.3%: 0.5428

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=21.82, p=2.62e-68
Wilcoxon delta_p: statistic=5185.00, p=2.93e-45
Mean Δp = 0.5235  [0.4764, 0.5705]
Idea 1 N = 369; 

  Idea 1.5: Calibration Metrics
  NLL: 3.6864, Signed ECE (overconf pos under neg): -0.1617, ECE: 0.3741 (n=399)
  Brier: 0.3991, Reliability (absolute calibration error; lower better): 0.1686, Resolution (relative calibration quality; higher better): 0.0162, Uncertainty: 0.2449 (n=399)
  AUROC: 0.4180

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.192
Model:                            OLS   Adj. R-squared:                  0.187
Method:                 Least Squares   F-statistic:                     34.51
Date:                Thu, 18 Sep 2025   Prob (F-statistic):           5.00e-20
Time:                        20:46:33   Log-Likelihood:                -227.80
No. Observations:                 439   AIC:                             463.6
Df Residuals:                     435   BIC:                             479.9
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.2908      0.090     -3.218      0.001      -0.468      -0.113
p1                    0.9991      0.108      9.271      0.000       0.787       1.211
answer_changed       -0.0123      0.218     -0.056      0.955      -0.442       0.417
p1:answer_changed     0.0926      0.283      0.327      0.744      -0.463       0.648
==============================================================================
Omnibus:                      148.836   Durbin-Watson:                   2.038
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               83.713
Skew:                          -0.938   Prob(JB):                     6.64e-19
Kurtosis:                       1.971   Cond. No.                         24.1
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=8.12, p=7e-15
Wilcoxon delta_H: statistic=18367.00, p=3.71e-14
Mean ΔH = 0.3172  [0.2407, 0.3938]
Paired t-test delta_H Changed: statistic=5.39, p=9.29e-07
Wilcoxon delta_H Changed: statistic=416.00, p=2.22e-06
Mean ΔH Changed = 0.3789  [0.2411, 0.5167]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=9.07, p=4.12e-18
Wilcoxon (p_top2_game vs p_top2_base): statistic=35713.00, p=2.26e-06
Mean Δp_top2 = 0.0437  [0.0342, 0.0531] (n=439)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=9.43, p=2.39e-19
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=24556.00, p=1.85e-18
Mean ΔH_unchosen_baseline_set = 0.3270  [0.2591, 0.3950] (n=439)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  439
Model:                          Logit   Df Residuals:                      436
Method:                           MLE   Df Model:                            2
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:                 0.04192
Time:                        20:46:33   Log-Likelihood:                -184.54
converged:                       True   LL-Null:                       -192.62
Covariance Type:            nonrobust   LLR p-value:                 0.0003112
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.3401      0.187     -7.180      0.000      -1.706      -0.974
p1_z            -0.7221      0.188     -3.845      0.000      -1.090      -0.354
I(p1_z ** 2)    -0.4229      0.160     -2.640      0.008      -0.737      -0.109
================================================================================
AUC = 0.654

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  442
Model:                          Logit   Df Residuals:                      440
Method:                           MLE   Df Model:                            1
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:                 0.08544
Time:                        20:46:33   Log-Likelihood:                -176.63
converged:                       True   LL-Null:                       -193.14
Covariance Type:            nonrobust   LLR p-value:                 9.206e-09
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -2.9285      0.274    -10.704      0.000      -3.465      -2.392
game_entropy     2.6190      0.453      5.787      0.000       1.732       3.506
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=28731.00, p=5.27e-14
Paired t-test (game_entropy vs capabilities_entropy): statistic=-9.71, p=2.44e-20
Mean capabilities_entropy-game_entropy = 0.2602  [0.2077, 0.3127] (n=442)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  442
Model:                          Logit   Df Residuals:                      439
Method:                           MLE   Df Model:                            2
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:                 0.09737
Time:                        20:46:33   Log-Likelihood:                -174.33
converged:                       True   LL-Null:                       -193.14
Covariance Type:            nonrobust   LLR p-value:                 6.806e-09
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -3.1930      0.311    -10.273      0.000      -3.802      -2.584
capabilities_entropy     0.5233      0.243      2.149      0.032       0.046       1.001
game_entropy             2.3199      0.469      4.945      0.000       1.400       3.239
========================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  442
Model:                          Logit   Df Residuals:                      440
Method:                           MLE   Df Model:                            1
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:                 0.01104
Time:                        20:46:33   Log-Likelihood:                -191.00
converged:                       True   LL-Null:                       -193.14
Covariance Type:            nonrobust   LLR p-value:                   0.03896
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -0.5536      0.554     -0.999      0.318      -1.640       0.533
human_difficulty    -0.4823      0.238     -2.027      0.043      -0.949      -0.016
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  442
Model:                          Logit   Df Residuals:                      435
Method:                           MLE   Df Model:                            6
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:                 0.03793
Time:                        20:46:33   Log-Likelihood:                -185.81
converged:                       True   LL-Null:                       -193.14
Covariance Type:            nonrobust   LLR p-value:                   0.02314
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -1.6767      1.936     -0.866      0.387      -5.472       2.118
C(domain_grouped)[T.chemistry]        0.7517      0.420      1.789      0.074      -0.072       1.575
C(domain_grouped)[T.physics]          0.0894      0.450      0.198      0.843      -0.793       0.972
human_difficulty                     -0.5311      0.250     -2.122      0.034      -1.022      -0.041
q_length                              0.1776      0.220      0.807      0.419      -0.254       0.609
avg_word_length                       0.0404      0.213      0.189      0.850      -0.377       0.458
percent_non_alphabetic_whitespace    -0.0474      0.028     -1.697      0.090      -0.102       0.007
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 0.6891
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  442
Model:                          Logit   Df Residuals:                      434
Method:                           MLE   Df Model:                            7
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:                 0.07088
Time:                        20:46:33   Log-Likelihood:                -179.45
converged:                       True   LL-Null:                       -193.14
Covariance Type:            nonrobust   LLR p-value:                 0.0002846
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -1.5011      1.928     -0.779      0.436      -5.279       2.277
C(domain_grouped)[T.chemistry]        0.4738      0.437      1.085      0.278      -0.382       1.330
C(domain_grouped)[T.physics]         -0.1005      0.468     -0.215      0.830      -1.018       0.817
human_difficulty                     -0.5667      0.256     -2.212      0.027      -1.069      -0.065
q_length                              0.0905      0.222      0.408      0.684      -0.345       0.526
avg_word_length                       0.0444      0.209      0.213      0.831      -0.364       0.453
percent_non_alphabetic_whitespace    -0.0551      0.029     -1.929      0.054      -0.111       0.001
capabilities_entropy                  0.8459      0.240      3.522      0.000       0.375       1.317
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  442
Model:                          Logit   Df Residuals:                      434
Method:                           MLE   Df Model:                            7
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:                  0.1159
Time:                        20:46:33   Log-Likelihood:                -170.75
converged:                       True   LL-Null:                       -193.14
Covariance Type:            nonrobust   LLR p-value:                 1.509e-07
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -2.0860      1.963     -1.062      0.288      -5.934       1.762
C(domain_grouped)[T.chemistry]        0.3535      0.441      0.802      0.422      -0.510       1.217
C(domain_grouped)[T.physics]         -0.2294      0.470     -0.488      0.626      -1.151       0.693
human_difficulty                     -0.5689      0.263     -2.161      0.031      -1.085      -0.053
q_length                              0.0777      0.232      0.335      0.738      -0.377       0.533
avg_word_length                       0.0687      0.210      0.328      0.743      -0.342       0.480
percent_non_alphabetic_whitespace    -0.0458      0.029     -1.553      0.120      -0.103       0.012
game_entropy                          2.5880      0.472      5.483      0.000       1.663       3.513
=====================================================================================================

                  Model 4.95: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  442
Model:                          Logit   Df Residuals:                      433
Method:                           MLE   Df Model:                            8
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:                  0.1286
Time:                        20:46:33   Log-Likelihood:                -168.30
converged:                       True   LL-Null:                       -193.14
Covariance Type:            nonrobust   LLR p-value:                 4.723e-08
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -1.8536      1.976     -0.938      0.348      -5.727       2.019
C(domain_grouped)[T.chemistry]        0.2098      0.450      0.466      0.641      -0.672       1.092
C(domain_grouped)[T.physics]         -0.3512      0.482     -0.728      0.467      -1.297       0.594
human_difficulty                     -0.5805      0.267     -2.178      0.029      -1.103      -0.058
q_length                              0.0294      0.233      0.126      0.900      -0.428       0.487
avg_word_length                       0.0532      0.209      0.255      0.799      -0.356       0.462
percent_non_alphabetic_whitespace    -0.0504      0.030     -1.688      0.091      -0.109       0.008
capabilities_entropy                  0.5657      0.256      2.209      0.027       0.064       1.068
game_entropy                          2.2975      0.486      4.726      0.000       1.345       3.250
=====================================================================================================

--- Analyzing gemini-1.5-pro (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_new/gemini-1.5-pro_GPQA_redacted_cor_temp0.0_1751757449_game_data.json', './sc_logs_new/gemini-1.5-pro_GPQA_redacted_temp0.0_1751722268_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    369
1     78
Name: count, dtype: int64

Answer change%: 0.1745 [0.13931247588832357, 0.20968081270228045] (n=447)
P-value vs 25%: 2.6e-05; P-value vs 0%: 2.466e-22
Phase 2 self-accuracy: 0.3846 [0.27664927985302107, 0.4925814893777482] (n=78)
P-value vs 25%: 0.01454; P-value vs 33%: 0.3488

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:               0.0004983
Time:                        20:46:33   Log-Likelihood:                -206.83
converged:                       True   LL-Null:                       -206.94
Covariance Type:            nonrobust   LLR p-value:                    0.6497
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -1.7884      0.532     -3.360      0.001      -2.832      -0.745
human_difficulty     0.0984      0.216      0.455      0.649      -0.326       0.522
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      440
Method:                           MLE   Df Model:                            6
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:                0.004551
Time:                        20:46:33   Log-Likelihood:                -205.99
converged:                       True   LL-Null:                       -206.94
Covariance Type:            nonrobust   LLR p-value:                    0.9301
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -0.9685      1.864     -0.520      0.603      -4.622       2.685
C(domain_grouped)[T.chemistry]        0.0932      0.389      0.240      0.811      -0.669       0.856
C(domain_grouped)[T.physics]         -0.0727      0.395     -0.184      0.854      -0.847       0.701
human_difficulty                      0.1193      0.225      0.531      0.595      -0.321       0.560
q_length                              0.0643      0.205      0.314      0.753      -0.337       0.466
avg_word_length                      -0.2482      0.220     -1.129      0.259      -0.679       0.183
percent_non_alphabetic_whitespace    -0.0143      0.024     -0.605      0.545      -0.061       0.032
=====================================================================================================

--- Analyzing gemini-2.0-flash-001 (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_new/gemini-2.0-flash-001_GPQA_redacted_cor_temp1.0_1757989025_game_data.json', './sc_logs_new/gemini-2.0-flash-001_GPQA_redacted_temp1.0_1757988130_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    326
1    121
Name: count, dtype: int64

Answer change%: 0.2707 [0.22950384429701254, 0.31188318031148854] (n=447)
P-value vs 25%: 0.3248; P-value vs 0%: 5.785e-38
Phase 2 self-accuracy: 0.2314 [0.15626161337460054, 0.3065483039807714] (n=121)
P-value vs 25%: 0.6277; P-value vs 33%: 0.008051

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:                 0.07685
Time:                        20:46:33   Log-Likelihood:                -240.97
converged:                       True   LL-Null:                       -261.02
Covariance Type:            nonrobust   LLR p-value:                 2.392e-10
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          3.7691      0.800      4.710      0.000       2.201       5.337
p_i_capability    -5.1306      0.856     -5.996      0.000      -6.808      -3.453
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:                  0.1046
Time:                        20:46:33   Log-Likelihood:                -233.73
converged:                       True   LL-Null:                       -261.02
Covariance Type:            nonrobust   LLR p-value:                 1.480e-13
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.5220      0.140    -10.871      0.000      -1.796      -1.248
capabilities_entropy     2.0048      0.287      6.992      0.000       1.443       2.567
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.5000 [0.4057, 0.5943] (n=108)
                  P-value vs 33.3%: 0.000532

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=6.41, p=1.53e-09
Wilcoxon delta_p: statistic=2671.00, p=1.79e-11
Mean Δp = 0.0954  [0.0662, 0.1246]
Idea 1 N = 164; 

  Idea 1.5: Calibration Metrics
  NLL: 4.9030, Signed ECE (overconf pos under neg): -0.0274, ECE: 0.0410 (n=270)
  Brier: 0.0396, Reliability (absolute calibration error; lower better): 0.0087, Resolution (relative calibration quality; higher better): 0.2094, Uncertainty: 0.2414 (n=270)
  AUROC: 0.9914

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.698
Model:                            OLS   Adj. R-squared:                  0.694
Method:                 Least Squares   F-statistic:                     205.5
Date:                Thu, 18 Sep 2025   Prob (F-statistic):           4.58e-69
Time:                        20:46:33   Log-Likelihood:                 42.485
No. Observations:                 271   AIC:                            -76.97
Df Residuals:                     267   BIC:                            -62.56
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept             0.0966      0.117      0.822      0.412      -0.135       0.328
p1                   -0.0013      0.125     -0.010      0.992      -0.248       0.246
answer_changed       -0.8334      0.160     -5.202      0.000      -1.149      -0.518
p1:answer_changed     1.5975      0.176      9.071      0.000       1.251       1.944
==============================================================================
Omnibus:                        8.349   Durbin-Watson:                   2.038
Prob(Omnibus):                  0.015   Jarque-Bera (JB):               14.968
Skew:                           0.027   Prob(JB):                     0.000562
Kurtosis:                       4.150   Cond. No.                         31.8
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-2.98, p=0.00337
Wilcoxon delta_H: statistic=5133.00, p=0.00737
Mean ΔH = -0.1337  [-0.2218, -0.0456]
Paired t-test delta_H Changed: statistic=0.08, p=0.937
Wilcoxon delta_H Changed: statistic=2910.00, p=0.919
Mean ΔH Changed = 0.0045  [-0.1074, 0.1165]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=-6.83, p=5.71e-11
Wilcoxon (p_top2_game vs p_top2_base): statistic=6491.00, p=1.44e-20
Mean Δp_top2 = -0.0300  [-0.0386, -0.0214] (n=272)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=-2.22, p=0.0273
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=15923.00, p=0.042
Mean ΔH_unchosen_baseline_set = -0.0788  [-0.1484, -0.0092] (n=272)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  272
Model:                          Logit   Df Residuals:                      269
Method:                           MLE   Df Model:                            2
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:                 0.03684
Time:                        20:46:33   Log-Likelihood:                -176.00
converged:                       True   LL-Null:                       -182.73
Covariance Type:            nonrobust   LLR p-value:                  0.001192
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.2399      0.176     -1.360      0.174      -0.586       0.106
p1_z            -0.7216      0.239     -3.018      0.003      -1.190      -0.253
I(p1_z ** 2)    -0.1927      0.126     -1.530      0.126      -0.440       0.054
================================================================================
AUC = 0.660

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:                  0.1610
Time:                        20:46:33   Log-Likelihood:                -219.01
converged:                       True   LL-Null:                       -261.02
Covariance Type:            nonrobust   LLR p-value:                 4.864e-20
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.9764      0.177    -11.175      0.000      -2.323      -1.630
game_entropy     1.8374      0.216      8.503      0.000       1.414       2.261
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=19287.00, p=2.01e-29
Paired t-test (game_entropy vs capabilities_entropy): statistic=9.44, p=2.02e-19
Mean capabilities_entropy-game_entropy = -0.2175  [-0.2627, -0.1724] (n=447)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      444
Method:                           MLE   Df Model:                            2
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:                  0.1883
Time:                        20:46:33   Log-Likelihood:                -211.88
converged:                       True   LL-Null:                       -261.02
Covariance Type:            nonrobust   LLR p-value:                 4.523e-22
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.1191      0.187    -11.347      0.000      -2.485      -1.753
capabilities_entropy     1.2168      0.324      3.753      0.000       0.581       1.852
game_entropy             1.5005      0.233      6.439      0.000       1.044       1.957
========================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:               0.0004758
Time:                        20:46:33   Log-Likelihood:                -260.90
converged:                       True   LL-Null:                       -261.02
Covariance Type:            nonrobust   LLR p-value:                    0.6182
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -0.7715      0.453     -1.704      0.088      -1.659       0.116
human_difficulty    -0.0929      0.187     -0.498      0.619      -0.459       0.273
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      440
Method:                           MLE   Df Model:                            6
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:                 0.02056
Time:                        20:46:33   Log-Likelihood:                -255.66
converged:                       True   LL-Null:                       -261.02
Covariance Type:            nonrobust   LLR p-value:                   0.09697
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -1.1406      1.656     -0.689      0.491      -4.386       2.105
C(domain_grouped)[T.chemistry]        0.8988      0.366      2.454      0.014       0.181       1.617
C(domain_grouped)[T.physics]          0.5167      0.374      1.383      0.167      -0.216       1.249
human_difficulty                     -0.0231      0.194     -0.119      0.905      -0.404       0.357
q_length                              0.1851      0.180      1.029      0.304      -0.168       0.538
avg_word_length                      -0.2770      0.195     -1.418      0.156      -0.660       0.106
percent_non_alphabetic_whitespace    -0.0267      0.021     -1.279      0.201      -0.068       0.014
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 0.2220
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      439
Method:                           MLE   Df Model:                            7
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:                  0.1155
Time:                        20:46:33   Log-Likelihood:                -230.88
converged:                       True   LL-Null:                       -261.02
Covariance Type:            nonrobust   LLR p-value:                 1.320e-10
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -0.9894      1.753     -0.565      0.572      -4.424       2.446
C(domain_grouped)[T.chemistry]        0.6612      0.384      1.721      0.085      -0.092       1.414
C(domain_grouped)[T.physics]          0.3330      0.393      0.847      0.397      -0.438       1.104
human_difficulty                     -0.0441      0.209     -0.211      0.833      -0.454       0.366
q_length                              0.0517      0.192      0.270      0.787      -0.324       0.427
avg_word_length                      -0.1823      0.204     -0.895      0.371      -0.582       0.217
percent_non_alphabetic_whitespace    -0.0370      0.023     -1.632      0.103      -0.081       0.007
capabilities_entropy                  1.9681      0.295      6.669      0.000       1.390       2.546
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      439
Method:                           MLE   Df Model:                            7
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:                  0.1677
Time:                        20:46:33   Log-Likelihood:                -217.24
converged:                       True   LL-Null:                       -261.02
Covariance Type:            nonrobust   LLR p-value:                 3.912e-16
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -2.2999      1.807     -1.273      0.203      -5.841       1.241
C(domain_grouped)[T.chemistry]        0.3148      0.397      0.793      0.428      -0.463       1.093
C(domain_grouped)[T.physics]         -0.0550      0.412     -0.134      0.894      -0.862       0.752
human_difficulty                     -0.1594      0.220     -0.724      0.469      -0.591       0.272
q_length                              0.1632      0.195      0.839      0.402      -0.218       0.545
avg_word_length                      -0.0474      0.205     -0.232      0.817      -0.448       0.354
percent_non_alphabetic_whitespace    -0.0195      0.023     -0.843      0.399      -0.065       0.026
game_entropy                          1.8451      0.228      8.101      0.000       1.399       2.291
=====================================================================================================

                  Model 4.95: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      438
Method:                           MLE   Df Model:                            8
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:                  0.1950
Time:                        20:46:33   Log-Likelihood:                -210.13
converged:                       True   LL-Null:                       -261.02
Covariance Type:            nonrobust   LLR p-value:                 1.832e-18
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -1.9890      1.848     -1.076      0.282      -5.611       1.633
C(domain_grouped)[T.chemistry]        0.2543      0.400      0.636      0.525      -0.530       1.039
C(domain_grouped)[T.physics]         -0.0911      0.417     -0.218      0.827      -0.908       0.726
human_difficulty                     -0.1393      0.227     -0.615      0.539      -0.583       0.305
q_length                              0.0867      0.199      0.435      0.664      -0.304       0.478
avg_word_length                      -0.0360      0.208     -0.173      0.863      -0.444       0.372
percent_non_alphabetic_whitespace    -0.0280      0.024     -1.166      0.244      -0.075       0.019
capabilities_entropy                  1.2318      0.329      3.741      0.000       0.586       1.877
game_entropy                          1.5180      0.243      6.235      0.000       1.041       1.995
=====================================================================================================

--- Analyzing gemini-2.5-flash-lite_nothink (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_new/gemini-2.5-flash-lite_nothink_GPQA_redacted_cor_temp1.0_1757983987_game_data.json', './sc_logs_new/gemini-2.5-flash-lite_nothink_GPQA_redacted_temp1.0_1757983795_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    289
1    158
Name: count, dtype: int64

Answer change%: 0.3535 [0.30915118218300114, 0.39778394085950447] (n=447)
P-value vs 25%: 4.739e-06; P-value vs 0%: 4.361e-55
Phase 2 self-accuracy: 0.3544 [0.2798445097312725, 0.4290162497623984] (n=158)
P-value vs 25%: 0.006066; P-value vs 33%: 0.5733

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:                  0.1609
Time:                        20:46:33   Log-Likelihood:                -243.65
converged:                       True   LL-Null:                       -290.36
Covariance Type:            nonrobust   LLR p-value:                 4.229e-22
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          3.0808      0.422      7.299      0.000       2.254       3.908
p_i_capability    -4.9297      0.558     -8.827      0.000      -6.024      -3.835
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:                  0.1702
Time:                        20:46:33   Log-Likelihood:                -240.93
converged:                       True   LL-Null:                       -290.36
Covariance Type:            nonrobust   LLR p-value:                 2.724e-23
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.1760      0.222     -9.822      0.000      -2.610      -1.742
capabilities_entropy     1.7566      0.197      8.920      0.000       1.371       2.143
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.4430 [0.3656, 0.5205] (n=158)
                  P-value vs 33.3%: 0.005503

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=0.23, p=0.822
Wilcoxon delta_p: statistic=19511.00, p=0.311
Mean Δp = 0.0027  [-0.0211, 0.0265]
Idea 1 N = 289; 

  Idea 1.5: Calibration Metrics
  NLL: 2.3622, Signed ECE (overconf pos under neg): 0.0009, ECE: 0.0326 (n=447)
  Brier: 0.0806, Reliability (absolute calibration error; lower better): 0.0030, Resolution (relative calibration quality; higher better): 0.1575, Uncertainty: 0.2362 (n=447)
  AUROC: 0.9528

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.433
Model:                            OLS   Adj. R-squared:                  0.429
Method:                 Least Squares   F-statistic:                     112.8
Date:                Thu, 18 Sep 2025   Prob (F-statistic):           2.74e-54
Time:                        20:46:33   Log-Likelihood:                 8.2536
No. Observations:                 447   AIC:                            -8.507
Df Residuals:                     443   BIC:                             7.903
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.2755      0.065     -4.215      0.000      -0.404      -0.147
p1                    0.3308      0.076      4.359      0.000       0.182       0.480
answer_changed       -0.2291      0.094     -2.429      0.016      -0.414      -0.044
p1:answer_changed     0.9263      0.127      7.321      0.000       0.678       1.175
==============================================================================
Omnibus:                       11.092   Durbin-Watson:                   2.029
Prob(Omnibus):                  0.004   Jarque-Bera (JB):               20.571
Skew:                           0.029   Prob(JB):                     3.41e-05
Kurtosis:                       4.049   Cond. No.                         20.4
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=0.49, p=0.621
Wilcoxon delta_H: statistic=20006.00, p=0.506
Mean ΔH = 0.0142  [-0.0422, 0.0706]
Paired t-test delta_H Changed: statistic=7.85, p=5.98e-13
Wilcoxon delta_H Changed: statistic=2115.00, p=4.78e-13
Mean ΔH Changed = 0.2924  [0.2194, 0.3654]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=6.74, p=4.81e-11
Wilcoxon (p_top2_game vs p_top2_base): statistic=34751.00, p=2.1e-08
Mean Δp_top2 = 0.0282  [0.0200, 0.0364] (n=447)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=4.76, p=2.56e-06
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=36314.00, p=4.86e-07
Mean ΔH_unchosen_baseline_set = 0.1125  [0.0663, 0.1588] (n=447)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      444
Method:                           MLE   Df Model:                            2
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:                  0.1749
Time:                        20:46:33   Log-Likelihood:                -239.57
converged:                       True   LL-Null:                       -290.36
Covariance Type:            nonrobust   LLR p-value:                 8.784e-23
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.4063      0.158     -2.566      0.010      -0.717      -0.096
p1_z            -1.2573      0.148     -8.494      0.000      -1.547      -0.967
I(p1_z ** 2)    -0.3865      0.134     -2.876      0.004      -0.650      -0.123
================================================================================
AUC = 0.776

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:                  0.1437
Time:                        20:46:33   Log-Likelihood:                -248.64
converged:                       True   LL-Null:                       -290.36
Covariance Type:            nonrobust   LLR p-value:                 6.592e-20
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.9225      0.200     -9.616      0.000      -2.314      -1.531
game_entropy     1.8290      0.219      8.363      0.000       1.400       2.258
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=33392.00, p=1.06e-09
Paired t-test (game_entropy vs capabilities_entropy): statistic=-6.22, p=1.14e-09
Mean capabilities_entropy-game_entropy = 0.1449  [0.0992, 0.1905] (n=447)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      444
Method:                           MLE   Df Model:                            2
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:                  0.1978
Time:                        20:46:33   Log-Likelihood:                -232.94
converged:                       True   LL-Null:                       -290.36
Covariance Type:            nonrobust   LLR p-value:                 1.156e-25
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.4920      0.247    -10.099      0.000      -2.976      -2.008
capabilities_entropy     1.2559      0.231      5.438      0.000       0.803       1.709
game_entropy             1.0421      0.263      3.964      0.000       0.527       1.557
========================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:               0.0009934
Time:                        20:46:33   Log-Likelihood:                -290.07
converged:                       True   LL-Null:                       -290.36
Covariance Type:            nonrobust   LLR p-value:                    0.4475
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -0.2926      0.421     -0.695      0.487      -1.118       0.533
human_difficulty    -0.1316      0.174     -0.758      0.449      -0.472       0.209
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      440
Method:                           MLE   Df Model:                            6
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:                 0.03413
Time:                        20:46:33   Log-Likelihood:                -280.45
converged:                       True   LL-Null:                       -290.36
Covariance Type:            nonrobust   LLR p-value:                  0.002978
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -3.6170      1.534     -2.358      0.018      -6.624      -0.610
C(domain_grouped)[T.chemistry]        1.1081      0.365      3.039      0.002       0.393       1.823
C(domain_grouped)[T.physics]          1.2139      0.370      3.279      0.001       0.488       1.939
human_difficulty                     -0.0104      0.181     -0.057      0.954      -0.365       0.344
q_length                              0.2491      0.169      1.474      0.141      -0.082       0.580
avg_word_length                       0.0750      0.168      0.446      0.656      -0.255       0.405
percent_non_alphabetic_whitespace     0.0257      0.018      1.406      0.160      -0.010       0.062
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 0.8067
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      439
Method:                           MLE   Df Model:                            7
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:                  0.1870
Time:                        20:46:33   Log-Likelihood:                -236.07
converged:                       True   LL-Null:                       -290.36
Covariance Type:            nonrobust   LLR p-value:                 1.814e-20
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -4.9403      1.680     -2.941      0.003      -8.233      -1.648
C(domain_grouped)[T.chemistry]        0.1807      0.414      0.436      0.663      -0.631       0.993
C(domain_grouped)[T.physics]          0.7494      0.416      1.804      0.071      -0.065       1.564
human_difficulty                      0.0109      0.203      0.054      0.957      -0.387       0.409
q_length                              0.0573      0.184      0.311      0.756      -0.303       0.418
avg_word_length                       0.3371      0.181      1.862      0.063      -0.018       0.692
percent_non_alphabetic_whitespace     0.0461      0.020      2.295      0.022       0.007       0.085
capabilities_entropy                  1.8047      0.213      8.479      0.000       1.388       2.222
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      439
Method:                           MLE   Df Model:                            7
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:                  0.1663
Time:                        20:46:33   Log-Likelihood:                -242.07
converged:                       True   LL-Null:                       -290.36
Covariance Type:            nonrobust   LLR p-value:                 5.503e-18
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -4.4595      1.689     -2.640      0.008      -7.770      -1.149
C(domain_grouped)[T.chemistry]        0.7466      0.401      1.864      0.062      -0.038       1.532
C(domain_grouped)[T.physics]          1.1092      0.410      2.708      0.007       0.306       1.912
human_difficulty                      0.0500      0.201      0.249      0.803      -0.344       0.444
q_length                              0.1116      0.183      0.611      0.541      -0.246       0.469
avg_word_length                       0.1418      0.182      0.778      0.436      -0.215       0.499
percent_non_alphabetic_whitespace     0.0362      0.021      1.767      0.077      -0.004       0.076
game_entropy                          1.8161      0.226      8.035      0.000       1.373       2.259
=====================================================================================================

                  Model 4.95: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      438
Method:                           MLE   Df Model:                            8
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:                  0.2152
Time:                        20:46:33   Log-Likelihood:                -227.87
converged:                       True   LL-Null:                       -290.36
Covariance Type:            nonrobust   LLR p-value:                 3.118e-23
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -5.1368      1.738     -2.956      0.003      -8.542      -1.731
C(domain_grouped)[T.chemistry]        0.2476      0.425      0.583      0.560      -0.585       1.080
C(domain_grouped)[T.physics]          0.8306      0.428      1.942      0.052      -0.008       1.669
human_difficulty                      0.0521      0.209      0.249      0.804      -0.358       0.462
q_length                              0.0373      0.188      0.198      0.843      -0.332       0.406
avg_word_length                       0.3017      0.187      1.612      0.107      -0.065       0.669
percent_non_alphabetic_whitespace     0.0461      0.021      2.221      0.026       0.005       0.087
capabilities_entropy                  1.2801      0.247      5.173      0.000       0.795       1.765
game_entropy                          1.0682      0.267      3.995      0.000       0.544       1.592
=====================================================================================================

--- Analyzing gemini-2.5-flash-lite_think (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_new/gemini-2.5-flash-lite_think_GPQA_redacted_cor_temp1.0_1758169794_game_data.json', './sc_logs_new/gemini-2.5-flash-lite_think_GPQA_redacted_temp1.0_1758161989_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
1    229
0    218
Name: count, dtype: int64

Answer change%: 0.5123 [0.4659667297261465, 0.5586417713924217] (n=447)
P-value vs 25%: 1.329e-28; P-value vs 0%: 4.005e-104
Phase 2 self-accuracy: 0.2096 [0.15688949091449972, 0.2623244828846269] (n=229)
P-value vs 25%: 0.1332; P-value vs 33%: 4.484e-06

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:                 0.02319
Time:                        20:46:33   Log-Likelihood:                -302.52
converged:                       True   LL-Null:                       -309.70
Covariance Type:            nonrobust   LLR p-value:                 0.0001508
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept         90.1323     39.243      2.297      0.022      13.218     167.047
p_i_capability   -90.1944     39.275     -2.296      0.022    -167.172     -13.217
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:                 0.02171
Time:                        20:46:33   Log-Likelihood:                -302.98
converged:                       True   LL-Null:                       -309.70
Covariance Type:            nonrobust   LLR p-value:                 0.0002450
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -0.0687      0.102     -0.672      0.501      -0.269       0.132
capabilities_entropy    11.0512      4.640      2.382      0.017       1.957      20.146
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.1505 [0.1017, 0.1993] (n=206)
                  P-value vs 33.3%: 2.137e-13

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=2.21, p=0.0284
Wilcoxon delta_p: statistic=5494.00, p=3.06e-05
Mean Δp = 0.0083  [0.0009, 0.0157]
Idea 1 N = 184; 

  Idea 1.5: Calibration Metrics
  NLL: 1.9179, Signed ECE (overconf pos under neg): -0.0009, ECE: 0.0025 (n=308)
  Brier: 0.0002, Reliability (absolute calibration error; lower better): 0.0001, Resolution (relative calibration quality; higher better): 0.1627, Uncertainty: 0.1627 (n=308)
  AUROC: 1.0000

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.992
Model:                            OLS   Adj. R-squared:                  0.992
Method:                 Least Squares   F-statistic:                 1.329e+04
Date:                Thu, 18 Sep 2025   Prob (F-statistic):               0.00
Time:                        20:46:33   Log-Likelihood:                 548.90
No. Observations:                 318   AIC:                            -1090.
Df Residuals:                     314   BIC:                            -1075.
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -1.9835      1.965     -1.010      0.313      -5.849       1.882
p1                    1.9932      1.966      1.014      0.311      -1.875       5.862
answer_changed        1.4645      1.972      0.743      0.458      -2.415       5.344
p1:answer_changed    -0.4788      1.973     -0.243      0.808      -4.361       3.403
==============================================================================
Omnibus:                      454.198   Durbin-Watson:                   2.052
Prob(Omnibus):                  0.000   Jarque-Bera (JB):            99401.033
Skew:                           6.769   Prob(JB):                         0.00
Kurtosis:                      88.549   Cond. No.                     2.53e+03
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The condition number is large, 2.53e+03. This might indicate that there are
strong multicollinearity or other numerical problems.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-4.83, p=2.92e-06
Wilcoxon delta_H: statistic=4993.00, p=1.17e-06
Mean ΔH = -0.2016  [-0.2835, -0.1197]
Paired t-test delta_H Changed: statistic=30.83, p=1.07e-76
Wilcoxon delta_H Changed: statistic=47.00, p=1.96e-33
Mean ΔH Changed = 1.0049  [0.9410, 1.0688]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=-1.36, p=0.176
Wilcoxon (p_top2_game vs p_top2_base): statistic=18547.00, p=2.83e-16
Mean Δp_top2 = -0.0016  [-0.0040, 0.0007] (n=379)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=10.31, p=3.95e-22
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=16862.00, p=2.97e-19
Mean ΔH_unchosen_baseline_set = 0.4191  [0.3395, 0.4988] (n=379)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  379
Model:                          Logit   Df Residuals:                      376
Method:                           MLE   Df Model:                            2
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:                 0.03375
Time:                        20:46:33   Log-Likelihood:                -253.68
converged:                       True   LL-Null:                       -262.54
Covariance Type:            nonrobust   LLR p-value:                 0.0001419
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.1581      0.318     -0.496      0.620      -0.782       0.466
p1_z            -0.5930      1.785     -0.332      0.740      -4.092       2.906
I(p1_z ** 2)    13.3325      9.865      1.351      0.177      -6.003      32.668
================================================================================
AUC = 0.580

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:                0.005086
Time:                        20:46:33   Log-Likelihood:                -308.13
converged:                       True   LL-Null:                       -309.70
Covariance Type:            nonrobust   LLR p-value:                   0.07592
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept        0.0034      0.098      0.035      0.972      -0.189       0.196
game_entropy     0.9773      0.593      1.648      0.099      -0.185       2.139
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=30769.00, p=1.66e-12
Paired t-test (game_entropy vs capabilities_entropy): statistic=3.53, p=0.000466
Mean capabilities_entropy-game_entropy = -0.0309  [-0.0481, -0.0137] (n=447)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      444
Method:                           MLE   Df Model:                            2
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:                 0.02274
Time:                        20:46:33   Log-Likelihood:                -302.66
converged:                       True   LL-Null:                       -309.70
Covariance Type:            nonrobust   LLR p-value:                 0.0008745
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -0.0858      0.105     -0.820      0.412      -0.291       0.119
capabilities_entropy    10.6543      4.694      2.270      0.023       1.453      19.855
game_entropy             0.4986      0.641      0.778      0.437      -0.757       1.755
========================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:                0.009490
Time:                        20:46:33   Log-Likelihood:                -306.76
converged:                       True   LL-Null:                       -309.70
Covariance Type:            nonrobust   LLR p-value:                   0.01533
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -0.9086      0.410     -2.218      0.027      -1.711      -0.106
human_difficulty     0.4045      0.168      2.401      0.016       0.074       0.735
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      440
Method:                           MLE   Df Model:                            6
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:                 0.01680
Time:                        20:46:33   Log-Likelihood:                -304.50
converged:                       True   LL-Null:                       -309.70
Covariance Type:            nonrobust   LLR p-value:                    0.1087
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -1.2941      1.377     -0.940      0.347      -3.994       1.405
C(domain_grouped)[T.chemistry]        0.2231      0.297      0.750      0.453      -0.360       0.806
C(domain_grouped)[T.physics]         -0.1944      0.301     -0.645      0.519      -0.785       0.396
human_difficulty                      0.4400      0.175      2.516      0.012       0.097       0.783
q_length                              0.0537      0.155      0.346      0.729      -0.250       0.357
avg_word_length                      -0.0226      0.153     -0.147      0.883      -0.323       0.278
percent_non_alphabetic_whitespace     0.0091      0.017      0.520      0.603      -0.025       0.043
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 0.0189
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      439
Method:                           MLE   Df Model:                            7
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:                 0.03315
Time:                        20:46:33   Log-Likelihood:                -299.43
converged:                       True   LL-Null:                       -309.70
Covariance Type:            nonrobust   LLR p-value:                  0.004526
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -0.9763      1.396     -0.699      0.484      -3.713       1.761
C(domain_grouped)[T.chemistry]        0.0718      0.303      0.237      0.813      -0.523       0.667
C(domain_grouped)[T.physics]         -0.2334      0.302     -0.772      0.440      -0.826       0.359
human_difficulty                      0.3761      0.177      2.125      0.034       0.029       0.723
q_length                              0.0002      0.159      0.001      0.999      -0.311       0.312
avg_word_length                      -0.0002      0.154     -0.001      0.999      -0.303       0.302
percent_non_alphabetic_whitespace     0.0117      0.018      0.668      0.504      -0.023       0.046
capabilities_entropy                  9.4208      4.655      2.024      0.043       0.298      18.544
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      439
Method:                           MLE   Df Model:                            7
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:                 0.02058
Time:                        20:46:33   Log-Likelihood:                -303.33
converged:                       True   LL-Null:                       -309.70
Covariance Type:            nonrobust   LLR p-value:                   0.07855
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -1.2353      1.379     -0.896      0.370      -3.938       1.468
C(domain_grouped)[T.chemistry]        0.1952      0.298      0.655      0.513      -0.389       0.780
C(domain_grouped)[T.physics]         -0.2159      0.302     -0.715      0.474      -0.807       0.376
human_difficulty                      0.4151      0.176      2.359      0.018       0.070       0.760
q_length                              0.0403      0.155      0.259      0.795      -0.264       0.344
avg_word_length                      -0.0111      0.154     -0.072      0.942      -0.313       0.291
percent_non_alphabetic_whitespace     0.0099      0.018      0.563      0.573      -0.024       0.044
game_entropy                          0.8501      0.588      1.446      0.148      -0.302       2.003
=====================================================================================================

                  Model 4.95: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      438
Method:                           MLE   Df Model:                            8
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:                 0.03393
Time:                        20:46:33   Log-Likelihood:                -299.19
converged:                       True   LL-Null:                       -309.70
Covariance Type:            nonrobust   LLR p-value:                  0.007099
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -0.9304      1.399     -0.665      0.506      -3.672       1.811
C(domain_grouped)[T.chemistry]        0.0648      0.304      0.213      0.831      -0.530       0.660
C(domain_grouped)[T.physics]         -0.2427      0.303     -0.802      0.423      -0.836       0.350
human_difficulty                      0.3668      0.178      2.065      0.039       0.019       0.715
q_length                             -0.0069      0.159     -0.043      0.966      -0.319       0.306
avg_word_length                       0.0016      0.154      0.011      0.992      -0.301       0.304
percent_non_alphabetic_whitespace     0.0118      0.018      0.669      0.503      -0.023       0.046
capabilities_entropy                  9.1255      4.721      1.933      0.053      -0.127      18.378
game_entropy                          0.4396      0.641      0.686      0.493      -0.817       1.696
=====================================================================================================

--- Analyzing gemini-2.5-flash-preview-04-17 (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_new/gemini-2.5-flash-preview-04-17_GPQA_redacted_cor_temp0.0_1751803003_game_data.json', './sc_logs_new/gemini-2.5-flash-preview-04-17_GPQA_redacted_temp0.0_1751720035_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    291
1    152
Name: count, dtype: int64

Answer change%: 0.3431 [0.29890611409609097, 0.3873241342109068] (n=443)
P-value vs 25%: 3.657e-05; P-value vs 0%: 2.959e-52
Phase 2 self-accuracy: 0.3026 [0.22959934965651124, 0.3756638082382256] (n=152)
P-value vs 25%: 0.1578; P-value vs 33%: 0.4151

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  441
Model:                          Logit   Df Residuals:                      439
Method:                           MLE   Df Model:                            1
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:                0.009313
Time:                        20:46:33   Log-Likelihood:                -281.40
converged:                       True   LL-Null:                       -284.04
Covariance Type:            nonrobust   LLR p-value:                   0.02144
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.7305      0.108     -6.750      0.000      -0.943      -0.518
game_entropy     0.6934      0.302      2.297      0.022       0.102       1.285
================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  443
Model:                          Logit   Df Residuals:                      441
Method:                           MLE   Df Model:                            1
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:                0.001021
Time:                        20:46:33   Log-Likelihood:                -284.59
converged:                       True   LL-Null:                       -284.88
Covariance Type:            nonrobust   LLR p-value:                    0.4457
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -0.9664      0.428     -2.256      0.024      -1.806      -0.127
human_difficulty     0.1335      0.175      0.763      0.446      -0.209       0.476
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  443
Model:                          Logit   Df Residuals:                      436
Method:                           MLE   Df Model:                            6
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:                 0.02280
Time:                        20:46:33   Log-Likelihood:                -278.39
converged:                       True   LL-Null:                       -284.88
Covariance Type:            nonrobust   LLR p-value:                   0.04321
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -1.8807      1.509     -1.246      0.213      -4.838       1.077
C(domain_grouped)[T.chemistry]        0.6391      0.339      1.883      0.060      -0.026       1.304
C(domain_grouped)[T.physics]          0.6613      0.344      1.920      0.055      -0.014       1.336
human_difficulty                      0.2821      0.183      1.539      0.124      -0.077       0.641
q_length                             -0.0299      0.166     -0.180      0.857      -0.356       0.296
avg_word_length                      -0.0149      0.168     -0.089      0.929      -0.344       0.314
percent_non_alphabetic_whitespace     0.0295      0.018      1.600      0.110      -0.007       0.066
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  441
Model:                          Logit   Df Residuals:                      433
Method:                           MLE   Df Model:                            7
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:                 0.02789
Time:                        20:46:33   Log-Likelihood:                -276.12
converged:                       True   LL-Null:                       -284.04
Covariance Type:            nonrobust   LLR p-value:                   0.02658
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -1.7155      1.516     -1.131      0.258      -4.688       1.257
C(domain_grouped)[T.chemistry]        0.5435      0.346      1.572      0.116      -0.134       1.221
C(domain_grouped)[T.physics]          0.6176      0.346      1.785      0.074      -0.060       1.296
human_difficulty                      0.2419      0.185      1.305      0.192      -0.121       0.605
q_length                             -0.0335      0.167     -0.201      0.841      -0.361       0.294
avg_word_length                      -0.0215      0.169     -0.127      0.899      -0.353       0.310
percent_non_alphabetic_whitespace     0.0271      0.019      1.464      0.143      -0.009       0.063
game_entropy                          0.5319      0.312      1.706      0.088      -0.079       1.143
=====================================================================================================

--- Analyzing gemini-2.5-flash_nothink (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_new/gemini-2.5-flash_nothink_GPQA_redacted_cor_temp1.0_1758161812_game_data.json', './sc_logs_new/gemini-2.5-flash_nothink_GPQA_redacted_temp1.0_1758161699_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    314
1    133
Name: count, dtype: int64

Answer change%: 0.2975 [0.2551575398784204, 0.33992075989786597] (n=447)
P-value vs 25%: 0.02792; P-value vs 0%: 4.442e-43
Phase 2 self-accuracy: 0.3233 [0.2438157786328595, 0.4028007627205239] (n=133)
P-value vs 25%: 0.07069; P-value vs 33%: 0.8111

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:                 0.08157
Time:                        20:46:33   Log-Likelihood:                -249.92
converged:                       True   LL-Null:                       -272.12
Covariance Type:            nonrobust   LLR p-value:                 2.687e-11
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          1.4010      0.356      3.935      0.000       0.703       2.099
p_i_capability    -3.0989      0.482     -6.429      0.000      -4.044      -2.154
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:                 0.08474
Time:                        20:46:33   Log-Likelihood:                -249.06
converged:                       True   LL-Null:                       -272.12
Covariance Type:            nonrobust   LLR p-value:                 1.113e-11
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.8872      0.206     -9.170      0.000      -2.291      -1.484
capabilities_entropy     1.1000      0.170      6.462      0.000       0.766       1.434
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.6466 [0.5654, 0.7279] (n=133)
                  P-value vs 33.3%: 4.088e-14

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=13.72, p=7.88e-34
Wilcoxon delta_p: statistic=5433.00, p=7.05e-33
Mean Δp = 0.1317  [0.1129, 0.1505]
Idea 1 N = 313; 

  Idea 1.5: Calibration Metrics
  NLL: 1.7304, Signed ECE (overconf pos under neg): -0.0255, ECE: 0.1049 (n=447)
  Brier: 0.0489, Reliability (absolute calibration error; lower better): 0.0242, Resolution (relative calibration quality; higher better): 0.2253, Uncertainty: 0.2498 (n=447)
  AUROC: 0.9964

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.578
Model:                            OLS   Adj. R-squared:                  0.575
Method:                 Least Squares   F-statistic:                     200.4
Date:                Thu, 18 Sep 2025   Prob (F-statistic):           7.61e-82
Time:                        20:46:33   Log-Likelihood:                 213.19
No. Observations:                 443   AIC:                            -418.4
Df Residuals:                     439   BIC:                            -402.0
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.0011      0.033     -0.034      0.973      -0.066       0.064
p1                    0.1647      0.040      4.168      0.000       0.087       0.242
answer_changed       -0.1938      0.054     -3.566      0.000      -0.301      -0.087
p1:answer_changed     0.7938      0.075     10.625      0.000       0.647       0.941
==============================================================================
Omnibus:                       10.643   Durbin-Watson:                   1.820
Prob(Omnibus):                  0.005   Jarque-Bera (JB):               10.887
Skew:                           0.383   Prob(JB):                      0.00433
Kurtosis:                       3.053   Cond. No.                         17.8
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-7.95, p=3.39e-14
Wilcoxon delta_H: statistic=12324.00, p=1.32e-14
Mean ΔH = -0.2012  [-0.2508, -0.1516]
Paired t-test delta_H Changed: statistic=-2.81, p=0.00573
Wilcoxon delta_H Changed: statistic=3132.00, p=0.00296
Mean ΔH Changed = -0.0939  [-0.1594, -0.0284]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=-19.30, p=8.53e-61
Wilcoxon (p_top2_game vs p_top2_base): statistic=5265.00, p=2.13e-60
Mean Δp_top2 = -0.0977  [-0.1076, -0.0878] (n=447)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=-8.27, p=1.61e-15
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=27821.00, p=3.97e-16
Mean ΔH_unchosen_baseline_set = -0.1693  [-0.2094, -0.1291] (n=447)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      444
Method:                           MLE   Df Model:                            2
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:                 0.09863
Time:                        20:46:33   Log-Likelihood:                -245.28
converged:                       True   LL-Null:                       -272.12
Covariance Type:            nonrobust   LLR p-value:                 2.208e-12
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.5730      0.165     -3.467      0.001      -0.897      -0.249
p1_z            -0.9594      0.145     -6.624      0.000      -1.243      -0.676
I(p1_z ** 2)    -0.4266      0.141     -3.023      0.002      -0.703      -0.150
================================================================================
AUC = 0.717

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:                  0.1109
Time:                        20:46:33   Log-Likelihood:                -241.94
converged:                       True   LL-Null:                       -272.12
Covariance Type:            nonrobust   LLR p-value:                 7.908e-15
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -3.0068      0.362     -8.305      0.000      -3.716      -2.297
game_entropy     1.5789      0.234      6.753      0.000       1.121       2.037
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=7824.00, p=6.77e-54
Paired t-test (game_entropy vs capabilities_entropy): statistic=18.61, p=1.29e-57
Mean capabilities_entropy-game_entropy = -0.4000  [-0.4421, -0.3578] (n=447)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      444
Method:                           MLE   Df Model:                            2
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:                  0.1156
Time:                        20:46:33   Log-Likelihood:                -240.65
converged:                       True   LL-Null:                       -272.12
Covariance Type:            nonrobust   LLR p-value:                 2.155e-14
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.9011      0.362     -8.011      0.000      -3.611      -2.191
capabilities_entropy     0.3814      0.239      1.596      0.111      -0.087       0.850
game_entropy             1.2381      0.313      3.958      0.000       0.625       1.851
========================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:               8.731e-05
Time:                        20:46:33   Log-Likelihood:                -272.09
converged:                       True   LL-Null:                       -272.12
Covariance Type:            nonrobust   LLR p-value:                    0.8274
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -0.9524      0.441     -2.161      0.031      -1.816      -0.088
human_difficulty     0.0393      0.180      0.218      0.827      -0.314       0.393
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      440
Method:                           MLE   Df Model:                            6
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:                 0.01810
Time:                        20:46:34   Log-Likelihood:                -267.19
converged:                       True   LL-Null:                       -272.12
Covariance Type:            nonrobust   LLR p-value:                    0.1311
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -3.1940      1.549     -2.063      0.039      -6.229      -0.159
C(domain_grouped)[T.chemistry]        0.7539      0.339      2.227      0.026       0.090       1.418
C(domain_grouped)[T.physics]          0.5028      0.346      1.455      0.146      -0.174       1.180
human_difficulty                      0.0344      0.187      0.184      0.854      -0.332       0.401
q_length                              0.3443      0.174      1.981      0.048       0.004       0.685
avg_word_length                      -0.0229      0.172     -0.134      0.894      -0.359       0.313
percent_non_alphabetic_whitespace    -0.0252      0.020     -1.234      0.217      -0.065       0.015
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 0.8397
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      439
Method:                           MLE   Df Model:                            7
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:                 0.09357
Time:                        20:46:34   Log-Likelihood:                -246.66
converged:                       True   LL-Null:                       -272.12
Covariance Type:            nonrobust   LLR p-value:                 9.513e-09
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -3.9154      1.601     -2.445      0.014      -7.053      -0.777
C(domain_grouped)[T.chemistry]        0.1778      0.365      0.488      0.626      -0.537       0.893
C(domain_grouped)[T.physics]          0.0275      0.373      0.074      0.941      -0.704       0.759
human_difficulty                     -0.0225      0.197     -0.114      0.909      -0.409       0.364
q_length                              0.2458      0.183      1.344      0.179      -0.113       0.604
avg_word_length                       0.1366      0.177      0.771      0.441      -0.211       0.484
percent_non_alphabetic_whitespace    -0.0123      0.021     -0.577      0.564      -0.054       0.029
capabilities_entropy                  1.1094      0.182      6.092      0.000       0.753       1.466
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      439
Method:                           MLE   Df Model:                            7
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:                  0.1223
Time:                        20:46:34   Log-Likelihood:                -238.84
converged:                       True   LL-Null:                       -272.12
Covariance Type:            nonrobust   LLR p-value:                 7.323e-12
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -4.7180      1.643     -2.872      0.004      -7.938      -1.498
C(domain_grouped)[T.chemistry]       -0.0461      0.377     -0.122      0.903      -0.785       0.693
C(domain_grouped)[T.physics]         -0.0961      0.386     -0.249      0.803      -0.853       0.661
human_difficulty                     -0.0077      0.199     -0.039      0.969      -0.398       0.383
q_length                              0.2377      0.184      1.290      0.197      -0.124       0.599
avg_word_length                       0.0992      0.177      0.561      0.575      -0.247       0.446
percent_non_alphabetic_whitespace    -0.0221      0.021     -1.046      0.296      -0.064       0.019
game_entropy                          1.6551      0.253      6.549      0.000       1.160       2.150
=====================================================================================================

                  Model 4.95: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      438
Method:                           MLE   Df Model:                            8
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:                  0.1269
Time:                        20:46:34   Log-Likelihood:                -237.58
converged:                       True   LL-Null:                       -272.12
Covariance Type:            nonrobust   LLR p-value:                 7.506e-12
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -4.6606      1.651     -2.823      0.005      -7.896      -1.425
C(domain_grouped)[T.chemistry]       -0.0909      0.379     -0.240      0.810      -0.833       0.651
C(domain_grouped)[T.physics]         -0.1546      0.389     -0.398      0.691      -0.917       0.607
human_difficulty                     -0.0203      0.200     -0.101      0.919      -0.413       0.372
q_length                              0.2252      0.185      1.215      0.224      -0.138       0.588
avg_word_length                       0.1310      0.180      0.729      0.466      -0.221       0.483
percent_non_alphabetic_whitespace    -0.0187      0.021     -0.873      0.382      -0.061       0.023
capabilities_entropy                  0.3857      0.244      1.578      0.115      -0.093       0.865
game_entropy                          1.3260      0.324      4.091      0.000       0.691       1.961
=====================================================================================================

--- Analyzing gpt-4.1-2025-04-14 (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_new/gpt-4.1-2025-04-14_GPQA_redacted_cor_temp1.0_1757988295_game_data.json', './sc_logs_new/gpt-4.1-2025-04-14_GPQA_redacted_temp1.0_1757987232_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    273
1    174
Name: count, dtype: int64

Answer change%: 0.3893 [0.34406129543835273, 0.43446219449453316] (n=447)
P-value vs 25%: 1.554e-09; P-value vs 0%: 6.421e-64
Phase 2 self-accuracy: 0.2931 [0.2254699483016363, 0.3607369482500878] (n=174)
P-value vs 25%: 0.2116; P-value vs 33%: 0.2476

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:                 0.06318
Time:                        20:46:34   Log-Likelihood:                -279.90
converged:                       True   LL-Null:                       -298.78
Covariance Type:            nonrobust   LLR p-value:                 8.023e-10
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          3.5078      0.707      4.959      0.000       2.122       4.894
p_i_capability    -4.3076      0.757     -5.689      0.000      -5.792      -2.823
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:                 0.08032
Time:                        20:46:34   Log-Likelihood:                -274.78
converged:                       True   LL-Null:                       -298.78
Covariance Type:            nonrobust   LLR p-value:                 4.265e-12
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -0.9077      0.123     -7.373      0.000      -1.149      -0.666
capabilities_entropy     1.5903      0.246      6.452      0.000       1.107       2.073
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.6535 [0.5607, 0.7463] (n=101)
                  P-value vs 33.3%: 1.371e-11

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=-0.67, p=0.507
Wilcoxon delta_p: statistic=575.00, p=0.299
Mean Δp = -0.0211  [-0.0829, 0.0407]
Idea 1 N = 52; 

  Idea 1.5: Calibration Metrics
  NLL: 4.1382, Signed ECE (overconf pos under neg): -0.0047, ECE: 0.0922 (n=119)
  Brier: 0.0298, Reliability (absolute calibration error; lower better): 0.0223, Resolution (relative calibration quality; higher better): 0.2191, Uncertainty: 0.2258 (n=119)
  AUROC: 0.9987

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.891
Model:                            OLS   Adj. R-squared:                  0.889
Method:                 Least Squares   F-statistic:                     314.6
Date:                Thu, 18 Sep 2025   Prob (F-statistic):           2.97e-55
Time:                        20:46:34   Log-Likelihood:                 66.358
No. Observations:                 119   AIC:                            -124.7
Df Residuals:                     115   BIC:                            -113.6
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.8128      0.097     -8.344      0.000      -1.006      -0.620
p1                    0.9153      0.110      8.296      0.000       0.697       1.134
answer_changed        0.7737      0.123      6.284      0.000       0.530       1.018
p1:answer_changed     0.0412      0.145      0.284      0.777      -0.246       0.329
==============================================================================
Omnibus:                        3.567   Durbin-Watson:                   1.841
Prob(Omnibus):                  0.168   Jarque-Bera (JB):                4.090
Skew:                           0.035   Prob(JB):                        0.129
Kurtosis:                       3.906   Cond. No.                         26.5
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=0.97, p=0.334
Wilcoxon delta_H: statistic=588.00, p=0.358
Mean ΔH = 0.0734  [-0.0742, 0.2209]
Paired t-test delta_H Changed: statistic=3.98, p=0.000172
Wilcoxon delta_H Changed: statistic=514.00, p=9.46e-05
Mean ΔH Changed = 0.2680  [0.1361, 0.3998]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=3.13, p=0.00223
Wilcoxon (p_top2_game vs p_top2_base): statistic=2285.00, p=0.000655
Mean Δp_top2 = 0.0223  [0.0083, 0.0363] (n=119)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=3.61, p=0.000458
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=2208.00, p=0.000304
Mean ΔH_unchosen_baseline_set = 0.1829  [0.0835, 0.2824] (n=119)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  119
Model:                          Logit   Df Residuals:                      116
Method:                           MLE   Df Model:                            2
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:                 0.06748
Time:                        20:46:34   Log-Likelihood:                -76.034
converged:                       True   LL-Null:                       -81.537
Covariance Type:            nonrobust   LLR p-value:                  0.004077
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept        0.7265      0.305      2.385      0.017       0.129       1.324
p1_z            -0.8201      0.256     -3.207      0.001      -1.321      -0.319
I(p1_z ** 2)    -0.4498      0.226     -1.993      0.046      -0.892      -0.007
================================================================================
AUC = 0.660

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:                 0.05933
Time:                        20:46:34   Log-Likelihood:                -281.06
converged:                       True   LL-Null:                       -298.78
Covariance Type:            nonrobust   LLR p-value:                 2.614e-09
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.7952      0.117     -6.803      0.000      -1.024      -0.566
game_entropy     1.6218      0.288      5.629      0.000       1.057       2.186
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=26266.00, p=0.0046
Paired t-test (game_entropy vs capabilities_entropy): statistic=-3.34, p=0.00092
Mean capabilities_entropy-game_entropy = 0.0722  [0.0298, 0.1147] (n=447)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      444
Method:                           MLE   Df Model:                            2
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:                  0.1050
Time:                        20:46:34   Log-Likelihood:                -267.41
converged:                       True   LL-Null:                       -298.78
Covariance Type:            nonrobust   LLR p-value:                 2.375e-14
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.0652      0.133     -8.026      0.000      -1.325      -0.805
capabilities_entropy     1.2903      0.256      5.035      0.000       0.788       1.793
game_entropy             1.1493      0.306      3.760      0.000       0.550       1.748
========================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:                0.001197
Time:                        20:46:34   Log-Likelihood:                -298.42
converged:                       True   LL-Null:                       -298.78
Covariance Type:            nonrobust   LLR p-value:                    0.3977
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -0.1106      0.413     -0.268      0.789      -0.921       0.699
human_difficulty    -0.1437      0.170     -0.844      0.399      -0.477       0.190
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      440
Method:                           MLE   Df Model:                            6
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:                 0.01936
Time:                        20:46:34   Log-Likelihood:                -293.00
converged:                       True   LL-Null:                       -298.78
Covariance Type:            nonrobust   LLR p-value:                   0.07236
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -0.7414      1.476     -0.502      0.615      -3.635       2.152
C(domain_grouped)[T.chemistry]        0.7224      0.317      2.280      0.023       0.101       1.343
C(domain_grouped)[T.physics]          0.3283      0.322      1.019      0.308      -0.303       0.959
human_difficulty                     -0.0874      0.178     -0.492      0.623      -0.435       0.261
q_length                              0.2399      0.163      1.472      0.141      -0.080       0.559
avg_word_length                      -0.2604      0.171     -1.524      0.127      -0.595       0.074
percent_non_alphabetic_whitespace    -0.0194      0.018     -1.050      0.294      -0.056       0.017
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 0.2781
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      439
Method:                           MLE   Df Model:                            7
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:                 0.09104
Time:                        20:46:34   Log-Likelihood:                -271.58
converged:                       True   LL-Null:                       -298.78
Covariance Type:            nonrobust   LLR p-value:                 1.956e-09
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -1.9235      1.536     -1.252      0.211      -4.935       1.088
C(domain_grouped)[T.chemistry]        0.4436      0.331      1.339      0.181      -0.206       1.093
C(domain_grouped)[T.physics]          0.0306      0.339      0.090      0.928      -0.634       0.695
human_difficulty                     -0.0657      0.189     -0.348      0.728      -0.436       0.304
q_length                              0.2867      0.172      1.665      0.096      -0.051       0.624
avg_word_length                      -0.1345      0.173     -0.779      0.436      -0.473       0.204
percent_non_alphabetic_whitespace    -0.0113      0.019     -0.592      0.554      -0.049       0.026
capabilities_entropy                  1.5590      0.255      6.114      0.000       1.059       2.059
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      439
Method:                           MLE   Df Model:                            7
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:                 0.06635
Time:                        20:46:34   Log-Likelihood:                -278.96
converged:                       True   LL-Null:                       -298.78
Covariance Type:            nonrobust   LLR p-value:                 1.470e-06
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -1.1128      1.505     -0.739      0.460      -4.063       1.837
C(domain_grouped)[T.chemistry]        0.5073      0.326      1.554      0.120      -0.132       1.147
C(domain_grouped)[T.physics]          0.2061      0.331      0.622      0.534      -0.443       0.855
human_difficulty                     -0.0469      0.185     -0.254      0.799      -0.409       0.315
q_length                              0.1411      0.168      0.841      0.400      -0.188       0.470
avg_word_length                      -0.1253      0.173     -0.726      0.468      -0.464       0.213
percent_non_alphabetic_whitespace    -0.0119      0.019     -0.631      0.528      -0.049       0.025
game_entropy                          1.4937      0.295      5.059      0.000       0.915       2.072
=====================================================================================================

                  Model 4.95: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      438
Method:                           MLE   Df Model:                            8
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:                  0.1109
Time:                        20:46:34   Log-Likelihood:                -265.63
converged:                       True   LL-Null:                       -298.78
Covariance Type:            nonrobust   LLR p-value:                 2.674e-11
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -1.9563      1.548     -1.263      0.206      -4.991       1.078
C(domain_grouped)[T.chemistry]        0.3408      0.335      1.016      0.309      -0.316       0.998
C(domain_grouped)[T.physics]         -0.0108      0.343     -0.032      0.975      -0.682       0.661
human_difficulty                     -0.0444      0.192     -0.232      0.817      -0.421       0.332
q_length                              0.2073      0.174      1.188      0.235      -0.135       0.549
avg_word_length                      -0.0621      0.173     -0.358      0.721      -0.402       0.278
percent_non_alphabetic_whitespace    -0.0080      0.019     -0.414      0.679      -0.046       0.030
capabilities_entropy                  1.3073      0.263      4.965      0.000       0.791       1.823
game_entropy                          1.0578      0.312      3.389      0.001       0.446       1.669
=====================================================================================================

--- Analyzing gpt-4o-2024-08-06 (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_new/gpt-4o-2024-08-06_GPQA_redacted_cor_temp1.0_1757988603_game_data.json', './sc_logs_new/gpt-4o-2024-08-06_GPQA_redacted_temp1.0_1757987499_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    322
1    125
Name: count, dtype: int64

Answer change%: 0.2796 [0.23803473762474414, 0.32124937870635206] (n=447)
P-value vs 25%: 0.1626; P-value vs 0%: 1.257e-39
Phase 2 self-accuracy: 0.3680 [0.2834574130189166, 0.4525425869810834] (n=125)
P-value vs 25%: 0.006226; P-value vs 33%: 0.4171

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:                  0.1579
Time:                        20:46:34   Log-Likelihood:                -223.08
converged:                       True   LL-Null:                       -264.90
Covariance Type:            nonrobust   LLR p-value:                 5.924e-20
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          2.2934      0.385      5.956      0.000       1.539       3.048
p_i_capability    -4.6634      0.563     -8.278      0.000      -5.768      -3.559
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:                  0.1393
Time:                        20:46:34   Log-Likelihood:                -227.99
converged:                       True   LL-Null:                       -264.90
Covariance Type:            nonrobust   LLR p-value:                 8.584e-18
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.4816      0.252     -9.840      0.000      -2.976      -1.987
capabilities_entropy     1.5209      0.197      7.725      0.000       1.135       1.907
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.7200 [0.6413, 0.7987] (n=125)
                  P-value vs 33.3%: 6.077e-22

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=-4.16, p=4.14e-05
Wilcoxon delta_p: statistic=15372.00, p=2.17e-05
Mean Δp = -0.0417  [-0.0614, -0.0221]
Idea 1 N = 293; 

  Idea 1.5: Calibration Metrics
  NLL: 2.1907, Signed ECE (overconf pos under neg): -0.0062, ECE: 0.1128 (n=418)
  Brier: 0.0534, Reliability (absolute calibration error; lower better): 0.0279, Resolution (relative calibration quality; higher better): 0.2114, Uncertainty: 0.2363 (n=418)
  AUROC: 0.9959

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.739
Model:                            OLS   Adj. R-squared:                  0.737
Method:                 Least Squares   F-statistic:                     390.3
Date:                Thu, 18 Sep 2025   Prob (F-statistic):          2.97e-120
Time:                        20:46:34   Log-Likelihood:                 224.46
No. Observations:                 418   AIC:                            -440.9
Df Residuals:                     414   BIC:                            -424.8
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.3964      0.032    -12.447      0.000      -0.459      -0.334
p1                    0.4529      0.039     11.535      0.000       0.376       0.530
answer_changed        0.1871      0.054      3.478      0.001       0.081       0.293
p1:answer_changed     0.5703      0.080      7.088      0.000       0.412       0.729
==============================================================================
Omnibus:                        7.121   Durbin-Watson:                   1.858
Prob(Omnibus):                  0.028   Jarque-Bera (JB):                7.252
Skew:                           0.322   Prob(JB):                       0.0266
Kurtosis:                       2.950   Cond. No.                         18.6
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=4.71, p=3.88e-06
Wilcoxon delta_H: statistic=14509.00, p=1.29e-06
Mean ΔH = 0.1302  [0.0760, 0.1844]
Paired t-test delta_H Changed: statistic=10.58, p=4.86e-19
Wilcoxon delta_H Changed: statistic=599.00, p=1.94e-16
Mean ΔH Changed = 0.3912  [0.3187, 0.4637]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=8.32, p=1.26e-15
Wilcoxon (p_top2_game vs p_top2_base): statistic=22724.00, p=1.57e-17
Mean Δp_top2 = 0.0381  [0.0292, 0.0471] (n=418)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=9.04, p=6.16e-18
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=22167.00, p=2.19e-18
Mean ΔH_unchosen_baseline_set = 0.2082  [0.1631, 0.2534] (n=418)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  418
Model:                          Logit   Df Residuals:                      415
Method:                           MLE   Df Model:                            2
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:                  0.1453
Time:                        20:46:34   Log-Likelihood:                -217.94
converged:                       True   LL-Null:                       -255.00
Covariance Type:            nonrobust   LLR p-value:                 8.064e-17
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.7692      0.174     -4.422      0.000      -1.110      -0.428
p1_z            -1.0967      0.150     -7.298      0.000      -1.391      -0.802
I(p1_z ** 2)    -0.3220      0.154     -2.097      0.036      -0.623      -0.021
================================================================================
AUC = 0.755

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:                  0.1039
Time:                        20:46:34   Log-Likelihood:                -237.39
converged:                       True   LL-Null:                       -264.90
Covariance Type:            nonrobust   LLR p-value:                 1.191e-13
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -2.0701      0.212     -9.756      0.000      -2.486      -1.654
game_entropy     1.3915      0.200      6.972      0.000       1.000       1.783
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=30460.00, p=7.3e-13
Paired t-test (game_entropy vs capabilities_entropy): statistic=-7.20, p=2.5e-12
Mean capabilities_entropy-game_entropy = 0.1622  [0.1180, 0.2063] (n=447)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      444
Method:                           MLE   Df Model:                            2
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:                  0.1471
Time:                        20:46:34   Log-Likelihood:                -225.94
converged:                       True   LL-Null:                       -264.90
Covariance Type:            nonrobust   LLR p-value:                 1.200e-17
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.5794      0.259     -9.950      0.000      -3.087      -2.071
capabilities_entropy     1.1852      0.255      4.651      0.000       0.686       1.685
game_entropy             0.5376      0.266      2.021      0.043       0.016       1.059
========================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:                0.006466
Time:                        20:46:34   Log-Likelihood:                -263.19
converged:                       True   LL-Null:                       -264.90
Covariance Type:            nonrobust   LLR p-value:                   0.06420
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -0.1353      0.451     -0.300      0.764      -1.018       0.748
human_difficulty    -0.3457      0.189     -1.832      0.067      -0.716       0.024
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      440
Method:                           MLE   Df Model:                            6
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:                 0.02134
Time:                        20:46:34   Log-Likelihood:                -259.25
converged:                       True   LL-Null:                       -264.90
Covariance Type:            nonrobust   LLR p-value:                   0.07937
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                             1.0894      1.640      0.664      0.506      -2.124       4.303
C(domain_grouped)[T.chemistry]        0.6284      0.367      1.711      0.087      -0.091       1.348
C(domain_grouped)[T.physics]          0.6056      0.370      1.635      0.102      -0.120       1.332
human_difficulty                     -0.2558      0.193     -1.323      0.186      -0.635       0.123
q_length                             -0.0635      0.177     -0.359      0.719      -0.410       0.283
avg_word_length                      -0.2979      0.195     -1.524      0.127      -0.681       0.085
percent_non_alphabetic_whitespace    -0.0263      0.020     -1.290      0.197      -0.066       0.014
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 0.8688
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      439
Method:                           MLE   Df Model:                            7
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:                  0.1459
Time:                        20:46:34   Log-Likelihood:                -226.26
converged:                       True   LL-Null:                       -264.90
Covariance Type:            nonrobust   LLR p-value:                 4.924e-14
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -0.1647      1.677     -0.098      0.922      -3.452       3.122
C(domain_grouped)[T.chemistry]       -0.3755      0.418     -0.899      0.368      -1.194       0.443
C(domain_grouped)[T.physics]         -0.1860      0.419     -0.444      0.657      -1.008       0.636
human_difficulty                     -0.2215      0.210     -1.054      0.292      -0.633       0.190
q_length                             -0.1659      0.189     -0.876      0.381      -0.537       0.205
avg_word_length                      -0.1078      0.188     -0.575      0.566      -0.476       0.260
percent_non_alphabetic_whitespace    -0.0144      0.020     -0.706      0.480      -0.054       0.026
capabilities_entropy                  1.5586      0.212      7.360      0.000       1.144       1.974
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      439
Method:                           MLE   Df Model:                            7
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:                  0.1095
Time:                        20:46:34   Log-Likelihood:                -235.88
converged:                       True   LL-Null:                       -264.90
Covariance Type:            nonrobust   LLR p-value:                 3.720e-10
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -0.0953      1.680     -0.057      0.955      -3.388       3.197
C(domain_grouped)[T.chemistry]       -0.0042      0.395     -0.011      0.992      -0.779       0.771
C(domain_grouped)[T.physics]          0.1348      0.400      0.337      0.736      -0.649       0.919
human_difficulty                     -0.1990      0.204     -0.974      0.330      -0.599       0.201
q_length                             -0.1500      0.187     -0.803      0.422      -0.516       0.216
avg_word_length                      -0.1144      0.191     -0.599      0.549      -0.489       0.260
percent_non_alphabetic_whitespace    -0.0150      0.021     -0.726      0.468      -0.055       0.025
game_entropy                          1.3596      0.210      6.473      0.000       0.948       1.771
=====================================================================================================

                  Model 4.95: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      438
Method:                           MLE   Df Model:                            8
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:                  0.1533
Time:                        20:46:34   Log-Likelihood:                -224.29
converged:                       True   LL-Null:                       -264.90
Covariance Type:            nonrobust   LLR p-value:                 2.772e-14
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -0.3734      1.686     -0.221      0.825      -3.679       2.932
C(domain_grouped)[T.chemistry]       -0.4069      0.420     -0.970      0.332      -1.229       0.415
C(domain_grouped)[T.physics]         -0.2128      0.422     -0.504      0.614      -1.041       0.615
human_difficulty                     -0.2135      0.211     -1.010      0.313      -0.628       0.201
q_length                             -0.1730      0.190     -0.909      0.363      -0.546       0.200
avg_word_length                      -0.0772      0.188     -0.410      0.682      -0.446       0.292
percent_non_alphabetic_whitespace    -0.0132      0.021     -0.642      0.521      -0.053       0.027
capabilities_entropy                  1.2348      0.265      4.663      0.000       0.716       1.754
game_entropy                          0.5350      0.270      1.980      0.048       0.005       1.065
=====================================================================================================

--- Analyzing gpt-4o-mini (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_new/gpt-4o-mini_GPQA_redacted_cor_temp1.0_1757988839_game_data.json', './sc_logs_new/gpt-4o-mini_GPQA_redacted_temp1.0_1757987785_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    303
1    144
Name: count, dtype: int64

Answer change%: 0.3221 [0.2788275593713588, 0.365467742642064] (n=447)
P-value vs 25%: 0.001098; P-value vs 0%: 4.041e-48
Phase 2 self-accuracy: 0.3611 [0.28265984836243213, 0.4395623738597901] (n=144)
P-value vs 25%: 0.005505; P-value vs 33%: 0.4825

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:                  0.1048
Time:                        20:46:34   Log-Likelihood:                -251.50
converged:                       True   LL-Null:                       -280.93
Covariance Type:            nonrobust   LLR p-value:                 1.689e-14
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          2.4334      0.438      5.558      0.000       1.575       3.291
p_i_capability    -4.0781      0.558     -7.308      0.000      -5.172      -2.984
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:                 0.09520
Time:                        20:46:34   Log-Likelihood:                -254.18
converged:                       True   LL-Null:                       -280.93
Covariance Type:            nonrobust   LLR p-value:                 2.598e-13
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.7641      0.193     -9.126      0.000      -2.143      -1.385
capabilities_entropy     1.3436      0.194      6.923      0.000       0.963       1.724
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.7483 [0.6771, 0.8194] (n=143)
                  P-value vs 33.3%: 2.892e-30

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=-2.97, p=0.00319
Wilcoxon delta_p: statistic=14911.00, p=0.00208
Mean Δp = -0.0307  [-0.0509, -0.0105]
Idea 1 N = 275; 

  Idea 1.5: Calibration Metrics
  NLL: 3.5821, Signed ECE (overconf pos under neg): 0.0061, ECE: 0.0913 (n=418)
  Brier: 0.0365, Reliability (absolute calibration error; lower better): 0.0213, Resolution (relative calibration quality; higher better): 0.1982, Uncertainty: 0.2134 (n=418)
  AUROC: 0.9981

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.827
Model:                            OLS   Adj. R-squared:                  0.826
Method:                 Least Squares   F-statistic:                     659.2
Date:                Thu, 18 Sep 2025   Prob (F-statistic):          3.15e-157
Time:                        20:46:34   Log-Likelihood:                 231.63
No. Observations:                 418   AIC:                            -455.3
Df Residuals:                     414   BIC:                            -439.1
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.4992      0.041    -12.230      0.000      -0.579      -0.419
p1                    0.5601      0.048     11.731      0.000       0.466       0.654
answer_changed        0.3484      0.060      5.851      0.000       0.231       0.465
p1:answer_changed     0.4292      0.077      5.606      0.000       0.279       0.580
==============================================================================
Omnibus:                       14.691   Durbin-Watson:                   1.903
Prob(Omnibus):                  0.001   Jarque-Bera (JB):               15.420
Skew:                           0.468   Prob(JB):                     0.000448
Kurtosis:                       3.092   Cond. No.                         21.1
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=4.37, p=1.76e-05
Wilcoxon delta_H: statistic=13312.00, p=2.57e-05
Mean ΔH = 0.1309  [0.0722, 0.1897]
Paired t-test delta_H Changed: statistic=7.85, p=9.26e-13
Wilcoxon delta_H Changed: statistic=1678.00, p=4.49e-12
Mean ΔH Changed = 0.2902  [0.2178, 0.3627]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=5.84, p=1.03e-08
Wilcoxon (p_top2_game vs p_top2_base): statistic=28187.00, p=2.76e-10
Mean Δp_top2 = 0.0214  [0.0143, 0.0286] (n=418)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=7.83, p=4.1e-14
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=24910.00, p=5.38e-14
Mean ΔH_unchosen_baseline_set = 0.1854  [0.1390, 0.2319] (n=418)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  418
Model:                          Logit   Df Residuals:                      415
Method:                           MLE   Df Model:                            2
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:                 0.08973
Time:                        20:46:34   Log-Likelihood:                -244.44
converged:                       True   LL-Null:                       -268.53
Covariance Type:            nonrobust   LLR p-value:                 3.433e-11
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.6929      0.168     -4.120      0.000      -1.022      -0.363
p1_z            -0.7545      0.134     -5.649      0.000      -1.016      -0.493
I(p1_z ** 2)    -0.0372      0.138     -0.270      0.787      -0.307       0.233
================================================================================
AUC = 0.711

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:                  0.1143
Time:                        20:46:34   Log-Likelihood:                -248.81
converged:                       True   LL-Null:                       -280.93
Covariance Type:            nonrobust   LLR p-value:                 1.103e-15
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.8383      0.193     -9.537      0.000      -2.216      -1.460
game_entropy     1.7128      0.229      7.474      0.000       1.264       2.162
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=36135.00, p=1.33e-06
Paired t-test (game_entropy vs capabilities_entropy): statistic=-4.80, p=2.17e-06
Mean capabilities_entropy-game_entropy = 0.1117  [0.0661, 0.1573] (n=447)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      444
Method:                           MLE   Df Model:                            2
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:                  0.1357
Time:                        20:46:34   Log-Likelihood:                -242.80
converged:                       True   LL-Null:                       -280.93
Covariance Type:            nonrobust   LLR p-value:                 2.762e-17
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.1419      0.222     -9.643      0.000      -2.577      -1.707
capabilities_entropy     0.7837      0.227      3.450      0.001       0.338       1.229
game_entropy             1.2452      0.266      4.685      0.000       0.724       1.766
========================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:                0.007932
Time:                        20:46:34   Log-Likelihood:                -278.70
converged:                       True   LL-Null:                       -280.93
Covariance Type:            nonrobust   LLR p-value:                   0.03477
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept            0.1459      0.434      0.336      0.737      -0.705       0.997
human_difficulty    -0.3789      0.182     -2.087      0.037      -0.735      -0.023
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      440
Method:                           MLE   Df Model:                            6
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:                 0.01566
Time:                        20:46:34   Log-Likelihood:                -276.53
converged:                       True   LL-Null:                       -280.93
Covariance Type:            nonrobust   LLR p-value:                    0.1853
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -0.9536      1.512     -0.631      0.528      -3.917       2.009
C(domain_grouped)[T.chemistry]        0.1312      0.324      0.405      0.686      -0.504       0.767
C(domain_grouped)[T.physics]          0.1738      0.329      0.528      0.597      -0.471       0.819
human_difficulty                     -0.4029      0.188     -2.146      0.032      -0.771      -0.035
q_length                              0.2821      0.171      1.654      0.098      -0.052       0.616
avg_word_length                      -0.1178      0.172     -0.684      0.494      -0.455       0.220
percent_non_alphabetic_whitespace    -0.0119      0.019     -0.624      0.533      -0.049       0.026
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 0.6857
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      439
Method:                           MLE   Df Model:                            7
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:                  0.1091
Time:                        20:46:34   Log-Likelihood:                -250.29
converged:                       True   LL-Null:                       -280.93
Covariance Type:            nonrobust   LLR p-value:                 8.359e-11
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -1.5586      1.562     -0.998      0.318      -4.619       1.502
C(domain_grouped)[T.chemistry]       -0.5510      0.359     -1.536      0.125      -1.254       0.152
C(domain_grouped)[T.physics]         -0.2987      0.358     -0.833      0.405      -1.001       0.404
human_difficulty                     -0.3667      0.198     -1.853      0.064      -0.754       0.021
q_length                              0.1977      0.178      1.114      0.265      -0.150       0.546
avg_word_length                      -0.0289      0.176     -0.165      0.869      -0.373       0.315
percent_non_alphabetic_whitespace    -0.0105      0.021     -0.510      0.610      -0.051       0.030
capabilities_entropy                  1.4209      0.208      6.843      0.000       1.014       1.828
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      439
Method:                           MLE   Df Model:                            7
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:                  0.1237
Time:                        20:46:34   Log-Likelihood:                -246.19
converged:                       True   LL-Null:                       -280.93
Covariance Type:            nonrobust   LLR p-value:                 1.881e-12
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -1.7949      1.615     -1.112      0.266      -4.959       1.370
C(domain_grouped)[T.chemistry]       -0.4286      0.357     -1.200      0.230      -1.129       0.271
C(domain_grouped)[T.physics]         -0.2710      0.363     -0.747      0.455      -0.982       0.440
human_difficulty                     -0.3034      0.203     -1.498      0.134      -0.700       0.094
q_length                              0.2265      0.186      1.215      0.224      -0.139       0.592
avg_word_length                      -0.0895      0.177     -0.505      0.613      -0.437       0.258
percent_non_alphabetic_whitespace     0.0023      0.021      0.111      0.911      -0.038       0.043
game_entropy                          1.7277      0.237      7.279      0.000       1.262       2.193
=====================================================================================================

                  Model 4.95: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      438
Method:                           MLE   Df Model:                            8
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:                  0.1482
Time:                        20:46:34   Log-Likelihood:                -239.29
converged:                       True   LL-Null:                       -280.93
Covariance Type:            nonrobust   LLR p-value:                 1.063e-14
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -1.9701      1.622     -1.215      0.224      -5.149       1.208
C(domain_grouped)[T.chemistry]       -0.7112      0.373     -1.906      0.057      -1.442       0.020
C(domain_grouped)[T.physics]         -0.4534      0.374     -1.212      0.226      -1.187       0.280
human_difficulty                     -0.3068      0.205     -1.494      0.135      -0.709       0.096
q_length                              0.1995      0.186      1.074      0.283      -0.164       0.563
avg_word_length                      -0.0484      0.179     -0.270      0.787      -0.400       0.303
percent_non_alphabetic_whitespace    -0.0003      0.021     -0.013      0.990      -0.042       0.041
capabilities_entropy                  0.8779      0.238      3.683      0.000       0.411       1.345
game_entropy                          1.2503      0.271      4.611      0.000       0.719       1.782
=====================================================================================================

--- Analyzing grok-3-latest (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_new/grok-3-latest_GPQA_redacted_cor_temp0.0_1751718817_game_data.json', './sc_logs_new/grok-3-latest_GPQA_redacted_temp0.0_1751719817_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    328
1    119
Name: count, dtype: int64

Answer change%: 0.2662 [0.22524629171821187, 0.30719218702899176] (n=447)
P-value vs 25%: 0.4378; P-value vs 0%: 3.791e-37
Phase 2 self-accuracy: 0.3193 [0.2355628537906747, 0.4030926083941992] (n=119)
P-value vs 25%: 0.1048; P-value vs 33%: 0.749

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:                 0.01139
Time:                        20:46:34   Log-Likelihood:                -256.07
converged:                       True   LL-Null:                       -259.02
Covariance Type:            nonrobust   LLR p-value:                   0.01512
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept         -0.1112      0.377     -0.295      0.768      -0.850       0.628
p_i_capability    -1.0426      0.422     -2.472      0.013      -1.869      -0.216
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  433
Model:                          Logit   Df Residuals:                      431
Method:                           MLE   Df Model:                            1
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:                 0.09024
Time:                        20:46:34   Log-Likelihood:                -228.01
converged:                       True   LL-Null:                       -250.63
Covariance Type:            nonrobust   LLR p-value:                 1.750e-11
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.6296      0.155    -10.523      0.000      -1.933      -1.326
capabilities_entropy     1.7688      0.271      6.518      0.000       1.237       2.301
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.7105 [0.6273, 0.7938] (n=114)
                  P-value vs 33.3%: 6.676e-19

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=3.61, p=0.000353
Wilcoxon delta_p: statistic=15077.00, p=5.69e-08
Mean Δp = 0.0328  [0.0150, 0.0506]
Idea 1 N = 306; 

  Idea 1.5: Calibration Metrics
  NLL: 3.7898, Signed ECE (overconf pos under neg): 0.0021, ECE: 0.0384 (n=420)
  Brier: 0.0094, Reliability (absolute calibration error; lower better): 0.0079, Resolution (relative calibration quality; higher better): 0.2470, Uncertainty: 0.2482 (n=420)
  AUROC: 1.0000

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.832
Model:                            OLS   Adj. R-squared:                  0.831
Method:                 Least Squares   F-statistic:                     685.9
Date:                Thu, 18 Sep 2025   Prob (F-statistic):          1.34e-160
Time:                        20:46:34   Log-Likelihood:                 212.81
No. Observations:                 420   AIC:                            -417.6
Df Residuals:                     416   BIC:                            -401.5
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.4708      0.071     -6.644      0.000      -0.610      -0.332
p1                    0.5330      0.074      7.157      0.000       0.387       0.679
answer_changed        0.3702      0.105      3.519      0.000       0.163       0.577
p1:answer_changed     0.4340      0.116      3.740      0.000       0.206       0.662
==============================================================================
Omnibus:                      162.477   Durbin-Watson:                   2.048
Prob(Omnibus):                  0.000   Jarque-Bera (JB):              790.761
Skew:                           1.619   Prob(JB):                    1.94e-172
Kurtosis:                       8.891   Cond. No.                         34.3
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=0.30, p=0.766
Wilcoxon delta_H: statistic=22815.00, p=0.665
Mean ΔH = 0.0083  [-0.0462, 0.0628]
Paired t-test delta_H Changed: statistic=4.18, p=5.87e-05
Wilcoxon delta_H Changed: statistic=1943.00, p=0.000161
Mean ΔH Changed = 0.1632  [0.0866, 0.2398]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=-1.52, p=0.13
Wilcoxon (p_top2_game vs p_top2_base): statistic=30870.00, p=8.45e-08
Mean Δp_top2 = -0.0037  [-0.0085, 0.0011] (n=420)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=2.18, p=0.0299
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=38731.00, p=0.0279
Mean ΔH_unchosen_baseline_set = 0.0503  [0.0051, 0.0956] (n=420)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  420
Model:                          Logit   Df Residuals:                      417
Method:                           MLE   Df Model:                            2
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:                 0.08826
Time:                        20:46:34   Log-Likelihood:                -223.89
converged:                       True   LL-Null:                       -245.56
Covariance Type:            nonrobust   LLR p-value:                 3.863e-10
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.7482      0.146     -5.128      0.000      -1.034      -0.462
p1_z            -1.2350      0.222     -5.572      0.000      -1.669      -0.801
I(p1_z ** 2)    -0.3323      0.100     -3.334      0.001      -0.528      -0.137
================================================================================
AUC = 0.780

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:                  0.1186
Time:                        20:46:34   Log-Likelihood:                -228.29
converged:                       True   LL-Null:                       -259.02
Covariance Type:            nonrobust   LLR p-value:                 4.535e-15
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.8881      0.175    -10.795      0.000      -2.231      -1.545
game_entropy     1.8730      0.251      7.459      0.000       1.381       2.365
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=33000.00, p=8.06e-08
Paired t-test (game_entropy vs capabilities_entropy): statistic=4.68, p=3.86e-06
Mean capabilities_entropy-game_entropy = -0.0993  [-0.1409, -0.0577] (n=433)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  433
Model:                          Logit   Df Residuals:                      430
Method:                           MLE   Df Model:                            2
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:                  0.1421
Time:                        20:46:34   Log-Likelihood:                -215.01
converged:                       True   LL-Null:                       -250.63
Covariance Type:            nonrobust   LLR p-value:                 3.395e-16
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.0785      0.193    -10.793      0.000      -2.456      -1.701
capabilities_entropy     1.1812      0.297      3.973      0.000       0.598       1.764
game_entropy             1.3938      0.275      5.062      0.000       0.854       1.933
========================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:                0.002963
Time:                        20:46:34   Log-Likelihood:                -258.25
converged:                       True   LL-Null:                       -259.02
Covariance Type:            nonrobust   LLR p-value:                    0.2154
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -0.4642      0.456     -1.018      0.308      -1.357       0.429
human_difficulty    -0.2337      0.190     -1.231      0.218      -0.606       0.138
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      440
Method:                           MLE   Df Model:                            6
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:                 0.01363
Time:                        20:46:34   Log-Likelihood:                -255.49
converged:                       True   LL-Null:                       -259.02
Covariance Type:            nonrobust   LLR p-value:                    0.3152
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -1.5351      1.571     -0.977      0.329      -4.614       1.544
C(domain_grouped)[T.chemistry]        0.7490      0.364      2.060      0.039       0.036       1.461
C(domain_grouped)[T.physics]          0.6567      0.373      1.760      0.078      -0.075       1.388
human_difficulty                     -0.1816      0.195     -0.932      0.352      -0.564       0.200
q_length                             -0.0636      0.175     -0.362      0.717      -0.407       0.280
avg_word_length                       0.1690      0.173      0.979      0.328      -0.169       0.507
percent_non_alphabetic_whitespace    -0.0061      0.020     -0.307      0.759      -0.045       0.033
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 0.2951
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  433
Model:                          Logit   Df Residuals:                      425
Method:                           MLE   Df Model:                            7
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:                 0.09956
Time:                        20:46:34   Log-Likelihood:                -225.68
converged:                       True   LL-Null:                       -250.63
Covariance Type:            nonrobust   LLR p-value:                 1.506e-08
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -2.6184      1.648     -1.589      0.112      -5.848       0.611
C(domain_grouped)[T.chemistry]        0.3177      0.388      0.818      0.413      -0.443       1.079
C(domain_grouped)[T.physics]          0.1536      0.405      0.379      0.705      -0.640       0.947
human_difficulty                     -0.2012      0.208     -0.965      0.334      -0.610       0.207
q_length                             -0.0101      0.187     -0.054      0.957      -0.376       0.356
avg_word_length                       0.2747      0.178      1.542      0.123      -0.074       0.624
percent_non_alphabetic_whitespace     0.0043      0.021      0.207      0.836      -0.036       0.045
capabilities_entropy                  1.8090      0.282      6.423      0.000       1.257       2.361
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      439
Method:                           MLE   Df Model:                            7
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:                  0.1340
Time:                        20:46:34   Log-Likelihood:                -224.30
converged:                       True   LL-Null:                       -259.02
Covariance Type:            nonrobust   LLR p-value:                 1.923e-12
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -3.5498      1.701     -2.087      0.037      -6.883      -0.216
C(domain_grouped)[T.chemistry]        0.5342      0.392      1.363      0.173      -0.234       1.302
C(domain_grouped)[T.physics]          0.6967      0.409      1.704      0.088      -0.105       1.498
human_difficulty                     -0.2388      0.211     -1.133      0.257      -0.652       0.174
q_length                             -0.0574      0.189     -0.304      0.761      -0.427       0.312
avg_word_length                       0.4145      0.187      2.213      0.027       0.047       0.782
percent_non_alphabetic_whitespace     0.0100      0.021      0.466      0.641      -0.032       0.052
game_entropy                          1.9507      0.261      7.487      0.000       1.440       2.461
=====================================================================================================

                  Model 4.95: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  433
Model:                          Logit   Df Residuals:                      424
Method:                           MLE   Df Model:                            8
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:                  0.1549
Time:                        20:46:34   Log-Likelihood:                -211.80
converged:                       True   LL-Null:                       -250.63
Covariance Type:            nonrobust   LLR p-value:                 1.442e-13
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -3.6297      1.717     -2.114      0.035      -6.996      -0.264
C(domain_grouped)[T.chemistry]        0.2344      0.407      0.576      0.564      -0.563       1.032
C(domain_grouped)[T.physics]          0.2972      0.427      0.696      0.487      -0.540       1.134
human_difficulty                     -0.2522      0.216     -1.167      0.243      -0.676       0.171
q_length                             -0.0291      0.193     -0.151      0.880      -0.407       0.348
avg_word_length                       0.4153      0.188      2.205      0.027       0.046       0.785
percent_non_alphabetic_whitespace     0.0138      0.022      0.640      0.522      -0.029       0.056
capabilities_entropy                  1.2169      0.309      3.934      0.000       0.611       1.823
game_entropy                          1.4784      0.284      5.205      0.000       0.922       2.035
=====================================================================================================

--- Analyzing qwen3-235b-a22b-2507 (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_new/qwen3-235b-a22b-2507_GPQA_redacted_cor_temp0.0_1756235281_game_data.json', './sc_logs_new/qwen3-235b-a22b-2507_GPQA_redacted_temp0.0_1756233720_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    326
1    121
Name: count, dtype: int64

Answer change%: 0.2707 [0.22950384429701254, 0.31188318031148854] (n=447)
P-value vs 25%: 0.3248; P-value vs 0%: 5.785e-38
Phase 2 self-accuracy: 0.2975 [0.21606322273406486, 0.37897809957998474] (n=121)
P-value vs 25%: 0.2529; P-value vs 33%: 0.3933

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:                 0.05636
Time:                        20:46:34   Log-Likelihood:                -246.31
converged:                       True   LL-Null:                       -261.02
Covariance Type:            nonrobust   LLR p-value:                 5.816e-08
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          1.9413      0.548      3.540      0.000       0.866       3.016
p_i_capability    -3.3458      0.622     -5.383      0.000      -4.564      -2.128
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:                 0.05771
Time:                        20:46:34   Log-Likelihood:                -245.96
converged:                       True   LL-Null:                       -261.02
Covariance Type:            nonrobust   LLR p-value:                 4.047e-08
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.4749      0.148     -9.966      0.000      -1.765      -1.185
capabilities_entropy     1.1150      0.205      5.439      0.000       0.713       1.517
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.7190 [0.6389, 0.7991] (n=121)
                  P-value vs 33.3%: 3.784e-21

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=2.52, p=0.0125
Wilcoxon delta_p: statistic=11675.00, p=1.31e-05
Mean Δp = 0.0297  [0.0066, 0.0529]
Idea 1 N = 263; 

  Idea 1.5: Calibration Metrics
  NLL: 6.4714, Signed ECE (overconf pos under neg): -0.0125, ECE: 0.0522 (n=367)
  Brier: 0.0243, Reliability (absolute calibration error; lower better): 0.0126, Resolution (relative calibration quality; higher better): 0.2376, Uncertainty: 0.2492 (n=367)
  AUROC: 0.9972

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.786
Model:                            OLS   Adj. R-squared:                  0.784
Method:                 Least Squares   F-statistic:                     453.8
Date:                Thu, 18 Sep 2025   Prob (F-statistic):          9.51e-124
Time:                        20:46:34   Log-Likelihood:                 135.81
No. Observations:                 375   AIC:                            -263.6
Df Residuals:                     371   BIC:                            -247.9
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.6154      0.064     -9.607      0.000      -0.741      -0.489
p1                    0.7082      0.069     10.207      0.000       0.572       0.845
answer_changed        0.2825      0.096      2.952      0.003       0.094       0.471
p1:answer_changed     0.4813      0.109      4.426      0.000       0.267       0.695
==============================================================================
Omnibus:                       51.559   Durbin-Watson:                   1.941
Prob(Omnibus):                  0.000   Jarque-Bera (JB):              190.597
Skew:                           0.541   Prob(JB):                     4.10e-42
Kurtosis:                       6.321   Cond. No.                         25.6
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-8.01, p=3.68e-14
Wilcoxon delta_H: statistic=8575.00, p=2.95e-12
Mean ΔH = -0.2971  [-0.3698, -0.2244]
Paired t-test delta_H Changed: statistic=0.38, p=0.703
Wilcoxon delta_H Changed: statistic=3218.00, p=0.994
Mean ΔH Changed = 0.0205  [-0.0847, 0.1257]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=-1.11, p=0.268
Wilcoxon (p_top2_game vs p_top2_base): statistic=22832.00, p=3.38e-09
Mean Δp_top2 = -0.0033  [-0.0092, 0.0026] (n=376)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=-6.42, p=4.14e-10
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=22718.00, p=3.62e-09
Mean ΔH_unchosen_baseline_set = -0.2017  [-0.2632, -0.1401] (n=376)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  376
Model:                          Logit   Df Residuals:                      373
Method:                           MLE   Df Model:                            2
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:                 0.04544
Time:                        20:46:34   Log-Likelihood:                -219.41
converged:                       True   LL-Null:                       -229.85
Covariance Type:            nonrobust   LLR p-value:                 2.910e-05
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.7592      0.170     -4.478      0.000      -1.091      -0.427
p1_z            -0.6640      0.212     -3.139      0.002      -1.079      -0.249
I(p1_z ** 2)    -0.1297      0.130     -0.997      0.319      -0.385       0.125
================================================================================
AUC = 0.642

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:                  0.1319
Time:                        20:46:34   Log-Likelihood:                -226.60
converged:                       True   LL-Null:                       -261.02
Covariance Type:            nonrobust   LLR p-value:                 1.064e-16
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.9869      0.185    -10.730      0.000      -2.350      -1.624
game_entropy     1.8372      0.236      7.792      0.000       1.375       2.299
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=35325.00, p=0.000207
Paired t-test (game_entropy vs capabilities_entropy): statistic=2.88, p=0.00416
Mean capabilities_entropy-game_entropy = -0.0788  [-0.1325, -0.0252] (n=447)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      444
Method:                           MLE   Df Model:                            2
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:                  0.1508
Time:                        20:46:34   Log-Likelihood:                -221.66
converged:                       True   LL-Null:                       -261.02
Covariance Type:            nonrobust   LLR p-value:                 8.060e-18
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.1830      0.201    -10.854      0.000      -2.577      -1.789
capabilities_entropy     0.7147      0.226      3.159      0.002       0.271       1.158
game_entropy             1.6364      0.244      6.693      0.000       1.157       2.116
========================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:               0.0001198
Time:                        20:46:34   Log-Likelihood:                -260.99
converged:                       True   LL-Null:                       -261.02
Covariance Type:            nonrobust   LLR p-value:                    0.8025
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -0.8809      0.453     -1.945      0.052      -1.769       0.007
human_difficulty    -0.0465      0.186     -0.250      0.803      -0.412       0.318
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      440
Method:                           MLE   Df Model:                            6
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:                 0.01733
Time:                        20:46:34   Log-Likelihood:                -256.50
converged:                       True   LL-Null:                       -261.02
Covariance Type:            nonrobust   LLR p-value:                    0.1710
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -1.5412      1.580     -0.975      0.329      -4.638       1.556
C(domain_grouped)[T.chemistry]        0.8367      0.359      2.329      0.020       0.132       1.541
C(domain_grouped)[T.physics]          0.4021      0.372      1.080      0.280      -0.328       1.132
human_difficulty                      0.0656      0.195      0.336      0.737      -0.317       0.448
q_length                             -0.0826      0.175     -0.471      0.637      -0.426       0.261
avg_word_length                       0.0607      0.175      0.348      0.728      -0.281       0.403
percent_non_alphabetic_whitespace     0.0080      0.019      0.414      0.679      -0.030       0.046
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 0.3771
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      439
Method:                           MLE   Df Model:                            7
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:                 0.06690
Time:                        20:46:34   Log-Likelihood:                -243.56
converged:                       True   LL-Null:                       -261.02
Covariance Type:            nonrobust   LLR p-value:                 1.156e-05
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -2.0818      1.611     -1.292      0.196      -5.239       1.076
C(domain_grouped)[T.chemistry]        0.5207      0.373      1.395      0.163      -0.211       1.252
C(domain_grouped)[T.physics]          0.1727      0.385      0.449      0.653      -0.581       0.927
human_difficulty                      0.0933      0.202      0.461      0.645      -0.303       0.490
q_length                             -0.0685      0.180     -0.380      0.704      -0.421       0.284
avg_word_length                       0.0865      0.178      0.487      0.626      -0.261       0.434
percent_non_alphabetic_whitespace     0.0134      0.020      0.670      0.503      -0.026       0.052
capabilities_entropy                  1.0589      0.210      5.042      0.000       0.647       1.470
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      439
Method:                           MLE   Df Model:                            7
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:                  0.1478
Time:                        20:46:34   Log-Likelihood:                -222.44
converged:                       True   LL-Null:                       -261.02
Covariance Type:            nonrobust   LLR p-value:                 5.183e-14
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -3.0384      1.699     -1.789      0.074      -6.367       0.291
C(domain_grouped)[T.chemistry]        0.4808      0.388      1.238      0.216      -0.280       1.242
C(domain_grouped)[T.physics]          0.1368      0.402      0.340      0.734      -0.652       0.925
human_difficulty                      0.1027      0.209      0.492      0.623      -0.307       0.512
q_length                             -0.1786      0.192     -0.928      0.353      -0.556       0.199
avg_word_length                       0.2922      0.184      1.585      0.113      -0.069       0.654
percent_non_alphabetic_whitespace     0.0241      0.021      1.145      0.252      -0.017       0.065
game_entropy                          1.9040      0.247      7.694      0.000       1.419       2.389
=====================================================================================================

                  Model 4.95: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      438
Method:                           MLE   Df Model:                            8
Date:                Thu, 18 Sep 2025   Pseudo R-squ.:                  0.1642
Time:                        20:46:34   Log-Likelihood:                -218.16
converged:                       True   LL-Null:                       -261.02
Covariance Type:            nonrobust   LLR p-value:                 3.426e-15
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -3.2410      1.712     -1.893      0.058      -6.597       0.115
C(domain_grouped)[T.chemistry]        0.3227      0.395      0.816      0.414      -0.452       1.097
C(domain_grouped)[T.physics]          0.0168      0.409      0.041      0.967      -0.785       0.818
human_difficulty                      0.1190      0.212      0.561      0.574      -0.296       0.534
q_length                             -0.1648      0.195     -0.844      0.399      -0.548       0.218
avg_word_length                       0.2909      0.185      1.569      0.117      -0.072       0.654
percent_non_alphabetic_whitespace     0.0255      0.021      1.192      0.233      -0.016       0.067
capabilities_entropy                  0.6792      0.231      2.937      0.003       0.226       1.132
game_entropy                          1.7315      0.255      6.779      0.000       1.231       2.232
=====================================================================================================
