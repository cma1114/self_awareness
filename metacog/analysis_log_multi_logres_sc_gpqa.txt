
--- Analyzing claude-3-5-sonnet-20241022 (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./secondchance_game_logs/claude-3-5-sonnet-20241022_GPQA_redacted_cor_temp0.0_1750775279_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    168
1     23
Name: count, dtype: int64

Answer change%: 0.1204 [0.07426407732768933, 0.1665736190073892] (n=191)
P-value vs 25%: 3.741e-08; P-value vs 0%: 3.161e-07
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=23)
P-value vs 25%: 0; P-value vs 33%: 0

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  191
Model:                          Logit   Df Residuals:                      189
Method:                           MLE   Df Model:                            1
Date:                Fri, 04 Jul 2025   Pseudo R-squ.:                 0.01241
Time:                        22:35:04   Log-Likelihood:                -69.370
converged:                       True   LL-Null:                       -70.242
Covariance Type:            nonrobust   LLR p-value:                    0.1866
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -0.7598      0.944     -0.805      0.421      -2.610       1.090
human_difficulty    -0.5311      0.407     -1.304      0.192      -1.329       0.267
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  191
Model:                          Logit   Df Residuals:                      184
Method:                           MLE   Df Model:                            6
Date:                Fri, 04 Jul 2025   Pseudo R-squ.:                 0.04635
Time:                        22:35:04   Log-Likelihood:                -66.986
converged:                       True   LL-Null:                       -70.242
Covariance Type:            nonrobust   LLR p-value:                    0.3684
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -1.7259      3.319     -0.520      0.603      -8.232       4.780
C(domain_grouped)[T.chemistry]        0.1100      0.827      0.133      0.894      -1.511       1.731
C(domain_grouped)[T.physics]          0.9727      0.741      1.313      0.189      -0.479       2.425
human_difficulty                     -0.4513      0.413     -1.092      0.275      -1.262       0.359
q_length                             -0.2402      0.388     -0.619      0.536      -1.000       0.520
avg_word_length                       0.2695      0.362      0.745      0.456      -0.439       0.978
percent_non_alphabetic_whitespace     0.0444      0.040      1.102      0.271      -0.035       0.123
=====================================================================================================

--- Analyzing claude-3-5-sonnet-20241022 (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./secondchance_game_logs/claude-3-5-sonnet-20241022_GPQA_redacted_temp0.0_1750638230_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    164
1     92
Name: count, dtype: int64

Answer change%: 0.3594 [0.30059846488790765, 0.41815153511209235] (n=256)
P-value vs 25%: 0.0002651; P-value vs 0%: 4.324e-33
Phase 2 self-accuracy: 0.2826 [0.1906008224868458, 0.374616568817502] (n=92)
P-value vs 25%: 0.4873; P-value vs 33%: 0.2831

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  256
Model:                          Logit   Df Residuals:                      254
Method:                           MLE   Df Model:                            1
Date:                Fri, 04 Jul 2025   Pseudo R-squ.:                0.001160
Time:                        22:35:04   Log-Likelihood:                -166.99
converged:                       True   LL-Null:                       -167.18
Covariance Type:            nonrobust   LLR p-value:                    0.5335
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -0.9088      0.548     -1.659      0.097      -1.983       0.165
human_difficulty     0.1394      0.224      0.623      0.533      -0.299       0.578
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  256
Model:                          Logit   Df Residuals:                      249
Method:                           MLE   Df Model:                            6
Date:                Fri, 04 Jul 2025   Pseudo R-squ.:                0.005340
Time:                        22:35:04   Log-Likelihood:                -166.29
converged:                       True   LL-Null:                       -167.18
Covariance Type:            nonrobust   LLR p-value:                    0.9383
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -1.3885      1.978     -0.702      0.483      -5.266       2.489
C(domain_grouped)[T.chemistry]        0.2287      0.478      0.478      0.632      -0.708       1.165
C(domain_grouped)[T.physics]          0.4430      0.498      0.889      0.374      -0.534       1.420
human_difficulty                      0.1858      0.233      0.798      0.425      -0.270       0.642
q_length                             -0.0758      0.211     -0.360      0.719      -0.489       0.337
avg_word_length                       0.0924      0.216      0.427      0.669      -0.331       0.516
percent_non_alphabetic_whitespace     0.0122      0.024      0.519      0.604      -0.034       0.058
=====================================================================================================

--- Analyzing claude-3-haiku-20240307 (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./secondchance_game_logs/claude-3-haiku-20240307_GPQA_redacted_cor_temp0.0_1751316780_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    107
1     29
Name: count, dtype: int64

Answer change%: 0.2132 [0.14439691809619587, 0.28207367013909823] (n=136)
P-value vs 25%: 0.2952; P-value vs 0%: 1.269e-09
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=29)
P-value vs 25%: 0; P-value vs 33%: 0

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  136
Model:                          Logit   Df Residuals:                      134
Method:                           MLE   Df Model:                            1
Date:                Fri, 04 Jul 2025   Pseudo R-squ.:               0.0005736
Time:                        22:35:04   Log-Likelihood:                -70.436
converged:                       True   LL-Null:                       -70.477
Covariance Type:            nonrobust   LLR p-value:                    0.7762
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -1.0383      0.962     -1.080      0.280      -2.923       0.847
human_difficulty    -0.1127      0.397     -0.284      0.777      -0.891       0.666
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  136
Model:                          Logit   Df Residuals:                      129
Method:                           MLE   Df Model:                            6
Date:                Fri, 04 Jul 2025   Pseudo R-squ.:                 0.03355
Time:                        22:35:04   Log-Likelihood:                -68.112
converged:                       True   LL-Null:                       -70.477
Covariance Type:            nonrobust   LLR p-value:                    0.5789
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -2.9898      3.031     -0.986      0.324      -8.931       2.951
C(domain_grouped)[T.chemistry]        1.3056      0.702      1.860      0.063      -0.070       2.681
C(domain_grouped)[T.physics]          1.1726      0.706      1.661      0.097      -0.211       2.556
human_difficulty                     -0.0345      0.398     -0.087      0.931      -0.814       0.745
q_length                              0.0614      0.386      0.159      0.874      -0.695       0.818
avg_word_length                       0.1501      0.280      0.536      0.592      -0.399       0.699
percent_non_alphabetic_whitespace    -0.0403      0.041     -0.989      0.323      -0.120       0.040
=====================================================================================================

--- Analyzing claude-3-haiku-20240307 (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./secondchance_game_logs/claude-3-haiku-20240307_GPQA_redacted_temp0.0_1750638196_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    242
1     69
Name: count, dtype: int64

Answer change%: 0.2219 [0.17568646090609805, 0.2680434426308795] (n=311)
P-value vs 25%: 0.2324; P-value vs 0%: 4.656e-21
Phase 2 self-accuracy: 0.3333 [0.2221045238738893, 0.44456214279277734] (n=69)
P-value vs 25%: 0.142; P-value vs 33%: 0.9953

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  311
Model:                          Logit   Df Residuals:                      309
Method:                           MLE   Df Model:                            1
Date:                Fri, 04 Jul 2025   Pseudo R-squ.:                0.002109
Time:                        22:35:04   Log-Likelihood:                -164.25
converged:                       True   LL-Null:                       -164.60
Covariance Type:            nonrobust   LLR p-value:                    0.4048
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -0.7987      0.563     -1.419      0.156      -1.902       0.304
human_difficulty    -0.1943      0.234     -0.829      0.407      -0.654       0.265
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  311
Model:                          Logit   Df Residuals:                      304
Method:                           MLE   Df Model:                            6
Date:                Fri, 04 Jul 2025   Pseudo R-squ.:                 0.02324
Time:                        22:35:04   Log-Likelihood:                -160.77
converged:                       True   LL-Null:                       -164.60
Covariance Type:            nonrobust   LLR p-value:                    0.2648
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -1.5359      2.133     -0.720      0.472      -5.717       2.645
C(domain_grouped)[T.chemistry]        0.2725      0.494      0.552      0.581      -0.696       1.241
C(domain_grouped)[T.physics]          0.8956      0.499      1.795      0.073      -0.082       1.874
human_difficulty                     -0.1655      0.238     -0.694      0.488      -0.633       0.302
q_length                             -0.2245      0.217     -1.037      0.300      -0.649       0.200
avg_word_length                       0.3045      0.253      1.202      0.229      -0.192       0.801
percent_non_alphabetic_whitespace     0.0080      0.026      0.310      0.756      -0.042       0.058
=====================================================================================================

--- Analyzing claude-3-sonnet-20240229 (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./secondchance_game_logs/claude-3-sonnet-20240229_GPQA_redacted_temp0.0_1750639213_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    227
1     74
Name: count, dtype: int64

Answer change%: 0.2458 [0.19720341618973009, 0.29449093596973835] (n=301)
P-value vs 25%: 0.8671; P-value vs 0%: 3.931e-23
Phase 2 self-accuracy: 0.3108 [0.205360098555157, 0.4162615230664646] (n=74)
P-value vs 25%: 0.2584; P-value vs 33%: 0.68

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  301
Model:                          Logit   Df Residuals:                      299
Method:                           MLE   Df Model:                            1
Date:                Fri, 04 Jul 2025   Pseudo R-squ.:                0.002603
Time:                        22:35:04   Log-Likelihood:                -167.44
converged:                       True   LL-Null:                       -167.88
Covariance Type:            nonrobust   LLR p-value:                    0.3499
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -0.5979      0.574     -1.041      0.298      -1.724       0.528
human_difficulty    -0.2223      0.239     -0.929      0.353      -0.691       0.247
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  301
Model:                          Logit   Df Residuals:                      294
Method:                           MLE   Df Model:                            6
Date:                Fri, 04 Jul 2025   Pseudo R-squ.:                 0.01347
Time:                        22:35:04   Log-Likelihood:                -165.61
converged:                       True   LL-Null:                       -167.88
Covariance Type:            nonrobust   LLR p-value:                    0.6062
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -2.0080      1.971     -1.019      0.308      -5.871       1.855
C(domain_grouped)[T.chemistry]        0.1367      0.497      0.275      0.784      -0.838       1.112
C(domain_grouped)[T.physics]          0.6095      0.499      1.223      0.221      -0.368       1.587
human_difficulty                     -0.2008      0.246     -0.817      0.414      -0.682       0.281
q_length                              0.0136      0.215      0.063      0.949      -0.408       0.436
avg_word_length                       0.1588      0.214      0.741      0.458      -0.261       0.579
percent_non_alphabetic_whitespace     0.0234      0.024      0.993      0.321      -0.023       0.070
=====================================================================================================

--- Analyzing claude-sonnet-4-20250514 (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./secondchance_game_logs/claude-sonnet-4-20250514_GPQA_redacted_cor_temp0.0_1750937990_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    161
1     90
Name: count, dtype: int64

Answer change%: 0.3586 [0.2992360986367705, 0.4178953754668152] (n=251)
P-value vs 25%: 0.0003352; P-value vs 0%: 2.277e-32
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=90)
P-value vs 25%: 0; P-value vs 33%: 0

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  251
Model:                          Logit   Df Residuals:                      249
Method:                           MLE   Df Model:                            1
Date:                Fri, 04 Jul 2025   Pseudo R-squ.:                0.004176
Time:                        22:35:04   Log-Likelihood:                -163.12
converged:                       True   LL-Null:                       -163.80
Covariance Type:            nonrobust   LLR p-value:                    0.2422
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept            0.0471      0.554      0.085      0.932      -1.038       1.133
human_difficulty    -0.2689      0.231     -1.162      0.245      -0.722       0.185
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  251
Model:                          Logit   Df Residuals:                      244
Method:                           MLE   Df Model:                            6
Date:                Fri, 04 Jul 2025   Pseudo R-squ.:                 0.06247
Time:                        22:35:04   Log-Likelihood:                -153.57
converged:                       True   LL-Null:                       -163.80
Covariance Type:            nonrobust   LLR p-value:                  0.002286
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -2.2876      2.071     -1.105      0.269      -6.346       1.771
C(domain_grouped)[T.chemistry]        0.8206      0.470      1.747      0.081      -0.100       1.741
C(domain_grouped)[T.physics]          0.8693      0.462      1.883      0.060      -0.035       1.774
human_difficulty                     -0.1117      0.247     -0.452      0.651      -0.596       0.373
q_length                              0.5037      0.247      2.038      0.042       0.019       0.988
avg_word_length                      -0.3958      0.252     -1.569      0.117      -0.890       0.099
percent_non_alphabetic_whitespace     0.0099      0.025      0.399      0.690      -0.039       0.058
=====================================================================================================

--- Analyzing claude-sonnet-4-20250514 (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./secondchance_game_logs/claude-sonnet-4-20250514_GPQA_redacted_temp0.0_1750937041_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
1    113
0     83
Name: count, dtype: int64

Answer change%: 0.5765 [0.5073567138094872, 0.6457045106803088] (n=196)
P-value vs 25%: 2.206e-20; P-value vs 0%: 5.532e-60
Phase 2 self-accuracy: 0.2832 [0.20011513032038655, 0.36625655109554267] (n=113)
P-value vs 25%: 0.4336; P-value vs 33%: 0.2399

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  196
Model:                          Logit   Df Residuals:                      194
Method:                           MLE   Df Model:                            1
Date:                Fri, 04 Jul 2025   Pseudo R-squ.:                0.005744
Time:                        22:35:04   Log-Likelihood:                -132.78
converged:                       True   LL-Null:                       -133.55
Covariance Type:            nonrobust   LLR p-value:                    0.2155
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept            1.0706      0.636      1.683      0.092      -0.176       2.318
human_difficulty    -0.3172      0.257     -1.234      0.217      -0.821       0.187
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  196
Model:                          Logit   Df Residuals:                      189
Method:                           MLE   Df Model:                            6
Date:                Fri, 04 Jul 2025   Pseudo R-squ.:                 0.02659
Time:                        22:35:04   Log-Likelihood:                -130.00
converged:                       True   LL-Null:                       -133.55
Covariance Type:            nonrobust   LLR p-value:                    0.3116
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                             1.5899      2.407      0.660      0.509      -3.128       6.308
C(domain_grouped)[T.chemistry]        0.6753      0.483      1.397      0.162      -0.272       1.622
C(domain_grouped)[T.physics]          0.1202      0.497      0.242      0.809      -0.854       1.094
human_difficulty                     -0.2451      0.267     -0.919      0.358      -0.768       0.277
q_length                              0.1485      0.236      0.630      0.529      -0.313       0.610
avg_word_length                      -0.3640      0.265     -1.374      0.169      -0.883       0.155
percent_non_alphabetic_whitespace    -0.0315      0.029     -1.095      0.274      -0.088       0.025
=====================================================================================================

--- Analyzing deepseek-chat (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./secondchance_game_logs/deepseek-chat_GPQA_redacted_temp0.0_1750801173_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    183
1     58
Name: count, dtype: int64

Answer change%: 0.2407 [0.18669270109924524, 0.2946350997306303] (n=241)
P-value vs 25%: 0.7346; P-value vs 0%: 2.337e-18
Phase 2 self-accuracy: 0.3966 [0.27065801159558067, 0.5224454366802814] (n=58)
P-value vs 25%: 0.02251; P-value vs 33%: 0.3225

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  241
Model:                          Logit   Df Residuals:                      239
Method:                           MLE   Df Model:                            1
Date:                Fri, 04 Jul 2025   Pseudo R-squ.:                 0.01263
Time:                        22:35:04   Log-Likelihood:                -131.31
converged:                       True   LL-Null:                       -132.99
Covariance Type:            nonrobust   LLR p-value:                   0.06682
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept         -1.5235      0.268     -5.692      0.000      -2.048      -0.999
p_i_capability     0.5831      0.325      1.795      0.073      -0.054       1.220
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                    Could not fit Model 1.5: Singular matrix

  Model 1.6: Answer Changed ~ Game Entropy
                    Could not fit Model 1.6: Singular matrix

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                    Could not fit Model 1.7: Singular matrix

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  241
Model:                          Logit   Df Residuals:                      239
Method:                           MLE   Df Model:                            1
Date:                Fri, 04 Jul 2025   Pseudo R-squ.:               9.187e-05
Time:                        22:35:04   Log-Likelihood:                -132.98
converged:                       True   LL-Null:                       -132.99
Covariance Type:            nonrobust   LLR p-value:                    0.8758
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -1.0520      0.638     -1.648      0.099      -2.303       0.199
human_difficulty    -0.0405      0.259     -0.156      0.876      -0.549       0.468
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  241
Model:                          Logit   Df Residuals:                      234
Method:                           MLE   Df Model:                            6
Date:                Fri, 04 Jul 2025   Pseudo R-squ.:                 0.04964
Time:                        22:35:04   Log-Likelihood:                -126.39
converged:                       True   LL-Null:                       -132.99
Covariance Type:            nonrobust   LLR p-value:                   0.03992
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                             0.4404      2.390      0.184      0.854      -4.245       5.125
C(domain_grouped)[T.chemistry]       -1.4524      0.504     -2.880      0.004      -2.441      -0.464
C(domain_grouped)[T.physics]         -0.9781      0.518     -1.887      0.059      -1.994       0.038
human_difficulty                     -0.2193      0.277     -0.792      0.428      -0.762       0.323
q_length                             -0.2750      0.240     -1.144      0.253      -0.746       0.196
avg_word_length                       0.3187      0.269      1.186      0.236      -0.208       0.846
percent_non_alphabetic_whitespace     0.0149      0.028      0.540      0.589      -0.039       0.069
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
                    Could not fit Model 4.6: Singular matrix

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + normalized_prob_entropy
                    Could not fit Model 4.8: Singular matrix

                  Model 4.95: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy + normalized_prob_entropy
                    Could not fit Model 4.95: Singular matrix

--- Analyzing gemini-1.5-pro (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./secondchance_game_logs/gemini-1.5-pro_GPQA_redacted_temp0.0_1750683374_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    196
1     50
Name: count, dtype: int64

Answer change%: 0.2033 [0.1529647151654029, 0.2535393498752475] (n=246)
P-value vs 25%: 0.06845; P-value vs 0%: 2.341e-15
Phase 2 self-accuracy: 0.5000 [0.3614096175650322, 0.6385903824349678] (n=50)
P-value vs 25%: 0.000407; P-value vs 33%: 0.01819

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  246
Model:                          Logit   Df Residuals:                      244
Method:                           MLE   Df Model:                            1
Date:                Fri, 04 Jul 2025   Pseudo R-squ.:                 0.01029
Time:                        22:35:04   Log-Likelihood:                -122.92
converged:                       True   LL-Null:                       -124.20
Covariance Type:            nonrobust   LLR p-value:                    0.1099
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -0.3260      0.670     -0.486      0.627      -1.640       0.988
human_difficulty    -0.4454      0.284     -1.567      0.117      -1.003       0.112
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  246
Model:                          Logit   Df Residuals:                      239
Method:                           MLE   Df Model:                            6
Date:                Fri, 04 Jul 2025   Pseudo R-squ.:                 0.02136
Time:                        22:35:04   Log-Likelihood:                -121.55
converged:                       True   LL-Null:                       -124.20
Covariance Type:            nonrobust   LLR p-value:                    0.5052
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -0.5112      2.575     -0.199      0.843      -5.559       4.536
C(domain_grouped)[T.chemistry]       -0.2300      0.548     -0.419      0.675      -1.305       0.845
C(domain_grouped)[T.physics]         -0.0908      0.563     -0.161      0.872      -1.195       1.013
human_difficulty                     -0.4867      0.295     -1.651      0.099      -1.064       0.091
q_length                              0.2708      0.278      0.974      0.330      -0.274       0.816
avg_word_length                      -0.2329      0.290     -0.802      0.423      -0.802       0.336
percent_non_alphabetic_whitespace    -0.0147      0.032     -0.465      0.642      -0.077       0.047
=====================================================================================================

--- Analyzing gemini-2.0-flash-001 (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./secondchance_game_logs/gemini-2.0-flash-001_GPQA_redacted_cor_temp0.0_1750863700_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    171
1     22
Name: count, dtype: int64

Answer change%: 0.1140 [0.06915418832619999, 0.15882508628519898] (n=193)
P-value vs 25%: 2.754e-09; P-value vs 0%: 6.26e-07
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=22)
P-value vs 25%: 0; P-value vs 33%: 0

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  193
Model:                          Logit   Df Residuals:                      191
Method:                           MLE   Df Model:                            1
Date:                Fri, 04 Jul 2025   Pseudo R-squ.:                 0.08466
Time:                        22:35:04   Log-Likelihood:                -62.675
converged:                       True   LL-Null:                       -68.472
Covariance Type:            nonrobust   LLR p-value:                 0.0006616
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept         -2.9652      0.431     -6.885      0.000      -3.809      -2.121
p_i_capability     1.7185      0.540      3.183      0.001       0.660       2.777
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  192
Model:                          Logit   Df Residuals:                      190
Method:                           MLE   Df Model:                            1
Date:                Fri, 04 Jul 2025   Pseudo R-squ.:                  0.1604
Time:                        22:35:04   Log-Likelihood:                -57.390
converged:                       True   LL-Null:                       -68.350
Covariance Type:            nonrobust   LLR p-value:                 2.840e-06
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.6511      0.304     -8.707      0.000      -3.248      -2.054
capabilities_entropy     2.3291      0.510      4.568      0.000       1.330       3.329
========================================================================================

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Wilcoxon delta_p: statistic=276.0, p=7.23e-06

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.242
Model:                            OLS   Adj. R-squared:                  0.211
Method:                 Least Squares   F-statistic:                     7.681
Date:                Fri, 04 Jul 2025   Prob (F-statistic):           0.000160
Time:                        22:35:04   Log-Likelihood:                -23.870
No. Observations:                  76   AIC:                             55.74
Df Residuals:                      72   BIC:                             65.06
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept             0.2547      0.316      0.806      0.423      -0.375       0.884
p1                   -0.0701      0.337     -0.208      0.836      -0.741       0.601
answer_changed       -0.3939      0.455     -0.866      0.389      -1.300       0.513
p1:answer_changed     0.9559      0.517      1.850      0.068      -0.074       1.986
==============================================================================
Omnibus:                       10.434   Durbin-Watson:                   1.881
Prob(Omnibus):                  0.005   Jarque-Bera (JB):               10.498
Skew:                           0.783   Prob(JB):                      0.00525
Kurtosis:                       3.928   Cond. No.                         27.2
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Wilcoxon delta_H: statistic=850.0, p=0.375

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)

--- Analyzing gemini-2.0-flash-001 (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./secondchance_game_logs/gemini-2.0-flash-001_GPQA_redacted_temp0.0_1750871141_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    167
1     84
Name: count, dtype: int64

Answer change%: 0.3347 [0.2762852128860139, 0.3930374962773327] (n=251)
P-value vs 25%: 0.004476; P-value vs 0%: 2.709e-29
Phase 2 self-accuracy: 0.3929 [0.2884160951285467, 0.497298190585739] (n=84)
P-value vs 25%: 0.007343; P-value vs 33%: 0.2613

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  251
Model:                          Logit   Df Residuals:                      249
Method:                           MLE   Df Model:                            1
Date:                Fri, 04 Jul 2025   Pseudo R-squ.:                 0.01551
Time:                        22:35:04   Log-Likelihood:                -157.51
converged:                       True   LL-Null:                       -160.00
Covariance Type:            nonrobust   LLR p-value:                   0.02591
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept         -1.1080      0.241     -4.594      0.000      -1.581      -0.635
p_i_capability     0.7099      0.324      2.190      0.029       0.075       1.345
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  251
Model:                          Logit   Df Residuals:                      249
Method:                           MLE   Df Model:                            1
Date:                Fri, 04 Jul 2025   Pseudo R-squ.:                 0.09112
Time:                        22:35:04   Log-Likelihood:                -145.42
converged:                       True   LL-Null:                       -160.00
Covariance Type:            nonrobust   LLR p-value:                 6.671e-08
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.2736      0.185     -6.880      0.000      -1.636      -0.911
capabilities_entropy     1.5817      0.309      5.119      0.000       0.976       2.187
========================================================================================

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Wilcoxon delta_p: statistic=1255.0, p=5.45e-05

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.546
Model:                            OLS   Adj. R-squared:                  0.537
Method:                 Least Squares   F-statistic:                     63.63
Date:                Fri, 04 Jul 2025   Prob (F-statistic):           4.41e-27
Time:                        22:35:04   Log-Likelihood:                -2.8898
No. Observations:                 163   AIC:                             13.78
Df Residuals:                     159   BIC:                             26.15
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept             0.1966      0.159      1.240      0.217      -0.117       0.510
p1                   -0.1209      0.174     -0.697      0.487      -0.464       0.222
answer_changed       -0.4362      0.213     -2.047      0.042      -0.857      -0.015
p1:answer_changed     1.1368      0.244      4.659      0.000       0.655       1.619
==============================================================================
Omnibus:                       13.528   Durbin-Watson:                   2.119
Prob(Omnibus):                  0.001   Jarque-Bera (JB):               38.140
Skew:                          -0.124   Prob(JB):                     5.22e-09
Kurtosis:                       5.357   Cond. No.                         27.6
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Wilcoxon delta_H: statistic=1824.0, p=0.0468

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)

--- Analyzing gemini-2.5-flash-preview-04-17 (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./secondchance_game_logs/gemini-2.5-flash-preview-04-17_GPQA_redacted_cor_temp0.0_1750776430_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    261
1     45
Name: count, dtype: int64

Answer change%: 0.1471 [0.10737692320782272, 0.18674072385100082] (n=306)
P-value vs 25%: 3.687e-07; P-value vs 0%: 3.772e-13
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=45)
P-value vs 25%: 0; P-value vs 33%: 0

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  306
Model:                          Logit   Df Residuals:                      304
Method:                           MLE   Df Model:                            1
Date:                Fri, 04 Jul 2025   Pseudo R-squ.:                0.001630
Time:                        22:35:04   Log-Likelihood:                -127.57
converged:                       True   LL-Null:                       -127.78
Covariance Type:            nonrobust   LLR p-value:                    0.5187
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -2.1838      0.683     -3.197      0.001      -3.522      -0.845
human_difficulty     0.1828      0.282      0.648      0.517      -0.371       0.736
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  306
Model:                          Logit   Df Residuals:                      299
Method:                           MLE   Df Model:                            6
Date:                Fri, 04 Jul 2025   Pseudo R-squ.:                 0.01794
Time:                        22:35:04   Log-Likelihood:                -125.49
converged:                       True   LL-Null:                       -127.78
Covariance Type:            nonrobust   LLR p-value:                    0.5981
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -1.9314      2.327     -0.830      0.406      -6.491       2.628
C(domain_grouped)[T.chemistry]        0.9477      0.542      1.749      0.080      -0.114       2.010
C(domain_grouped)[T.physics]          0.5001      0.535      0.935      0.350      -0.549       1.549
human_difficulty                      0.3015      0.296      1.019      0.308      -0.278       0.881
q_length                             -0.1478      0.269     -0.550      0.582      -0.674       0.379
avg_word_length                      -0.0152      0.252     -0.060      0.952      -0.509       0.478
percent_non_alphabetic_whitespace    -0.0204      0.031     -0.668      0.504      -0.080       0.040
=====================================================================================================

--- Analyzing gemini-2.5-flash-preview-04-17 (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./secondchance_game_logs/gemini-2.5-flash-preview-04-17_GPQA_redacted_temp0.0_1750640902_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    71
1    58
Name: count, dtype: int64

Answer change%: 0.4496 [0.36376904533912613, 0.5354557608624243] (n=129)
P-value vs 25%: 5.176e-06; P-value vs 0%: 1.008e-24
Phase 2 self-accuracy: 0.5862 [0.4594559591037108, 0.7129578339997373] (n=58)
P-value vs 25%: 2.006e-07; P-value vs 33%: 9.027e-05

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  129
Model:                          Logit   Df Residuals:                      127
Method:                           MLE   Df Model:                            1
Date:                Fri, 04 Jul 2025   Pseudo R-squ.:               0.0001733
Time:                        22:35:04   Log-Likelihood:                -88.744
converged:                       True   LL-Null:                       -88.760
Covariance Type:            nonrobust   LLR p-value:                    0.8607
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -0.3425      0.819     -0.418      0.676      -1.948       1.263
human_difficulty     0.0559      0.319      0.175      0.861      -0.569       0.681
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  129
Model:                          Logit   Df Residuals:                      122
Method:                           MLE   Df Model:                            6
Date:                Fri, 04 Jul 2025   Pseudo R-squ.:                 0.03305
Time:                        22:35:04   Log-Likelihood:                -85.826
converged:                       True   LL-Null:                       -88.760
Covariance Type:            nonrobust   LLR p-value:                    0.4383
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -1.4419      3.076     -0.469      0.639      -7.470       4.586
C(domain_grouped)[T.chemistry]        1.0227      0.665      1.539      0.124      -0.280       2.326
C(domain_grouped)[T.physics]          0.9621      0.721      1.335      0.182      -0.451       2.375
human_difficulty                      0.1043      0.351      0.297      0.766      -0.583       0.792
q_length                              0.2461      0.285      0.863      0.388      -0.313       0.805
avg_word_length                      -0.2870      0.358     -0.802      0.423      -0.989       0.415
percent_non_alphabetic_whitespace    -0.0043      0.038     -0.113      0.910      -0.079       0.070
=====================================================================================================

--- Analyzing gpt-4.1-2025-04-14 (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./secondchance_game_logs/gpt-4.1-2025-04-14_GPQA_redacted_cor_temp0.0_1751576170_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    155
1     52
Name: count, dtype: int64

Answer change%: 0.2512 [0.19212506212302705, 0.31029039681417103] (n=207)
P-value vs 25%: 0.968; P-value vs 0%: 7.857e-17
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=52)
P-value vs 25%: 0; P-value vs 33%: 0

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  207
Model:                          Logit   Df Residuals:                      205
Method:                           MLE   Df Model:                            1
Date:                Fri, 04 Jul 2025   Pseudo R-squ.:                 0.06591
Time:                        22:35:04   Log-Likelihood:                -108.99
converged:                       True   LL-Null:                       -116.68
Covariance Type:            nonrobust   LLR p-value:                 8.789e-05
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          3.4942      1.231      2.838      0.005       1.081       5.908
p_i_capability    -4.8821      1.302     -3.749      0.000      -7.434      -2.330
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  207
Model:                          Logit   Df Residuals:                      205
Method:                           MLE   Df Model:                            1
Date:                Fri, 04 Jul 2025   Pseudo R-squ.:                 0.08698
Time:                        22:35:04   Log-Likelihood:                -106.53
converged:                       True   LL-Null:                       -116.68
Covariance Type:            nonrobust   LLR p-value:                 6.632e-06
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.4842      0.196     -7.586      0.000      -1.868      -1.101
capabilities_entropy     1.8303      0.423      4.322      0.000       1.000       2.660
========================================================================================

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Wilcoxon delta_p: statistic=494.0, p=0.000433

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.975
Model:                            OLS   Adj. R-squared:                  0.975
Method:                 Least Squares   F-statistic:                     2571.
Date:                Fri, 04 Jul 2025   Prob (F-statistic):          1.85e-156
Time:                        22:35:04   Log-Likelihood:                 279.06
No. Observations:                 199   AIC:                            -550.1
Df Residuals:                     195   BIC:                            -536.9
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.9109      0.050    -18.311      0.000      -1.009      -0.813
p1                    0.9156      0.051     17.943      0.000       0.815       1.016
answer_changed        0.7188      0.070     10.323      0.000       0.581       0.856
p1:answer_changed     0.2475      0.075      3.309      0.001       0.100       0.395
==============================================================================
Omnibus:                      140.821   Durbin-Watson:                   2.041
Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2924.885
Skew:                          -2.300   Prob(JB):                         0.00
Kurtosis:                      21.210   Cond. No.                         38.5
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Wilcoxon delta_H: statistic=714.0, p=0.000467

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)

--- Analyzing gpt-4.1-2025-04-14 (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./secondchance_game_logs/gpt-4.1-2025-04-14_GPQA_redacted_temp0.0_1751576596_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    128
1    112
Name: count, dtype: int64

Answer change%: 0.4667 [0.4035498299801499, 0.5297835033531835] (n=240)
P-value vs 25%: 1.718e-11; P-value vs 0%: 1.374e-47
Phase 2 self-accuracy: 0.4286 [0.33692159879038713, 0.5202212583524699] (n=112)
P-value vs 25%: 0.0001341; P-value vs 33%: 0.04097

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  240
Model:                          Logit   Df Residuals:                      238
Method:                           MLE   Df Model:                            1
Date:                Fri, 04 Jul 2025   Pseudo R-squ.:                 0.06117
Time:                        22:35:04   Log-Likelihood:                -155.68
converged:                       True   LL-Null:                       -165.82
Covariance Type:            nonrobust   LLR p-value:                 6.663e-06
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          2.7434      0.696      3.944      0.000       1.380       4.107
p_i_capability    -3.3200      0.780     -4.255      0.000      -4.849      -1.791
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  240
Model:                          Logit   Df Residuals:                      238
Method:                           MLE   Df Model:                            1
Date:                Fri, 04 Jul 2025   Pseudo R-squ.:                 0.05755
Time:                        22:35:04   Log-Likelihood:                -156.28
converged:                       True   LL-Null:                       -165.82
Covariance Type:            nonrobust   LLR p-value:                 1.249e-05
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -0.6301      0.177     -3.555      0.000      -0.977      -0.283
capabilities_entropy     1.1038      0.263      4.196      0.000       0.588       1.619
========================================================================================

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Wilcoxon delta_p: statistic=1026.5, p=2.57e-07

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.962
Model:                            OLS   Adj. R-squared:                  0.961
Method:                 Least Squares   F-statistic:                     1843.
Date:                Fri, 04 Jul 2025   Prob (F-statistic):          4.69e-156
Time:                        22:35:04   Log-Likelihood:                 229.31
No. Observations:                 225   AIC:                            -450.6
Df Residuals:                     221   BIC:                            -437.0
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.8425      0.049    -17.274      0.000      -0.939      -0.746
p1                    0.8641      0.053     16.396      0.000       0.760       0.968
answer_changed        0.7876      0.060     13.051      0.000       0.669       0.906
p1:answer_changed     0.1575      0.068      2.313      0.022       0.023       0.292
==============================================================================
Omnibus:                       64.312   Durbin-Watson:                   1.829
Prob(Omnibus):                  0.000   Jarque-Bera (JB):              921.932
Skew:                           0.615   Prob(JB):                    6.38e-201
Kurtosis:                      12.840   Cond. No.                         27.2
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Wilcoxon delta_H: statistic=811.0, p=1.76e-10

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)

--- Analyzing gpt-4o-2024-08-06 (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./secondchance_game_logs/gpt-4o-2024-08-06_GPQA_redacted_cor_temp0.0_1750857149_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    156
1     28
Name: count, dtype: int64

Answer change%: 0.1522 [0.10027447309604909, 0.20407335299090745] (n=184)
P-value vs 25%: 0.0002204; P-value vs 0%: 9.095e-09
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=28)
P-value vs 25%: 0; P-value vs 33%: 0

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  184
Model:                          Logit   Df Residuals:                      182
Method:                           MLE   Df Model:                            1
Date:                Fri, 04 Jul 2025   Pseudo R-squ.:                 0.08246
Time:                        22:35:04   Log-Likelihood:                -71.998
converged:                       True   LL-Null:                       -78.469
Covariance Type:            nonrobust   LLR p-value:                 0.0003215
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept         -0.1377      0.453     -0.304      0.761      -1.025       0.749
p_i_capability    -2.2686      0.629     -3.605      0.000      -3.502      -1.035
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  184
Model:                          Logit   Df Residuals:                      182
Method:                           MLE   Df Model:                            1
Date:                Fri, 04 Jul 2025   Pseudo R-squ.:                  0.3398
Time:                        22:35:04   Log-Likelihood:                -51.804
converged:                       True   LL-Null:                       -78.469
Covariance Type:            nonrobust   LLR p-value:                 2.821e-13
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -4.1256      0.598     -6.895      0.000      -5.298      -2.953
capabilities_entropy     2.7262      0.475      5.738      0.000       1.795       3.657
========================================================================================

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Wilcoxon delta_p: statistic=3330.0, p=0.0774

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.192
Model:                            OLS   Adj. R-squared:                  0.176
Method:                 Least Squares   F-statistic:                     11.90
Date:                Fri, 04 Jul 2025   Prob (F-statistic):           4.90e-07
Time:                        22:35:04   Log-Likelihood:                 38.216
No. Observations:                 154   AIC:                            -68.43
Df Residuals:                     150   BIC:                            -56.28
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.1165      0.084     -1.382      0.169      -0.283       0.050
p1                    0.1351      0.095      1.418      0.158      -0.053       0.323
answer_changed       -0.1193      0.149     -0.802      0.424      -0.413       0.175
p1:answer_changed     0.6231      0.231      2.698      0.008       0.167       1.079
==============================================================================
Omnibus:                       25.541   Durbin-Watson:                   1.944
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               61.216
Skew:                           0.671   Prob(JB):                     5.10e-14
Kurtosis:                       5.782   Cond. No.                         23.7
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Wilcoxon delta_H: statistic=3407.0, p=0.148

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)

--- Analyzing gpt-4o-2024-08-06 (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./secondchance_game_logs/gpt-4o-2024-08-06_GPQA_redacted_temp0.0_1750677391_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    155
1    108
Name: count, dtype: int64

Answer change%: 0.4106 [0.35119086601250704, 0.4701019096528922] (n=263)
P-value vs 25%: 1.185e-07; P-value vs 0%: 9.451e-42
Phase 2 self-accuracy: 0.3889 [0.2969479211314872, 0.4808298566462906] (n=108)
P-value vs 25%: 0.003069; P-value vs 33%: 0.2335

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  263
Model:                          Logit   Df Residuals:                      261
Method:                           MLE   Df Model:                            1
Date:                Fri, 04 Jul 2025   Pseudo R-squ.:                 0.02291
Time:                        22:35:04   Log-Likelihood:                -174.00
converged:                       True   LL-Null:                       -178.08
Covariance Type:            nonrobust   LLR p-value:                  0.004286
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          0.8222      0.438      1.879      0.060      -0.036       1.680
p_i_capability    -1.7053      0.608     -2.805      0.005      -2.897      -0.514
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  263
Model:                          Logit   Df Residuals:                      261
Method:                           MLE   Df Model:                            1
Date:                Fri, 04 Jul 2025   Pseudo R-squ.:                 0.04816
Time:                        22:35:04   Log-Likelihood:                -169.50
converged:                       True   LL-Null:                       -178.08
Covariance Type:            nonrobust   LLR p-value:                 3.450e-05
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.3271      0.282     -4.709      0.000      -1.879      -0.775
capabilities_entropy     0.9409      0.236      3.983      0.000       0.478       1.404
========================================================================================

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Wilcoxon delta_p: statistic=4541.0, p=0.107

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.301
Model:                            OLS   Adj. R-squared:                  0.293
Method:                 Least Squares   F-statistic:                     35.50
Date:                Fri, 04 Jul 2025   Prob (F-statistic):           4.12e-19
Time:                        22:35:04   Log-Likelihood:                -3.6040
No. Observations:                 251   AIC:                             15.21
Df Residuals:                     247   BIC:                             29.31
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept             0.0121      0.075      0.161      0.872      -0.136       0.160
p1                    0.0386      0.098      0.393      0.695      -0.155       0.232
answer_changed       -0.5727      0.122     -4.710      0.000      -0.812      -0.333
p1:answer_changed     1.1680      0.173      6.764      0.000       0.828       1.508
==============================================================================
Omnibus:                        1.608   Durbin-Watson:                   2.196
Prob(Omnibus):                  0.447   Jarque-Bera (JB):                1.430
Skew:                          -0.043   Prob(JB):                        0.489
Kurtosis:                       2.640   Cond. No.                         19.3
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Wilcoxon delta_H: statistic=2645.0, p=1.07e-07

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)

--- Analyzing grok-3-latest (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./secondchance_game_logs/grok-3-latest_GPQA_redacted_cor_temp0.0_1750857024_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    176
1     27
Name: count, dtype: int64

Answer change%: 0.1330 [0.08629144308167455, 0.17971840913507423] (n=203)
P-value vs 25%: 9.165e-07; P-value vs 0%: 2.398e-08
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=27)
P-value vs 25%: 0; P-value vs 33%: 0

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  203
Model:                          Logit   Df Residuals:                      201
Method:                           MLE   Df Model:                            1
Date:                Fri, 04 Jul 2025   Pseudo R-squ.:                0.006393
Time:                        22:35:04   Log-Likelihood:                -79.079
converged:                       True   LL-Null:                       -79.588
Covariance Type:            nonrobust   LLR p-value:                    0.3131
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept         -1.1609      0.690     -1.682      0.093      -2.514       0.192
p_i_capability    -0.7996      0.752     -1.064      0.288      -2.273       0.674
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  197
Model:                          Logit   Df Residuals:                      195
Method:                           MLE   Df Model:                            1
Date:                Fri, 04 Jul 2025   Pseudo R-squ.:                  0.1516
Time:                        22:35:04   Log-Likelihood:                -66.782
converged:                       True   LL-Null:                       -78.718
Covariance Type:            nonrobust   LLR p-value:                 1.030e-06
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.5403      0.294     -8.647      0.000      -3.116      -1.964
capabilities_entropy     2.8227      0.582      4.851      0.000       1.682       3.963
========================================================================================

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Wilcoxon delta_p: statistic=6643.0, p=0.739

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.908
Model:                            OLS   Adj. R-squared:                  0.907
Method:                 Least Squares   F-statistic:                     620.3
Date:                Fri, 04 Jul 2025   Prob (F-statistic):           3.21e-97
Time:                        22:35:04   Log-Likelihood:                 193.42
No. Observations:                 192   AIC:                            -378.8
Df Residuals:                     188   BIC:                            -365.8
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.7691      0.091     -8.436      0.000      -0.949      -0.589
p1                    0.7899      0.093      8.458      0.000       0.606       0.974
answer_changed        0.5895      0.133      4.430      0.000       0.327       0.852
p1:answer_changed     0.2996      0.145      2.072      0.040       0.014       0.585
==============================================================================
Omnibus:                      110.537   Durbin-Watson:                   1.940
Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1200.387
Skew:                           1.915   Prob(JB):                    2.18e-261
Kurtosis:                      14.636   Cond. No.                         47.5
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Wilcoxon delta_H: statistic=5654.0, p=0.0522

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)

--- Analyzing grok-3-latest (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./secondchance_game_logs/grok-3-latest_GPQA_redacted_temp0.0_1750676259_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    169
1     75
Name: count, dtype: int64

Answer change%: 0.3074 [0.24948254545143583, 0.3652715529092199] (n=244)
P-value vs 25%: 0.05208; P-value vs 0%: 2.329e-25
Phase 2 self-accuracy: 0.3867 [0.2764533401424207, 0.49687999319091264] (n=75)
P-value vs 25%: 0.01508; P-value vs 33%: 0.3399

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  244
Model:                          Logit   Df Residuals:                      242
Method:                           MLE   Df Model:                            1
Date:                Fri, 04 Jul 2025   Pseudo R-squ.:                 0.01188
Time:                        22:35:04   Log-Likelihood:                -148.76
converged:                       True   LL-Null:                       -150.54
Covariance Type:            nonrobust   LLR p-value:                   0.05858
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          0.0947      0.493      0.192      0.848      -0.872       1.062
p_i_capability    -1.0778      0.567     -1.903      0.057      -2.188       0.033
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  236
Model:                          Logit   Df Residuals:                      234
Method:                           MLE   Df Model:                            1
Date:                Fri, 04 Jul 2025   Pseudo R-squ.:                 0.09551
Time:                        22:35:04   Log-Likelihood:                -132.75
converged:                       True   LL-Null:                       -146.77
Covariance Type:            nonrobust   LLR p-value:                 1.190e-07
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.5609      0.222     -7.033      0.000      -1.996      -1.126
capabilities_entropy     1.7106      0.338      5.063      0.000       1.048       2.373
========================================================================================

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Wilcoxon delta_p: statistic=5910.0, p=0.809

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.905
Model:                            OLS   Adj. R-squared:                  0.904
Method:                 Least Squares   F-statistic:                     712.4
Date:                Fri, 04 Jul 2025   Prob (F-statistic):          3.13e-114
Time:                        22:35:04   Log-Likelihood:                 164.31
No. Observations:                 228   AIC:                            -320.6
Df Residuals:                     224   BIC:                            -306.9
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.6466      0.074     -8.756      0.000      -0.792      -0.501
p1                    0.6961      0.079      8.802      0.000       0.540       0.852
answer_changed        0.4430      0.101      4.368      0.000       0.243       0.643
p1:answer_changed     0.4421      0.115      3.850      0.000       0.216       0.668
==============================================================================
Omnibus:                       45.657   Durbin-Watson:                   2.008
Prob(Omnibus):                  0.000   Jarque-Bera (JB):              110.786
Skew:                           0.907   Prob(JB):                     8.77e-25
Kurtosis:                       5.894   Cond. No.                         31.4
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Wilcoxon delta_H: statistic=5134.0, p=0.104

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
