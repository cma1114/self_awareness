
--- Analyzing claude-3-5-sonnet-20241022 (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/claude-3-5-sonnet-20241022_SimpleMC_redacted_cor_temp0.0_1751756800_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    242
1     49
Name: count, dtype: int64

Answer change%: 0.1684 [0.12539023837349272, 0.21137952107667912] (n=291)
P-value vs 25%: 0.0001988; P-value vs 0%: 1.641e-14
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=49)
P-value vs 25%: 0; P-value vs 33%: 0
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.857143
                        1                 0.142857
Geography               0                 0.809524
                        1                 0.190476
Misc                    0                 0.888889
                        1                 0.111111
Music                   0                 0.869565
                        1                 0.130435
Other                   0                 0.785714
                        1                 0.214286
Politics                0                 0.826087
                        1                 0.173913
Science and technology  0                 0.818182
                        1                 0.181818
Sports                  0                 0.750000
                        1                 0.250000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.750000
                     1                 0.250000
Number               0                 0.777778
                     1                 0.222222
Other                0                 0.860465
                     1                 0.139535
Person               0                 0.922078
                     1                 0.077922
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.800000  0.200000           10
                       Number               0.428571  0.571429            7
                       Other                0.916667  0.083333           12
                       Person               1.000000  0.000000           20
Geography              Date                 0.500000  0.500000            6
                       Number               1.000000  0.000000            8
                       Other                0.857143  0.142857            7
Misc                   Date                 0.800000  0.200000           15
                       Number               0.833333  0.166667            6
                       Other                0.933333  0.066667           15
                       Person               1.000000  0.000000            9
Music                  Date                 0.714286  0.285714            7
                       Other                0.833333  0.166667            6
                       Person               1.000000  0.000000           10
Other                  Date                 0.750000  0.250000            8
                       Number               1.000000  0.000000            2
                       Other                0.818182  0.181818           11
                       Person               0.714286  0.285714            7
Politics               Date                 0.809524  0.190476           21
                       Number               1.000000  0.000000            2
                       Other                0.785714  0.214286           14
                       Person               0.888889  0.111111            9
Science and technology Date                 0.736842  0.263158           19
                       Number               0.800000  0.200000            5
                       Other                0.866667  0.133333           15
                       Person               0.875000  0.125000           16
Sports                 Date                 0.666667  0.333333            6
                       Number               0.666667  0.333333            6
                       Other                0.833333  0.166667            6
                       Person               0.833333  0.166667            6

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  291
Model:                          Logit   Df Residuals:                      279
Method:                           MLE   Df Model:                           11
Date:                Sun, 06 Jul 2025   Pseudo R-squ.:                 0.05232
Time:                        10:05:13   Log-Likelihood:                -125.01
converged:                       True   LL-Null:                       -131.91
Covariance Type:            nonrobust   LLR p-value:                    0.2441
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -0.6068      2.027     -0.299      0.765      -4.579       3.365
C(topic_grouped)[T.Geography]                 -0.0457      0.713     -0.064      0.949      -1.444       1.352
C(topic_grouped)[T.Misc]                      -0.4977      0.640     -0.778      0.437      -1.751       0.756
C(topic_grouped)[T.Music]                     -0.1015      0.763     -0.133      0.894      -1.597       1.394
C(topic_grouped)[T.Other]                      0.3980      0.634      0.628      0.530      -0.844       1.640
C(topic_grouped)[T.Politics]                   0.0226      0.603      0.037      0.970      -1.160       1.205
C(topic_grouped)[T.Science and technology]     0.1623      0.555      0.292      0.770      -0.926       1.251
C(topic_grouped)[T.Sports]                     0.5306      0.641      0.828      0.407      -0.725       1.786
C(answer_type_grouped)[T.Number]              -0.1899      0.495     -0.384      0.701      -1.159       0.780
C(answer_type_grouped)[T.Other]               -0.7478      0.399     -1.874      0.061      -1.530       0.034
C(answer_type_grouped)[T.Person]              -1.4151      0.499     -2.837      0.005      -2.393      -0.437
q_length                                      -0.1161      0.443     -0.262      0.793      -0.983       0.751
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing claude-3-5-sonnet-20241022 (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/claude-3-5-sonnet-20241022_SimpleMC_redacted_temp0.0_1751717952_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    116
1     93
Name: count, dtype: int64

Answer change%: 0.4450 [0.3776010218616946, 0.5123511312483532] (n=209)
P-value vs 25%: 1.412e-08; P-value vs 0%: 2.524e-38
Phase 2 self-accuracy: 0.5376 [0.43630327570698096, 0.63896554149732] (n=93)
P-value vs 25%: 2.645e-08; P-value vs 33%: 7.556e-05
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'Video games', 'History']
                  Grouped rare answer_type into 'Misc'/'Other': None
topic_grouped           answer_changed
Art                     0                 0.576923
                        1                 0.423077
Geography               1                 0.565217
                        0                 0.434783
Misc                    0                 0.586207
                        1                 0.413793
Music                   0                 0.529412
                        1                 0.470588
Other                   1                 0.583333
                        0                 0.416667
Politics                0                 0.741935
                        1                 0.258065
Science and technology  1                 0.511628
                        0                 0.488372
Sports                  0                 0.687500
                        1                 0.312500
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.506494
                     1                 0.493506
Number               0                 0.571429
                     1                 0.428571
Other                0                 0.580645
                     1                 0.419355
Person               0                 0.604651
                     1                 0.395349
Place                0                 0.562500
                     1                 0.437500
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.454545  0.545455           11
                       Number               0.500000  0.500000            2
                       Other                1.000000  0.000000            4
                       Person               0.428571  0.571429            7
                       Place                1.000000  0.000000            2
Geography              Date                 0.666667  0.333333            9
                       Number               0.300000  0.700000           10
                       Place                0.250000  0.750000            4
Misc                   Date                 0.500000  0.500000            8
                       Number               0.666667  0.333333            3
                       Other                0.600000  0.400000           10
                       Person               0.666667  0.333333            6
                       Place                0.500000  0.500000            2
Music                  Date                 0.400000  0.600000            5
                       Number               0.750000  0.250000            4
                       Other                0.250000  0.750000            4
                       Person               1.000000  0.000000            2
                       Place                0.500000  0.500000            2
Other                  Date                 0.300000  0.700000           10
                       Number               0.600000  0.400000            5
                       Other                1.000000  0.000000            2
                       Person               0.333333  0.666667            6
                       Place                0.000000  1.000000            1
Politics               Date                 0.733333  0.266667           15
                       Number               0.500000  0.500000            4
                       Other                0.600000  0.400000            5
                       Person               1.000000  0.000000            6
                       Place                1.000000  0.000000            1
Science and technology Date                 0.437500  0.562500           16
                       Number               0.555556  0.444444            9
                       Other                0.000000  1.000000            2
                       Person               0.571429  0.428571           14
                       Place                0.500000  0.500000            2
Sports                 Date                 0.333333  0.666667            3
                       Number               1.000000  0.000000            5
                       Other                0.500000  0.500000            4
                       Person               0.500000  0.500000            2
                       Place                1.000000  0.000000            2

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  209
Model:                          Logit   Df Residuals:                      196
Method:                           MLE   Df Model:                           12
Date:                Sun, 06 Jul 2025   Pseudo R-squ.:                 0.05387
Time:                        10:05:13   Log-Likelihood:                -135.86
converged:                       True   LL-Null:                       -143.60
Covariance Type:            nonrobust   LLR p-value:                    0.2167
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -3.6439      1.883     -1.935      0.053      -7.335       0.047
C(topic_grouped)[T.Geography]                  0.5827      0.611      0.954      0.340      -0.614       1.780
C(topic_grouped)[T.Misc]                      -0.0881      0.561     -0.157      0.875      -1.188       1.011
C(topic_grouped)[T.Music]                      0.2361      0.641      0.368      0.713      -1.020       1.493
C(topic_grouped)[T.Other]                      0.6858      0.585      1.173      0.241      -0.460       1.832
C(topic_grouped)[T.Politics]                  -0.9215      0.587     -1.571      0.116      -2.071       0.228
C(topic_grouped)[T.Science and technology]     0.3780      0.514      0.735      0.462      -0.630       1.386
C(topic_grouped)[T.Sports]                    -0.5645      0.690     -0.818      0.413      -1.917       0.788
C(answer_type_grouped)[T.Number]              -0.4440      0.413     -1.074      0.283      -1.254       0.366
C(answer_type_grouped)[T.Other]               -0.0788      0.463     -0.170      0.865      -0.986       0.828
C(answer_type_grouped)[T.Person]              -0.3091      0.411     -0.752      0.452      -1.115       0.496
C(answer_type_grouped)[T.Place]               -0.1406      0.592     -0.238      0.812      -1.300       1.019
q_length                                       0.7791      0.405      1.924      0.054      -0.015       1.573
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing claude-3-haiku-20240307 (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/claude-3-haiku-20240307_SimpleMC_redacted_cor_temp0.0_1751757170_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    128
1     20
Name: count, dtype: int64

Answer change%: 0.1351 [0.0800574726228318, 0.19021279764743848] (n=148)
P-value vs 25%: 4.36e-05; P-value vs 0%: 1.518e-06
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=20)
P-value vs 25%: 0; P-value vs 33%: 0
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'Sports', 'History']
                  Grouped rare answer_type into 'Misc'/'Other': None
topic_grouped           answer_changed
Art                     0                 0.913043
                        1                 0.086957
Geography               0                 0.750000
                        1                 0.250000
Misc                    0                 0.666667
                        1                 0.333333
Music                   0                 0.900000
                        1                 0.100000
Other                   0                 0.809524
                        1                 0.190476
Politics                0                 0.909091
                        1                 0.090909
Science and technology  0                 0.965517
                        1                 0.034483
Video games             0                 1.000000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.784314
                     1                 0.215686
Number               0                 0.866667
                     1                 0.133333
Other                0                 0.891892
                     1                 0.108108
Person               0                 0.906250
                     1                 0.093750
Place                0                 1.000000
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.750000  0.250000            4
                       Number               1.000000  0.000000            2
                       Other                0.800000  0.200000            5
                       Person               1.000000  0.000000           10
                       Place                1.000000  0.000000            2
Geography              Date                 0.333333  0.666667            3
                       Number               0.750000  0.250000            4
                       Other                1.000000  0.000000            3
                       Place                1.000000  0.000000            2
Misc                   Date                 0.666667  0.333333            6
                       Number               1.000000  0.000000            1
                       Other                0.571429  0.428571            7
                       Person               0.666667  0.333333            6
                       Place                1.000000  0.000000            1
Music                  Date                 0.750000  0.250000            4
                       Other                1.000000  0.000000            3
                       Person               1.000000  0.000000            3
Other                  Date                 0.700000  0.300000           10
                       Number               1.000000  0.000000            1
                       Other                1.000000  0.000000            2
                       Person               0.800000  0.200000            5
                       Place                1.000000  0.000000            3
Politics               Date                 0.857143  0.142857            7
                       Number               0.000000  1.000000            1
                       Other                1.000000  0.000000            6
                       Person               1.000000  0.000000            4
                       Place                1.000000  0.000000            4
Science and technology Date                 0.916667  0.083333           12
                       Number               1.000000  0.000000            4
                       Other                1.000000  0.000000            9
                       Person               1.000000  0.000000            4
Video games            Date                 1.000000  0.000000            5
                       Number               1.000000  0.000000            2
                       Other                1.000000  0.000000            2
                       Place                1.000000  0.000000            1

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                    Could not fit Model 4: Singular matrix

                  Model 6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length (after removing deterministic categories: defaultdict(<class 'list'>, {'topic_grouped': ['Video games'], 'answer_type_grouped': ['Place']}))
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  126
Model:                          Logit   Df Residuals:                      115
Method:                           MLE   Df Model:                           10
Date:                Sun, 06 Jul 2025   Pseudo R-squ.:                  0.1533
Time:                        10:05:13   Log-Likelihood:                -46.683
converged:                       True   LL-Null:                       -55.132
Covariance Type:            nonrobust   LLR p-value:                   0.07663
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      0.3619      3.542      0.102      0.919      -6.580       7.304
C(topic_grouped)[T.Geography]                  1.1507      1.082      1.064      0.287      -0.970       3.271
C(topic_grouped)[T.Misc]                       1.5762      0.906      1.740      0.082      -0.199       3.352
C(topic_grouped)[T.Music]                     -0.1594      1.329     -0.120      0.905      -2.765       2.446
C(topic_grouped)[T.Other]                      0.6137      0.980      0.626      0.531      -1.307       2.534
C(topic_grouped)[T.Politics]                   0.0248      1.114      0.022      0.982      -2.158       2.208
C(topic_grouped)[T.Science and technology]    -1.3157      1.311     -1.004      0.316      -3.885       1.254
C(answer_type_grouped)[T.Number]              -0.6274      0.995     -0.631      0.528      -2.577       1.323
C(answer_type_grouped)[T.Other]               -1.1285      0.699     -1.615      0.106      -2.498       0.241
C(answer_type_grouped)[T.Person]              -1.3171      0.761     -1.731      0.083      -2.808       0.174
q_length                                      -0.4057      0.797     -0.509      0.611      -1.967       1.156
==============================================================================================================

--- Analyzing claude-3-haiku-20240307 (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/claude-3-haiku-20240307_SimpleMC_redacted_temp0.0_1751717106_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    260
1     92
Name: count, dtype: int64

Answer change%: 0.2614 [0.21546342520526302, 0.3072638475220097] (n=352)
P-value vs 25%: 0.6275; P-value vs 0%: 6.373e-29
Phase 2 self-accuracy: 0.2935 [0.20043071771916576, 0.3865258040199647] (n=92)
P-value vs 25%: 0.3598; P-value vs 33%: 0.4051
                  Grouped rare topic into 'Misc'/'Other': ['History', 'TV shows', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.711538
                        1                 0.288462
Geography               0                 0.656250
                        1                 0.343750
Misc                    0                 0.705882
                        1                 0.294118
Music                   0                 0.733333
                        1                 0.266667
Other                   0                 0.741935
                        1                 0.258065
Politics                0                 0.781818
                        1                 0.218182
Science and technology  0                 0.797101
                        1                 0.202899
Sports                  0                 0.718750
                        1                 0.281250
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.771186
                     1                 0.228814
Number               0                 0.746032
                     1                 0.253968
Other                0                 0.698795
                     1                 0.301205
Person               0                 0.727273
                     1                 0.272727
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.588235  0.411765           17
                       Number               0.428571  0.571429            7
                       Other                0.818182  0.181818           11
                       Person               0.882353  0.117647           17
Geography              Date                 0.750000  0.250000           12
                       Number               0.571429  0.428571           14
                       Other                0.666667  0.333333            6
Misc                   Date                 0.692308  0.307692           13
                       Number               0.666667  0.333333            6
                       Other                0.684211  0.315789           19
                       Person               0.769231  0.230769           13
Music                  Date                 0.625000  0.375000            8
                       Number               1.000000  0.000000            4
                       Other                0.777778  0.222222            9
                       Person               0.666667  0.333333            9
Other                  Date                 0.875000  0.125000            8
                       Number               0.833333  0.166667            6
                       Other                0.555556  0.444444            9
                       Person               0.750000  0.250000            8
Politics               Date                 0.862069  0.137931           29
                       Number               1.000000  0.000000            5
                       Other                0.700000  0.300000           10
                       Person               0.545455  0.454545           11
Science and technology Date                 0.913043  0.086957           23
                       Number               0.900000  0.100000           10
                       Other                0.700000  0.300000           10
                       Person               0.692308  0.307692           26
Sports                 Date                 0.625000  0.375000            8
                       Number               0.818182  0.181818           11
                       Other                0.666667  0.333333            9
                       Person               0.750000  0.250000            4

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  352
Model:                          Logit   Df Residuals:                      340
Method:                           MLE   Df Model:                           11
Date:                Sun, 06 Jul 2025   Pseudo R-squ.:                 0.01224
Time:                        10:05:13   Log-Likelihood:                -199.74
converged:                       True   LL-Null:                       -202.22
Covariance Type:            nonrobust   LLR p-value:                    0.9335
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -0.6794      1.564     -0.434      0.664      -3.745       2.387
C(topic_grouped)[T.Geography]                  0.3478      0.501      0.695      0.487      -0.633       1.329
C(topic_grouped)[T.Misc]                      -0.0061      0.437     -0.014      0.989      -0.864       0.851
C(topic_grouped)[T.Music]                     -0.1377      0.517     -0.267      0.790      -1.150       0.875
C(topic_grouped)[T.Other]                     -0.1684      0.515     -0.327      0.744      -1.178       0.841
C(topic_grouped)[T.Politics]                  -0.3111      0.456     -0.683      0.495      -1.204       0.582
C(topic_grouped)[T.Science and technology]    -0.4598      0.430     -1.070      0.285      -1.302       0.382
C(topic_grouped)[T.Sports]                     0.0011      0.507      0.002      0.998      -0.993       0.995
C(answer_type_grouped)[T.Number]               0.0275      0.376      0.073      0.942      -0.709       0.764
C(answer_type_grouped)[T.Other]                0.3221      0.334      0.966      0.334      -0.332       0.976
C(answer_type_grouped)[T.Person]               0.2830      0.337      0.841      0.400      -0.377       0.943
q_length                                      -0.0877      0.336     -0.261      0.794      -0.747       0.571
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing claude-3-sonnet-20240229 (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/claude-3-sonnet-20240229_SimpleMC_redacted_cor_temp0.0_1751757346_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    107
1     45
Name: count, dtype: int64

Answer change%: 0.2961 [0.22347866592810672, 0.36862659722978797] (n=152)
P-value vs 25%: 0.2136; P-value vs 0%: 1.292e-15
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=45)
P-value vs 25%: 0; P-value vs 33%: 0
                  Grouped rare topic into 'Misc'/'Other': ['Sports', 'TV shows', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.766667
                        1                 0.233333
Geography               0                 0.571429
                        1                 0.428571
Misc                    0                 0.750000
                        1                 0.250000
Music                   0                 0.857143
                        1                 0.142857
Other                   0                 0.750000
                        1                 0.250000
Politics                0                 0.619048
                        1                 0.380952
Science and technology  0                 0.636364
                        1                 0.363636
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.641791
                     1                 0.358209
Number               0                 0.550000
                     1                 0.450000
Other                0                 0.848485
                     1                 0.151515
Person               0                 0.781250
                     1                 0.218750
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.555556  0.444444            9
                       Number               1.000000  0.000000            3
                       Other                1.000000  0.000000            6
                       Person               0.750000  0.250000           12
Geography              Date                 0.500000  0.500000            4
                       Number               0.571429  0.428571            7
                       Other                0.666667  0.333333            3
Misc                   Date                 0.769231  0.230769           13
                       Number               0.500000  0.500000            4
                       Other                0.666667  0.333333            6
                       Person               1.000000  0.000000            5
Music                  Date                 1.000000  0.000000            5
                       Number               0.000000  1.000000            1
                       Other                1.000000  0.000000            3
                       Person               0.800000  0.200000            5
Other                  Date                 0.833333  0.166667            6
                       Number               0.000000  1.000000            1
                       Other                0.666667  0.333333            3
                       Person               1.000000  0.000000            2
Politics               Date                 0.461538  0.538462           13
                       Other                0.833333  0.166667            6
                       Person               1.000000  0.000000            2
Science and technology Date                 0.588235  0.411765           17
                       Number               0.500000  0.500000            4
                       Other                1.000000  0.000000            6
                       Person               0.500000  0.500000            6

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  152
Model:                          Logit   Df Residuals:                      141
Method:                           MLE   Df Model:                           10
Date:                Sun, 06 Jul 2025   Pseudo R-squ.:                 0.06624
Time:                        10:05:13   Log-Likelihood:                -86.221
converged:                       True   LL-Null:                       -92.337
Covariance Type:            nonrobust   LLR p-value:                    0.2698
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.9415      2.433     -0.798      0.425      -6.710       2.827
C(topic_grouped)[T.Geography]                  0.5878      0.762      0.771      0.440      -0.905       2.081
C(topic_grouped)[T.Misc]                      -0.0342      0.636     -0.054      0.957      -1.281       1.212
C(topic_grouped)[T.Music]                     -0.6190      0.889     -0.696      0.486      -2.361       1.123
C(topic_grouped)[T.Other]                      0.0341      0.817      0.042      0.967      -1.567       1.635
C(topic_grouped)[T.Politics]                   0.6288      0.685      0.917      0.359      -0.715       1.972
C(topic_grouped)[T.Science and technology]     0.4625      0.596      0.775      0.438      -0.706       1.631
C(answer_type_grouped)[T.Number]               0.3621      0.569      0.636      0.525      -0.753       1.478
C(answer_type_grouped)[T.Other]               -1.1111      0.558     -1.992      0.046      -2.204      -0.018
C(answer_type_grouped)[T.Person]              -0.4790      0.525     -0.913      0.361      -1.507       0.549
q_length                                       0.2424      0.534      0.454      0.650      -0.803       1.288
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing claude-3-sonnet-20240229 (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/claude-3-sonnet-20240229_SimpleMC_redacted_temp0.0_1751717606_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    201
1    147
Name: count, dtype: int64

Answer change%: 0.4224 [0.37051754977978874, 0.47431003642710784] (n=348)
P-value vs 25%: 7.438e-11; P-value vs 0%: 2.703e-57
Phase 2 self-accuracy: 0.3333 [0.2571283860895982, 0.4095382805770684] (n=147)
P-value vs 25%: 0.03209; P-value vs 33%: 0.9932
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': None
topic_grouped           answer_changed
Art                     0                 0.533333
                        1                 0.466667
Geography               0                 0.566667
                        1                 0.433333
Misc                    0                 0.618182
                        1                 0.381818
Music                   0                 0.807692
                        1                 0.192308
Other                   1                 0.550000
                        0                 0.450000
Politics                0                 0.535714
                        1                 0.464286
Science and technology  0                 0.615385
                        1                 0.384615
Sports                  0                 0.548387
                        1                 0.451613
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.539216
                     1                 0.460784
Number               1                 0.551724
                     0                 0.448276
Other                0                 0.689189
                     1                 0.310811
Person               0                 0.602273
                     1                 0.397727
Place                0                 0.615385
                     1                 0.384615
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.500000  0.500000           12
                       Number               0.333333  0.666667            6
                       Other                0.600000  0.400000           10
                       Person               0.533333  0.466667           15
                       Place                1.000000  0.000000            2
Geography              Date                 0.545455  0.454545           11
                       Number               0.545455  0.454545           11
                       Other                1.000000  0.000000            1
                       Place                0.571429  0.428571            7
Misc                   Date                 0.583333  0.416667           12
                       Number               0.428571  0.571429            7
                       Other                0.666667  0.333333           21
                       Person               0.615385  0.384615           13
                       Place                1.000000  0.000000            2
Music                  Date                 0.571429  0.428571            7
                       Number               1.000000  0.000000            3
                       Other                0.875000  0.125000            8
                       Person               0.857143  0.142857            7
                       Place                1.000000  0.000000            1
Other                  Date                 0.333333  0.666667           12
                       Number               0.333333  0.666667            6
                       Other                0.857143  0.142857            7
                       Person               0.454545  0.545455           11
                       Place                0.250000  0.750000            4
Politics               Date                 0.652174  0.347826           23
                       Number               0.166667  0.833333            6
                       Other                0.666667  0.333333            9
                       Person               0.384615  0.615385           13
                       Place                0.600000  0.400000            5
Science and technology Date                 0.500000  0.500000           18
                       Number               0.500000  0.500000           10
                       Other                0.700000  0.300000           10
                       Person               0.708333  0.291667           24
                       Place                0.666667  0.333333            3
Sports                 Date                 0.571429  0.428571            7
                       Number               0.444444  0.555556            9
                       Other                0.500000  0.500000            8
                       Person               0.800000  0.200000            5
                       Place                0.500000  0.500000            2

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  348
Model:                          Logit   Df Residuals:                      335
Method:                           MLE   Df Model:                           12
Date:                Sun, 06 Jul 2025   Pseudo R-squ.:                 0.04120
Time:                        10:05:13   Log-Likelihood:                -227.24
converged:                       True   LL-Null:                       -237.01
Covariance Type:            nonrobust   LLR p-value:                   0.07656
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      1.3418      1.388      0.967      0.334      -1.378       4.062
C(topic_grouped)[T.Geography]                 -0.4031      0.502     -0.803      0.422      -1.387       0.581
C(topic_grouped)[T.Misc]                      -0.2885      0.416     -0.694      0.488      -1.103       0.526
C(topic_grouped)[T.Music]                     -1.3144      0.587     -2.240      0.025      -2.465      -0.164
C(topic_grouped)[T.Other]                      0.2956      0.443      0.667      0.505      -0.573       1.164
C(topic_grouped)[T.Politics]                  -0.0012      0.412     -0.003      0.998      -0.808       0.805
C(topic_grouped)[T.Science and technology]    -0.3814      0.399     -0.957      0.339      -1.163       0.400
C(topic_grouped)[T.Sports]                    -0.1383      0.480     -0.288      0.773      -1.079       0.802
C(answer_type_grouped)[T.Number]               0.4147      0.342      1.214      0.225      -0.255       1.084
C(answer_type_grouped)[T.Other]               -0.6382      0.335     -1.907      0.057      -1.294       0.018
C(answer_type_grouped)[T.Person]              -0.2832      0.306     -0.924      0.355      -0.884       0.317
C(answer_type_grouped)[T.Place]               -0.3311      0.460     -0.720      0.472      -1.233       0.570
q_length                                      -0.2855      0.296     -0.965      0.334      -0.865       0.294
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing claude-sonnet-4-20250514 (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/claude-sonnet-4-20250514_SimpleMC_redacted_cor_temp0.0_1751759842_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    155
1     64
Name: count, dtype: int64

Answer change%: 0.2922 [0.2320039907301435, 0.35247089511460533] (n=219)
P-value vs 25%: 0.1693; P-value vs 0%: 1.92e-21
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=64)
P-value vs 25%: 0; P-value vs 33%: 0
                  Grouped rare topic into 'Misc'/'Other': ['History', 'TV shows', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': None
topic_grouped           answer_changed
Art                     0                 0.815789
                        1                 0.184211
Geography               0                 0.619048
                        1                 0.380952
Misc                    0                 0.828571
                        1                 0.171429
Music                   0                 0.809524
                        1                 0.190476
Other                   0                 0.666667
                        1                 0.333333
Politics                0                 0.645161
                        1                 0.354839
Science and technology  0                 0.650000
                        1                 0.350000
Sports                  1                 0.533333
                        0                 0.466667
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.671053
                     1                 0.328947
Number               0                 0.612903
                     1                 0.387097
Other                0                 0.784314
                     1                 0.215686
Person               0                 0.760870
                     1                 0.239130
Place                0                 0.666667
                     1                 0.333333
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.666667  0.333333            9
                       Number               1.000000  0.000000            3
                       Other                1.000000  0.000000            8
                       Person               0.800000  0.200000           15
                       Place                0.666667  0.333333            3
Geography              Date                 0.250000  0.750000            4
                       Number               0.666667  0.333333            9
                       Other                1.000000  0.000000            3
                       Place                0.600000  0.400000            5
Misc                   Date                 0.846154  0.153846           13
                       Number               1.000000  0.000000            4
                       Other                0.692308  0.307692           13
                       Person               1.000000  0.000000            4
                       Place                1.000000  0.000000            1
Music                  Date                 0.875000  0.125000            8
                       Number               0.333333  0.666667            3
                       Other                1.000000  0.000000            2
                       Person               1.000000  0.000000            7
                       Place                0.000000  1.000000            1
Other                  Date                 0.500000  0.500000            6
                       Number               0.500000  0.500000            4
                       Other                0.750000  0.250000            4
                       Person               1.000000  0.000000            3
                       Place                1.000000  0.000000            1
Politics               Date                 0.666667  0.333333           15
                       Number               0.000000  1.000000            1
                       Other                0.800000  0.200000            5
                       Person               0.428571  0.571429            7
                       Place                1.000000  0.000000            3
Science and technology Date                 0.647059  0.352941           17
                       Number               0.500000  0.500000            4
                       Other                0.750000  0.250000           12
                       Person               0.666667  0.333333            6
                       Place                0.000000  1.000000            1
Sports                 Date                 0.500000  0.500000            4
                       Number               0.333333  0.666667            3
                       Other                0.500000  0.500000            4
                       Person               0.500000  0.500000            4

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  219
Model:                          Logit   Df Residuals:                      206
Method:                           MLE   Df Model:                           12
Date:                Sun, 06 Jul 2025   Pseudo R-squ.:                 0.06208
Time:                        10:05:13   Log-Likelihood:                -124.09
converged:                       True   LL-Null:                       -132.31
Covariance Type:            nonrobust   LLR p-value:                    0.1725
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      0.7720      1.902      0.406      0.685      -2.956       4.500
C(topic_grouped)[T.Geography]                  0.7513      0.656      1.146      0.252      -0.534       2.036
C(topic_grouped)[T.Misc]                      -0.0925      0.629     -0.147      0.883      -1.325       1.140
C(topic_grouped)[T.Music]                     -0.0722      0.704     -0.103      0.918      -1.451       1.307
C(topic_grouped)[T.Other]                      0.6066      0.673      0.901      0.368      -0.713       1.926
C(topic_grouped)[T.Politics]                   0.9553      0.585      1.632      0.103      -0.192       2.103
C(topic_grouped)[T.Science and technology]     0.8830      0.551      1.603      0.109      -0.197       1.963
C(topic_grouped)[T.Sports]                     1.5514      0.678      2.288      0.022       0.222       2.881
C(answer_type_grouped)[T.Number]               0.2174      0.482      0.451      0.652      -0.726       1.161
C(answer_type_grouped)[T.Other]               -0.6122      0.436     -1.404      0.160      -1.467       0.243
C(answer_type_grouped)[T.Person]              -0.3787      0.450     -0.842      0.400      -1.260       0.503
C(answer_type_grouped)[T.Place]                0.0553      0.633      0.087      0.930      -1.184       1.295
q_length                                      -0.4545      0.413     -1.100      0.271      -1.264       0.355
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing claude-sonnet-4-20250514 (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/claude-sonnet-4-20250514_SimpleMC_redacted_temp0.0_1751719035_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
1    180
0    101
Name: count, dtype: int64

Answer change%: 0.6406 [0.5844664640439934, 0.6966723259915939] (n=281)
P-value vs 25%: 2.174e-42; P-value vs 0%: 6.392e-111
Phase 2 self-accuracy: 0.4944 [0.4214054083963724, 0.5674834804925165] (n=180)
P-value vs 25%: 5.397e-11; P-value vs 33%: 1.476e-05
                  Grouped rare topic into 'Misc'/'Other': ['History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     1                 0.702703
                        0                 0.297297
Geography               1                 0.565217
                        0                 0.434783
Misc                    1                 0.550000
                        0                 0.450000
Music                   1                 0.578947
                        0                 0.421053
Other                   1                 0.823529
                        0                 0.176471
Politics                1                 0.652174
                        0                 0.347826
Science and technology  0                 0.534483
                        1                 0.465517
Sports                  1                 0.680000
                        0                 0.320000
TV shows                1                 0.894737
                        0                 0.105263
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 1                 0.559140
                     0                 0.440860
Number               1                 0.638298
                     0                 0.361702
Other                1                 0.716418
                     0                 0.283582
Person               1                 0.675676
                     0                 0.324324
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.666667  0.333333           12
                       Number               0.166667  0.833333            6
                       Other                0.285714  0.714286            7
                       Person               0.000000  1.000000           12
Geography              Date                 0.454545  0.545455           11
                       Number               0.444444  0.555556            9
                       Other                0.333333  0.666667            3
Misc                   Date                 0.444444  0.555556            9
                       Number               0.250000  0.750000            4
                       Other                0.500000  0.500000            4
                       Person               0.666667  0.333333            3
Music                  Date                 0.250000  0.750000            4
                       Number               1.000000  0.000000            1
                       Other                0.444444  0.555556            9
                       Person               0.400000  0.600000            5
Other                  Date                 0.166667  0.833333           12
                       Number               0.000000  1.000000            3
                       Other                0.111111  0.888889            9
                       Person               0.300000  0.700000           10
Politics               Date                 0.428571  0.571429           21
                       Number               0.000000  1.000000            5
                       Other                0.333333  0.666667           12
                       Person               0.375000  0.625000            8
Science and technology Date                 0.666667  0.333333           18
                       Number               0.600000  0.400000           10
                       Other                0.333333  0.666667            6
                       Person               0.458333  0.541667           24
Sports                 Date                 0.000000  1.000000            5
                       Number               0.500000  0.500000            8
                       Other                0.250000  0.750000            8
                       Person               0.500000  0.500000            4
TV shows               Date                 0.000000  1.000000            1
                       Number               0.000000  1.000000            1
                       Other                0.111111  0.888889            9
                       Person               0.125000  0.875000            8

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  281
Model:                          Logit   Df Residuals:                      268
Method:                           MLE   Df Model:                           12
Date:                Sun, 06 Jul 2025   Pseudo R-squ.:                 0.06959
Time:                        10:05:13   Log-Likelihood:                -170.75
converged:                       True   LL-Null:                       -183.52
Covariance Type:            nonrobust   LLR p-value:                   0.01245
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      2.0138      1.680      1.199      0.231      -1.278       5.306
C(topic_grouped)[T.Geography]                 -0.5525      0.572     -0.966      0.334      -1.673       0.568
C(topic_grouped)[T.Misc]                      -0.5661      0.584     -0.970      0.332      -1.710       0.577
C(topic_grouped)[T.Music]                     -0.6437      0.600     -1.073      0.283      -1.820       0.532
C(topic_grouped)[T.Other]                      0.7179      0.581      1.236      0.217      -0.421       1.856
C(topic_grouped)[T.Politics]                  -0.1178      0.485     -0.243      0.808      -1.069       0.833
C(topic_grouped)[T.Science and technology]    -0.9914      0.451     -2.196      0.028      -1.876      -0.107
C(topic_grouped)[T.Sports]                    -0.1352      0.569     -0.238      0.812      -1.251       0.981
C(topic_grouped)[T.TV shows]                   1.1056      0.840      1.316      0.188      -0.541       2.752
C(answer_type_grouped)[T.Number]               0.4410      0.389      1.133      0.257      -0.322       1.204
C(answer_type_grouped)[T.Other]                0.4815      0.368      1.309      0.190      -0.239       1.202
C(answer_type_grouped)[T.Person]               0.4453      0.357      1.246      0.213      -0.255       1.146
q_length                                      -0.3242      0.360     -0.901      0.368      -1.029       0.381
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing deepseek-chat (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/deepseek-chat_SimpleMC_redacted_cor_temp0.0_1751758366_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    216
1     21
Name: count, dtype: int64

Answer change%: 0.0886 [0.052428133730502396, 0.12478705614291533] (n=237)
P-value vs 25%: 2.267e-18; P-value vs 0%: 1.585e-06
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=21)
P-value vs 25%: 0; P-value vs 33%: 0

  Model 1.4: Answer Changed ~ capabilities_prob
                    Could not fit Model 1.4: Singular matrix

  Model 1.5: Answer Changed ~ capabilities_entropy
                    Could not fit Model 1.5: Singular matrix

  Model 1.6: Answer Changed ~ Game Entropy
                    Could not fit Model 1.6: Singular matrix

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                    Could not fit Model 1.7: Singular matrix
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': None
topic_grouped           answer_changed
Art                     0                 0.972222
                        1                 0.027778
Geography               0                 0.833333
                        1                 0.166667
History                 0                 0.944444
                        1                 0.055556
Misc                    0                 0.833333
                        1                 0.166667
Music                   0                 0.888889
                        1                 0.111111
Other                   0                 0.952381
                        1                 0.047619
Politics                0                 0.888889
                        1                 0.111111
Science and technology  0                 0.906977
                        1                 0.093023
Sports                  0                 1.000000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.925532
                     1                 0.074468
Number               0                 0.862069
                     1                 0.137931
Other                0                 0.882353
                     1                 0.117647
Person               0                 0.978261
                     1                 0.021739
Place                0                 0.823529
                     1                 0.176471
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 1.000000  0.000000           12
                       Number               1.000000  0.000000            4
                       Other                1.000000  0.000000            6
                       Person               0.916667  0.083333           12
                       Place                1.000000  0.000000            2
Geography              Date                 0.833333  0.166667            6
                       Number               0.900000  0.100000           10
                       Other                0.666667  0.333333            3
                       Place                0.800000  0.200000            5
History                Date                 0.900000  0.100000           10
                       Number               1.000000  0.000000            2
                       Other                1.000000  0.000000            2
                       Person               1.000000  0.000000            3
                       Place                1.000000  0.000000            1
Misc                   Date                 1.000000  0.000000            6
                       Number               0.750000  0.250000            4
                       Other                0.777778  0.222222            9
                       Person               1.000000  0.000000            4
                       Place                0.000000  1.000000            1
Music                  Date                 0.857143  0.142857            7
                       Number               0.000000  1.000000            1
                       Other                1.000000  0.000000            5
                       Person               1.000000  0.000000            5
Other                  Date                 0.900000  0.100000           10
                       Number               1.000000  0.000000            1
                       Other                1.000000  0.000000            4
                       Person               1.000000  0.000000            4
                       Place                1.000000  0.000000            2
Politics               Date                 0.842105  0.157895           19
                       Number               1.000000  0.000000            1
                       Other                1.000000  0.000000            5
                       Person               1.000000  0.000000            6
                       Place                0.800000  0.200000            5
Science and technology Date                 1.000000  0.000000           20
                       Number               0.800000  0.200000            5
                       Other                0.700000  0.300000           10
                       Person               1.000000  0.000000            7
                       Place                1.000000  0.000000            1
Sports                 Date                 1.000000  0.000000            4
                       Number               1.000000  0.000000            1
                       Other                1.000000  0.000000            7
                       Person               1.000000  0.000000            5

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  237
Model:                          Logit   Df Residuals:                      223
Method:                           MLE   Df Model:                           13
Date:                Sun, 06 Jul 2025   Pseudo R-squ.:                  0.1022
Time:                        10:05:13   Log-Likelihood:                -63.687
converged:                      False   LL-Null:                       -70.935
Covariance Type:            nonrobust   LLR p-value:                    0.3398
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -0.8994      3.152     -0.285      0.775      -7.077       5.279
C(topic_grouped)[T.Geography]                  1.4704      1.184      1.242      0.214      -0.850       3.791
C(topic_grouped)[T.History]                    0.6389      1.460      0.438      0.662      -2.223       3.500
C(topic_grouped)[T.Misc]                       1.7952      1.170      1.534      0.125      -0.498       4.089
C(topic_grouped)[T.Music]                      1.5074      1.279      1.179      0.238      -0.999       4.014
C(topic_grouped)[T.Other]                      0.3712      1.457      0.255      0.799      -2.484       3.227
C(topic_grouped)[T.Politics]                   1.5190      1.172      1.296      0.195      -0.777       3.815
C(topic_grouped)[T.Science and technology]     1.3077      1.161      1.127      0.260      -0.967       3.583
C(topic_grouped)[T.Sports]                   -18.2353   1.26e+04     -0.001      0.999   -2.47e+04    2.46e+04
C(answer_type_grouped)[T.Number]               0.5224      0.722      0.724      0.469      -0.892       1.937
C(answer_type_grouped)[T.Other]                0.4532      0.617      0.735      0.463      -0.756       1.662
C(answer_type_grouped)[T.Person]              -1.1467      1.099     -1.043      0.297      -3.301       1.007
C(answer_type_grouped)[T.Place]                0.9674      0.800      1.209      0.227      -0.601       2.536
q_length                                      -0.6059      0.672     -0.901      0.367      -1.924       0.712
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
                    Could not fit Model 4.6: Singular matrix

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                    Could not fit Model 4.8: Singular matrix

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                    Could not fit Model 4.95: Singular matrix

                  Model 6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length (after removing deterministic categories: defaultdict(<class 'list'>, {'topic_grouped': ['Sports']}))
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  220
Model:                          Logit   Df Residuals:                      207
Method:                           MLE   Df Model:                           12
Date:                Sun, 06 Jul 2025   Pseudo R-squ.:                 0.08094
Time:                        10:05:13   Log-Likelihood:                -63.687
converged:                       True   LL-Null:                       -69.295
Covariance Type:            nonrobust   LLR p-value:                    0.5104
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -0.8994      3.152     -0.285      0.775      -7.077       5.279
C(topic_grouped)[T.Geography]                  1.4704      1.184      1.242      0.214      -0.850       3.791
C(topic_grouped)[T.History]                    0.6389      1.460      0.438      0.662      -2.223       3.500
C(topic_grouped)[T.Misc]                       1.7952      1.170      1.534      0.125      -0.498       4.089
C(topic_grouped)[T.Music]                      1.5074      1.279      1.179      0.238      -0.999       4.014
C(topic_grouped)[T.Other]                      0.3712      1.457      0.255      0.799      -2.484       3.227
C(topic_grouped)[T.Politics]                   1.5190      1.172      1.296      0.195      -0.777       3.815
C(topic_grouped)[T.Science and technology]     1.3077      1.161      1.127      0.260      -0.967       3.583
C(answer_type_grouped)[T.Number]               0.5224      0.722      0.724      0.469      -0.892       1.937
C(answer_type_grouped)[T.Other]                0.4532      0.617      0.735      0.463      -0.756       1.662
C(answer_type_grouped)[T.Person]              -1.1467      1.099     -1.043      0.297      -3.301       1.007
C(answer_type_grouped)[T.Place]                0.9674      0.800      1.209      0.227      -0.601       2.536
q_length                                      -0.6059      0.672     -0.901      0.367      -1.924       0.712
==============================================================================================================

                  Model 6.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
                    Could not fit Model 6.6: Singular matrix

--- Analyzing deepseek-chat (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/deepseek-chat_SimpleMC_redacted_temp0.0_1751720899_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    174
1     89
Name: count, dtype: int64

Answer change%: 0.3384 [0.2812177823879086, 0.3955883012622815] (n=263)
P-value vs 25%: 0.002446; P-value vs 0%: 4.198e-31
Phase 2 self-accuracy: 0.5730 [0.4702699523083599, 0.6757974634219771] (n=89)
P-value vs 25%: 7.226e-10; P-value vs 33%: 4.693e-06

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  262
Model:                          Logit   Df Residuals:                      260
Method:                           MLE   Df Model:                            1
Date:                Sun, 06 Jul 2025   Pseudo R-squ.:                0.002478
Time:                        10:05:13   Log-Likelihood:                -167.48
converged:                      False   LL-Null:                       -167.90
Covariance Type:            nonrobust   LLR p-value:                    0.3617
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept        -26.1541   4.78e+05  -5.47e-05      1.000   -9.37e+05    9.37e+05
p_i_capability    25.4953   4.78e+05   5.33e-05      1.000   -9.37e+05    9.37e+05
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                    Could not fit Model 1.5: Singular matrix

  Model 1.6: Answer Changed ~ Game Entropy
                    Could not fit Model 1.6: Singular matrix

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                    Could not fit Model 1.7: Singular matrix
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'Video games', 'History']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.692308
                        1                 0.307692
Geography               0                 0.800000
                        1                 0.200000
Misc                    0                 0.500000
                        1                 0.500000
Music                   0                 0.636364
                        1                 0.363636
Other                   0                 0.774194
                        1                 0.225806
Politics                0                 0.609756
                        1                 0.390244
Science and technology  0                 0.654545
                        1                 0.345455
Sports                  0                 0.695652
                        1                 0.304348
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.626667
                     1                 0.373333
Number               0                 0.714286
                     1                 0.285714
Other                0                 0.676923
                     1                 0.323077
Person               0                 0.648649
                     1                 0.351351
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.666667  0.333333            9
                       Number               0.800000  0.200000            5
                       Other                0.700000  0.300000           10
                       Person               0.666667  0.333333           15
Geography              Date                 0.777778  0.222222            9
                       Number               0.750000  0.250000            8
                       Other                1.000000  0.000000            3
Misc                   Date                 0.285714  0.714286            7
                       Number               0.666667  0.333333            3
                       Other                0.571429  0.428571           14
                       Person               0.500000  0.500000            8
Music                  Date                 0.400000  0.600000            5
                       Number               0.666667  0.333333            3
                       Other                0.571429  0.428571            7
                       Person               0.857143  0.142857            7
Other                  Date                 0.875000  0.125000            8
                       Number               0.833333  0.166667            6
                       Other                0.875000  0.125000            8
                       Person               0.555556  0.444444            9
Politics               Date                 0.647059  0.352941           17
                       Number               0.600000  0.400000            5
                       Other                0.500000  0.500000           10
                       Person               0.666667  0.333333            9
Science and technology Date                 0.600000  0.400000           15
                       Number               0.666667  0.333333            9
                       Other                0.750000  0.250000            8
                       Person               0.652174  0.347826           23
Sports                 Date                 0.600000  0.400000            5
                       Number               0.700000  0.300000           10
                       Other                0.800000  0.200000            5
                       Person               0.666667  0.333333            3

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  263
Model:                          Logit   Df Residuals:                      251
Method:                           MLE   Df Model:                           11
Date:                Sun, 06 Jul 2025   Pseudo R-squ.:                 0.03045
Time:                        10:05:13   Log-Likelihood:                -163.19
converged:                       True   LL-Null:                       -168.31
Covariance Type:            nonrobust   LLR p-value:                    0.5080
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      1.0663      1.702      0.627      0.531      -2.269       4.402
C(topic_grouped)[T.Geography]                 -0.6404      0.678     -0.945      0.345      -1.968       0.687
C(topic_grouped)[T.Misc]                       0.8636      0.502      1.720      0.085      -0.120       1.847
C(topic_grouped)[T.Music]                      0.2331      0.566      0.412      0.680      -0.876       1.342
C(topic_grouped)[T.Other]                     -0.4185      0.555     -0.755      0.451      -1.506       0.669
C(topic_grouped)[T.Politics]                   0.4058      0.483      0.839      0.401      -0.542       1.353
C(topic_grouped)[T.Science and technology]     0.1476      0.451      0.327      0.743      -0.736       1.032
C(topic_grouped)[T.Sports]                     0.0362      0.585      0.062      0.951      -1.111       1.183
C(answer_type_grouped)[T.Number]              -0.2872      0.411     -0.698      0.485      -1.093       0.519
C(answer_type_grouped)[T.Other]               -0.3991      0.376     -1.063      0.288      -1.135       0.337
C(answer_type_grouped)[T.Person]              -0.2180      0.362     -0.603      0.547      -0.927       0.491
q_length                                      -0.3716      0.363     -1.024      0.306      -1.083       0.340
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
                    Could not fit Model 4.6: Singular matrix

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                    Could not fit Model 4.8: Singular matrix

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                    Could not fit Model 4.95: Singular matrix
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing gemini-1.5-pro (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/gemini-1.5-pro_SimpleMC_redacted_cor_temp0.0_1751757561_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    217
1     23
Name: count, dtype: int64

Answer change%: 0.0958 [0.05859201783934817, 0.1330746488273185] (n=240)
P-value vs 25%: 4.914e-16; P-value vs 0%: 4.569e-07
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=23)
P-value vs 25%: 0; P-value vs 33%: 0
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 1.000000
Geography               0                 0.900000
                        1                 0.100000
History                 0                 0.900000
                        1                 0.100000
Misc                    0                 0.727273
                        1                 0.272727
Music                   0                 0.888889
                        1                 0.111111
Other                   0                 0.875000
                        1                 0.125000
Politics                0                 0.926829
                        1                 0.073171
Science and technology  0                 0.906977
                        1                 0.093023
Sports                  0                 0.950000
                        1                 0.050000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.930000
                     1                 0.070000
Number               0                 0.878788
                     1                 0.121212
Other                0                 0.901639
                     1                 0.098361
Person               0                 0.869565
                     1                 0.130435
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 1.000000  0.000000           12
                       Number               1.000000  0.000000            4
                       Other                1.000000  0.000000            7
                       Person               1.000000  0.000000            9
Geography              Date                 0.875000  0.125000            8
                       Number               0.857143  0.142857            7
                       Other                1.000000  0.000000            5
History                Date                 1.000000  0.000000           11
                       Number               0.666667  0.333333            3
                       Other                0.666667  0.333333            3
                       Person               1.000000  0.000000            3
Misc                   Date                 0.600000  0.400000            5
                       Number               0.666667  0.333333            3
                       Other                0.900000  0.100000           10
                       Person               0.500000  0.500000            4
Music                  Date                 1.000000  0.000000            6
                       Other                0.750000  0.250000            4
                       Person               0.875000  0.125000            8
Other                  Date                 1.000000  0.000000           11
                       Number               1.000000  0.000000            4
                       Other                0.571429  0.428571            7
                       Person               1.000000  0.000000            2
Politics               Date                 0.913043  0.086957           23
                       Number               1.000000  0.000000            1
                       Other                1.000000  0.000000           11
                       Person               0.833333  0.166667            6
Science and technology Date                 0.882353  0.117647           17
                       Number               0.857143  0.142857            7
                       Other                1.000000  0.000000           11
                       Person               0.875000  0.125000            8
Sports                 Date                 1.000000  0.000000            7
                       Number               1.000000  0.000000            4
                       Other                1.000000  0.000000            3
                       Person               0.833333  0.166667            6

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  240
Model:                          Logit   Df Residuals:                      227
Method:                           MLE   Df Model:                           12
Date:                Sun, 06 Jul 2025   Pseudo R-squ.:                 0.09948
Time:                        10:05:13   Log-Likelihood:                -68.259
converged:                      False   LL-Null:                       -75.799
Covariance Type:            nonrobust   LLR p-value:                    0.2370
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                    -23.9418    2.4e+04     -0.001      0.999    -4.7e+04    4.69e+04
C(topic_grouped)[T.Geography]                 21.5785    2.4e+04      0.001      0.999   -4.69e+04     4.7e+04
C(topic_grouped)[T.History]                   21.5604    2.4e+04      0.001      0.999   -4.69e+04     4.7e+04
C(topic_grouped)[T.Misc]                      22.7395    2.4e+04      0.001      0.999   -4.69e+04     4.7e+04
C(topic_grouped)[T.Music]                     21.4924    2.4e+04      0.001      0.999   -4.69e+04     4.7e+04
C(topic_grouped)[T.Other]                     21.8492    2.4e+04      0.001      0.999   -4.69e+04     4.7e+04
C(topic_grouped)[T.Politics]                  21.2773    2.4e+04      0.001      0.999   -4.69e+04     4.7e+04
C(topic_grouped)[T.Science and technology]    21.4292    2.4e+04      0.001      0.999   -4.69e+04     4.7e+04
C(topic_grouped)[T.Sports]                    20.6494    2.4e+04      0.001      0.999   -4.69e+04     4.7e+04
C(answer_type_grouped)[T.Number]               0.5238      0.701      0.747      0.455      -0.850       1.898
C(answer_type_grouped)[T.Other]                0.1267      0.612      0.207      0.836      -1.072       1.326
C(answer_type_grouped)[T.Person]               0.8073      0.632      1.277      0.202      -0.432       2.047
q_length                                      -0.0163      0.637     -0.026      0.980      -1.264       1.231
==============================================================================================================

Possibly complete quasi-separation: A fraction 0.13 of observations can be
perfectly predicted. This might indicate that there is complete
quasi-separation. In this case some parameters will not be identified.

                  Model 6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length (after removing deterministic categories: defaultdict(<class 'list'>, {'topic_grouped': ['Art']}))
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  208
Model:                          Logit   Df Residuals:                      196
Method:                           MLE   Df Model:                           11
Date:                Sun, 06 Jul 2025   Pseudo R-squ.:                 0.05623
Time:                        10:05:13   Log-Likelihood:                -68.259
converged:                       True   LL-Null:                       -72.326
Covariance Type:            nonrobust   LLR p-value:                    0.7013
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -2.3633      2.899     -0.815      0.415      -8.046       3.320
C(topic_grouped)[T.History]                   -0.0181      1.083     -0.017      0.987      -2.141       2.105
C(topic_grouped)[T.Misc]                       1.1610      0.924      1.256      0.209      -0.651       2.973
C(topic_grouped)[T.Music]                     -0.0861      1.137     -0.076      0.940      -2.314       2.142
C(topic_grouped)[T.Other]                      0.2707      0.983      0.275      0.783      -1.656       2.197
C(topic_grouped)[T.Politics]                  -0.3012      1.025     -0.294      0.769      -2.311       1.708
C(topic_grouped)[T.Science and technology]    -0.1494      0.946     -0.158      0.875      -2.003       1.704
C(topic_grouped)[T.Sports]                    -0.9292      1.297     -0.716      0.474      -3.472       1.614
C(answer_type_grouped)[T.Number]               0.5238      0.701      0.747      0.455      -0.850       1.898
C(answer_type_grouped)[T.Other]                0.1267      0.612      0.207      0.836      -1.072       1.326
C(answer_type_grouped)[T.Person]               0.8073      0.632      1.277      0.202      -0.432       2.047
q_length                                      -0.0163      0.637     -0.026      0.980      -1.264       1.231
==============================================================================================================

--- Analyzing gemini-1.5-pro (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/gemini-1.5-pro_SimpleMC_redacted_temp0.0_1751722404_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    196
1     64
Name: count, dtype: int64

Answer change%: 0.2462 [0.1937930680496052, 0.29851462425808717] (n=260)
P-value vs 25%: 0.8855; P-value vs 0%: 3.142e-20
Phase 2 self-accuracy: 0.5000 [0.37750225096624657, 0.6224977490337534] (n=64)
P-value vs 25%: 6.334e-05; P-value vs 33%: 0.00754
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'Video games', 'History']
                  Grouped rare answer_type into 'Misc'/'Other': None
topic_grouped           answer_changed
Art                     0                 0.813953
                        1                 0.186047
Geography               0                 0.791667
                        1                 0.208333
Misc                    0                 0.718750
                        1                 0.281250
Music                   0                 0.727273
                        1                 0.272727
Other                   0                 0.750000
                        1                 0.250000
Politics                0                 0.777778
                        1                 0.222222
Science and technology  0                 0.709091
                        1                 0.290909
Sports                  0                 0.750000
                        1                 0.250000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.826087
                     1                 0.173913
Number               0                 0.800000
                     1                 0.200000
Other                0                 0.666667
                     1                 0.333333
Person               0                 0.716216
                     1                 0.283784
Place                0                 0.777778
                     1                 0.222222
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.888889  0.111111            9
                       Number               0.800000  0.200000            5
                       Other                0.800000  0.200000           10
                       Person               0.777778  0.222222           18
                       Place                1.000000  0.000000            1
Geography              Date                 0.857143  0.142857            7
                       Number               0.727273  0.272727           11
                       Other                1.000000  0.000000            1
                       Place                0.800000  0.200000            5
Misc                   Date                 0.857143  0.142857            7
                       Number               1.000000  0.000000            3
                       Other                0.615385  0.384615           13
                       Person               0.625000  0.375000            8
                       Place                1.000000  0.000000            1
Music                  Date                 0.833333  0.166667            6
                       Number               1.000000  0.000000            4
                       Other                0.428571  0.571429            7
                       Person               1.000000  0.000000            4
                       Place                0.000000  1.000000            1
Other                  Date                 0.857143  0.142857            7
                       Number               1.000000  0.000000            3
                       Other                0.500000  0.500000            4
                       Person               0.636364  0.363636           11
                       Place                1.000000  0.000000            3
Politics               Date                 0.769231  0.230769           13
                       Number               0.800000  0.200000            5
                       Other                1.000000  0.000000            7
                       Person               0.666667  0.333333            9
                       Place                0.500000  0.500000            2
Science and technology Date                 0.777778  0.222222           18
                       Number               0.714286  0.285714            7
                       Other                0.600000  0.400000            5
                       Person               0.681818  0.318182           22
                       Place                0.666667  0.333333            3
Sports                 Date                 1.000000  0.000000            2
                       Number               0.714286  0.285714            7
                       Other                0.571429  0.428571            7
                       Person               1.000000  0.000000            2
                       Place                1.000000  0.000000            2

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  260
Model:                          Logit   Df Residuals:                      247
Method:                           MLE   Df Model:                           12
Date:                Sun, 06 Jul 2025   Pseudo R-squ.:                 0.02651
Time:                        10:05:13   Log-Likelihood:                -141.25
converged:                       True   LL-Null:                       -145.10
Covariance Type:            nonrobust   LLR p-value:                    0.8085
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.7378      1.858     -0.935      0.350      -5.380       1.904
C(topic_grouped)[T.Geography]                  0.5081      0.687      0.739      0.460      -0.839       1.855
C(topic_grouped)[T.Misc]                       0.4966      0.566      0.877      0.380      -0.613       1.606
C(topic_grouped)[T.Music]                      0.5491      0.634      0.866      0.387      -0.694       1.792
C(topic_grouped)[T.Other]                      0.4649      0.595      0.781      0.435      -0.702       1.632
C(topic_grouped)[T.Politics]                   0.3673      0.573      0.641      0.522      -0.756       1.491
C(topic_grouped)[T.Science and technology]     0.7373      0.503      1.467      0.142      -0.248       1.723
C(topic_grouped)[T.Sports]                     0.4222      0.671      0.629      0.529      -0.892       1.737
C(answer_type_grouped)[T.Number]               0.1904      0.506      0.377      0.706      -0.800       1.181
C(answer_type_grouped)[T.Other]                0.9273      0.452      2.054      0.040       0.042       1.812
C(answer_type_grouped)[T.Person]               0.6626      0.425      1.558      0.119      -0.171       1.496
C(answer_type_grouped)[T.Place]                0.2951      0.663      0.445      0.656      -1.005       1.595
q_length                                      -0.0666      0.391     -0.170      0.865      -0.834       0.700
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing gemini-2.0-flash-001 (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/gemini-2.0-flash-001_SimpleMC_redacted_cor_temp0.0_1751718104_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    145
1     75
Name: count, dtype: int64

Answer change%: 0.3409 [0.27827241490091514, 0.4035457669172666] (n=220)
P-value vs 25%: 0.004446; P-value vs 0%: 1.446e-26
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=75)
P-value vs 25%: 0; P-value vs 33%: 0

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  220
Model:                          Logit   Df Residuals:                      218
Method:                           MLE   Df Model:                            1
Date:                Sun, 06 Jul 2025   Pseudo R-squ.:                 0.05105
Time:                        10:05:13   Log-Likelihood:                -133.95
converged:                       True   LL-Null:                       -141.16
Covariance Type:            nonrobust   LLR p-value:                 0.0001468
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept         -1.3560      0.252     -5.388      0.000      -1.849      -0.863
p_i_capability     1.2626      0.344      3.674      0.000       0.589       1.936
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  220
Model:                          Logit   Df Residuals:                      218
Method:                           MLE   Df Model:                            1
Date:                Sun, 06 Jul 2025   Pseudo R-squ.:                 0.06608
Time:                        10:05:13   Log-Likelihood:                -131.83
converged:                       True   LL-Null:                       -141.16
Covariance Type:            nonrobust   LLR p-value:                 1.565e-05
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.1159      0.187     -5.965      0.000      -1.483      -0.749
capabilities_entropy     1.5887      0.385      4.127      0.000       0.834       2.343
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.5517 [0.4237, 0.6797] (n=58)
                  P-value vs 33.3%: 0.0008247

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=3.58, p=0.000663
Wilcoxon delta_p: statistic=590.00, p=0.000991
Mean p = 0.0856  [0.0387, 0.1326]

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.823
Model:                            OLS   Adj. R-squared:                  0.818
Method:                 Least Squares   F-statistic:                     184.2
Date:                Sun, 06 Jul 2025   Prob (F-statistic):           1.53e-44
Time:                        10:05:13   Log-Likelihood:                 53.209
No. Observations:                 123   AIC:                            -98.42
Df Residuals:                     119   BIC:                            -87.17
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.4738      0.129     -3.676      0.000      -0.729      -0.219
p1                    0.6136      0.140      4.391      0.000       0.337       0.890
answer_changed        0.3144      0.166      1.891      0.061      -0.015       0.644
p1:answer_changed     0.4139      0.186      2.231      0.028       0.046       0.781
==============================================================================
Omnibus:                        3.158   Durbin-Watson:                   2.040
Prob(Omnibus):                  0.206   Jarque-Bera (JB):                2.655
Skew:                           0.343   Prob(JB):                        0.265
Kurtosis:                       3.216   Cond. No.                         30.6
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-3.49, p=0.000858
Wilcoxon delta_H: statistic=599.00, p=0.000743
Mean H = -0.2235  [-0.3490, -0.0981]
Paired t-test delta_H Changed: statistic=1.38, p=0.172
Wilcoxon delta_H Changed: statistic=690.00, p=0.2
Mean H Changed = 0.1038  [-0.0432, 0.2509]

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=1721.00, p=4.73e-08
Paired t-test (game_entropy vs capabilities_entropy): statistic=6.07, p=1.46e-08
Mean capabilities_entropy-game_entropy = -0.3255  [-0.4307, -0.2203] (n=125)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  125
Model:                          Logit   Df Residuals:                      122
Method:                           MLE   Df Model:                            2
Date:                Sun, 06 Jul 2025   Pseudo R-squ.:                 0.03278
Time:                        10:05:13   Log-Likelihood:                -83.489
converged:                       True   LL-Null:                       -86.319
Covariance Type:            nonrobust   LLR p-value:                   0.05903
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept        0.0250      0.268      0.093      0.926      -0.500       0.550
p1_z            -0.6349      0.326     -1.949      0.051      -1.273       0.004
I(p1_z ** 2)    -0.1718      0.198     -0.869      0.385      -0.559       0.216
================================================================================
AUC = 0.651

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  220
Model:                          Logit   Df Residuals:                      218
Method:                           MLE   Df Model:                            1
Date:                Sun, 06 Jul 2025   Pseudo R-squ.:                 0.07757
Time:                        10:05:13   Log-Likelihood:                -130.21
converged:                       True   LL-Null:                       -141.16
Covariance Type:            nonrobust   LLR p-value:                 2.872e-06
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.3521      0.222     -6.100      0.000      -1.787      -0.918
game_entropy     1.2261      0.271      4.525      0.000       0.695       1.757
================================================================================

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  220
Model:                          Logit   Df Residuals:                      217
Method:                           MLE   Df Model:                            2
Date:                Sun, 06 Jul 2025   Pseudo R-squ.:                  0.1039
Time:                        10:05:13   Log-Likelihood:                -126.49
converged:                       True   LL-Null:                       -141.16
Covariance Type:            nonrobust   LLR p-value:                 4.260e-07
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.5104      0.235     -6.438      0.000      -1.970      -1.051
capabilities_entropy     1.1068      0.414      2.674      0.008       0.295       1.918
game_entropy             0.9449      0.291      3.243      0.001       0.374       1.516
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': None
topic_grouped           answer_changed
Art                     0                 0.851852
                        1                 0.148148
Geography               0                 0.523810
                        1                 0.476190
Misc                    0                 0.636364
                        1                 0.363636
Music                   0                 0.722222
                        1                 0.277778
Other                   0                 0.772727
                        1                 0.227273
Politics                0                 0.648649
                        1                 0.351351
Science and technology  0                 0.574468
                        1                 0.425532
Sports                  0                 0.600000
                        1                 0.400000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.538462
                     1                 0.461538
Number               0                 0.571429
                     1                 0.428571
Other                0                 0.682927
                     1                 0.317073
Person               0                 0.842105
                     1                 0.157895
Place                0                 0.687500
                     1                 0.312500
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 1.000000  0.000000            3
                       Number               0.333333  0.666667            3
                       Other                0.500000  0.500000            4
                       Person               1.000000  0.000000           14
                       Place                1.000000  0.000000            3
Geography              Date                 0.500000  0.500000            6
                       Number               0.428571  0.571429            7
                       Other                1.000000  0.000000            2
                       Place                0.500000  0.500000            6
Misc                   Date                 0.636364  0.363636           11
                       Number               0.750000  0.250000            4
                       Other                0.583333  0.416667           12
                       Person               0.600000  0.400000            5
                       Place                1.000000  0.000000            1
Music                  Date                 0.428571  0.571429            7
                       Other                0.500000  0.500000            2
                       Person               1.000000  0.000000            8
                       Place                1.000000  0.000000            1
Other                  Date                 0.666667  0.333333            9
                       Number               0.500000  0.500000            2
                       Other                1.000000  0.000000            4
                       Person               0.833333  0.166667            6
                       Place                1.000000  0.000000            1
Politics               Date                 0.631579  0.368421           19
                       Number               1.000000  0.000000            2
                       Other                0.571429  0.428571            7
                       Person               0.666667  0.333333            6
                       Place                0.666667  0.333333            3
Science and technology Date                 0.400000  0.600000           20
                       Number               0.500000  0.500000            6
                       Other                0.857143  0.142857            7
                       Person               0.769231  0.230769           13
                       Place                0.000000  1.000000            1
Sports                 Date                 0.000000  1.000000            3
                       Number               0.750000  0.250000            4
                       Other                0.666667  0.333333            3
                       Person               0.800000  0.200000            5

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  220
Model:                          Logit   Df Residuals:                      207
Method:                           MLE   Df Model:                           12
Date:                Sun, 06 Jul 2025   Pseudo R-squ.:                 0.07749
Time:                        10:05:13   Log-Likelihood:                -130.22
converged:                       True   LL-Null:                       -141.16
Covariance Type:            nonrobust   LLR p-value:                   0.03893
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.0979      1.922     -0.571      0.568      -4.864       2.668
C(topic_grouped)[T.Geography]                  1.1601      0.730      1.589      0.112      -0.271       2.591
C(topic_grouped)[T.Misc]                       0.8199      0.679      1.207      0.227      -0.511       2.151
C(topic_grouped)[T.Music]                      0.6194      0.786      0.788      0.431      -0.922       2.160
C(topic_grouped)[T.Other]                      0.1686      0.769      0.219      0.827      -1.339       1.676
C(topic_grouped)[T.Politics]                   0.6770      0.680      0.996      0.319      -0.656       2.010
C(topic_grouped)[T.Science and technology]     1.1215      0.643      1.744      0.081      -0.139       2.382
C(topic_grouped)[T.Sports]                     1.1559      0.787      1.469      0.142      -0.386       2.698
C(answer_type_grouped)[T.Number]              -0.2448      0.481     -0.508      0.611      -1.188       0.699
C(answer_type_grouped)[T.Other]               -0.5869      0.420     -1.397      0.162      -1.410       0.236
C(answer_type_grouped)[T.Person]              -1.4093      0.448     -3.145      0.002      -2.288      -0.531
C(answer_type_grouped)[T.Place]               -0.6267      0.633     -0.990      0.322      -1.867       0.613
q_length                                       0.0353      0.411      0.086      0.931      -0.770       0.841
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  220
Model:                          Logit   Df Residuals:                      206
Method:                           MLE   Df Model:                           13
Date:                Sun, 06 Jul 2025   Pseudo R-squ.:                  0.1309
Time:                        10:05:13   Log-Likelihood:                -122.68
converged:                       True   LL-Null:                       -141.16
Covariance Type:            nonrobust   LLR p-value:                 0.0004197
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.0806      1.995     -0.542      0.588      -4.990       2.829
C(topic_grouped)[T.Geography]                  1.1752      0.747      1.574      0.116      -0.288       2.639
C(topic_grouped)[T.Misc]                       0.7900      0.707      1.117      0.264      -0.596       2.176
C(topic_grouped)[T.Music]                      0.5761      0.826      0.698      0.485      -1.042       2.194
C(topic_grouped)[T.Other]                      0.1635      0.803      0.204      0.839      -1.409       1.737
C(topic_grouped)[T.Politics]                   0.9443      0.709      1.332      0.183      -0.445       2.334
C(topic_grouped)[T.Science and technology]     1.1954      0.672      1.779      0.075      -0.122       2.512
C(topic_grouped)[T.Sports]                     1.1446      0.813      1.408      0.159      -0.449       2.738
C(answer_type_grouped)[T.Number]              -0.4264      0.513     -0.832      0.406      -1.431       0.579
C(answer_type_grouped)[T.Other]               -0.4907      0.436     -1.125      0.261      -1.346       0.364
C(answer_type_grouped)[T.Person]              -1.3087      0.460     -2.842      0.004      -2.211      -0.406
C(answer_type_grouped)[T.Place]               -0.4443      0.645     -0.689      0.491      -1.709       0.820
q_length                                      -0.0851      0.430     -0.198      0.843      -0.927       0.757
capabilities_entropy                           1.5529      0.421      3.690      0.000       0.728       2.378
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  220
Model:                          Logit   Df Residuals:                      206
Method:                           MLE   Df Model:                           13
Date:                Sun, 06 Jul 2025   Pseudo R-squ.:                  0.1253
Time:                        10:05:13   Log-Likelihood:                -123.48
converged:                       True   LL-Null:                       -141.16
Covariance Type:            nonrobust   LLR p-value:                 0.0007449
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.6924      1.996     -0.848      0.397      -5.605       2.220
C(topic_grouped)[T.Geography]                  0.9911      0.750      1.321      0.187      -0.479       2.462
C(topic_grouped)[T.Misc]                       0.4860      0.707      0.687      0.492      -0.900       1.872
C(topic_grouped)[T.Music]                      0.7373      0.809      0.912      0.362      -0.848       2.322
C(topic_grouped)[T.Other]                     -0.1627      0.796     -0.204      0.838      -1.723       1.397
C(topic_grouped)[T.Politics]                   0.6369      0.701      0.909      0.363      -0.736       2.010
C(topic_grouped)[T.Science and technology]     0.9844      0.663      1.484      0.138      -0.315       2.284
C(topic_grouped)[T.Sports]                     1.0716      0.812      1.320      0.187      -0.519       2.663
C(answer_type_grouped)[T.Number]              -0.3087      0.504     -0.612      0.540      -1.297       0.680
C(answer_type_grouped)[T.Other]               -0.1760      0.450     -0.391      0.696      -1.058       0.706
C(answer_type_grouped)[T.Person]              -1.0376      0.467     -2.223      0.026      -1.952      -0.123
C(answer_type_grouped)[T.Place]               -0.2578      0.669     -0.385      0.700      -1.568       1.053
q_length                                       0.0210      0.426      0.049      0.961      -0.814       0.856
game_entropy                                   1.0943      0.306      3.579      0.000       0.495       1.693
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  220
Model:                          Logit   Df Residuals:                      205
Method:                           MLE   Df Model:                           14
Date:                Sun, 06 Jul 2025   Pseudo R-squ.:                  0.1525
Time:                        10:05:13   Log-Likelihood:                -119.64
converged:                       True   LL-Null:                       -141.16
Covariance Type:            nonrobust   LLR p-value:                 8.420e-05
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.4630      2.044     -0.716      0.474      -5.469       2.544
C(topic_grouped)[T.Geography]                  1.0409      0.756      1.377      0.168      -0.441       2.522
C(topic_grouped)[T.Misc]                       0.5407      0.724      0.747      0.455      -0.878       1.959
C(topic_grouped)[T.Music]                      0.6625      0.836      0.793      0.428      -0.975       2.300
C(topic_grouped)[T.Other]                     -0.0989      0.818     -0.121      0.904      -1.701       1.504
C(topic_grouped)[T.Politics]                   0.8632      0.719      1.200      0.230      -0.547       2.273
C(topic_grouped)[T.Science and technology]     1.0805      0.681      1.587      0.112      -0.254       2.415
C(topic_grouped)[T.Sports]                     1.1034      0.817      1.350      0.177      -0.499       2.705
C(answer_type_grouped)[T.Number]              -0.4248      0.524     -0.810      0.418      -1.453       0.603
C(answer_type_grouped)[T.Other]               -0.2099      0.458     -0.458      0.647      -1.107       0.687
C(answer_type_grouped)[T.Person]              -1.0530      0.473     -2.228      0.026      -1.980      -0.127
C(answer_type_grouped)[T.Place]               -0.2172      0.670     -0.324      0.746      -1.530       1.095
q_length                                      -0.0805      0.440     -0.183      0.855      -0.942       0.781
capabilities_entropy                           1.1990      0.445      2.695      0.007       0.327       2.071
game_entropy                                   0.7985      0.326      2.451      0.014       0.160       1.437
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing gemini-2.0-flash-001 (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/gemini-2.0-flash-001_SimpleMC_redacted_temp0.0_1751719568_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    150
1    130
Name: count, dtype: int64

Answer change%: 0.4643 [0.40587018047684087, 0.5227012480945877] (n=280)
P-value vs 25%: 6.492e-13; P-value vs 0%: 1.031e-54
Phase 2 self-accuracy: 0.3923 [0.308374895240235, 0.4762404893751496] (n=130)
P-value vs 25%: 0.0008902; P-value vs 33%: 0.1661

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  280
Model:                          Logit   Df Residuals:                      278
Method:                           MLE   Df Model:                            1
Date:                Sun, 06 Jul 2025   Pseudo R-squ.:                0.008868
Time:                        10:05:13   Log-Likelihood:                -191.65
converged:                       True   LL-Null:                       -193.37
Covariance Type:            nonrobust   LLR p-value:                   0.06404
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept         -0.4966      0.228     -2.174      0.030      -0.944      -0.049
p_i_capability     0.5522      0.300      1.838      0.066      -0.037       1.141
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  280
Model:                          Logit   Df Residuals:                      278
Method:                           MLE   Df Model:                            1
Date:                Sun, 06 Jul 2025   Pseudo R-squ.:                 0.09578
Time:                        10:05:13   Log-Likelihood:                -174.85
converged:                       True   LL-Null:                       -193.37
Covariance Type:            nonrobust   LLR p-value:                 1.157e-09
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -0.7402      0.161     -4.590      0.000      -1.056      -0.424
capabilities_entropy     1.7083      0.308      5.553      0.000       1.105       2.311
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.6355 [0.5443, 0.7267] (n=107)
                  P-value vs 33.3%: 8.323e-11

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=2.74, p=0.00741
Wilcoxon delta_p: statistic=1338.00, p=0.000471
Mean p = 0.0540  [0.0153, 0.0927]

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.852
Model:                            OLS   Adj. R-squared:                  0.850
Method:                 Least Squares   F-statistic:                     372.5
Date:                Sun, 06 Jul 2025   Prob (F-statistic):           3.21e-80
Time:                        10:05:13   Log-Likelihood:                 102.71
No. Observations:                 198   AIC:                            -197.4
Df Residuals:                     194   BIC:                            -184.3
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.7818      0.105     -7.465      0.000      -0.988      -0.575
p1                    0.9087      0.113      8.063      0.000       0.686       1.131
answer_changed        0.6312      0.124      5.090      0.000       0.387       0.876
p1:answer_changed     0.0945      0.138      0.687      0.493      -0.177       0.366
==============================================================================
Omnibus:                        2.182   Durbin-Watson:                   1.900
Prob(Omnibus):                  0.336   Jarque-Bera (JB):                2.155
Skew:                           0.252   Prob(JB):                        0.340
Kurtosis:                       2.914   Cond. No.                         33.8
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-3.04, p=0.00308
Wilcoxon delta_H: statistic=1486.00, p=0.00321
Mean H = -0.1761  [-0.2896, -0.0625]
Paired t-test delta_H Changed: statistic=0.94, p=0.348
Wilcoxon delta_H Changed: statistic=2429.00, p=0.153
Mean H Changed = 0.0464  [-0.0501, 0.1429]

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=5238.00, p=1.67e-09
Paired t-test (game_entropy vs capabilities_entropy): statistic=6.35, p=1.4e-09
Mean capabilities_entropy-game_entropy = -0.2786  [-0.3646, -0.1926] (n=202)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  202
Model:                          Logit   Df Residuals:                      199
Method:                           MLE   Df Model:                            2
Date:                Sun, 06 Jul 2025   Pseudo R-squ.:                 0.08113
Time:                        10:05:13   Log-Likelihood:                -128.33
converged:                       True   LL-Null:                       -139.66
Covariance Type:            nonrobust   LLR p-value:                 1.200e-05
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept        0.3620      0.237      1.526      0.127      -0.103       0.827
p1_z            -0.9354      0.259     -3.613      0.000      -1.443      -0.428
I(p1_z ** 2)    -0.2098      0.189     -1.113      0.266      -0.579       0.160
================================================================================
AUC = 0.714

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  280
Model:                          Logit   Df Residuals:                      278
Method:                           MLE   Df Model:                            1
Date:                Sun, 06 Jul 2025   Pseudo R-squ.:                  0.1674
Time:                        10:05:13   Log-Likelihood:                -160.99
converged:                       True   LL-Null:                       -193.37
Covariance Type:            nonrobust   LLR p-value:                 8.512e-16
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.4527      0.226     -6.429      0.000      -1.896      -1.010
game_entropy     1.9782      0.275      7.206      0.000       1.440       2.516
================================================================================

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  280
Model:                          Logit   Df Residuals:                      277
Method:                           MLE   Df Model:                            2
Date:                Sun, 06 Jul 2025   Pseudo R-squ.:                  0.2095
Time:                        10:05:13   Log-Likelihood:                -152.86
converged:                       True   LL-Null:                       -193.37
Covariance Type:            nonrobust   LLR p-value:                 2.567e-18
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.7558      0.252     -6.980      0.000      -2.249      -1.263
capabilities_entropy     1.2701      0.328      3.873      0.000       0.627       1.913
game_entropy             1.7512      0.284      6.164      0.000       1.194       2.308
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.583333
                        1                 0.416667
Geography               1                 0.608696
                        0                 0.391304
Misc                    1                 0.560976
                        0                 0.439024
Music                   0                 0.545455
                        1                 0.454545
Other                   0                 0.566667
                        1                 0.433333
Politics                0                 0.525000
                        1                 0.475000
Science and technology  0                 0.549020
                        1                 0.450980
Sports                  0                 0.680000
                        1                 0.320000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 1                 0.549451
                     0                 0.450549
Number               1                 0.540000
                     0                 0.460000
Other                0                 0.578947
                     1                 0.421053
Person               0                 0.666667
                     1                 0.333333
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.611111  0.388889           18
                       Number               0.500000  0.500000            6
                       Other                0.363636  0.636364           11
                       Person               0.769231  0.230769           13
Geography              Date                 0.333333  0.666667            9
                       Number               0.545455  0.454545           11
                       Other                0.000000  1.000000            3
Misc                   Date                 0.416667  0.583333           12
                       Number               0.000000  1.000000            5
                       Other                0.428571  0.571429           14
                       Person               0.700000  0.300000           10
Music                  Date                 0.200000  0.800000            5
                       Number               0.250000  0.750000            4
                       Other                0.888889  0.111111            9
                       Person               0.500000  0.500000            4
Other                  Date                 0.444444  0.555556            9
                       Number               0.600000  0.400000            5
                       Other                0.555556  0.444444            9
                       Person               0.714286  0.285714            7
Politics               Date                 0.235294  0.764706           17
                       Number               1.000000  0.000000            4
                       Other                0.800000  0.200000           10
                       Person               0.555556  0.444444            9
Science and technology Date                 0.466667  0.533333           15
                       Number               0.500000  0.500000            8
                       Other                0.636364  0.363636           11
                       Person               0.588235  0.411765           17
Sports                 Date                 1.000000  0.000000            6
                       Number               0.285714  0.714286            7
                       Other                0.666667  0.333333            9
                       Person               1.000000  0.000000            3

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  280
Model:                          Logit   Df Residuals:                      268
Method:                           MLE   Df Model:                           11
Date:                Sun, 06 Jul 2025   Pseudo R-squ.:                 0.03816
Time:                        10:05:13   Log-Likelihood:                -185.99
converged:                       True   LL-Null:                       -193.37
Covariance Type:            nonrobust   LLR p-value:                    0.1939
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      0.8479      1.566      0.542      0.588      -2.221       3.917
C(topic_grouped)[T.Geography]                  0.5004      0.538      0.931      0.352      -0.553       1.554
C(topic_grouped)[T.Misc]                       0.6389      0.439      1.455      0.146      -0.222       1.500
C(topic_grouped)[T.Music]                      0.1649      0.530      0.311      0.756      -0.875       1.205
C(topic_grouped)[T.Other]                      0.0701      0.480      0.146      0.884      -0.871       1.011
C(topic_grouped)[T.Politics]                   0.2579      0.447      0.578      0.563      -0.617       1.133
C(topic_grouped)[T.Science and technology]     0.2102      0.416      0.506      0.613      -0.605       1.025
C(topic_grouped)[T.Sports]                    -0.4603      0.533     -0.863      0.388      -1.506       0.585
C(answer_type_grouped)[T.Number]              -0.0297      0.366     -0.081      0.935      -0.748       0.688
C(answer_type_grouped)[T.Other]               -0.5247      0.324     -1.619      0.105      -1.160       0.110
C(answer_type_grouped)[T.Person]              -0.9324      0.356     -2.621      0.009      -1.630      -0.235
q_length                                      -0.1850      0.338     -0.548      0.584      -0.847       0.477
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  280
Model:                          Logit   Df Residuals:                      267
Method:                           MLE   Df Model:                           12
Date:                Sun, 06 Jul 2025   Pseudo R-squ.:                  0.1234
Time:                        10:05:13   Log-Likelihood:                -169.51
converged:                       True   LL-Null:                       -193.37
Covariance Type:            nonrobust   LLR p-value:                 3.519e-06
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      1.3907      1.660      0.838      0.402      -1.863       4.645
C(topic_grouped)[T.Geography]                  0.5626      0.565      0.995      0.320      -0.546       1.671
C(topic_grouped)[T.Misc]                       0.4968      0.470      1.056      0.291      -0.425       1.419
C(topic_grouped)[T.Music]                     -0.1256      0.570     -0.220      0.826      -1.242       0.991
C(topic_grouped)[T.Other]                      0.0018      0.509      0.004      0.997      -0.995       0.999
C(topic_grouped)[T.Politics]                   0.3780      0.475      0.797      0.426      -0.552       1.308
C(topic_grouped)[T.Science and technology]     0.1778      0.443      0.402      0.688      -0.690       1.045
C(topic_grouped)[T.Sports]                    -0.2857      0.567     -0.504      0.614      -1.397       0.825
C(answer_type_grouped)[T.Number]              -0.0954      0.391     -0.244      0.807      -0.861       0.671
C(answer_type_grouped)[T.Other]               -0.4533      0.347     -1.305      0.192      -1.134       0.228
C(answer_type_grouped)[T.Person]              -0.8019      0.375     -2.139      0.032      -1.537      -0.067
q_length                                      -0.4399      0.361     -1.218      0.223      -1.148       0.268
capabilities_entropy                           1.6868      0.321      5.257      0.000       1.058       2.316
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  280
Model:                          Logit   Df Residuals:                      267
Method:                           MLE   Df Model:                           12
Date:                Sun, 06 Jul 2025   Pseudo R-squ.:                  0.1785
Time:                        10:05:13   Log-Likelihood:                -158.85
converged:                       True   LL-Null:                       -193.37
Covariance Type:            nonrobust   LLR p-value:                 4.871e-10
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -0.4865      1.740     -0.280      0.780      -3.896       2.923
C(topic_grouped)[T.Geography]                  0.5743      0.593      0.968      0.333      -0.589       1.737
C(topic_grouped)[T.Misc]                       0.5447      0.490      1.112      0.266      -0.415       1.504
C(topic_grouped)[T.Music]                      0.2209      0.574      0.385      0.700      -0.904       1.346
C(topic_grouped)[T.Other]                      0.0911      0.531      0.171      0.864      -0.950       1.133
C(topic_grouped)[T.Politics]                   0.3397      0.499      0.680      0.496      -0.639       1.318
C(topic_grouped)[T.Science and technology]     0.2749      0.468      0.587      0.557      -0.642       1.192
C(topic_grouped)[T.Sports]                    -0.2127      0.583     -0.365      0.715      -1.356       0.930
C(answer_type_grouped)[T.Number]               0.1118      0.410      0.273      0.785      -0.691       0.915
C(answer_type_grouped)[T.Other]                0.0667      0.371      0.180      0.857      -0.660       0.793
C(answer_type_grouped)[T.Person]              -0.2631      0.409     -0.644      0.520      -1.064       0.538
q_length                                      -0.2568      0.372     -0.690      0.490      -0.986       0.473
game_entropy                                   1.9347      0.290      6.677      0.000       1.367       2.503
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  280
Model:                          Logit   Df Residuals:                      266
Method:                           MLE   Df Model:                           13
Date:                Sun, 06 Jul 2025   Pseudo R-squ.:                  0.2205
Time:                        10:05:13   Log-Likelihood:                -150.72
converged:                       True   LL-Null:                       -193.37
Covariance Type:            nonrobust   LLR p-value:                 1.104e-12
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      0.1516      1.779      0.085      0.932      -3.335       3.639
C(topic_grouped)[T.Geography]                  0.5782      0.598      0.967      0.334      -0.594       1.750
C(topic_grouped)[T.Misc]                       0.4574      0.513      0.892      0.373      -0.548       1.463
C(topic_grouped)[T.Music]                     -0.0246      0.608     -0.040      0.968      -1.217       1.168
C(topic_grouped)[T.Other]                      0.0284      0.551      0.052      0.959      -1.051       1.108
C(topic_grouped)[T.Politics]                   0.3795      0.515      0.737      0.461      -0.630       1.389
C(topic_grouped)[T.Science and technology]     0.2143      0.481      0.446      0.656      -0.727       1.156
C(topic_grouped)[T.Sports]                    -0.1331      0.607     -0.219      0.826      -1.323       1.057
C(answer_type_grouped)[T.Number]               0.0085      0.417      0.020      0.984      -0.808       0.825
C(answer_type_grouped)[T.Other]                0.0473      0.385      0.123      0.902      -0.706       0.801
C(answer_type_grouped)[T.Person]              -0.2534      0.424     -0.597      0.550      -1.085       0.578
q_length                                      -0.4575      0.385     -1.190      0.234      -1.211       0.296
capabilities_entropy                           1.2992      0.336      3.863      0.000       0.640       1.958
game_entropy                                   1.7180      0.300      5.728      0.000       1.130       2.306
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing gemini-2.5-flash-preview-04-17 (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/gemini-2.5-flash-preview-04-17_SimpleMC_redacted_temp0.0_1751726354_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
1    95
0    70
Name: count, dtype: int64

Answer change%: 0.5758 [0.5003468713811036, 0.651168280134048] (n=165)
P-value vs 25%: 2.526e-17; P-value vs 0%: 1.257e-50
Phase 2 self-accuracy: 0.6000 [0.501487370995732, 0.6985126290042679] (n=95)
P-value vs 25%: 3.32e-12; P-value vs 33%: 1.084e-07

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  165
Model:                          Logit   Df Residuals:                      163
Method:                           MLE   Df Model:                            1
Date:                Sun, 06 Jul 2025   Pseudo R-squ.:                0.004136
Time:                        10:05:13   Log-Likelihood:                -112.00
converged:                       True   LL-Null:                       -112.47
Covariance Type:            nonrobust   LLR p-value:                    0.3348
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept        0.3225      0.159      2.032      0.042       0.011       0.634
game_entropy    -1.3116      1.724     -0.761      0.447      -4.691       2.068
================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['Video games', 'History']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.500000
                        1                 0.500000
Geography               1                 0.846154
                        0                 0.153846
Misc                    1                 0.700000
                        0                 0.300000
Music                   1                 0.555556
                        0                 0.444444
Other                   0                 0.666667
                        1                 0.333333
Politics                1                 0.571429
                        0                 0.428571
Science and technology  1                 0.606061
                        0                 0.393939
Sports                  0                 0.500000
                        1                 0.500000
TV shows                1                 0.533333
                        0                 0.466667
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 1                 0.685185
                     0                 0.314815
Number               1                 0.571429
                     0                 0.428571
Other                1                 0.571429
                     0                 0.428571
Person               0                 0.588235
                     1                 0.411765
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.500000  0.500000            4
                       Number               0.000000  1.000000            2
                       Other                0.500000  0.500000            4
                       Person               0.625000  0.375000            8
Geography              Date                 0.200000  0.800000            5
                       Number               0.142857  0.857143            7
                       Other                0.000000  1.000000            1
Misc                   Date                 0.000000  1.000000            9
                       Number               1.000000  0.000000            3
                       Other                0.500000  0.500000            6
                       Person               0.000000  1.000000            2
Music                  Date                 0.600000  0.400000            5
                       Number               0.333333  0.666667            3
                       Other                0.285714  0.714286            7
                       Person               0.666667  0.333333            3
Other                  Date                 0.571429  0.428571            7
                       Number               0.750000  0.250000            4
                       Other                0.500000  0.500000            2
                       Person               1.000000  0.000000            2
Politics               Date                 0.363636  0.636364           11
                       Number               0.500000  0.500000            2
                       Other                0.500000  0.500000            4
                       Person               0.500000  0.500000            4
Science and technology Date                 0.272727  0.727273           11
                       Number               0.571429  0.428571            7
                       Other                0.333333  0.666667            6
                       Person               0.444444  0.555556            9
Sports                 Number               0.333333  0.666667            6
                       Other                0.333333  0.666667            3
                       Person               1.000000  0.000000            3
TV shows               Date                 0.000000  1.000000            2
                       Number               0.000000  1.000000            1
                       Other                0.555556  0.444444            9
                       Person               0.666667  0.333333            3

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  165
Model:                          Logit   Df Residuals:                      152
Method:                           MLE   Df Model:                           12
Date:                Sun, 06 Jul 2025   Pseudo R-squ.:                 0.09603
Time:                        10:05:13   Log-Likelihood:                -101.67
converged:                       True   LL-Null:                       -112.47
Covariance Type:            nonrobust   LLR p-value:                   0.04225
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      5.6234      2.182      2.577      0.010       1.347       9.900
C(topic_grouped)[T.Geography]                  1.4261      0.975      1.463      0.143      -0.484       3.337
C(topic_grouped)[T.Misc]                       0.6672      0.723      0.923      0.356      -0.750       2.085
C(topic_grouped)[T.Music]                     -0.1730      0.709     -0.244      0.807      -1.563       1.217
C(topic_grouped)[T.Other]                     -1.2137      0.771     -1.574      0.116      -2.725       0.298
C(topic_grouped)[T.Politics]                   0.0357      0.686      0.052      0.958      -1.308       1.379
C(topic_grouped)[T.Science and technology]     0.3225      0.622      0.518      0.604      -0.897       1.542
C(topic_grouped)[T.Sports]                     0.0480      0.791      0.061      0.952      -1.502       1.598
C(topic_grouped)[T.TV shows]                  -0.1671      0.745     -0.224      0.823      -1.628       1.293
C(answer_type_grouped)[T.Number]              -0.7750      0.514     -1.507      0.132      -1.783       0.233
C(answer_type_grouped)[T.Other]               -0.6826      0.481     -1.421      0.155      -1.624       0.259
C(answer_type_grouped)[T.Person]              -1.3108      0.504     -2.600      0.009      -2.299      -0.323
q_length                                      -1.0545      0.448     -2.355      0.019      -1.932      -0.177
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  165
Model:                          Logit   Df Residuals:                      151
Method:                           MLE   Df Model:                           13
Date:                Sun, 06 Jul 2025   Pseudo R-squ.:                  0.1184
Time:                        10:05:13   Log-Likelihood:                -99.147
converged:                       True   LL-Null:                       -112.47
Covariance Type:            nonrobust   LLR p-value:                   0.01392
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      6.1634      2.230      2.764      0.006       1.793      10.534
C(topic_grouped)[T.Geography]                  2.2164      1.188      1.866      0.062      -0.111       4.544
C(topic_grouped)[T.Misc]                       0.7075      0.728      0.972      0.331      -0.719       2.134
C(topic_grouped)[T.Music]                     -0.1818      0.712     -0.255      0.799      -1.577       1.214
C(topic_grouped)[T.Other]                     -1.2448      0.775     -1.607      0.108      -2.763       0.273
C(topic_grouped)[T.Politics]                   0.0173      0.689      0.025      0.980      -1.334       1.369
C(topic_grouped)[T.Science and technology]     0.3478      0.626      0.556      0.578      -0.879       1.574
C(topic_grouped)[T.Sports]                     0.1300      0.794      0.164      0.870      -1.427       1.687
C(topic_grouped)[T.TV shows]                  -0.1769      0.747     -0.237      0.813      -1.641       1.287
C(answer_type_grouped)[T.Number]              -0.9845      0.532     -1.850      0.064      -2.028       0.058
C(answer_type_grouped)[T.Other]               -0.8003      0.490     -1.633      0.102      -1.761       0.160
C(answer_type_grouped)[T.Person]              -1.4104      0.512     -2.755      0.006      -2.414      -0.407
q_length                                      -1.1515      0.457     -2.520      0.012      -2.047      -0.256
game_entropy                                  -3.3319      2.139     -1.558      0.119      -7.524       0.860
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing gpt-4.1-2025-04-14 (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/gpt-4.1-2025-04-14_SimpleMC_redacted_cor_temp0.0_1751719329_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    192
1     63
Name: count, dtype: int64

Answer change%: 0.2471 [0.19412189864559706, 0.29999574841322646] (n=255)
P-value vs 25%: 0.9133; P-value vs 0%: 5.841e-20
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=63)
P-value vs 25%: 0; P-value vs 33%: 0

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  255
Model:                          Logit   Df Residuals:                      253
Method:                           MLE   Df Model:                            1
Date:                Sun, 06 Jul 2025   Pseudo R-squ.:                 0.02635
Time:                        10:05:13   Log-Likelihood:                -138.81
converged:                       True   LL-Null:                       -142.57
Covariance Type:            nonrobust   LLR p-value:                  0.006123
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          1.1245      0.808      1.392      0.164      -0.458       2.707
p_i_capability    -2.4865      0.893     -2.784      0.005      -4.237      -0.736
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  255
Model:                          Logit   Df Residuals:                      253
Method:                           MLE   Df Model:                            1
Date:                Sun, 06 Jul 2025   Pseudo R-squ.:                 0.03999
Time:                        10:05:13   Log-Likelihood:                -136.86
converged:                       True   LL-Null:                       -142.57
Covariance Type:            nonrobust   LLR p-value:                 0.0007338
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.4564      0.187     -7.793      0.000      -1.823      -1.090
capabilities_entropy     0.9907      0.291      3.400      0.001       0.420       1.562
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.8108 [0.6846, 0.9370] (n=37)
                  P-value vs 33.3%: 1.211e-13

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=-3.15, p=0.0024
Wilcoxon delta_p: statistic=620.00, p=0.000727
Mean p = -0.0672  [-0.1089, -0.0254]

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.910
Model:                            OLS   Adj. R-squared:                  0.908
Method:                 Least Squares   F-statistic:                     344.6
Date:                Sun, 06 Jul 2025   Prob (F-statistic):           3.23e-53
Time:                        10:05:13   Log-Likelihood:                 66.237
No. Observations:                 106   AIC:                            -124.5
Df Residuals:                     102   BIC:                            -113.8
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.6408      0.076     -8.446      0.000      -0.791      -0.490
p1                    0.6906      0.089      7.732      0.000       0.513       0.868
answer_changed        0.3124      0.131      2.393      0.019       0.053       0.571
p1:answer_changed     0.5854      0.154      3.796      0.000       0.280       0.891
==============================================================================
Omnibus:                        5.771   Durbin-Watson:                   1.919
Prob(Omnibus):                  0.056   Jarque-Bera (JB):                5.278
Skew:                           0.441   Prob(JB):                       0.0714
Kurtosis:                       3.647   Cond. No.                         23.4
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=2.42, p=0.0182
Wilcoxon delta_H: statistic=933.00, p=0.101
Mean H = 0.1330  [0.0252, 0.2407]
Paired t-test delta_H Changed: statistic=3.61, p=0.000937
Wilcoxon delta_H Changed: statistic=135.00, p=0.000729
Mean H Changed = 0.2836  [0.1294, 0.4377]

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=1990.00, p=0.0077
Paired t-test (game_entropy vs capabilities_entropy): statistic=-2.80, p=0.00611
Mean capabilities_entropy-game_entropy = 0.1467  [0.0440, 0.2494] (n=106)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  106
Model:                          Logit   Df Residuals:                      103
Method:                           MLE   Df Model:                            2
Date:                Sun, 06 Jul 2025   Pseudo R-squ.:                0.001866
Time:                        10:05:13   Log-Likelihood:                -68.439
converged:                       True   LL-Null:                       -68.567
Covariance Type:            nonrobust   LLR p-value:                    0.8799
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.4835      0.346     -1.398      0.162      -1.161       0.194
p1_z            -0.1041      0.265     -0.392      0.695      -0.624       0.416
I(p1_z ** 2)    -0.1413      0.285     -0.495      0.620      -0.700       0.418
================================================================================
AUC = 0.543

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  255
Model:                          Logit   Df Residuals:                      253
Method:                           MLE   Df Model:                            1
Date:                Sun, 06 Jul 2025   Pseudo R-squ.:                 0.09798
Time:                        10:05:13   Log-Likelihood:                -128.60
converged:                       True   LL-Null:                       -142.57
Covariance Type:            nonrobust   LLR p-value:                 1.253e-07
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.6701      0.196     -8.503      0.000      -2.055      -1.285
game_entropy     1.8718      0.364      5.135      0.000       1.157       2.586
================================================================================

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  255
Model:                          Logit   Df Residuals:                      252
Method:                           MLE   Df Model:                            2
Date:                Sun, 06 Jul 2025   Pseudo R-squ.:                 0.09980
Time:                        10:05:13   Log-Likelihood:                -128.34
converged:                       True   LL-Null:                       -142.57
Covariance Type:            nonrobust   LLR p-value:                 6.622e-07
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.7113      0.206     -8.309      0.000      -2.115      -1.308
capabilities_entropy     0.2596      0.358      0.725      0.468      -0.442       0.961
game_entropy             1.7124      0.424      4.041      0.000       0.882       2.543
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': None
topic_grouped           answer_changed
Art                     0                 0.780488
                        1                 0.219512
Geography               0                 0.650000
                        1                 0.350000
Misc                    0                 0.729730
                        1                 0.270270
Music                   0                 0.700000
                        1                 0.300000
Other                   0                 0.781250
                        1                 0.218750
Politics                0                 0.675000
                        1                 0.325000
Science and technology  0                 0.837209
                        1                 0.162791
Sports                  0                 0.818182
                        1                 0.181818
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.710145
                     1                 0.289855
Number               0                 0.615385
                     1                 0.384615
Other                0                 0.800000
                     1                 0.200000
Person               0                 0.833333
                     1                 0.166667
Place                0                 0.636364
                     1                 0.363636
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.800000  0.200000            5
                       Number               0.500000  0.500000            4
                       Other                0.750000  0.250000            8
                       Person               0.894737  0.105263           19
                       Place                0.600000  0.400000            5
Geography              Date                 0.428571  0.571429            7
                       Number               0.750000  0.250000            4
                       Other                1.000000  0.000000            3
                       Place                0.666667  0.333333            6
Misc                   Date                 0.666667  0.333333            9
                       Number               1.000000  0.000000            4
                       Other                0.615385  0.384615           13
                       Person               0.888889  0.111111            9
                       Place                0.500000  0.500000            2
Music                  Date                 0.500000  0.500000            6
                       Number               0.000000  1.000000            1
                       Other                1.000000  0.000000            3
                       Person               0.800000  0.200000           10
Other                  Date                 0.625000  0.375000            8
                       Number               0.750000  0.250000            4
                       Other                0.714286  0.285714            7
                       Person               0.900000  0.100000           10
                       Place                1.000000  0.000000            3
Politics               Date                 0.687500  0.312500           16
                       Number               0.666667  0.333333            3
                       Other                0.888889  0.111111            9
                       Person               0.500000  0.500000            8
                       Place                0.500000  0.500000            4
Science and technology Date                 0.916667  0.083333           12
                       Number               0.333333  0.666667            3
                       Other                0.909091  0.090909           11
                       Person               0.823529  0.176471           17
Sports                 Date                 1.000000  0.000000            6
                       Number               0.333333  0.666667            3
                       Other                0.833333  0.166667            6
                       Person               1.000000  0.000000            5
                       Place                0.500000  0.500000            2

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  255
Model:                          Logit   Df Residuals:                      242
Method:                           MLE   Df Model:                           12
Date:                Sun, 06 Jul 2025   Pseudo R-squ.:                 0.04284
Time:                        10:05:13   Log-Likelihood:                -136.46
converged:                       True   LL-Null:                       -142.57
Covariance Type:            nonrobust   LLR p-value:                    0.4286
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.5869      1.873     -0.847      0.397      -5.258       2.084
C(topic_grouped)[T.Geography]                  0.2701      0.632      0.427      0.669      -0.969       1.509
C(topic_grouped)[T.Misc]                       0.2312      0.545      0.424      0.672      -0.838       1.300
C(topic_grouped)[T.Music]                      0.5152      0.635      0.812      0.417      -0.729       1.759
C(topic_grouped)[T.Other]                     -0.0955      0.583     -0.164      0.870      -1.238       1.047
C(topic_grouped)[T.Politics]                   0.3926      0.536      0.733      0.464      -0.658       1.443
C(topic_grouped)[T.Science and technology]    -0.3490      0.581     -0.601      0.548      -1.488       0.790
C(topic_grouped)[T.Sports]                    -0.3608      0.685     -0.526      0.599      -1.704       0.983
C(answer_type_grouped)[T.Number]               0.4800      0.494      0.972      0.331      -0.488       1.448
C(answer_type_grouped)[T.Other]               -0.4270      0.428     -0.998      0.318      -1.266       0.412
C(answer_type_grouped)[T.Person]              -0.6460      0.421     -1.534      0.125      -1.471       0.179
C(answer_type_grouped)[T.Place]                0.3135      0.541      0.580      0.562      -0.747       1.373
q_length                                       0.1272      0.405      0.314      0.753      -0.666       0.920
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  255
Model:                          Logit   Df Residuals:                      241
Method:                           MLE   Df Model:                           13
Date:                Sun, 06 Jul 2025   Pseudo R-squ.:                 0.07638
Time:                        10:05:13   Log-Likelihood:                -131.68
converged:                       True   LL-Null:                       -142.57
Covariance Type:            nonrobust   LLR p-value:                   0.05889
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -2.6739      1.970     -1.357      0.175      -6.535       1.187
C(topic_grouped)[T.Geography]                  0.2122      0.644      0.329      0.742      -1.051       1.475
C(topic_grouped)[T.Misc]                       0.2188      0.560      0.391      0.696      -0.879       1.317
C(topic_grouped)[T.Music]                      0.5179      0.648      0.799      0.424      -0.753       1.789
C(topic_grouped)[T.Other]                     -0.1770      0.597     -0.296      0.767      -1.348       0.994
C(topic_grouped)[T.Politics]                   0.4609      0.545      0.846      0.397      -0.607       1.529
C(topic_grouped)[T.Science and technology]    -0.3084      0.591     -0.522      0.602      -1.467       0.850
C(topic_grouped)[T.Sports]                    -0.4246      0.711     -0.597      0.550      -1.818       0.969
C(answer_type_grouped)[T.Number]               0.4299      0.507      0.848      0.396      -0.564       1.423
C(answer_type_grouped)[T.Other]               -0.1350      0.450     -0.300      0.764      -1.017       0.747
C(answer_type_grouped)[T.Person]              -0.3916      0.436     -0.898      0.369      -1.246       0.463
C(answer_type_grouped)[T.Place]                0.6904      0.560      1.234      0.217      -0.406       1.787
q_length                                       0.2548      0.421      0.605      0.545      -0.570       1.080
capabilities_entropy                           0.9910      0.319      3.109      0.002       0.366       1.616
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  255
Model:                          Logit   Df Residuals:                      241
Method:                           MLE   Df Model:                           13
Date:                Sun, 06 Jul 2025   Pseudo R-squ.:                  0.1366
Time:                        10:05:13   Log-Likelihood:                -123.09
converged:                       True   LL-Null:                       -142.57
Covariance Type:            nonrobust   LLR p-value:                 0.0002041
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -2.7800      2.023     -1.374      0.169      -6.745       1.185
C(topic_grouped)[T.Geography]                  0.5021      0.666      0.754      0.451      -0.804       1.808
C(topic_grouped)[T.Misc]                       0.4017      0.579      0.694      0.488      -0.733       1.536
C(topic_grouped)[T.Music]                      0.3817      0.697      0.547      0.584      -0.985       1.748
C(topic_grouped)[T.Other]                     -0.0640      0.622     -0.103      0.918      -1.284       1.156
C(topic_grouped)[T.Politics]                   0.7322      0.568      1.289      0.197      -0.381       1.846
C(topic_grouped)[T.Science and technology]    -0.2757      0.615     -0.449      0.654      -1.480       0.929
C(topic_grouped)[T.Sports]                    -0.6277      0.748     -0.839      0.402      -2.094       0.839
C(answer_type_grouped)[T.Number]               0.4328      0.531      0.815      0.415      -0.608       1.473
C(answer_type_grouped)[T.Other]                0.2793      0.479      0.583      0.560      -0.659       1.218
C(answer_type_grouped)[T.Person]              -0.0951      0.470     -0.203      0.839      -1.015       0.825
C(answer_type_grouped)[T.Place]                0.8730      0.588      1.485      0.138      -0.279       2.025
q_length                                       0.1552      0.432      0.359      0.720      -0.692       1.002
game_entropy                                   2.0591      0.418      4.927      0.000       1.240       2.878
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  255
Model:                          Logit   Df Residuals:                      240
Method:                           MLE   Df Model:                           14
Date:                Sun, 06 Jul 2025   Pseudo R-squ.:                  0.1390
Time:                        10:05:13   Log-Likelihood:                -122.75
converged:                       True   LL-Null:                       -142.57
Covariance Type:            nonrobust   LLR p-value:                 0.0002909
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -3.0409      2.059     -1.477      0.140      -7.077       0.995
C(topic_grouped)[T.Geography]                  0.4690      0.668      0.703      0.482      -0.839       1.778
C(topic_grouped)[T.Misc]                       0.3852      0.582      0.662      0.508      -0.755       1.526
C(topic_grouped)[T.Music]                      0.3911      0.699      0.560      0.576      -0.978       1.760
C(topic_grouped)[T.Other]                     -0.0967      0.624     -0.155      0.877      -1.320       1.127
C(topic_grouped)[T.Politics]                   0.7276      0.569      1.280      0.201      -0.387       1.842
C(topic_grouped)[T.Science and technology]    -0.2697      0.615     -0.439      0.661      -1.475       0.935
C(topic_grouped)[T.Sports]                    -0.6234      0.754     -0.827      0.408      -2.101       0.854
C(answer_type_grouped)[T.Number]               0.4266      0.533      0.800      0.424      -0.618       1.472
C(answer_type_grouped)[T.Other]                0.3248      0.484      0.671      0.502      -0.623       1.273
C(answer_type_grouped)[T.Person]              -0.0589      0.472     -0.125      0.901      -0.984       0.866
C(answer_type_grouped)[T.Place]                0.9482      0.593      1.600      0.110      -0.213       2.110
q_length                                       0.1957      0.437      0.448      0.655      -0.661       1.053
capabilities_entropy                           0.3145      0.375      0.838      0.402      -0.421       1.050
game_entropy                                   1.8896      0.462      4.088      0.000       0.984       2.796
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing gpt-4.1-2025-04-14 (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/gpt-4.1-2025-04-14_SimpleMC_redacted_temp0.0_1751719704_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
1    128
0    109
Name: count, dtype: int64

Answer change%: 0.5401 [0.47663260876685, 0.6035361676044579] (n=237)
P-value vs 25%: 3.234e-19; P-value vs 0%: 1.752e-62
Phase 2 self-accuracy: 0.5781 [0.49256990530408606, 0.6636800946959139] (n=128)
P-value vs 25%: 5.607e-14; P-value vs 33%: 1.96e-08

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  237
Model:                          Logit   Df Residuals:                      235
Method:                           MLE   Df Model:                            1
Date:                Sun, 06 Jul 2025   Pseudo R-squ.:                 0.03888
Time:                        10:05:14   Log-Likelihood:                -157.16
converged:                       True   LL-Null:                       -163.51
Covariance Type:            nonrobust   LLR p-value:                 0.0003627
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          2.1835      0.610      3.578      0.000       0.987       3.380
p_i_capability    -2.4550      0.715     -3.434      0.001      -3.856      -1.054
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  237
Model:                          Logit   Df Residuals:                      235
Method:                           MLE   Df Model:                            1
Date:                Sun, 06 Jul 2025   Pseudo R-squ.:                 0.04234
Time:                        10:05:14   Log-Likelihood:                -156.59
converged:                       True   LL-Null:                       -163.51
Covariance Type:            nonrobust   LLR p-value:                 0.0001983
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -0.3639      0.194     -1.873      0.061      -0.745       0.017
capabilities_entropy     0.8794      0.245      3.597      0.000       0.400       1.359
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.6667 [0.5709, 0.7625] (n=93)
                  P-value vs 33.3%: 9.162e-12

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=-3.16, p=0.00243
Wilcoxon delta_p: statistic=617.00, p=0.0018
Mean p = -0.0691  [-0.1119, -0.0262]

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.900
Model:                            OLS   Adj. R-squared:                  0.899
Method:                 Least Squares   F-statistic:                     467.6
Date:                Sun, 06 Jul 2025   Prob (F-statistic):           2.04e-77
Time:                        10:05:14   Log-Likelihood:                 94.851
No. Observations:                 159   AIC:                            -181.7
Df Residuals:                     155   BIC:                            -169.4
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.6045      0.079     -7.630      0.000      -0.761      -0.448
p1                    0.6563      0.095      6.912      0.000       0.469       0.844
answer_changed        0.5081      0.095      5.375      0.000       0.321       0.695
p1:answer_changed     0.3560      0.116      3.070      0.003       0.127       0.585
==============================================================================
Omnibus:                        6.557   Durbin-Watson:                   1.768
Prob(Omnibus):                  0.038   Jarque-Bera (JB):                8.016
Skew:                          -0.269   Prob(JB):                       0.0182
Kurtosis:                       3.959   Cond. No.                         25.9
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=3.83, p=0.000289
Wilcoxon delta_H: statistic=687.00, p=0.00751
Mean H = 0.2445  [0.1195, 0.3696]
Paired t-test delta_H Changed: statistic=4.80, p=6.03e-06
Wilcoxon delta_H Changed: statistic=1004.00, p=5.98e-06
Mean H Changed = 0.2656  [0.1572, 0.3739]

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=3727.00, p=5.96e-06
Paired t-test (game_entropy vs capabilities_entropy): statistic=-4.86, p=2.82e-06
Mean capabilities_entropy-game_entropy = 0.2306  [0.1376, 0.3236] (n=159)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  159
Model:                          Logit   Df Residuals:                      156
Method:                           MLE   Df Model:                            2
Date:                Sun, 06 Jul 2025   Pseudo R-squ.:                 0.02713
Time:                        10:05:14   Log-Likelihood:                -104.98
converged:                       True   LL-Null:                       -107.91
Covariance Type:            nonrobust   LLR p-value:                   0.05354
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept        0.1629      0.250      0.652      0.514      -0.327       0.653
p1_z            -0.2723      0.194     -1.406      0.160      -0.652       0.107
I(p1_z ** 2)     0.2034      0.203      1.001      0.317      -0.195       0.602
================================================================================
AUC = 0.562

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  237
Model:                          Logit   Df Residuals:                      235
Method:                           MLE   Df Model:                            1
Date:                Sun, 06 Jul 2025   Pseudo R-squ.:                 0.04549
Time:                        10:05:14   Log-Likelihood:                -156.07
converged:                       True   LL-Null:                       -163.51
Covariance Type:            nonrobust   LLR p-value:                 0.0001147
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.3281      0.184     -1.786      0.074      -0.688       0.032
game_entropy     1.1969      0.323      3.711      0.000       0.565       1.829
================================================================================

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  237
Model:                          Logit   Df Residuals:                      234
Method:                           MLE   Df Model:                            2
Date:                Sun, 06 Jul 2025   Pseudo R-squ.:                 0.06425
Time:                        10:05:14   Log-Likelihood:                -153.01
converged:                       True   LL-Null:                       -163.51
Covariance Type:            nonrobust   LLR p-value:                 2.737e-05
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -0.5897      0.215     -2.737      0.006      -1.012      -0.167
capabilities_entropy     0.6400      0.262      2.444      0.015       0.127       1.153
game_entropy             0.9043      0.344      2.631      0.009       0.231       1.578
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'Video games', 'History']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     1                 0.575758
                        0                 0.424242
Geography               1                 0.652174
                        0                 0.347826
Misc                    1                 0.540541
                        0                 0.459459
Music                   0                 0.500000
                        1                 0.500000
Other                   1                 0.631579
                        0                 0.368421
Politics                1                 0.514286
                        0                 0.485714
Science and technology  1                 0.528302
                        0                 0.471698
Sports                  0                 0.647059
                        1                 0.352941
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 1                 0.562500
                     0                 0.437500
Number               1                 0.647059
                     0                 0.352941
Other                0                 0.540000
                     1                 0.460000
Person               0                 0.550000
                     1                 0.450000
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.533333  0.466667           15
                       Number               0.200000  0.800000            5
                       Other                0.200000  0.800000            5
                       Person               0.500000  0.500000            8
Geography              Date                 0.428571  0.571429            7
                       Number               0.357143  0.642857           14
                       Other                0.000000  1.000000            2
Misc                   Date                 0.285714  0.714286           14
                       Number               0.200000  0.800000            5
                       Other                0.750000  0.250000           12
                       Person               0.500000  0.500000            6
Music                  Date                 0.666667  0.333333            6
                       Number               0.333333  0.666667            3
                       Other                0.444444  0.555556            9
                       Person               0.500000  0.500000            2
Other                  Date                 0.400000  0.600000           10
                       Number               0.333333  0.666667            3
                       Other                0.500000  0.500000            4
                       Person               0.000000  1.000000            2
Politics               Date                 0.526316  0.473684           19
                       Number               0.000000  1.000000            3
                       Other                0.571429  0.428571            7
                       Person               0.500000  0.500000            6
Science and technology Date                 0.363636  0.636364           22
                       Number               0.363636  0.636364           11
                       Other                0.714286  0.285714            7
                       Person               0.615385  0.384615           13
Sports                 Date                 0.333333  0.666667            3
                       Number               0.714286  0.285714            7
                       Other                0.500000  0.500000            4
                       Person               1.000000  0.000000            3

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  237
Model:                          Logit   Df Residuals:                      225
Method:                           MLE   Df Model:                           11
Date:                Sun, 06 Jul 2025   Pseudo R-squ.:                 0.04009
Time:                        10:05:14   Log-Likelihood:                -156.96
converged:                       True   LL-Null:                       -163.51
Covariance Type:            nonrobust   LLR p-value:                    0.2862
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      3.6201      1.721      2.103      0.035       0.247       6.993
C(topic_grouped)[T.Geography]                 -0.0428      0.597     -0.072      0.943      -1.214       1.128
C(topic_grouped)[T.Misc]                      -0.0935      0.496     -0.189      0.850      -1.066       0.879
C(topic_grouped)[T.Music]                     -0.3283      0.591     -0.555      0.579      -1.487       0.831
C(topic_grouped)[T.Other]                      0.1417      0.607      0.233      0.815      -1.048       1.332
C(topic_grouped)[T.Politics]                  -0.0975      0.504     -0.194      0.847      -1.085       0.890
C(topic_grouped)[T.Science and technology]    -0.1997      0.458     -0.436      0.663      -1.098       0.698
C(topic_grouped)[T.Sports]                    -0.9916      0.648     -1.531      0.126      -2.261       0.278
C(answer_type_grouped)[T.Number]               0.4721      0.391      1.206      0.228      -0.295       1.239
C(answer_type_grouped)[T.Other]               -0.4371      0.367     -1.190      0.234      -1.157       0.283
C(answer_type_grouped)[T.Person]              -0.5443      0.396     -1.373      0.170      -1.321       0.233
q_length                                      -0.7092      0.368     -1.927      0.054      -1.431       0.012
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  237
Model:                          Logit   Df Residuals:                      224
Method:                           MLE   Df Model:                           12
Date:                Sun, 06 Jul 2025   Pseudo R-squ.:                 0.07637
Time:                        10:05:14   Log-Likelihood:                -151.03
converged:                       True   LL-Null:                       -163.51
Covariance Type:            nonrobust   LLR p-value:                   0.01495
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      2.7973      1.770      1.580      0.114      -0.672       6.267
C(topic_grouped)[T.Geography]                 -0.0709      0.609     -0.116      0.907      -1.265       1.123
C(topic_grouped)[T.Misc]                      -0.2271      0.510     -0.445      0.656      -1.228       0.773
C(topic_grouped)[T.Music]                     -0.2771      0.612     -0.453      0.651      -1.477       0.923
C(topic_grouped)[T.Other]                      0.2225      0.621      0.358      0.720      -0.994       1.439
C(topic_grouped)[T.Politics]                  -0.0407      0.517     -0.079      0.937      -1.055       0.973
C(topic_grouped)[T.Science and technology]    -0.2928      0.471     -0.622      0.534      -1.215       0.630
C(topic_grouped)[T.Sports]                    -0.8598      0.660     -1.302      0.193      -2.154       0.435
C(answer_type_grouped)[T.Number]               0.6627      0.403      1.643      0.100      -0.128       1.453
C(answer_type_grouped)[T.Other]               -0.2715      0.379     -0.716      0.474      -1.015       0.472
C(answer_type_grouped)[T.Person]              -0.2379      0.419     -0.568      0.570      -1.059       0.583
q_length                                      -0.6667      0.376     -1.774      0.076      -1.403       0.070
capabilities_entropy                           0.8654      0.259      3.343      0.001       0.358       1.373
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  237
Model:                          Logit   Df Residuals:                      224
Method:                           MLE   Df Model:                           12
Date:                Sun, 06 Jul 2025   Pseudo R-squ.:                 0.08841
Time:                        10:05:14   Log-Likelihood:                -149.06
converged:                       True   LL-Null:                       -163.51
Covariance Type:            nonrobust   LLR p-value:                  0.004060
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      3.1327      1.776      1.764      0.078      -0.349       6.614
C(topic_grouped)[T.Geography]                  0.1909      0.621      0.307      0.759      -1.026       1.408
C(topic_grouped)[T.Misc]                       0.0131      0.518      0.025      0.980      -1.002       1.029
C(topic_grouped)[T.Music]                     -0.0322      0.622     -0.052      0.959      -1.252       1.188
C(topic_grouped)[T.Other]                      0.4742      0.635      0.746      0.456      -0.771       1.720
C(topic_grouped)[T.Politics]                   0.2230      0.529      0.421      0.673      -0.814       1.260
C(topic_grouped)[T.Science and technology]    -0.0054      0.479     -0.011      0.991      -0.944       0.933
C(topic_grouped)[T.Sports]                    -1.0463      0.680     -1.539      0.124      -2.378       0.286
C(answer_type_grouped)[T.Number]               0.5685      0.404      1.406      0.160      -0.224       1.361
C(answer_type_grouped)[T.Other]               -0.4062      0.379     -1.071      0.284      -1.150       0.338
C(answer_type_grouped)[T.Person]              -0.1835      0.419     -0.439      0.661      -1.004       0.637
q_length                                      -0.7818      0.380     -2.059      0.040      -1.526      -0.037
game_entropy                                   1.3355      0.351      3.806      0.000       0.648       2.023
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  237
Model:                          Logit   Df Residuals:                      223
Method:                           MLE   Df Model:                           13
Date:                Sun, 06 Jul 2025   Pseudo R-squ.:                  0.1032
Time:                        10:05:14   Log-Likelihood:                -146.64
converged:                       True   LL-Null:                       -163.51
Covariance Type:            nonrobust   LLR p-value:                  0.001314
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      2.7105      1.806      1.500      0.133      -0.830       6.251
C(topic_grouped)[T.Geography]                  0.1175      0.627      0.188      0.851      -1.111       1.346
C(topic_grouped)[T.Misc]                      -0.1147      0.526     -0.218      0.827      -1.146       0.917
C(topic_grouped)[T.Music]                     -0.0595      0.637     -0.093      0.926      -1.308       1.189
C(topic_grouped)[T.Other]                      0.4306      0.639      0.674      0.500      -0.822       1.683
C(topic_grouped)[T.Politics]                   0.1887      0.534      0.353      0.724      -0.859       1.236
C(topic_grouped)[T.Science and technology]    -0.1243      0.487     -0.255      0.799      -1.080       0.831
C(topic_grouped)[T.Sports]                    -0.9521      0.681     -1.398      0.162      -2.287       0.383
C(answer_type_grouped)[T.Number]               0.6805      0.410      1.659      0.097      -0.123       1.484
C(answer_type_grouped)[T.Other]               -0.3053      0.387     -0.790      0.430      -1.063       0.452
C(answer_type_grouped)[T.Person]              -0.0485      0.430     -0.113      0.910      -0.891       0.794
q_length                                      -0.7463      0.385     -1.941      0.052      -1.500       0.007
capabilities_entropy                           0.6015      0.277      2.175      0.030       0.059       1.144
game_entropy                                   1.0740      0.371      2.893      0.004       0.346       1.802
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing gpt-4o-2024-08-06 (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/gpt-4o-2024-08-06_SimpleMC_redacted_cor_temp0.0_1751718574_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    219
1     34
Name: count, dtype: int64

Answer change%: 0.1344 [0.09236030966488987, 0.1764143938924224] (n=253)
P-value vs 25%: 6.98e-08; P-value vs 0%: 3.675e-10
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=34)
P-value vs 25%: 0; P-value vs 33%: 0

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  253
Model:                          Logit   Df Residuals:                      251
Method:                           MLE   Df Model:                            1
Date:                Sun, 06 Jul 2025   Pseudo R-squ.:                 0.05688
Time:                        10:05:14   Log-Likelihood:                -94.166
converged:                       True   LL-Null:                       -99.845
Covariance Type:            nonrobust   LLR p-value:                 0.0007512
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept         -0.5531      0.396     -1.396      0.163      -1.329       0.223
p_i_capability    -1.9053      0.556     -3.427      0.001      -2.995      -0.816
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  253
Model:                          Logit   Df Residuals:                      251
Method:                           MLE   Df Model:                            1
Date:                Sun, 06 Jul 2025   Pseudo R-squ.:                  0.2515
Time:                        10:05:14   Log-Likelihood:                -74.731
converged:                       True   LL-Null:                       -99.845
Covariance Type:            nonrobust   LLR p-value:                 1.370e-12
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -3.9837      0.518     -7.685      0.000      -5.000      -2.968
capabilities_entropy     2.2588      0.390      5.793      0.000       1.495       3.023
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.8182 [0.6866, 0.9498] (n=33)
                  P-value vs 33.3%: 5.147e-13

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=-1.01, p=0.313
Wilcoxon delta_p: statistic=9073.00, p=0.541
Mean p = -0.0086  [-0.0252, 0.0080]

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.610
Model:                            OLS   Adj. R-squared:                  0.605
Method:                 Least Squares   F-statistic:                     116.9
Date:                Sun, 06 Jul 2025   Prob (F-statistic):           1.36e-45
Time:                        10:05:14   Log-Likelihood:                 184.25
No. Observations:                 228   AIC:                            -360.5
Df Residuals:                     224   BIC:                            -346.8
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.2253      0.035     -6.419      0.000      -0.294      -0.156
p1                    0.2561      0.040      6.333      0.000       0.176       0.336
answer_changed       -0.1126      0.077     -1.459      0.146      -0.265       0.039
p1:answer_changed     0.8441      0.122      6.930      0.000       0.604       1.084
==============================================================================
Omnibus:                       20.031   Durbin-Watson:                   1.911
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               41.569
Skew:                           0.422   Prob(JB):                     9.40e-10
Kurtosis:                       4.914   Cond. No.                         26.1
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-0.07, p=0.945
Wilcoxon delta_H: statistic=9275.00, p=0.912
Mean H = -0.0023  [-0.0672, 0.0627]
Paired t-test delta_H Changed: statistic=4.98, p=2.12e-05
Wilcoxon delta_H Changed: statistic=61.00, p=2.48e-05
Mean H Changed = 0.3370  [0.2043, 0.4697]

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=12085.00, p=0.332
Paired t-test (game_entropy vs capabilities_entropy): statistic=-1.38, p=0.169
Mean capabilities_entropy-game_entropy = 0.0291  [-0.0122, 0.0704] (n=228)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  228
Model:                          Logit   Df Residuals:                      225
Method:                           MLE   Df Model:                            2
Date:                Sun, 06 Jul 2025   Pseudo R-squ.:                  0.2483
Time:                        10:05:14   Log-Likelihood:                -70.860
converged:                       True   LL-Null:                       -94.271
Covariance Type:            nonrobust   LLR p-value:                 6.803e-11
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -2.1998      0.333     -6.602      0.000      -2.853      -1.547
p1_z            -1.8008      0.445     -4.048      0.000      -2.673      -0.929
I(p1_z ** 2)    -0.3882      0.277     -1.402      0.161      -0.931       0.155
================================================================================
AUC = 0.849

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  253
Model:                          Logit   Df Residuals:                      251
Method:                           MLE   Df Model:                            1
Date:                Sun, 06 Jul 2025   Pseudo R-squ.:                  0.2274
Time:                        10:05:14   Log-Likelihood:                -77.135
converged:                       True   LL-Null:                       -99.845
Covariance Type:            nonrobust   LLR p-value:                 1.591e-11
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -3.7950      0.481     -7.894      0.000      -4.737      -2.853
game_entropy     2.2341      0.390      5.727      0.000       1.470       2.999
================================================================================

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  253
Model:                          Logit   Df Residuals:                      250
Method:                           MLE   Df Model:                            2
Date:                Sun, 06 Jul 2025   Pseudo R-squ.:                  0.2606
Time:                        10:05:14   Log-Likelihood:                -73.830
converged:                       True   LL-Null:                       -99.845
Covariance Type:            nonrobust   LLR p-value:                 5.034e-12
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -4.1192      0.542     -7.603      0.000      -5.181      -3.057
capabilities_entropy     1.5756      0.632      2.492      0.013       0.336       2.815
game_entropy             0.8805      0.659      1.336      0.181      -0.411       2.172
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': None
topic_grouped           answer_changed
Art                     0                 0.880952
                        1                 0.119048
Geography               0                 0.863636
                        1                 0.136364
Misc                    0                 0.761905
                        1                 0.238095
Music                   0                 0.850000
                        1                 0.150000
Other                   0                 0.925926
                        1                 0.074074
Politics                0                 0.897436
                        1                 0.102564
Science and technology  0                 0.863636
                        1                 0.136364
Sports                  0                 0.857143
                        1                 0.142857
TV shows                0                 0.823529
                        1                 0.176471
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.824324
                     1                 0.175676
Number               0                 0.756757
                     1                 0.243243
Other                0                 0.933333
                     1                 0.066667
Person               0                 0.906250
                     1                 0.093750
Place                0                 0.888889
                     1                 0.111111
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.500000  0.500000            6
                       Number               0.714286  0.285714            7
                       Other                1.000000  0.000000            6
                       Person               1.000000  0.000000           19
                       Place                1.000000  0.000000            4
Geography              Date                 0.833333  0.166667            6
                       Number               0.750000  0.250000            8
                       Other                1.000000  0.000000            3
                       Place                1.000000  0.000000            5
Misc                   Date                 0.636364  0.363636           11
                       Number               0.666667  0.333333            3
                       Other                1.000000  0.000000            3
                       Person               1.000000  0.000000            2
                       Place                1.000000  0.000000            2
Music                  Date                 1.000000  0.000000            4
                       Number               1.000000  0.000000            2
                       Other                0.750000  0.250000            4
                       Person               0.800000  0.200000           10
Other                  Date                 0.900000  0.100000           10
                       Number               1.000000  0.000000            3
                       Other                1.000000  0.000000            4
                       Person               1.000000  0.000000            7
                       Place                0.666667  0.333333            3
Politics               Date                 0.800000  0.200000           15
                       Number               1.000000  0.000000            5
                       Other                1.000000  0.000000           11
                       Person               0.833333  0.166667            6
                       Place                1.000000  0.000000            2
Science and technology Date                 0.941176  0.058824           17
                       Number               0.428571  0.571429            7
                       Other                1.000000  0.000000           10
                       Person               0.900000  0.100000           10
Sports                 Date                 1.000000  0.000000            4
                       Number               1.000000  0.000000            1
                       Other                0.750000  0.250000            8
                       Person               1.000000  0.000000            6
                       Place                0.500000  0.500000            2
TV shows               Date                 1.000000  0.000000            1
                       Number               1.000000  0.000000            1
                       Other                0.909091  0.090909           11
                       Person               0.500000  0.500000            4

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  253
Model:                          Logit   Df Residuals:                      239
Method:                           MLE   Df Model:                           13
Date:                Sun, 06 Jul 2025   Pseudo R-squ.:                 0.06442
Time:                        10:05:14   Log-Likelihood:                -93.413
converged:                       True   LL-Null:                       -99.845
Covariance Type:            nonrobust   LLR p-value:                    0.4584
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.7654      2.337     -0.756      0.450      -6.345       2.814
C(topic_grouped)[T.Geography]                 -0.2411      0.819     -0.294      0.769      -1.847       1.365
C(topic_grouped)[T.Misc]                       0.6025      0.738      0.817      0.414      -0.844       2.049
C(topic_grouped)[T.Music]                      0.3899      0.812      0.480      0.631      -1.202       1.982
C(topic_grouped)[T.Other]                     -0.6444      0.896     -0.719      0.472      -2.401       1.112
C(topic_grouped)[T.Politics]                  -0.2725      0.752     -0.362      0.717      -1.747       1.202
C(topic_grouped)[T.Science and technology]     0.0183      0.685      0.027      0.979      -1.324       1.361
C(topic_grouped)[T.Sports]                     0.4684      0.817      0.573      0.567      -1.134       2.070
C(topic_grouped)[T.TV shows]                   1.0253      0.872      1.176      0.239      -0.683       2.733
C(answer_type_grouped)[T.Number]               0.4512      0.512      0.881      0.378      -0.552       1.455
C(answer_type_grouped)[T.Other]               -1.3599      0.659     -2.062      0.039      -2.652      -0.067
C(answer_type_grouped)[T.Person]              -0.8353      0.567     -1.473      0.141      -1.947       0.276
C(answer_type_grouped)[T.Place]               -0.4599      0.840     -0.548      0.584      -2.106       1.186
q_length                                       0.0383      0.502      0.076      0.939      -0.946       1.023
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  253
Model:                          Logit   Df Residuals:                      238
Method:                           MLE   Df Model:                           14
Date:                Sun, 06 Jul 2025   Pseudo R-squ.:                  0.3082
Time:                        10:05:14   Log-Likelihood:                -69.076
converged:                       True   LL-Null:                       -99.845
Covariance Type:            nonrobust   LLR p-value:                 6.296e-08
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -6.5944      3.086     -2.137      0.033     -12.643      -0.546
C(topic_grouped)[T.Geography]                 -0.0463      0.905     -0.051      0.959      -1.821       1.728
C(topic_grouped)[T.Misc]                       1.6452      0.880      1.870      0.062      -0.080       3.370
C(topic_grouped)[T.Music]                      1.2979      0.998      1.301      0.193      -0.658       3.254
C(topic_grouped)[T.Other]                     -0.8084      0.984     -0.821      0.411      -2.737       1.121
C(topic_grouped)[T.Politics]                   0.1784      0.871      0.205      0.838      -1.528       1.885
C(topic_grouped)[T.Science and technology]     0.5194      0.806      0.645      0.519      -1.060       2.099
C(topic_grouped)[T.Sports]                     0.9907      0.974      1.017      0.309      -0.919       2.900
C(topic_grouped)[T.TV shows]                   1.4959      1.127      1.327      0.184      -0.713       3.705
C(answer_type_grouped)[T.Number]               0.1942      0.582      0.334      0.739      -0.946       1.335
C(answer_type_grouped)[T.Other]               -0.5622      0.831     -0.676      0.499      -2.191       1.067
C(answer_type_grouped)[T.Person]               0.6822      0.733      0.931      0.352      -0.754       2.118
C(answer_type_grouped)[T.Place]                0.0493      0.999      0.049      0.961      -1.909       2.007
q_length                                       0.3443      0.641      0.537      0.591      -0.913       1.601
capabilities_entropy                           2.6796      0.489      5.484      0.000       1.722       3.637
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  253
Model:                          Logit   Df Residuals:                      238
Method:                           MLE   Df Model:                           14
Date:                Sun, 06 Jul 2025   Pseudo R-squ.:                  0.2721
Time:                        10:05:14   Log-Likelihood:                -72.676
converged:                       True   LL-Null:                       -99.845
Covariance Type:            nonrobust   LLR p-value:                 1.125e-06
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -4.0180      2.775     -1.448      0.148      -9.456       1.420
C(topic_grouped)[T.Geography]                 -0.4800      0.904     -0.531      0.596      -2.252       1.292
C(topic_grouped)[T.Misc]                       0.9467      0.854      1.108      0.268      -0.728       2.621
C(topic_grouped)[T.Music]                      0.5839      0.969      0.603      0.547      -1.315       2.483
C(topic_grouped)[T.Other]                     -1.2566      0.971     -1.294      0.196      -3.160       0.647
C(topic_grouped)[T.Politics]                  -0.1779      0.829     -0.215      0.830      -1.802       1.446
C(topic_grouped)[T.Science and technology]    -0.0469      0.779     -0.060      0.952      -1.573       1.479
C(topic_grouped)[T.Sports]                     0.8533      0.916      0.932      0.351      -0.941       2.648
C(topic_grouped)[T.TV shows]                   0.7573      1.054      0.719      0.472      -1.308       2.822
C(answer_type_grouped)[T.Number]              -0.0751      0.577     -0.130      0.896      -1.206       1.056
C(answer_type_grouped)[T.Other]               -0.6686      0.795     -0.841      0.400      -2.227       0.890
C(answer_type_grouped)[T.Person]               0.0059      0.670      0.009      0.993      -1.308       1.319
C(answer_type_grouped)[T.Place]               -0.5396      0.954     -0.565      0.572      -2.410       1.331
q_length                                       0.0226      0.601      0.038      0.970      -1.155       1.201
game_entropy                                   2.4382      0.444      5.487      0.000       1.567       3.309
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  253
Model:                          Logit   Df Residuals:                      237
Method:                           MLE   Df Model:                           15
Date:                Sun, 06 Jul 2025   Pseudo R-squ.:                  0.3167
Time:                        10:05:14   Log-Likelihood:                -68.219
converged:                       True   LL-Null:                       -99.845
Covariance Type:            nonrobust   LLR p-value:                 6.905e-08
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -6.1587      3.074     -2.004      0.045     -12.183      -0.134
C(topic_grouped)[T.Geography]                 -0.2080      0.916     -0.227      0.820      -2.004       1.588
C(topic_grouped)[T.Misc]                       1.4747      0.891      1.655      0.098      -0.272       3.221
C(topic_grouped)[T.Music]                      1.1699      1.030      1.136      0.256      -0.848       3.188
C(topic_grouped)[T.Other]                     -1.0534      1.001     -1.052      0.293      -3.015       0.909
C(topic_grouped)[T.Politics]                   0.0481      0.869      0.055      0.956      -1.655       1.752
C(topic_grouped)[T.Science and technology]     0.3351      0.816      0.411      0.681      -1.264       1.935
C(topic_grouped)[T.Sports]                     0.9890      0.973      1.017      0.309      -0.917       2.895
C(topic_grouped)[T.TV shows]                   1.2071      1.133      1.065      0.287      -1.014       3.428
C(answer_type_grouped)[T.Number]               0.0484      0.594      0.081      0.935      -1.117       1.213
C(answer_type_grouped)[T.Other]               -0.5466      0.840     -0.651      0.515      -2.193       1.099
C(answer_type_grouped)[T.Person]               0.5918      0.732      0.809      0.419      -0.842       2.026
C(answer_type_grouped)[T.Place]               -0.1178      1.010     -0.117      0.907      -2.097       1.861
q_length                                       0.2586      0.643      0.402      0.687      -1.001       1.518
capabilities_entropy                           1.9996      0.703      2.843      0.004       0.621       3.378
game_entropy                                   0.8891      0.683      1.302      0.193      -0.449       2.227
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing gpt-4o-2024-08-06 (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/gpt-4o-2024-08-06_SimpleMC_redacted_temp0.0_1751721962_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    161
1     86
Name: count, dtype: int64

Answer change%: 0.3482 [0.2887674164022944, 0.4075888589013493] (n=247)
P-value vs 25%: 0.0012; P-value vs 0%: 1.544e-30
Phase 2 self-accuracy: 0.5349 [0.42946704305053107, 0.640300398809934] (n=86)
P-value vs 25%: 1.179e-07; P-value vs 33%: 0.0001744

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  247
Model:                          Logit   Df Residuals:                      245
Method:                           MLE   Df Model:                            1
Date:                Sun, 06 Jul 2025   Pseudo R-squ.:                 0.09470
Time:                        10:05:14   Log-Likelihood:                -144.52
converged:                       True   LL-Null:                       -159.64
Covariance Type:            nonrobust   LLR p-value:                 3.824e-08
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          1.8397      0.494      3.724      0.000       0.872       2.808
p_i_capability    -3.7765      0.748     -5.049      0.000      -5.242      -2.311
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  247
Model:                          Logit   Df Residuals:                      245
Method:                           MLE   Df Model:                            1
Date:                Sun, 06 Jul 2025   Pseudo R-squ.:                  0.1232
Time:                        10:05:14   Log-Likelihood:                -139.98
converged:                       True   LL-Null:                       -159.64
Covariance Type:            nonrobust   LLR p-value:                 3.584e-10
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.6007      0.410     -6.345      0.000      -3.404      -1.797
capabilities_entropy     1.7299      0.313      5.525      0.000       1.116       2.344
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.6977 [0.6006, 0.7947] (n=86)
                  P-value vs 33.3%: 1.883e-13

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=-2.21, p=0.0283
Wilcoxon delta_p: statistic=5004.00, p=0.0477
Mean p = -0.0284  [-0.0536, -0.0033]

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.740
Model:                            OLS   Adj. R-squared:                  0.736
Method:                 Least Squares   F-statistic:                     225.4
Date:                Sun, 06 Jul 2025   Prob (F-statistic):           2.97e-69
Time:                        10:05:14   Log-Likelihood:                 138.67
No. Observations:                 242   AIC:                            -269.3
Df Residuals:                     238   BIC:                            -255.4
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.3257      0.044     -7.349      0.000      -0.413      -0.238
p1                    0.4022      0.058      6.925      0.000       0.288       0.517
answer_changed        0.1449      0.069      2.092      0.037       0.008       0.281
p1:answer_changed     0.5805      0.106      5.486      0.000       0.372       0.789
==============================================================================
Omnibus:                        0.442   Durbin-Watson:                   2.150
Prob(Omnibus):                  0.802   Jarque-Bera (JB):                0.220
Skew:                           0.037   Prob(JB):                        0.896
Kurtosis:                       3.128   Cond. No.                         19.5
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=2.41, p=0.0173
Wilcoxon delta_H: statistic=4767.00, p=0.0164
Mean H = 0.0806  [0.0149, 0.1462]
Paired t-test delta_H Changed: statistic=6.47, p=5.87e-09
Wilcoxon delta_H Changed: statistic=585.00, p=3.11e-08
Mean H Changed = 0.2825  [0.1970, 0.3681]

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=9815.00, p=7.38e-06
Paired t-test (game_entropy vs capabilities_entropy): statistic=-4.26, p=2.97e-05
Mean capabilities_entropy-game_entropy = 0.1134  [0.0612, 0.1656] (n=242)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  242
Model:                          Logit   Df Residuals:                      239
Method:                           MLE   Df Model:                            2
Date:                Sun, 06 Jul 2025   Pseudo R-squ.:                  0.1263
Time:                        10:05:14   Log-Likelihood:                -137.58
converged:                       True   LL-Null:                       -157.47
Covariance Type:            nonrobust   LLR p-value:                 2.295e-09
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.7708      0.215     -3.580      0.000      -1.193      -0.349
p1_z            -0.9374      0.164     -5.709      0.000      -1.259      -0.616
I(p1_z ** 2)     0.0543      0.179      0.303      0.762      -0.297       0.406
================================================================================
AUC = 0.734

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  247
Model:                          Logit   Df Residuals:                      245
Method:                           MLE   Df Model:                            1
Date:                Sun, 06 Jul 2025   Pseudo R-squ.:                 0.08111
Time:                        10:05:14   Log-Likelihood:                -146.69
converged:                       True   LL-Null:                       -159.64
Covariance Type:            nonrobust   LLR p-value:                 3.604e-07
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.9655      0.330     -5.953      0.000      -2.613      -1.318
game_entropy     1.3294      0.280      4.754      0.000       0.781       1.877
================================================================================

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  247
Model:                          Logit   Df Residuals:                      244
Method:                           MLE   Df Model:                            2
Date:                Sun, 06 Jul 2025   Pseudo R-squ.:                  0.1259
Time:                        10:05:14   Log-Likelihood:                -139.54
converged:                       True   LL-Null:                       -159.64
Covariance Type:            nonrobust   LLR p-value:                 1.865e-09
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.6703      0.418     -6.393      0.000      -3.489      -1.852
capabilities_entropy     1.4775      0.410      3.606      0.000       0.675       2.280
game_entropy             0.3544      0.380      0.933      0.351      -0.390       1.099
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['History', 'TV shows', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.545455
                        1                 0.454545
Geography               0                 0.590909
                        1                 0.409091
Misc                    0                 0.555556
                        1                 0.444444
Music                   0                 0.850000
                        1                 0.150000
Other                   0                 0.760000
                        1                 0.240000
Politics                0                 0.605263
                        1                 0.394737
Science and technology  0                 0.685185
                        1                 0.314815
Sports                  0                 0.736842
                        1                 0.263158
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.578947
                     1                 0.421053
Number               0                 0.756098
                     1                 0.243902
Other                0                 0.709091
                     1                 0.290909
Person               0                 0.642857
                     1                 0.357143
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.466667  0.533333           15
                       Number               1.000000  0.000000            2
                       Other                0.750000  0.250000            8
                       Person               0.375000  0.625000            8
Geography              Date                 0.444444  0.555556            9
                       Number               0.700000  0.300000           10
                       Other                0.666667  0.333333            3
Misc                   Date                 0.727273  0.272727           11
                       Number               0.600000  0.400000            5
                       Other                0.636364  0.363636           11
                       Person               0.222222  0.777778            9
Music                  Date                 0.875000  0.125000            8
                       Number               1.000000  0.000000            2
                       Other                0.875000  0.125000            8
                       Person               0.500000  0.500000            2
Other                  Date                 0.750000  0.250000            8
                       Number               1.000000  0.000000            4
                       Other                0.714286  0.285714            7
                       Person               0.666667  0.333333            6
Politics               Date                 0.523810  0.476190           21
                       Number               1.000000  0.000000            1
                       Other                0.714286  0.285714            7
                       Person               0.666667  0.333333            9
Science and technology Date                 0.555556  0.444444           18
                       Number               0.571429  0.428571            7
                       Other                0.555556  0.444444            9
                       Person               0.900000  0.100000           20
Sports                 Date                 0.400000  0.600000            5
                       Number               0.800000  0.200000           10
                       Other                1.000000  0.000000            2
                       Person               1.000000  0.000000            2

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  247
Model:                          Logit   Df Residuals:                      235
Method:                           MLE   Df Model:                           11
Date:                Sun, 06 Jul 2025   Pseudo R-squ.:                 0.04703
Time:                        10:05:14   Log-Likelihood:                -152.13
converged:                       True   LL-Null:                       -159.64
Covariance Type:            nonrobust   LLR p-value:                    0.1817
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      1.3918      1.804      0.771      0.440      -2.144       4.928
C(topic_grouped)[T.Geography]                 -0.0053      0.591     -0.009      0.993      -1.164       1.154
C(topic_grouped)[T.Misc]                       0.0929      0.493      0.188      0.851      -0.874       1.060
C(topic_grouped)[T.Music]                     -1.5194      0.724     -2.098      0.036      -2.939      -0.100
C(topic_grouped)[T.Other]                     -0.9044      0.590     -1.532      0.125      -2.061       0.252
C(topic_grouped)[T.Politics]                  -0.2483      0.494     -0.503      0.615      -1.216       0.719
C(topic_grouped)[T.Science and technology]    -0.5480      0.463     -1.183      0.237      -1.456       0.360
C(topic_grouped)[T.Sports]                    -0.5546      0.661     -0.839      0.401      -1.850       0.741
C(answer_type_grouped)[T.Number]              -0.8194      0.454     -1.805      0.071      -1.709       0.070
C(answer_type_grouped)[T.Other]               -0.5586      0.377     -1.482      0.138      -1.298       0.180
C(answer_type_grouped)[T.Person]              -0.2978      0.367     -0.812      0.417      -1.016       0.421
q_length                                      -0.2966      0.392     -0.757      0.449      -1.065       0.471
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  247
Model:                          Logit   Df Residuals:                      234
Method:                           MLE   Df Model:                           12
Date:                Sun, 06 Jul 2025   Pseudo R-squ.:                  0.1709
Time:                        10:05:14   Log-Likelihood:                -132.36
converged:                       True   LL-Null:                       -159.64
Covariance Type:            nonrobust   LLR p-value:                 2.180e-07
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -0.8592      1.993     -0.431      0.666      -4.766       3.047
C(topic_grouped)[T.Geography]                 -0.1904      0.661     -0.288      0.773      -1.487       1.106
C(topic_grouped)[T.Misc]                      -0.2708      0.541     -0.501      0.616      -1.330       0.789
C(topic_grouped)[T.Music]                     -1.8263      0.780     -2.342      0.019      -3.355      -0.298
C(topic_grouped)[T.Other]                     -0.9398      0.637     -1.475      0.140      -2.189       0.309
C(topic_grouped)[T.Politics]                  -0.5345      0.549     -0.973      0.330      -1.611       0.542
C(topic_grouped)[T.Science and technology]    -0.8244      0.515     -1.602      0.109      -1.833       0.184
C(topic_grouped)[T.Sports]                    -0.7095      0.714     -0.994      0.320      -2.109       0.690
C(answer_type_grouped)[T.Number]              -0.7721      0.486     -1.587      0.112      -1.725       0.181
C(answer_type_grouped)[T.Other]               -0.1218      0.415     -0.294      0.769      -0.935       0.692
C(answer_type_grouped)[T.Person]               0.4048      0.423      0.956      0.339      -0.425       1.235
q_length                                      -0.2891      0.424     -0.683      0.495      -1.119       0.541
capabilities_entropy                           1.9033      0.347      5.485      0.000       1.223       2.583
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  247
Model:                          Logit   Df Residuals:                      234
Method:                           MLE   Df Model:                           12
Date:                Sun, 06 Jul 2025   Pseudo R-squ.:                  0.1393
Time:                        10:05:14   Log-Likelihood:                -137.40
converged:                       True   LL-Null:                       -159.64
Covariance Type:            nonrobust   LLR p-value:                 1.265e-05
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -0.9182      1.961     -0.468      0.640      -4.761       2.925
C(topic_grouped)[T.Geography]                  0.0454      0.636      0.071      0.943      -1.202       1.293
C(topic_grouped)[T.Misc]                       0.0599      0.527      0.114      0.909      -0.973       1.093
C(topic_grouped)[T.Music]                     -1.7426      0.764     -2.282      0.023      -3.239      -0.246
C(topic_grouped)[T.Other]                     -0.9950      0.623     -1.596      0.110      -2.217       0.227
C(topic_grouped)[T.Politics]                  -0.2130      0.528     -0.403      0.687      -1.248       0.822
C(topic_grouped)[T.Science and technology]    -0.6657      0.501     -1.330      0.184      -1.647       0.316
C(topic_grouped)[T.Sports]                    -0.3832      0.699     -0.548      0.583      -1.753       0.986
C(answer_type_grouped)[T.Number]              -0.9708      0.482     -2.014      0.044      -1.915      -0.026
C(answer_type_grouped)[T.Other]               -0.4692      0.403     -1.163      0.245      -1.260       0.321
C(answer_type_grouped)[T.Person]               0.2390      0.407      0.587      0.557      -0.559       1.037
q_length                                      -0.1476      0.415     -0.356      0.722      -0.960       0.665
game_entropy                                   1.5427      0.309      4.992      0.000       0.937       2.148
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  247
Model:                          Logit   Df Residuals:                      233
Method:                           MLE   Df Model:                           13
Date:                Sun, 06 Jul 2025   Pseudo R-squ.:                  0.1776
Time:                        10:05:14   Log-Likelihood:                -131.29
converged:                       True   LL-Null:                       -159.64
Covariance Type:            nonrobust   LLR p-value:                 2.035e-07
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.2375      2.016     -0.614      0.539      -5.189       2.714
C(topic_grouped)[T.Geography]                 -0.1461      0.665     -0.220      0.826      -1.449       1.157
C(topic_grouped)[T.Misc]                      -0.2138      0.544     -0.393      0.694      -1.280       0.852
C(topic_grouped)[T.Music]                     -1.8331      0.782     -2.345      0.019      -3.365      -0.301
C(topic_grouped)[T.Other]                     -0.9939      0.639     -1.555      0.120      -2.247       0.259
C(topic_grouped)[T.Politics]                  -0.4696      0.551     -0.853      0.394      -1.549       0.609
C(topic_grouped)[T.Science and technology]    -0.8315      0.517     -1.607      0.108      -1.846       0.183
C(topic_grouped)[T.Sports]                    -0.6302      0.718     -0.877      0.380      -2.038       0.778
C(answer_type_grouped)[T.Number]              -0.8451      0.492     -1.717      0.086      -1.810       0.120
C(answer_type_grouped)[T.Other]               -0.1931      0.421     -0.458      0.647      -1.018       0.632
C(answer_type_grouped)[T.Person]               0.4660      0.428      1.089      0.276      -0.372       1.304
q_length                                      -0.2348      0.426     -0.551      0.582      -1.070       0.601
capabilities_entropy                           1.4852      0.444      3.347      0.001       0.616       2.355
game_entropy                                   0.5954      0.409      1.456      0.145      -0.206       1.397
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing grok-3-latest (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/grok-3-latest_SimpleMC_redacted_cor_temp0.0_1751718904_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    239
1     56
Name: count, dtype: int64

Answer change%: 0.1898 [0.1450789637260746, 0.23458205322307796] (n=295)
P-value vs 25%: 0.008408; P-value vs 0%: 9.259e-17
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=56)
P-value vs 25%: 0; P-value vs 33%: 0

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  295
Model:                          Logit   Df Residuals:                      293
Method:                           MLE   Df Model:                            1
Date:                Sun, 06 Jul 2025   Pseudo R-squ.:                 0.04532
Time:                        10:05:14   Log-Likelihood:                -136.87
converged:                       True   LL-Null:                       -143.36
Covariance Type:            nonrobust   LLR p-value:                 0.0003122
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          1.0602      0.709      1.495      0.135      -0.330       2.450
p_i_capability    -2.8200      0.790     -3.568      0.000      -4.369      -1.271
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  295
Model:                          Logit   Df Residuals:                      293
Method:                           MLE   Df Model:                            1
Date:                Sun, 06 Jul 2025   Pseudo R-squ.:                  0.1139
Time:                        10:05:14   Log-Likelihood:                -127.04
converged:                       True   LL-Null:                       -143.36
Covariance Type:            nonrobust   LLR p-value:                 1.105e-08
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.1461      0.217     -9.868      0.000      -2.572      -1.720
capabilities_entropy     1.8634      0.335      5.563      0.000       1.207       2.520
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.6071 [0.4792, 0.7351] (n=56)
                  P-value vs 33.3%: 2.723e-05

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=2.25, p=0.0251
Wilcoxon delta_p: statistic=8867.00, p=1.1e-06
Mean p = 0.0216  [0.0028, 0.0403]

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.809
Model:                            OLS   Adj. R-squared:                  0.807
Method:                 Least Squares   F-statistic:                     405.3
Date:                Sun, 06 Jul 2025   Prob (F-statistic):          5.22e-103
Time:                        10:05:14   Log-Likelihood:                 188.02
No. Observations:                 292   AIC:                            -368.0
Df Residuals:                     288   BIC:                            -353.3
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.5177      0.065     -8.004      0.000      -0.645      -0.390
p1                    0.5725      0.068      8.408      0.000       0.438       0.707
answer_changed        0.5053      0.107      4.729      0.000       0.295       0.716
p1:answer_changed     0.2204      0.121      1.820      0.070      -0.018       0.459
==============================================================================
Omnibus:                      113.981   Durbin-Watson:                   2.070
Prob(Omnibus):                  0.000   Jarque-Bera (JB):              366.918
Skew:                           1.740   Prob(JB):                     2.11e-80
Kurtosis:                       7.248   Cond. No.                         31.8
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-6.47, p=5.52e-10
Wilcoxon delta_H: statistic=7546.00, p=8.74e-10
Mean H = -0.2331  [-0.3037, -0.1625]
Paired t-test delta_H Changed: statistic=0.20, p=0.844
Wilcoxon delta_H Changed: statistic=760.00, p=0.757
Mean H Changed = 0.0133  [-0.1180, 0.1446]

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=11091.00, p=9.96e-13
Paired t-test (game_entropy vs capabilities_entropy): statistic=5.81, p=1.65e-08
Mean capabilities_entropy-game_entropy = -0.1634  [-0.2185, -0.1082] (n=292)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  292
Model:                          Logit   Df Residuals:                      289
Method:                           MLE   Df Model:                            2
Date:                Sun, 06 Jul 2025   Pseudo R-squ.:                  0.1172
Time:                        10:05:14   Log-Likelihood:                -126.00
converged:                       True   LL-Null:                       -142.73
Covariance Type:            nonrobust   LLR p-value:                 5.414e-08
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.2012      0.196     -6.131      0.000      -1.585      -0.817
p1_z            -1.5249      0.314     -4.855      0.000      -2.141      -0.909
I(p1_z ** 2)    -0.4255      0.137     -3.108      0.002      -0.694      -0.157
================================================================================
AUC = 0.777

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  295
Model:                          Logit   Df Residuals:                      293
Method:                           MLE   Df Model:                            1
Date:                Sun, 06 Jul 2025   Pseudo R-squ.:                  0.2834
Time:                        10:05:14   Log-Likelihood:                -102.73
converged:                       True   LL-Null:                       -143.36
Covariance Type:            nonrobust   LLR p-value:                 1.976e-19
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -3.2033      0.333     -9.614      0.000      -3.856      -2.550
game_entropy     2.7416      0.353      7.761      0.000       2.049       3.434
================================================================================

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  295
Model:                          Logit   Df Residuals:                      292
Method:                           MLE   Df Model:                            2
Date:                Sun, 06 Jul 2025   Pseudo R-squ.:                  0.3008
Time:                        10:05:14   Log-Likelihood:                -100.24
converged:                       True   LL-Null:                       -143.36
Covariance Type:            nonrobust   LLR p-value:                 1.878e-19
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -3.3861      0.356     -9.510      0.000      -4.084      -2.688
capabilities_entropy     0.9021      0.402      2.243      0.025       0.114       1.690
game_entropy             2.4695      0.372      6.646      0.000       1.741       3.198
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['Other', 'Sports', 'Music', 'Geography', 'History', 'TV shows', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.875000
                        1                 0.125000
Misc                    0                 0.768212
                        1                 0.231788
Politics                0                 0.833333
                        1                 0.166667
Science and technology  0                 0.854167
                        1                 0.145833
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.811881
                     1                 0.188119
Number               0                 0.700000
                     1                 0.300000
Other                0                 0.857143
                     1                 0.142857
Person               0                 0.809524
                     1                 0.190476
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.714286  0.285714           14
                       Number               1.000000  0.000000            5
                       Other                0.923077  0.076923           13
                       Person               0.937500  0.062500           16
Misc                   Date                 0.782609  0.217391           46
                       Number               0.692308  0.307692           26
                       Other                0.803922  0.196078           51
                       Person               0.750000  0.250000           28
Politics               Date                 0.900000  0.100000           20
                       Number               0.500000  0.500000            4
                       Other                0.923077  0.076923           13
                       Person               0.727273  0.272727           11
Science and technology Date                 0.857143  0.142857           21
                       Number               0.600000  0.400000            5
                       Other                0.928571  0.071429           14
                       Person               0.875000  0.125000            8

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  295
Model:                          Logit   Df Residuals:                      287
Method:                           MLE   Df Model:                            7
Date:                Sun, 06 Jul 2025   Pseudo R-squ.:                 0.02877
Time:                        10:05:14   Log-Likelihood:                -139.24
converged:                       True   LL-Null:                       -143.36
Covariance Type:            nonrobust   LLR p-value:                    0.3111
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -3.1743      1.971     -1.611      0.107      -7.037       0.689
C(topic_grouped)[T.Misc]                       0.7405      0.484      1.531      0.126      -0.208       1.689
C(topic_grouped)[T.Politics]                   0.2887      0.599      0.482      0.630      -0.886       1.463
C(topic_grouped)[T.Science and technology]     0.1590      0.608      0.262      0.794      -1.032       1.350
C(answer_type_grouped)[T.Number]               0.5048      0.438      1.153      0.249      -0.353       1.363
C(answer_type_grouped)[T.Other]               -0.3776      0.397     -0.951      0.342      -1.156       0.401
C(answer_type_grouped)[T.Person]               0.0321      0.416      0.077      0.939      -0.783       0.848
q_length                                       0.2799      0.431      0.649      0.516      -0.565       1.125
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  295
Model:                          Logit   Df Residuals:                      286
Method:                           MLE   Df Model:                            8
Date:                Sun, 06 Jul 2025   Pseudo R-squ.:                  0.1426
Time:                        10:05:14   Log-Likelihood:                -122.92
converged:                       True   LL-Null:                       -143.36
Covariance Type:            nonrobust   LLR p-value:                 2.181e-06
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -4.7818      2.136     -2.239      0.025      -8.968      -0.595
C(topic_grouped)[T.Misc]                       0.4999      0.518      0.966      0.334      -0.515       1.515
C(topic_grouped)[T.Politics]                   0.2532      0.630      0.402      0.688      -0.981       1.487
C(topic_grouped)[T.Science and technology]    -0.0525      0.641     -0.082      0.935      -1.309       1.204
C(answer_type_grouped)[T.Number]               0.2995      0.465      0.644      0.520      -0.612       1.211
C(answer_type_grouped)[T.Other]               -0.7288      0.439     -1.660      0.097      -1.589       0.132
C(answer_type_grouped)[T.Person]              -0.1966      0.447     -0.440      0.660      -1.072       0.679
q_length                                       0.5509      0.463      1.189      0.235      -0.357       1.459
capabilities_entropy                           1.9587      0.356      5.500      0.000       1.261       2.657
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  295
Model:                          Logit   Df Residuals:                      286
Method:                           MLE   Df Model:                            8
Date:                Sun, 06 Jul 2025   Pseudo R-squ.:                  0.2974
Time:                        10:05:14   Log-Likelihood:                -100.72
converged:                       True   LL-Null:                       -143.36
Covariance Type:            nonrobust   LLR p-value:                 4.199e-15
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -3.3399      2.382     -1.402      0.161      -8.009       1.329
C(topic_grouped)[T.Misc]                       0.7105      0.572      1.241      0.215      -0.411       1.832
C(topic_grouped)[T.Politics]                   0.7880      0.713      1.106      0.269      -0.609       2.185
C(topic_grouped)[T.Science and technology]     0.4657      0.710      0.656      0.512      -0.927       1.858
C(answer_type_grouped)[T.Number]               0.1932      0.535      0.361      0.718      -0.856       1.242
C(answer_type_grouped)[T.Other]               -0.5559      0.470     -1.183      0.237      -1.477       0.365
C(answer_type_grouped)[T.Person]              -0.2072      0.502     -0.413      0.680      -1.191       0.777
q_length                                      -0.0624      0.525     -0.119      0.905      -1.091       0.966
game_entropy                                   2.7447      0.363      7.564      0.000       2.033       3.456
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  295
Model:                          Logit   Df Residuals:                      285
Method:                           MLE   Df Model:                            9
Date:                Sun, 06 Jul 2025   Pseudo R-squ.:                  0.3171
Time:                        10:05:14   Log-Likelihood:                -97.904
converged:                       True   LL-Null:                       -143.36
Covariance Type:            nonrobust   LLR p-value:                 1.065e-15
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -4.2451      2.427     -1.749      0.080      -9.002       0.512
C(topic_grouped)[T.Misc]                       0.5698      0.585      0.974      0.330      -0.576       1.716
C(topic_grouped)[T.Politics]                   0.6826      0.713      0.957      0.339      -0.715       2.080
C(topic_grouped)[T.Science and technology]     0.3120      0.724      0.431      0.667      -1.107       1.731
C(answer_type_grouped)[T.Number]               0.1786      0.535      0.334      0.738      -0.870       1.227
C(answer_type_grouped)[T.Other]               -0.7157      0.491     -1.457      0.145      -1.678       0.247
C(answer_type_grouped)[T.Person]              -0.2755      0.505     -0.546      0.585      -1.265       0.714
q_length                                       0.1328      0.531      0.250      0.803      -0.908       1.174
capabilities_entropy                           0.9953      0.419      2.376      0.018       0.174       1.816
game_entropy                                   2.4412      0.381      6.409      0.000       1.695       3.188
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing grok-3-latest (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/grok-3-latest_SimpleMC_redacted_temp0.0_1751719937_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
1    111
0     94
Name: count, dtype: int64

Answer change%: 0.5415 [0.473254252367988, 0.6096725769003047] (n=205)
P-value vs 25%: 5.518e-17; P-value vs 0%: 1.388e-54
Phase 2 self-accuracy: 0.5405 [0.447831019784466, 0.6332500612966151] (n=111)
P-value vs 25%: 8.134e-10; P-value vs 33%: 1.146e-05

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  205
Model:                          Logit   Df Residuals:                      203
Method:                           MLE   Df Model:                            1
Date:                Sun, 06 Jul 2025   Pseudo R-squ.:                 0.05674
Time:                        10:05:14   Log-Likelihood:                -133.37
converged:                       True   LL-Null:                       -141.39
Covariance Type:            nonrobust   LLR p-value:                 6.183e-05
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          3.0605      0.787      3.887      0.000       1.517       4.604
p_i_capability    -3.4778      0.918     -3.787      0.000      -5.278      -1.678
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  205
Model:                          Logit   Df Residuals:                      203
Method:                           MLE   Df Model:                            1
Date:                Sun, 06 Jul 2025   Pseudo R-squ.:                 0.05585
Time:                        10:05:14   Log-Likelihood:                -133.49
converged:                       True   LL-Null:                       -141.39
Covariance Type:            nonrobust   LLR p-value:                 7.060e-05
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -0.5727      0.238     -2.407      0.016      -1.039      -0.106
capabilities_entropy     1.2345      0.323      3.818      0.000       0.601       1.868
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.6036 [0.5126, 0.6946] (n=111)
                  P-value vs 33.3%: 5.84e-09

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=4.05, p=0.000107
Wilcoxon delta_p: statistic=1146.00, p=4.18e-05
Mean p = 0.0783  [0.0404, 0.1162]

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.804
Model:                            OLS   Adj. R-squared:                  0.801
Method:                 Least Squares   F-statistic:                     275.5
Date:                Sun, 06 Jul 2025   Prob (F-statistic):           6.27e-71
Time:                        10:05:14   Log-Likelihood:                 90.653
No. Observations:                 205   AIC:                            -173.3
Df Residuals:                     201   BIC:                            -160.0
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.3689      0.096     -3.829      0.000      -0.559      -0.179
p1                    0.5107      0.108      4.709      0.000       0.297       0.725
answer_changed        0.2595      0.117      2.210      0.028       0.028       0.491
p1:answer_changed     0.4590      0.137      3.350      0.001       0.189       0.729
==============================================================================
Omnibus:                       25.083   Durbin-Watson:                   2.070
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               79.040
Skew:                          -0.420   Prob(JB):                     6.86e-18
Kurtosis:                       5.924   Cond. No.                         30.1
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-3.34, p=0.00121
Wilcoxon delta_H: statistic=1381.00, p=0.00132
Mean H = -0.1752  [-0.2780, -0.0723]
Paired t-test delta_H Changed: statistic=0.68, p=0.495
Wilcoxon delta_H Changed: statistic=2839.00, p=0.429
Mean H Changed = 0.0335  [-0.0625, 0.1294]

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=6854.00, p=1.33e-05
Paired t-test (game_entropy vs capabilities_entropy): statistic=4.93, p=1.66e-06
Mean capabilities_entropy-game_entropy = -0.2027  [-0.2832, -0.1222] (n=205)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  205
Model:                          Logit   Df Residuals:                      202
Method:                           MLE   Df Model:                            2
Date:                Sun, 06 Jul 2025   Pseudo R-squ.:                 0.06024
Time:                        10:05:14   Log-Likelihood:                -132.87
converged:                       True   LL-Null:                       -141.39
Covariance Type:            nonrobust   LLR p-value:                 0.0001999
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept        0.3526      0.218      1.616      0.106      -0.075       0.780
p1_z            -0.7140      0.196     -3.643      0.000      -1.098      -0.330
I(p1_z ** 2)    -0.1678      0.166     -1.009      0.313      -0.494       0.158
================================================================================
AUC = 0.669

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  205
Model:                          Logit   Df Residuals:                      203
Method:                           MLE   Df Model:                            1
Date:                Sun, 06 Jul 2025   Pseudo R-squ.:                 0.02882
Time:                        10:05:14   Log-Likelihood:                -137.31
converged:                       True   LL-Null:                       -141.39
Covariance Type:            nonrobust   LLR p-value:                  0.004308
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.4745      0.268     -1.772      0.076      -0.999       0.050
game_entropy     0.7936      0.283      2.802      0.005       0.238       1.349
================================================================================

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  205
Model:                          Logit   Df Residuals:                      202
Method:                           MLE   Df Model:                            2
Date:                Sun, 06 Jul 2025   Pseudo R-squ.:                 0.06786
Time:                        10:05:14   Log-Likelihood:                -131.80
converged:                       True   LL-Null:                       -141.39
Covariance Type:            nonrobust   LLR p-value:                 6.814e-05
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -0.9235      0.311     -2.973      0.003      -1.532      -0.315
capabilities_entropy     1.0838      0.335      3.234      0.001       0.427       1.741
game_entropy             0.5462      0.299      1.829      0.067      -0.039       1.131
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['Politics', 'Art', 'Geography', 'Other', 'Music', 'Sports', 'TV shows', 'Video games', 'History']
                  Grouped rare answer_type into 'Misc'/'Other': ['Number', 'Other', 'Place']
topic_grouped           answer_changed
Misc                    1                 0.535484
                        0                 0.464516
Science and technology  1                 0.560000
                        0                 0.440000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.500000
                     1                 0.500000
Misc                 1                 0.662500
                     0                 0.337500
Person               0                 0.578947
                     1                 0.421053
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Misc                   Date                 0.574074  0.425926           54
                       Misc                 0.348485  0.651515           66
                       Person               0.514286  0.485714           35
Science and technology Date                 0.214286  0.785714           14
                       Misc                 0.285714  0.714286           14
                       Person               0.681818  0.318182           22

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  205
Model:                          Logit   Df Residuals:                      200
Method:                           MLE   Df Model:                            4
Date:                Sun, 06 Jul 2025   Pseudo R-squ.:                 0.03537
Time:                        10:05:14   Log-Likelihood:                -136.39
converged:                       True   LL-Null:                       -141.39
Covariance Type:            nonrobust   LLR p-value:                   0.04038
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.4544      1.720     -0.846      0.398      -4.825       1.916
C(topic_grouped)[T.Science and technology]     0.2724      0.345      0.789      0.430      -0.404       0.949
C(answer_type_grouped)[T.Misc]                 0.7212      0.343      2.100      0.036       0.048       1.394
C(answer_type_grouped)[T.Person]              -0.2907      0.381     -0.762      0.446      -1.038       0.457
q_length                                       0.2994      0.365      0.821      0.412      -0.416       1.014
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  205
Model:                          Logit   Df Residuals:                      199
Method:                           MLE   Df Model:                            5
Date:                Sun, 06 Jul 2025   Pseudo R-squ.:                 0.09571
Time:                        10:05:14   Log-Likelihood:                -127.86
converged:                       True   LL-Null:                       -141.39
Covariance Type:            nonrobust   LLR p-value:                 5.544e-05
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -2.2161      1.808     -1.226      0.220      -5.759       1.327
C(topic_grouped)[T.Science and technology]     0.2071      0.366      0.565      0.572      -0.511       0.925
C(answer_type_grouped)[T.Misc]                 0.9537      0.367      2.596      0.009       0.234       1.674
C(answer_type_grouped)[T.Person]              -0.1352      0.401     -0.337      0.736      -0.920       0.650
q_length                                       0.2661      0.380      0.699      0.484      -0.480       1.012
capabilities_entropy                           1.3436      0.341      3.940      0.000       0.675       2.012
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  205
Model:                          Logit   Df Residuals:                      199
Method:                           MLE   Df Model:                            5
Date:                Sun, 06 Jul 2025   Pseudo R-squ.:                 0.06110
Time:                        10:05:14   Log-Likelihood:                -132.75
converged:                       True   LL-Null:                       -141.39
Covariance Type:            nonrobust   LLR p-value:                  0.004003
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -2.0585      1.772     -1.161      0.245      -5.532       1.415
C(topic_grouped)[T.Science and technology]     0.2615      0.351      0.746      0.456      -0.426       0.949
C(answer_type_grouped)[T.Misc]                 0.8032      0.352      2.281      0.023       0.113       1.493
C(answer_type_grouped)[T.Person]              -0.1331      0.392     -0.339      0.734      -0.902       0.636
q_length                                       0.2780      0.372      0.747      0.455      -0.452       1.008
game_entropy                                   0.7774      0.293      2.652      0.008       0.203       1.352
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  205
Model:                          Logit   Df Residuals:                      198
Method:                           MLE   Df Model:                            6
Date:                Sun, 06 Jul 2025   Pseudo R-squ.:                  0.1054
Time:                        10:05:14   Log-Likelihood:                -126.49
converged:                       True   LL-Null:                       -141.39
Covariance Type:            nonrobust   LLR p-value:                 4.280e-05
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -2.5322      1.838     -1.378      0.168      -6.134       1.070
C(topic_grouped)[T.Science and technology]     0.2031      0.368      0.552      0.581      -0.519       0.925
C(answer_type_grouped)[T.Misc]                 0.9747      0.369      2.640      0.008       0.251       1.698
C(answer_type_grouped)[T.Person]              -0.0539      0.407     -0.132      0.895      -0.852       0.744
q_length                                       0.2561      0.384      0.666      0.505      -0.497       1.009
capabilities_entropy                           1.2060      0.352      3.422      0.001       0.515       1.897
game_entropy                                   0.5069      0.308      1.646      0.100      -0.097       1.111
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.
