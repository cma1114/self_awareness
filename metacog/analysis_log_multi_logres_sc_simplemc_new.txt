
--- Analyzing claude-3-5-sonnet-20241022 (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/claude-3-5-sonnet-20241022_SimpleMC_redacted_cor_temp0.0_1753745296_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    247
1     53
Name: count, dtype: int64

Answer change%: 0.1767 [0.13350953025765339, 0.21982380307567995] (n=300)
P-value vs 25%: 0.0008672; P-value vs 0%: 1.03e-15
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=53)
P-value vs 25%: 0; P-value vs 33%: 0

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  300
Model:                          Logit   Df Residuals:                      298
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1042
Time:                        09:26:42   Log-Likelihood:                -125.32
converged:                       True   LL-Null:                       -139.89
Covariance Type:            nonrobust   LLR p-value:                 6.728e-08
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          1.4638      0.562      2.605      0.009       0.363       2.565
p_i_capability    -4.0545      0.775     -5.229      0.000      -5.574      -2.535
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  300
Model:                          Logit   Df Residuals:                      298
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1201
Time:                        09:26:42   Log-Likelihood:                -123.09
converged:                       True   LL-Null:                       -139.89
Covariance Type:            nonrobust   LLR p-value:                 6.778e-09
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -3.1261      0.370     -8.455      0.000      -3.851      -2.401
capabilities_entropy     1.6202      0.296      5.471      0.000       1.040       2.201
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.6604 [0.5329, 0.7879] (n=53)
                  P-value vs 33.3%: 4.97e-07

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=6.08, p=4.51e-09
Wilcoxon delta_p: statistic=4942.50, p=5.05e-09
Mean Δp = 0.0644  [0.0437, 0.0852]
Idea 1 N = 247; 

  Idea 1.5: Calibration Metrics
  NLL: 0.2738, Signed ECE (overconf pos under neg): -0.2103, ECE: 0.2103 (n=300)
  Brier: 0.0822, Reliability (absolute calibration error; lower better): 0.0817, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=300)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.506
Model:                            OLS   Adj. R-squared:                  0.501
Method:                 Least Squares   F-statistic:                     100.9
Date:                Sat, 20 Sep 2025   Prob (F-statistic):           5.29e-45
Time:                        09:26:42   Log-Likelihood:                 141.41
No. Observations:                 300   AIC:                            -274.8
Df Residuals:                     296   BIC:                            -260.0
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.1429      0.044     -3.252      0.001      -0.229      -0.056
p1                    0.2533      0.052      4.837      0.000       0.150       0.356
answer_changed       -0.0364      0.089     -0.408      0.684      -0.212       0.139
p1:answer_changed     0.6395      0.126      5.081      0.000       0.392       0.887
==============================================================================
Omnibus:                       17.550   Durbin-Watson:                   2.055
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               18.922
Skew:                           0.594   Prob(JB):                     7.78e-05
Kurtosis:                       3.321   Cond. No.                         23.1
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-0.21, p=0.836
Wilcoxon delta_H: statistic=9540.50, p=0.792
Mean ΔH = -0.0048  [-0.0499, 0.0403]
Paired t-test delta_H Changed: statistic=1.53, p=0.131
Wilcoxon delta_H Changed: statistic=568.00, p=0.192
Mean ΔH Changed = 0.0831  [-0.0231, 0.1892]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=-7.60, p=3.83e-13
Wilcoxon (p_top2_game vs p_top2_base): statistic=7520.00, p=9.58e-13
Mean Δp_top2 = -0.0421  [-0.0530, -0.0313] (n=300)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=0.51, p=0.614
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=15211.50, p=0.677
Mean ΔH_unchosen_baseline_set = 0.0107  [-0.0309, 0.0524] (n=300)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  300
Model:                          Logit   Df Residuals:                      297
Method:                           MLE   Df Model:                            2
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1287
Time:                        09:26:42   Log-Likelihood:                -121.89
converged:                       True   LL-Null:                       -139.89
Covariance Type:            nonrobust   LLR p-value:                 1.524e-08
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.3636      0.227     -6.017      0.000      -1.808      -0.919
p1_z            -1.2878      0.257     -5.013      0.000      -1.791      -0.784
I(p1_z ** 2)    -0.4810      0.188     -2.553      0.011      -0.850      -0.112
================================================================================
AUC = 0.733

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  300
Model:                          Logit   Df Residuals:                      298
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1868
Time:                        09:26:42   Log-Likelihood:                -113.76
converged:                       True   LL-Null:                       -139.89
Covariance Type:            nonrobust   LLR p-value:                 4.854e-13
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -4.4449      0.596     -7.456      0.000      -5.613      -3.276
game_entropy     2.2685      0.388      5.845      0.000       1.508       3.029
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=7157.50, p=9.12e-14
Paired t-test (game_entropy vs capabilities_entropy): statistic=7.95, p=3.94e-14
Mean capabilities_entropy-game_entropy = -0.2181  [-0.2719, -0.1643] (n=300)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  300
Model:                          Logit   Df Residuals:                      297
Method:                           MLE   Df Model:                            2
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1959
Time:                        09:26:42   Log-Likelihood:                -112.49
converged:                       True   LL-Null:                       -139.89
Covariance Type:            nonrobust   LLR p-value:                 1.261e-12
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -4.5271      0.593     -7.631      0.000      -5.690      -3.364
capabilities_entropy     0.5777      0.366      1.578      0.115      -0.140       1.295
game_entropy             1.8882      0.449      4.203      0.000       1.008       2.769
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.914894
                        1                 0.085106
Geography               0                 0.739130
                        1                 0.260870
Misc                    0                 0.897959
                        1                 0.102041
Music                   0                 0.833333
                        1                 0.166667
Other                   0                 0.750000
                        1                 0.250000
Politics                0                 0.800000
                        1                 0.200000
Science and technology  0                 0.807692
                        1                 0.192308
Sports                  0                 0.739130
                        1                 0.260870
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.740000
                     1                 0.260000
Number               0                 0.800000
                     1                 0.200000
Other                0                 0.840909
                     1                 0.159091
Person               0                 0.922078
                     1                 0.077922
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.900000  0.100000           10
                       Number               0.666667  0.333333            6
                       Other                0.916667  0.083333           12
                       Person               1.000000  0.000000           19
Geography              Date                 0.428571  0.571429            7
                       Number               0.888889  0.111111            9
                       Other                0.857143  0.142857            7
Misc                   Date                 0.812500  0.187500           16
                       Number               0.833333  0.166667            6
                       Other                0.941176  0.058824           17
                       Person               1.000000  0.000000           10
Music                  Date                 0.714286  0.285714            7
                       Other                0.857143  0.142857            7
                       Person               0.900000  0.100000           10
Other                  Date                 0.727273  0.272727           11
                       Number               1.000000  0.000000            2
                       Other                0.800000  0.200000           10
                       Person               0.666667  0.333333            9
Politics               Date                 0.772727  0.227273           22
                       Number               0.666667  0.333333            3
                       Other                0.750000  0.250000           16
                       Person               1.000000  0.000000            9
Science and technology Date                 0.700000  0.300000           20
                       Number               0.800000  0.200000            5
                       Other                0.846154  0.153846           13
                       Person               0.928571  0.071429           14
Sports                 Date                 0.714286  0.285714            7
                       Number               0.750000  0.250000            4
                       Other                0.666667  0.333333            6
                       Person               0.833333  0.166667            6

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  300
Model:                          Logit   Df Residuals:                      288
Method:                           MLE   Df Model:                           11
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.06485
Time:                        09:26:42   Log-Likelihood:                -130.82
converged:                       True   LL-Null:                       -139.89
Covariance Type:            nonrobust   LLR p-value:                   0.07830
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -2.0237      1.997     -1.013      0.311      -5.938       1.891
C(topic_grouped)[T.Geography]                  1.0155      0.727      1.397      0.162      -0.409       2.440
C(topic_grouped)[T.Misc]                       0.0089      0.714      0.013      0.990      -1.391       1.409
C(topic_grouped)[T.Music]                      0.7732      0.774      0.999      0.318      -0.744       2.290
C(topic_grouped)[T.Other]                      1.1670      0.676      1.727      0.084      -0.157       2.491
C(topic_grouped)[T.Politics]                   0.7248      0.662      1.095      0.274      -0.572       2.022
C(topic_grouped)[T.Science and technology]     0.7623      0.645      1.182      0.237      -0.502       2.027
C(topic_grouped)[T.Sports]                     1.2140      0.718      1.690      0.091      -0.194       2.622
C(answer_type_grouped)[T.Number]              -0.3523      0.509     -0.692      0.489      -1.351       0.646
C(answer_type_grouped)[T.Other]               -0.5899      0.377     -1.565      0.118      -1.329       0.149
C(answer_type_grouped)[T.Person]              -1.3668      0.495     -2.762      0.006      -2.337      -0.397
q_length                                       0.0622      0.430      0.145      0.885      -0.781       0.905
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.8267
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  300
Model:                          Logit   Df Residuals:                      287
Method:                           MLE   Df Model:                           12
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1813
Time:                        09:26:42   Log-Likelihood:                -114.53
converged:                       True   LL-Null:                       -139.89
Covariance Type:            nonrobust   LLR p-value:                 1.041e-06
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -4.5335      2.241     -2.023      0.043      -8.926      -0.141
C(topic_grouped)[T.Geography]                  0.9103      0.778      1.171      0.242      -0.614       2.434
C(topic_grouped)[T.Misc]                      -0.1407      0.750     -0.188      0.851      -1.610       1.329
C(topic_grouped)[T.Music]                      0.2905      0.824      0.353      0.724      -1.325       1.906
C(topic_grouped)[T.Other]                      1.0563      0.727      1.453      0.146      -0.368       2.481
C(topic_grouped)[T.Politics]                   0.8163      0.687      1.188      0.235      -0.530       2.162
C(topic_grouped)[T.Science and technology]     0.8638      0.682      1.266      0.206      -0.474       2.201
C(topic_grouped)[T.Sports]                     1.4235      0.770      1.848      0.065      -0.086       2.933
C(answer_type_grouped)[T.Number]              -0.7293      0.549     -1.329      0.184      -1.805       0.346
C(answer_type_grouped)[T.Other]               -0.4348      0.407     -1.068      0.286      -1.233       0.363
C(answer_type_grouped)[T.Person]              -1.2289      0.520     -2.362      0.018      -2.248      -0.209
q_length                                       0.2467      0.469      0.526      0.599      -0.672       1.166
capabilities_entropy                           1.7147      0.324      5.300      0.000       1.081       2.349
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  300
Model:                          Logit   Df Residuals:                      287
Method:                           MLE   Df Model:                           12
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.2407
Time:                        09:26:42   Log-Likelihood:                -106.22
converged:                       True   LL-Null:                       -139.89
Covariance Type:            nonrobust   LLR p-value:                 1.005e-09
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -8.5103      2.650     -3.212      0.001     -13.704      -3.317
C(topic_grouped)[T.Geography]                  1.0529      0.779      1.351      0.177      -0.475       2.580
C(topic_grouped)[T.Misc]                      -0.2706      0.759     -0.357      0.721      -1.758       1.217
C(topic_grouped)[T.Music]                     -0.0102      0.830     -0.012      0.990      -1.637       1.616
C(topic_grouped)[T.Other]                      0.8277      0.730      1.134      0.257      -0.603       2.259
C(topic_grouped)[T.Politics]                   0.7862      0.705      1.115      0.265      -0.596       2.168
C(topic_grouped)[T.Science and technology]     0.9109      0.708      1.287      0.198      -0.476       2.298
C(topic_grouped)[T.Sports]                     1.3183      0.776      1.698      0.089      -0.203       2.840
C(answer_type_grouped)[T.Number]              -0.7445      0.556     -1.338      0.181      -1.835       0.346
C(answer_type_grouped)[T.Other]                0.0886      0.430      0.206      0.837      -0.754       0.931
C(answer_type_grouped)[T.Person]              -0.7232      0.543     -1.331      0.183      -1.788       0.342
q_length                                       0.7431      0.533      1.395      0.163      -0.301       1.787
game_entropy                                   2.5068      0.442      5.668      0.000       1.640       3.374
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  300
Model:                          Logit   Df Residuals:                      286
Method:                           MLE   Df Model:                           13
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.2553
Time:                        09:26:42   Log-Likelihood:                -104.18
converged:                       True   LL-Null:                       -139.89
Covariance Type:            nonrobust   LLR p-value:                 4.374e-10
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -8.4710      2.673     -3.169      0.002     -13.711      -3.231
C(topic_grouped)[T.Geography]                  0.9327      0.794      1.174      0.240      -0.624       2.490
C(topic_grouped)[T.Misc]                      -0.3803      0.769     -0.494      0.621      -1.888       1.128
C(topic_grouped)[T.Music]                     -0.1455      0.843     -0.173      0.863      -1.798       1.507
C(topic_grouped)[T.Other]                      0.7841      0.741      1.059      0.290      -0.667       2.236
C(topic_grouped)[T.Politics]                   0.8220      0.708      1.161      0.246      -0.566       2.210
C(topic_grouped)[T.Science and technology]     0.8493      0.717      1.185      0.236      -0.556       2.254
C(topic_grouped)[T.Sports]                     1.3611      0.782      1.740      0.082      -0.172       2.894
C(answer_type_grouped)[T.Number]              -0.8885      0.574     -1.549      0.121      -2.013       0.236
C(answer_type_grouped)[T.Other]                0.0440      0.435      0.101      0.919      -0.808       0.896
C(answer_type_grouped)[T.Person]              -0.7945      0.548     -1.449      0.147      -1.869       0.280
q_length                                       0.7137      0.537      1.330      0.184      -0.338       1.766
capabilities_entropy                           0.7673      0.385      1.995      0.046       0.013       1.521
game_entropy                                   2.0503      0.494      4.152      0.000       1.082       3.018
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing claude-3-5-sonnet-20241022 (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/claude-3-5-sonnet-20241022_SimpleMC_redacted_temp0.0_1753644934_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    116
1     84
Name: count, dtype: int64

Answer change%: 0.4200 [0.3515975377372609, 0.4884024622627391] (n=200)
P-value vs 25%: 1.11e-06; P-value vs 0%: 2.342e-33
Phase 2 self-accuracy: 0.5714 [0.46560046363803614, 0.6772566792191067] (n=84)
P-value vs 25%: 2.634e-09; P-value vs 33%: 1.007e-05

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  200
Model:                          Logit   Df Residuals:                      198
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.09308
Time:                        09:26:42   Log-Likelihood:                -123.39
converged:                       True   LL-Null:                       -136.06
Covariance Type:            nonrobust   LLR p-value:                 4.834e-07
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          1.9541      0.498      3.927      0.000       0.979       2.929
p_i_capability    -3.8391      0.821     -4.675      0.000      -5.449      -2.229
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  200
Model:                          Logit   Df Residuals:                      198
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1096
Time:                        09:26:42   Log-Likelihood:                -121.15
converged:                       True   LL-Null:                       -136.06
Covariance Type:            nonrobust   LLR p-value:                 4.750e-08
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.6873      0.525     -5.121      0.000      -3.716      -1.659
capabilities_entropy     1.7229      0.351      4.908      0.000       1.035       2.411
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.6786 [0.5787, 0.7784] (n=84)
                  P-value vs 33.3%: 1.243e-11

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=4.63, p=9.61e-06
Wilcoxon delta_p: statistic=1580.00, p=2.94e-05
Mean Δp = 0.0736  [0.0425, 0.1047]
Idea 1 N = 116; 

  Idea 1.5: Calibration Metrics
  NLL: 2.2591, Signed ECE (overconf pos under neg): 0.1590, ECE: 0.1590 (n=200)
  Brier: 0.0387, Reliability (absolute calibration error; lower better): 0.0380, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=200)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.583
Model:                            OLS   Adj. R-squared:                  0.577
Method:                 Least Squares   F-statistic:                     91.46
Date:                Sat, 20 Sep 2025   Prob (F-statistic):           4.74e-37
Time:                        09:26:42   Log-Likelihood:                 120.37
No. Observations:                 200   AIC:                            -232.7
Df Residuals:                     196   BIC:                            -219.6
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.1716      0.041     -4.169      0.000      -0.253      -0.090
p1                    0.3671      0.059      6.249      0.000       0.251       0.483
answer_changed       -0.0370      0.065     -0.565      0.573      -0.166       0.092
p1:answer_changed     0.5859      0.110      5.338      0.000       0.369       0.802
==============================================================================
Omnibus:                        0.153   Durbin-Watson:                   1.958
Prob(Omnibus):                  0.926   Jarque-Bera (JB):                0.286
Skew:                           0.043   Prob(JB):                        0.867
Kurtosis:                       2.836   Cond. No.                         18.1
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-0.80, p=0.423
Wilcoxon delta_H: statistic=2573.00, p=0.199
Mean ΔH = -0.0270  [-0.0927, 0.0388]
Paired t-test delta_H Changed: statistic=3.63, p=0.000493
Wilcoxon delta_H Changed: statistic=951.00, p=0.0002
Mean ΔH Changed = 0.1237  [0.0569, 0.1905]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=-4.43, p=1.57e-05
Wilcoxon (p_top2_game vs p_top2_base): statistic=6023.00, p=1.74e-05
Mean Δp_top2 = -0.0335  [-0.0483, -0.0187] (n=200)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=1.47, p=0.143
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=8276.00, p=0.163
Mean ΔH_unchosen_baseline_set = 0.0363  [-0.0121, 0.0847] (n=200)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  200
Model:                          Logit   Df Residuals:                      197
Method:                           MLE   Df Model:                            2
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1088
Time:                        09:26:42   Log-Likelihood:                -121.25
converged:                       True   LL-Null:                       -136.06
Covariance Type:            nonrobust   LLR p-value:                 3.723e-07
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.0512      0.222     -0.231      0.818      -0.486       0.384
p1_z            -0.7524      0.178     -4.227      0.000      -1.101      -0.404
I(p1_z ** 2)    -0.3890      0.193     -2.016      0.044      -0.767      -0.011
================================================================================
AUC = 0.701

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  200
Model:                          Logit   Df Residuals:                      198
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.05575
Time:                        09:26:42   Log-Likelihood:                -128.47
converged:                       True   LL-Null:                       -136.06
Covariance Type:            nonrobust   LLR p-value:                 9.821e-05
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -2.2740      0.585     -3.885      0.000      -3.421      -1.127
game_entropy     1.3042      0.367      3.550      0.000       0.584       2.024
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=5654.00, p=1.84e-06
Paired t-test (game_entropy vs capabilities_entropy): statistic=5.11, p=7.47e-07
Mean capabilities_entropy-game_entropy = -0.1362  [-0.1884, -0.0840] (n=200)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  200
Model:                          Logit   Df Residuals:                      197
Method:                           MLE   Df Model:                            2
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1098
Time:                        09:26:42   Log-Likelihood:                -121.13
converged:                       True   LL-Null:                       -136.06
Covariance Type:            nonrobust   LLR p-value:                 3.271e-07
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.7621      0.627     -4.405      0.000      -3.991      -1.533
capabilities_entropy     1.6591      0.452      3.671      0.000       0.773       2.545
game_entropy             0.1078      0.483      0.223      0.824      -0.839       1.055
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'Video games', 'History']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.607143
                        1                 0.392857
Geography               0                 0.571429
                        1                 0.428571
Misc                    0                 0.720000
                        1                 0.280000
Music                   0                 0.562500
                        1                 0.437500
Other                   1                 0.600000
                        0                 0.400000
Politics                0                 0.666667
                        1                 0.333333
Science and technology  0                 0.500000
                        1                 0.500000
Sports                  0                 0.647059
                        1                 0.352941
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 1                 0.521739
                     0                 0.478261
Number               0                 0.604651
                     1                 0.395349
Other                0                 0.644444
                     1                 0.355556
Person               0                 0.651163
                     1                 0.348837
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.454545  0.545455           11
                       Number               0.666667  0.333333            3
                       Other                1.000000  0.000000            6
                       Person               0.500000  0.500000            8
Geography              Date                 0.625000  0.375000            8
                       Number               0.666667  0.333333            9
                       Other                0.250000  0.750000            4
Misc                   Date                 0.571429  0.428571            7
                       Number               0.333333  0.666667            3
                       Other                0.900000  0.100000           10
                       Person               0.800000  0.200000            5
Music                  Date                 0.400000  0.600000            5
                       Number               0.750000  0.250000            4
                       Other                0.400000  0.600000            5
                       Person               1.000000  0.000000            2
Other                  Date                 0.285714  0.714286            7
                       Number               0.600000  0.400000            5
                       Other                0.500000  0.500000            4
                       Person               0.250000  0.750000            4
Politics               Date                 0.642857  0.357143           14
                       Number               0.333333  0.666667            3
                       Other                0.750000  0.250000            4
                       Person               0.833333  0.166667            6
Science and technology Date                 0.400000  0.600000           15
                       Number               0.444444  0.555556            9
                       Other                0.333333  0.666667            6
                       Person               0.687500  0.312500           16
Sports                 Date                 0.000000  1.000000            2
                       Number               0.857143  0.142857            7
                       Other                0.666667  0.333333            6
                       Person               0.500000  0.500000            2

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  200
Model:                          Logit   Df Residuals:                      188
Method:                           MLE   Df Model:                           11
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.05898
Time:                        09:26:42   Log-Likelihood:                -128.03
converged:                       True   LL-Null:                       -136.06
Covariance Type:            nonrobust   LLR p-value:                    0.1393
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -3.5450      1.888     -1.877      0.060      -7.246       0.156
C(topic_grouped)[T.Geography]                  0.1243      0.615      0.202      0.840      -1.081       1.330
C(topic_grouped)[T.Misc]                      -0.4950      0.607     -0.815      0.415      -1.685       0.695
C(topic_grouped)[T.Music]                      0.2765      0.656      0.422      0.673      -1.009       1.562
C(topic_grouped)[T.Other]                      0.9684      0.621      1.560      0.119      -0.249       2.185
C(topic_grouped)[T.Politics]                  -0.4647      0.583     -0.798      0.425      -1.607       0.677
C(topic_grouped)[T.Science and technology]     0.5025      0.504      0.997      0.319      -0.486       1.491
C(topic_grouped)[T.Sports]                    -0.0895      0.666     -0.134      0.893      -1.395       1.216
C(answer_type_grouped)[T.Number]              -0.6653      0.424     -1.571      0.116      -1.495       0.165
C(answer_type_grouped)[T.Other]               -0.5896      0.417     -1.415      0.157      -1.406       0.227
C(answer_type_grouped)[T.Person]              -0.7236      0.424     -1.705      0.088      -1.556       0.108
q_length                                       0.7762      0.403      1.924      0.054      -0.014       1.567
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 1.3228
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  200
Model:                          Logit   Df Residuals:                      187
Method:                           MLE   Df Model:                           12
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1493
Time:                        09:26:42   Log-Likelihood:                -115.74
converged:                       True   LL-Null:                       -136.06
Covariance Type:            nonrobust   LLR p-value:                 5.641e-05
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -5.5221      2.113     -2.613      0.009      -9.664      -1.380
C(topic_grouped)[T.Geography]                 -0.0293      0.647     -0.045      0.964      -1.297       1.239
C(topic_grouped)[T.Misc]                      -0.3695      0.645     -0.573      0.567      -1.634       0.895
C(topic_grouped)[T.Music]                      0.5099      0.707      0.721      0.471      -0.875       1.895
C(topic_grouped)[T.Other]                      1.2316      0.685      1.798      0.072      -0.111       2.575
C(topic_grouped)[T.Politics]                  -0.1812      0.636     -0.285      0.776      -1.427       1.065
C(topic_grouped)[T.Science and technology]     0.5178      0.537      0.964      0.335      -0.535       1.570
C(topic_grouped)[T.Sports]                    -0.1449      0.709     -0.204      0.838      -1.534       1.244
C(answer_type_grouped)[T.Number]              -0.3906      0.446     -0.876      0.381      -1.265       0.484
C(answer_type_grouped)[T.Other]               -0.3742      0.449     -0.834      0.404      -1.254       0.505
C(answer_type_grouped)[T.Person]              -0.2743      0.471     -0.582      0.560      -1.198       0.649
q_length                                       0.6339      0.434      1.462      0.144      -0.216       1.484
capabilities_entropy                           1.7024      0.375      4.541      0.000       0.968       2.437
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  200
Model:                          Logit   Df Residuals:                      187
Method:                           MLE   Df Model:                           12
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1118
Time:                        09:26:42   Log-Likelihood:                -120.85
converged:                       True   LL-Null:                       -136.06
Covariance Type:            nonrobust   LLR p-value:                  0.002421
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -6.2098      2.132     -2.913      0.004     -10.388      -2.032
C(topic_grouped)[T.Geography]                  0.2156      0.639      0.337      0.736      -1.038       1.469
C(topic_grouped)[T.Misc]                      -0.4860      0.624     -0.779      0.436      -1.709       0.737
C(topic_grouped)[T.Music]                      0.4263      0.685      0.622      0.534      -0.917       1.769
C(topic_grouped)[T.Other]                      1.0457      0.649      1.612      0.107      -0.226       2.317
C(topic_grouped)[T.Politics]                  -0.3166      0.608     -0.521      0.603      -1.509       0.876
C(topic_grouped)[T.Science and technology]     0.6075      0.525      1.158      0.247      -0.421       1.636
C(topic_grouped)[T.Sports]                    -0.0508      0.686     -0.074      0.941      -1.395       1.294
C(answer_type_grouped)[T.Number]              -0.8091      0.439     -1.841      0.066      -1.670       0.052
C(answer_type_grouped)[T.Other]               -0.5265      0.434     -1.213      0.225      -1.378       0.325
C(answer_type_grouped)[T.Person]              -0.3228      0.459     -0.703      0.482      -1.223       0.577
q_length                                       0.8716      0.421      2.071      0.038       0.047       1.696
game_entropy                                   1.3937      0.398      3.499      0.000       0.613       2.174
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  200
Model:                          Logit   Df Residuals:                      186
Method:                           MLE   Df Model:                           13
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1502
Time:                        09:26:42   Log-Likelihood:                -115.62
converged:                       True   LL-Null:                       -136.06
Covariance Type:            nonrobust   LLR p-value:                 9.976e-05
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -5.8332      2.209     -2.640      0.008     -10.164      -1.503
C(topic_grouped)[T.Geography]                  0.0079      0.652      0.012      0.990      -1.270       1.286
C(topic_grouped)[T.Misc]                      -0.3751      0.644     -0.583      0.560      -1.637       0.887
C(topic_grouped)[T.Music]                      0.5186      0.708      0.733      0.464      -0.869       1.906
C(topic_grouped)[T.Other]                      1.2263      0.685      1.791      0.073      -0.116       2.568
C(topic_grouped)[T.Politics]                  -0.1798      0.635     -0.283      0.777      -1.425       1.065
C(topic_grouped)[T.Science and technology]     0.5356      0.538      0.995      0.320      -0.519       1.591
C(topic_grouped)[T.Sports]                    -0.1344      0.708     -0.190      0.849      -1.523       1.254
C(answer_type_grouped)[T.Number]              -0.4496      0.462     -0.973      0.330      -1.355       0.456
C(answer_type_grouped)[T.Other]               -0.3839      0.449     -0.854      0.393      -1.265       0.497
C(answer_type_grouped)[T.Person]              -0.2528      0.474     -0.533      0.594      -1.182       0.676
q_length                                       0.6647      0.438      1.516      0.129      -0.194       1.524
capabilities_entropy                           1.5436      0.493      3.132      0.002       0.578       2.509
game_entropy                                   0.2604      0.530      0.492      0.623      -0.778       1.298
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing claude-3-haiku-20240307 (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/claude-3-haiku-20240307_SimpleMC_redacted_cor_temp0.0_1754173427_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    124
1     27
Name: count, dtype: int64

Answer change%: 0.1788 [0.11768906596126844, 0.23992682807846666] (n=151)
P-value vs 25%: 0.02243; P-value vs 0%: 9.808e-09
Phase 2 self-accuracy: 0.0741 [0.0, 0.17285826494558254] (n=27)
P-value vs 25%: 0.0004821; P-value vs 33%: 2.787e-07

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  151
Model:                          Logit   Df Residuals:                      149
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.05849
Time:                        09:26:42   Log-Likelihood:                -66.760
converged:                       True   LL-Null:                       -70.907
Covariance Type:            nonrobust   LLR p-value:                  0.003977
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          2.0996      1.229      1.708      0.088      -0.310       4.509
p_i_capability    -4.1053      1.395     -2.943      0.003      -6.840      -1.371
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  151
Model:                          Logit   Df Residuals:                      149
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.07001
Time:                        09:26:42   Log-Likelihood:                -65.943
converged:                       True   LL-Null:                       -70.907
Covariance Type:            nonrobust   LLR p-value:                  0.001628
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.5813      0.422     -6.123      0.000      -3.408      -1.755
capabilities_entropy     2.1784      0.691      3.154      0.002       0.825       3.532
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.3704 [0.1882, 0.5525] (n=27)
                  P-value vs 33.3%: 0.6902

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=-0.60, p=0.55
Wilcoxon delta_p: statistic=524.00, p=0.378
Mean Δp = -0.0073  [-0.0311, 0.0165]
Idea 1 N = 124; 

  Idea 1.5: Calibration Metrics
  NLL: 0.1291, Signed ECE (overconf pos under neg): -0.1033, ECE: 0.1033 (n=151)
  Brier: 0.0321, Reliability (absolute calibration error; lower better): 0.0319, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=151)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.872
Model:                            OLS   Adj. R-squared:                  0.869
Method:                 Least Squares   F-statistic:                     334.1
Date:                Sat, 20 Sep 2025   Prob (F-statistic):           2.07e-65
Time:                        09:26:42   Log-Likelihood:                 122.73
No. Observations:                 151   AIC:                            -237.5
Df Residuals:                     147   BIC:                            -225.4
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.8486      0.086     -9.870      0.000      -1.019      -0.679
p1                    0.9164      0.093      9.849      0.000       0.733       1.100
answer_changed        0.9107      0.130      7.004      0.000       0.654       1.168
p1:answer_changed    -0.1833      0.148     -1.243      0.216      -0.475       0.108
==============================================================================
Omnibus:                       56.469   Durbin-Watson:                   2.146
Prob(Omnibus):                  0.000   Jarque-Bera (JB):              147.529
Skew:                           1.539   Prob(JB):                     9.22e-33
Kurtosis:                       6.738   Cond. No.                         33.5
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-1.48, p=0.14
Wilcoxon delta_H: statistic=449.00, p=0.104
Mean ΔH = -0.0808  [-0.1874, 0.0259]
Paired t-test delta_H Changed: statistic=6.19, p=1.5e-06
Wilcoxon delta_H Changed: statistic=21.00, p=5.25e-05
Mean ΔH Changed = 0.7561  [0.5169, 0.9954]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=-0.70, p=0.482
Wilcoxon (p_top2_game vs p_top2_base): statistic=929.00, p=0.0958
Mean Δp_top2 = -0.0028  [-0.0106, 0.0050] (n=151)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=1.23, p=0.221
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=1242.00, p=0.252
Mean ΔH_unchosen_baseline_set = 0.0689  [-0.0410, 0.1788] (n=151)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  151
Model:                          Logit   Df Residuals:                      148
Method:                           MLE   Df Model:                            2
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.05851
Time:                        09:26:42   Log-Likelihood:                -66.758
converged:                       True   LL-Null:                       -70.907
Covariance Type:            nonrobust   LLR p-value:                   0.01579
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.6158      0.287     -5.628      0.000      -2.179      -1.053
p1_z            -0.4961      0.503     -0.987      0.324      -1.481       0.489
I(p1_z ** 2)     0.0102      0.191      0.054      0.957      -0.364       0.385
================================================================================
AUC = 0.616

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  151
Model:                          Logit   Df Residuals:                      149
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1956
Time:                        09:26:42   Log-Likelihood:                -57.040
converged:                       True   LL-Null:                       -70.907
Covariance Type:            nonrobust   LLR p-value:                 1.392e-07
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -3.3551      0.476     -7.042      0.000      -4.289      -2.421
game_entropy     3.4579      0.713      4.849      0.000       2.060       4.856
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=1165.00, p=0.799
Paired t-test (game_entropy vs capabilities_entropy): statistic=0.44, p=0.662
Mean capabilities_entropy-game_entropy = -0.0134  [-0.0733, 0.0465] (n=151)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  151
Model:                          Logit   Df Residuals:                      148
Method:                           MLE   Df Model:                            2
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.2609
Time:                        09:26:42   Log-Likelihood:                -52.409
converged:                       True   LL-Null:                       -70.907
Covariance Type:            nonrobust   LLR p-value:                 9.262e-09
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -4.6054      0.707     -6.514      0.000      -5.991      -3.220
capabilities_entropy     2.3533      0.765      3.077      0.002       0.855       3.852
game_entropy             3.5802      0.754      4.746      0.000       2.102       5.059
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['Video games', 'Sports', 'History', 'TV shows']
                  Grouped rare answer_type into 'Misc'/'Other': None
topic_grouped           answer_changed
Art                     0                 0.800000
                        1                 0.200000
Geography               0                 0.571429
                        1                 0.428571
Misc                    0                 0.814815
                        1                 0.185185
Music                   0                 0.909091
                        1                 0.090909
Other                   0                 0.714286
                        1                 0.285714
Politics                0                 0.913043
                        1                 0.086957
Science and technology  0                 0.933333
                        1                 0.066667
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.730769
                     1                 0.269231
Number               0                 0.733333
                     1                 0.266667
Other                0                 0.897436
                     1                 0.102564
Person               0                 0.870968
                     1                 0.129032
Place                0                 0.928571
                     1                 0.071429
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.500000  0.500000            6
                       Number               1.000000  0.000000            1
                       Other                0.800000  0.200000            5
                       Person               0.909091  0.090909           11
                       Place                1.000000  0.000000            2
Geography              Date                 0.000000  1.000000            2
                       Number               0.500000  0.500000            6
                       Other                1.000000  0.000000            3
                       Place                0.666667  0.333333            3
Misc                   Date                 0.777778  0.222222            9
                       Number               1.000000  0.000000            3
                       Other                0.875000  0.125000            8
                       Person               0.600000  0.400000            5
                       Place                1.000000  0.000000            2
Music                  Date                 0.800000  0.200000            5
                       Other                1.000000  0.000000            3
                       Person               1.000000  0.000000            3
Other                  Date                 0.700000  0.300000           10
                       Number               1.000000  0.000000            1
                       Other                0.500000  0.500000            4
                       Person               0.750000  0.250000            4
                       Place                1.000000  0.000000            2
Politics               Date                 0.875000  0.125000            8
                       Number               0.000000  1.000000            1
                       Other                1.000000  0.000000            6
                       Person               1.000000  0.000000            4
                       Place                1.000000  0.000000            4
Science and technology Date                 0.833333  0.166667           12
                       Number               1.000000  0.000000            3
                       Other                1.000000  0.000000           10
                       Person               1.000000  0.000000            4
                       Place                1.000000  0.000000            1

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  151
Model:                          Logit   Df Residuals:                      139
Method:                           MLE   Df Model:                           11
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1593
Time:                        09:26:42   Log-Likelihood:                -59.609
converged:                       True   LL-Null:                       -70.907
Covariance Type:            nonrobust   LLR p-value:                   0.02014
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      4.2291      3.197      1.323      0.186      -2.037      10.495
C(topic_grouped)[T.Geography]                  1.3462      0.911      1.478      0.139      -0.439       3.131
C(topic_grouped)[T.Misc]                      -0.1695      0.749     -0.226      0.821      -1.637       1.298
C(topic_grouped)[T.Music]                     -1.1478      1.201     -0.955      0.339      -3.503       1.207
C(topic_grouped)[T.Other]                      0.2370      0.749      0.316      0.752      -1.231       1.705
C(topic_grouped)[T.Politics]                  -0.8091      0.944     -0.858      0.391      -2.658       1.040
C(topic_grouped)[T.Science and technology]    -1.3061      0.942     -1.386      0.166      -3.153       0.541
C(answer_type_grouped)[T.Number]              -0.6007      0.880     -0.682      0.495      -2.326       1.125
C(answer_type_grouped)[T.Other]               -1.5112      0.675     -2.239      0.025      -2.834      -0.188
C(answer_type_grouped)[T.Person]              -0.9859      0.668     -1.475      0.140      -2.296       0.324
C(answer_type_grouped)[T.Place]               -2.1337      1.190     -1.794      0.073      -4.465       0.198
q_length                                      -1.0870      0.714     -1.523      0.128      -2.486       0.312
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.4401
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  151
Model:                          Logit   Df Residuals:                      138
Method:                           MLE   Df Model:                           12
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.2107
Time:                        09:26:42   Log-Likelihood:                -55.964
converged:                       True   LL-Null:                       -70.907
Covariance Type:            nonrobust   LLR p-value:                  0.002905
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      2.0862      3.507      0.595      0.552      -4.787       8.960
C(topic_grouped)[T.Geography]                  1.2866      0.963      1.336      0.182      -0.601       3.174
C(topic_grouped)[T.Misc]                      -0.1941      0.795     -0.244      0.807      -1.752       1.364
C(topic_grouped)[T.Music]                     -1.5440      1.302     -1.186      0.236      -4.096       1.008
C(topic_grouped)[T.Other]                      0.1792      0.781      0.229      0.819      -1.352       1.710
C(topic_grouped)[T.Politics]                  -1.0527      1.020     -1.032      0.302      -3.052       0.947
C(topic_grouped)[T.Science and technology]    -1.3995      0.976     -1.434      0.152      -3.313       0.514
C(answer_type_grouped)[T.Number]              -0.8045      0.955     -0.842      0.400      -2.676       1.067
C(answer_type_grouped)[T.Other]               -1.2957      0.690     -1.879      0.060      -2.647       0.056
C(answer_type_grouped)[T.Person]              -0.8594      0.696     -1.235      0.217      -2.223       0.504
C(answer_type_grouped)[T.Place]               -2.4607      1.247     -1.974      0.048      -4.904      -0.017
q_length                                      -0.8358      0.769     -1.087      0.277      -2.342       0.671
capabilities_entropy                           2.2412      0.866      2.587      0.010       0.543       3.939
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  151
Model:                          Logit   Df Residuals:                      138
Method:                           MLE   Df Model:                           12
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.3537
Time:                        09:26:42   Log-Likelihood:                -45.830
converged:                       True   LL-Null:                       -70.907
Covariance Type:            nonrobust   LLR p-value:                 1.313e-06
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      3.7620      3.595      1.046      0.295      -3.284      10.808
C(topic_grouped)[T.Geography]                  1.1110      1.022      1.087      0.277      -0.892       3.114
C(topic_grouped)[T.Misc]                      -0.5655      0.884     -0.640      0.522      -2.298       1.167
C(topic_grouped)[T.Music]                     -1.6200      1.423     -1.138      0.255      -4.409       1.169
C(topic_grouped)[T.Other]                     -0.8702      0.951     -0.915      0.360      -2.734       0.993
C(topic_grouped)[T.Politics]                  -2.2579      1.212     -1.862      0.063      -4.634       0.118
C(topic_grouped)[T.Science and technology]    -1.6951      1.060     -1.599      0.110      -3.773       0.383
C(answer_type_grouped)[T.Number]               0.0430      1.003      0.043      0.966      -1.923       2.009
C(answer_type_grouped)[T.Other]               -1.3449      0.795     -1.692      0.091      -2.903       0.213
C(answer_type_grouped)[T.Person]              -1.0178      0.834     -1.221      0.222      -2.652       0.616
C(answer_type_grouped)[T.Place]               -1.2589      1.282     -0.982      0.326      -3.771       1.253
q_length                                      -1.4171      0.814     -1.740      0.082      -3.013       0.179
game_entropy                                   4.3035      0.994      4.329      0.000       2.355       6.252
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  151
Model:                          Logit   Df Residuals:                      137
Method:                           MLE   Df Model:                           13
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.3937
Time:                        09:26:42   Log-Likelihood:                -42.991
converged:                       True   LL-Null:                       -70.907
Covariance Type:            nonrobust   LLR p-value:                 2.887e-07
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      1.6693      3.856      0.433      0.665      -5.889       9.227
C(topic_grouped)[T.Geography]                  1.1444      1.101      1.039      0.299      -1.014       3.303
C(topic_grouped)[T.Misc]                      -0.5945      0.947     -0.628      0.530      -2.451       1.262
C(topic_grouped)[T.Music]                     -1.6502      1.379     -1.197      0.231      -4.353       1.052
C(topic_grouped)[T.Other]                     -0.8392      0.976     -0.860      0.390      -2.752       1.073
C(topic_grouped)[T.Politics]                  -2.4242      1.263     -1.919      0.055      -4.900       0.052
C(topic_grouped)[T.Science and technology]    -1.6247      1.067     -1.523      0.128      -3.715       0.466
C(answer_type_grouped)[T.Number]              -0.0381      1.095     -0.035      0.972      -2.183       2.107
C(answer_type_grouped)[T.Other]               -1.0597      0.826     -1.283      0.200      -2.679       0.559
C(answer_type_grouped)[T.Person]              -0.8407      0.844     -0.996      0.319      -2.495       0.813
C(answer_type_grouped)[T.Place]               -1.5437      1.373     -1.124      0.261      -4.235       1.148
q_length                                      -1.1995      0.851     -1.409      0.159      -2.868       0.469
capabilities_entropy                           2.1495      0.947      2.270      0.023       0.293       4.006
game_entropy                                   4.3408      1.022      4.246      0.000       2.337       6.345
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing claude-3-haiku-20240307 (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/claude-3-haiku-20240307_SimpleMC_redacted_temp0.0_1754183680_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    253
1     96
Name: count, dtype: int64

Answer change%: 0.2751 [0.2282220396630573, 0.32192122681258745] (n=349)
P-value vs 25%: 0.2942; P-value vs 0%: 1.207e-30
Phase 2 self-accuracy: 0.3438 [0.2487401820076643, 0.4387598179923357] (n=96)
P-value vs 25%: 0.05312; P-value vs 33%: 0.8245

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  349
Model:                          Logit   Df Residuals:                      347
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.03241
Time:                        09:26:42   Log-Likelihood:                -198.64
converged:                       True   LL-Null:                       -205.30
Covariance Type:            nonrobust   LLR p-value:                 0.0002643
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          1.8955      0.787      2.409      0.016       0.353       3.438
p_i_capability    -3.2051      0.875     -3.663      0.000      -4.920      -1.490
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  349
Model:                          Logit   Df Residuals:                      347
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.03280
Time:                        09:26:42   Log-Likelihood:                -198.56
converged:                       True   LL-Null:                       -205.30
Covariance Type:            nonrobust   LLR p-value:                 0.0002427
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.6404      0.224     -7.318      0.000      -2.080      -1.201
capabilities_entropy     1.4480      0.394      3.676      0.000       0.676       2.220
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.2917 [0.2007, 0.3826] (n=96)
                  P-value vs 33.3%: 0.3691

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=0.88, p=0.379
Wilcoxon delta_p: statistic=2777.00, p=0.0896
Mean Δp = 0.0075  [-0.0092, 0.0241]
Idea 1 N = 253; 

  Idea 1.5: Calibration Metrics
  NLL: 4.1953, Signed ECE (overconf pos under neg): 0.0394, ECE: 0.0394 (n=349)
  Brier: 0.0097, Reliability (absolute calibration error; lower better): 0.0095, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=349)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.898
Model:                            OLS   Adj. R-squared:                  0.897
Method:                 Least Squares   F-statistic:                     1013.
Date:                Sat, 20 Sep 2025   Prob (F-statistic):          1.22e-170
Time:                        09:26:42   Log-Likelihood:                 255.98
No. Observations:                 349   AIC:                            -504.0
Df Residuals:                     345   BIC:                            -488.5
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.7557      0.066    -11.391      0.000      -0.886      -0.625
p1                    0.8307      0.072     11.575      0.000       0.690       0.972
answer_changed        0.6078      0.091      6.690      0.000       0.429       0.786
p1:answer_changed     0.1952      0.101      1.936      0.054      -0.003       0.393
==============================================================================
Omnibus:                       41.234   Durbin-Watson:                   2.008
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               65.374
Skew:                           0.738   Prob(JB):                     6.37e-15
Kurtosis:                       4.523   Cond. No.                         35.1
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=1.05, p=0.295
Wilcoxon delta_H: statistic=3025.00, p=0.311
Mean ΔH = 0.0427  [-0.0371, 0.1225]
Paired t-test delta_H Changed: statistic=13.10, p=5.22e-23
Wilcoxon delta_H Changed: statistic=234.00, p=1.87e-14
Mean ΔH Changed = 0.8910  [0.7577, 1.0243]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=-0.31, p=0.761
Wilcoxon (p_top2_game vs p_top2_base): statistic=8305.50, p=0.175
Mean Δp_top2 = -0.0007  [-0.0049, 0.0036] (n=349)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=6.84, p=3.63e-11
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=5563.00, p=1.51e-10
Mean ΔH_unchosen_baseline_set = 0.2760  [0.1969, 0.3551] (n=349)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  349
Model:                          Logit   Df Residuals:                      346
Method:                           MLE   Df Model:                            2
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.03923
Time:                        09:26:42   Log-Likelihood:                -197.24
converged:                       True   LL-Null:                       -205.30
Covariance Type:            nonrobust   LLR p-value:                 0.0003176
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.2387      0.195     -6.342      0.000      -1.621      -0.856
p1_z             0.1423      0.357      0.398      0.691      -0.558       0.843
I(p1_z ** 2)     0.2456      0.153      1.604      0.109      -0.054       0.546
================================================================================
AUC = 0.581

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  349
Model:                          Logit   Df Residuals:                      347
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1058
Time:                        09:26:42   Log-Likelihood:                -183.58
converged:                       True   LL-Null:                       -205.30
Covariance Type:            nonrobust   LLR p-value:                 4.390e-11
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -2.2785      0.252     -9.039      0.000      -2.773      -1.784
game_entropy     2.4114      0.386      6.241      0.000       1.654       3.169
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=6739.00, p=0.000741
Paired t-test (game_entropy vs capabilities_entropy): statistic=3.06, p=0.00236
Mean capabilities_entropy-game_entropy = -0.0624  [-0.1023, -0.0225] (n=349)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  349
Model:                          Logit   Df Residuals:                      346
Method:                           MLE   Df Model:                            2
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1211
Time:                        09:26:42   Log-Likelihood:                -180.44
converged:                       True   LL-Null:                       -205.30
Covariance Type:            nonrobust   LLR p-value:                 1.597e-11
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.6924      0.310     -8.674      0.000      -3.301      -2.084
capabilities_entropy     1.0684      0.421      2.536      0.011       0.243       1.894
game_entropy             2.2619      0.393      5.758      0.000       1.492       3.032
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.720000
                        1                 0.280000
Geography               0                 0.600000
                        1                 0.400000
Misc                    0                 0.733333
                        1                 0.266667
Music                   0                 0.724138
                        1                 0.275862
Other                   0                 0.709677
                        1                 0.290323
Politics                0                 0.833333
                        1                 0.166667
Science and technology  0                 0.705882
                        1                 0.294118
Sports                  0                 0.718750
                        1                 0.281250
TV shows                0                 0.720000
                        1                 0.280000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.735043
                     1                 0.264957
Number               0                 0.746032
                     1                 0.253968
Other                0                 0.712500
                     1                 0.287500
Person               0                 0.707865
                     1                 0.292135
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.800000  0.200000           15
                       Number               0.375000  0.625000            8
                       Other                0.636364  0.363636           11
                       Person               0.875000  0.125000           16
Geography              Date                 0.615385  0.384615           13
                       Number               0.666667  0.333333           12
                       Other                0.400000  0.600000            5
Misc                   Date                 0.538462  0.461538           13
                       Number               1.000000  0.000000            5
                       Other                0.857143  0.142857            7
                       Person               0.800000  0.200000            5
Music                  Date                 0.428571  0.571429            7
                       Number               1.000000  0.000000            4
                       Other                0.777778  0.222222            9
                       Person               0.777778  0.222222            9
Other                  Date                 0.875000  0.125000            8
                       Number               0.833333  0.166667            6
                       Other                0.500000  0.500000            8
                       Person               0.666667  0.333333            9
Politics               Date                 0.892857  0.107143           28
                       Number               0.800000  0.200000            5
                       Other                0.900000  0.100000           10
                       Person               0.636364  0.363636           11
Science and technology Date                 0.782609  0.217391           23
                       Number               0.727273  0.272727           11
                       Other                0.875000  0.125000            8
                       Person               0.576923  0.423077           26
Sports                 Date                 0.625000  0.375000            8
                       Number               0.818182  0.181818           11
                       Other                0.666667  0.333333            9
                       Person               0.750000  0.250000            4
TV shows               Date                 0.500000  0.500000            2
                       Number               1.000000  0.000000            1
                       Other                0.692308  0.307692           13
                       Person               0.777778  0.222222            9

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  349
Model:                          Logit   Df Residuals:                      336
Method:                           MLE   Df Model:                           12
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.01719
Time:                        09:26:42   Log-Likelihood:                -201.77
converged:                       True   LL-Null:                       -205.30
Covariance Type:            nonrobust   LLR p-value:                    0.8536
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.6799      1.543     -1.089      0.276      -4.703       1.344
C(topic_grouped)[T.Geography]                  0.6589      0.504      1.307      0.191      -0.329       1.647
C(topic_grouped)[T.Misc]                      -0.0531      0.523     -0.102      0.919      -1.078       0.972
C(topic_grouped)[T.Music]                     -0.0201      0.524     -0.038      0.969      -1.046       1.006
C(topic_grouped)[T.Other]                      0.0609      0.507      0.120      0.904      -0.933       1.055
C(topic_grouped)[T.Politics]                  -0.6882      0.491     -1.402      0.161      -1.650       0.274
C(topic_grouped)[T.Science and technology]     0.0639      0.415      0.154      0.877      -0.749       0.876
C(topic_grouped)[T.Sports]                     0.0605      0.511      0.119      0.906      -0.941       1.062
C(topic_grouped)[T.TV shows]                  -0.0424      0.556     -0.076      0.939      -1.132       1.047
C(answer_type_grouped)[T.Number]              -0.2152      0.369     -0.583      0.560      -0.939       0.509
C(answer_type_grouped)[T.Other]                0.1055      0.340      0.310      0.756      -0.561       0.772
C(answer_type_grouped)[T.Person]               0.1676      0.331      0.507      0.612      -0.480       0.816
q_length                                       0.1540      0.331      0.466      0.642      -0.494       0.802
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.4433
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  349
Model:                          Logit   Df Residuals:                      335
Method:                           MLE   Df Model:                           13
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.05088
Time:                        09:26:42   Log-Likelihood:                -194.85
converged:                       True   LL-Null:                       -205.30
Covariance Type:            nonrobust   LLR p-value:                   0.07514
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -2.6374      1.612     -1.636      0.102      -5.798       0.523
C(topic_grouped)[T.Geography]                  0.7564      0.516      1.466      0.143      -0.255       1.768
C(topic_grouped)[T.Misc]                      -0.0631      0.534     -0.118      0.906      -1.110       0.984
C(topic_grouped)[T.Music]                     -0.0826      0.541     -0.153      0.879      -1.142       0.977
C(topic_grouped)[T.Other]                      0.0442      0.520      0.085      0.932      -0.975       1.063
C(topic_grouped)[T.Politics]                  -0.6481      0.499     -1.298      0.194      -1.626       0.330
C(topic_grouped)[T.Science and technology]     0.0468      0.424      0.110      0.912      -0.784       0.877
C(topic_grouped)[T.Sports]                    -0.0210      0.523     -0.040      0.968      -1.046       1.004
C(topic_grouped)[T.TV shows]                  -0.0508      0.567     -0.089      0.929      -1.162       1.061
C(answer_type_grouped)[T.Number]              -0.1735      0.377     -0.460      0.646      -0.913       0.566
C(answer_type_grouped)[T.Other]                0.1352      0.348      0.389      0.697      -0.546       0.816
C(answer_type_grouped)[T.Person]               0.2726      0.341      0.800      0.423      -0.395       0.940
q_length                                       0.2042      0.341      0.599      0.549      -0.464       0.872
capabilities_entropy                           1.4985      0.405      3.700      0.000       0.705       2.292
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  349
Model:                          Logit   Df Residuals:                      335
Method:                           MLE   Df Model:                           13
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1296
Time:                        09:26:42   Log-Likelihood:                -178.68
converged:                       True   LL-Null:                       -205.30
Covariance Type:            nonrobust   LLR p-value:                 8.260e-07
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -3.9283      1.731     -2.270      0.023      -7.320      -0.536
C(topic_grouped)[T.Geography]                  0.8341      0.546      1.526      0.127      -0.237       1.905
C(topic_grouped)[T.Misc]                       0.1279      0.562      0.228      0.820      -0.973       1.229
C(topic_grouped)[T.Music]                      0.1111      0.579      0.192      0.848      -1.023       1.245
C(topic_grouped)[T.Other]                      0.4776      0.545      0.877      0.381      -0.590       1.545
C(topic_grouped)[T.Politics]                  -0.6858      0.525     -1.305      0.192      -1.716       0.344
C(topic_grouped)[T.Science and technology]     0.2485      0.445      0.558      0.577      -0.624       1.121
C(topic_grouped)[T.Sports]                    -0.0719      0.557     -0.129      0.897      -1.163       1.019
C(topic_grouped)[T.TV shows]                  -0.2836      0.623     -0.455      0.649      -1.504       0.937
C(answer_type_grouped)[T.Number]              -0.4394      0.396     -1.108      0.268      -1.216       0.338
C(answer_type_grouped)[T.Other]               -0.1621      0.370     -0.438      0.661      -0.888       0.563
C(answer_type_grouped)[T.Person]               0.0010      0.355      0.003      0.998      -0.695       0.697
q_length                                       0.3465      0.363      0.954      0.340      -0.365       1.058
game_entropy                                   2.6446      0.420      6.293      0.000       1.821       3.468
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  349
Model:                          Logit   Df Residuals:                      334
Method:                           MLE   Df Model:                           14
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1446
Time:                        09:26:42   Log-Likelihood:                -175.60
converged:                       True   LL-Null:                       -205.30
Covariance Type:            nonrobust   LLR p-value:                 1.504e-07
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -4.4099      1.766     -2.497      0.013      -7.872      -0.948
C(topic_grouped)[T.Geography]                  0.8725      0.548      1.591      0.112      -0.202       1.947
C(topic_grouped)[T.Misc]                       0.1055      0.564      0.187      0.852      -1.001       1.212
C(topic_grouped)[T.Music]                      0.0369      0.590      0.063      0.950      -1.120       1.194
C(topic_grouped)[T.Other]                      0.4250      0.548      0.776      0.438      -0.649       1.499
C(topic_grouped)[T.Politics]                  -0.6724      0.527     -1.275      0.202      -1.706       0.361
C(topic_grouped)[T.Science and technology]     0.2118      0.448      0.473      0.636      -0.666       1.089
C(topic_grouped)[T.Sports]                    -0.1405      0.563     -0.249      0.803      -1.245       0.963
C(topic_grouped)[T.TV shows]                  -0.3050      0.634     -0.481      0.630      -1.547       0.937
C(answer_type_grouped)[T.Number]              -0.3915      0.399     -0.980      0.327      -1.174       0.391
C(answer_type_grouped)[T.Other]               -0.1437      0.371     -0.387      0.699      -0.872       0.584
C(answer_type_grouped)[T.Person]               0.0778      0.364      0.214      0.831      -0.636       0.791
q_length                                       0.3587      0.368      0.974      0.330      -0.363       1.080
capabilities_entropy                           1.0930      0.437      2.504      0.012       0.237       1.949
game_entropy                                   2.4834      0.428      5.805      0.000       1.645       3.322
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing claude-3-sonnet-20240229 (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/claude-3-sonnet-20240229_SimpleMC_redacted_cor_temp0.0_1751757346_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    107
1     45
Name: count, dtype: int64

Answer change%: 0.2961 [0.22347866592810672, 0.36862659722978797] (n=152)
P-value vs 25%: 0.2136; P-value vs 0%: 1.292e-15
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=45)
P-value vs 25%: 0; P-value vs 33%: 0
                  Grouped rare topic into 'Misc'/'Other': ['Sports', 'TV shows', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.766667
                        1                 0.233333
Geography               0                 0.571429
                        1                 0.428571
Misc                    0                 0.750000
                        1                 0.250000
Music                   0                 0.857143
                        1                 0.142857
Other                   0                 0.750000
                        1                 0.250000
Politics                0                 0.619048
                        1                 0.380952
Science and technology  0                 0.636364
                        1                 0.363636
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.641791
                     1                 0.358209
Number               0                 0.550000
                     1                 0.450000
Other                0                 0.848485
                     1                 0.151515
Person               0                 0.781250
                     1                 0.218750
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.555556  0.444444            9
                       Number               1.000000  0.000000            3
                       Other                1.000000  0.000000            6
                       Person               0.750000  0.250000           12
Geography              Date                 0.500000  0.500000            4
                       Number               0.571429  0.428571            7
                       Other                0.666667  0.333333            3
Misc                   Date                 0.769231  0.230769           13
                       Number               0.500000  0.500000            4
                       Other                0.666667  0.333333            6
                       Person               1.000000  0.000000            5
Music                  Date                 1.000000  0.000000            5
                       Number               0.000000  1.000000            1
                       Other                1.000000  0.000000            3
                       Person               0.800000  0.200000            5
Other                  Date                 0.833333  0.166667            6
                       Number               0.000000  1.000000            1
                       Other                0.666667  0.333333            3
                       Person               1.000000  0.000000            2
Politics               Date                 0.461538  0.538462           13
                       Other                0.833333  0.166667            6
                       Person               1.000000  0.000000            2
Science and technology Date                 0.588235  0.411765           17
                       Number               0.500000  0.500000            4
                       Other                1.000000  0.000000            6
                       Person               0.500000  0.500000            6

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  152
Model:                          Logit   Df Residuals:                      141
Method:                           MLE   Df Model:                           10
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.06624
Time:                        09:26:42   Log-Likelihood:                -86.221
converged:                       True   LL-Null:                       -92.337
Covariance Type:            nonrobust   LLR p-value:                    0.2698
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.9415      2.433     -0.798      0.425      -6.710       2.827
C(topic_grouped)[T.Geography]                  0.5878      0.762      0.771      0.440      -0.905       2.081
C(topic_grouped)[T.Misc]                      -0.0342      0.636     -0.054      0.957      -1.281       1.212
C(topic_grouped)[T.Music]                     -0.6190      0.889     -0.696      0.486      -2.361       1.123
C(topic_grouped)[T.Other]                      0.0341      0.817      0.042      0.967      -1.567       1.635
C(topic_grouped)[T.Politics]                   0.6288      0.685      0.917      0.359      -0.715       1.972
C(topic_grouped)[T.Science and technology]     0.4625      0.596      0.775      0.438      -0.706       1.631
C(answer_type_grouped)[T.Number]               0.3621      0.569      0.636      0.525      -0.753       1.478
C(answer_type_grouped)[T.Other]               -1.1111      0.558     -1.992      0.046      -2.204      -0.018
C(answer_type_grouped)[T.Person]              -0.4790      0.525     -0.913      0.361      -1.507       0.549
q_length                                       0.2424      0.534      0.454      0.650      -0.803       1.288
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing claude-3-sonnet-20240229 (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/claude-3-sonnet-20240229_SimpleMC_redacted_temp0.0_1751717606_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    201
1    147
Name: count, dtype: int64

Answer change%: 0.4224 [0.37051754977978874, 0.47431003642710784] (n=348)
P-value vs 25%: 7.438e-11; P-value vs 0%: 2.703e-57
Phase 2 self-accuracy: 0.3333 [0.2571283860895982, 0.4095382805770684] (n=147)
P-value vs 25%: 0.03209; P-value vs 33%: 0.9932
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': None
topic_grouped           answer_changed
Art                     0                 0.533333
                        1                 0.466667
Geography               0                 0.566667
                        1                 0.433333
Misc                    0                 0.618182
                        1                 0.381818
Music                   0                 0.807692
                        1                 0.192308
Other                   1                 0.550000
                        0                 0.450000
Politics                0                 0.535714
                        1                 0.464286
Science and technology  0                 0.615385
                        1                 0.384615
Sports                  0                 0.548387
                        1                 0.451613
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.539216
                     1                 0.460784
Number               1                 0.551724
                     0                 0.448276
Other                0                 0.689189
                     1                 0.310811
Person               0                 0.602273
                     1                 0.397727
Place                0                 0.615385
                     1                 0.384615
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.500000  0.500000           12
                       Number               0.333333  0.666667            6
                       Other                0.600000  0.400000           10
                       Person               0.533333  0.466667           15
                       Place                1.000000  0.000000            2
Geography              Date                 0.545455  0.454545           11
                       Number               0.545455  0.454545           11
                       Other                1.000000  0.000000            1
                       Place                0.571429  0.428571            7
Misc                   Date                 0.583333  0.416667           12
                       Number               0.428571  0.571429            7
                       Other                0.666667  0.333333           21
                       Person               0.615385  0.384615           13
                       Place                1.000000  0.000000            2
Music                  Date                 0.571429  0.428571            7
                       Number               1.000000  0.000000            3
                       Other                0.875000  0.125000            8
                       Person               0.857143  0.142857            7
                       Place                1.000000  0.000000            1
Other                  Date                 0.333333  0.666667           12
                       Number               0.333333  0.666667            6
                       Other                0.857143  0.142857            7
                       Person               0.454545  0.545455           11
                       Place                0.250000  0.750000            4
Politics               Date                 0.652174  0.347826           23
                       Number               0.166667  0.833333            6
                       Other                0.666667  0.333333            9
                       Person               0.384615  0.615385           13
                       Place                0.600000  0.400000            5
Science and technology Date                 0.500000  0.500000           18
                       Number               0.500000  0.500000           10
                       Other                0.700000  0.300000           10
                       Person               0.708333  0.291667           24
                       Place                0.666667  0.333333            3
Sports                 Date                 0.571429  0.428571            7
                       Number               0.444444  0.555556            9
                       Other                0.500000  0.500000            8
                       Person               0.800000  0.200000            5
                       Place                0.500000  0.500000            2

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  348
Model:                          Logit   Df Residuals:                      335
Method:                           MLE   Df Model:                           12
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.04120
Time:                        09:26:42   Log-Likelihood:                -227.24
converged:                       True   LL-Null:                       -237.01
Covariance Type:            nonrobust   LLR p-value:                   0.07656
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      1.3418      1.388      0.967      0.334      -1.378       4.062
C(topic_grouped)[T.Geography]                 -0.4031      0.502     -0.803      0.422      -1.387       0.581
C(topic_grouped)[T.Misc]                      -0.2885      0.416     -0.694      0.488      -1.103       0.526
C(topic_grouped)[T.Music]                     -1.3144      0.587     -2.240      0.025      -2.465      -0.164
C(topic_grouped)[T.Other]                      0.2956      0.443      0.667      0.505      -0.573       1.164
C(topic_grouped)[T.Politics]                  -0.0012      0.412     -0.003      0.998      -0.808       0.805
C(topic_grouped)[T.Science and technology]    -0.3814      0.399     -0.957      0.339      -1.163       0.400
C(topic_grouped)[T.Sports]                    -0.1383      0.480     -0.288      0.773      -1.079       0.802
C(answer_type_grouped)[T.Number]               0.4147      0.342      1.214      0.225      -0.255       1.084
C(answer_type_grouped)[T.Other]               -0.6382      0.335     -1.907      0.057      -1.294       0.018
C(answer_type_grouped)[T.Person]              -0.2832      0.306     -0.924      0.355      -0.884       0.317
C(answer_type_grouped)[T.Place]               -0.3311      0.460     -0.720      0.472      -1.233       0.570
q_length                                      -0.2855      0.296     -0.965      0.334      -0.865       0.294
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing claude-opus-4-1-20250805 (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/claude-opus-4-1-20250805_SimpleMC_redacted_cor_temp0.0_1758371084_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    294
1     48
Name: count, dtype: int64

Answer change%: 0.1404 [0.10353770723845743, 0.17716404714750747] (n=342)
P-value vs 25%: 5.289e-09; P-value vs 0%: 7.875e-14
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=48)
P-value vs 25%: 0; P-value vs 33%: 0
                  Grouped rare topic into 'Misc'/'Other': ['History', 'TV shows', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.944444
                        1                 0.055556
Geography               0                 0.833333
                        1                 0.166667
Misc                    0                 0.888889
                        1                 0.111111
Music                   0                 0.846154
                        1                 0.153846
Other                   0                 0.823529
                        1                 0.176471
Politics                0                 0.787234
                        1                 0.212766
Science and technology  0                 0.876923
                        1                 0.123077
Sports                  0                 0.807692
                        1                 0.192308
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.877049
                     1                 0.122951
Number               0                 0.780000
                     1                 0.220000
Other                0                 0.860215
                     1                 0.139785
Person               0                 0.883117
                     1                 0.116883
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.928571  0.071429           14
                       Number               1.000000  0.000000            5
                       Other                1.000000  0.000000           14
                       Person               0.904762  0.095238           21
Geography              Date                 0.909091  0.090909           11
                       Number               0.764706  0.235294           17
                       Other                0.875000  0.125000            8
Misc                   Date                 0.947368  0.052632           19
                       Number               1.000000  0.000000            7
                       Other                0.722222  0.277778           18
                       Person               1.000000  0.000000           10
Music                  Date                 0.857143  0.142857            7
                       Number               0.500000  0.500000            2
                       Other                0.875000  0.125000            8
                       Person               0.888889  0.111111            9
Other                  Date                 0.769231  0.230769           13
                       Number               0.250000  0.750000            4
                       Other                1.000000  0.000000           10
                       Person               1.000000  0.000000            7
Politics               Date                 0.826087  0.173913           23
                       Number               1.000000  0.000000            1
                       Other                0.733333  0.266667           15
                       Person               0.750000  0.250000            8
Science and technology Date                 0.925926  0.074074           27
                       Number               0.777778  0.222222            9
                       Other                0.923077  0.076923           13
                       Person               0.812500  0.187500           16
Sports                 Date                 0.750000  0.250000            8
                       Number               0.800000  0.200000            5
                       Other                0.857143  0.142857            7
                       Person               0.833333  0.166667            6

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  342
Model:                          Logit   Df Residuals:                      330
Method:                           MLE   Df Model:                           11
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.04810
Time:                        09:26:42   Log-Likelihood:                -132.04
converged:                       True   LL-Null:                       -138.72
Covariance Type:            nonrobust   LLR p-value:                    0.2715
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -6.0615      1.998     -3.034      0.002      -9.978      -2.145
C(topic_grouped)[T.Geography]                  0.9358      0.783      1.196      0.232      -0.598       2.470
C(topic_grouped)[T.Misc]                       0.7219      0.744      0.971      0.332      -0.735       2.179
C(topic_grouped)[T.Music]                      1.2032      0.810      1.486      0.137      -0.384       2.790
C(topic_grouped)[T.Other]                      1.3196      0.753      1.752      0.080      -0.157       2.796
C(topic_grouped)[T.Politics]                   1.4282      0.718      1.988      0.047       0.020       2.836
C(topic_grouped)[T.Science and technology]     0.8121      0.712      1.141      0.254      -0.583       2.208
C(topic_grouped)[T.Sports]                     1.3279      0.788      1.684      0.092      -0.217       2.873
C(answer_type_grouped)[T.Number]               0.8062      0.480      1.680      0.093      -0.134       1.747
C(answer_type_grouped)[T.Other]                0.1924      0.415      0.463      0.643      -0.621       1.006
C(answer_type_grouped)[T.Person]               0.1302      0.466      0.279      0.780      -0.784       1.044
q_length                                       0.6747      0.417      1.620      0.105      -0.142       1.491
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing claude-opus-4-1-20250805 (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/claude-opus-4-1-20250805_SimpleMC_redacted_temp0.0_1758370707_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
1    94
0    64
Name: count, dtype: int64

Answer change%: 0.5949 [0.5183917887039337, 0.6714816290175852] (n=158)
P-value vs 25%: 1.026e-18; P-value vs 0%: 2.116e-52
Phase 2 self-accuracy: 0.5638 [0.4635793734655892, 0.6640802010024959] (n=94)
P-value vs 25%: 8.485e-10; P-value vs 33%: 6.395e-06
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'Geography', 'Video games', 'History']
                  Grouped rare answer_type into 'Misc'/'Other': None
topic_grouped           answer_changed
Art                     0                 0.619048
                        1                 0.380952
Misc                    1                 0.678571
                        0                 0.321429
Music                   1                 0.714286
                        0                 0.285714
Other                   1                 0.777778
                        0                 0.222222
Politics                1                 0.600000
                        0                 0.400000
Science and technology  1                 0.515152
                        0                 0.484848
Sports                  1                 0.571429
                        0                 0.428571
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 1                 0.553191
                     0                 0.446809
Number               1                 0.571429
                     0                 0.428571
Other                1                 0.655172
                     0                 0.344828
Person               1                 0.534884
                     0                 0.465116
Place                1                 0.909091
                     0                 0.090909
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.714286  0.285714            7
                       Number               0.750000  0.250000            4
                       Other                0.500000  0.500000            2
                       Person               0.666667  0.333333            6
                       Place                0.000000  1.000000            2
Misc                   Date                 0.375000  0.625000            8
                       Number               0.333333  0.666667            3
                       Other                0.300000  0.700000           10
                       Person               0.400000  0.600000            5
                       Place                0.000000  1.000000            2
Music                  Date                 0.400000  0.600000            5
                       Number               0.500000  0.500000            2
                       Other                0.000000  1.000000            2
                       Person               0.333333  0.666667            3
                       Place                0.000000  1.000000            2
Other                  Date                 0.400000  0.600000            5
                       Number               0.333333  0.666667            3
                       Other                0.000000  1.000000            3
                       Person               0.166667  0.833333            6
                       Place                0.000000  1.000000            1
Politics               Date                 0.461538  0.538462           13
                       Number               0.200000  0.800000            5
                       Other                0.400000  0.600000            5
                       Person               0.428571  0.571429            7
Science and technology Date                 0.375000  0.625000            8
                       Number               0.400000  0.600000            5
                       Other                0.750000  0.250000            4
                       Person               0.500000  0.500000           14
                       Place                0.500000  0.500000            2
Sports                 Date                 0.000000  1.000000            1
                       Number               0.500000  0.500000            6
                       Other                0.333333  0.666667            3
                       Person               1.000000  0.000000            2
                       Place                0.000000  1.000000            2

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  158
Model:                          Logit   Df Residuals:                      146
Method:                           MLE   Df Model:                           11
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.07679
Time:                        09:26:42   Log-Likelihood:                -98.462
converged:                       True   LL-Null:                       -106.65
Covariance Type:            nonrobust   LLR p-value:                    0.1276
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -0.8918      2.222     -0.401      0.688      -5.247       3.463
C(topic_grouped)[T.Misc]                       1.2654      0.637      1.986      0.047       0.017       2.514
C(topic_grouped)[T.Music]                      1.4113      0.770      1.833      0.067      -0.098       2.920
C(topic_grouped)[T.Other]                      1.8672      0.744      2.510      0.012       0.409       3.325
C(topic_grouped)[T.Politics]                   1.0806      0.609      1.773      0.076      -0.114       2.275
C(topic_grouped)[T.Science and technology]     0.6496      0.600      1.082      0.279      -0.527       1.826
C(topic_grouped)[T.Sports]                     0.6466      0.751      0.861      0.389      -0.826       2.119
C(answer_type_grouped)[T.Number]               0.1882      0.515      0.365      0.715      -0.822       1.198
C(answer_type_grouped)[T.Other]                0.3718      0.526      0.707      0.479      -0.658       1.402
C(answer_type_grouped)[T.Person]              -0.0009      0.466     -0.002      0.998      -0.913       0.912
C(answer_type_grouped)[T.Place]                2.3150      1.129      2.050      0.040       0.101       4.529
q_length                                       0.0272      0.467      0.058      0.954      -0.888       0.942
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing claude-sonnet-4-20250514 (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/claude-sonnet-4-20250514_SimpleMC_redacted_cor_temp0.0_1751759842_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    155
1     64
Name: count, dtype: int64

Answer change%: 0.2922 [0.2320039907301435, 0.35247089511460533] (n=219)
P-value vs 25%: 0.1693; P-value vs 0%: 1.92e-21
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=64)
P-value vs 25%: 0; P-value vs 33%: 0
                  Grouped rare topic into 'Misc'/'Other': ['History', 'TV shows', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': None
topic_grouped           answer_changed
Art                     0                 0.815789
                        1                 0.184211
Geography               0                 0.619048
                        1                 0.380952
Misc                    0                 0.828571
                        1                 0.171429
Music                   0                 0.809524
                        1                 0.190476
Other                   0                 0.666667
                        1                 0.333333
Politics                0                 0.645161
                        1                 0.354839
Science and technology  0                 0.650000
                        1                 0.350000
Sports                  1                 0.533333
                        0                 0.466667
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.671053
                     1                 0.328947
Number               0                 0.612903
                     1                 0.387097
Other                0                 0.784314
                     1                 0.215686
Person               0                 0.760870
                     1                 0.239130
Place                0                 0.666667
                     1                 0.333333
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.666667  0.333333            9
                       Number               1.000000  0.000000            3
                       Other                1.000000  0.000000            8
                       Person               0.800000  0.200000           15
                       Place                0.666667  0.333333            3
Geography              Date                 0.250000  0.750000            4
                       Number               0.666667  0.333333            9
                       Other                1.000000  0.000000            3
                       Place                0.600000  0.400000            5
Misc                   Date                 0.846154  0.153846           13
                       Number               1.000000  0.000000            4
                       Other                0.692308  0.307692           13
                       Person               1.000000  0.000000            4
                       Place                1.000000  0.000000            1
Music                  Date                 0.875000  0.125000            8
                       Number               0.333333  0.666667            3
                       Other                1.000000  0.000000            2
                       Person               1.000000  0.000000            7
                       Place                0.000000  1.000000            1
Other                  Date                 0.500000  0.500000            6
                       Number               0.500000  0.500000            4
                       Other                0.750000  0.250000            4
                       Person               1.000000  0.000000            3
                       Place                1.000000  0.000000            1
Politics               Date                 0.666667  0.333333           15
                       Number               0.000000  1.000000            1
                       Other                0.800000  0.200000            5
                       Person               0.428571  0.571429            7
                       Place                1.000000  0.000000            3
Science and technology Date                 0.647059  0.352941           17
                       Number               0.500000  0.500000            4
                       Other                0.750000  0.250000           12
                       Person               0.666667  0.333333            6
                       Place                0.000000  1.000000            1
Sports                 Date                 0.500000  0.500000            4
                       Number               0.333333  0.666667            3
                       Other                0.500000  0.500000            4
                       Person               0.500000  0.500000            4

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  219
Model:                          Logit   Df Residuals:                      206
Method:                           MLE   Df Model:                           12
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.06208
Time:                        09:26:42   Log-Likelihood:                -124.09
converged:                       True   LL-Null:                       -132.31
Covariance Type:            nonrobust   LLR p-value:                    0.1725
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      0.7720      1.902      0.406      0.685      -2.956       4.500
C(topic_grouped)[T.Geography]                  0.7513      0.656      1.146      0.252      -0.534       2.036
C(topic_grouped)[T.Misc]                      -0.0925      0.629     -0.147      0.883      -1.325       1.140
C(topic_grouped)[T.Music]                     -0.0722      0.704     -0.103      0.918      -1.451       1.307
C(topic_grouped)[T.Other]                      0.6066      0.673      0.901      0.368      -0.713       1.926
C(topic_grouped)[T.Politics]                   0.9553      0.585      1.632      0.103      -0.192       2.103
C(topic_grouped)[T.Science and technology]     0.8830      0.551      1.603      0.109      -0.197       1.963
C(topic_grouped)[T.Sports]                     1.5514      0.678      2.288      0.022       0.222       2.881
C(answer_type_grouped)[T.Number]               0.2174      0.482      0.451      0.652      -0.726       1.161
C(answer_type_grouped)[T.Other]               -0.6122      0.436     -1.404      0.160      -1.467       0.243
C(answer_type_grouped)[T.Person]              -0.3787      0.450     -0.842      0.400      -1.260       0.503
C(answer_type_grouped)[T.Place]                0.0553      0.633      0.087      0.930      -1.184       1.295
q_length                                      -0.4545      0.413     -1.100      0.271      -1.264       0.355
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing claude-sonnet-4-20250514 (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/claude-sonnet-4-20250514_SimpleMC_redacted_temp0.0_1751719035_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
1    181
0    100
Name: count, dtype: int64

Answer change%: 0.6441 [0.5881487577930817, 0.7001074699649255] (n=281)
P-value vs 25%: 2.573e-43; P-value vs 0%: 1.272e-112
Phase 2 self-accuracy: 0.4917 [0.41888122543484535, 0.5645441889297955] (n=181)
P-value vs 25%: 7.784e-11; P-value vs 33%: 1.945e-05
                  Grouped rare topic into 'Misc'/'Other': ['History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     1                 0.702703
                        0                 0.297297
Geography               1                 0.565217
                        0                 0.434783
Misc                    1                 0.550000
                        0                 0.450000
Music                   1                 0.578947
                        0                 0.421053
Other                   1                 0.823529
                        0                 0.176471
Politics                1                 0.673913
                        0                 0.326087
Science and technology  0                 0.534483
                        1                 0.465517
Sports                  1                 0.680000
                        0                 0.320000
TV shows                1                 0.894737
                        0                 0.105263
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 1                 0.569892
                     0                 0.430108
Number               1                 0.638298
                     0                 0.361702
Other                1                 0.716418
                     0                 0.283582
Person               1                 0.675676
                     0                 0.324324
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.666667  0.333333           12
                       Number               0.166667  0.833333            6
                       Other                0.285714  0.714286            7
                       Person               0.000000  1.000000           12
Geography              Date                 0.454545  0.545455           11
                       Number               0.444444  0.555556            9
                       Other                0.333333  0.666667            3
Misc                   Date                 0.444444  0.555556            9
                       Number               0.250000  0.750000            4
                       Other                0.500000  0.500000            4
                       Person               0.666667  0.333333            3
Music                  Date                 0.250000  0.750000            4
                       Number               1.000000  0.000000            1
                       Other                0.444444  0.555556            9
                       Person               0.400000  0.600000            5
Other                  Date                 0.166667  0.833333           12
                       Number               0.000000  1.000000            3
                       Other                0.111111  0.888889            9
                       Person               0.300000  0.700000           10
Politics               Date                 0.380952  0.619048           21
                       Number               0.000000  1.000000            5
                       Other                0.333333  0.666667           12
                       Person               0.375000  0.625000            8
Science and technology Date                 0.666667  0.333333           18
                       Number               0.600000  0.400000           10
                       Other                0.333333  0.666667            6
                       Person               0.458333  0.541667           24
Sports                 Date                 0.000000  1.000000            5
                       Number               0.500000  0.500000            8
                       Other                0.250000  0.750000            8
                       Person               0.500000  0.500000            4
TV shows               Date                 0.000000  1.000000            1
                       Number               0.000000  1.000000            1
                       Other                0.111111  0.888889            9
                       Person               0.125000  0.875000            8

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  281
Model:                          Logit   Df Residuals:                      268
Method:                           MLE   Df Model:                           12
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.06840
Time:                        09:26:42   Log-Likelihood:                -170.42
converged:                       True   LL-Null:                       -182.93
Covariance Type:            nonrobust   LLR p-value:                   0.01470
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      1.8370      1.680      1.093      0.274      -1.456       5.130
C(topic_grouped)[T.Geography]                 -0.5521      0.571     -0.967      0.334      -1.672       0.567
C(topic_grouped)[T.Misc]                      -0.5744      0.583     -0.986      0.324      -1.717       0.568
C(topic_grouped)[T.Music]                     -0.6319      0.599     -1.054      0.292      -1.807       0.543
C(topic_grouped)[T.Other]                      0.7131      0.580      1.229      0.219      -0.424       1.850
C(topic_grouped)[T.Politics]                  -0.0307      0.488     -0.063      0.950      -0.987       0.926
C(topic_grouped)[T.Science and technology]    -0.9925      0.451     -2.201      0.028      -1.876      -0.109
C(topic_grouped)[T.Sports]                    -0.1326      0.569     -0.233      0.816      -1.248       0.982
C(topic_grouped)[T.TV shows]                   1.1218      0.840      1.336      0.182      -0.524       2.768
C(answer_type_grouped)[T.Number]               0.4025      0.390      1.033      0.301      -0.361       1.166
C(answer_type_grouped)[T.Other]                0.4397      0.368      1.194      0.233      -0.282       1.162
C(answer_type_grouped)[T.Person]               0.4146      0.358      1.158      0.247      -0.287       1.116
q_length                                      -0.2797      0.360     -0.777      0.437      -0.985       0.426
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing deepseek-chat (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/deepseek-chat_SimpleMC_redacted_cor_temp0.0_1753737594_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    215
1     43
Name: count, dtype: int64

Answer change%: 0.1667 [0.12119174183927743, 0.21214159149405587] (n=258)
P-value vs 25%: 0.0003286; P-value vs 0%: 6.804e-13
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=43)
P-value vs 25%: 0; P-value vs 33%: 0

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  258
Model:                          Logit   Df Residuals:                      256
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.05829
Time:                        09:26:42   Log-Likelihood:                -109.47
converged:                       True   LL-Null:                       -116.24
Covariance Type:            nonrobust   LLR p-value:                 0.0002321
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          0.7262      0.630      1.153      0.249      -0.508       1.960
p_i_capability    -2.9760      0.811     -3.670      0.000      -4.565      -1.387
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  258
Model:                          Logit   Df Residuals:                      256
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.07811
Time:                        09:26:42   Log-Likelihood:                -107.17
converged:                       True   LL-Null:                       -116.24
Covariance Type:            nonrobust   LLR p-value:                 2.032e-05
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.5210      0.312     -8.085      0.000      -3.132      -1.910
capabilities_entropy     1.1985      0.290      4.134      0.000       0.630       1.767
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.5349 [0.3858, 0.6840] (n=43)
                  P-value vs 33.3%: 0.008055

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=20.51, p=3.97e-52
Wilcoxon delta_p: statistic=914.00, p=4.01e-31
Mean Δp = 0.6078  [0.5497, 0.6658]
Idea 1 N = 212; 

  Idea 1.5: Calibration Metrics
  NLL: 3.9199, Signed ECE (overconf pos under neg): -0.4308, ECE: 0.5124 (n=233)
  Brier: 0.5393, Reliability (absolute calibration error; lower better): 0.3599, Resolution (relative calibration quality; higher better): 0.0338, Uncertainty: 0.2084 (n=233)
  AUROC: 0.3595

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.191
Model:                            OLS   Adj. R-squared:                  0.182
Method:                 Least Squares   F-statistic:                     19.79
Date:                Sat, 20 Sep 2025   Prob (F-statistic):           1.52e-11
Time:                        09:26:42   Log-Likelihood:                -113.51
No. Observations:                 255   AIC:                             235.0
Df Residuals:                     251   BIC:                             249.2
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.1752      0.117     -1.494      0.136      -0.406       0.056
p1                    0.9297      0.136      6.850      0.000       0.662       1.197
answer_changed       -0.0408      0.261     -0.157      0.876      -0.554       0.473
p1:answer_changed     0.1056      0.342      0.309      0.758      -0.568       0.779
==============================================================================
Omnibus:                       47.652   Durbin-Watson:                   1.883
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               71.644
Skew:                          -1.294   Prob(JB):                     2.77e-16
Kurtosis:                       2.788   Cond. No.                         24.0
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=8.50, p=3.44e-15
Wilcoxon delta_H: statistic=4711.00, p=1.89e-13
Mean ΔH = 0.4065  [0.3127, 0.5002]
Paired t-test delta_H Changed: statistic=4.76, p=2.35e-05
Wilcoxon delta_H Changed: statistic=150.00, p=4.1e-05
Mean ΔH Changed = 0.4048  [0.2380, 0.5717]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=5.46, p=1.15e-07
Wilcoxon (p_top2_game vs p_top2_base): statistic=14616.00, p=0.148
Mean Δp_top2 = 0.0293  [0.0188, 0.0399] (n=255)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=9.62, p=6.8e-19
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=6551.00, p=1.17e-16
Mean ΔH_unchosen_baseline_set = 0.4062  [0.3235, 0.4889] (n=255)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  255
Model:                          Logit   Df Residuals:                      252
Method:                           MLE   Df Model:                            2
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.09052
Time:                        09:26:42   Log-Likelihood:                -105.22
converged:                       True   LL-Null:                       -115.69
Covariance Type:            nonrobust   LLR p-value:                 2.831e-05
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.1959      0.253     -4.723      0.000      -1.692      -0.700
p1_z            -1.1634      0.279     -4.172      0.000      -1.710      -0.617
I(p1_z ** 2)    -0.6143      0.228     -2.690      0.007      -1.062      -0.167
================================================================================
AUC = 0.715

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  258
Model:                          Logit   Df Residuals:                      256
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.2486
Time:                        09:26:42   Log-Likelihood:                -87.342
converged:                       True   LL-Null:                       -116.24
Covariance Type:            nonrobust   LLR p-value:                 2.893e-14
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -3.8843      0.408     -9.530      0.000      -4.683      -3.086
game_entropy     4.8358      0.731      6.612      0.000       3.402       6.269
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=11500.00, p=1.43e-05
Paired t-test (game_entropy vs capabilities_entropy): statistic=-6.02, p=6.09e-09
Mean capabilities_entropy-game_entropy = 0.2133  [0.1438, 0.2828] (n=258)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  258
Model:                          Logit   Df Residuals:                      255
Method:                           MLE   Df Model:                            2
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.2743
Time:                        09:26:42   Log-Likelihood:                -84.355
converged:                       True   LL-Null:                       -116.24
Covariance Type:            nonrobust   LLR p-value:                 1.415e-14
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -4.3495      0.489     -8.892      0.000      -5.308      -3.391
capabilities_entropy     0.8418      0.345      2.441      0.015       0.166       1.518
game_entropy             4.4525      0.742      5.999      0.000       2.998       5.907
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['Music', 'TV shows', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.950000
                        1                 0.050000
Geography               0                 0.655172
                        1                 0.344828
History                 0                 0.894737
                        1                 0.105263
Misc                    0                 0.794872
                        1                 0.205128
Other                   0                 0.826087
                        1                 0.173913
Politics                0                 0.767442
                        1                 0.232558
Science and technology  0                 0.893617
                        1                 0.106383
Sports                  0                 0.888889
                        1                 0.111111
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.826531
                     1                 0.173469
Number               0                 0.771429
                     1                 0.228571
Other                0                 0.819444
                     1                 0.180556
Person               0                 0.905660
                     1                 0.094340
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 1.000000  0.000000           13
                       Number               1.000000  0.000000            5
                       Other                0.875000  0.125000            8
                       Person               0.928571  0.071429           14
Geography              Date                 0.333333  0.666667            9
                       Number               0.833333  0.166667           12
                       Other                0.750000  0.250000            8
History                Date                 0.818182  0.181818           11
                       Number               1.000000  0.000000            2
                       Other                1.000000  0.000000            3
                       Person               1.000000  0.000000            3
Misc                   Date                 1.000000  0.000000           10
                       Number               0.666667  0.333333            3
                       Other                0.705882  0.294118           17
                       Person               0.777778  0.222222            9
Other                  Date                 0.777778  0.222222            9
                       Number               0.500000  0.500000            2
                       Other                0.857143  0.142857            7
                       Person               1.000000  0.000000            5
Politics               Date                 0.750000  0.250000           20
                       Number               0.666667  0.333333            3
                       Other                0.833333  0.166667           12
                       Person               0.750000  0.250000            8
Science and technology Date                 0.952381  0.047619           21
                       Number               0.666667  0.333333            6
                       Other                0.818182  0.181818           11
                       Person               1.000000  0.000000            9
Sports                 Date                 0.800000  0.200000            5
                       Number               0.500000  0.500000            2
                       Other                1.000000  0.000000            6
                       Person               1.000000  0.000000            5

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  258
Model:                          Logit   Df Residuals:                      246
Method:                           MLE   Df Model:                           11
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.06807
Time:                        09:26:42   Log-Likelihood:                -108.33
converged:                       True   LL-Null:                       -116.24
Covariance Type:            nonrobust   LLR p-value:                    0.1477
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -3.4651      2.264     -1.530      0.126      -7.903       0.973
C(topic_grouped)[T.Geography]                  2.1197      0.844      2.512      0.012       0.466       3.774
C(topic_grouped)[T.History]                    0.7213      1.048      0.688      0.491      -1.332       2.775
C(topic_grouped)[T.Misc]                       1.5657      0.834      1.878      0.060      -0.068       3.200
C(topic_grouped)[T.Other]                      1.3406      0.914      1.467      0.142      -0.451       3.132
C(topic_grouped)[T.Politics]                   1.6507      0.827      1.995      0.046       0.029       3.272
C(topic_grouped)[T.Science and technology]     0.7148      0.876      0.816      0.415      -1.002       2.432
C(topic_grouped)[T.Sports]                     0.8566      1.048      0.818      0.414      -1.197       2.910
C(answer_type_grouped)[T.Number]               0.1282      0.527      0.243      0.808      -0.904       1.161
C(answer_type_grouped)[T.Other]               -0.0551      0.425     -0.130      0.897      -0.889       0.778
C(answer_type_grouped)[T.Person]              -0.5044      0.561     -0.899      0.369      -1.604       0.595
q_length                                       0.1496      0.475      0.315      0.753      -0.781       1.080
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.6231
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  258
Model:                          Logit   Df Residuals:                      245
Method:                           MLE   Df Model:                           12
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1433
Time:                        09:26:42   Log-Likelihood:                -99.584
converged:                       True   LL-Null:                       -116.24
Covariance Type:            nonrobust   LLR p-value:                 0.0008622
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -3.7333      2.392     -1.561      0.119      -8.422       0.955
C(topic_grouped)[T.Geography]                  1.9945      0.867      2.302      0.021       0.296       3.693
C(topic_grouped)[T.History]                    0.7663      1.086      0.705      0.481      -1.363       2.896
C(topic_grouped)[T.Misc]                       1.2589      0.860      1.464      0.143      -0.427       2.945
C(topic_grouped)[T.Other]                      1.1650      0.938      1.242      0.214      -0.674       3.004
C(topic_grouped)[T.Politics]                   1.7610      0.851      2.070      0.038       0.094       3.428
C(topic_grouped)[T.Science and technology]     0.5146      0.901      0.571      0.568      -1.251       2.280
C(topic_grouped)[T.Sports]                     0.7473      1.071      0.698      0.485      -1.352       2.847
C(answer_type_grouped)[T.Number]               0.0354      0.539      0.066      0.948      -1.022       1.093
C(answer_type_grouped)[T.Other]                0.0273      0.447      0.061      0.951      -0.850       0.904
C(answer_type_grouped)[T.Person]              -0.5788      0.585     -0.989      0.323      -1.726       0.569
q_length                                       0.0105      0.499      0.021      0.983      -0.967       0.988
capabilities_entropy                           1.2949      0.323      4.007      0.000       0.662       1.928
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  258
Model:                          Logit   Df Residuals:                      245
Method:                           MLE   Df Model:                           12
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.2963
Time:                        09:26:42   Log-Likelihood:                -81.802
converged:                       True   LL-Null:                       -116.24
Covariance Type:            nonrobust   LLR p-value:                 5.173e-10
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -4.7340      2.752     -1.720      0.085     -10.127       0.659
C(topic_grouped)[T.Geography]                  1.8694      0.903      2.070      0.038       0.099       3.640
C(topic_grouped)[T.History]                    0.8400      1.062      0.791      0.429      -1.242       2.922
C(topic_grouped)[T.Misc]                       0.9172      0.899      1.021      0.307      -0.844       2.678
C(topic_grouped)[T.Other]                      0.8074      1.003      0.805      0.421      -1.158       2.773
C(topic_grouped)[T.Politics]                   0.6928      0.901      0.769      0.442      -1.073       2.459
C(topic_grouped)[T.Science and technology]    -0.1613      0.977     -0.165      0.869      -2.076       1.754
C(topic_grouped)[T.Sports]                     0.4811      1.106      0.435      0.664      -1.686       2.648
C(answer_type_grouped)[T.Number]              -0.6083      0.656     -0.927      0.354      -1.894       0.678
C(answer_type_grouped)[T.Other]               -0.4776      0.517     -0.924      0.356      -1.491       0.536
C(answer_type_grouped)[T.Person]              -0.7746      0.671     -1.154      0.248      -2.090       0.541
q_length                                       0.0827      0.586      0.141      0.888      -1.065       1.231
game_entropy                                   5.0704      0.836      6.064      0.000       3.432       6.709
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  258
Model:                          Logit   Df Residuals:                      244
Method:                           MLE   Df Model:                           13
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.3237
Time:                        09:26:42   Log-Likelihood:                -78.611
converged:                       True   LL-Null:                       -116.24
Covariance Type:            nonrobust   LLR p-value:                 8.488e-11
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -4.4971      2.844     -1.581      0.114     -10.071       1.077
C(topic_grouped)[T.Geography]                  1.8112      0.913      1.983      0.047       0.021       3.601
C(topic_grouped)[T.History]                    0.8342      1.089      0.766      0.444      -1.299       2.968
C(topic_grouped)[T.Misc]                       0.6958      0.918      0.758      0.448      -1.103       2.495
C(topic_grouped)[T.Other]                      0.7412      0.987      0.751      0.453      -1.193       2.676
C(topic_grouped)[T.Politics]                   0.8134      0.910      0.894      0.371      -0.970       2.596
C(topic_grouped)[T.Science and technology]    -0.2789      0.980     -0.285      0.776      -2.200       1.642
C(topic_grouped)[T.Sports]                     0.3266      1.127      0.290      0.772      -1.883       2.536
C(answer_type_grouped)[T.Number]              -0.6840      0.655     -1.045      0.296      -1.967       0.599
C(answer_type_grouped)[T.Other]               -0.4026      0.529     -0.761      0.446      -1.439       0.634
C(answer_type_grouped)[T.Person]              -0.8007      0.687     -1.165      0.244      -2.148       0.546
q_length                                      -0.0839      0.604     -0.139      0.890      -1.268       1.101
capabilities_entropy                           0.9489      0.380      2.496      0.013       0.204       1.694
game_entropy                                   4.7132      0.845      5.574      0.000       3.056       6.370
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing deepseek-chat (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/deepseek-chat_SimpleMC_redacted_temp0.0_1753645078_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    155
1     82
Name: count, dtype: int64

Answer change%: 0.3460 [0.2854298207782457, 0.4065533015846235] (n=237)
P-value vs 25%: 0.001893; P-value vs 0%: 4.201e-29
Phase 2 self-accuracy: 0.5732 [0.46611491632694646, 0.6802265470876876] (n=82)
P-value vs 25%: 3.287e-09; P-value vs 33%: 1.097e-05

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  237
Model:                          Logit   Df Residuals:                      235
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.05068
Time:                        09:26:42   Log-Likelihood:                -145.10
converged:                       True   LL-Null:                       -152.85
Covariance Type:            nonrobust   LLR p-value:                 8.288e-05
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          1.4352      0.549      2.614      0.009       0.359       2.511
p_i_capability    -2.7887      0.727     -3.834      0.000      -4.215      -1.363
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  237
Model:                          Logit   Df Residuals:                      235
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.06271
Time:                        09:26:42   Log-Likelihood:                -143.26
converged:                       True   LL-Null:                       -152.85
Covariance Type:            nonrobust   LLR p-value:                 1.196e-05
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.6311      0.289     -5.643      0.000      -2.198      -1.065
capabilities_entropy     1.0935      0.262      4.182      0.000       0.581       1.606
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.2927 [0.1942, 0.3912] (n=82)
                  P-value vs 33.3%: 0.4185

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=12.93, p=2.36e-26
Wilcoxon delta_p: statistic=1054.00, p=4.82e-19
Mean Δp = 0.4889  [0.4148, 0.5631]
Idea 1 N = 155; 

  Idea 1.5: Calibration Metrics
  NLL: 3.7096, Signed ECE (overconf pos under neg): 0.0130, ECE: 0.2592 (n=222)
  Brier: 0.2760, Reliability (absolute calibration error; lower better): 0.1258, Resolution (relative calibration quality; higher better): 0.0054, Uncertainty: 0.1562 (n=222)
  AUROC: 0.4481

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.240
Model:                            OLS   Adj. R-squared:                  0.230
Method:                 Least Squares   F-statistic:                     24.53
Date:                Sat, 20 Sep 2025   Prob (F-statistic):           7.88e-14
Time:                        09:26:42   Log-Likelihood:                -117.76
No. Observations:                 237   AIC:                             243.5
Df Residuals:                     233   BIC:                             257.4
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.3714      0.135     -2.760      0.006      -0.637      -0.106
p1                    1.0829      0.164      6.584      0.000       0.759       1.407
answer_changed       -0.1339      0.223     -0.600      0.549      -0.574       0.306
p1:answer_changed     0.2457      0.299      0.821      0.413      -0.344       0.836
==============================================================================
Omnibus:                      103.870   Durbin-Watson:                   1.878
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               40.376
Skew:                          -0.837   Prob(JB):                     1.71e-09
Kurtosis:                       1.866   Cond. No.                         20.3
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=6.03, p=1.18e-08
Wilcoxon delta_H: statistic=2993.00, p=4.97e-08
Mean ΔH = 0.3317  [0.2238, 0.4395]
Paired t-test delta_H Changed: statistic=6.36, p=1.11e-08
Wilcoxon delta_H Changed: statistic=573.00, p=1.82e-07
Mean ΔH Changed = 0.4399  [0.3044, 0.5755]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=8.47, p=2.64e-15
Wilcoxon (p_top2_game vs p_top2_base): statistic=6950.00, p=1.3e-11
Mean Δp_top2 = 0.0519  [0.0399, 0.0640] (n=237)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=8.53, p=1.74e-15
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=6199.00, p=7.47e-14
Mean ΔH_unchosen_baseline_set = 0.3691  [0.2844, 0.4539] (n=237)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  237
Model:                          Logit   Df Residuals:                      234
Method:                           MLE   Df Model:                            2
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.07232
Time:                        09:26:42   Log-Likelihood:                -141.79
converged:                       True   LL-Null:                       -152.85
Covariance Type:            nonrobust   LLR p-value:                 1.583e-05
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.3067      0.202     -1.517      0.129      -0.703       0.090
p1_z            -0.7385      0.170     -4.341      0.000      -1.072      -0.405
I(p1_z ** 2)    -0.4137      0.164     -2.528      0.011      -0.734      -0.093
================================================================================
AUC = 0.670

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  237
Model:                          Logit   Df Residuals:                      235
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.07767
Time:                        09:26:42   Log-Likelihood:                -140.98
converged:                       True   LL-Null:                       -152.85
Covariance Type:            nonrobust   LLR p-value:                 1.100e-06
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.8086      0.293     -6.169      0.000      -2.383      -1.234
game_entropy     2.2302      0.483      4.617      0.000       1.284       3.177
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=6145.00, p=5.06e-14
Paired t-test (game_entropy vs capabilities_entropy): statistic=-8.88, p=1.7e-16
Mean capabilities_entropy-game_entropy = 0.3460  [0.2697, 0.4224] (n=237)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  237
Model:                          Logit   Df Residuals:                      234
Method:                           MLE   Df Model:                            2
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1234
Time:                        09:26:42   Log-Likelihood:                -133.98
converged:                       True   LL-Null:                       -152.85
Covariance Type:            nonrobust   LLR p-value:                 6.397e-09
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.6129      0.396     -6.601      0.000      -3.389      -1.837
capabilities_entropy     0.9877      0.274      3.611      0.000       0.452       1.524
game_entropy             2.0481      0.498      4.116      0.000       1.073       3.023
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'Geography', 'Video games', 'History']
                  Grouped rare answer_type into 'Misc'/'Other': None
topic_grouped           answer_changed
Art                     0                 0.657143
                        1                 0.342857
Misc                    0                 0.586957
                        1                 0.413043
Music                   0                 0.695652
                        1                 0.304348
Other                   0                 0.689655
                        1                 0.310345
Politics                0                 0.636364
                        1                 0.363636
Science and technology  0                 0.720000
                        1                 0.280000
Sports                  0                 0.571429
                        1                 0.428571
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.579710
                     1                 0.420290
Number               0                 0.738095
                     1                 0.261905
Other                0                 0.636364
                     1                 0.363636
Person               0                 0.712121
                     1                 0.287879
Place                0                 0.562500
                     1                 0.437500
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.625000  0.375000            8
                       Number               0.750000  0.250000            4
                       Other                0.428571  0.571429            7
                       Person               0.769231  0.230769           13
                       Place                0.666667  0.333333            3
Misc                   Date                 0.545455  0.454545           11
                       Number               0.900000  0.100000           10
                       Other                0.636364  0.363636           11
                       Person               0.400000  0.600000           10
                       Place                0.250000  0.750000            4
Music                  Date                 0.571429  0.428571            7
                       Number               1.000000  0.000000            4
                       Other                0.400000  0.600000            5
                       Person               0.800000  0.200000            5
                       Place                1.000000  0.000000            2
Other                  Date                 0.555556  0.444444            9
                       Number               0.800000  0.200000            5
                       Other                1.000000  0.000000            5
                       Person               0.625000  0.375000            8
                       Place                0.500000  0.500000            2
Politics               Date                 0.625000  0.375000           16
                       Number               0.666667  0.333333            3
                       Other                0.666667  0.333333            6
                       Person               0.571429  0.428571            7
                       Place                1.000000  0.000000            1
Science and technology Date                 0.571429  0.428571           14
                       Number               0.625000  0.375000            8
                       Other                0.666667  0.333333            6
                       Person               0.850000  0.150000           20
                       Place                1.000000  0.000000            2
Sports                 Date                 0.500000  0.500000            4
                       Number               0.500000  0.500000            8
                       Other                0.750000  0.250000            4
                       Person               1.000000  0.000000            3
                       Place                0.000000  1.000000            2

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  237
Model:                          Logit   Df Residuals:                      225
Method:                           MLE   Df Model:                           11
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.02566
Time:                        09:26:42   Log-Likelihood:                -148.93
converged:                       True   LL-Null:                       -152.85
Covariance Type:            nonrobust   LLR p-value:                    0.7273
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      0.2148      1.756      0.122      0.903      -3.227       3.657
C(topic_grouped)[T.Misc]                       0.3146      0.473      0.665      0.506      -0.613       1.242
C(topic_grouped)[T.Music]                     -0.2266      0.585     -0.387      0.699      -1.374       0.920
C(topic_grouped)[T.Other]                     -0.1788      0.544     -0.328      0.743      -1.246       0.888
C(topic_grouped)[T.Politics]                  -0.0091      0.522     -0.017      0.986      -1.032       1.014
C(topic_grouped)[T.Science and technology]    -0.2780      0.482     -0.577      0.564      -1.223       0.667
C(topic_grouped)[T.Sports]                     0.4628      0.585      0.791      0.429      -0.684       1.610
C(answer_type_grouped)[T.Number]              -0.8188      0.444     -1.845      0.065      -1.689       0.051
C(answer_type_grouped)[T.Other]               -0.3108      0.404     -0.768      0.442      -1.103       0.482
C(answer_type_grouped)[T.Person]              -0.5776      0.375     -1.540      0.124      -1.313       0.158
C(answer_type_grouped)[T.Place]               -0.0287      0.574     -0.050      0.960      -1.155       1.097
q_length                                      -0.1125      0.375     -0.300      0.764      -0.847       0.622
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.8547
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  237
Model:                          Logit   Df Residuals:                      224
Method:                           MLE   Df Model:                           12
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.08076
Time:                        09:26:42   Log-Likelihood:                -140.50
converged:                       True   LL-Null:                       -152.85
Covariance Type:            nonrobust   LLR p-value:                   0.01638
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -0.4693      1.846     -0.254      0.799      -4.088       3.149
C(topic_grouped)[T.Misc]                       0.1909      0.491      0.389      0.697      -0.771       1.153
C(topic_grouped)[T.Music]                     -0.1330      0.606     -0.219      0.826      -1.322       1.056
C(topic_grouped)[T.Other]                     -0.2431      0.568     -0.428      0.669      -1.357       0.871
C(topic_grouped)[T.Politics]                  -0.1563      0.544     -0.287      0.774      -1.223       0.911
C(topic_grouped)[T.Science and technology]    -0.1817      0.503     -0.361      0.718      -1.168       0.805
C(topic_grouped)[T.Sports]                     0.4908      0.606      0.810      0.418      -0.697       1.679
C(answer_type_grouped)[T.Number]              -0.7950      0.462     -1.721      0.085      -1.700       0.110
C(answer_type_grouped)[T.Other]               -0.2324      0.421     -0.552      0.581      -1.057       0.592
C(answer_type_grouped)[T.Person]              -0.4610      0.390     -1.182      0.237      -1.225       0.303
C(answer_type_grouped)[T.Place]               -0.0488      0.598     -0.082      0.935      -1.221       1.124
q_length                                      -0.1807      0.393     -0.459      0.646      -0.952       0.590
capabilities_entropy                           1.0597      0.269      3.946      0.000       0.533       1.586
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  237
Model:                          Logit   Df Residuals:                      224
Method:                           MLE   Df Model:                           12
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1067
Time:                        09:26:42   Log-Likelihood:                -136.54
converged:                       True   LL-Null:                       -152.85
Covariance Type:            nonrobust   LLR p-value:                  0.001109
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -0.7576      1.862     -0.407      0.684      -4.408       2.893
C(topic_grouped)[T.Misc]                       0.0778      0.508      0.153      0.878      -0.917       1.073
C(topic_grouped)[T.Music]                     -0.1655      0.607     -0.272      0.785      -1.356       1.025
C(topic_grouped)[T.Other]                     -0.2694      0.583     -0.462      0.644      -1.413       0.874
C(topic_grouped)[T.Politics]                   0.0718      0.545      0.132      0.895      -0.997       1.141
C(topic_grouped)[T.Science and technology]    -0.4815      0.513     -0.939      0.348      -1.486       0.523
C(topic_grouped)[T.Sports]                     0.5484      0.608      0.902      0.367      -0.643       1.740
C(answer_type_grouped)[T.Number]              -1.0085      0.472     -2.136      0.033      -1.934      -0.083
C(answer_type_grouped)[T.Other]               -0.2699      0.426     -0.634      0.526      -1.104       0.564
C(answer_type_grouped)[T.Person]              -0.4876      0.397     -1.227      0.220      -1.266       0.291
C(answer_type_grouped)[T.Place]               -0.1631      0.630     -0.259      0.796      -1.398       1.071
q_length                                      -0.1590      0.396     -0.402      0.688      -0.934       0.616
game_entropy                                   2.4039      0.514      4.679      0.000       1.397       3.411
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  237
Model:                          Logit   Df Residuals:                      223
Method:                           MLE   Df Model:                           13
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1463
Time:                        09:26:42   Log-Likelihood:                -130.48
converged:                       True   LL-Null:                       -152.85
Covariance Type:            nonrobust   LLR p-value:                 2.320e-05
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.1378      1.929     -0.590      0.555      -4.918       2.642
C(topic_grouped)[T.Misc]                      -0.0184      0.523     -0.035      0.972      -1.043       1.006
C(topic_grouped)[T.Music]                     -0.1093      0.626     -0.174      0.862      -1.337       1.119
C(topic_grouped)[T.Other]                     -0.3406      0.603     -0.565      0.572      -1.522       0.841
C(topic_grouped)[T.Politics]                  -0.0621      0.564     -0.110      0.912      -1.168       1.044
C(topic_grouped)[T.Science and technology]    -0.3960      0.531     -0.746      0.456      -1.437       0.645
C(topic_grouped)[T.Sports]                     0.5658      0.631      0.896      0.370      -0.671       1.803
C(answer_type_grouped)[T.Number]              -0.9851      0.487     -2.021      0.043      -1.940      -0.030
C(answer_type_grouped)[T.Other]               -0.2102      0.441     -0.477      0.634      -1.075       0.654
C(answer_type_grouped)[T.Person]              -0.3832      0.410     -0.935      0.350      -1.186       0.420
C(answer_type_grouped)[T.Place]               -0.2054      0.644     -0.319      0.750      -1.467       1.056
q_length                                      -0.2530      0.410     -0.617      0.537      -1.057       0.551
capabilities_entropy                           0.9582      0.283      3.384      0.001       0.403       1.513
game_entropy                                   2.2407      0.528      4.240      0.000       1.205       3.277
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing gemini-1.5-pro (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/gemini-1.5-pro_SimpleMC_redacted_cor_temp0.0_1751757561_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    217
1     23
Name: count, dtype: int64

Answer change%: 0.0958 [0.05859201783934817, 0.1330746488273185] (n=240)
P-value vs 25%: 4.914e-16; P-value vs 0%: 4.569e-07
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=23)
P-value vs 25%: 0; P-value vs 33%: 0
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 1.000000
Geography               0                 0.900000
                        1                 0.100000
History                 0                 0.900000
                        1                 0.100000
Misc                    0                 0.727273
                        1                 0.272727
Music                   0                 0.888889
                        1                 0.111111
Other                   0                 0.875000
                        1                 0.125000
Politics                0                 0.926829
                        1                 0.073171
Science and technology  0                 0.906977
                        1                 0.093023
Sports                  0                 0.950000
                        1                 0.050000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.930000
                     1                 0.070000
Number               0                 0.878788
                     1                 0.121212
Other                0                 0.901639
                     1                 0.098361
Person               0                 0.869565
                     1                 0.130435
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 1.000000  0.000000           12
                       Number               1.000000  0.000000            4
                       Other                1.000000  0.000000            7
                       Person               1.000000  0.000000            9
Geography              Date                 0.875000  0.125000            8
                       Number               0.857143  0.142857            7
                       Other                1.000000  0.000000            5
History                Date                 1.000000  0.000000           11
                       Number               0.666667  0.333333            3
                       Other                0.666667  0.333333            3
                       Person               1.000000  0.000000            3
Misc                   Date                 0.600000  0.400000            5
                       Number               0.666667  0.333333            3
                       Other                0.900000  0.100000           10
                       Person               0.500000  0.500000            4
Music                  Date                 1.000000  0.000000            6
                       Other                0.750000  0.250000            4
                       Person               0.875000  0.125000            8
Other                  Date                 1.000000  0.000000           11
                       Number               1.000000  0.000000            4
                       Other                0.571429  0.428571            7
                       Person               1.000000  0.000000            2
Politics               Date                 0.913043  0.086957           23
                       Number               1.000000  0.000000            1
                       Other                1.000000  0.000000           11
                       Person               0.833333  0.166667            6
Science and technology Date                 0.882353  0.117647           17
                       Number               0.857143  0.142857            7
                       Other                1.000000  0.000000           11
                       Person               0.875000  0.125000            8
Sports                 Date                 1.000000  0.000000            7
                       Number               1.000000  0.000000            4
                       Other                1.000000  0.000000            3
                       Person               0.833333  0.166667            6

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  240
Model:                          Logit   Df Residuals:                      227
Method:                           MLE   Df Model:                           12
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.09948
Time:                        09:26:42   Log-Likelihood:                -68.259
converged:                      False   LL-Null:                       -75.799
Covariance Type:            nonrobust   LLR p-value:                    0.2370
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                    -23.9418    2.4e+04     -0.001      0.999    -4.7e+04    4.69e+04
C(topic_grouped)[T.Geography]                 21.5785    2.4e+04      0.001      0.999   -4.69e+04     4.7e+04
C(topic_grouped)[T.History]                   21.5604    2.4e+04      0.001      0.999   -4.69e+04     4.7e+04
C(topic_grouped)[T.Misc]                      22.7395    2.4e+04      0.001      0.999   -4.69e+04     4.7e+04
C(topic_grouped)[T.Music]                     21.4924    2.4e+04      0.001      0.999   -4.69e+04     4.7e+04
C(topic_grouped)[T.Other]                     21.8492    2.4e+04      0.001      0.999   -4.69e+04     4.7e+04
C(topic_grouped)[T.Politics]                  21.2773    2.4e+04      0.001      0.999   -4.69e+04     4.7e+04
C(topic_grouped)[T.Science and technology]    21.4292    2.4e+04      0.001      0.999   -4.69e+04     4.7e+04
C(topic_grouped)[T.Sports]                    20.6494    2.4e+04      0.001      0.999   -4.69e+04     4.7e+04
C(answer_type_grouped)[T.Number]               0.5238      0.701      0.747      0.455      -0.850       1.898
C(answer_type_grouped)[T.Other]                0.1267      0.612      0.207      0.836      -1.072       1.326
C(answer_type_grouped)[T.Person]               0.8073      0.632      1.277      0.202      -0.432       2.047
q_length                                      -0.0163      0.637     -0.026      0.980      -1.264       1.231
==============================================================================================================

Possibly complete quasi-separation: A fraction 0.13 of observations can be
perfectly predicted. This might indicate that there is complete
quasi-separation. In this case some parameters will not be identified.

                  Model 6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length (after removing deterministic categories: defaultdict(<class 'list'>, {'topic_grouped': ['Art']}))
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  208
Model:                          Logit   Df Residuals:                      196
Method:                           MLE   Df Model:                           11
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.05623
Time:                        09:26:42   Log-Likelihood:                -68.259
converged:                       True   LL-Null:                       -72.326
Covariance Type:            nonrobust   LLR p-value:                    0.7013
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -2.3633      2.899     -0.815      0.415      -8.046       3.320
C(topic_grouped)[T.History]                   -0.0181      1.083     -0.017      0.987      -2.141       2.105
C(topic_grouped)[T.Misc]                       1.1610      0.924      1.256      0.209      -0.651       2.973
C(topic_grouped)[T.Music]                     -0.0861      1.137     -0.076      0.940      -2.314       2.142
C(topic_grouped)[T.Other]                      0.2707      0.983      0.275      0.783      -1.656       2.197
C(topic_grouped)[T.Politics]                  -0.3012      1.025     -0.294      0.769      -2.311       1.708
C(topic_grouped)[T.Science and technology]    -0.1494      0.946     -0.158      0.875      -2.003       1.704
C(topic_grouped)[T.Sports]                    -0.9292      1.297     -0.716      0.474      -3.472       1.614
C(answer_type_grouped)[T.Number]               0.5238      0.701      0.747      0.455      -0.850       1.898
C(answer_type_grouped)[T.Other]                0.1267      0.612      0.207      0.836      -1.072       1.326
C(answer_type_grouped)[T.Person]               0.8073      0.632      1.277      0.202      -0.432       2.047
q_length                                      -0.0163      0.637     -0.026      0.980      -1.264       1.231
==============================================================================================================

--- Analyzing gemini-1.5-pro (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/gemini-1.5-pro_SimpleMC_redacted_temp0.0_1751722404_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    196
1     64
Name: count, dtype: int64

Answer change%: 0.2462 [0.1937930680496052, 0.29851462425808717] (n=260)
P-value vs 25%: 0.8855; P-value vs 0%: 3.142e-20
Phase 2 self-accuracy: 0.5000 [0.37750225096624657, 0.6224977490337534] (n=64)
P-value vs 25%: 6.334e-05; P-value vs 33%: 0.00754
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'Video games', 'History']
                  Grouped rare answer_type into 'Misc'/'Other': None
topic_grouped           answer_changed
Art                     0                 0.813953
                        1                 0.186047
Geography               0                 0.791667
                        1                 0.208333
Misc                    0                 0.718750
                        1                 0.281250
Music                   0                 0.727273
                        1                 0.272727
Other                   0                 0.750000
                        1                 0.250000
Politics                0                 0.777778
                        1                 0.222222
Science and technology  0                 0.709091
                        1                 0.290909
Sports                  0                 0.750000
                        1                 0.250000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.826087
                     1                 0.173913
Number               0                 0.800000
                     1                 0.200000
Other                0                 0.666667
                     1                 0.333333
Person               0                 0.716216
                     1                 0.283784
Place                0                 0.777778
                     1                 0.222222
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.888889  0.111111            9
                       Number               0.800000  0.200000            5
                       Other                0.800000  0.200000           10
                       Person               0.777778  0.222222           18
                       Place                1.000000  0.000000            1
Geography              Date                 0.857143  0.142857            7
                       Number               0.727273  0.272727           11
                       Other                1.000000  0.000000            1
                       Place                0.800000  0.200000            5
Misc                   Date                 0.857143  0.142857            7
                       Number               1.000000  0.000000            3
                       Other                0.615385  0.384615           13
                       Person               0.625000  0.375000            8
                       Place                1.000000  0.000000            1
Music                  Date                 0.833333  0.166667            6
                       Number               1.000000  0.000000            4
                       Other                0.428571  0.571429            7
                       Person               1.000000  0.000000            4
                       Place                0.000000  1.000000            1
Other                  Date                 0.857143  0.142857            7
                       Number               1.000000  0.000000            3
                       Other                0.500000  0.500000            4
                       Person               0.636364  0.363636           11
                       Place                1.000000  0.000000            3
Politics               Date                 0.769231  0.230769           13
                       Number               0.800000  0.200000            5
                       Other                1.000000  0.000000            7
                       Person               0.666667  0.333333            9
                       Place                0.500000  0.500000            2
Science and technology Date                 0.777778  0.222222           18
                       Number               0.714286  0.285714            7
                       Other                0.600000  0.400000            5
                       Person               0.681818  0.318182           22
                       Place                0.666667  0.333333            3
Sports                 Date                 1.000000  0.000000            2
                       Number               0.714286  0.285714            7
                       Other                0.571429  0.428571            7
                       Person               1.000000  0.000000            2
                       Place                1.000000  0.000000            2

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  260
Model:                          Logit   Df Residuals:                      247
Method:                           MLE   Df Model:                           12
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.02651
Time:                        09:26:42   Log-Likelihood:                -141.25
converged:                       True   LL-Null:                       -145.10
Covariance Type:            nonrobust   LLR p-value:                    0.8085
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.7378      1.858     -0.935      0.350      -5.380       1.904
C(topic_grouped)[T.Geography]                  0.5081      0.687      0.739      0.460      -0.839       1.855
C(topic_grouped)[T.Misc]                       0.4966      0.566      0.877      0.380      -0.613       1.606
C(topic_grouped)[T.Music]                      0.5491      0.634      0.866      0.387      -0.694       1.792
C(topic_grouped)[T.Other]                      0.4649      0.595      0.781      0.435      -0.702       1.632
C(topic_grouped)[T.Politics]                   0.3673      0.573      0.641      0.522      -0.756       1.491
C(topic_grouped)[T.Science and technology]     0.7373      0.503      1.467      0.142      -0.248       1.723
C(topic_grouped)[T.Sports]                     0.4222      0.671      0.629      0.529      -0.892       1.737
C(answer_type_grouped)[T.Number]               0.1904      0.506      0.377      0.706      -0.800       1.181
C(answer_type_grouped)[T.Other]                0.9273      0.452      2.054      0.040       0.042       1.812
C(answer_type_grouped)[T.Person]               0.6626      0.425      1.558      0.119      -0.171       1.496
C(answer_type_grouped)[T.Place]                0.2951      0.663      0.445      0.656      -1.005       1.595
q_length                                      -0.0666      0.391     -0.170      0.865      -0.834       0.700
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing gemini-2.0-flash-001 (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/gemini-2.0-flash-001_SimpleMC_redacted_cor_temp1.0_1757990222_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    150
1     65
Name: count, dtype: int64

Answer change%: 0.3023 [0.24093627748118668, 0.36371488530951096] (n=215)
P-value vs 25%: 0.0948; P-value vs 0%: 4.807e-22
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=65)
P-value vs 25%: 0; P-value vs 33%: 0

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  215
Model:                          Logit   Df Residuals:                      213
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.02738
Time:                        09:26:42   Log-Likelihood:                -128.15
converged:                       True   LL-Null:                       -131.76
Covariance Type:            nonrobust   LLR p-value:                  0.007226
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          2.1451      1.131      1.896      0.058      -0.072       4.362
p_i_capability    -3.1834      1.200     -2.652      0.008      -5.536      -0.831
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  215
Model:                          Logit   Df Residuals:                      213
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.03892
Time:                        09:26:42   Log-Likelihood:                -126.63
converged:                       True   LL-Null:                       -131.76
Covariance Type:            nonrobust   LLR p-value:                  0.001363
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.1366      0.182     -6.232      0.000      -1.494      -0.779
capabilities_entropy     1.2527      0.398      3.150      0.002       0.473       2.032
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.4130 [0.2708, 0.5553] (n=46)
                  P-value vs 33.3%: 0.2722

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=6.11, p=3.63e-08
Wilcoxon delta_p: statistic=469.00, p=5.65e-08
Mean Δp = 0.1662  [0.1129, 0.2196]
Idea 1 N = 79; 

  Idea 1.5: Calibration Metrics
  NLL: 0.2000, Signed ECE (overconf pos under neg): -0.1245, ECE: 0.1245 (n=125)
  Brier: 0.0649, Reliability (absolute calibration error; lower better): 0.0643, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=125)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.620
Model:                            OLS   Adj. R-squared:                  0.611
Method:                 Least Squares   F-statistic:                     65.94
Date:                Sat, 20 Sep 2025   Prob (F-statistic):           2.44e-25
Time:                        09:26:42   Log-Likelihood:                 12.066
No. Observations:                 125   AIC:                            -16.13
Df Residuals:                     121   BIC:                            -4.819
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.0929      0.186     -0.498      0.619      -0.462       0.276
p1                    0.2789      0.199      1.403      0.163      -0.115       0.672
answer_changed       -0.1366      0.274     -0.499      0.619      -0.679       0.406
p1:answer_changed     0.7798      0.299      2.612      0.010       0.189       1.371
==============================================================================
Omnibus:                        4.212   Durbin-Watson:                   1.882
Prob(Omnibus):                  0.122   Jarque-Bera (JB):                3.633
Skew:                           0.380   Prob(JB):                        0.163
Kurtosis:                       3.346   Cond. No.                         33.2
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-2.62, p=0.0107
Wilcoxon delta_H: statistic=1089.00, p=0.0164
Mean ΔH = -0.1761  [-0.3081, -0.0442]
Paired t-test delta_H Changed: statistic=0.85, p=0.401
Wilcoxon delta_H Changed: statistic=486.00, p=0.559
Mean ΔH Changed = 0.0818  [-0.1074, 0.2710]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=-5.81, p=5.06e-08
Wilcoxon (p_top2_game vs p_top2_base): statistic=934.00, p=1.36e-13
Mean Δp_top2 = -0.0434  [-0.0581, -0.0287] (n=125)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=-1.44, p=0.152
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=3310.00, p=0.122
Mean ΔH_unchosen_baseline_set = -0.0812  [-0.1916, 0.0292] (n=125)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  125
Model:                          Logit   Df Residuals:                      122
Method:                           MLE   Df Model:                            2
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.02147
Time:                        09:26:42   Log-Likelihood:                -80.470
converged:                       True   LL-Null:                       -82.235
Covariance Type:            nonrobust   LLR p-value:                    0.1711
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.3823      0.250     -1.531      0.126      -0.872       0.107
p1_z            -0.6032      0.362     -1.667      0.096      -1.313       0.106
I(p1_z ** 2)    -0.1713      0.171     -1.004      0.316      -0.506       0.163
================================================================================
AUC = 0.613

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  215
Model:                          Logit   Df Residuals:                      213
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.09445
Time:                        09:26:42   Log-Likelihood:                -119.31
converged:                       True   LL-Null:                       -131.76
Covariance Type:            nonrobust   LLR p-value:                 6.077e-07
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.6830      0.252     -6.691      0.000      -2.176      -1.190
game_entropy     1.3671      0.287      4.766      0.000       0.805       1.929
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=4067.00, p=1.46e-16
Paired t-test (game_entropy vs capabilities_entropy): statistic=8.58, p=1.89e-15
Mean capabilities_entropy-game_entropy = -0.3299  [-0.4052, -0.2546] (n=215)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  215
Model:                          Logit   Df Residuals:                      212
Method:                           MLE   Df Model:                            2
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1082
Time:                        09:26:42   Log-Likelihood:                -117.50
converged:                       True   LL-Null:                       -131.76
Covariance Type:            nonrobust   LLR p-value:                 6.449e-07
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.7939      0.263     -6.824      0.000      -2.309      -1.279
capabilities_entropy     0.7989      0.420      1.903      0.057      -0.024       1.622
game_entropy             1.2321      0.297      4.150      0.000       0.650       1.814
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'Sports', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': None
topic_grouped           answer_changed
Art                     0                 0.787879
                        1                 0.212121
Geography               0                 0.619048
                        1                 0.380952
Misc                    0                 0.638298
                        1                 0.361702
Music                   0                 0.727273
                        1                 0.272727
Other                   0                 0.750000
                        1                 0.250000
Politics                0                 0.727273
                        1                 0.272727
Science and technology  0                 0.666667
                        1                 0.333333
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.607595
                     1                 0.392405
Number               0                 0.521739
                     1                 0.478261
Other                0                 0.739130
                     1                 0.260870
Person               0                 0.846154
                     1                 0.153846
Place                0                 0.800000
                     1                 0.200000
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.500000  0.500000           10
                       Number               1.000000  0.000000            2
                       Other                0.833333  0.166667            6
                       Person               0.928571  0.071429           14
                       Place                1.000000  0.000000            1
Geography              Date                 0.200000  0.800000            5
                       Number               0.625000  0.375000            8
                       Other                1.000000  0.000000            2
                       Place                0.833333  0.166667            6
Misc                   Date                 0.733333  0.266667           15
                       Number               0.400000  0.600000            5
                       Other                0.562500  0.437500           16
                       Person               0.666667  0.333333            9
                       Place                1.000000  0.000000            2
Music                  Date                 0.750000  0.250000            8
                       Number               0.000000  1.000000            1
                       Other                0.666667  0.333333            3
                       Person               0.888889  0.111111            9
                       Place                0.000000  1.000000            1
Other                  Date                 0.625000  0.375000            8
                       Number               0.500000  0.500000            2
                       Other                1.000000  0.000000            4
                       Person               0.750000  0.250000            4
                       Place                1.000000  0.000000            2
Politics               Date                 0.631579  0.368421           19
                       Number               1.000000  0.000000            1
                       Other                0.833333  0.166667            6
                       Person               1.000000  0.000000            4
                       Place                0.666667  0.333333            3
Science and technology Date                 0.571429  0.428571           14
                       Number               0.250000  0.750000            4
                       Other                0.777778  0.222222            9
                       Person               0.833333  0.166667           12

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  215
Model:                          Logit   Df Residuals:                      203
Method:                           MLE   Df Model:                           11
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.06506
Time:                        09:26:42   Log-Likelihood:                -123.18
converged:                       True   LL-Null:                       -131.76
Covariance Type:            nonrobust   LLR p-value:                    0.1036
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      1.5429      2.094      0.737      0.461      -2.561       5.646
C(topic_grouped)[T.Geography]                  0.4219      0.687      0.614      0.539      -0.924       1.768
C(topic_grouped)[T.Misc]                       0.6299      0.546      1.153      0.249      -0.441       1.701
C(topic_grouped)[T.Music]                      0.2860      0.664      0.431      0.667      -1.016       1.588
C(topic_grouped)[T.Other]                      0.0146      0.695      0.021      0.983      -1.347       1.376
C(topic_grouped)[T.Politics]                   0.2087      0.619      0.337      0.736      -1.004       1.422
C(topic_grouped)[T.Science and technology]     0.5615      0.568      0.989      0.323      -0.551       1.674
C(answer_type_grouped)[T.Number]               0.2848      0.512      0.556      0.578      -0.719       1.289
C(answer_type_grouped)[T.Other]               -0.7552      0.423     -1.787      0.074      -1.584       0.073
C(answer_type_grouped)[T.Person]              -1.2702      0.462     -2.750      0.006      -2.175      -0.365
C(answer_type_grouped)[T.Place]               -0.9473      0.725     -1.308      0.191      -2.367       0.473
q_length                                      -0.5097      0.458     -1.112      0.266      -1.408       0.389
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.2166
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  215
Model:                          Logit   Df Residuals:                      202
Method:                           MLE   Df Model:                           12
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1025
Time:                        09:26:42   Log-Likelihood:                -118.25
converged:                       True   LL-Null:                       -131.76
Covariance Type:            nonrobust   LLR p-value:                  0.007717
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      1.3784      2.150      0.641      0.521      -2.836       5.592
C(topic_grouped)[T.Geography]                  0.4102      0.718      0.571      0.568      -0.997       1.817
C(topic_grouped)[T.Misc]                       0.6551      0.567      1.156      0.248      -0.456       1.766
C(topic_grouped)[T.Music]                      0.4466      0.683      0.654      0.513      -0.891       1.785
C(topic_grouped)[T.Other]                     -0.0539      0.715     -0.075      0.940      -1.454       1.347
C(topic_grouped)[T.Politics]                   0.2740      0.644      0.426      0.670      -0.988       1.536
C(topic_grouped)[T.Science and technology]     0.8026      0.591      1.358      0.175      -0.356       1.961
C(answer_type_grouped)[T.Number]               0.2403      0.531      0.452      0.651      -0.801       1.282
C(answer_type_grouped)[T.Other]               -0.9104      0.443     -2.057      0.040      -1.778      -0.043
C(answer_type_grouped)[T.Person]              -1.2613      0.472     -2.669      0.008      -2.187      -0.335
C(answer_type_grouped)[T.Place]               -0.7863      0.731     -1.075      0.282      -2.219       0.647
q_length                                      -0.5552      0.471     -1.178      0.239      -1.479       0.369
capabilities_entropy                           1.3271      0.430      3.087      0.002       0.485       2.170
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  215
Model:                          Logit   Df Residuals:                      202
Method:                           MLE   Df Model:                           12
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1302
Time:                        09:26:42   Log-Likelihood:                -114.61
converged:                       True   LL-Null:                       -131.76
Covariance Type:            nonrobust   LLR p-value:                 0.0006055
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      1.1911      2.200      0.542      0.588      -3.120       5.502
C(topic_grouped)[T.Geography]                  0.1431      0.732      0.195      0.845      -1.291       1.577
C(topic_grouped)[T.Misc]                       0.5461      0.581      0.940      0.347      -0.592       1.685
C(topic_grouped)[T.Music]                      0.1431      0.699      0.205      0.838      -1.226       1.512
C(topic_grouped)[T.Other]                     -0.1528      0.727     -0.210      0.834      -1.578       1.272
C(topic_grouped)[T.Politics]                   0.2028      0.656      0.309      0.757      -1.083       1.488
C(topic_grouped)[T.Science and technology]     0.7405      0.603      1.229      0.219      -0.441       1.922
C(answer_type_grouped)[T.Number]               0.4846      0.538      0.900      0.368      -0.571       1.540
C(answer_type_grouped)[T.Other]               -0.3657      0.456     -0.803      0.422      -1.259       0.527
C(answer_type_grouped)[T.Person]              -0.7551      0.498     -1.517      0.129      -1.731       0.221
C(answer_type_grouped)[T.Place]               -0.1307      0.772     -0.169      0.865      -1.643       1.382
q_length                                      -0.6575      0.484     -1.358      0.174      -1.606       0.291
game_entropy                                   1.2789      0.320      4.002      0.000       0.653       1.905
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  215
Model:                          Logit   Df Residuals:                      201
Method:                           MLE   Df Model:                           13
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1467
Time:                        09:26:42   Log-Likelihood:                -112.43
converged:                       True   LL-Null:                       -131.76
Covariance Type:            nonrobust   LLR p-value:                 0.0002265
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      1.1069      2.218      0.499      0.618      -3.240       5.453
C(topic_grouped)[T.Geography]                  0.1572      0.745      0.211      0.833      -1.302       1.617
C(topic_grouped)[T.Misc]                       0.5670      0.592      0.958      0.338      -0.593       1.727
C(topic_grouped)[T.Music]                      0.2896      0.709      0.409      0.683      -1.100       1.679
C(topic_grouped)[T.Other]                     -0.1924      0.738     -0.261      0.794      -1.638       1.254
C(topic_grouped)[T.Politics]                   0.2483      0.666      0.373      0.709      -1.058       1.554
C(topic_grouped)[T.Science and technology]     0.8794      0.617      1.426      0.154      -0.330       2.088
C(answer_type_grouped)[T.Number]               0.4171      0.545      0.765      0.444      -0.652       1.486
C(answer_type_grouped)[T.Other]               -0.5315      0.473     -1.124      0.261      -1.459       0.396
C(answer_type_grouped)[T.Person]              -0.8080      0.505     -1.601      0.109      -1.797       0.181
C(answer_type_grouped)[T.Place]               -0.1186      0.769     -0.154      0.877      -1.626       1.389
q_length                                      -0.6669      0.488     -1.368      0.171      -1.623       0.289
capabilities_entropy                           0.9314      0.449      2.076      0.038       0.052       1.811
game_entropy                                   1.1110      0.332      3.342      0.001       0.459       1.763
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing gemini-2.0-flash-001 (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/gemini-2.0-flash-001_SimpleMC_redacted_temp1.0_1758161280_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    155
1    130
Name: count, dtype: int64

Answer change%: 0.4561 [0.39831499340263155, 0.5139657083517544] (n=285)
P-value vs 25%: 2.808e-12; P-value vs 0%: 6.393e-54
Phase 2 self-accuracy: 0.4769 [0.3910645637090254, 0.5627815901371285] (n=130)
P-value vs 25%: 2.217e-07; P-value vs 33%: 0.001018

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  285
Model:                          Logit   Df Residuals:                      283
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.01176
Time:                        09:26:42   Log-Likelihood:                -194.14
converged:                       True   LL-Null:                       -196.45
Covariance Type:            nonrobust   LLR p-value:                   0.03156
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          1.3402      0.724      1.851      0.064      -0.079       2.759
p_i_capability    -1.6953      0.798     -2.125      0.034      -3.259      -0.132
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  285
Model:                          Logit   Df Residuals:                      283
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.02257
Time:                        09:26:42   Log-Likelihood:                -192.01
converged:                       True   LL-Null:                       -196.45
Covariance Type:            nonrobust   LLR p-value:                  0.002901
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -0.4826      0.160     -3.025      0.002      -0.795      -0.170
capabilities_entropy     0.8075      0.276      2.925      0.003       0.266       1.349
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.5586 [0.4662, 0.6509] (n=111)
                  P-value vs 33.3%: 1.765e-06

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=5.49, p=2.89e-07
Wilcoxon delta_p: statistic=1067.00, p=4.16e-08
Mean Δp = 0.1276  [0.0820, 0.1731]
Idea 1 N = 105; 

  Idea 1.5: Calibration Metrics
  NLL: 5.8775, Signed ECE (overconf pos under neg): 0.0768, ECE: 0.0768 (n=215)
  Brier: 0.0333, Reliability (absolute calibration error; lower better): 0.0328, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=215)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.692
Model:                            OLS   Adj. R-squared:                  0.687
Method:                 Least Squares   F-statistic:                     156.9
Date:                Sat, 20 Sep 2025   Prob (F-statistic):           2.25e-53
Time:                        09:26:42   Log-Likelihood:                 24.001
No. Observations:                 214   AIC:                            -40.00
Df Residuals:                     210   BIC:                            -26.54
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept             0.0782      0.119      0.660      0.510      -0.156       0.312
p1                    0.0557      0.132      0.423      0.673      -0.204       0.315
answer_changed       -0.6055      0.165     -3.670      0.000      -0.931      -0.280
p1:answer_changed     1.3681      0.186      7.341      0.000       1.001       1.736
==============================================================================
Omnibus:                       11.644   Durbin-Watson:                   2.179
Prob(Omnibus):                  0.003   Jarque-Bera (JB):               20.578
Skew:                          -0.264   Prob(JB):                     3.40e-05
Kurtosis:                       4.425   Cond. No.                         29.0
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-1.71, p=0.0897
Wilcoxon delta_H: statistic=2204.00, p=0.0644
Mean ΔH = -0.0933  [-0.2000, 0.0135]
Paired t-test delta_H Changed: statistic=0.84, p=0.402
Wilcoxon delta_H Changed: statistic=2799.00, p=0.363
Mean ΔH Changed = 0.0513  [-0.0682, 0.1707]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=-5.79, p=2.43e-08
Wilcoxon (p_top2_game vs p_top2_base): statistic=4959.00, p=1.98e-13
Mean Δp_top2 = -0.0352  [-0.0472, -0.0233] (n=216)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=-0.46, p=0.645
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=11263.00, p=0.621
Mean ΔH_unchosen_baseline_set = -0.0190  [-0.0998, 0.0618] (n=216)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  216
Model:                          Logit   Df Residuals:                      213
Method:                           MLE   Df Model:                            2
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.02319
Time:                        09:26:42   Log-Likelihood:                -146.17
converged:                       True   LL-Null:                       -149.64
Covariance Type:            nonrobust   LLR p-value:                   0.03110
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept        0.3859      0.205      1.883      0.060      -0.016       0.788
p1_z            -0.5954      0.230     -2.585      0.010      -1.047      -0.144
I(p1_z ** 2)    -0.3275      0.150     -2.190      0.029      -0.621      -0.034
================================================================================
AUC = 0.602

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  285
Model:                          Logit   Df Residuals:                      283
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.07885
Time:                        09:26:42   Log-Likelihood:                -180.96
converged:                       True   LL-Null:                       -196.45
Covariance Type:            nonrobust   LLR p-value:                 2.606e-08
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.0223      0.204     -5.006      0.000      -1.422      -0.622
game_entropy     1.3037      0.246      5.290      0.000       0.821       1.787
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=9585.00, p=9.19e-15
Paired t-test (game_entropy vs capabilities_entropy): statistic=7.88, p=7.17e-14
Mean capabilities_entropy-game_entropy = -0.2623  [-0.3275, -0.1970] (n=285)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  285
Model:                          Logit   Df Residuals:                      282
Method:                           MLE   Df Model:                            2
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.08234
Time:                        09:26:42   Log-Likelihood:                -180.27
converged:                       True   LL-Null:                       -196.45
Covariance Type:            nonrobust   LLR p-value:                 9.445e-08
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.0935      0.215     -5.097      0.000      -1.514      -0.673
capabilities_entropy     0.3475      0.297      1.170      0.242      -0.234       0.929
game_entropy             1.2084      0.259      4.669      0.000       0.701       1.716
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['Music', 'TV shows', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.595238
                        1                 0.404762
Geography               1                 0.652174
                        0                 0.347826
Misc                    0                 0.586207
                        1                 0.413793
Other                   0                 0.562500
                        1                 0.437500
Politics                0                 0.613636
                        1                 0.386364
Science and technology  1                 0.525424
                        0                 0.474576
Sports                  0                 0.555556
                        1                 0.444444
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.500000
                     1                 0.500000
Number               1                 0.636364
                     0                 0.363636
Other                0                 0.680556
                     1                 0.319444
Person               0                 0.602941
                     1                 0.397059
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.636364  0.363636           11
                       Number               0.285714  0.714286            7
                       Other                0.545455  0.454545           11
                       Person               0.769231  0.230769           13
Geography              Date                 0.300000  0.700000           10
                       Number               0.400000  0.600000           10
                       Other                0.333333  0.666667            3
Misc                   Date                 0.571429  0.428571           14
                       Number               0.555556  0.444444            9
                       Other                0.681818  0.318182           22
                       Person               0.461538  0.538462           13
Other                  Date                 0.500000  0.500000           10
                       Number               0.600000  0.400000            5
                       Other                0.750000  0.250000            8
                       Person               0.444444  0.555556            9
Politics               Date                 0.411765  0.588235           17
                       Number               0.600000  0.400000            5
                       Other                0.818182  0.181818           11
                       Person               0.727273  0.272727           11
Science and technology Date                 0.476190  0.523810           21
                       Number               0.200000  0.800000           10
                       Other                0.700000  0.300000           10
                       Person               0.500000  0.500000           18
Sports                 Date                 0.714286  0.285714            7
                       Number               0.111111  0.888889            9
                       Other                0.714286  0.285714            7
                       Person               1.000000  0.000000            4

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  285
Model:                          Logit   Df Residuals:                      274
Method:                           MLE   Df Model:                           10
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.04624
Time:                        09:26:42   Log-Likelihood:                -187.37
converged:                       True   LL-Null:                       -196.45
Covariance Type:            nonrobust   LLR p-value:                   0.05220
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -0.6900      1.502     -0.459      0.646      -3.635       2.255
C(topic_grouped)[T.Geography]                  0.7094      0.561      1.264      0.206      -0.391       1.809
C(topic_grouped)[T.Misc]                       0.0947      0.423      0.224      0.823      -0.734       0.924
C(topic_grouped)[T.Other]                      0.1305      0.485      0.269      0.788      -0.820       1.081
C(topic_grouped)[T.Politics]                  -0.0991      0.455     -0.218      0.827      -0.990       0.792
C(topic_grouped)[T.Science and technology]     0.4309      0.418      1.031      0.303      -0.389       1.250
C(topic_grouped)[T.Sports]                     0.0072      0.516      0.014      0.989      -1.005       1.019
C(answer_type_grouped)[T.Number]               0.5325      0.358      1.486      0.137      -0.170       1.235
C(answer_type_grouped)[T.Other]               -0.6832      0.337     -2.030      0.042      -1.343      -0.024
C(answer_type_grouped)[T.Person]              -0.3462      0.337     -1.026      0.305      -1.007       0.315
q_length                                       0.1094      0.321      0.341      0.733      -0.520       0.738
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.3777
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  285
Model:                          Logit   Df Residuals:                      273
Method:                           MLE   Df Model:                           11
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.05788
Time:                        09:26:42   Log-Likelihood:                -185.08
converged:                       True   LL-Null:                       -196.45
Covariance Type:            nonrobust   LLR p-value:                   0.01921
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -0.8196      1.518     -0.540      0.589      -3.795       2.156
C(topic_grouped)[T.Geography]                  0.7314      0.568      1.287      0.198      -0.382       1.845
C(topic_grouped)[T.Misc]                       0.1160      0.427      0.272      0.786      -0.721       0.953
C(topic_grouped)[T.Other]                      0.1999      0.490      0.408      0.683      -0.760       1.159
C(topic_grouped)[T.Politics]                  -0.0014      0.461     -0.003      0.998      -0.905       0.902
C(topic_grouped)[T.Science and technology]     0.4270      0.423      1.009      0.313      -0.402       1.256
C(topic_grouped)[T.Sports]                     0.1268      0.524      0.242      0.809      -0.900       1.154
C(answer_type_grouped)[T.Number]               0.4546      0.363      1.252      0.211      -0.257       1.167
C(answer_type_grouped)[T.Other]               -0.6414      0.340     -1.889      0.059      -1.307       0.024
C(answer_type_grouped)[T.Person]              -0.2612      0.342     -0.764      0.445      -0.931       0.409
q_length                                       0.0743      0.325      0.229      0.819      -0.562       0.710
capabilities_entropy                           0.6163      0.290      2.125      0.034       0.048       1.185
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  285
Model:                          Logit   Df Residuals:                      273
Method:                           MLE   Df Model:                           11
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1064
Time:                        09:26:42   Log-Likelihood:                -175.55
converged:                       True   LL-Null:                       -196.45
Covariance Type:            nonrobust   LLR p-value:                 1.759e-05
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -2.0278      1.598     -1.269      0.204      -5.159       1.104
C(topic_grouped)[T.Geography]                  0.8595      0.578      1.488      0.137      -0.273       1.992
C(topic_grouped)[T.Misc]                       0.3129      0.440      0.711      0.477      -0.550       1.176
C(topic_grouped)[T.Other]                      0.1130      0.503      0.225      0.822      -0.873       1.099
C(topic_grouped)[T.Politics]                  -0.0117      0.473     -0.025      0.980      -0.938       0.915
C(topic_grouped)[T.Science and technology]     0.4034      0.440      0.916      0.360      -0.460       1.266
C(topic_grouped)[T.Sports]                     0.3044      0.541      0.563      0.574      -0.756       1.365
C(answer_type_grouped)[T.Number]               0.6115      0.377      1.624      0.104      -0.127       1.350
C(answer_type_grouped)[T.Other]               -0.2997      0.360     -0.832      0.405      -1.005       0.406
C(answer_type_grouped)[T.Person]               0.0400      0.361      0.111      0.912      -0.667       0.747
q_length                                       0.1627      0.335      0.485      0.628      -0.495       0.820
game_entropy                                   1.2400      0.265      4.671      0.000       0.720       1.760
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  285
Model:                          Logit   Df Residuals:                      272
Method:                           MLE   Df Model:                           12
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1076
Time:                        09:26:42   Log-Likelihood:                -175.32
converged:                       True   LL-Null:                       -196.45
Covariance Type:            nonrobust   LLR p-value:                 3.008e-05
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -2.0184      1.600     -1.261      0.207      -5.154       1.118
C(topic_grouped)[T.Geography]                  0.8612      0.579      1.487      0.137      -0.274       1.996
C(topic_grouped)[T.Misc]                       0.3096      0.441      0.702      0.483      -0.555       1.174
C(topic_grouped)[T.Other]                      0.1359      0.505      0.269      0.788      -0.853       1.125
C(topic_grouped)[T.Politics]                   0.0175      0.474      0.037      0.971      -0.912       0.947
C(topic_grouped)[T.Science and technology]     0.4018      0.441      0.911      0.362      -0.463       1.266
C(topic_grouped)[T.Sports]                     0.3328      0.543      0.612      0.540      -0.732       1.398
C(answer_type_grouped)[T.Number]               0.5787      0.380      1.523      0.128      -0.166       1.323
C(answer_type_grouped)[T.Other]               -0.3036      0.360     -0.842      0.400      -1.010       0.403
C(answer_type_grouped)[T.Person]               0.0536      0.362      0.148      0.882      -0.655       0.762
q_length                                       0.1494      0.336      0.444      0.657      -0.510       0.809
capabilities_entropy                           0.2133      0.311      0.686      0.493      -0.396       0.823
game_entropy                                   1.1852      0.277      4.280      0.000       0.642       1.728
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing gemini-2.5-flash-lite_nothink (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/gemini-2.5-flash-lite_nothink_SimpleMC_redacted_cor_temp1.0_1757984044_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    147
1     37
Name: count, dtype: int64

Answer change%: 0.2011 [0.1431733133538262, 0.2590005996896521] (n=184)
P-value vs 25%: 0.09785; P-value vs 0%: 1.008e-11
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=37)
P-value vs 25%: 0; P-value vs 33%: 0

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  184
Model:                          Logit   Df Residuals:                      182
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1916
Time:                        09:26:42   Log-Likelihood:                -74.653
converged:                       True   LL-Null:                       -92.351
Covariance Type:            nonrobust   LLR p-value:                 2.691e-09
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          3.2467      0.828      3.921      0.000       1.624       4.870
p_i_capability    -6.0698      1.126     -5.390      0.000      -8.277      -3.862
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  184
Model:                          Logit   Df Residuals:                      182
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.2088
Time:                        09:26:42   Log-Likelihood:                -73.071
converged:                       True   LL-Null:                       -92.351
Covariance Type:            nonrobust   LLR p-value:                 5.312e-10
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -3.3538      0.486     -6.894      0.000      -4.307      -2.400
capabilities_entropy     2.3188      0.433      5.359      0.000       1.471       3.167
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.4324 [0.2728, 0.5921] (n=37)
                  P-value vs 33.3%: 0.2237

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=1.27, p=0.207
Wilcoxon delta_p: statistic=4456.00, p=0.0573
Mean Δp = 0.0201  [-0.0110, 0.0512]
Idea 1 N = 147; 

  Idea 1.5: Calibration Metrics
  NLL: 0.3360, Signed ECE (overconf pos under neg): -0.2212, ECE: 0.2212 (n=184)
  Brier: 0.1114, Reliability (absolute calibration error; lower better): 0.1107, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=184)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.307
Model:                            OLS   Adj. R-squared:                  0.296
Method:                 Least Squares   F-statistic:                     26.59
Date:                Sat, 20 Sep 2025   Prob (F-statistic):           2.76e-14
Time:                        09:26:42   Log-Likelihood:                 23.330
No. Observations:                 184   AIC:                            -38.66
Df Residuals:                     180   BIC:                            -25.80
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.2029      0.094     -2.170      0.031      -0.387      -0.018
p1                    0.2590      0.107      2.429      0.016       0.049       0.469
answer_changed       -0.2313      0.177     -1.310      0.192      -0.580       0.117
p1:answer_changed     0.8563      0.246      3.475      0.001       0.370       1.343
==============================================================================
Omnibus:                       10.406   Durbin-Watson:                   2.204
Prob(Omnibus):                  0.006   Jarque-Bera (JB):               17.334
Skew:                           0.276   Prob(JB):                     0.000172
Kurtosis:                       4.399   Cond. No.                         25.7
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-3.82, p=0.000197
Wilcoxon delta_H: statistic=3620.00, p=0.000436
Mean ΔH = -0.1228  [-0.1858, -0.0598]
Paired t-test delta_H Changed: statistic=1.89, p=0.0668
Wilcoxon delta_H Changed: statistic=239.00, p=0.0913
Mean ΔH Changed = 0.1518  [-0.0056, 0.3092]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=0.45, p=0.654
Wilcoxon (p_top2_game vs p_top2_base): statistic=7738.00, p=0.286
Mean Δp_top2 = 0.0021  [-0.0072, 0.0115] (n=184)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=-2.16, p=0.0322
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=6968.00, p=0.033
Mean ΔH_unchosen_baseline_set = -0.0676  [-0.1290, -0.0062] (n=184)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  184
Model:                          Logit   Df Residuals:                      181
Method:                           MLE   Df Model:                            2
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.2124
Time:                        09:26:43   Log-Likelihood:                -72.737
converged:                       True   LL-Null:                       -92.351
Covariance Type:            nonrobust   LLR p-value:                 3.032e-09
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.4216      0.291     -4.891      0.000      -1.991      -0.852
p1_z            -1.6146      0.354     -4.556      0.000      -2.309      -0.920
I(p1_z ** 2)    -0.4667      0.241     -1.933      0.053      -0.940       0.006
================================================================================
AUC = 0.798

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  184
Model:                          Logit   Df Residuals:                      182
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1608
Time:                        09:26:43   Log-Likelihood:                -77.499
converged:                       True   LL-Null:                       -92.351
Covariance Type:            nonrobust   LLR p-value:                 5.036e-08
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -2.9613      0.417     -7.100      0.000      -3.779      -2.144
game_entropy     2.0624      0.412      5.011      0.000       1.256       2.869
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=8193.00, p=0.661
Paired t-test (game_entropy vs capabilities_entropy): statistic=-1.01, p=0.314
Mean capabilities_entropy-game_entropy = 0.0329  [-0.0309, 0.0966] (n=184)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  184
Model:                          Logit   Df Residuals:                      181
Method:                           MLE   Df Model:                            2
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.2363
Time:                        09:26:43   Log-Likelihood:                -70.524
converged:                       True   LL-Null:                       -92.351
Covariance Type:            nonrobust   LLR p-value:                 3.318e-10
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -3.7556      0.547     -6.866      0.000      -4.828      -2.683
capabilities_entropy     1.7607      0.496      3.552      0.000       0.789       2.732
game_entropy             1.1168      0.497      2.248      0.025       0.143       2.090
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': None
topic_grouped           answer_changed
Art                     0                 0.777778
                        1                 0.222222
Geography               0                 0.866667
                        1                 0.133333
Misc                    0                 0.578947
                        1                 0.421053
Music                   0                 0.857143
                        1                 0.142857
Other                   0                 0.823529
                        1                 0.176471
Politics                0                 0.774194
                        1                 0.225806
Science and technology  0                 0.866667
                        1                 0.133333
Sports                  0                 0.800000
                        1                 0.200000
TV shows                0                 0.875000
                        1                 0.125000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.653061
                     1                 0.346939
Number               0                 0.720000
                     1                 0.280000
Other                0                 0.900000
                     1                 0.100000
Person               0                 0.857143
                     1                 0.142857
Place                0                 0.928571
                     1                 0.071429
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.571429  0.428571            7
                       Number               0.000000  1.000000            1
                       Other                1.000000  0.000000            4
                       Person               0.846154  0.153846           13
                       Place                1.000000  0.000000            2
Geography              Date                 1.000000  0.000000            3
                       Number               0.714286  0.285714            7
                       Other                1.000000  0.000000            2
                       Place                1.000000  0.000000            3
Misc                   Date                 0.375000  0.625000            8
                       Number               1.000000  0.000000            2
                       Other                0.750000  0.250000            4
                       Person               0.666667  0.333333            3
                       Place                0.500000  0.500000            2
Music                  Date                 0.750000  0.250000            4
                       Number               1.000000  0.000000            1
                       Other                1.000000  0.000000            1
                       Person               0.875000  0.125000            8
Other                  Date                 0.800000  0.200000            5
                       Number               1.000000  0.000000            2
                       Other                1.000000  0.000000            2
                       Person               0.666667  0.333333            6
                       Place                1.000000  0.000000            2
Politics               Date                 0.500000  0.500000           10
                       Number               0.666667  0.333333            3
                       Other                1.000000  0.000000            7
                       Person               0.857143  0.142857            7
                       Place                1.000000  0.000000            4
Science and technology Date                 0.888889  0.111111            9
                       Number               0.500000  0.500000            4
                       Other                0.875000  0.125000            8
                       Person               1.000000  0.000000            9
Sports                 Date                 0.500000  0.500000            2
                       Number               0.800000  0.200000            5
                       Other                1.000000  0.000000            2
                       Person               0.800000  0.200000            5
                       Place                1.000000  0.000000            1
TV shows               Date                 1.000000  0.000000            1
                       Other                0.800000  0.200000           10
                       Person               1.000000  0.000000            5

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  184
Model:                          Logit   Df Residuals:                      170
Method:                           MLE   Df Model:                           13
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1072
Time:                        09:26:43   Log-Likelihood:                -82.446
converged:                       True   LL-Null:                       -92.351
Covariance Type:            nonrobust   LLR p-value:                    0.1001
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -0.1258      2.442     -0.052      0.959      -4.913       4.661
C(topic_grouped)[T.Geography]                 -1.0231      0.976     -1.048      0.295      -2.936       0.890
C(topic_grouped)[T.Misc]                       0.7964      0.704      1.131      0.258      -0.584       2.176
C(topic_grouped)[T.Music]                     -0.7091      0.918     -0.773      0.440      -2.508       1.090
C(topic_grouped)[T.Other]                     -0.4425      0.821     -0.539      0.590      -2.051       1.166
C(topic_grouped)[T.Politics]                  -0.0573      0.680     -0.084      0.933      -1.391       1.276
C(topic_grouped)[T.Science and technology]    -0.8224      0.742     -1.109      0.268      -2.276       0.631
C(topic_grouped)[T.Sports]                    -0.3512      0.853     -0.412      0.681      -2.023       1.321
C(topic_grouped)[T.TV shows]                  -0.2332      0.940     -0.248      0.804      -2.075       1.609
C(answer_type_grouped)[T.Number]              -0.0358      0.601     -0.060      0.952      -1.214       1.142
C(answer_type_grouped)[T.Other]               -1.5789      0.649     -2.432      0.015      -2.851      -0.306
C(answer_type_grouped)[T.Person]              -1.0986      0.510     -2.155      0.031      -2.098      -0.099
C(answer_type_grouped)[T.Place]               -2.0347      1.103     -1.844      0.065      -4.197       0.127
q_length                                      -0.0727      0.532     -0.137      0.891      -1.114       0.969
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.6596
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  184
Model:                          Logit   Df Residuals:                      169
Method:                           MLE   Df Model:                           14
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.2666
Time:                        09:26:43   Log-Likelihood:                -67.726
converged:                       True   LL-Null:                       -92.351
Covariance Type:            nonrobust   LLR p-value:                 8.153e-06
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.0849      2.745     -0.395      0.693      -6.465       4.295
C(topic_grouped)[T.Geography]                 -1.2390      1.051     -1.179      0.239      -3.299       0.821
C(topic_grouped)[T.Misc]                       0.2351      0.809      0.291      0.771      -1.350       1.820
C(topic_grouped)[T.Music]                     -1.2129      1.062     -1.142      0.253      -3.294       0.868
C(topic_grouped)[T.Other]                     -1.0135      0.921     -1.101      0.271      -2.818       0.791
C(topic_grouped)[T.Politics]                  -0.1589      0.788     -0.202      0.840      -1.703       1.385
C(topic_grouped)[T.Science and technology]    -0.6987      0.839     -0.832      0.405      -2.344       0.947
C(topic_grouped)[T.Sports]                    -0.5531      0.941     -0.588      0.557      -2.396       1.290
C(topic_grouped)[T.TV shows]                  -1.3196      1.070     -1.233      0.217      -3.417       0.777
C(answer_type_grouped)[T.Number]              -0.6168      0.663     -0.930      0.352      -1.917       0.683
C(answer_type_grouped)[T.Other]               -0.5476      0.779     -0.703      0.482      -2.074       0.979
C(answer_type_grouped)[T.Person]               0.1976      0.638      0.310      0.757      -1.053       1.448
C(answer_type_grouped)[T.Place]               -1.8619      1.242     -1.500      0.134      -4.295       0.572
q_length                                      -0.3829      0.589     -0.650      0.516      -1.537       0.771
capabilities_entropy                           2.5665      0.544      4.719      0.000       1.501       3.633
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  184
Model:                          Logit   Df Residuals:                      169
Method:                           MLE   Df Model:                           14
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.2118
Time:                        09:26:43   Log-Likelihood:                -72.795
converged:                       True   LL-Null:                       -92.351
Covariance Type:            nonrobust   LLR p-value:                 0.0003505
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -2.5312      2.727     -0.928      0.353      -7.876       2.813
C(topic_grouped)[T.Geography]                 -1.0711      1.023     -1.047      0.295      -3.076       0.934
C(topic_grouped)[T.Misc]                       0.7409      0.759      0.976      0.329      -0.748       2.229
C(topic_grouped)[T.Music]                     -0.5967      0.976     -0.611      0.541      -2.511       1.317
C(topic_grouped)[T.Other]                     -0.2004      0.897     -0.224      0.823      -1.958       1.557
C(topic_grouped)[T.Politics]                   0.2787      0.753      0.370      0.711      -1.198       1.755
C(topic_grouped)[T.Science and technology]    -0.3489      0.793     -0.440      0.660      -1.902       1.204
C(topic_grouped)[T.Sports]                    -0.0553      0.925     -0.060      0.952      -1.867       1.757
C(topic_grouped)[T.TV shows]                  -0.4003      1.018     -0.393      0.694      -2.396       1.595
C(answer_type_grouped)[T.Number]              -0.2601      0.655     -0.397      0.691      -1.543       1.023
C(answer_type_grouped)[T.Other]               -0.7842      0.716     -1.095      0.274      -2.188       0.620
C(answer_type_grouped)[T.Person]              -0.4913      0.563     -0.873      0.383      -1.594       0.612
C(answer_type_grouped)[T.Place]               -1.6795      1.149     -1.462      0.144      -3.931       0.572
q_length                                       0.0337      0.575      0.059      0.953      -1.093       1.160
game_entropy                                   1.9286      0.469      4.111      0.000       1.009       2.848
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  184
Model:                          Logit   Df Residuals:                      168
Method:                           MLE   Df Model:                           15
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.2866
Time:                        09:26:43   Log-Likelihood:                -65.887
converged:                       True   LL-Null:                       -92.351
Covariance Type:            nonrobust   LLR p-value:                 3.965e-06
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -2.1158      2.842     -0.745      0.457      -7.686       3.454
C(topic_grouped)[T.Geography]                 -1.1939      1.043     -1.145      0.252      -3.238       0.851
C(topic_grouped)[T.Misc]                       0.3896      0.819      0.476      0.634      -1.215       1.994
C(topic_grouped)[T.Music]                     -1.0585      1.086     -0.975      0.330      -3.186       1.069
C(topic_grouped)[T.Other]                     -0.7564      0.958     -0.790      0.430      -2.634       1.121
C(topic_grouped)[T.Politics]                   0.0590      0.812      0.073      0.942      -1.533       1.651
C(topic_grouped)[T.Science and technology]    -0.4243      0.856     -0.496      0.620      -2.102       1.254
C(topic_grouped)[T.Sports]                    -0.2915      0.968     -0.301      0.763      -2.189       1.606
C(topic_grouped)[T.TV shows]                  -1.0707      1.094     -0.978      0.328      -3.216       1.074
C(answer_type_grouped)[T.Number]              -0.5607      0.663     -0.845      0.398      -1.861       0.739
C(answer_type_grouped)[T.Other]               -0.4351      0.798     -0.546      0.585      -1.998       1.128
C(answer_type_grouped)[T.Person]               0.2369      0.645      0.368      0.713      -1.026       1.500
C(answer_type_grouped)[T.Place]               -1.6105      1.244     -1.294      0.196      -4.050       0.829
q_length                                      -0.2824      0.600     -0.471      0.638      -1.459       0.894
capabilities_entropy                           2.0396      0.592      3.443      0.001       0.879       3.201
game_entropy                                   1.0260      0.538      1.905      0.057      -0.029       2.081
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing gemini-2.5-flash-lite_nothink (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/gemini-2.5-flash-lite_nothink_SimpleMC_redacted_temp1.0_1757983883_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    189
1    127
Name: count, dtype: int64

Answer change%: 0.4019 [0.3478419470647744, 0.45595552128965594] (n=316)
P-value vs 25%: 3.64e-08; P-value vs 0%: 4.243e-48
Phase 2 self-accuracy: 0.4252 [0.33921618147345844, 0.5111775193139432] (n=127)
P-value vs 25%: 6.505e-05; P-value vs 33%: 0.03558

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  316
Model:                          Logit   Df Residuals:                      314
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.09384
Time:                        09:26:43   Log-Likelihood:                -192.93
converged:                       True   LL-Null:                       -212.91
Covariance Type:            nonrobust   LLR p-value:                 2.591e-10
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          2.4945      0.492      5.070      0.000       1.530       3.459
p_i_capability    -3.9150      0.654     -5.985      0.000      -5.197      -2.633
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  316
Model:                          Logit   Df Residuals:                      314
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1040
Time:                        09:26:43   Log-Likelihood:                -190.77
converged:                       True   LL-Null:                       -212.91
Covariance Type:            nonrobust   LLR p-value:                 2.839e-11
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.7776      0.265     -6.719      0.000      -2.296      -1.259
capabilities_entropy     1.5032      0.243      6.174      0.000       1.026       1.980
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.3937 [0.3087, 0.4787] (n=127)
                  P-value vs 33.3%: 0.1638

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=4.77, p=3.74e-06
Wilcoxon delta_p: statistic=5395.00, p=3.03e-06
Mean Δp = 0.0761  [0.0448, 0.1074]
Idea 1 N = 188; 

  Idea 1.5: Calibration Metrics
  NLL: 3.4667, Signed ECE (overconf pos under neg): 0.1396, ECE: 0.1396 (n=315)
  Brier: 0.0579, Reliability (absolute calibration error; lower better): 0.0571, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=315)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.275
Model:                            OLS   Adj. R-squared:                  0.268
Method:                 Least Squares   F-statistic:                     39.36
Date:                Sat, 20 Sep 2025   Prob (F-statistic):           1.37e-21
Time:                        09:26:43   Log-Likelihood:                -10.039
No. Observations:                 315   AIC:                             28.08
Df Residuals:                     311   BIC:                             43.09
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.0664      0.081     -0.815      0.416      -0.227       0.094
p1                    0.1768      0.099      1.795      0.074      -0.017       0.371
answer_changed       -0.2331      0.120     -1.950      0.052      -0.468       0.002
p1:answer_changed     0.7304      0.160      4.552      0.000       0.415       1.046
==============================================================================
Omnibus:                        5.871   Durbin-Watson:                   1.946
Prob(Omnibus):                  0.053   Jarque-Bera (JB):                5.082
Skew:                          -0.234   Prob(JB):                       0.0788
Kurtosis:                       2.589   Cond. No.                         21.0
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-1.73, p=0.0844
Wilcoxon delta_H: statistic=7590.00, p=0.0835
Mean ΔH = -0.0498  [-0.1062, 0.0065]
Paired t-test delta_H Changed: statistic=2.74, p=0.00702
Wilcoxon delta_H Changed: statistic=2949.00, p=0.0073
Mean ΔH Changed = 0.1132  [0.0323, 0.1942]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=-1.84, p=0.0661
Wilcoxon (p_top2_game vs p_top2_base): statistic=19652.00, p=0.00122
Mean Δp_top2 = -0.0090  [-0.0185, 0.0006] (n=315)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=0.65, p=0.513
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=24099.00, p=0.627
Mean ΔH_unchosen_baseline_set = 0.0159  [-0.0317, 0.0635] (n=315)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  315
Model:                          Logit   Df Residuals:                      312
Method:                           MLE   Df Model:                            2
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1045
Time:                        09:26:43   Log-Likelihood:                -190.21
converged:                       True   LL-Null:                       -212.40
Covariance Type:            nonrobust   LLR p-value:                 2.310e-10
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.1440      0.180     -0.799      0.424      -0.497       0.209
p1_z            -0.8708      0.141     -6.160      0.000      -1.148      -0.594
I(p1_z ** 2)    -0.3297      0.147     -2.243      0.025      -0.618      -0.042
================================================================================
AUC = 0.704

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  316
Model:                          Logit   Df Residuals:                      314
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.07579
Time:                        09:26:43   Log-Likelihood:                -196.78
converged:                       True   LL-Null:                       -212.91
Covariance Type:            nonrobust   LLR p-value:                 1.338e-08
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.6664      0.273     -6.112      0.000      -2.201      -1.132
game_entropy     1.3188      0.245      5.381      0.000       0.838       1.799
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=21709.00, p=0.0403
Paired t-test (game_entropy vs capabilities_entropy): statistic=1.87, p=0.0628
Mean capabilities_entropy-game_entropy = -0.0528  [-0.1083, 0.0026] (n=316)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  316
Model:                          Logit   Df Residuals:                      313
Method:                           MLE   Df Model:                            2
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1201
Time:                        09:26:43   Log-Likelihood:                -187.34
converged:                       True   LL-Null:                       -212.91
Covariance Type:            nonrobust   LLR p-value:                 7.830e-12
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.1881      0.321     -6.809      0.000      -2.818      -1.558
capabilities_entropy     1.1670      0.276      4.233      0.000       0.627       1.707
game_entropy             0.7411      0.285      2.603      0.009       0.183       1.299
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.583333
                        1                 0.416667
Geography               1                 0.655172
                        0                 0.344828
Misc                    0                 0.564103
                        1                 0.435897
Music                   0                 0.730769
                        1                 0.269231
Other                   0                 0.628571
                        1                 0.371429
Politics                0                 0.565217
                        1                 0.434783
Science and technology  0                 0.676471
                        1                 0.323529
Sports                  0                 0.640000
                        1                 0.360000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.533333
                     1                 0.466667
Number               0                 0.547170
                     1                 0.452830
Other                0                 0.645570
                     1                 0.354430
Person               0                 0.703125
                     1                 0.296875
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.571429  0.428571           14
                       Number               0.375000  0.625000            8
                       Other                0.750000  0.250000           12
                       Person               0.571429  0.428571           14
Geography              Date                 0.333333  0.666667           12
                       Number               0.545455  0.454545           11
                       Other                0.000000  1.000000            6
Misc                   Date                 0.571429  0.428571           14
                       Number               0.428571  0.571429            7
                       Other                0.636364  0.363636           11
                       Person               0.571429  0.428571            7
Music                  Date                 0.500000  0.500000            8
                       Number               0.666667  0.333333            3
                       Other                0.818182  0.181818           11
                       Person               1.000000  0.000000            4
Other                  Date                 0.538462  0.461538           13
                       Number               0.800000  0.200000            5
                       Other                0.600000  0.400000           10
                       Person               0.714286  0.285714            7
Politics               Date                 0.500000  0.500000           26
                       Number               0.666667  0.333333            3
                       Other                0.666667  0.333333            9
                       Person               0.625000  0.375000            8
Science and technology Date                 0.576923  0.423077           26
                       Number               0.700000  0.300000           10
                       Other                0.727273  0.272727           11
                       Person               0.761905  0.238095           21
Sports                 Date                 0.714286  0.285714            7
                       Number               0.333333  0.666667            6
                       Other                0.666667  0.333333            9
                       Person               1.000000  0.000000            3

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  316
Model:                          Logit   Df Residuals:                      304
Method:                           MLE   Df Model:                           11
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.03892
Time:                        09:26:43   Log-Likelihood:                -204.63
converged:                       True   LL-Null:                       -212.91
Covariance Type:            nonrobust   LLR p-value:                    0.1212
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      0.7601      1.506      0.505      0.614      -2.192       3.712
C(topic_grouped)[T.Geography]                  0.8052      0.502      1.604      0.109      -0.179       1.789
C(topic_grouped)[T.Misc]                       0.0318      0.441      0.072      0.942      -0.832       0.895
C(topic_grouped)[T.Music]                     -0.7055      0.538     -1.312      0.189      -1.759       0.348
C(topic_grouped)[T.Other]                     -0.2457      0.461     -0.533      0.594      -1.150       0.658
C(topic_grouped)[T.Politics]                  -0.0053      0.431     -0.012      0.990      -0.849       0.839
C(topic_grouped)[T.Science and technology]    -0.4254      0.396     -1.073      0.283      -1.202       0.351
C(topic_grouped)[T.Sports]                    -0.2819      0.516     -0.546      0.585      -1.293       0.730
C(answer_type_grouped)[T.Number]              -0.1595      0.347     -0.460      0.646      -0.840       0.521
C(answer_type_grouped)[T.Other]               -0.4429      0.309     -1.435      0.151      -1.048       0.162
C(answer_type_grouped)[T.Person]              -0.6459      0.342     -1.887      0.059      -1.317       0.025
q_length                                      -0.1738      0.324     -0.537      0.592      -0.809       0.461
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.8737
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  316
Model:                          Logit   Df Residuals:                      303
Method:                           MLE   Df Model:                           12
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1312
Time:                        09:26:43   Log-Likelihood:                -184.97
converged:                       True   LL-Null:                       -212.91
Covariance Type:            nonrobust   LLR p-value:                 1.253e-07
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -0.9097      1.635     -0.556      0.578      -4.114       2.295
C(topic_grouped)[T.Geography]                  0.7574      0.527      1.437      0.151      -0.276       1.791
C(topic_grouped)[T.Misc]                       0.3523      0.476      0.740      0.459      -0.580       1.285
C(topic_grouped)[T.Music]                     -0.7932      0.584     -1.358      0.174      -1.938       0.352
C(topic_grouped)[T.Other]                     -0.2948      0.484     -0.609      0.542      -1.243       0.654
C(topic_grouped)[T.Politics]                   0.0681      0.460      0.148      0.882      -0.834       0.970
C(topic_grouped)[T.Science and technology]    -0.3470      0.423     -0.820      0.412      -1.177       0.483
C(topic_grouped)[T.Sports]                    -0.1630      0.556     -0.293      0.769      -1.252       0.926
C(answer_type_grouped)[T.Number]              -0.3829      0.370     -1.034      0.301      -1.109       0.343
C(answer_type_grouped)[T.Other]                0.1523      0.347      0.439      0.661      -0.528       0.832
C(answer_type_grouped)[T.Person]              -0.2206      0.372     -0.592      0.554      -0.950       0.509
q_length                                      -0.1833      0.344     -0.532      0.595      -0.858       0.492
capabilities_entropy                           1.5843      0.273      5.807      0.000       1.050       2.119
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  316
Model:                          Logit   Df Residuals:                      303
Method:                           MLE   Df Model:                           12
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1143
Time:                        09:26:43   Log-Likelihood:                -188.58
converged:                       True   LL-Null:                       -212.91
Covariance Type:            nonrobust   LLR p-value:                 2.388e-06
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      0.2022      1.587      0.127      0.899      -2.909       3.313
C(topic_grouped)[T.Geography]                  0.6363      0.528      1.204      0.228      -0.399       1.672
C(topic_grouped)[T.Misc]                       0.0678      0.466      0.146      0.884      -0.845       0.980
C(topic_grouped)[T.Music]                     -0.9261      0.568     -1.630      0.103      -2.040       0.187
C(topic_grouped)[T.Other]                     -0.5084      0.487     -1.044      0.297      -1.463       0.446
C(topic_grouped)[T.Politics]                   0.0699      0.458      0.153      0.879      -0.828       0.968
C(topic_grouped)[T.Science and technology]    -0.6983      0.427     -1.637      0.102      -1.534       0.138
C(topic_grouped)[T.Sports]                    -0.5133      0.551     -0.932      0.351      -1.592       0.566
C(answer_type_grouped)[T.Number]              -0.2989      0.364     -0.820      0.412      -1.013       0.415
C(answer_type_grouped)[T.Other]               -0.1793      0.330     -0.543      0.587      -0.826       0.467
C(answer_type_grouped)[T.Person]              -0.4580      0.363     -1.262      0.207      -1.169       0.253
q_length                                      -0.3463      0.343     -1.009      0.313      -1.019       0.327
game_entropy                                   1.4304      0.268      5.336      0.000       0.905       1.956
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  316
Model:                          Logit   Df Residuals:                      302
Method:                           MLE   Df Model:                           13
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1522
Time:                        09:26:43   Log-Likelihood:                -180.51
converged:                       True   LL-Null:                       -212.91
Covariance Type:            nonrobust   LLR p-value:                 7.140e-09
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -0.8989      1.660     -0.541      0.588      -4.153       2.355
C(topic_grouped)[T.Geography]                  0.6745      0.538      1.255      0.210      -0.379       1.728
C(topic_grouped)[T.Misc]                       0.3191      0.487      0.655      0.512      -0.635       1.273
C(topic_grouped)[T.Music]                     -0.9034      0.590     -1.532      0.126      -2.059       0.253
C(topic_grouped)[T.Other]                     -0.4203      0.493     -0.853      0.394      -1.386       0.545
C(topic_grouped)[T.Politics]                   0.0913      0.472      0.193      0.847      -0.834       1.017
C(topic_grouped)[T.Science and technology]    -0.5215      0.436     -1.195      0.232      -1.377       0.334
C(topic_grouped)[T.Sports]                    -0.3267      0.572     -0.571      0.568      -1.447       0.794
C(answer_type_grouped)[T.Number]              -0.4239      0.376     -1.126      0.260      -1.161       0.314
C(answer_type_grouped)[T.Other]                0.1627      0.353      0.461      0.645      -0.530       0.855
C(answer_type_grouped)[T.Person]              -0.2056      0.378     -0.544      0.586      -0.946       0.535
q_length                                      -0.2798      0.351     -0.796      0.426      -0.969       0.409
capabilities_entropy                           1.1941      0.305      3.917      0.000       0.597       1.792
game_entropy                                   0.8953      0.304      2.948      0.003       0.300       1.491
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing gemini-2.5-flash-lite_think (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/gemini-2.5-flash-lite_think_SimpleMC_redacted_cor_temp1.0_1758179683_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    153
1     75
Name: count, dtype: int64

Answer change%: 0.3289 [0.2679624892591379, 0.3899322475829674] (n=228)
P-value vs 25%: 0.01117; P-value vs 0%: 4.023e-26
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=75)
P-value vs 25%: 0; P-value vs 33%: 0

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  228
Model:                          Logit   Df Residuals:                      226
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                0.008196
Time:                        09:26:43   Log-Likelihood:                -143.24
converged:                       True   LL-Null:                       -144.42
Covariance Type:            nonrobust   LLR p-value:                    0.1239
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept       1145.3648    840.379      1.363      0.173    -501.747    2792.476
p_i_capability -1146.1275    840.411     -1.364      0.173   -2793.303     501.048
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  228
Model:                          Logit   Df Residuals:                      226
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                0.007662
Time:                        09:26:43   Log-Likelihood:                -143.32
converged:                       True   LL-Null:                       -144.42
Covariance Type:            nonrobust   LLR p-value:                    0.1368
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -0.7626      0.146     -5.235      0.000      -1.048      -0.477
capabilities_entropy    93.9330     69.911      1.344      0.179     -43.090     230.956
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.1159 [0.0404, 0.1915] (n=69)
                  P-value vs 33.3%: 1.697e-08

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=4.91, p=2.67e-06
Wilcoxon delta_p: statistic=443.00, p=1.31e-19
Mean Δp = 0.0001  [0.0001, 0.0001]
Idea 1 N = 134; 

  Idea 1.5: Calibration Metrics
  NLL: 0.0000, Signed ECE (overconf pos under neg): -0.0000, ECE: 0.0000 (n=203)
  Brier: 0.0000, Reliability (absolute calibration error; lower better): 0.0000, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=203)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       1.000
Model:                            OLS   Adj. R-squared:                  1.000
Method:                 Least Squares   F-statistic:                 6.071e+06
Date:                Sat, 20 Sep 2025   Prob (F-statistic):               0.00
Time:                        09:26:43   Log-Likelihood:                 937.08
No. Observations:                 181   AIC:                            -1866.
Df Residuals:                     177   BIC:                            -1853.
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -1.0248      0.970     -1.056      0.292      -2.939       0.890
p1                    1.0249      0.970      1.056      0.292      -0.890       2.940
answer_changed        0.0977      1.423      0.069      0.945      -2.710       2.906
p1:answer_changed     0.9015      1.423      0.634      0.527      -1.907       3.710
==============================================================================
Omnibus:                      356.043   Durbin-Watson:                   2.072
Prob(Omnibus):                  0.000   Jarque-Bera (JB):           125851.317
Skew:                         -10.644   Prob(JB):                         0.00
Kurtosis:                     130.414   Cond. No.                     3.25e+04
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The condition number is large, 3.25e+04. This might indicate that there are
strong multicollinearity or other numerical problems.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=0.23, p=0.822
Wilcoxon delta_H: statistic=4445.00, p=0.863
Mean ΔH = 0.0081  [-0.0623, 0.0785]
Paired t-test delta_H Changed: statistic=35.99, p=5.28e-46
Wilcoxon delta_H Changed: statistic=0.00, p=5.21e-13
Mean ΔH Changed = 1.2599  [1.1913, 1.3285]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=-2.34, p=0.0204
Wilcoxon (p_top2_game vs p_top2_base): statistic=857.00, p=9.17e-30
Mean Δp_top2 = -0.0001  [-0.0002, -0.0000] (n=203)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=8.77, p=7.2e-16
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=4525.00, p=3.54e-12
Mean ΔH_unchosen_baseline_set = 0.4336  [0.3367, 0.5304] (n=203)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  203
Model:                          Logit   Df Residuals:                      200
Method:                           MLE   Df Model:                            2
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                0.008360
Time:                        09:26:43   Log-Likelihood:                -129.03
converged:                       True   LL-Null:                       -130.12
Covariance Type:            nonrobust   LLR p-value:                    0.3370
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.6659      0.161     -4.127      0.000      -0.982      -0.350
p1_z            -0.2121      0.542     -0.391      0.695      -1.274       0.850
I(p1_z ** 2)     0.0014      0.067      0.021      0.983      -0.129       0.132
================================================================================
AUC = 0.530

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  228
Model:                          Logit   Df Residuals:                      226
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.06504
Time:                        09:26:43   Log-Likelihood:                -135.03
converged:                       True   LL-Null:                       -144.42
Covariance Type:            nonrobust   LLR p-value:                 1.462e-05
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.0968      0.180     -6.078      0.000      -1.451      -0.743
game_entropy   151.7557     48.540      3.126      0.002      56.620     246.892
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=1392.00, p=1.35e-31
Paired t-test (game_entropy vs capabilities_entropy): statistic=2.30, p=0.0222
Mean capabilities_entropy-game_entropy = -0.0044  [-0.0081, -0.0007] (n=228)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  228
Model:                          Logit   Df Residuals:                      225
Method:                           MLE   Df Model:                            2
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.07214
Time:                        09:26:43   Log-Likelihood:                -134.00
converged:                       True   LL-Null:                       -144.42
Covariance Type:            nonrobust   LLR p-value:                 2.987e-05
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.1456      0.185     -6.196      0.000      -1.508      -0.783
capabilities_entropy    88.4434     65.850      1.343      0.179     -40.621     217.508
game_entropy           152.2160     48.911      3.112      0.002      56.351     248.081
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': None
topic_grouped           answer_changed
Art                     0                 0.756757
                        1                 0.243243
Geography               0                 0.590909
                        1                 0.409091
Misc                    0                 0.555556
                        1                 0.444444
Music                   0                 0.764706
                        1                 0.235294
Other                   0                 0.760000
                        1                 0.240000
Politics                0                 0.641026
                        1                 0.358974
Science and technology  0                 0.627907
                        1                 0.372093
Sports                  0                 0.722222
                        1                 0.277778
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.589041
                     1                 0.410959
Number               0                 0.592593
                     1                 0.407407
Other                0                 0.703704
                     1                 0.296296
Person               0                 0.789474
                     1                 0.210526
Place                0                 0.647059
                     1                 0.352941
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.600000  0.400000           10
                       Number               1.000000  0.000000            4
                       Other                0.875000  0.125000            8
                       Person               0.666667  0.333333           12
                       Place                1.000000  0.000000            3
Geography              Date                 0.400000  0.600000            5
                       Number               0.500000  0.500000            8
                       Other                1.000000  0.000000            3
                       Place                0.666667  0.333333            6
Misc                   Date                 0.285714  0.714286            7
                       Number               0.500000  0.500000            2
                       Other                0.666667  0.333333            9
                       Person               0.857143  0.142857            7
                       Place                0.000000  1.000000            2
Music                  Date                 0.600000  0.400000            5
                       Other                0.750000  0.250000            4
                       Person               0.875000  0.125000            8
Other                  Date                 0.500000  0.500000            6
                       Number               0.666667  0.333333            3
                       Other                1.000000  0.000000            5
                       Person               0.875000  0.125000            8
                       Place                0.666667  0.333333            3
Politics               Date                 0.666667  0.333333           18
                       Number               0.500000  0.500000            2
                       Other                0.636364  0.363636           11
                       Person               0.666667  0.333333            6
                       Place                0.500000  0.500000            2
Science and technology Date                 0.666667  0.333333           18
                       Number               0.600000  0.400000            5
                       Other                0.444444  0.555556            9
                       Person               0.700000  0.300000           10
                       Place                1.000000  0.000000            1
Sports                 Date                 0.750000  0.250000            4
                       Number               0.333333  0.666667            3
                       Other                0.600000  0.400000            5
                       Person               1.000000  0.000000            6

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  228
Model:                          Logit   Df Residuals:                      215
Method:                           MLE   Df Model:                           12
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.04154
Time:                        09:26:43   Log-Likelihood:                -138.42
converged:                       True   LL-Null:                       -144.42
Covariance Type:            nonrobust   LLR p-value:                    0.4459
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.8379      1.730     -1.063      0.288      -5.228       1.552
C(topic_grouped)[T.Geography]                  0.5232      0.610      0.858      0.391      -0.672       1.718
C(topic_grouped)[T.Misc]                       0.9058      0.557      1.626      0.104      -0.186       1.998
C(topic_grouped)[T.Music]                      0.0414      0.705      0.059      0.953      -1.341       1.424
C(topic_grouped)[T.Other]                     -0.0453      0.614     -0.074      0.941      -1.249       1.158
C(topic_grouped)[T.Politics]                   0.3890      0.529      0.735      0.462      -0.648       1.426
C(topic_grouped)[T.Science and technology]     0.4686      0.514      0.912      0.362      -0.539       1.476
C(topic_grouped)[T.Sports]                     0.1962      0.664      0.296      0.768      -1.105       1.497
C(answer_type_grouped)[T.Number]              -0.0384      0.487     -0.079      0.937      -0.994       0.917
C(answer_type_grouped)[T.Other]               -0.5231      0.389     -1.343      0.179      -1.287       0.240
C(answer_type_grouped)[T.Person]              -0.8821      0.416     -2.122      0.034      -1.697      -0.068
C(answer_type_grouped)[T.Place]               -0.2628      0.594     -0.442      0.658      -1.428       0.902
q_length                                       0.2473      0.380      0.651      0.515      -0.497       0.991
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.0005
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  228
Model:                          Logit   Df Residuals:                      214
Method:                           MLE   Df Model:                           13
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.05216
Time:                        09:26:43   Log-Likelihood:                -136.89
converged:                       True   LL-Null:                       -144.42
Covariance Type:            nonrobust   LLR p-value:                    0.3032
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.9676      1.745     -1.127      0.260      -5.388       1.453
C(topic_grouped)[T.Geography]                  0.7032      0.627      1.121      0.262      -0.526       1.933
C(topic_grouped)[T.Misc]                       1.0516      0.572      1.838      0.066      -0.070       2.173
C(topic_grouped)[T.Music]                      0.1476      0.713      0.207      0.836      -1.250       1.546
C(topic_grouped)[T.Other]                     -0.0365      0.637     -0.057      0.954      -1.285       1.212
C(topic_grouped)[T.Politics]                   0.5483      0.546      1.005      0.315      -0.521       1.618
C(topic_grouped)[T.Science and technology]     0.6035      0.529      1.140      0.254      -0.434       1.641
C(topic_grouped)[T.Sports]                     0.3207      0.675      0.475      0.635      -1.002       1.643
C(answer_type_grouped)[T.Number]              -0.0104      0.491     -0.021      0.983      -0.973       0.952
C(answer_type_grouped)[T.Other]               -0.4804      0.392     -1.226      0.220      -1.249       0.288
C(answer_type_grouped)[T.Person]              -0.8295      0.418     -1.983      0.047      -1.649      -0.010
C(answer_type_grouped)[T.Place]               -0.3787      0.614     -0.616      0.538      -1.583       0.826
q_length                                       0.2342      0.382      0.613      0.540      -0.514       0.983
capabilities_entropy                         115.8874     74.085      1.564      0.118     -29.317     261.092
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  228
Model:                          Logit   Df Residuals:                      214
Method:                           MLE   Df Model:                           13
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1051
Time:                        09:26:43   Log-Likelihood:                -129.25
converged:                       True   LL-Null:                       -144.42
Covariance Type:            nonrobust   LLR p-value:                  0.004192
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.4998      1.787     -0.839      0.401      -5.002       2.002
C(topic_grouped)[T.Geography]                  0.6906      0.631      1.095      0.273      -0.545       1.927
C(topic_grouped)[T.Misc]                       0.6127      0.610      1.005      0.315      -0.582       1.807
C(topic_grouped)[T.Music]                      0.1691      0.724      0.234      0.815      -1.249       1.588
C(topic_grouped)[T.Other]                      0.0159      0.653      0.024      0.981      -1.264       1.295
C(topic_grouped)[T.Politics]                   0.4843      0.550      0.880      0.379      -0.594       1.562
C(topic_grouped)[T.Science and technology]     0.4540      0.544      0.835      0.404      -0.612       1.520
C(topic_grouped)[T.Sports]                     0.4310      0.681      0.632      0.527      -0.905       1.767
C(answer_type_grouped)[T.Number]              -0.1202      0.503     -0.239      0.811      -1.107       0.866
C(answer_type_grouped)[T.Other]               -0.6478      0.408     -1.586      0.113      -1.448       0.153
C(answer_type_grouped)[T.Person]              -1.0489      0.437     -2.399      0.016      -1.906      -0.192
C(answer_type_grouped)[T.Place]               -0.4387      0.634     -0.692      0.489      -1.681       0.803
q_length                                       0.1000      0.393      0.254      0.799      -0.670       0.870
game_entropy                                 152.0131     50.762      2.995      0.003      52.521     251.505
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  228
Model:                          Logit   Df Residuals:                      213
Method:                           MLE   Df Model:                           14
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1150
Time:                        09:26:43   Log-Likelihood:                -127.81
converged:                       True   LL-Null:                       -144.42
Covariance Type:            nonrobust   LLR p-value:                  0.002672
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.6753      1.804     -0.929      0.353      -5.210       1.860
C(topic_grouped)[T.Geography]                  0.8705      0.650      1.339      0.181      -0.404       2.145
C(topic_grouped)[T.Misc]                       0.7533      0.625      1.206      0.228      -0.471       1.978
C(topic_grouped)[T.Music]                      0.2802      0.733      0.382      0.702      -1.157       1.717
C(topic_grouped)[T.Other]                      0.0109      0.674      0.016      0.987      -1.310       1.332
C(topic_grouped)[T.Politics]                   0.6431      0.568      1.132      0.258      -0.471       1.757
C(topic_grouped)[T.Science and technology]     0.5981      0.561      1.065      0.287      -0.502       1.698
C(topic_grouped)[T.Sports]                     0.5550      0.694      0.800      0.424      -0.805       1.915
C(answer_type_grouped)[T.Number]              -0.0773      0.508     -0.152      0.879      -1.073       0.918
C(answer_type_grouped)[T.Other]               -0.6051      0.411     -1.472      0.141      -1.411       0.200
C(answer_type_grouped)[T.Person]              -0.9951      0.440     -2.260      0.024      -1.858      -0.132
C(answer_type_grouped)[T.Place]               -0.5683      0.653     -0.870      0.385      -1.849       0.712
q_length                                       0.0966      0.395      0.245      0.807      -0.678       0.871
capabilities_entropy                         110.6309     69.746      1.586      0.113     -26.068     247.330
game_entropy                                 152.7424     51.127      2.987      0.003      52.535     252.950
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing gemini-2.5-flash-lite_think (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/gemini-2.5-flash-lite_think_SimpleMC_redacted_temp1.0_1758167956_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
1    142
0    130
Name: count, dtype: int64

Answer change%: 0.5221 [0.4626965421296195, 0.5814211049292041] (n=272)
P-value vs 25%: 2.645e-19; P-value vs 0%: 1.406e-66
Phase 2 self-accuracy: 0.4577 [0.3758023929008596, 0.5396905648456193] (n=142)
P-value vs 25%: 6.732e-07; P-value vs 33%: 0.002848

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  272
Model:                          Logit   Df Residuals:                      270
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.02623
Time:                        09:26:43   Log-Likelihood:                -183.33
converged:                       True   LL-Null:                       -188.27
Covariance Type:            nonrobust   LLR p-value:                  0.001675
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept       4645.2619   2225.079      2.088      0.037     284.187    9006.336
p_i_capability -4645.3526   2225.145     -2.088      0.037   -9006.557    -284.148
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  272
Model:                          Logit   Df Residuals:                      270
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.02707
Time:                        09:26:43   Log-Likelihood:                -183.17
converged:                       True   LL-Null:                       -188.27
Covariance Type:            nonrobust   LLR p-value:                  0.001410
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -0.0889      0.139     -0.641      0.522      -0.361       0.183
capabilities_entropy   367.7758    172.042      2.138      0.033      30.580     704.971
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.1085 [0.0549, 0.1622] (n=129)
                  P-value vs 33.3%: 2.234e-16

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=1.45, p=0.149
Wilcoxon delta_p: statistic=445.00, p=1.88e-17
Mean Δp = 0.0004  [-0.0001, 0.0009]
Idea 1 N = 123; 

  Idea 1.5: Calibration Metrics
  NLL: 12.1289, Signed ECE (overconf pos under neg): 0.0033, ECE: 0.0033 (n=93)
  Brier: 0.0005, Reliability (absolute calibration error; lower better): 0.0005, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=93)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       1.000
Model:                            OLS   Adj. R-squared:                  1.000
Method:                 Least Squares   F-statistic:                 1.778e+06
Date:                Sat, 20 Sep 2025   Prob (F-statistic):               0.00
Time:                        09:26:43   Log-Likelihood:                 832.39
No. Observations:                 186   AIC:                            -1657.
Df Residuals:                     182   BIC:                            -1644.
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -2.7323      4.950     -0.552      0.582     -12.498       7.034
p1                    2.7328      4.950      0.552      0.582      -7.034      12.499
answer_changed        2.7342      4.950      0.552      0.581      -7.032      12.500
p1:answer_changed    -1.7351      4.950     -0.351      0.726     -11.502       8.031
==============================================================================
Omnibus:                      255.300   Durbin-Watson:                   1.745
Prob(Omnibus):                  0.000   Jarque-Bera (JB):            73275.223
Skew:                           5.124   Prob(JB):                         0.00
Kurtosis:                      99.695   Cond. No.                     7.32e+04
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The condition number is large, 7.32e+04. This might indicate that there are
strong multicollinearity or other numerical problems.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-0.08, p=0.935
Wilcoxon delta_H: statistic=3630.00, p=0.644
Mean ΔH = -0.0030  [-0.0756, 0.0696]
Paired t-test delta_H Changed: statistic=45.40, p=8.74e-81
Wilcoxon delta_H Changed: statistic=0.00, p=6.51e-23
Mean ΔH Changed = 1.2394  [1.1859, 1.2929]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=0.71, p=0.481
Wilcoxon (p_top2_game vs p_top2_base): statistic=2691.00, p=2.7e-30
Mean Δp_top2 = 0.0001  [-0.0001, 0.0003] (n=252)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=13.96, p=3.7e-33
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=4151.00, p=2.5e-24
Mean ΔH_unchosen_baseline_set = 0.6330  [0.5441, 0.7219] (n=252)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  252
Model:                          Logit   Df Residuals:                      249
Method:                           MLE   Df Model:                            2
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.02948
Time:                        09:26:43   Log-Likelihood:                -169.45
converged:                       True   LL-Null:                       -174.60
Covariance Type:            nonrobust   LLR p-value:                  0.005817
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept        6.5800      3.107      2.118      0.034       0.490      12.670
p1_z           -72.1426     34.052     -2.119      0.034    -138.884      -5.401
I(p1_z ** 2)    -6.0386      5.725     -1.055      0.292     -17.260       5.182
================================================================================
AUC = 0.578

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  272
Model:                          Logit   Df Residuals:                      270
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:               6.805e-06
Time:                        09:26:43   Log-Likelihood:                -188.27
converged:                       True   LL-Null:                       -188.27
Covariance Type:            nonrobust   LLR p-value:                    0.9596
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept        0.0895      0.124      0.724      0.469      -0.153       0.332
game_entropy    -0.3581      7.074     -0.051      0.960     -14.222      13.506
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=4511.00, p=2.71e-27
Paired t-test (game_entropy vs capabilities_entropy): statistic=-0.71, p=0.477
Mean capabilities_entropy-game_entropy = 0.0029  [-0.0051, 0.0109] (n=272)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  272
Model:                          Logit   Df Residuals:                      269
Method:                           MLE   Df Model:                            2
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.02707
Time:                        09:26:43   Log-Likelihood:                -183.17
converged:                       True   LL-Null:                       -188.27
Covariance Type:            nonrobust   LLR p-value:                  0.006117
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -0.0887      0.141     -0.629      0.529      -0.365       0.187
capabilities_entropy   367.7378    172.087      2.137      0.033      30.454     705.022
game_entropy            -0.0633      7.085     -0.009      0.993     -13.950      13.823
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.526316
                        1                 0.473684
Geography               1                 0.545455
                        0                 0.454545
Misc                    0                 0.629630
                        1                 0.370370
Music                   0                 0.521739
                        1                 0.478261
Other                   1                 0.518519
                        0                 0.481481
Politics                1                 0.552632
                        0                 0.447368
Science and technology  1                 0.527273
                        0                 0.472727
Sports                  1                 0.727273
                        0                 0.272727
TV shows                1                 0.550000
                        0                 0.450000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 1                 0.510417
                     0                 0.489583
Number               1                 0.509804
                     0                 0.490196
Other                1                 0.564516
                     0                 0.435484
Person               1                 0.507937
                     0                 0.492063
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.454545  0.545455           11
                       Number               0.400000  0.600000            5
                       Other                0.714286  0.285714            7
                       Person               0.533333  0.466667           15
Geography              Date                 0.400000  0.600000           10
                       Number               0.400000  0.600000           10
                       Other                1.000000  0.000000            2
Misc                   Date                 0.714286  0.285714           14
                       Number               0.500000  0.500000            6
                       Other                0.600000  0.400000            5
                       Person               0.500000  0.500000            2
Music                  Date                 0.428571  0.571429            7
                       Number               0.250000  0.750000            4
                       Other                0.750000  0.250000            8
                       Person               0.500000  0.500000            4
Other                  Date                 0.416667  0.583333           12
                       Number               1.000000  0.000000            4
                       Other                0.500000  0.500000            6
                       Person               0.200000  0.800000            5
Politics               Date                 0.500000  0.500000           18
                       Number               0.500000  0.500000            4
                       Other                0.142857  0.857143            7
                       Person               0.555556  0.444444            9
Science and technology Date                 0.529412  0.470588           17
                       Number               0.444444  0.555556            9
                       Other                0.333333  0.666667            9
                       Person               0.500000  0.500000           20
Sports                 Date                 0.000000  1.000000            5
                       Number               0.500000  0.500000            8
                       Other                0.142857  0.857143            7
                       Person               0.500000  0.500000            2
TV shows               Date                 1.000000  0.000000            2
                       Number               1.000000  0.000000            1
                       Other                0.272727  0.727273           11
                       Person               0.500000  0.500000            6

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  272
Model:                          Logit   Df Residuals:                      259
Method:                           MLE   Df Model:                           12
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.02121
Time:                        09:26:43   Log-Likelihood:                -184.28
converged:                       True   LL-Null:                       -188.27
Covariance Type:            nonrobust   LLR p-value:                    0.7862
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      0.8092      1.666      0.486      0.627      -2.457       4.075
C(topic_grouped)[T.Geography]                  0.2994      0.562      0.533      0.594      -0.802       1.401
C(topic_grouped)[T.Misc]                      -0.4224      0.525     -0.804      0.421      -1.452       0.607
C(topic_grouped)[T.Music]                     -0.0456      0.539     -0.085      0.933      -1.102       1.011
C(topic_grouped)[T.Other]                      0.1343      0.513      0.262      0.793      -0.870       1.139
C(topic_grouped)[T.Politics]                   0.3548      0.472      0.752      0.452      -0.570       1.279
C(topic_grouped)[T.Science and technology]     0.2131      0.424      0.503      0.615      -0.617       1.043
C(topic_grouped)[T.Sports]                     1.0857      0.591      1.836      0.066      -0.073       2.245
C(topic_grouped)[T.TV shows]                   0.2015      0.570      0.354      0.724      -0.916       1.319
C(answer_type_grouped)[T.Number]              -0.1083      0.361     -0.300      0.764      -0.817       0.600
C(answer_type_grouped)[T.Other]                0.1309      0.349      0.375      0.707      -0.553       0.815
C(answer_type_grouped)[T.Person]              -0.0611      0.347     -0.176      0.860      -0.741       0.619
q_length                                      -0.1998      0.354     -0.565      0.572      -0.893       0.493
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.0062
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  272
Model:                          Logit   Df Residuals:                      258
Method:                           MLE   Df Model:                           13
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.04858
Time:                        09:26:43   Log-Likelihood:                -179.12
converged:                       True   LL-Null:                       -188.27
Covariance Type:            nonrobust   LLR p-value:                    0.1467
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      0.3175      1.689      0.188      0.851      -2.993       3.628
C(topic_grouped)[T.Geography]                  0.2842      0.580      0.490      0.624      -0.853       1.421
C(topic_grouped)[T.Misc]                      -0.3899      0.539     -0.724      0.469      -1.446       0.666
C(topic_grouped)[T.Music]                      0.1177      0.548      0.215      0.830      -0.956       1.192
C(topic_grouped)[T.Other]                      0.1767      0.528      0.334      0.738      -0.859       1.212
C(topic_grouped)[T.Politics]                   0.4251      0.481      0.883      0.377      -0.518       1.369
C(topic_grouped)[T.Science and technology]     0.2891      0.435      0.665      0.506      -0.563       1.142
C(topic_grouped)[T.Sports]                     1.1571      0.601      1.927      0.054      -0.020       2.334
C(topic_grouped)[T.TV shows]                   0.1482      0.590      0.251      0.802      -1.009       1.305
C(answer_type_grouped)[T.Number]              -0.1113      0.367     -0.304      0.761      -0.830       0.607
C(answer_type_grouped)[T.Other]                0.1158      0.353      0.328      0.743      -0.576       0.807
C(answer_type_grouped)[T.Person]              -0.1308      0.354     -0.370      0.712      -0.824       0.563
q_length                                      -0.1368      0.357     -0.384      0.701      -0.836       0.562
capabilities_entropy                         374.2014    174.157      2.149      0.032      32.859     715.543
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  272
Model:                          Logit   Df Residuals:                      258
Method:                           MLE   Df Model:                           13
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.02130
Time:                        09:26:43   Log-Likelihood:                -184.26
converged:                       True   LL-Null:                       -188.27
Covariance Type:            nonrobust   LLR p-value:                    0.8424
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      0.7915      1.669      0.474      0.635      -2.480       4.063
C(topic_grouped)[T.Geography]                  0.3009      0.562      0.535      0.592      -0.801       1.402
C(topic_grouped)[T.Misc]                      -0.4357      0.531     -0.821      0.412      -1.476       0.604
C(topic_grouped)[T.Music]                     -0.0441      0.539     -0.082      0.935      -1.101       1.013
C(topic_grouped)[T.Other]                      0.1366      0.513      0.266      0.790      -0.868       1.142
C(topic_grouped)[T.Politics]                   0.3479      0.473      0.735      0.462      -0.580       1.275
C(topic_grouped)[T.Science and technology]     0.2141      0.424      0.505      0.613      -0.616       1.044
C(topic_grouped)[T.Sports]                     1.0861      0.591      1.837      0.066      -0.073       2.245
C(topic_grouped)[T.TV shows]                   0.2012      0.570      0.353      0.724      -0.916       1.318
C(answer_type_grouped)[T.Number]              -0.1038      0.362     -0.287      0.774      -0.814       0.606
C(answer_type_grouped)[T.Other]                0.1335      0.349      0.382      0.702      -0.551       0.818
C(answer_type_grouped)[T.Person]              -0.0579      0.347     -0.167      0.867      -0.739       0.623
q_length                                      -0.1970      0.354     -0.556      0.578      -0.891       0.497
game_entropy                                   1.3358      7.350      0.182      0.856     -13.070      15.742
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  272
Model:                          Logit   Df Residuals:                      257
Method:                           MLE   Df Model:                           14
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.04871
Time:                        09:26:43   Log-Likelihood:                -179.10
converged:                       True   LL-Null:                       -188.27
Covariance Type:            nonrobust   LLR p-value:                    0.1917
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      0.2953      1.692      0.175      0.861      -3.021       3.611
C(topic_grouped)[T.Geography]                  0.2867      0.580      0.494      0.621      -0.850       1.424
C(topic_grouped)[T.Misc]                      -0.4061      0.544     -0.746      0.455      -1.472       0.660
C(topic_grouped)[T.Music]                      0.1199      0.548      0.219      0.827      -0.954       1.194
C(topic_grouped)[T.Other]                      0.1796      0.529      0.340      0.734      -0.857       1.216
C(topic_grouped)[T.Politics]                   0.4167      0.483      0.863      0.388      -0.530       1.363
C(topic_grouped)[T.Science and technology]     0.2903      0.435      0.667      0.504      -0.562       1.143
C(topic_grouped)[T.Sports]                     1.1578      0.601      1.928      0.054      -0.019       2.335
C(topic_grouped)[T.TV shows]                   0.1489      0.590      0.252      0.801      -1.008       1.306
C(answer_type_grouped)[T.Number]              -0.1057      0.367     -0.288      0.774      -0.826       0.615
C(answer_type_grouped)[T.Other]                0.1193      0.353      0.338      0.736      -0.573       0.811
C(answer_type_grouped)[T.Person]              -0.1270      0.354     -0.358      0.720      -0.822       0.568
q_length                                      -0.1334      0.357     -0.374      0.709      -0.833       0.566
capabilities_entropy                         375.5085    174.533      2.151      0.031      33.429     717.588
game_entropy                                   1.6208      7.376      0.220      0.826     -12.835      16.077
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing gemini-2.5-flash-preview-04-17 (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/gemini-2.5-flash-preview-04-17_SimpleMC_redacted_cor_temp0.0_1751802958_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    254
1     81
Name: count, dtype: int64

Answer change%: 0.2418 [0.19594094889328484, 0.28764114065895396] (n=335)
P-value vs 25%: 0.7257; P-value vs 0%: 4.849e-25
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=81)
P-value vs 25%: 0; P-value vs 33%: 0

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  335
Model:                          Logit   Df Residuals:                      333
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1398
Time:                        09:26:43   Log-Likelihood:                -159.40
converged:                       True   LL-Null:                       -185.30
Covariance Type:            nonrobust   LLR p-value:                 6.118e-13
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.5799      0.158    -10.030      0.000      -1.889      -1.271
game_entropy   195.2384     48.922      3.991      0.000      99.354     291.123
================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['Music', 'History', 'TV shows', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': None
topic_grouped           answer_changed
Art                     0                 0.824561
                        1                 0.175439
Geography               0                 0.709677
                        1                 0.290323
Misc                    0                 0.688525
                        1                 0.311475
Other                   0                 0.864865
                        1                 0.135135
Politics                0                 0.803571
                        1                 0.196429
Science and technology  0                 0.692308
                        1                 0.307692
Sports                  0                 0.750000
                        1                 0.250000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.800000
                     1                 0.200000
Number               0                 0.581395
                     1                 0.418605
Other                0                 0.720588
                     1                 0.279412
Person               0                 0.767442
                     1                 0.232558
Place                0                 0.956522
                     1                 0.043478
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.882353  0.117647           17
                       Number               0.571429  0.428571            7
                       Other                0.555556  0.444444            9
                       Person               0.947368  0.052632           19
                       Place                1.000000  0.000000            5
Geography              Date                 0.600000  0.400000           10
                       Number               0.727273  0.272727           11
                       Other                0.666667  0.333333            3
                       Place                0.857143  0.142857            7
Misc                   Date                 0.684211  0.315789           19
                       Number               0.833333  0.166667            6
                       Other                0.812500  0.187500           16
                       Person               0.526316  0.473684           19
                       Place                1.000000  0.000000            1
Other                  Date                 0.909091  0.090909           11
                       Number               0.666667  0.333333            3
                       Other                0.750000  0.250000            8
                       Person               0.909091  0.090909           11
                       Place                1.000000  0.000000            4
Politics               Date                 0.840000  0.160000           25
                       Number               0.500000  0.500000            4
                       Other                0.818182  0.181818           11
                       Person               0.727273  0.272727           11
                       Place                1.000000  0.000000            5
Science and technology Date                 0.791667  0.208333           24
                       Number               0.142857  0.857143            7
                       Other                0.666667  0.333333           12
                       Person               0.761905  0.238095           21
                       Place                1.000000  0.000000            1
Sports                 Date                 0.888889  0.111111            9
                       Number               0.600000  0.400000            5
                       Other                0.666667  0.333333            9
                       Person               0.800000  0.200000            5

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  335
Model:                          Logit   Df Residuals:                      323
Method:                           MLE   Df Model:                           11
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.06864
Time:                        09:26:43   Log-Likelihood:                -172.58
converged:                       True   LL-Null:                       -185.30
Covariance Type:            nonrobust   LLR p-value:                  0.007856
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -5.0820      1.732     -2.935      0.003      -8.476      -1.688
C(topic_grouped)[T.Geography]                  0.7312      0.576      1.270      0.204      -0.397       1.860
C(topic_grouped)[T.Misc]                       0.6879      0.456      1.510      0.131      -0.205       1.581
C(topic_grouped)[T.Other]                     -0.2635      0.604     -0.436      0.663      -1.448       0.921
C(topic_grouped)[T.Politics]                   0.0293      0.510      0.057      0.954      -0.970       1.028
C(topic_grouped)[T.Science and technology]     0.6194      0.454      1.365      0.172      -0.270       1.509
C(topic_grouped)[T.Sports]                     0.2638      0.575      0.459      0.646      -0.863       1.391
C(answer_type_grouped)[T.Number]               0.9388      0.408      2.302      0.021       0.139       1.738
C(answer_type_grouped)[T.Other]                0.5005      0.368      1.361      0.174      -0.220       1.221
C(answer_type_grouped)[T.Person]               0.2829      0.359      0.787      0.431      -0.421       0.987
C(answer_type_grouped)[T.Place]               -1.7148      1.071     -1.601      0.109      -3.814       0.384
q_length                                       0.7357      0.373      1.973      0.048       0.005       1.467
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  335
Model:                          Logit   Df Residuals:                      322
Method:                           MLE   Df Model:                           12
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1910
Time:                        09:26:43   Log-Likelihood:                -149.91
converged:                       True   LL-Null:                       -185.30
Covariance Type:            nonrobust   LLR p-value:                 2.289e-10
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -5.3904      1.870     -2.883      0.004      -9.055      -1.726
C(topic_grouped)[T.Geography]                  0.5168      0.623      0.829      0.407      -0.705       1.738
C(topic_grouped)[T.Misc]                       0.5107      0.491      1.041      0.298      -0.451       1.472
C(topic_grouped)[T.Other]                     -0.4398      0.642     -0.685      0.493      -1.698       0.819
C(topic_grouped)[T.Politics]                  -0.0134      0.540     -0.025      0.980      -1.072       1.045
C(topic_grouped)[T.Science and technology]     0.5636      0.477      1.182      0.237      -0.371       1.498
C(topic_grouped)[T.Sports]                    -0.3507      0.699     -0.502      0.616      -1.721       1.020
C(answer_type_grouped)[T.Number]               0.8223      0.461      1.784      0.074      -0.081       1.726
C(answer_type_grouped)[T.Other]                0.5234      0.399      1.311      0.190      -0.259       1.306
C(answer_type_grouped)[T.Person]               0.3381      0.389      0.868      0.385      -0.425       1.101
C(answer_type_grouped)[T.Place]               -1.4849      1.085     -1.369      0.171      -3.612       0.642
q_length                                       0.7377      0.403      1.830      0.067      -0.052       1.528
game_entropy                                 198.7938     53.793      3.696      0.000      93.361     304.226
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing gemini-2.5-flash-preview-04-17 (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/gemini-2.5-flash-preview-04-17_SimpleMC_redacted_temp0.0_1751726354_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
1    95
0    70
Name: count, dtype: int64

Answer change%: 0.5758 [0.5003468713811036, 0.651168280134048] (n=165)
P-value vs 25%: 2.526e-17; P-value vs 0%: 1.257e-50
Phase 2 self-accuracy: 0.6000 [0.501487370995732, 0.6985126290042679] (n=95)
P-value vs 25%: 3.32e-12; P-value vs 33%: 1.084e-07

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  165
Model:                          Logit   Df Residuals:                      163
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                0.004136
Time:                        09:26:43   Log-Likelihood:                -112.00
converged:                       True   LL-Null:                       -112.47
Covariance Type:            nonrobust   LLR p-value:                    0.3348
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept        0.3225      0.159      2.032      0.042       0.011       0.634
game_entropy    -1.3116      1.724     -0.761      0.447      -4.691       2.068
================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['Video games', 'History']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.500000
                        1                 0.500000
Geography               1                 0.846154
                        0                 0.153846
Misc                    1                 0.700000
                        0                 0.300000
Music                   1                 0.555556
                        0                 0.444444
Other                   0                 0.666667
                        1                 0.333333
Politics                1                 0.571429
                        0                 0.428571
Science and technology  1                 0.606061
                        0                 0.393939
Sports                  0                 0.500000
                        1                 0.500000
TV shows                1                 0.533333
                        0                 0.466667
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 1                 0.685185
                     0                 0.314815
Number               1                 0.571429
                     0                 0.428571
Other                1                 0.571429
                     0                 0.428571
Person               0                 0.588235
                     1                 0.411765
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.500000  0.500000            4
                       Number               0.000000  1.000000            2
                       Other                0.500000  0.500000            4
                       Person               0.625000  0.375000            8
Geography              Date                 0.200000  0.800000            5
                       Number               0.142857  0.857143            7
                       Other                0.000000  1.000000            1
Misc                   Date                 0.000000  1.000000            9
                       Number               1.000000  0.000000            3
                       Other                0.500000  0.500000            6
                       Person               0.000000  1.000000            2
Music                  Date                 0.600000  0.400000            5
                       Number               0.333333  0.666667            3
                       Other                0.285714  0.714286            7
                       Person               0.666667  0.333333            3
Other                  Date                 0.571429  0.428571            7
                       Number               0.750000  0.250000            4
                       Other                0.500000  0.500000            2
                       Person               1.000000  0.000000            2
Politics               Date                 0.363636  0.636364           11
                       Number               0.500000  0.500000            2
                       Other                0.500000  0.500000            4
                       Person               0.500000  0.500000            4
Science and technology Date                 0.272727  0.727273           11
                       Number               0.571429  0.428571            7
                       Other                0.333333  0.666667            6
                       Person               0.444444  0.555556            9
Sports                 Number               0.333333  0.666667            6
                       Other                0.333333  0.666667            3
                       Person               1.000000  0.000000            3
TV shows               Date                 0.000000  1.000000            2
                       Number               0.000000  1.000000            1
                       Other                0.555556  0.444444            9
                       Person               0.666667  0.333333            3

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  165
Model:                          Logit   Df Residuals:                      152
Method:                           MLE   Df Model:                           12
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.09603
Time:                        09:26:43   Log-Likelihood:                -101.67
converged:                       True   LL-Null:                       -112.47
Covariance Type:            nonrobust   LLR p-value:                   0.04225
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      5.6234      2.182      2.577      0.010       1.347       9.900
C(topic_grouped)[T.Geography]                  1.4261      0.975      1.463      0.143      -0.484       3.337
C(topic_grouped)[T.Misc]                       0.6672      0.723      0.923      0.356      -0.750       2.085
C(topic_grouped)[T.Music]                     -0.1730      0.709     -0.244      0.807      -1.563       1.217
C(topic_grouped)[T.Other]                     -1.2137      0.771     -1.574      0.116      -2.725       0.298
C(topic_grouped)[T.Politics]                   0.0357      0.686      0.052      0.958      -1.308       1.379
C(topic_grouped)[T.Science and technology]     0.3225      0.622      0.518      0.604      -0.897       1.542
C(topic_grouped)[T.Sports]                     0.0480      0.791      0.061      0.952      -1.502       1.598
C(topic_grouped)[T.TV shows]                  -0.1671      0.745     -0.224      0.823      -1.628       1.293
C(answer_type_grouped)[T.Number]              -0.7750      0.514     -1.507      0.132      -1.783       0.233
C(answer_type_grouped)[T.Other]               -0.6826      0.481     -1.421      0.155      -1.624       0.259
C(answer_type_grouped)[T.Person]              -1.3108      0.504     -2.600      0.009      -2.299      -0.323
q_length                                      -1.0545      0.448     -2.355      0.019      -1.932      -0.177
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  165
Model:                          Logit   Df Residuals:                      151
Method:                           MLE   Df Model:                           13
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1184
Time:                        09:26:43   Log-Likelihood:                -99.147
converged:                       True   LL-Null:                       -112.47
Covariance Type:            nonrobust   LLR p-value:                   0.01392
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      6.1634      2.230      2.764      0.006       1.793      10.534
C(topic_grouped)[T.Geography]                  2.2164      1.188      1.866      0.062      -0.111       4.544
C(topic_grouped)[T.Misc]                       0.7075      0.728      0.972      0.331      -0.719       2.134
C(topic_grouped)[T.Music]                     -0.1818      0.712     -0.255      0.799      -1.577       1.214
C(topic_grouped)[T.Other]                     -1.2448      0.775     -1.607      0.108      -2.763       0.273
C(topic_grouped)[T.Politics]                   0.0173      0.689      0.025      0.980      -1.334       1.369
C(topic_grouped)[T.Science and technology]     0.3478      0.626      0.556      0.578      -0.879       1.574
C(topic_grouped)[T.Sports]                     0.1300      0.794      0.164      0.870      -1.427       1.687
C(topic_grouped)[T.TV shows]                  -0.1769      0.747     -0.237      0.813      -1.641       1.287
C(answer_type_grouped)[T.Number]              -0.9845      0.532     -1.850      0.064      -2.028       0.058
C(answer_type_grouped)[T.Other]               -0.8003      0.490     -1.633      0.102      -1.761       0.160
C(answer_type_grouped)[T.Person]              -1.4104      0.512     -2.755      0.006      -2.414      -0.407
q_length                                      -1.1515      0.457     -2.520      0.012      -2.047      -0.256
game_entropy                                  -3.3319      2.139     -1.558      0.119      -7.524       0.860
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing gemini-2.5-flash_nothink (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/gemini-2.5-flash_nothink_SimpleMC_redacted_cor_temp1.0_1757984473_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    172
1     81
Name: count, dtype: int64

Answer change%: 0.3202 [0.2626705207546876, 0.3776456847789092] (n=253)
P-value vs 25%: 0.01676; P-value vs 0%: 9.733e-28
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=81)
P-value vs 25%: 0; P-value vs 33%: 0

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  253
Model:                          Logit   Df Residuals:                      251
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1357
Time:                        09:26:43   Log-Likelihood:                -137.11
converged:                       True   LL-Null:                       -158.63
Covariance Type:            nonrobust   LLR p-value:                 5.370e-11
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          2.2474      0.495      4.543      0.000       1.278       3.217
p_i_capability    -4.0363      0.655     -6.159      0.000      -5.321      -2.752
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  253
Model:                          Logit   Df Residuals:                      251
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1370
Time:                        09:26:43   Log-Likelihood:                -136.90
converged:                       True   LL-Null:                       -158.63
Covariance Type:            nonrobust   LLR p-value:                 4.333e-11
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.0243      0.273     -7.415      0.000      -2.559      -1.489
capabilities_entropy     1.3964      0.229      6.107      0.000       0.948       1.845
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.6049 [0.4985, 0.7114] (n=81)
                  P-value vs 33.3%: 5.725e-07

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=9.09, p=2.41e-16
Wilcoxon delta_p: statistic=2164.00, p=7.29e-16
Mean Δp = 0.1199  [0.0941, 0.1458]
Idea 1 N = 172; 

  Idea 1.5: Calibration Metrics
  NLL: 0.3101, Signed ECE (overconf pos under neg): -0.2264, ECE: 0.2264 (n=253)
  Brier: 0.1025, Reliability (absolute calibration error; lower better): 0.1017, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=253)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.593
Model:                            OLS   Adj. R-squared:                  0.588
Method:                 Least Squares   F-statistic:                     120.5
Date:                Sat, 20 Sep 2025   Prob (F-statistic):           3.67e-48
Time:                        09:26:43   Log-Likelihood:                 121.61
No. Observations:                 252   AIC:                            -235.2
Df Residuals:                     248   BIC:                            -221.1
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.0010      0.050     -0.021      0.983      -0.099       0.097
p1                    0.1444      0.058      2.488      0.014       0.030       0.259
answer_changed       -0.2193      0.071     -3.078      0.002      -0.360      -0.079
p1:answer_changed     0.8325      0.095      8.735      0.000       0.645       1.020
==============================================================================
Omnibus:                       25.628   Durbin-Watson:                   1.864
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               30.837
Skew:                           0.763   Prob(JB):                     2.01e-07
Kurtosis:                       3.778   Cond. No.                         18.2
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-6.40, p=1.44e-09
Wilcoxon delta_H: statistic=3720.00, p=1.3e-08
Mean ΔH = -0.2240  [-0.2926, -0.1554]
Paired t-test delta_H Changed: statistic=-2.97, p=0.00392
Wilcoxon delta_H Changed: statistic=1084.00, p=0.00664
Mean ΔH Changed = -0.1206  [-0.2001, -0.0410]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=-14.31, p=2.07e-34
Wilcoxon (p_top2_game vs p_top2_base): statistic=1730.00, p=8.65e-35
Mean Δp_top2 = -0.1056  [-0.1201, -0.0912] (n=253)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=-7.01, p=2.2e-11
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=8757.00, p=3.55e-10
Mean ΔH_unchosen_baseline_set = -0.1909  [-0.2442, -0.1375] (n=253)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  253
Model:                          Logit   Df Residuals:                      250
Method:                           MLE   Df Model:                            2
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1394
Time:                        09:26:43   Log-Likelihood:                -136.52
converged:                       True   LL-Null:                       -158.63
Covariance Type:            nonrobust   LLR p-value:                 2.496e-10
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.6910      0.226     -3.060      0.002      -1.134      -0.248
p1_z            -1.0662      0.208     -5.130      0.000      -1.473      -0.659
I(p1_z ** 2)    -0.2114      0.194     -1.091      0.275      -0.591       0.168
================================================================================
AUC = 0.770

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  253
Model:                          Logit   Df Residuals:                      251
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.2372
Time:                        09:26:43   Log-Likelihood:                -121.01
converged:                       True   LL-Null:                       -158.63
Covariance Type:            nonrobust   LLR p-value:                 4.172e-18
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -4.2257      0.614     -6.881      0.000      -5.429      -3.022
game_entropy     2.4586      0.375      6.554      0.000       1.723       3.194
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=3178.00, p=1.94e-28
Paired t-test (game_entropy vs capabilities_entropy): statistic=13.34, p=4.62e-31
Mean capabilities_entropy-game_entropy = -0.4145  [-0.4755, -0.3536] (n=253)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  253
Model:                          Logit   Df Residuals:                      250
Method:                           MLE   Df Model:                            2
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.2398
Time:                        09:26:43   Log-Likelihood:                -120.60
converged:                       True   LL-Null:                       -158.63
Covariance Type:            nonrobust   LLR p-value:                 3.042e-17
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -4.1593      0.611     -6.803      0.000      -5.358      -2.961
capabilities_entropy     0.2745      0.302      0.908      0.364      -0.318       0.867
game_entropy             2.2303      0.446      5.006      0.000       1.357       3.104
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': None
topic_grouped           answer_changed
Art                     0                 0.790698
                        1                 0.209302
Geography               1                 0.523810
                        0                 0.476190
Misc                    0                 0.527778
                        1                 0.472222
Music                   0                 0.833333
                        1                 0.166667
Other                   0                 0.720000
                        1                 0.280000
Politics                0                 0.738095
                        1                 0.261905
Science and technology  0                 0.630435
                        1                 0.369565
Sports                  0                 0.727273
                        1                 0.272727
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.534884
                     1                 0.465116
Number               0                 0.555556
                     1                 0.444444
Other                0                 0.795918
                     1                 0.204082
Person               0                 0.852459
                     1                 0.147541
Place                0                 0.714286
                     1                 0.285714
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.500000  0.500000           10
                       Number               0.750000  0.250000            4
                       Other                0.875000  0.125000            8
                       Person               0.937500  0.062500           16
                       Place                0.800000  0.200000            5
Geography              Date                 0.166667  0.833333            6
                       Number               0.333333  0.666667            6
                       Other                0.666667  0.333333            3
                       Place                0.833333  0.166667            6
Misc                   Date                 0.400000  0.600000           10
                       Number               0.285714  0.714286            7
                       Other                0.600000  0.400000           10
                       Person               0.750000  0.250000            8
                       Place                1.000000  0.000000            1
Music                  Date                 0.571429  0.428571            7
                       Number               1.000000  0.000000            1
                       Other                1.000000  0.000000            3
                       Person               1.000000  0.000000            7
Other                  Date                 0.500000  0.500000            8
                       Number               0.666667  0.333333            3
                       Other                1.000000  0.000000            3
                       Person               1.000000  0.000000            7
                       Place                0.500000  0.500000            4
Politics               Date                 0.761905  0.238095           21
                       Number               0.666667  0.333333            3
                       Other                1.000000  0.000000            6
                       Person               0.500000  0.500000            8
                       Place                0.750000  0.250000            4
Science and technology Date                 0.500000  0.500000           20
                       Number               0.800000  0.200000            5
                       Other                0.700000  0.300000           10
                       Person               0.800000  0.200000           10
                       Place                0.000000  1.000000            1
Sports                 Date                 0.500000  0.500000            4
                       Number               0.571429  0.428571            7
                       Other                0.833333  0.166667            6
                       Person               1.000000  0.000000            5

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  253
Model:                          Logit   Df Residuals:                      240
Method:                           MLE   Df Model:                           12
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1114
Time:                        09:26:43   Log-Likelihood:                -140.95
converged:                       True   LL-Null:                       -158.63
Covariance Type:            nonrobust   LLR p-value:                 0.0004109
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -0.0991      1.802     -0.055      0.956      -3.632       3.434
C(topic_grouped)[T.Geography]                  1.1044      0.616      1.792      0.073      -0.103       2.312
C(topic_grouped)[T.Misc]                       1.1692      0.532      2.197      0.028       0.126       2.212
C(topic_grouped)[T.Music]                     -0.4621      0.769     -0.601      0.548      -1.969       1.044
C(topic_grouped)[T.Other]                      0.2243      0.609      0.368      0.713      -0.969       1.418
C(topic_grouped)[T.Politics]                  -0.0478      0.554     -0.086      0.931      -1.134       1.038
C(topic_grouped)[T.Science and technology]     0.5769      0.516      1.117      0.264      -0.435       1.589
C(topic_grouped)[T.Sports]                     0.2218      0.646      0.344      0.731      -1.043       1.487
C(answer_type_grouped)[T.Number]              -0.3021      0.431     -0.701      0.483      -1.147       0.543
C(answer_type_grouped)[T.Other]               -1.4044      0.438     -3.209      0.001      -2.262      -0.547
C(answer_type_grouped)[T.Person]              -1.5995      0.439     -3.643      0.000      -2.460      -0.739
C(answer_type_grouped)[T.Place]               -0.9252      0.575     -1.609      0.108      -2.052       0.202
q_length                                      -0.0812      0.389     -0.209      0.835      -0.843       0.681
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.8057
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  253
Model:                          Logit   Df Residuals:                      239
Method:                           MLE   Df Model:                           13
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1966
Time:                        09:26:43   Log-Likelihood:                -127.44
converged:                       True   LL-Null:                       -158.63
Covariance Type:            nonrobust   LLR p-value:                 1.975e-08
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.2298      1.926     -0.638      0.523      -5.005       2.546
C(topic_grouped)[T.Geography]                  1.2343      0.668      1.847      0.065      -0.076       2.544
C(topic_grouped)[T.Misc]                       1.1524      0.557      2.068      0.039       0.060       2.245
C(topic_grouped)[T.Music]                     -0.3510      0.814     -0.431      0.666      -1.946       1.244
C(topic_grouped)[T.Other]                      0.1277      0.642      0.199      0.842      -1.130       1.386
C(topic_grouped)[T.Politics]                   0.1201      0.583      0.206      0.837      -1.023       1.264
C(topic_grouped)[T.Science and technology]     0.7599      0.545      1.396      0.163      -0.307       1.827
C(topic_grouped)[T.Sports]                     0.2333      0.696      0.335      0.737      -1.130       1.597
C(answer_type_grouped)[T.Number]              -0.3453      0.460     -0.751      0.453      -1.246       0.556
C(answer_type_grouped)[T.Other]               -1.0047      0.471     -2.132      0.033      -1.928      -0.081
C(answer_type_grouped)[T.Person]              -1.0559      0.465     -2.269      0.023      -1.968      -0.144
C(answer_type_grouped)[T.Place]               -0.7030      0.600     -1.171      0.242      -1.880       0.474
q_length                                      -0.1355      0.414     -0.327      0.744      -0.947       0.676
capabilities_entropy                           1.2258      0.248      4.937      0.000       0.739       1.712
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  253
Model:                          Logit   Df Residuals:                      239
Method:                           MLE   Df Model:                           13
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.2868
Time:                        09:26:43   Log-Likelihood:                -113.13
converged:                       True   LL-Null:                       -158.63
Covariance Type:            nonrobust   LLR p-value:                 9.033e-14
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.7853      2.116     -0.844      0.399      -5.933       2.363
C(topic_grouped)[T.Geography]                  1.1828      0.714      1.656      0.098      -0.217       2.583
C(topic_grouped)[T.Misc]                       1.0867      0.603      1.802      0.072      -0.096       2.269
C(topic_grouped)[T.Music]                     -0.5754      0.846     -0.680      0.497      -2.234       1.083
C(topic_grouped)[T.Other]                      0.0824      0.688      0.120      0.905      -1.266       1.430
C(topic_grouped)[T.Politics]                  -0.1202      0.618     -0.195      0.846      -1.331       1.091
C(topic_grouped)[T.Science and technology]     0.6302      0.593      1.063      0.288      -0.531       1.792
C(topic_grouped)[T.Sports]                     0.3369      0.743      0.453      0.650      -1.119       1.793
C(answer_type_grouped)[T.Number]              -0.4792      0.468     -1.024      0.306      -1.397       0.438
C(answer_type_grouped)[T.Other]               -0.4927      0.524     -0.940      0.347      -1.520       0.534
C(answer_type_grouped)[T.Person]              -0.8698      0.498     -1.748      0.080      -1.845       0.105
C(answer_type_grouped)[T.Place]               -0.1634      0.663     -0.247      0.805      -1.462       1.135
q_length                                      -0.5512      0.459     -1.201      0.230      -1.450       0.348
game_entropy                                   2.4632      0.419      5.885      0.000       1.643       3.283
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  253
Model:                          Logit   Df Residuals:                      238
Method:                           MLE   Df Model:                           14
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.2876
Time:                        09:26:43   Log-Likelihood:                -113.00
converged:                       True   LL-Null:                       -158.63
Covariance Type:            nonrobust   LLR p-value:                 2.194e-13
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.8346      2.116     -0.867      0.386      -5.981       2.312
C(topic_grouped)[T.Geography]                  1.1968      0.717      1.669      0.095      -0.208       2.602
C(topic_grouped)[T.Misc]                       1.0949      0.604      1.814      0.070      -0.088       2.278
C(topic_grouped)[T.Music]                     -0.5635      0.848     -0.664      0.507      -2.226       1.099
C(topic_grouped)[T.Other]                      0.0810      0.686      0.118      0.906      -1.263       1.425
C(topic_grouped)[T.Politics]                  -0.0910      0.622     -0.146      0.884      -1.309       1.127
C(topic_grouped)[T.Science and technology]     0.6580      0.596      1.105      0.269      -0.510       1.826
C(topic_grouped)[T.Sports]                     0.3488      0.745      0.468      0.640      -1.111       1.808
C(answer_type_grouped)[T.Number]              -0.4726      0.470     -1.006      0.315      -1.394       0.449
C(answer_type_grouped)[T.Other]               -0.4890      0.524     -0.933      0.351      -1.517       0.539
C(answer_type_grouped)[T.Person]              -0.8349      0.501     -1.666      0.096      -1.817       0.148
C(answer_type_grouped)[T.Place]               -0.1572      0.660     -0.238      0.812      -1.451       1.137
q_length                                      -0.5378      0.459     -1.171      0.242      -1.438       0.362
capabilities_entropy                           0.1655      0.320      0.518      0.605      -0.461       0.792
game_entropy                                   2.3291      0.489      4.762      0.000       1.370       3.288
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing gemini-2.5-flash_nothink (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/gemini-2.5-flash_nothink_SimpleMC_redacted_temp1.0_1758161562_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    130
1    117
Name: count, dtype: int64

Answer change%: 0.4737 [0.41141587338576746, 0.5359525476668641] (n=247)
P-value vs 25%: 1.913e-12; P-value vs 0%: 2.849e-50
Phase 2 self-accuracy: 0.5299 [0.4394774590058506, 0.6203516008232092] (n=117)
P-value vs 25%: 1.309e-09; P-value vs 33%: 1.976e-05

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  247
Model:                          Logit   Df Residuals:                      245
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.04977
Time:                        09:26:43   Log-Likelihood:                -162.36
converged:                       True   LL-Null:                       -170.87
Covariance Type:            nonrobust   LLR p-value:                 3.725e-05
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          1.6343      0.453      3.609      0.000       0.747       2.522
p_i_capability    -2.7205      0.683     -3.982      0.000      -4.059      -1.382
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  247
Model:                          Logit   Df Residuals:                      245
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.04794
Time:                        09:26:43   Log-Likelihood:                -162.67
converged:                       True   LL-Null:                       -170.87
Covariance Type:            nonrobust   LLR p-value:                 5.174e-05
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.3422      0.351     -3.819      0.000      -2.031      -0.653
capabilities_entropy     1.0077      0.261      3.866      0.000       0.497       1.519
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.6154 [0.5272, 0.7035] (n=117)
                  P-value vs 33.3%: 3.588e-10

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=7.83, p=1.53e-12
Wilcoxon delta_p: statistic=1333.00, p=1.08e-11
Mean Δp = 0.1302  [0.0976, 0.1628]
Idea 1 N = 130; 

  Idea 1.5: Calibration Metrics
  NLL: 2.4472, Signed ECE (overconf pos under neg): 0.1591, ECE: 0.1591 (n=247)
  Brier: 0.0398, Reliability (absolute calibration error; lower better): 0.0390, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=247)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.636
Model:                            OLS   Adj. R-squared:                  0.631
Method:                 Least Squares   F-statistic:                     141.4
Date:                Sat, 20 Sep 2025   Prob (F-statistic):           4.99e-53
Time:                        09:26:43   Log-Likelihood:                 139.95
No. Observations:                 247   AIC:                            -271.9
Df Residuals:                     243   BIC:                            -257.9
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.1148      0.042     -2.707      0.007      -0.198      -0.031
p1                    0.3535      0.059      6.030      0.000       0.238       0.469
answer_changed       -0.1266      0.061     -2.061      0.040      -0.248      -0.006
p1:answer_changed     0.6821      0.093      7.330      0.000       0.499       0.865
==============================================================================
Omnibus:                        9.557   Durbin-Watson:                   1.974
Prob(Omnibus):                  0.008   Jarque-Bera (JB):               12.860
Skew:                          -0.284   Prob(JB):                      0.00161
Kurtosis:                       3.962   Cond. No.                         18.5
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-8.18, p=2.35e-13
Wilcoxon delta_H: statistic=912.00, p=7.61e-15
Mean ΔH = -0.2494  [-0.3091, -0.1896]
Paired t-test delta_H Changed: statistic=-2.62, p=0.00989
Wilcoxon delta_H Changed: statistic=2393.00, p=0.00399
Mean ΔH Changed = -0.0834  [-0.1457, -0.0211]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=-17.61, p=1.83e-45
Wilcoxon (p_top2_game vs p_top2_base): statistic=1342.00, p=1.79e-35
Mean Δp_top2 = -0.1240  [-0.1378, -0.1102] (n=247)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=-7.56, p=8.05e-13
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=6471.00, p=3.62e-15
Mean ΔH_unchosen_baseline_set = -0.1708  [-0.2150, -0.1265] (n=247)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  247
Model:                          Logit   Df Residuals:                      244
Method:                           MLE   Df Model:                            2
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.05456
Time:                        09:26:43   Log-Likelihood:                -161.54
converged:                       True   LL-Null:                       -170.87
Covariance Type:            nonrobust   LLR p-value:                 8.943e-05
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept        0.0655      0.194      0.337      0.736      -0.315       0.446
p1_z            -0.5051      0.142     -3.569      0.000      -0.783      -0.228
I(p1_z ** 2)    -0.1946      0.153     -1.273      0.203      -0.494       0.105
================================================================================
AUC = 0.651

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  247
Model:                          Logit   Df Residuals:                      245
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.05758
Time:                        09:26:43   Log-Likelihood:                -161.03
converged:                       True   LL-Null:                       -170.87
Covariance Type:            nonrobust   LLR p-value:                 9.163e-06
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -2.2271      0.551     -4.044      0.000      -3.306      -1.148
game_entropy     1.3588      0.335      4.060      0.000       0.703       2.015
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=3789.00, p=1.14e-24
Paired t-test (game_entropy vs capabilities_entropy): statistic=11.73, p=1.61e-25
Mean capabilities_entropy-game_entropy = -0.3257  [-0.3801, -0.2712] (n=247)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  247
Model:                          Logit   Df Residuals:                      244
Method:                           MLE   Df Model:                            2
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.06580
Time:                        09:26:43   Log-Likelihood:                -159.62
converged:                       True   LL-Null:                       -170.87
Covariance Type:            nonrobust   LLR p-value:                 1.310e-05
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.2695      0.549     -4.132      0.000      -3.346      -1.193
capabilities_entropy     0.5372      0.322      1.666      0.096      -0.095       1.169
game_entropy             0.9626      0.403      2.388      0.017       0.172       1.753
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'Video games', 'History']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     1                 0.562500
                        0                 0.437500
Geography               0                 0.521739
                        1                 0.478261
Misc                    1                 0.526316
                        0                 0.473684
Music                   0                 0.636364
                        1                 0.363636
Other                   1                 0.592593
                        0                 0.407407
Politics                0                 0.600000
                        1                 0.400000
Science and technology  0                 0.557692
                        1                 0.442308
Sports                  0                 0.611111
                        1                 0.388889
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 1                 0.566265
                     0                 0.433735
Number               1                 0.523810
                     0                 0.476190
Other                0                 0.571429
                     1                 0.428571
Person               0                 0.644068
                     1                 0.355932
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.090909  0.909091           11
                       Number               0.400000  0.600000            5
                       Other                0.600000  0.400000            5
                       Person               0.727273  0.272727           11
Geography              Date                 0.444444  0.555556            9
                       Number               0.583333  0.416667           12
                       Other                0.500000  0.500000            2
Misc                   Date                 0.461538  0.538462           13
                       Number               0.000000  1.000000            2
                       Other                0.562500  0.437500           16
                       Person               0.428571  0.571429            7
Music                  Date                 0.800000  0.200000            5
                       Number               0.333333  0.666667            3
                       Other                0.555556  0.444444            9
                       Person               0.800000  0.200000            5
Other                  Date                 0.300000  0.700000           10
                       Number               0.250000  0.750000            4
                       Other                0.714286  0.285714            7
                       Person               0.333333  0.666667            6
Politics               Date                 0.600000  0.400000           15
                       Number               0.333333  0.666667            3
                       Other                0.600000  0.400000           10
                       Person               0.714286  0.285714            7
Science and technology Date                 0.400000  0.600000           15
                       Number               0.555556  0.444444            9
                       Other                0.500000  0.500000            8
                       Person               0.700000  0.300000           20
Sports                 Date                 0.600000  0.400000            5
                       Number               0.750000  0.250000            4
                       Other                0.500000  0.500000            6
                       Person               0.666667  0.333333            3

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  247
Model:                          Logit   Df Residuals:                      235
Method:                           MLE   Df Model:                           11
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.04552
Time:                        09:26:43   Log-Likelihood:                -163.09
converged:                       True   LL-Null:                       -170.87
Covariance Type:            nonrobust   LLR p-value:                    0.1585
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      3.2869      1.735      1.894      0.058      -0.114       6.687
C(topic_grouped)[T.Geography]                 -0.6879      0.583     -1.180      0.238      -1.830       0.455
C(topic_grouped)[T.Misc]                      -0.1064      0.505     -0.211      0.833      -1.096       0.883
C(topic_grouped)[T.Music]                     -0.8395      0.588     -1.428      0.153      -1.992       0.313
C(topic_grouped)[T.Other]                      0.0010      0.548      0.002      0.999      -1.072       1.074
C(topic_grouped)[T.Politics]                  -0.6613      0.516     -1.283      0.200      -1.672       0.349
C(topic_grouped)[T.Science and technology]    -0.4648      0.466     -0.998      0.318      -1.378       0.448
C(topic_grouped)[T.Sports]                    -0.7140      0.621     -1.150      0.250      -1.931       0.503
C(answer_type_grouped)[T.Number]              -0.0438      0.403     -0.109      0.913      -0.834       0.746
C(answer_type_grouped)[T.Other]               -0.6177      0.353     -1.748      0.080      -1.310       0.075
C(answer_type_grouped)[T.Person]              -0.9739      0.367     -2.657      0.008      -1.692      -0.255
q_length                                      -0.5808      0.374     -1.551      0.121      -1.315       0.153
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 1.2115
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  247
Model:                          Logit   Df Residuals:                      234
Method:                           MLE   Df Model:                           12
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.08437
Time:                        09:26:43   Log-Likelihood:                -156.45
converged:                       True   LL-Null:                       -170.87
Covariance Type:            nonrobust   LLR p-value:                  0.004172
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      2.2978      1.787      1.286      0.199      -1.205       5.801
C(topic_grouped)[T.Geography]                 -0.8623      0.599     -1.440      0.150      -2.036       0.312
C(topic_grouped)[T.Misc]                      -0.0771      0.516     -0.149      0.881      -1.089       0.935
C(topic_grouped)[T.Music]                     -0.9543      0.605     -1.578      0.115      -2.140       0.231
C(topic_grouped)[T.Other]                     -0.0087      0.559     -0.016      0.988      -1.105       1.087
C(topic_grouped)[T.Politics]                  -0.5890      0.529     -1.114      0.265      -1.625       0.447
C(topic_grouped)[T.Science and technology]    -0.5270      0.477     -1.104      0.269      -1.462       0.408
C(topic_grouped)[T.Sports]                    -0.6936      0.636     -1.091      0.275      -1.939       0.552
C(answer_type_grouped)[T.Number]               0.1811      0.415      0.436      0.663      -0.633       0.995
C(answer_type_grouped)[T.Other]               -0.4072      0.367     -1.110      0.267      -1.126       0.312
C(answer_type_grouped)[T.Person]              -0.6666      0.387     -1.724      0.085      -1.425       0.091
q_length                                      -0.6613      0.384     -1.724      0.085      -1.413       0.090
capabilities_entropy                           0.9832      0.281      3.497      0.000       0.432       1.534
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  247
Model:                          Logit   Df Residuals:                      234
Method:                           MLE   Df Model:                           12
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.08652
Time:                        09:26:43   Log-Likelihood:                -156.08
converged:                       True   LL-Null:                       -170.87
Covariance Type:            nonrobust   LLR p-value:                  0.003246
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      1.3302      1.826      0.729      0.466      -2.248       4.909
C(topic_grouped)[T.Geography]                 -0.8674      0.607     -1.428      0.153      -2.058       0.323
C(topic_grouped)[T.Misc]                      -0.2723      0.525     -0.518      0.604      -1.302       0.757
C(topic_grouped)[T.Music]                     -1.0262      0.619     -1.659      0.097      -2.239       0.186
C(topic_grouped)[T.Other]                     -0.2934      0.569     -0.515      0.606      -1.409       0.822
C(topic_grouped)[T.Politics]                  -0.7226      0.541     -1.335      0.182      -1.783       0.338
C(topic_grouped)[T.Science and technology]    -0.6126      0.488     -1.256      0.209      -1.569       0.343
C(topic_grouped)[T.Sports]                    -0.9140      0.641     -1.427      0.154      -2.170       0.342
C(answer_type_grouped)[T.Number]              -0.1273      0.409     -0.311      0.755      -0.928       0.674
C(answer_type_grouped)[T.Other]               -0.3772      0.369     -1.022      0.307      -1.100       0.346
C(answer_type_grouped)[T.Person]              -0.5594      0.396     -1.412      0.158      -1.336       0.217
q_length                                      -0.5929      0.378     -1.569      0.117      -1.333       0.148
game_entropy                                   1.2880      0.370      3.482      0.000       0.563       2.013
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  247
Model:                          Logit   Df Residuals:                      233
Method:                           MLE   Df Model:                           13
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.09552
Time:                        09:26:43   Log-Likelihood:                -154.54
converged:                       True   LL-Null:                       -170.87
Covariance Type:            nonrobust   LLR p-value:                  0.001927
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      1.4031      1.843      0.761      0.446      -2.209       5.015
C(topic_grouped)[T.Geography]                 -0.9196      0.610     -1.507      0.132      -2.115       0.276
C(topic_grouped)[T.Misc]                      -0.1976      0.527     -0.375      0.708      -1.231       0.836
C(topic_grouped)[T.Music]                     -1.0479      0.620     -1.690      0.091      -2.263       0.167
C(topic_grouped)[T.Other]                     -0.2088      0.576     -0.363      0.717      -1.337       0.920
C(topic_grouped)[T.Politics]                  -0.6675      0.542     -1.231      0.218      -1.730       0.395
C(topic_grouped)[T.Science and technology]    -0.6059      0.488     -1.241      0.215      -1.563       0.351
C(topic_grouped)[T.Sports]                    -0.8418      0.647     -1.302      0.193      -2.109       0.426
C(answer_type_grouped)[T.Number]               0.0404      0.422      0.096      0.924      -0.787       0.868
C(answer_type_grouped)[T.Other]               -0.3261      0.373     -0.875      0.382      -1.057       0.405
C(answer_type_grouped)[T.Person]              -0.5117      0.399     -1.281      0.200      -1.294       0.271
q_length                                      -0.6378      0.383     -1.667      0.096      -1.388       0.112
capabilities_entropy                           0.5972      0.343      1.740      0.082      -0.075       1.270
game_entropy                                   0.8463      0.443      1.909      0.056      -0.022       1.715
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing gemini-2.5-flash_think (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/gemini-2.5-flash_think_SimpleMC_redacted_cor_temp1.0_1758281503_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    224
1    116
Name: count, dtype: int64

Answer change%: 0.3412 [0.2907820194835736, 0.39157092169289703] (n=340)
P-value vs 25%: 0.000391; P-value vs 0%: 3.493e-40
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=116)
P-value vs 25%: 0; P-value vs 33%: 0

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  340
Model:                          Logit   Df Residuals:                      338
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:               0.0005360
Time:                        09:26:43   Log-Likelihood:                -218.10
converged:                       True   LL-Null:                       -218.22
Covariance Type:            nonrobust   LLR p-value:                    0.6286
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept       -184.0827    403.323     -0.456      0.648    -974.582     606.417
p_i_capability   183.4330    403.340      0.455      0.649    -607.099     973.965
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  340
Model:                          Logit   Df Residuals:                      338
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:               0.0002518
Time:                        09:26:43   Log-Likelihood:                -218.16
converged:                       True   LL-Null:                       -218.22
Covariance Type:            nonrobust   LLR p-value:                    0.7403
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -0.6515      0.116     -5.615      0.000      -0.879      -0.424
capabilities_entropy   -12.5402     39.084     -0.321      0.748     -89.144      64.063
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.3190 [0.2341, 0.4038] (n=116)
                  P-value vs 33.3%: 0.7399

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=2.17, p=0.0311
Wilcoxon delta_p: statistic=3722.50, p=6.11e-20
Mean Δp = 0.0064  [0.0006, 0.0122]
Idea 1 N = 224; 

  Idea 1.5: Calibration Metrics
  NLL: 0.0000, Signed ECE (overconf pos under neg): -0.0000, ECE: 0.0000 (n=340)
  Brier: 0.0000, Reliability (absolute calibration error; lower better): 0.0000, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=340)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.991
Model:                            OLS   Adj. R-squared:                  0.990
Method:                 Least Squares   F-statistic:                 1.160e+04
Date:                Sat, 20 Sep 2025   Prob (F-statistic):               0.00
Time:                        09:26:43   Log-Likelihood:                 563.75
No. Observations:                 337   AIC:                            -1119.
Df Residuals:                     333   BIC:                            -1104.
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept             2.5269      7.861      0.321      0.748     -12.936      17.990
p1                   -2.5206      7.861     -0.321      0.749     -17.984      12.943
answer_changed        5.2468     25.168      0.208      0.835     -44.261      54.755
p1:answer_changed    -4.2635     25.169     -0.169      0.866     -53.774      45.247
==============================================================================
Omnibus:                      286.194   Durbin-Watson:                   1.895
Prob(Omnibus):                  0.000   Jarque-Bera (JB):            31102.820
Skew:                           2.787   Prob(JB):                         0.00
Kurtosis:                      49.733   Cond. No.                     2.17e+04
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The condition number is large, 2.17e+04. This might indicate that there are
strong multicollinearity or other numerical problems.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-4.66, p=5.5e-06
Wilcoxon delta_H: statistic=8576.00, p=3.41e-05
Mean ΔH = -0.1043  [-0.1481, -0.0604]
Paired t-test delta_H Changed: statistic=30.76, p=2.56e-57
Wilcoxon delta_H Changed: statistic=12.00, p=1.23e-20
Mean ΔH Changed = 1.1448  [1.0718, 1.2177]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=-2.82, p=0.00503
Wilcoxon (p_top2_game vs p_top2_base): statistic=5638.00, p=6.47e-38
Mean Δp_top2 = -0.0063  [-0.0107, -0.0019] (n=340)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=8.57, p=3.83e-16
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=17593.00, p=3.37e-10
Mean ΔH_unchosen_baseline_set = 0.3219  [0.2482, 0.3955] (n=340)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  340
Model:                          Logit   Df Residuals:                      337
Method:                           MLE   Df Model:                            2
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                0.007083
Time:                        09:26:43   Log-Likelihood:                -216.67
converged:                       True   LL-Null:                       -218.22
Covariance Type:            nonrobust   LLR p-value:                    0.2132
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.5864      0.124     -4.734      0.000      -0.829      -0.344
p1_z            -0.7472      0.534     -1.399      0.162      -1.794       0.300
I(p1_z ** 2)    -0.0854      0.066     -1.291      0.197      -0.215       0.044
================================================================================
AUC = 0.525

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  340
Model:                          Logit   Df Residuals:                      338
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.01003
Time:                        09:26:43   Log-Likelihood:                -216.03
converged:                       True   LL-Null:                       -218.22
Covariance Type:            nonrobust   LLR p-value:                   0.03645
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.7071      0.117     -6.021      0.000      -0.937      -0.477
game_entropy     0.9325      0.472      1.977      0.048       0.008       1.857
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=7287.00, p=5.56e-33
Paired t-test (game_entropy vs capabilities_entropy): statistic=3.60, p=0.000365
Mean capabilities_entropy-game_entropy = -0.0493  [-0.0761, -0.0224] (n=340)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  340
Model:                          Logit   Df Residuals:                      337
Method:                           MLE   Df Model:                            2
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.01032
Time:                        09:26:43   Log-Likelihood:                -215.96
converged:                       True   LL-Null:                       -218.22
Covariance Type:            nonrobust   LLR p-value:                    0.1052
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -0.7002      0.119     -5.884      0.000      -0.933      -0.467
capabilities_entropy   -13.3877     38.828     -0.345      0.730     -89.489      62.713
game_entropy             0.9351      0.473      1.978      0.048       0.009       1.861
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['History', 'TV shows', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': None
topic_grouped           answer_changed
Art                     0                 0.683333
                        1                 0.316667
Geography               0                 0.694444
                        1                 0.305556
Misc                    0                 0.568182
                        1                 0.431818
Music                   0                 0.520000
                        1                 0.480000
Other                   0                 0.760000
                        1                 0.240000
Politics                0                 0.684211
                        1                 0.315789
Science and technology  0                 0.661538
                        1                 0.338462
Sports                  0                 0.678571
                        1                 0.321429
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.591667
                     1                 0.408333
Number               0                 0.697674
                     1                 0.302326
Other                0                 0.750000
                     1                 0.250000
Person               0                 0.662651
                     1                 0.337349
Place                0                 0.653846
                     1                 0.346154
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.647059  0.352941           17
                       Number               0.833333  0.166667            6
                       Other                0.900000  0.100000           10
                       Person               0.545455  0.454545           22
                       Place                0.800000  0.200000            5
Geography              Date                 0.428571  0.571429           14
                       Number               0.818182  0.181818           11
                       Other                1.000000  0.000000            3
                       Place                0.875000  0.125000            8
Misc                   Date                 0.466667  0.533333           15
                       Number               0.714286  0.285714            7
                       Other                0.666667  0.333333           12
                       Person               0.555556  0.444444            9
                       Place                0.000000  1.000000            1
Music                  Date                 0.750000  0.250000            8
                       Number               0.500000  0.500000            2
                       Other                0.400000  0.600000            5
                       Person               0.500000  0.500000            8
                       Place                0.000000  1.000000            2
Other                  Date                 0.571429  0.428571            7
                       Number               1.000000  0.000000            1
                       Other                0.800000  0.200000            5
                       Person               0.875000  0.125000            8
                       Place                0.750000  0.250000            4
Politics               Date                 0.680000  0.320000           25
                       Number               0.400000  0.600000            5
                       Other                0.833333  0.166667           12
                       Person               0.727273  0.272727           11
                       Place                0.500000  0.500000            4
Science and technology Date                 0.576923  0.423077           26
                       Number               0.666667  0.333333            6
                       Other                0.750000  0.250000           12
                       Person               0.700000  0.300000           20
                       Place                1.000000  0.000000            1
Sports                 Date                 0.625000  0.375000            8
                       Number               0.600000  0.400000            5
                       Other                0.666667  0.333333            9
                       Person               1.000000  0.000000            5
                       Place                0.000000  1.000000            1

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  340
Model:                          Logit   Df Residuals:                      327
Method:                           MLE   Df Model:                           12
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.04294
Time:                        09:26:43   Log-Likelihood:                -208.85
converged:                       True   LL-Null:                       -218.22
Covariance Type:            nonrobust   LLR p-value:                   0.09502
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -4.3691      1.492     -2.927      0.003      -7.294      -1.444
C(topic_grouped)[T.Geography]                 -0.0273      0.484     -0.056      0.955      -0.977       0.922
C(topic_grouped)[T.Misc]                       0.5410      0.425      1.273      0.203      -0.292       1.374
C(topic_grouped)[T.Music]                      0.7706      0.498      1.547      0.122      -0.206       1.747
C(topic_grouped)[T.Other]                     -0.4039      0.555     -0.728      0.467      -1.491       0.684
C(topic_grouped)[T.Politics]                  -0.2465      0.420     -0.587      0.557      -1.070       0.577
C(topic_grouped)[T.Science and technology]     0.0117      0.392      0.030      0.976      -0.757       0.781
C(topic_grouped)[T.Sports]                     0.1352      0.504      0.268      0.789      -0.853       1.123
C(answer_type_grouped)[T.Number]              -0.5844      0.398     -1.468      0.142      -1.365       0.196
C(answer_type_grouped)[T.Other]               -0.7152      0.346     -2.066      0.039      -1.394      -0.037
C(answer_type_grouped)[T.Person]              -0.2805      0.312     -0.899      0.369      -0.892       0.331
C(answer_type_grouped)[T.Place]               -0.1800      0.472     -0.381      0.703      -1.105       0.745
q_length                                       0.8650      0.323      2.682      0.007       0.233       1.497
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.0005
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  340
Model:                          Logit   Df Residuals:                      326
Method:                           MLE   Df Model:                           13
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.04364
Time:                        09:26:43   Log-Likelihood:                -208.69
converged:                       True   LL-Null:                       -218.22
Covariance Type:            nonrobust   LLR p-value:                    0.1216
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -4.3816      1.492     -2.937      0.003      -7.306      -1.457
C(topic_grouped)[T.Geography]                 -0.0359      0.485     -0.074      0.941      -0.986       0.914
C(topic_grouped)[T.Misc]                       0.5644      0.427      1.321      0.187      -0.273       1.402
C(topic_grouped)[T.Music]                      0.7683      0.498      1.542      0.123      -0.208       1.745
C(topic_grouped)[T.Other]                     -0.4018      0.555     -0.724      0.469      -1.489       0.686
C(topic_grouped)[T.Politics]                  -0.2502      0.420     -0.596      0.551      -1.073       0.573
C(topic_grouped)[T.Science and technology]     0.0224      0.393      0.057      0.954      -0.748       0.792
C(topic_grouped)[T.Sports]                     0.1361      0.504      0.270      0.787      -0.852       1.124
C(answer_type_grouped)[T.Number]              -0.5533      0.401     -1.378      0.168      -1.340       0.234
C(answer_type_grouped)[T.Other]               -0.7213      0.347     -2.081      0.037      -1.401      -0.042
C(answer_type_grouped)[T.Person]              -0.2777      0.312     -0.889      0.374      -0.890       0.334
C(answer_type_grouped)[T.Place]               -0.1787      0.472     -0.379      0.705      -1.104       0.747
q_length                                       0.8687      0.322      2.694      0.007       0.237       1.501
capabilities_entropy                         -21.3729     40.500     -0.528      0.598    -100.752      58.006
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  340
Model:                          Logit   Df Residuals:                      326
Method:                           MLE   Df Model:                           13
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.05426
Time:                        09:26:43   Log-Likelihood:                -206.38
converged:                       True   LL-Null:                       -218.22
Covariance Type:            nonrobust   LLR p-value:                   0.03418
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -4.3676      1.503     -2.907      0.004      -7.313      -1.423
C(topic_grouped)[T.Geography]                  0.0148      0.487      0.030      0.976      -0.940       0.970
C(topic_grouped)[T.Misc]                       0.6131      0.429      1.430      0.153      -0.227       1.453
C(topic_grouped)[T.Music]                      0.7951      0.499      1.592      0.111      -0.184       1.774
C(topic_grouped)[T.Other]                     -0.5280      0.579     -0.912      0.362      -1.663       0.607
C(topic_grouped)[T.Politics]                  -0.2654      0.427     -0.622      0.534      -1.102       0.571
C(topic_grouped)[T.Science and technology]     0.0938      0.397      0.237      0.813      -0.683       0.871
C(topic_grouped)[T.Sports]                     0.1452      0.509      0.285      0.775      -0.852       1.142
C(answer_type_grouped)[T.Number]              -0.5436      0.400     -1.360      0.174      -1.327       0.240
C(answer_type_grouped)[T.Other]               -0.7099      0.350     -2.031      0.042      -1.395      -0.025
C(answer_type_grouped)[T.Person]              -0.2911      0.315     -0.923      0.356      -0.909       0.327
C(answer_type_grouped)[T.Place]               -0.1152      0.474     -0.243      0.808      -1.045       0.814
q_length                                       0.8455      0.325      2.605      0.009       0.209       1.482
game_entropy                                   1.0149      0.480      2.113      0.035       0.074       1.956
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  340
Model:                          Logit   Df Residuals:                      325
Method:                           MLE   Df Model:                           14
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.05519
Time:                        09:26:43   Log-Likelihood:                -206.17
converged:                       True   LL-Null:                       -218.22
Covariance Type:            nonrobust   LLR p-value:                   0.04473
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -4.3822      1.502     -2.917      0.004      -7.326      -1.438
C(topic_grouped)[T.Geography]                  0.0050      0.488      0.010      0.992      -0.951       0.961
C(topic_grouped)[T.Misc]                       0.6414      0.431      1.488      0.137      -0.203       1.486
C(topic_grouped)[T.Music]                      0.7927      0.500      1.587      0.113      -0.186       1.772
C(topic_grouped)[T.Other]                     -0.5271      0.579     -0.910      0.363      -1.663       0.608
C(topic_grouped)[T.Politics]                  -0.2700      0.427     -0.633      0.527      -1.107       0.567
C(topic_grouped)[T.Science and technology]     0.1065      0.397      0.268      0.789      -0.672       0.885
C(topic_grouped)[T.Sports]                     0.1460      0.509      0.287      0.774      -0.851       1.143
C(answer_type_grouped)[T.Number]              -0.5062      0.403     -1.255      0.209      -1.297       0.284
C(answer_type_grouped)[T.Other]               -0.7170      0.350     -2.048      0.041      -1.403      -0.031
C(answer_type_grouped)[T.Person]              -0.2881      0.316     -0.913      0.361      -0.907       0.331
C(answer_type_grouped)[T.Place]               -0.1128      0.474     -0.238      0.812      -1.043       0.817
q_length                                       0.8495      0.324      2.618      0.009       0.214       1.486
capabilities_entropy                         -24.3489     40.400     -0.603      0.547    -103.531      54.833
game_entropy                                   1.0271      0.482      2.129      0.033       0.082       1.973
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing gemini-2.5-flash_think (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/gemini-2.5-flash_think_SimpleMC_redacted_temp1.0_1758262178_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
1    98
0    62
Name: count, dtype: int64

Answer change%: 0.6125 [0.5370121598379034, 0.6879878401620967] (n=160)
P-value vs 25%: 4.871e-21; P-value vs 0%: 6.047e-57
Phase 2 self-accuracy: 0.6224 [0.5264703030707152, 0.7184276561129583] (n=98)
P-value vs 25%: 2.833e-14; P-value vs 33%: 3.405e-09

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  160
Model:                          Logit   Df Residuals:                      158
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  -3.064
Time:                        09:26:43   Log-Likelihood:                -434.14
converged:                      False   LL-Null:                       -106.82
Covariance Type:            nonrobust   LLR p-value:                     1.000
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept       5.417e+05   9.44e+04      5.738      0.000    3.57e+05    7.27e+05
p_i_capability -5.417e+05   9.44e+04     -5.738      0.000   -7.27e+05   -3.57e+05
==================================================================================

Possibly complete quasi-separation: A fraction 0.12 of observations can be
perfectly predicted. This might indicate that there is complete
quasi-separation. In this case some parameters will not be identified.

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  160
Model:                          Logit   Df Residuals:                      158
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                0.006843
Time:                        09:26:43   Log-Likelihood:                -106.09
converged:                       True   LL-Null:                       -106.82
Covariance Type:            nonrobust   LLR p-value:                    0.2266
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept                0.3772      0.192      1.961      0.050       0.000       0.754
capabilities_entropy   280.9774    422.694      0.665      0.506    -547.489    1109.443
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.3776 [0.2816, 0.4735] (n=98)
                  P-value vs 33.3%: 0.3665

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=1.77, p=0.0823
Wilcoxon delta_p: statistic=330.00, p=5.82e-06
Mean Δp = 0.0311  [-0.0034, 0.0656]
Idea 1 N = 62; 

  Idea 1.5: Calibration Metrics
  NLL: 13.0208, Signed ECE (overconf pos under neg): 0.0000, ECE: 0.0000 (n=140)
  Brier: 0.0000, Reliability (absolute calibration error; lower better): 0.0000, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=140)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.958
Model:                            OLS   Adj. R-squared:                  0.957
Method:                 Least Squares   F-statistic:                     1178.
Date:                Sat, 20 Sep 2025   Prob (F-statistic):          6.00e-106
Time:                        09:26:43   Log-Likelihood:                 144.03
No. Observations:                 158   AIC:                            -280.1
Df Residuals:                     154   BIC:                            -267.8
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept          -596.1246    638.960     -0.933      0.352   -1858.382     666.133
p1                  596.1660    638.971      0.933      0.352    -666.114    1858.446
answer_changed      596.2760    638.962      0.933      0.352    -665.985    1858.537
p1:answer_changed  -595.3318    638.973     -0.932      0.353   -1857.615     666.951
==============================================================================
Omnibus:                      172.448   Durbin-Watson:                   1.987
Prob(Omnibus):                  0.000   Jarque-Bera (JB):             5404.894
Skew:                           4.002   Prob(JB):                         0.00
Kurtosis:                      30.513   Cond. No.                     2.77e+05
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The condition number is large, 2.77e+05. This might indicate that there are
strong multicollinearity or other numerical problems.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-2.22, p=0.0298
Wilcoxon delta_H: statistic=649.00, p=0.0217
Mean ΔH = -0.0860  [-0.1617, -0.0102]
Paired t-test delta_H Changed: statistic=24.26, p=5.63e-43
Wilcoxon delta_H Changed: statistic=31.00, p=2.16e-17
Mean ΔH Changed = 1.1224  [1.0318, 1.2131]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=-2.95, p=0.00362
Wilcoxon (p_top2_game vs p_top2_base): statistic=1740.00, p=1.17e-15
Mean Δp_top2 = -0.0173  [-0.0288, -0.0058] (n=160)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=11.56, p=7.99e-23
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=1670.00, p=4.42e-16
Mean ΔH_unchosen_baseline_set = 0.6542  [0.5433, 0.7651] (n=160)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  160
Model:                          Logit   Df Residuals:                      157
Method:                           MLE   Df Model:                            2
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.01617
Time:                        09:26:43   Log-Likelihood:                -105.09
converged:                       True   LL-Null:                       -106.82
Covariance Type:            nonrobust   LLR p-value:                    0.1778
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       19.1356     19.065      1.004      0.316     -18.230      56.501
p1_z          -526.6682    526.484     -1.000      0.317   -1558.558     505.222
I(p1_z ** 2)  3653.2225   3621.564      1.009      0.313   -3444.912    1.08e+04
================================================================================
AUC = 0.569

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  160
Model:                          Logit   Df Residuals:                      158
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:               0.0002754
Time:                        09:26:43   Log-Likelihood:                -106.79
converged:                       True   LL-Null:                       -106.82
Covariance Type:            nonrobust   LLR p-value:                    0.8084
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept        0.4480      0.167      2.680      0.007       0.120       0.776
game_entropy     0.0954      0.396      0.241      0.810      -0.681       0.872
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=2097.00, p=1.37e-13
Paired t-test (game_entropy vs capabilities_entropy): statistic=3.08, p=0.00247
Mean capabilities_entropy-game_entropy = -0.1024  [-0.1676, -0.0372] (n=160)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  160
Model:                          Logit   Df Residuals:                      157
Method:                           MLE   Df Model:                            2
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                0.006969
Time:                        09:26:43   Log-Likelihood:                -106.07
converged:                       True   LL-Null:                       -106.82
Covariance Type:            nonrobust   LLR p-value:                    0.4750
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept                0.3721      0.195      1.907      0.056      -0.010       0.755
capabilities_entropy   274.5599    427.133      0.643      0.520    -562.606    1111.726
game_entropy             0.0653      0.401      0.163      0.870      -0.720       0.851
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['Video games', 'Geography', 'History']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     1                 0.533333
                        0                 0.466667
Misc                    1                 0.800000
                        0                 0.200000
Music                   1                 0.600000
                        0                 0.400000
Other                   1                 0.629630
                        0                 0.370370
Politics                1                 0.650000
                        0                 0.350000
Science and technology  0                 0.545455
                        1                 0.454545
Sports                  1                 0.666667
                        0                 0.333333
TV shows                1                 0.615385
                        0                 0.384615
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 1                 0.653061
                     0                 0.346939
Number               1                 0.628571
                     0                 0.371429
Other                1                 0.512821
                     0                 0.487179
Person               1                 0.648649
                     0                 0.351351
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.750000  0.250000            4
                       Number               0.333333  0.666667            3
                       Other                0.666667  0.333333            3
                       Person               0.200000  0.800000            5
Misc                   Date                 0.111111  0.888889            9
                       Number               0.222222  0.777778            9
                       Other                0.333333  0.666667            6
                       Person               0.000000  1.000000            1
Music                  Date                 0.500000  0.500000            4
                       Number               0.000000  1.000000            2
                       Other                0.200000  0.800000            5
                       Person               0.750000  0.250000            4
Other                  Date                 0.363636  0.636364           11
                       Number               0.500000  0.500000            6
                       Other                0.600000  0.400000            5
                       Person               0.000000  1.000000            5
Politics               Date                 0.272727  0.727273           11
                       Number               0.000000  1.000000            1
                       Other                0.750000  0.250000            4
                       Person               0.250000  0.750000            4
Science and technology Date                 0.444444  0.555556            9
                       Number               0.750000  0.250000            8
                       Other                0.500000  0.500000            6
                       Person               0.500000  0.500000           10
Sports                 Date                 0.000000  1.000000            1
                       Number               0.166667  0.833333            6
                       Other                1.000000  0.000000            2
                       Person               0.333333  0.666667            3
TV shows               Other                0.375000  0.625000            8
                       Person               0.400000  0.600000            5

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  160
Model:                          Logit   Df Residuals:                      148
Method:                           MLE   Df Model:                           11
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.05428
Time:                        09:26:43   Log-Likelihood:                -101.02
converged:                       True   LL-Null:                       -106.82
Covariance Type:            nonrobust   LLR p-value:                    0.3947
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      1.4248      2.176      0.655      0.513      -2.839       5.689
C(topic_grouped)[T.Misc]                       1.3950      0.738      1.889      0.059      -0.052       2.842
C(topic_grouped)[T.Music]                      0.3631      0.751      0.483      0.629      -1.110       1.836
C(topic_grouped)[T.Other]                      0.4054      0.664      0.611      0.541      -0.896       1.706
C(topic_grouped)[T.Politics]                   0.5426      0.720      0.753      0.451      -0.869       1.954
C(topic_grouped)[T.Science and technology]    -0.2937      0.634     -0.464      0.643      -1.536       0.948
C(topic_grouped)[T.Sports]                     0.6410      0.825      0.777      0.437      -0.976       2.258
C(topic_grouped)[T.TV shows]                   0.5823      0.808      0.721      0.471      -1.001       2.166
C(answer_type_grouped)[T.Number]              -0.1657      0.502     -0.330      0.741      -1.149       0.817
C(answer_type_grouped)[T.Other]               -0.6783      0.484     -1.402      0.161      -1.627       0.270
C(answer_type_grouped)[T.Person]               0.1260      0.493      0.256      0.798      -0.840       1.092
q_length                                      -0.2610      0.459     -0.569      0.570      -1.161       0.639
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.0029
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  160
Model:                          Logit   Df Residuals:                      147
Method:                           MLE   Df Model:                           12
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.06535
Time:                        09:26:43   Log-Likelihood:                -99.838
converged:                       True   LL-Null:                       -106.82
Covariance Type:            nonrobust   LLR p-value:                    0.3032
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      1.1588      2.180      0.532      0.595      -3.114       5.431
C(topic_grouped)[T.Misc]                       1.4268      0.742      1.922      0.055      -0.028       2.882
C(topic_grouped)[T.Music]                      0.4648      0.760      0.612      0.541      -1.025       1.954
C(topic_grouped)[T.Other]                      0.4112      0.665      0.618      0.536      -0.892       1.715
C(topic_grouped)[T.Politics]                   0.5965      0.724      0.824      0.410      -0.822       2.015
C(topic_grouped)[T.Science and technology]    -0.3051      0.636     -0.480      0.632      -1.552       0.942
C(topic_grouped)[T.Sports]                     0.6574      0.830      0.792      0.428      -0.969       2.284
C(topic_grouped)[T.TV shows]                   0.4767      0.820      0.581      0.561      -1.130       2.083
C(answer_type_grouped)[T.Number]              -0.2107      0.504     -0.418      0.676      -1.198       0.776
C(answer_type_grouped)[T.Other]               -0.7675      0.490     -1.566      0.117      -1.728       0.193
C(answer_type_grouped)[T.Person]               0.1116      0.496      0.225      0.822      -0.860       1.084
q_length                                      -0.2270      0.460     -0.494      0.621      -1.128       0.674
capabilities_entropy                         492.0933    492.716      0.999      0.318    -473.613    1457.800
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  160
Model:                          Logit   Df Residuals:                      147
Method:                           MLE   Df Model:                           12
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.05450
Time:                        09:26:43   Log-Likelihood:                -101.00
converged:                       True   LL-Null:                       -106.82
Covariance Type:            nonrobust   LLR p-value:                    0.4748
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      1.4419      2.177      0.662      0.508      -2.825       5.709
C(topic_grouped)[T.Misc]                       1.3835      0.740      1.869      0.062      -0.067       2.834
C(topic_grouped)[T.Music]                      0.3618      0.751      0.482      0.630      -1.111       1.834
C(topic_grouped)[T.Other]                      0.3944      0.666      0.592      0.554      -0.911       1.699
C(topic_grouped)[T.Politics]                   0.5260      0.724      0.726      0.468      -0.894       1.946
C(topic_grouped)[T.Science and technology]    -0.3079      0.637     -0.483      0.629      -1.557       0.941
C(topic_grouped)[T.Sports]                     0.6437      0.825      0.780      0.435      -0.974       2.261
C(topic_grouped)[T.TV shows]                   0.5779      0.808      0.715      0.475      -1.006       2.162
C(answer_type_grouped)[T.Number]              -0.1726      0.503     -0.343      0.731      -1.158       0.813
C(answer_type_grouped)[T.Other]               -0.6738      0.485     -1.391      0.164      -1.624       0.276
C(answer_type_grouped)[T.Person]               0.1294      0.493      0.263      0.793      -0.837       1.096
q_length                                      -0.2650      0.459     -0.577      0.564      -1.165       0.636
game_entropy                                   0.0891      0.419      0.213      0.832      -0.731       0.909
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  160
Model:                          Logit   Df Residuals:                      146
Method:                           MLE   Df Model:                           13
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.06542
Time:                        09:26:43   Log-Likelihood:                -99.831
converged:                       True   LL-Null:                       -106.82
Covariance Type:            nonrobust   LLR p-value:                    0.3755
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      1.1700      2.182      0.536      0.592      -3.107       5.447
C(topic_grouped)[T.Misc]                       1.4230      0.743      1.915      0.056      -0.034       2.880
C(topic_grouped)[T.Music]                      0.4637      0.760      0.610      0.542      -1.026       1.953
C(topic_grouped)[T.Other]                      0.4044      0.667      0.606      0.544      -0.903       1.712
C(topic_grouped)[T.Politics]                   0.5863      0.728      0.805      0.421      -0.841       2.014
C(topic_grouped)[T.Science and technology]    -0.3137      0.640     -0.490      0.624      -1.568       0.941
C(topic_grouped)[T.Sports]                     0.6590      0.830      0.794      0.427      -0.968       2.286
C(topic_grouped)[T.TV shows]                   0.4737      0.820      0.578      0.564      -1.134       2.081
C(answer_type_grouped)[T.Number]              -0.2152      0.505     -0.426      0.670      -1.205       0.775
C(answer_type_grouped)[T.Other]               -0.7632      0.491     -1.554      0.120      -1.726       0.200
C(answer_type_grouped)[T.Person]               0.1139      0.496      0.230      0.818      -0.859       1.086
q_length                                      -0.2297      0.460     -0.499      0.618      -1.132       0.672
capabilities_entropy                         491.8110    495.929      0.992      0.321    -480.191    1463.813
game_entropy                                   0.0537      0.432      0.124      0.901      -0.793       0.900
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing gpt-4.1-2025-04-14 (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/gpt-4.1-2025-04-14_SimpleMC_redacted_cor_temp1.0_1757988452_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    193
1     65
Name: count, dtype: int64

Answer change%: 0.2519 [0.1989650703623943, 0.30491089862985377] (n=258)
P-value vs 25%: 0.9428; P-value vs 0%: 1.147e-20
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=65)
P-value vs 25%: 0; P-value vs 33%: 0

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  258
Model:                          Logit   Df Residuals:                      256
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.02317
Time:                        09:26:43   Log-Likelihood:                -142.25
converged:                       True   LL-Null:                       -145.63
Covariance Type:            nonrobust   LLR p-value:                  0.009383
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          1.0367      0.811      1.278      0.201      -0.553       2.626
p_i_capability    -2.3718      0.901     -2.633      0.008      -4.137      -0.606
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  258
Model:                          Logit   Df Residuals:                      256
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.02246
Time:                        09:26:43   Log-Likelihood:                -142.36
converged:                       True   LL-Null:                       -145.63
Covariance Type:            nonrobust   LLR p-value:                   0.01055
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.3622      0.186     -7.321      0.000      -1.727      -0.997
capabilities_entropy     0.7370      0.285      2.584      0.010       0.178       1.296
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.6591 [0.5190, 0.7992] (n=44)
                  P-value vs 33.3%: 5.15e-06

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=-2.56, p=0.013
Wilcoxon delta_p: statistic=559.00, p=0.00877
Mean Δp = -0.0619  [-0.1093, -0.0145]
Idea 1 N = 60; 

  Idea 1.5: Calibration Metrics
  NLL: 0.2213, Signed ECE (overconf pos under neg): -0.1794, ECE: 0.1794 (n=95)
  Brier: 0.0599, Reliability (absolute calibration error; lower better): 0.0589, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=95)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.890
Model:                            OLS   Adj. R-squared:                  0.886
Method:                 Least Squares   F-statistic:                     244.5
Date:                Sat, 20 Sep 2025   Prob (F-statistic):           2.05e-43
Time:                        09:26:43   Log-Likelihood:                 51.995
No. Observations:                  95   AIC:                            -95.99
Df Residuals:                      91   BIC:                            -85.78
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.6672      0.098     -6.831      0.000      -0.861      -0.473
p1                    0.7375      0.117      6.311      0.000       0.505       0.970
answer_changed        0.5866      0.149      3.929      0.000       0.290       0.883
p1:answer_changed     0.2251      0.178      1.264      0.210      -0.129       0.579
==============================================================================
Omnibus:                        3.393   Durbin-Watson:                   1.699
Prob(Omnibus):                  0.183   Jarque-Bera (JB):                3.361
Skew:                           0.448   Prob(JB):                        0.186
Kurtosis:                       2.783   Cond. No.                         24.5
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=4.75, p=1.34e-05
Wilcoxon delta_H: statistic=354.00, p=3.63e-05
Mean ΔH = 0.3445  [0.2024, 0.4866]
Paired t-test delta_H Changed: statistic=3.53, p=0.00121
Wilcoxon delta_H Changed: statistic=116.00, p=0.00073
Mean ΔH Changed = 0.2915  [0.1298, 0.4532]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=3.20, p=0.00185
Wilcoxon (p_top2_game vs p_top2_base): statistic=1280.00, p=0.000206
Mean Δp_top2 = 0.0217  [0.0084, 0.0350] (n=95)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=5.94, p=4.88e-08
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=873.00, p=1.76e-07
Mean ΔH_unchosen_baseline_set = 0.3250  [0.2176, 0.4323] (n=95)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                   95
Model:                          Logit   Df Residuals:                       92
Method:                           MLE   Df Model:                            2
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.01408
Time:                        09:26:43   Log-Likelihood:                -61.640
converged:                       True   LL-Null:                       -62.520
Covariance Type:            nonrobust   LLR p-value:                    0.4147
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.8492      0.323     -2.628      0.009      -1.483      -0.216
p1_z             0.1830      0.253      0.722      0.470      -0.314       0.679
I(p1_z ** 2)     0.3022      0.231      1.307      0.191      -0.151       0.755
================================================================================
AUC = 0.598

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  258
Model:                          Logit   Df Residuals:                      256
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.09606
Time:                        09:26:43   Log-Likelihood:                -131.64
converged:                       True   LL-Null:                       -145.63
Covariance Type:            nonrobust   LLR p-value:                 1.226e-07
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.6971      0.203     -8.361      0.000      -2.095      -1.299
game_entropy     1.7822      0.345      5.160      0.000       1.105       2.459
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=9776.00, p=0.209
Paired t-test (game_entropy vs capabilities_entropy): statistic=-1.78, p=0.0758
Mean capabilities_entropy-game_entropy = 0.0520  [-0.0052, 0.1092] (n=258)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  258
Model:                          Logit   Df Residuals:                      255
Method:                           MLE   Df Model:                            2
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.09632
Time:                        09:26:43   Log-Likelihood:                -131.60
converged:                       True   LL-Null:                       -145.63
Covariance Type:            nonrobust   LLR p-value:                 8.090e-07
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.7161      0.215     -7.986      0.000      -2.137      -1.295
capabilities_entropy     0.0922      0.334      0.276      0.782      -0.562       0.747
game_entropy             1.7369      0.382      4.548      0.000       0.988       2.485
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': None
topic_grouped           answer_changed
Art                     0                 0.837209
                        1                 0.162791
Geography               0                 0.736842
                        1                 0.263158
Misc                    0                 0.636364
                        1                 0.363636
Music                   0                 0.761905
                        1                 0.238095
Other                   0                 0.758621
                        1                 0.241379
Politics                0                 0.783784
                        1                 0.216216
Science and technology  0                 0.804348
                        1                 0.195652
Sports                  0                 0.565217
                        1                 0.434783
TV shows                0                 0.666667
                        1                 0.333333
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.746479
                     1                 0.253521
Number               0                 0.625000
                     1                 0.375000
Other                0                 0.765625
                     1                 0.234375
Person               0                 0.794521
                     1                 0.205479
Place                0                 0.722222
                     1                 0.277778
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.777778  0.222222            9
                       Number               0.666667  0.333333            3
                       Other                0.888889  0.111111            9
                       Person               0.833333  0.166667           18
                       Place                1.000000  0.000000            4
Geography              Date                 0.666667  0.333333            3
                       Number               0.625000  0.375000            8
                       Other                1.000000  0.000000            3
                       Place                0.800000  0.200000            5
Misc                   Date                 0.444444  0.555556            9
                       Number               0.666667  0.333333            3
                       Other                0.600000  0.400000            5
                       Person               1.000000  0.000000            5
Music                  Date                 1.000000  0.000000            5
                       Number               0.500000  0.500000            2
                       Other                0.500000  0.500000            4
                       Person               0.800000  0.200000           10
Other                  Date                 0.875000  0.125000            8
                       Number               0.250000  0.750000            4
                       Other                0.800000  0.200000            5
                       Person               0.888889  0.111111            9
                       Place                0.666667  0.333333            3
Politics               Date                 0.894737  0.105263           19
                       Number               1.000000  0.000000            1
                       Other                0.625000  0.375000            8
                       Person               0.600000  0.400000            5
                       Place                0.750000  0.250000            4
Science and technology Date                 0.769231  0.230769           13
                       Number               0.600000  0.400000            5
                       Other                0.833333  0.166667           12
                       Person               0.875000  0.125000           16
Sports                 Date                 0.000000  1.000000            4
                       Number               0.800000  0.200000            5
                       Other                1.000000  0.000000            6
                       Person               0.500000  0.500000            6
                       Place                0.000000  1.000000            2
TV shows               Date                 1.000000  0.000000            1
                       Number               1.000000  0.000000            1
                       Other                0.666667  0.333333           12
                       Person               0.500000  0.500000            4

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  258
Model:                          Logit   Df Residuals:                      244
Method:                           MLE   Df Model:                           13
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.04182
Time:                        09:26:43   Log-Likelihood:                -139.54
converged:                       True   LL-Null:                       -145.63
Covariance Type:            nonrobust   LLR p-value:                    0.5130
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -2.9874      1.871     -1.597      0.110      -6.655       0.680
C(topic_grouped)[T.Geography]                  0.2664      0.704      0.378      0.705      -1.113       1.646
C(topic_grouped)[T.Misc]                       0.9791      0.620      1.579      0.114      -0.236       2.194
C(topic_grouped)[T.Music]                      0.4915      0.665      0.739      0.460      -0.812       1.795
C(topic_grouped)[T.Other]                      0.4242      0.604      0.702      0.482      -0.760       1.608
C(topic_grouped)[T.Politics]                   0.2024      0.603      0.335      0.737      -0.980       1.385
C(topic_grouped)[T.Science and technology]     0.1598      0.568      0.281      0.779      -0.954       1.274
C(topic_grouped)[T.Sports]                     1.2818      0.600      2.137      0.033       0.106       2.457
C(topic_grouped)[T.TV shows]                   1.0365      0.676      1.534      0.125      -0.288       2.361
C(answer_type_grouped)[T.Number]               0.4653      0.493      0.944      0.345      -0.500       1.431
C(answer_type_grouped)[T.Other]               -0.2148      0.434     -0.495      0.620      -1.065       0.635
C(answer_type_grouped)[T.Person]              -0.2639      0.420     -0.628      0.530      -1.087       0.559
C(answer_type_grouped)[T.Place]                0.1537      0.632      0.243      0.808      -1.084       1.392
q_length                                       0.3233      0.402      0.804      0.421      -0.465       1.111
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.3327
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  258
Model:                          Logit   Df Residuals:                      243
Method:                           MLE   Df Model:                           14
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.06567
Time:                        09:26:43   Log-Likelihood:                -136.07
converged:                       True   LL-Null:                       -145.63
Covariance Type:            nonrobust   LLR p-value:                    0.1602
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -3.4259      1.924     -1.780      0.075      -7.197       0.346
C(topic_grouped)[T.Geography]                  0.3231      0.715      0.452      0.651      -1.078       1.724
C(topic_grouped)[T.Misc]                       1.1297      0.631      1.789      0.074      -0.108       2.367
C(topic_grouped)[T.Music]                      0.4210      0.674      0.625      0.532      -0.900       1.742
C(topic_grouped)[T.Other]                      0.3401      0.614      0.554      0.580      -0.864       1.544
C(topic_grouped)[T.Politics]                   0.1714      0.611      0.281      0.779      -1.026       1.368
C(topic_grouped)[T.Science and technology]     0.1534      0.574      0.267      0.789      -0.972       1.279
C(topic_grouped)[T.Sports]                     1.3901      0.613      2.268      0.023       0.189       2.591
C(topic_grouped)[T.TV shows]                   1.1491      0.686      1.674      0.094      -0.196       2.494
C(answer_type_grouped)[T.Number]               0.4558      0.504      0.904      0.366      -0.532       1.444
C(answer_type_grouped)[T.Other]                0.0301      0.455      0.066      0.947      -0.861       0.921
C(answer_type_grouped)[T.Person]               0.0506      0.446      0.113      0.910      -0.824       0.925
C(answer_type_grouped)[T.Place]                0.5082      0.655      0.776      0.438      -0.775       1.791
q_length                                       0.3091      0.412      0.750      0.453      -0.499       1.117
capabilities_entropy                           0.8528      0.324      2.633      0.008       0.218       1.488
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  258
Model:                          Logit   Df Residuals:                      243
Method:                           MLE   Df Model:                           14
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1411
Time:                        09:26:43   Log-Likelihood:                -125.07
converged:                       True   LL-Null:                       -145.63
Covariance Type:            nonrobust   LLR p-value:                 0.0001709
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -5.1854      2.063     -2.514      0.012      -9.228      -1.143
C(topic_grouped)[T.Geography]                  0.3989      0.744      0.536      0.592      -1.060       1.857
C(topic_grouped)[T.Misc]                       1.2326      0.677      1.821      0.069      -0.094       2.559
C(topic_grouped)[T.Music]                      0.6709      0.717      0.936      0.349      -0.734       2.076
C(topic_grouped)[T.Other]                      0.4571      0.650      0.703      0.482      -0.817       1.731
C(topic_grouped)[T.Politics]                   0.3080      0.637      0.484      0.629      -0.940       1.556
C(topic_grouped)[T.Science and technology]     0.4632      0.613      0.755      0.450      -0.739       1.665
C(topic_grouped)[T.Sports]                     1.5353      0.652      2.356      0.018       0.258       2.812
C(topic_grouped)[T.TV shows]                   1.3779      0.737      1.871      0.061      -0.066       2.822
C(answer_type_grouped)[T.Number]               0.4931      0.532      0.928      0.354      -0.549       1.535
C(answer_type_grouped)[T.Other]                0.2507      0.474      0.529      0.596      -0.677       1.179
C(answer_type_grouped)[T.Person]               0.1791      0.457      0.392      0.695      -0.716       1.074
C(answer_type_grouped)[T.Place]                0.6561      0.682      0.962      0.336      -0.680       1.993
q_length                                       0.5595      0.429      1.305      0.192      -0.281       1.400
game_entropy                                   1.9847      0.385      5.161      0.000       1.231       2.738
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  258
Model:                          Logit   Df Residuals:                      242
Method:                           MLE   Df Model:                           15
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1431
Time:                        09:26:43   Log-Likelihood:                -124.79
converged:                       True   LL-Null:                       -145.63
Covariance Type:            nonrobust   LLR p-value:                 0.0002514
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -5.2114      2.074     -2.513      0.012      -9.276      -1.147
C(topic_grouped)[T.Geography]                  0.4133      0.745      0.555      0.579      -1.047       1.874
C(topic_grouped)[T.Misc]                       1.2730      0.677      1.879      0.060      -0.055       2.601
C(topic_grouped)[T.Music]                      0.6469      0.721      0.897      0.369      -0.766       2.060
C(topic_grouped)[T.Other]                      0.4316      0.652      0.662      0.508      -0.847       1.710
C(topic_grouped)[T.Politics]                   0.3059      0.637      0.480      0.631      -0.943       1.555
C(topic_grouped)[T.Science and technology]     0.4557      0.615      0.741      0.459      -0.750       1.661
C(topic_grouped)[T.Sports]                     1.5674      0.652      2.403      0.016       0.289       2.846
C(topic_grouped)[T.TV shows]                   1.4038      0.739      1.899      0.058      -0.045       2.852
C(answer_type_grouped)[T.Number]               0.5039      0.533      0.946      0.344      -0.541       1.548
C(answer_type_grouped)[T.Other]                0.3154      0.485      0.651      0.515      -0.635       1.265
C(answer_type_grouped)[T.Person]               0.2692      0.474      0.568      0.570      -0.660       1.198
C(answer_type_grouped)[T.Place]                0.7605      0.696      1.093      0.274      -0.603       2.124
q_length                                       0.5383      0.432      1.246      0.213      -0.309       1.385
capabilities_entropy                           0.2761      0.364      0.759      0.448      -0.437       0.989
game_entropy                                   1.8809      0.408      4.615      0.000       1.082       2.680
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing gpt-4.1-2025-04-14 (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/gpt-4.1-2025-04-14_SimpleMC_redacted_temp1.0_1757987360_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    132
1    110
Name: count, dtype: int64

Answer change%: 0.4545 [0.39181067874966974, 0.5172802303412394] (n=242)
P-value vs 25%: 1.654e-10; P-value vs 0%: 9.039e-46
Phase 2 self-accuracy: 0.6364 [0.5464681101495028, 0.7262591625777699] (n=110)
P-value vs 25%: 3.646e-17; P-value vs 33%: 3.737e-11

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  242
Model:                          Logit   Df Residuals:                      240
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.01739
Time:                        09:26:43   Log-Likelihood:                -163.84
converged:                       True   LL-Null:                       -166.74
Covariance Type:            nonrobust   LLR p-value:                   0.01605
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          1.1695      0.582      2.011      0.044       0.030       2.309
p_i_capability    -1.6625      0.697     -2.384      0.017      -3.030      -0.295
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  242
Model:                          Logit   Df Residuals:                      240
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.02481
Time:                        09:26:43   Log-Likelihood:                -162.60
converged:                       True   LL-Null:                       -166.74
Covariance Type:            nonrobust   LLR p-value:                  0.004025
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -0.6187      0.203     -3.043      0.002      -1.017      -0.220
capabilities_entropy     0.6820      0.241      2.836      0.005       0.211       1.153
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.7766 [0.6924, 0.8608] (n=94)
                  P-value vs 33.3%: 5.863e-25

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=-1.91, p=0.0598
Wilcoxon delta_p: statistic=1261.00, p=0.0194
Mean Δp = -0.0436  [-0.0883, 0.0012]
Idea 1 N = 84; 

  Idea 1.5: Calibration Metrics
  NLL: 4.9839, Signed ECE (overconf pos under neg): 0.1177, ECE: 0.1177 (n=165)
  Brier: 0.0301, Reliability (absolute calibration error; lower better): 0.0293, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=165)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.889
Model:                            OLS   Adj. R-squared:                  0.887
Method:                 Least Squares   F-statistic:                     429.3
Date:                Sat, 20 Sep 2025   Prob (F-statistic):           1.48e-76
Time:                        09:26:43   Log-Likelihood:                 92.242
No. Observations:                 165   AIC:                            -176.5
Df Residuals:                     161   BIC:                            -164.1
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.6073      0.066     -9.248      0.000      -0.737      -0.478
p1                    0.7085      0.080      8.827      0.000       0.550       0.867
answer_changed        0.4327      0.091      4.775      0.000       0.254       0.612
p1:answer_changed     0.4170      0.115      3.631      0.000       0.190       0.644
==============================================================================
Omnibus:                        7.269   Durbin-Watson:                   2.148
Prob(Omnibus):                  0.026   Jarque-Bera (JB):                7.508
Skew:                           0.385   Prob(JB):                       0.0234
Kurtosis:                       3.707   Cond. No.                         21.9
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=5.29, p=9.84e-07
Wilcoxon delta_H: statistic=774.00, p=6.52e-06
Mean ΔH = 0.2813  [0.1770, 0.3855]
Paired t-test delta_H Changed: statistic=4.70, p=1.06e-05
Wilcoxon delta_H Changed: statistic=799.00, p=4.99e-05
Mean ΔH Changed = 0.2741  [0.1598, 0.3883]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=5.51, p=1.37e-07
Wilcoxon (p_top2_game vs p_top2_base): statistic=3678.00, p=2.51e-07
Mean Δp_top2 = 0.0348  [0.0224, 0.0472] (n=165)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=7.07, p=4.2e-11
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=3099.00, p=1.07e-09
Mean ΔH_unchosen_baseline_set = 0.2777  [0.2008, 0.3547] (n=165)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  165
Model:                          Logit   Df Residuals:                      162
Method:                           MLE   Df Model:                            2
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.02137
Time:                        09:26:43   Log-Likelihood:                -111.90
converged:                       True   LL-Null:                       -114.34
Covariance Type:            nonrobust   LLR p-value:                   0.08689
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept        0.1320      0.239      0.553      0.581      -0.336       0.600
p1_z            -0.3803      0.174     -2.182      0.029      -0.722      -0.039
I(p1_z ** 2)    -0.1709      0.182     -0.941      0.347      -0.527       0.185
================================================================================
AUC = 0.595

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  242
Model:                          Logit   Df Residuals:                      240
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                0.009604
Time:                        09:26:43   Log-Likelihood:                -165.14
converged:                       True   LL-Null:                       -166.74
Covariance Type:            nonrobust   LLR p-value:                   0.07352
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.4102      0.183     -2.244      0.025      -0.768      -0.052
game_entropy     0.5036      0.283      1.781      0.075      -0.051       1.058
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=8124.00, p=3.74e-08
Paired t-test (game_entropy vs capabilities_entropy): statistic=-5.31, p=2.49e-07
Mean capabilities_entropy-game_entropy = 0.1834  [0.1157, 0.2511] (n=242)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  242
Model:                          Logit   Df Residuals:                      239
Method:                           MLE   Df Model:                            2
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.02578
Time:                        09:26:43   Log-Likelihood:                -162.44
converged:                       True   LL-Null:                       -166.74
Covariance Type:            nonrobust   LLR p-value:                   0.01358
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -0.6579      0.215     -3.059      0.002      -1.079      -0.236
capabilities_entropy     0.6152      0.267      2.302      0.021       0.092       1.139
game_entropy             0.1812      0.317      0.571      0.568      -0.441       0.803
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['Video games', 'TV shows', 'History']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.562500
                        1                 0.437500
Geography               0                 0.560000
                        1                 0.440000
Misc                    1                 0.647059
                        0                 0.352941
Music                   0                 0.578947
                        1                 0.421053
Other                   0                 0.565217
                        1                 0.434783
Politics                0                 0.525000
                        1                 0.475000
Science and technology  0                 0.615385
                        1                 0.384615
Sports                  0                 0.647059
                        1                 0.352941
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 1                 0.540816
                     0                 0.459184
Number               0                 0.565217
                     1                 0.434783
Other                0                 0.666667
                     1                 0.333333
Person               0                 0.574468
                     1                 0.425532
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.500000  0.500000           12
                       Number               0.666667  0.333333            6
                       Other                0.400000  0.600000            5
                       Person               0.666667  0.333333            9
Geography              Date                 0.500000  0.500000           12
                       Number               0.500000  0.500000           10
                       Other                1.000000  0.000000            3
Misc                   Date                 0.307692  0.692308           13
                       Number               0.400000  0.600000            5
                       Other                0.600000  0.400000           10
                       Person               0.000000  1.000000            6
Music                  Date                 0.428571  0.571429            7
                       Number               1.000000  0.000000            2
                       Other                0.750000  0.250000            8
                       Person               0.000000  1.000000            2
Other                  Date                 0.500000  0.500000           10
                       Number               0.666667  0.333333            3
                       Other                0.666667  0.333333            6
                       Person               0.500000  0.500000            4
Politics               Date                 0.411765  0.588235           17
                       Number               0.400000  0.600000            5
                       Other                0.500000  0.500000            8
                       Person               0.800000  0.200000           10
Science and technology Date                 0.590909  0.409091           22
                       Number               0.555556  0.444444            9
                       Other                0.714286  0.285714            7
                       Person               0.642857  0.357143           14
Sports                 Date                 0.200000  0.800000            5
                       Number               0.666667  0.333333            6
                       Other                1.000000  0.000000            4
                       Person               1.000000  0.000000            2

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  242
Model:                          Logit   Df Residuals:                      230
Method:                           MLE   Df Model:                           11
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.04899
Time:                        09:26:43   Log-Likelihood:                -158.57
converged:                       True   LL-Null:                       -166.74
Covariance Type:            nonrobust   LLR p-value:                    0.1291
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      2.4315      1.742      1.396      0.163      -0.983       5.846
C(topic_grouped)[T.Geography]                 -0.1657      0.561     -0.295      0.768      -1.266       0.934
C(topic_grouped)[T.Misc]                       0.9552      0.520      1.837      0.066      -0.064       1.974
C(topic_grouped)[T.Music]                      0.0206      0.607      0.034      0.973      -1.170       1.211
C(topic_grouped)[T.Other]                     -0.0177      0.564     -0.031      0.975      -1.123       1.087
C(topic_grouped)[T.Politics]                   0.2472      0.490      0.504      0.614      -0.714       1.208
C(topic_grouped)[T.Science and technology]    -0.2449      0.464     -0.527      0.598      -1.155       0.665
C(topic_grouped)[T.Sports]                    -0.3243      0.640     -0.507      0.612      -1.579       0.930
C(answer_type_grouped)[T.Number]              -0.3569      0.373     -0.957      0.339      -1.088       0.374
C(answer_type_grouped)[T.Other]               -1.0519      0.382     -2.757      0.006      -1.800      -0.304
C(answer_type_grouped)[T.Person]              -0.5656      0.378     -1.497      0.134      -1.306       0.175
q_length                                      -0.5138      0.373     -1.378      0.168      -1.245       0.217
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.6324
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  242
Model:                          Logit   Df Residuals:                      229
Method:                           MLE   Df Model:                           12
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.06798
Time:                        09:26:43   Log-Likelihood:                -155.40
converged:                       True   LL-Null:                       -166.74
Covariance Type:            nonrobust   LLR p-value:                   0.03065
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      1.6674      1.784      0.935      0.350      -1.829       5.164
C(topic_grouped)[T.Geography]                 -0.3068      0.573     -0.535      0.593      -1.430       0.817
C(topic_grouped)[T.Misc]                       0.8976      0.525      1.709      0.087      -0.132       1.927
C(topic_grouped)[T.Music]                      0.1581      0.617      0.256      0.798      -1.050       1.367
C(topic_grouped)[T.Other]                      0.0362      0.569      0.064      0.949      -1.080       1.152
C(topic_grouped)[T.Politics]                   0.1672      0.495      0.338      0.735      -0.802       1.137
C(topic_grouped)[T.Science and technology]    -0.3573      0.472     -0.758      0.449      -1.282       0.567
C(topic_grouped)[T.Sports]                    -0.3938      0.651     -0.605      0.545      -1.669       0.882
C(answer_type_grouped)[T.Number]              -0.3098      0.379     -0.818      0.413      -1.052       0.432
C(answer_type_grouped)[T.Other]               -0.9381      0.389     -2.414      0.016      -1.700      -0.177
C(answer_type_grouped)[T.Person]              -0.2860      0.397     -0.721      0.471      -1.063       0.491
q_length                                      -0.4461      0.378     -1.181      0.238      -1.186       0.294
capabilities_entropy                           0.6602      0.266      2.485      0.013       0.140       1.181
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  242
Model:                          Logit   Df Residuals:                      229
Method:                           MLE   Df Model:                           12
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.05460
Time:                        09:26:43   Log-Likelihood:                -157.64
converged:                       True   LL-Null:                       -166.74
Covariance Type:            nonrobust   LLR p-value:                    0.1095
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      2.2433      1.751      1.281      0.200      -1.188       5.675
C(topic_grouped)[T.Geography]                 -0.1672      0.563     -0.297      0.767      -1.271       0.937
C(topic_grouped)[T.Misc]                       0.9446      0.523      1.808      0.071      -0.080       1.969
C(topic_grouped)[T.Music]                      0.1494      0.617      0.242      0.809      -1.060       1.359
C(topic_grouped)[T.Other]                     -0.0130      0.567     -0.023      0.982      -1.124       1.098
C(topic_grouped)[T.Politics]                   0.3102      0.495      0.626      0.531      -0.661       1.281
C(topic_grouped)[T.Science and technology]    -0.2392      0.467     -0.512      0.609      -1.155       0.677
C(topic_grouped)[T.Sports]                    -0.3518      0.645     -0.546      0.585      -1.615       0.911
C(answer_type_grouped)[T.Number]              -0.3463      0.374     -0.925      0.355      -1.080       0.387
C(answer_type_grouped)[T.Other]               -0.9686      0.387     -2.503      0.012      -1.727      -0.210
C(answer_type_grouped)[T.Person]              -0.4129      0.396     -1.043      0.297      -1.189       0.363
q_length                                      -0.5303      0.374     -1.418      0.156      -1.263       0.203
game_entropy                                   0.4294      0.315      1.365      0.172      -0.187       1.046
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  242
Model:                          Logit   Df Residuals:                      228
Method:                           MLE   Df Model:                           13
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.06858
Time:                        09:26:43   Log-Likelihood:                -155.30
converged:                       True   LL-Null:                       -166.74
Covariance Type:            nonrobust   LLR p-value:                   0.04326
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      1.6565      1.784      0.929      0.353      -1.840       5.153
C(topic_grouped)[T.Geography]                 -0.2976      0.573     -0.519      0.604      -1.421       0.826
C(topic_grouped)[T.Misc]                       0.8989      0.526      1.709      0.087      -0.132       1.930
C(topic_grouped)[T.Music]                      0.1941      0.623      0.312      0.755      -1.026       1.414
C(topic_grouped)[T.Other]                      0.0335      0.570      0.059      0.953      -1.083       1.150
C(topic_grouped)[T.Politics]                   0.1952      0.499      0.391      0.696      -0.783       1.174
C(topic_grouped)[T.Science and technology]    -0.3479      0.473     -0.735      0.462      -1.275       0.579
C(topic_grouped)[T.Sports]                    -0.3992      0.652     -0.613      0.540      -1.676       0.878
C(answer_type_grouped)[T.Number]              -0.3092      0.379     -0.817      0.414      -1.051       0.433
C(answer_type_grouped)[T.Other]               -0.9166      0.392     -2.341      0.019      -1.684      -0.149
C(answer_type_grouped)[T.Person]              -0.2509      0.405     -0.619      0.536      -1.045       0.543
q_length                                      -0.4571      0.379     -1.207      0.227      -1.199       0.285
capabilities_entropy                           0.6132      0.286      2.145      0.032       0.053       1.174
game_entropy                                   0.1535      0.343      0.447      0.655      -0.519       0.826
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing gpt-4o-2024-08-06 (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/gpt-4o-2024-08-06_SimpleMC_redacted_cor_temp1.0_1757988718_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    204
1     29
Name: count, dtype: int64

Answer change%: 0.1245 [0.08207694754971168, 0.16685009107689777] (n=233)
P-value vs 25%: 6.443e-09; P-value vs 0%: 8.653e-09
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=29)
P-value vs 25%: 0; P-value vs 33%: 0

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  233
Model:                          Logit   Df Residuals:                      231
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.2513
Time:                        09:26:43   Log-Likelihood:                -65.545
converged:                       True   LL-Null:                       -87.544
Covariance Type:            nonrobust   LLR p-value:                 3.287e-11
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          3.0230      0.814      3.715      0.000       1.428       4.618
p_i_capability    -6.9982      1.260     -5.553      0.000      -9.468      -4.528
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  233
Model:                          Logit   Df Residuals:                      231
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.2479
Time:                        09:26:43   Log-Likelihood:                -65.845
converged:                       True   LL-Null:                       -87.544
Covariance Type:            nonrobust   LLR p-value:                 4.467e-11
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -4.4084      0.638     -6.908      0.000      -5.659      -3.158
capabilities_entropy     2.4857      0.477      5.212      0.000       1.551       3.420
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.6897 [0.5213, 0.8580] (n=29)
                  P-value vs 33.3%: 3.359e-05

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=-1.35, p=0.179
Wilcoxon delta_p: statistic=8071.00, p=0.187
Mean Δp = -0.0137  [-0.0337, 0.0062]
Idea 1 N = 190; 

  Idea 1.5: Calibration Metrics
  NLL: 0.2560, Signed ECE (overconf pos under neg): -0.1965, ECE: 0.1965 (n=219)
  Brier: 0.0792, Reliability (absolute calibration error; lower better): 0.0785, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=219)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.509
Model:                            OLS   Adj. R-squared:                  0.502
Method:                 Least Squares   F-statistic:                     74.28
Date:                Sat, 20 Sep 2025   Prob (F-statistic):           5.25e-33
Time:                        09:26:43   Log-Likelihood:                 140.64
No. Observations:                 219   AIC:                            -273.3
Df Residuals:                     215   BIC:                            -259.7
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.2761      0.043     -6.492      0.000      -0.360      -0.192
p1                    0.3133      0.050      6.323      0.000       0.216       0.411
answer_changed        0.1953      0.118      1.656      0.099      -0.037       0.428
p1:answer_changed     0.3769      0.192      1.966      0.051      -0.001       0.755
==============================================================================
Omnibus:                       12.150   Durbin-Watson:                   1.861
Prob(Omnibus):                  0.002   Jarque-Bera (JB):               14.585
Skew:                           0.438   Prob(JB):                     0.000681
Kurtosis:                       3.911   Cond. No.                         33.6
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=1.83, p=0.069
Wilcoxon delta_H: statistic=7350.00, p=0.0232
Mean ΔH = 0.0590  [-0.0042, 0.1221]
Paired t-test delta_H Changed: statistic=5.36, p=1.03e-05
Wilcoxon delta_H Changed: statistic=20.00, p=1.38e-06
Mean ΔH Changed = 0.4044  [0.2565, 0.5522]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=3.11, p=0.00211
Wilcoxon (p_top2_game vs p_top2_base): statistic=9045.00, p=0.0014
Mean Δp_top2 = 0.0147  [0.0054, 0.0240] (n=219)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=3.41, p=0.000768
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=8474.00, p=0.000142
Mean ΔH_unchosen_baseline_set = 0.1047  [0.0446, 0.1648] (n=219)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  219
Model:                          Logit   Df Residuals:                      216
Method:                           MLE   Df Model:                            2
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.2718
Time:                        09:26:43   Log-Likelihood:                -62.351
converged:                       True   LL-Null:                       -85.621
Covariance Type:            nonrobust   LLR p-value:                 7.834e-11
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -2.3819      0.405     -5.882      0.000      -3.176      -1.588
p1_z            -2.4477      0.666     -3.673      0.000      -3.754      -1.141
I(p1_z ** 2)    -0.7841      0.362     -2.163      0.031      -1.494      -0.074
================================================================================
AUC = 0.843

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  233
Model:                          Logit   Df Residuals:                      231
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1677
Time:                        09:26:43   Log-Likelihood:                -72.863
converged:                       True   LL-Null:                       -87.544
Covariance Type:            nonrobust   LLR p-value:                 6.005e-08
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -3.5253      0.463     -7.611      0.000      -4.433      -2.618
game_entropy     1.9194      0.396      4.852      0.000       1.144       2.695
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=11102.00, p=0.0141
Paired t-test (game_entropy vs capabilities_entropy): statistic=-3.05, p=0.00256
Mean capabilities_entropy-game_entropy = 0.0759  [0.0271, 0.1248] (n=233)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  233
Model:                          Logit   Df Residuals:                      230
Method:                           MLE   Df Model:                            2
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.2507
Time:                        09:26:43   Log-Likelihood:                -65.593
converged:                       True   LL-Null:                       -87.544
Covariance Type:            nonrobust   LLR p-value:                 2.931e-10
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -4.4693      0.650     -6.877      0.000      -5.743      -3.196
capabilities_entropy     2.2150      0.611      3.628      0.000       1.018       3.412
game_entropy             0.3862      0.548      0.705      0.481      -0.687       1.459
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': None
topic_grouped           answer_changed
Art                     0                 0.853659
                        1                 0.146341
Geography               0                 0.882353
                        1                 0.117647
Misc                    0                 0.888889
                        1                 0.111111
Music                   0                 0.777778
                        1                 0.222222
Other                   0                 0.833333
                        1                 0.166667
Politics                0                 0.906250
                        1                 0.093750
Science and technology  0                 0.953488
                        1                 0.046512
Sports                  0                 0.833333
                        1                 0.166667
TV shows                0                 0.875000
                        1                 0.125000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.803279
                     1                 0.196721
Number               0                 0.827586
                     1                 0.172414
Other                0                 0.964912
                     1                 0.035088
Person               0                 0.882353
                     1                 0.117647
Place                0                 0.888889
                     1                 0.111111
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.750000  0.250000            8
                       Number               1.000000  0.000000            4
                       Other                1.000000  0.000000            6
                       Person               0.850000  0.150000           20
                       Place                0.666667  0.333333            3
Geography              Date                 0.600000  0.400000            5
                       Number               1.000000  0.000000            4
                       Other                1.000000  0.000000            3
                       Place                1.000000  0.000000            5
Misc                   Date                 0.875000  0.125000            8
                       Number               0.666667  0.333333            3
                       Other                1.000000  0.000000            3
                       Person               1.000000  0.000000            2
                       Place                1.000000  0.000000            2
Music                  Date                 0.000000  1.000000            2
                       Number               0.666667  0.333333            3
                       Other                1.000000  0.000000            4
                       Person               0.888889  0.111111            9
Other                  Date                 0.833333  0.166667            6
                       Number               0.666667  0.333333            3
                       Other                0.666667  0.333333            6
                       Person               1.000000  0.000000            7
                       Place                1.000000  0.000000            2
Politics               Date                 0.909091  0.090909           11
                       Number               1.000000  0.000000            1
                       Other                1.000000  0.000000            8
                       Person               0.875000  0.125000            8
                       Place                0.750000  0.250000            4
Science and technology Date                 0.933333  0.066667           15
                       Number               1.000000  0.000000            5
                       Other                1.000000  0.000000           11
                       Person               0.916667  0.083333           12
Sports                 Date                 0.600000  0.400000            5
                       Number               0.600000  0.400000            5
                       Other                1.000000  0.000000            6
                       Person               1.000000  0.000000            6
                       Place                1.000000  0.000000            2
TV shows               Date                 1.000000  0.000000            1
                       Number               1.000000  0.000000            1
                       Other                1.000000  0.000000           10
                       Person               0.500000  0.500000            4

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  233
Model:                          Logit   Df Residuals:                      219
Method:                           MLE   Df Model:                           13
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.09704
Time:                        09:26:43   Log-Likelihood:                -79.048
converged:                       True   LL-Null:                       -87.544
Covariance Type:            nonrobust   LLR p-value:                    0.1997
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      0.7855      2.722      0.289      0.773      -4.549       6.120
C(topic_grouped)[T.Geography]                 -0.4771      0.920     -0.519      0.604      -2.280       1.326
C(topic_grouped)[T.Misc]                      -0.6709      0.907     -0.740      0.459      -2.448       1.106
C(topic_grouped)[T.Music]                      0.6610      0.749      0.882      0.378      -0.807       2.129
C(topic_grouped)[T.Other]                      0.1713      0.730      0.235      0.815      -1.260       1.603
C(topic_grouped)[T.Politics]                  -0.5055      0.791     -0.639      0.523      -2.055       1.044
C(topic_grouped)[T.Science and technology]    -1.3762      0.875     -1.573      0.116      -3.091       0.338
C(topic_grouped)[T.Sports]                     0.1226      0.733      0.167      0.867      -1.314       1.559
C(topic_grouped)[T.TV shows]                   0.4084      0.951      0.429      0.668      -1.456       2.272
C(answer_type_grouped)[T.Number]              -0.3505      0.632     -0.554      0.579      -1.590       0.889
C(answer_type_grouped)[T.Other]               -2.2843      0.833     -2.743      0.006      -3.917      -0.652
C(answer_type_grouped)[T.Person]              -0.9922      0.542     -1.829      0.067      -2.055       0.071
C(answer_type_grouped)[T.Place]               -0.7744      0.842     -0.919      0.358      -2.425       0.876
q_length                                      -0.3994      0.598     -0.668      0.504      -1.572       0.773
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.6543
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  233
Model:                          Logit   Df Residuals:                      218
Method:                           MLE   Df Model:                           14
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.3104
Time:                        09:26:43   Log-Likelihood:                -60.369
converged:                       True   LL-Null:                       -87.544
Covariance Type:            nonrobust   LLR p-value:                 1.119e-06
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -3.2471      3.119     -1.041      0.298      -9.360       2.866
C(topic_grouped)[T.Geography]                 -0.3609      1.043     -0.346      0.729      -2.405       1.683
C(topic_grouped)[T.Misc]                      -0.2348      0.977     -0.240      0.810      -2.150       1.681
C(topic_grouped)[T.Music]                      0.9252      0.936      0.989      0.323      -0.909       2.759
C(topic_grouped)[T.Other]                      0.2212      0.825      0.268      0.789      -1.397       1.839
C(topic_grouped)[T.Politics]                  -0.6705      0.868     -0.773      0.440      -2.371       1.030
C(topic_grouped)[T.Science and technology]    -0.8300      0.943     -0.880      0.379      -2.678       1.018
C(topic_grouped)[T.Sports]                     0.4287      0.825      0.520      0.603      -1.187       2.045
C(topic_grouped)[T.TV shows]                   0.1555      1.165      0.133      0.894      -2.128       2.439
C(answer_type_grouped)[T.Number]              -0.9816      0.753     -1.303      0.193      -2.458       0.495
C(answer_type_grouped)[T.Other]               -1.5476      0.965     -1.603      0.109      -3.439       0.344
C(answer_type_grouped)[T.Person]               0.5052      0.661      0.764      0.445      -0.791       1.801
C(answer_type_grouped)[T.Place]               -0.0441      0.936     -0.047      0.962      -1.879       1.791
q_length                                      -0.2910      0.655     -0.444      0.657      -1.574       0.992
capabilities_entropy                           2.8425      0.600      4.738      0.000       1.667       4.018
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  233
Model:                          Logit   Df Residuals:                      218
Method:                           MLE   Df Model:                           14
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.2292
Time:                        09:26:43   Log-Likelihood:                -67.479
converged:                       True   LL-Null:                       -87.544
Covariance Type:            nonrobust   LLR p-value:                 0.0002435
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -0.8217      3.100     -0.265      0.791      -6.898       5.254
C(topic_grouped)[T.Geography]                 -0.4045      1.018     -0.398      0.691      -2.399       1.590
C(topic_grouped)[T.Misc]                      -0.6898      0.940     -0.734      0.463      -2.533       1.153
C(topic_grouped)[T.Music]                      0.6066      0.820      0.740      0.460      -1.001       2.214
C(topic_grouped)[T.Other]                     -0.1561      0.786     -0.199      0.843      -1.697       1.385
C(topic_grouped)[T.Politics]                  -0.6407      0.862     -0.743      0.457      -2.330       1.049
C(topic_grouped)[T.Science and technology]    -1.3552      0.913     -1.485      0.138      -3.144       0.434
C(topic_grouped)[T.Sports]                     0.0457      0.807      0.057      0.955      -1.536       1.627
C(topic_grouped)[T.TV shows]                   0.1374      1.089      0.126      0.900      -1.998       2.273
C(answer_type_grouped)[T.Number]              -0.6512      0.689     -0.945      0.345      -2.002       0.700
C(answer_type_grouped)[T.Other]               -1.8503      0.916     -2.019      0.044      -3.647      -0.054
C(answer_type_grouped)[T.Person]              -0.3466      0.615     -0.564      0.573      -1.552       0.859
C(answer_type_grouped)[T.Place]               -0.4969      0.907     -0.548      0.584      -2.275       1.281
q_length                                      -0.4198      0.680     -0.618      0.537      -1.752       0.912
game_entropy                                   1.8684      0.430      4.349      0.000       1.026       2.710
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  233
Model:                          Logit   Df Residuals:                      217
Method:                           MLE   Df Model:                           15
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.3137
Time:                        09:26:43   Log-Likelihood:                -60.079
converged:                       True   LL-Null:                       -87.544
Covariance Type:            nonrobust   LLR p-value:                 1.835e-06
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -3.2291      3.146     -1.026      0.305      -9.396       2.938
C(topic_grouped)[T.Geography]                 -0.3511      1.063     -0.330      0.741      -2.434       1.732
C(topic_grouped)[T.Misc]                      -0.2512      0.978     -0.257      0.797      -2.169       1.667
C(topic_grouped)[T.Music]                      0.8933      0.934      0.956      0.339      -0.938       2.724
C(topic_grouped)[T.Other]                      0.1715      0.831      0.207      0.836      -1.456       1.799
C(topic_grouped)[T.Politics]                  -0.6361      0.866     -0.735      0.463      -2.333       1.061
C(topic_grouped)[T.Science and technology]    -0.9060      0.953     -0.951      0.342      -2.773       0.961
C(topic_grouped)[T.Sports]                     0.4306      0.831      0.518      0.604      -1.198       2.059
C(topic_grouped)[T.TV shows]                   0.1488      1.165      0.128      0.898      -2.135       2.433
C(answer_type_grouped)[T.Number]              -1.0176      0.755     -1.347      0.178      -2.498       0.463
C(answer_type_grouped)[T.Other]               -1.5545      0.974     -1.597      0.110      -3.463       0.354
C(answer_type_grouped)[T.Person]               0.5007      0.665      0.753      0.452      -0.803       1.804
C(answer_type_grouped)[T.Place]               -0.0758      0.944     -0.080      0.936      -1.926       1.774
q_length                                      -0.3075      0.661     -0.465      0.642      -1.603       0.988
capabilities_entropy                           2.5532      0.711      3.590      0.000       1.159       3.947
game_entropy                                   0.4266      0.562      0.759      0.448      -0.675       1.528
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing gpt-4o-2024-08-06 (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/gpt-4o-2024-08-06_SimpleMC_redacted_temp1.0_1757987648_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    162
1    105
Name: count, dtype: int64

Answer change%: 0.3933 [0.3346670970543478, 0.45184975687823653] (n=267)
P-value vs 25%: 1.65e-06; P-value vs 0%: 1.592e-39
Phase 2 self-accuracy: 0.6476 [0.5562457158897331, 0.7389923793483621] (n=105)
P-value vs 25%: 1.477e-17; P-value vs 33%: 1.493e-11

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  267
Model:                          Logit   Df Residuals:                      265
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.05816
Time:                        09:26:43   Log-Likelihood:                -168.53
converged:                       True   LL-Null:                       -178.94
Covariance Type:            nonrobust   LLR p-value:                 5.065e-06
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          1.4436      0.440      3.284      0.001       0.582       2.305
p_i_capability    -2.8520      0.652     -4.372      0.000      -4.131      -1.573
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  267
Model:                          Logit   Df Residuals:                      265
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.05380
Time:                        09:26:43   Log-Likelihood:                -169.31
converged:                       True   LL-Null:                       -178.94
Covariance Type:            nonrobust   LLR p-value:                 1.145e-05
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.5762      0.314     -5.020      0.000      -2.192      -0.961
capabilities_entropy     1.0139      0.244      4.159      0.000       0.536       1.492
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.7238 [0.6383, 0.8093] (n=105)
                  P-value vs 33.3%: 3.588e-19

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=-2.09, p=0.0378
Wilcoxon delta_p: statistic=4936.00, p=0.0266
Mean Δp = -0.0296  [-0.0573, -0.0019]
Idea 1 N = 157; 

  Idea 1.5: Calibration Metrics
  NLL: 2.9149, Signed ECE (overconf pos under neg): 0.1604, ECE: 0.1604 (n=262)
  Brier: 0.0451, Reliability (absolute calibration error; lower better): 0.0442, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=262)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.751
Model:                            OLS   Adj. R-squared:                  0.748
Method:                 Least Squares   F-statistic:                     259.1
Date:                Sat, 20 Sep 2025   Prob (F-statistic):           1.62e-77
Time:                        09:26:43   Log-Likelihood:                 129.79
No. Observations:                 262   AIC:                            -251.6
Df Residuals:                     258   BIC:                            -237.3
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.3321      0.043     -7.664      0.000      -0.417      -0.247
p1                    0.4252      0.059      7.257      0.000       0.310       0.541
answer_changed        0.0733      0.063      1.155      0.249      -0.052       0.198
p1:answer_changed     0.6578      0.094      7.011      0.000       0.473       0.843
==============================================================================
Omnibus:                        5.807   Durbin-Watson:                   2.102
Prob(Omnibus):                  0.055   Jarque-Bera (JB):                3.954
Skew:                           0.146   Prob(JB):                        0.138
Kurtosis:                       2.474   Cond. No.                         17.6
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=2.44, p=0.0158
Wilcoxon delta_H: statistic=4693.00, p=0.0082
Mean ΔH = 0.0783  [0.0154, 0.1411]
Paired t-test delta_H Changed: statistic=7.16, p=1.18e-10
Wilcoxon delta_H Changed: statistic=800.00, p=2.33e-10
Mean ΔH Changed = 0.2689  [0.1953, 0.3425]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=3.44, p=0.000672
Wilcoxon (p_top2_game vs p_top2_base): statistic=13576.00, p=0.00295
Mean Δp_top2 = 0.0207  [0.0089, 0.0326] (n=262)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=6.18, p=2.49e-09
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=9643.00, p=6.54e-10
Mean ΔH_unchosen_baseline_set = 0.1547  [0.1056, 0.2038] (n=262)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  262
Model:                          Logit   Df Residuals:                      259
Method:                           MLE   Df Model:                            2
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.05459
Time:                        09:26:43   Log-Likelihood:                -166.78
converged:                       True   LL-Null:                       -176.41
Covariance Type:            nonrobust   LLR p-value:                 6.568e-05
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.5750      0.200     -2.880      0.004      -0.966      -0.184
p1_z            -0.5826      0.137     -4.240      0.000      -0.852      -0.313
I(p1_z ** 2)     0.1463      0.157      0.935      0.350      -0.160       0.453
================================================================================
AUC = 0.653

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  267
Model:                          Logit   Df Residuals:                      265
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.05904
Time:                        09:26:43   Log-Likelihood:                -168.38
converged:                       True   LL-Null:                       -178.94
Covariance Type:            nonrobust   LLR p-value:                 4.297e-06
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.5955      0.306     -5.219      0.000      -2.195      -0.996
game_entropy     1.1143      0.255      4.369      0.000       0.614       1.614
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=14099.00, p=0.00269
Paired t-test (game_entropy vs capabilities_entropy): statistic=-2.98, p=0.00313
Mean capabilities_entropy-game_entropy = 0.0817  [0.0280, 0.1354] (n=267)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  267
Model:                          Logit   Df Residuals:                      264
Method:                           MLE   Df Model:                            2
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.06784
Time:                        09:26:43   Log-Likelihood:                -166.80
converged:                       True   LL-Null:                       -178.94
Covariance Type:            nonrobust   LLR p-value:                 5.341e-06
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.8306      0.342     -5.347      0.000      -2.502      -1.160
capabilities_entropy     0.5588      0.317      1.764      0.078      -0.062       1.180
game_entropy             0.7342      0.331      2.218      0.027       0.085       1.383
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['Sports', 'Video games', 'TV shows', 'History']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.529412
                        1                 0.470588
Geography               0                 0.592593
                        1                 0.407407
Misc                    0                 0.642857
                        1                 0.357143
Music                   0                 0.636364
                        1                 0.363636
Other                   0                 0.642857
                        1                 0.357143
Politics                0                 0.555556
                        1                 0.444444
Science and technology  0                 0.636364
                        1                 0.363636
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.518519
                     1                 0.481481
Number               0                 0.693878
                     1                 0.306122
Other                0                 0.689655
                     1                 0.310345
Person               0                 0.615385
                     1                 0.384615
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.461538  0.538462           13
                       Number               0.800000  0.200000            5
                       Other                0.555556  0.444444            9
                       Person               0.428571  0.571429            7
Geography              Date                 0.200000  0.800000           10
                       Number               0.857143  0.142857           14
                       Other                0.666667  0.333333            3
Misc                   Date                 0.666667  0.333333           18
                       Number               0.636364  0.363636           11
                       Other                0.562500  0.437500           16
                       Person               0.727273  0.272727           11
Music                  Date                 0.600000  0.400000           10
                       Number               1.000000  0.000000            1
                       Other                0.750000  0.250000            8
                       Person               0.333333  0.666667            3
Other                  Date                 0.583333  0.416667           12
                       Number               0.500000  0.500000            4
                       Other                1.000000  0.000000            6
                       Person               0.500000  0.500000            6
Politics               Date                 0.480000  0.520000           25
                       Number               0.400000  0.600000            5
                       Other                0.750000  0.250000            8
                       Person               0.714286  0.285714            7
Science and technology Date                 0.550000  0.450000           20
                       Number               0.666667  0.333333            9
                       Other                0.750000  0.250000            8
                       Person               0.666667  0.333333           18

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  267
Model:                          Logit   Df Residuals:                      256
Method:                           MLE   Df Model:                           10
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.02526
Time:                        09:26:43   Log-Likelihood:                -174.42
converged:                       True   LL-Null:                       -178.94
Covariance Type:            nonrobust   LLR p-value:                    0.5282
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      1.1185      1.641      0.682      0.495      -2.097       4.334
C(topic_grouped)[T.Geography]                 -0.1733      0.548     -0.316      0.752      -1.248       0.901
C(topic_grouped)[T.Misc]                      -0.4025      0.452     -0.891      0.373      -1.288       0.483
C(topic_grouped)[T.Music]                     -0.4953      0.570     -0.869      0.385      -1.613       0.622
C(topic_grouped)[T.Other]                     -0.5295      0.530     -0.998      0.318      -1.569       0.510
C(topic_grouped)[T.Politics]                  -0.1736      0.471     -0.368      0.713      -1.098       0.750
C(topic_grouped)[T.Science and technology]    -0.4668      0.453     -1.032      0.302      -1.354       0.420
C(answer_type_grouped)[T.Number]              -0.7833      0.381     -2.054      0.040      -1.531      -0.036
C(answer_type_grouped)[T.Other]               -0.7381      0.351     -2.100      0.036      -1.427      -0.049
C(answer_type_grouped)[T.Person]              -0.3836      0.357     -1.074      0.283      -1.084       0.317
q_length                                      -0.1916      0.354     -0.542      0.588      -0.885       0.501
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 1.0850
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  267
Model:                          Logit   Df Residuals:                      255
Method:                           MLE   Df Model:                           11
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.08145
Time:                        09:26:43   Log-Likelihood:                -164.36
converged:                       True   LL-Null:                       -178.94
Covariance Type:            nonrobust   LLR p-value:                  0.002153
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -0.2523      1.724     -0.146      0.884      -3.631       3.127
C(topic_grouped)[T.Geography]                 -0.3560      0.571     -0.623      0.533      -1.476       0.764
C(topic_grouped)[T.Misc]                      -0.5138      0.469     -1.096      0.273      -1.432       0.405
C(topic_grouped)[T.Music]                     -0.4776      0.600     -0.796      0.426      -1.654       0.699
C(topic_grouped)[T.Other]                     -0.5320      0.558     -0.953      0.341      -1.626       0.562
C(topic_grouped)[T.Politics]                  -0.1998      0.494     -0.404      0.686      -1.169       0.769
C(topic_grouped)[T.Science and technology]    -0.5144      0.472     -1.090      0.276      -1.440       0.411
C(answer_type_grouped)[T.Number]              -0.8975      0.391     -2.293      0.022      -1.665      -0.130
C(answer_type_grouped)[T.Other]               -0.5848      0.365     -1.604      0.109      -1.299       0.130
C(answer_type_grouped)[T.Person]              -0.0099      0.384     -0.026      0.980      -0.762       0.742
q_length                                      -0.1695      0.366     -0.464      0.643      -0.886       0.547
capabilities_entropy                           1.1060      0.261      4.239      0.000       0.595       1.617
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  267
Model:                          Logit   Df Residuals:                      255
Method:                           MLE   Df Model:                           11
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.08377
Time:                        09:26:43   Log-Likelihood:                -163.95
converged:                       True   LL-Null:                       -178.94
Covariance Type:            nonrobust   LLR p-value:                  0.001595
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -0.6421      1.753     -0.366      0.714      -4.078       2.793
C(topic_grouped)[T.Geography]                 -0.2119      0.573     -0.370      0.711      -1.335       0.911
C(topic_grouped)[T.Misc]                      -0.3605      0.466     -0.773      0.439      -1.275       0.553
C(topic_grouped)[T.Music]                     -0.4505      0.590     -0.763      0.445      -1.607       0.706
C(topic_grouped)[T.Other]                     -0.4518      0.554     -0.816      0.415      -1.537       0.634
C(topic_grouped)[T.Politics]                  -0.0791      0.493     -0.160      0.873      -1.046       0.888
C(topic_grouped)[T.Science and technology]    -0.3174      0.473     -0.671      0.502      -1.244       0.610
C(answer_type_grouped)[T.Number]              -0.8857      0.393     -2.252      0.024      -1.657      -0.115
C(answer_type_grouped)[T.Other]               -0.6501      0.365     -1.783      0.075      -1.365       0.064
C(answer_type_grouped)[T.Person]              -0.1415      0.377     -0.375      0.708      -0.881       0.598
q_length                                      -0.0934      0.369     -0.253      0.800      -0.817       0.631
game_entropy                                   1.1591      0.267      4.349      0.000       0.637       1.682
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  267
Model:                          Logit   Df Residuals:                      254
Method:                           MLE   Df Model:                           12
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.09469
Time:                        09:26:43   Log-Likelihood:                -161.99
converged:                       True   LL-Null:                       -178.94
Covariance Type:            nonrobust   LLR p-value:                 0.0007023
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -0.8131      1.764     -0.461      0.645      -4.271       2.645
C(topic_grouped)[T.Geography]                 -0.3120      0.577     -0.541      0.589      -1.443       0.819
C(topic_grouped)[T.Misc]                      -0.4371      0.471     -0.929      0.353      -1.360       0.485
C(topic_grouped)[T.Music]                     -0.4663      0.601     -0.776      0.438      -1.644       0.711
C(topic_grouped)[T.Other]                     -0.4852      0.562     -0.863      0.388      -1.587       0.617
C(topic_grouped)[T.Politics]                  -0.1374      0.500     -0.275      0.783      -1.117       0.842
C(topic_grouped)[T.Science and technology]    -0.3980      0.478     -0.833      0.405      -1.335       0.538
C(answer_type_grouped)[T.Number]              -0.9248      0.395     -2.340      0.019      -1.699      -0.150
C(answer_type_grouped)[T.Other]               -0.5897      0.368     -1.604      0.109      -1.310       0.131
C(answer_type_grouped)[T.Person]              -0.0142      0.387     -0.037      0.971      -0.773       0.745
q_length                                      -0.1143      0.371     -0.308      0.758      -0.842       0.614
capabilities_entropy                           0.6528      0.333      1.960      0.050   -4.86e-05       1.306
game_entropy                                   0.7338      0.341      2.154      0.031       0.066       1.401
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing gpt-4o-mini (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/gpt-4o-mini_SimpleMC_redacted_cor_temp1.0_1757988920_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    123
1     49
Name: count, dtype: int64

Answer change%: 0.2849 [0.21742998371300268, 0.3523374581474624] (n=172)
P-value vs 25%: 0.3108; P-value vs 0%: 1.256e-16
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=49)
P-value vs 25%: 0; P-value vs 33%: 0

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  172
Model:                          Logit   Df Residuals:                      170
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.08240
Time:                        09:26:44   Log-Likelihood:                -94.303
converged:                       True   LL-Null:                       -102.77
Covariance Type:            nonrobust   LLR p-value:                 3.866e-05
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          2.0329      0.744      2.731      0.006       0.574       3.492
p_i_capability    -3.7042      0.930     -3.985      0.000      -5.526      -1.882
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  172
Model:                          Logit   Df Residuals:                      170
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.06825
Time:                        09:26:44   Log-Likelihood:                -95.757
converged:                       True   LL-Null:                       -102.77
Covariance Type:            nonrobust   LLR p-value:                 0.0001801
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.7508      0.308     -5.694      0.000      -2.354      -1.148
capabilities_entropy     1.1790      0.326      3.613      0.000       0.539       1.818
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.7708 [0.6519, 0.8897] (n=48)
                  P-value vs 33.3%: 5.522e-13

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=-1.42, p=0.158
Wilcoxon delta_p: statistic=2101.00, p=0.0143
Mean Δp = -0.0238  [-0.0567, 0.0091]
Idea 1 N = 108; 

  Idea 1.5: Calibration Metrics
  NLL: 0.2512, Signed ECE (overconf pos under neg): -0.1967, ECE: 0.1967 (n=156)
  Brier: 0.0737, Reliability (absolute calibration error; lower better): 0.0729, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=156)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.823
Model:                            OLS   Adj. R-squared:                  0.819
Method:                 Least Squares   F-statistic:                     235.1
Date:                Sat, 20 Sep 2025   Prob (F-statistic):           7.10e-57
Time:                        09:26:44   Log-Likelihood:                 85.251
No. Observations:                 156   AIC:                            -162.5
Df Residuals:                     152   BIC:                            -150.3
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.5377      0.070     -7.657      0.000      -0.676      -0.399
p1                    0.6120      0.082      7.461      0.000       0.450       0.774
answer_changed        0.4670      0.103      4.536      0.000       0.264       0.670
p1:answer_changed     0.2696      0.130      2.079      0.039       0.013       0.526
==============================================================================
Omnibus:                       15.037   Durbin-Watson:                   2.195
Prob(Omnibus):                  0.001   Jarque-Bera (JB):               16.474
Skew:                           0.716   Prob(JB):                     0.000265
Kurtosis:                       3.694   Cond. No.                         21.6
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=2.03, p=0.0446
Wilcoxon delta_H: statistic=2263.00, p=0.0371
Mean ΔH = 0.0895  [0.0032, 0.1758]
Paired t-test delta_H Changed: statistic=4.50, p=4.47e-05
Wilcoxon delta_H Changed: statistic=175.00, p=7.36e-06
Mean ΔH Changed = 0.2965  [0.1673, 0.4257]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=3.09, p=0.00236
Wilcoxon (p_top2_game vs p_top2_base): statistic=3773.00, p=3.21e-05
Mean Δp_top2 = 0.0191  [0.0070, 0.0311] (n=156)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=4.11, p=6.45e-05
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=3866.00, p=6.51e-05
Mean ΔH_unchosen_baseline_set = 0.1532  [0.0801, 0.2263] (n=156)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  156
Model:                          Logit   Df Residuals:                      153
Method:                           MLE   Df Model:                            2
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.07056
Time:                        09:26:44   Log-Likelihood:                -89.495
converged:                       True   LL-Null:                       -96.290
Covariance Type:            nonrobust   LLR p-value:                  0.001120
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.0118      0.266     -3.799      0.000      -1.534      -0.490
p1_z            -0.5266      0.228     -2.307      0.021      -0.974      -0.079
I(p1_z ** 2)     0.1441      0.204      0.707      0.480      -0.255       0.544
================================================================================
AUC = 0.679

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  172
Model:                          Logit   Df Residuals:                      170
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.09737
Time:                        09:26:44   Log-Likelihood:                -92.764
converged:                       True   LL-Null:                       -102.77
Covariance Type:            nonrobust   LLR p-value:                 7.685e-06
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.9327      0.320     -6.042      0.000      -2.560      -1.306
game_entropy     1.5997      0.378      4.235      0.000       0.859       2.340
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=5447.00, p=0.00462
Paired t-test (game_entropy vs capabilities_entropy): statistic=-1.81, p=0.0722
Mean capabilities_entropy-game_entropy = 0.0748  [-0.0062, 0.1557] (n=172)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  172
Model:                          Logit   Df Residuals:                      169
Method:                           MLE   Df Model:                            2
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1184
Time:                        09:26:44   Log-Likelihood:                -90.607
converged:                       True   LL-Null:                       -102.77
Covariance Type:            nonrobust   LLR p-value:                 5.215e-06
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.2679      0.377     -6.011      0.000      -3.007      -1.528
capabilities_entropy     0.7330      0.356      2.060      0.039       0.036       1.431
game_entropy             1.3033      0.412      3.162      0.002       0.495       2.111
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.705882
                        1                 0.294118
Geography               0                 0.692308
                        1                 0.307692
Misc                    0                 0.652174
                        1                 0.347826
Music                   0                 0.666667
                        1                 0.333333
Other                   0                 1.000000
Politics                0                 0.703704
                        1                 0.296296
Science and technology  0                 0.696970
                        1                 0.303030
Sports                  0                 0.615385
                        1                 0.384615
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.609756
                     1                 0.390244
Number               0                 0.800000
                     1                 0.200000
Other                0                 0.740741
                     1                 0.259259
Person               0                 0.723404
                     1                 0.276596
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.500000  0.500000            6
                       Number               0.666667  0.333333            6
                       Other                0.857143  0.142857            7
                       Person               0.733333  0.266667           15
Geography              Date                 0.000000  1.000000            1
                       Number               0.750000  0.250000            8
                       Other                0.750000  0.250000            4
Misc                   Date                 0.666667  0.333333            6
                       Number               0.666667  0.333333            3
                       Other                0.666667  0.333333            9
                       Person               0.600000  0.400000            5
Music                  Date                 0.666667  0.333333            3
                       Number               1.000000  0.000000            1
                       Other                0.500000  0.500000            4
                       Person               0.750000  0.250000            4
Other                  Date                 1.000000  0.000000            4
                       Number               1.000000  0.000000            2
                       Other                1.000000  0.000000            5
                       Person               1.000000  0.000000            6
Politics               Date                 0.625000  0.375000            8
                       Number               1.000000  0.000000            1
                       Other                0.692308  0.307692           13
                       Person               0.800000  0.200000            5
Science and technology Date                 0.583333  0.416667           12
                       Number               0.833333  0.166667            6
                       Other                0.875000  0.125000            8
                       Person               0.571429  0.428571            7
Sports                 Date                 0.000000  1.000000            1
                       Number               1.000000  0.000000            3
                       Other                0.500000  0.500000            4
                       Person               0.600000  0.400000            5

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  172
Model:                          Logit   Df Residuals:                      160
Method:                           MLE   Df Model:                           11
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.08478
Time:                        09:26:44   Log-Likelihood:                -94.059
converged:                      False   LL-Null:                       -102.77
Covariance Type:            nonrobust   LLR p-value:                   0.09592
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      0.8100      2.458      0.330      0.742      -4.008       5.628
C(topic_grouped)[T.Geography]                  0.4240      0.772      0.549      0.583      -1.089       1.936
C(topic_grouped)[T.Misc]                       0.2123      0.596      0.356      0.722      -0.956       1.380
C(topic_grouped)[T.Music]                      0.1122      0.731      0.153      0.878      -1.321       1.545
C(topic_grouped)[T.Other]                    -37.3479   4.67e+07  -7.99e-07      1.000   -9.16e+07    9.16e+07
C(topic_grouped)[T.Politics]                  -0.0744      0.592     -0.126      0.900      -1.235       1.086
C(topic_grouped)[T.Science and technology]    -0.0283      0.560     -0.050      0.960      -1.126       1.069
C(topic_grouped)[T.Sports]                     0.4745      0.705      0.673      0.501      -0.908       1.857
C(answer_type_grouped)[T.Number]              -1.1422      0.629     -1.816      0.069      -2.375       0.090
C(answer_type_grouped)[T.Other]               -0.7041      0.470     -1.498      0.134      -1.625       0.217
C(answer_type_grouped)[T.Person]              -0.5386      0.492     -1.095      0.274      -1.503       0.426
q_length                                      -0.2521      0.547     -0.461      0.645      -1.324       0.820
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.6319
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  172
Model:                          Logit   Df Residuals:                      159
Method:                           MLE   Df Model:                           12
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1630
Time:                        09:26:44   Log-Likelihood:                -86.019
converged:                      False   LL-Null:                       -102.77
Covariance Type:            nonrobust   LLR p-value:                 0.0008073
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.5018      2.696     -0.557      0.578      -6.786       3.782
C(topic_grouped)[T.Geography]                  0.3773      0.818      0.461      0.645      -1.226       1.980
C(topic_grouped)[T.Misc]                       0.2679      0.628      0.426      0.670      -0.963       1.499
C(topic_grouped)[T.Music]                     -0.0710      0.778     -0.091      0.927      -1.596       1.454
C(topic_grouped)[T.Other]                    -25.2245   9.19e+04     -0.000      1.000    -1.8e+05     1.8e+05
C(topic_grouped)[T.Politics]                  -0.2461      0.631     -0.390      0.696      -1.483       0.990
C(topic_grouped)[T.Science and technology]    -0.1287      0.588     -0.219      0.827      -1.281       1.024
C(topic_grouped)[T.Sports]                     0.6527      0.738      0.884      0.377      -0.795       2.100
C(answer_type_grouped)[T.Number]              -1.2017      0.666     -1.804      0.071      -2.507       0.104
C(answer_type_grouped)[T.Other]               -0.1224      0.522     -0.235      0.815      -1.145       0.900
C(answer_type_grouped)[T.Person]               0.2203      0.551      0.400      0.689      -0.859       1.300
q_length                                      -0.0405      0.582     -0.070      0.945      -1.181       1.100
capabilities_entropy                           1.4837      0.390      3.804      0.000       0.719       2.248
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  172
Model:                          Logit   Df Residuals:                      159
Method:                           MLE   Df Model:                           12
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.2021
Time:                        09:26:44   Log-Likelihood:                -82.001
converged:                      False   LL-Null:                       -102.77
Covariance Type:            nonrobust   LLR p-value:                 3.979e-05
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      0.3014      2.699      0.112      0.911      -4.989       5.592
C(topic_grouped)[T.Geography]                  0.3825      0.846      0.452      0.651      -1.276       2.041
C(topic_grouped)[T.Misc]                       0.3811      0.668      0.571      0.568      -0.928       1.690
C(topic_grouped)[T.Music]                      0.0142      0.810      0.017      0.986      -1.574       1.602
C(topic_grouped)[T.Other]                    -22.9733   3.07e+04     -0.001      0.999   -6.02e+04    6.01e+04
C(topic_grouped)[T.Politics]                   0.3954      0.652      0.606      0.544      -0.883       1.673
C(topic_grouped)[T.Science and technology]     0.2601      0.605      0.430      0.667      -0.925       1.445
C(topic_grouped)[T.Sports]                     0.6408      0.794      0.807      0.419      -0.915       2.196
C(answer_type_grouped)[T.Number]              -1.3988      0.680     -2.058      0.040      -2.731      -0.066
C(answer_type_grouped)[T.Other]               -0.6054      0.524     -1.156      0.248      -1.632       0.421
C(answer_type_grouped)[T.Person]              -0.0327      0.543     -0.060      0.952      -1.097       1.031
q_length                                      -0.4809      0.598     -0.804      0.421      -1.653       0.692
game_entropy                                   1.9926      0.440      4.527      0.000       1.130       2.855
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  172
Model:                          Logit   Df Residuals:                      158
Method:                           MLE   Df Model:                           13
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.2315
Time:                        09:26:44   Log-Likelihood:                -78.975
converged:                      False   LL-Null:                       -102.77
Covariance Type:            nonrobust   LLR p-value:                 7.672e-06
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.1764      2.861     -0.411      0.681      -6.784       4.432
C(topic_grouped)[T.Geography]                  0.3903      0.876      0.445      0.656      -1.327       2.108
C(topic_grouped)[T.Misc]                       0.4042      0.668      0.605      0.545      -0.906       1.714
C(topic_grouped)[T.Music]                     -0.1266      0.835     -0.152      0.880      -1.764       1.511
C(topic_grouped)[T.Other]                    -23.8897   3.93e+04     -0.001      1.000    -7.7e+04    7.69e+04
C(topic_grouped)[T.Politics]                   0.2155      0.675      0.319      0.749      -1.107       1.538
C(topic_grouped)[T.Science and technology]     0.1663      0.622      0.267      0.789      -1.053       1.385
C(topic_grouped)[T.Sports]                     0.7556      0.808      0.935      0.350      -0.828       2.340
C(answer_type_grouped)[T.Number]              -1.3638      0.690     -1.975      0.048      -2.717      -0.011
C(answer_type_grouped)[T.Other]               -0.2420      0.555     -0.436      0.663      -1.329       0.845
C(answer_type_grouped)[T.Person]               0.4184      0.582      0.718      0.472      -0.723       1.560
q_length                                      -0.3110      0.621     -0.501      0.616      -1.528       0.906
capabilities_entropy                           1.0077      0.418      2.410      0.016       0.188       1.827
game_entropy                                   1.6916      0.469      3.605      0.000       0.772       2.611
==============================================================================================================

                  Model 6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length (after removing deterministic categories: defaultdict(<class 'list'>, {'topic_grouped': ['Other']}))
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  155
Model:                          Logit   Df Residuals:                      144
Method:                           MLE   Df Model:                           10
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.02739
Time:                        09:26:44   Log-Likelihood:                -94.059
converged:                       True   LL-Null:                       -96.707
Covariance Type:            nonrobust   LLR p-value:                    0.8705
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      0.8100      2.458      0.330      0.742      -4.008       5.628
C(topic_grouped)[T.Geography]                  0.4240      0.772      0.549      0.583      -1.089       1.936
C(topic_grouped)[T.Misc]                       0.2123      0.596      0.356      0.722      -0.956       1.380
C(topic_grouped)[T.Music]                      0.1122      0.731      0.153      0.878      -1.321       1.545
C(topic_grouped)[T.Politics]                  -0.0744      0.592     -0.126      0.900      -1.235       1.086
C(topic_grouped)[T.Science and technology]    -0.0283      0.560     -0.050      0.960      -1.126       1.069
C(topic_grouped)[T.Sports]                     0.4745      0.705      0.673      0.501      -0.908       1.857
C(answer_type_grouped)[T.Number]              -1.1422      0.629     -1.816      0.069      -2.375       0.090
C(answer_type_grouped)[T.Other]               -0.7041      0.470     -1.498      0.134      -1.625       0.217
C(answer_type_grouped)[T.Person]              -0.5386      0.492     -1.095      0.274      -1.503       0.426
q_length                                      -0.2521      0.547     -0.461      0.645      -1.324       0.820
==============================================================================================================

                  Model 6.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  155
Model:                          Logit   Df Residuals:                      143
Method:                           MLE   Df Model:                           11
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1105
Time:                        09:26:44   Log-Likelihood:                -86.019
converged:                       True   LL-Null:                       -96.707
Covariance Type:            nonrobust   LLR p-value:                   0.02968
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.5018      2.696     -0.557      0.578      -6.786       3.782
C(topic_grouped)[T.Geography]                  0.3773      0.818      0.461      0.645      -1.226       1.980
C(topic_grouped)[T.Misc]                       0.2679      0.628      0.426      0.670      -0.963       1.499
C(topic_grouped)[T.Music]                     -0.0710      0.778     -0.091      0.927      -1.596       1.454
C(topic_grouped)[T.Politics]                  -0.2461      0.631     -0.390      0.696      -1.483       0.990
C(topic_grouped)[T.Science and technology]    -0.1287      0.588     -0.219      0.827      -1.281       1.024
C(topic_grouped)[T.Sports]                     0.6527      0.738      0.884      0.377      -0.795       2.100
C(answer_type_grouped)[T.Number]              -1.2017      0.666     -1.804      0.071      -2.507       0.104
C(answer_type_grouped)[T.Other]               -0.1224      0.522     -0.235      0.815      -1.145       0.900
C(answer_type_grouped)[T.Person]               0.2203      0.551      0.400      0.689      -0.859       1.300
q_length                                      -0.0405      0.582     -0.070      0.945      -1.181       1.100
capabilities_entropy                           1.4837      0.390      3.804      0.000       0.719       2.248
==============================================================================================================

--- Analyzing gpt-4o-mini (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/gpt-4o-mini_SimpleMC_redacted_temp1.0_1757987946_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    205
1    123
Name: count, dtype: int64

Answer change%: 0.3750 [0.3226077787174928, 0.4273922212825072] (n=328)
P-value vs 25%: 2.923e-06; P-value vs 0%: 1.043e-44
Phase 2 self-accuracy: 0.4309 [0.3433803403607629, 0.518408277525416] (n=123)
P-value vs 25%: 5.093e-05; P-value vs 33%: 0.02835

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  328
Model:                          Logit   Df Residuals:                      326
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.05561
Time:                        09:26:44   Log-Likelihood:                -204.93
converged:                       True   LL-Null:                       -216.99
Covariance Type:            nonrobust   LLR p-value:                 8.989e-07
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          1.8529      0.503      3.686      0.000       0.868       2.838
p_i_capability    -2.9866      0.624     -4.788      0.000      -4.209      -1.764
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  328
Model:                          Logit   Df Residuals:                      326
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.06291
Time:                        09:26:44   Log-Likelihood:                -203.34
converged:                       True   LL-Null:                       -216.99
Covariance Type:            nonrobust   LLR p-value:                 1.739e-07
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.3293      0.208     -6.396      0.000      -1.737      -0.922
capabilities_entropy     1.1319      0.225      5.035      0.000       0.691       1.573
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.7167 [0.6360, 0.7973] (n=120)
                  P-value vs 33.3%: 1.177e-20

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=-1.57, p=0.119
Wilcoxon delta_p: statistic=7210.00, p=0.0331
Mean Δp = -0.0232  [-0.0522, 0.0058]
Idea 1 N = 187; 

  Idea 1.5: Calibration Metrics
  NLL: 4.8281, Signed ECE (overconf pos under neg): 0.0872, ECE: 0.0872 (n=307)
  Brier: 0.0231, Reliability (absolute calibration error; lower better): 0.0224, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=307)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.850
Model:                            OLS   Adj. R-squared:                  0.848
Method:                 Least Squares   F-statistic:                     570.5
Date:                Sat, 20 Sep 2025   Prob (F-statistic):          2.89e-124
Time:                        09:26:44   Log-Likelihood:                 153.59
No. Observations:                 307   AIC:                            -299.2
Df Residuals:                     303   BIC:                            -284.3
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.6121      0.052    -11.786      0.000      -0.714      -0.510
p1                    0.7121      0.061     11.593      0.000       0.591       0.833
answer_changed        0.5234      0.074      7.082      0.000       0.378       0.669
p1:answer_changed     0.2586      0.093      2.784      0.006       0.076       0.441
==============================================================================
Omnibus:                       20.298   Durbin-Watson:                   1.961
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               22.594
Skew:                           0.606   Prob(JB):                     1.24e-05
Kurtosis:                       3.544   Cond. No.                         21.8
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=1.21, p=0.226
Wilcoxon delta_H: statistic=7853.00, p=0.207
Mean ΔH = 0.0453  [-0.0278, 0.1185]
Paired t-test delta_H Changed: statistic=7.16, p=7.23e-11
Wilcoxon delta_H Changed: statistic=1293.00, p=9.34e-10
Mean ΔH Changed = 0.2893  [0.2101, 0.3685]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=2.70, p=0.00726
Wilcoxon (p_top2_game vs p_top2_base): statistic=18411.00, p=0.000783
Mean Δp_top2 = 0.0122  [0.0034, 0.0211] (n=307)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=4.94, p=1.27e-06
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=16048.00, p=1.08e-06
Mean ΔH_unchosen_baseline_set = 0.1407  [0.0849, 0.1965] (n=307)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  307
Model:                          Logit   Df Residuals:                      304
Method:                           MLE   Df Model:                            2
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.04782
Time:                        09:26:44   Log-Likelihood:                -195.60
converged:                       True   LL-Null:                       -205.43
Covariance Type:            nonrobust   LLR p-value:                 5.418e-05
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.4282      0.185     -2.317      0.021      -0.790      -0.066
p1_z            -0.5469      0.144     -3.789      0.000      -0.830      -0.264
I(p1_z ** 2)    -0.0420      0.146     -0.287      0.774      -0.329       0.245
================================================================================
AUC = 0.644

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  328
Model:                          Logit   Df Residuals:                      326
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.07468
Time:                        09:26:44   Log-Likelihood:                -200.79
converged:                       True   LL-Null:                       -216.99
Covariance Type:            nonrobust   LLR p-value:                 1.248e-08
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.4203      0.212     -6.713      0.000      -1.835      -1.006
game_entropy     1.3941      0.256      5.436      0.000       0.891       1.897
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=22786.00, p=0.0186
Paired t-test (game_entropy vs capabilities_entropy): statistic=-2.07, p=0.0388
Mean capabilities_entropy-game_entropy = 0.0662  [0.0037, 0.1288] (n=328)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  328
Model:                          Logit   Df Residuals:                      325
Method:                           MLE   Df Model:                            2
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1033
Time:                        09:26:44   Log-Likelihood:                -194.57
converged:                       True   LL-Null:                       -216.99
Covariance Type:            nonrobust   LLR p-value:                 1.824e-10
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.8473      0.257     -7.175      0.000      -2.352      -1.343
capabilities_entropy     0.8330      0.239      3.481      0.001       0.364       1.302
game_entropy             1.1148      0.271      4.113      0.000       0.584       1.646
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': None
topic_grouped           answer_changed
Art                     0                 0.658537
                        1                 0.341463
Geography               0                 0.580645
                        1                 0.419355
Misc                    0                 0.686275
                        1                 0.313725
Music                   0                 0.714286
                        1                 0.285714
Other                   0                 0.542857
                        1                 0.457143
Politics                0                 0.520000
                        1                 0.480000
Science and technology  0                 0.646154
                        1                 0.353846
Sports                  0                 0.666667
                        1                 0.333333
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.515625
                     1                 0.484375
Number               0                 0.625000
                     1                 0.375000
Other                0                 0.745455
                     1                 0.254545
Person               0                 0.726027
                     1                 0.273973
Place                0                 0.625000
                     1                 0.375000
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.600000  0.400000           15
                       Number               0.666667  0.333333            3
                       Other                0.857143  0.142857            7
                       Person               0.666667  0.333333           12
                       Place                0.500000  0.500000            4
Geography              Date                 0.500000  0.500000           14
                       Number               0.700000  0.300000           10
                       Place                0.571429  0.428571            7
Misc                   Date                 0.647059  0.352941           17
                       Number               0.833333  0.166667            6
                       Other                0.705882  0.294118           17
                       Person               0.600000  0.400000           10
                       Place                1.000000  0.000000            1
Music                  Date                 0.666667  0.333333            9
                       Number               0.666667  0.333333            3
                       Other                0.666667  0.333333            6
                       Person               0.750000  0.250000            8
                       Place                1.000000  0.000000            2
Other                  Date                 0.357143  0.642857           14
                       Number               0.800000  0.200000            5
                       Other                0.666667  0.333333            6
                       Person               0.714286  0.285714            7
                       Place                0.333333  0.666667            3
Politics               Date                 0.392857  0.607143           28
                       Number               0.400000  0.600000            5
                       Other                0.750000  0.250000            4
                       Person               0.800000  0.200000           10
                       Place                0.666667  0.333333            3
Science and technology Date                 0.565217  0.434783           23
                       Number               0.500000  0.500000            8
                       Other                0.750000  0.250000            8
                       Person               0.739130  0.260870           23
                       Place                0.666667  0.333333            3
Sports                 Date                 0.500000  0.500000            8
                       Number               0.500000  0.500000            8
                       Other                0.857143  0.142857            7
                       Person               1.000000  0.000000            3
                       Place                1.000000  0.000000            1

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  328
Model:                          Logit   Df Residuals:                      315
Method:                           MLE   Df Model:                           12
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.04148
Time:                        09:26:44   Log-Likelihood:                -207.99
converged:                       True   LL-Null:                       -216.99
Covariance Type:            nonrobust   LLR p-value:                    0.1157
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.7996      1.444     -1.246      0.213      -4.630       1.030
C(topic_grouped)[T.Geography]                  0.1387      0.514      0.270      0.787      -0.869       1.146
C(topic_grouped)[T.Misc]                      -0.0966      0.460     -0.210      0.834      -0.999       0.806
C(topic_grouped)[T.Music]                     -0.2136      0.543     -0.393      0.694      -1.278       0.851
C(topic_grouped)[T.Other]                      0.4733      0.484      0.978      0.328      -0.475       1.422
C(topic_grouped)[T.Politics]                   0.3216      0.455      0.707      0.480      -0.570       1.213
C(topic_grouped)[T.Science and technology]     0.0346      0.430      0.081      0.936      -0.808       0.878
C(topic_grouped)[T.Sports]                    -0.0843      0.543     -0.155      0.877      -1.148       0.979
C(answer_type_grouped)[T.Number]              -0.4015      0.356     -1.128      0.259      -1.099       0.296
C(answer_type_grouped)[T.Other]               -0.8859      0.369     -2.398      0.016      -1.610      -0.162
C(answer_type_grouped)[T.Person]              -0.8227      0.327     -2.516      0.012      -1.464      -0.182
C(answer_type_grouped)[T.Place]               -0.4410      0.470     -0.939      0.348      -1.361       0.480
q_length                                       0.3545      0.309      1.146      0.252      -0.252       0.961
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.6848
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  328
Model:                          Logit   Df Residuals:                      314
Method:                           MLE   Df Model:                           13
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.09159
Time:                        09:26:44   Log-Likelihood:                -197.12
converged:                       True   LL-Null:                       -216.99
Covariance Type:            nonrobust   LLR p-value:                 0.0001518
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -2.0314      1.488     -1.365      0.172      -4.948       0.885
C(topic_grouped)[T.Geography]                  0.0801      0.538      0.149      0.882      -0.974       1.134
C(topic_grouped)[T.Misc]                      -0.2003      0.480     -0.417      0.677      -1.142       0.741
C(topic_grouped)[T.Music]                     -0.3376      0.569     -0.594      0.553      -1.452       0.777
C(topic_grouped)[T.Other]                      0.3138      0.508      0.617      0.537      -0.683       1.310
C(topic_grouped)[T.Politics]                   0.2355      0.475      0.496      0.620      -0.695       1.166
C(topic_grouped)[T.Science and technology]    -0.0080      0.447     -0.018      0.986      -0.884       0.868
C(topic_grouped)[T.Sports]                    -0.2049      0.561     -0.365      0.715      -1.305       0.895
C(answer_type_grouped)[T.Number]              -0.4694      0.368     -1.274      0.203      -1.192       0.253
C(answer_type_grouped)[T.Other]               -0.5814      0.385     -1.512      0.131      -1.335       0.172
C(answer_type_grouped)[T.Person]              -0.8064      0.340     -2.373      0.018      -1.472      -0.140
C(answer_type_grouped)[T.Place]               -0.2712      0.494     -0.549      0.583      -1.240       0.697
q_length                                       0.2415      0.319      0.758      0.448      -0.383       0.866
capabilities_entropy                           1.0676      0.236      4.522      0.000       0.605       1.530
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  328
Model:                          Logit   Df Residuals:                      314
Method:                           MLE   Df Model:                           13
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.09723
Time:                        09:26:44   Log-Likelihood:                -195.90
converged:                       True   LL-Null:                       -216.99
Covariance Type:            nonrobust   LLR p-value:                 6.084e-05
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -2.0889      1.498     -1.394      0.163      -5.025       0.847
C(topic_grouped)[T.Geography]                 -0.0648      0.538     -0.120      0.904      -1.119       0.990
C(topic_grouped)[T.Misc]                       0.0099      0.475      0.021      0.983      -0.921       0.940
C(topic_grouped)[T.Music]                     -0.2129      0.561     -0.380      0.704      -1.312       0.886
C(topic_grouped)[T.Other]                      0.4534      0.502      0.902      0.367      -0.531       1.438
C(topic_grouped)[T.Politics]                   0.3198      0.471      0.679      0.497      -0.603       1.243
C(topic_grouped)[T.Science and technology]     0.1482      0.447      0.332      0.740      -0.727       1.023
C(topic_grouped)[T.Sports]                     0.0736      0.567      0.130      0.897      -1.037       1.184
C(answer_type_grouped)[T.Number]              -0.3818      0.371     -1.029      0.303      -1.109       0.345
C(answer_type_grouped)[T.Other]               -0.5619      0.387     -1.453      0.146      -1.320       0.196
C(answer_type_grouped)[T.Person]              -0.7182      0.341     -2.109      0.035      -1.386      -0.051
C(answer_type_grouped)[T.Place]               -0.1430      0.498     -0.287      0.774      -1.118       0.832
q_length                                       0.2044      0.321      0.637      0.524      -0.424       0.833
game_entropy                                   1.2857      0.270      4.762      0.000       0.757       1.815
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  328
Model:                          Logit   Df Residuals:                      313
Method:                           MLE   Df Model:                           14
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1232
Time:                        09:26:44   Log-Likelihood:                -190.26
converged:                       True   LL-Null:                       -216.99
Covariance Type:            nonrobust   LLR p-value:                 1.587e-06
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -2.2009      1.520     -1.448      0.148      -5.180       0.778
C(topic_grouped)[T.Geography]                 -0.0708      0.547     -0.129      0.897      -1.143       1.001
C(topic_grouped)[T.Misc]                      -0.0743      0.488     -0.152      0.879      -1.030       0.881
C(topic_grouped)[T.Music]                     -0.3151      0.582     -0.541      0.588      -1.456       0.826
C(topic_grouped)[T.Other]                      0.3329      0.522      0.638      0.524      -0.690       1.356
C(topic_grouped)[T.Politics]                   0.2580      0.484      0.533      0.594      -0.690       1.206
C(topic_grouped)[T.Science and technology]     0.0892      0.460      0.194      0.846      -0.813       0.992
C(topic_grouped)[T.Sports]                    -0.0449      0.581     -0.077      0.938      -1.183       1.094
C(answer_type_grouped)[T.Number]              -0.4341      0.374     -1.159      0.246      -1.168       0.300
C(answer_type_grouped)[T.Other]               -0.4038      0.396     -1.020      0.308      -1.180       0.372
C(answer_type_grouped)[T.Person]              -0.7402      0.349     -2.121      0.034      -1.424      -0.056
C(answer_type_grouped)[T.Place]               -0.0808      0.514     -0.157      0.875      -1.088       0.926
q_length                                       0.1439      0.325      0.442      0.658      -0.494       0.781
capabilities_entropy                           0.8213      0.248      3.311      0.001       0.335       1.307
game_entropy                                   1.0340      0.283      3.651      0.000       0.479       1.589
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing grok-3-latest (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/grok-3-latest_SimpleMC_redacted_cor_temp0.0_1751718904_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    239
1     56
Name: count, dtype: int64

Answer change%: 0.1898 [0.1450789637260746, 0.23458205322307796] (n=295)
P-value vs 25%: 0.008408; P-value vs 0%: 9.259e-17
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=56)
P-value vs 25%: 0; P-value vs 33%: 0

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  295
Model:                          Logit   Df Residuals:                      293
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.04532
Time:                        09:26:44   Log-Likelihood:                -136.87
converged:                       True   LL-Null:                       -143.36
Covariance Type:            nonrobust   LLR p-value:                 0.0003122
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          1.0602      0.709      1.495      0.135      -0.330       2.450
p_i_capability    -2.8200      0.790     -3.568      0.000      -4.369      -1.271
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  295
Model:                          Logit   Df Residuals:                      293
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1139
Time:                        09:26:44   Log-Likelihood:                -127.04
converged:                       True   LL-Null:                       -143.36
Covariance Type:            nonrobust   LLR p-value:                 1.105e-08
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.1461      0.217     -9.868      0.000      -2.572      -1.720
capabilities_entropy     1.8634      0.335      5.563      0.000       1.207       2.520
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.6071 [0.4792, 0.7351] (n=56)
                  P-value vs 33.3%: 2.723e-05

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=2.25, p=0.0251
Wilcoxon delta_p: statistic=8867.00, p=1.1e-06
Mean Δp = 0.0216  [0.0028, 0.0403]
Idea 1 N = 236; 

  Idea 1.5: Calibration Metrics
  NLL: 0.0975, Signed ECE (overconf pos under neg): -0.0791, ECE: 0.0791 (n=292)
  Brier: 0.0258, Reliability (absolute calibration error; lower better): 0.0253, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=292)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.809
Model:                            OLS   Adj. R-squared:                  0.807
Method:                 Least Squares   F-statistic:                     405.3
Date:                Sat, 20 Sep 2025   Prob (F-statistic):          5.22e-103
Time:                        09:26:44   Log-Likelihood:                 188.02
No. Observations:                 292   AIC:                            -368.0
Df Residuals:                     288   BIC:                            -353.3
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.5177      0.065     -8.004      0.000      -0.645      -0.390
p1                    0.5725      0.068      8.408      0.000       0.438       0.707
answer_changed        0.5053      0.107      4.729      0.000       0.295       0.716
p1:answer_changed     0.2204      0.121      1.820      0.070      -0.018       0.459
==============================================================================
Omnibus:                      113.981   Durbin-Watson:                   2.070
Prob(Omnibus):                  0.000   Jarque-Bera (JB):              366.918
Skew:                           1.740   Prob(JB):                     2.11e-80
Kurtosis:                       7.248   Cond. No.                         31.8
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-6.47, p=5.52e-10
Wilcoxon delta_H: statistic=7546.00, p=8.74e-10
Mean ΔH = -0.2331  [-0.3037, -0.1625]
Paired t-test delta_H Changed: statistic=0.20, p=0.844
Wilcoxon delta_H Changed: statistic=760.00, p=0.757
Mean ΔH Changed = 0.0133  [-0.1180, 0.1446]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=-4.70, p=3.94e-06
Wilcoxon (p_top2_game vs p_top2_base): statistic=6853.00, p=7.83e-24
Mean Δp_top2 = -0.0171  [-0.0242, -0.0100] (n=292)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=-5.76, p=2.14e-08
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=13389.00, p=3.03e-08
Mean ΔH_unchosen_baseline_set = -0.1858  [-0.2491, -0.1226] (n=292)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  292
Model:                          Logit   Df Residuals:                      289
Method:                           MLE   Df Model:                            2
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1172
Time:                        09:26:44   Log-Likelihood:                -126.00
converged:                       True   LL-Null:                       -142.73
Covariance Type:            nonrobust   LLR p-value:                 5.414e-08
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.2012      0.196     -6.131      0.000      -1.585      -0.817
p1_z            -1.5249      0.314     -4.855      0.000      -2.141      -0.909
I(p1_z ** 2)    -0.4255      0.137     -3.108      0.002      -0.694      -0.157
================================================================================
AUC = 0.777

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  295
Model:                          Logit   Df Residuals:                      293
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.2834
Time:                        09:26:44   Log-Likelihood:                -102.73
converged:                       True   LL-Null:                       -143.36
Covariance Type:            nonrobust   LLR p-value:                 1.976e-19
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -3.2033      0.333     -9.614      0.000      -3.856      -2.550
game_entropy     2.7416      0.353      7.761      0.000       2.049       3.434
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=11281.00, p=6.3e-13
Paired t-test (game_entropy vs capabilities_entropy): statistic=5.81, p=1.6e-08
Mean capabilities_entropy-game_entropy = -0.1619  [-0.2165, -0.1073] (n=295)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  295
Model:                          Logit   Df Residuals:                      292
Method:                           MLE   Df Model:                            2
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.3008
Time:                        09:26:44   Log-Likelihood:                -100.24
converged:                       True   LL-Null:                       -143.36
Covariance Type:            nonrobust   LLR p-value:                 1.878e-19
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -3.3861      0.356     -9.510      0.000      -4.084      -2.688
capabilities_entropy     0.9021      0.402      2.243      0.025       0.114       1.690
game_entropy             2.4695      0.372      6.646      0.000       1.741       3.198
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['Other', 'Sports', 'Music', 'Geography', 'History', 'TV shows', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.875000
                        1                 0.125000
Misc                    0                 0.768212
                        1                 0.231788
Politics                0                 0.833333
                        1                 0.166667
Science and technology  0                 0.854167
                        1                 0.145833
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.811881
                     1                 0.188119
Number               0                 0.700000
                     1                 0.300000
Other                0                 0.857143
                     1                 0.142857
Person               0                 0.809524
                     1                 0.190476
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.714286  0.285714           14
                       Number               1.000000  0.000000            5
                       Other                0.923077  0.076923           13
                       Person               0.937500  0.062500           16
Misc                   Date                 0.782609  0.217391           46
                       Number               0.692308  0.307692           26
                       Other                0.803922  0.196078           51
                       Person               0.750000  0.250000           28
Politics               Date                 0.900000  0.100000           20
                       Number               0.500000  0.500000            4
                       Other                0.923077  0.076923           13
                       Person               0.727273  0.272727           11
Science and technology Date                 0.857143  0.142857           21
                       Number               0.600000  0.400000            5
                       Other                0.928571  0.071429           14
                       Person               0.875000  0.125000            8

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  295
Model:                          Logit   Df Residuals:                      287
Method:                           MLE   Df Model:                            7
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.02877
Time:                        09:26:44   Log-Likelihood:                -139.24
converged:                       True   LL-Null:                       -143.36
Covariance Type:            nonrobust   LLR p-value:                    0.3111
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -3.1743      1.971     -1.611      0.107      -7.037       0.689
C(topic_grouped)[T.Misc]                       0.7405      0.484      1.531      0.126      -0.208       1.689
C(topic_grouped)[T.Politics]                   0.2887      0.599      0.482      0.630      -0.886       1.463
C(topic_grouped)[T.Science and technology]     0.1590      0.608      0.262      0.794      -1.032       1.350
C(answer_type_grouped)[T.Number]               0.5048      0.438      1.153      0.249      -0.353       1.363
C(answer_type_grouped)[T.Other]               -0.3776      0.397     -0.951      0.342      -1.156       0.401
C(answer_type_grouped)[T.Person]               0.0321      0.416      0.077      0.939      -0.783       0.848
q_length                                       0.2799      0.431      0.649      0.516      -0.565       1.125
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.2838
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  295
Model:                          Logit   Df Residuals:                      286
Method:                           MLE   Df Model:                            8
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1426
Time:                        09:26:44   Log-Likelihood:                -122.92
converged:                       True   LL-Null:                       -143.36
Covariance Type:            nonrobust   LLR p-value:                 2.181e-06
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -4.7818      2.136     -2.239      0.025      -8.968      -0.595
C(topic_grouped)[T.Misc]                       0.4999      0.518      0.966      0.334      -0.515       1.515
C(topic_grouped)[T.Politics]                   0.2532      0.630      0.402      0.688      -0.981       1.487
C(topic_grouped)[T.Science and technology]    -0.0525      0.641     -0.082      0.935      -1.309       1.204
C(answer_type_grouped)[T.Number]               0.2995      0.465      0.644      0.520      -0.612       1.211
C(answer_type_grouped)[T.Other]               -0.7288      0.439     -1.660      0.097      -1.589       0.132
C(answer_type_grouped)[T.Person]              -0.1966      0.447     -0.440      0.660      -1.072       0.679
q_length                                       0.5509      0.463      1.189      0.235      -0.357       1.459
capabilities_entropy                           1.9587      0.356      5.500      0.000       1.261       2.657
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  295
Model:                          Logit   Df Residuals:                      286
Method:                           MLE   Df Model:                            8
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.2974
Time:                        09:26:44   Log-Likelihood:                -100.72
converged:                       True   LL-Null:                       -143.36
Covariance Type:            nonrobust   LLR p-value:                 4.199e-15
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -3.3399      2.382     -1.402      0.161      -8.009       1.329
C(topic_grouped)[T.Misc]                       0.7105      0.572      1.241      0.215      -0.411       1.832
C(topic_grouped)[T.Politics]                   0.7880      0.713      1.106      0.269      -0.609       2.185
C(topic_grouped)[T.Science and technology]     0.4657      0.710      0.656      0.512      -0.927       1.858
C(answer_type_grouped)[T.Number]               0.1932      0.535      0.361      0.718      -0.856       1.242
C(answer_type_grouped)[T.Other]               -0.5559      0.470     -1.183      0.237      -1.477       0.365
C(answer_type_grouped)[T.Person]              -0.2072      0.502     -0.413      0.680      -1.191       0.777
q_length                                      -0.0624      0.525     -0.119      0.905      -1.091       0.966
game_entropy                                   2.7447      0.363      7.564      0.000       2.033       3.456
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  295
Model:                          Logit   Df Residuals:                      285
Method:                           MLE   Df Model:                            9
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.3171
Time:                        09:26:44   Log-Likelihood:                -97.904
converged:                       True   LL-Null:                       -143.36
Covariance Type:            nonrobust   LLR p-value:                 1.065e-15
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -4.2451      2.427     -1.749      0.080      -9.002       0.512
C(topic_grouped)[T.Misc]                       0.5698      0.585      0.974      0.330      -0.576       1.716
C(topic_grouped)[T.Politics]                   0.6826      0.713      0.957      0.339      -0.715       2.080
C(topic_grouped)[T.Science and technology]     0.3120      0.724      0.431      0.667      -1.107       1.731
C(answer_type_grouped)[T.Number]               0.1786      0.535      0.334      0.738      -0.870       1.227
C(answer_type_grouped)[T.Other]               -0.7157      0.491     -1.457      0.145      -1.678       0.247
C(answer_type_grouped)[T.Person]              -0.2755      0.505     -0.546      0.585      -1.265       0.714
q_length                                       0.1328      0.531      0.250      0.803      -0.908       1.174
capabilities_entropy                           0.9953      0.419      2.376      0.018       0.174       1.816
game_entropy                                   2.4412      0.381      6.409      0.000       1.695       3.188
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing grok-3-latest (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/grok-3-latest_SimpleMC_redacted_temp0.0_1751719937_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
1    111
0     94
Name: count, dtype: int64

Answer change%: 0.5415 [0.473254252367988, 0.6096725769003047] (n=205)
P-value vs 25%: 5.518e-17; P-value vs 0%: 1.388e-54
Phase 2 self-accuracy: 0.5405 [0.447831019784466, 0.6332500612966151] (n=111)
P-value vs 25%: 8.134e-10; P-value vs 33%: 1.146e-05

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  205
Model:                          Logit   Df Residuals:                      203
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.05674
Time:                        09:26:44   Log-Likelihood:                -133.37
converged:                       True   LL-Null:                       -141.39
Covariance Type:            nonrobust   LLR p-value:                 6.183e-05
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          3.0605      0.787      3.887      0.000       1.517       4.604
p_i_capability    -3.4778      0.918     -3.787      0.000      -5.278      -1.678
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  205
Model:                          Logit   Df Residuals:                      203
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.05585
Time:                        09:26:44   Log-Likelihood:                -133.49
converged:                       True   LL-Null:                       -141.39
Covariance Type:            nonrobust   LLR p-value:                 7.060e-05
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -0.5727      0.238     -2.407      0.016      -1.039      -0.106
capabilities_entropy     1.2345      0.323      3.818      0.000       0.601       1.868
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.5946 [0.5033, 0.6859] (n=111)
                  P-value vs 33.3%: 2.066e-08

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=4.05, p=0.000107
Wilcoxon delta_p: statistic=1146.00, p=4.18e-05
Mean Δp = 0.0783  [0.0404, 0.1162]
Idea 1 N = 94; 

  Idea 1.5: Calibration Metrics
  NLL: 5.1560, Signed ECE (overconf pos under neg): 0.0779, ECE: 0.0779 (n=205)
  Brier: 0.0196, Reliability (absolute calibration error; lower better): 0.0189, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=205)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.804
Model:                            OLS   Adj. R-squared:                  0.801
Method:                 Least Squares   F-statistic:                     275.5
Date:                Sat, 20 Sep 2025   Prob (F-statistic):           6.27e-71
Time:                        09:26:44   Log-Likelihood:                 90.653
No. Observations:                 205   AIC:                            -173.3
Df Residuals:                     201   BIC:                            -160.0
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.3689      0.096     -3.829      0.000      -0.559      -0.179
p1                    0.5107      0.108      4.709      0.000       0.297       0.725
answer_changed        0.2595      0.117      2.210      0.028       0.028       0.491
p1:answer_changed     0.4590      0.137      3.350      0.001       0.189       0.729
==============================================================================
Omnibus:                       25.083   Durbin-Watson:                   2.070
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               79.040
Skew:                          -0.420   Prob(JB):                     6.86e-18
Kurtosis:                       5.924   Cond. No.                         30.1
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-3.34, p=0.00121
Wilcoxon delta_H: statistic=1381.00, p=0.00132
Mean ΔH = -0.1752  [-0.2780, -0.0723]
Paired t-test delta_H Changed: statistic=0.68, p=0.495
Wilcoxon delta_H Changed: statistic=2839.00, p=0.429
Mean ΔH Changed = 0.0335  [-0.0625, 0.1294]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=-4.61, p=6.98e-06
Wilcoxon (p_top2_game vs p_top2_base): statistic=6151.00, p=2.2e-07
Mean Δp_top2 = -0.0280  [-0.0399, -0.0161] (n=205)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=-1.71, p=0.0895
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=9163.00, p=0.101
Mean ΔH_unchosen_baseline_set = -0.0622  [-0.1336, 0.0093] (n=205)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  205
Model:                          Logit   Df Residuals:                      202
Method:                           MLE   Df Model:                            2
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.06024
Time:                        09:26:44   Log-Likelihood:                -132.87
converged:                       True   LL-Null:                       -141.39
Covariance Type:            nonrobust   LLR p-value:                 0.0001999
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept        0.3526      0.218      1.616      0.106      -0.075       0.780
p1_z            -0.7140      0.196     -3.643      0.000      -1.098      -0.330
I(p1_z ** 2)    -0.1678      0.166     -1.009      0.313      -0.494       0.158
================================================================================
AUC = 0.669

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  205
Model:                          Logit   Df Residuals:                      203
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.02882
Time:                        09:26:44   Log-Likelihood:                -137.31
converged:                       True   LL-Null:                       -141.39
Covariance Type:            nonrobust   LLR p-value:                  0.004308
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.4745      0.268     -1.772      0.076      -0.999       0.050
game_entropy     0.7936      0.283      2.802      0.005       0.238       1.349
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=6854.00, p=1.33e-05
Paired t-test (game_entropy vs capabilities_entropy): statistic=4.93, p=1.66e-06
Mean capabilities_entropy-game_entropy = -0.2027  [-0.2832, -0.1222] (n=205)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  205
Model:                          Logit   Df Residuals:                      202
Method:                           MLE   Df Model:                            2
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.06786
Time:                        09:26:44   Log-Likelihood:                -131.80
converged:                       True   LL-Null:                       -141.39
Covariance Type:            nonrobust   LLR p-value:                 6.814e-05
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -0.9235      0.311     -2.973      0.003      -1.532      -0.315
capabilities_entropy     1.0838      0.335      3.234      0.001       0.427       1.741
game_entropy             0.5462      0.299      1.829      0.067      -0.039       1.131
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['Politics', 'Art', 'Geography', 'Other', 'Music', 'Sports', 'TV shows', 'Video games', 'History']
                  Grouped rare answer_type into 'Misc'/'Other': ['Number', 'Other', 'Place']
topic_grouped           answer_changed
Misc                    1                 0.535484
                        0                 0.464516
Science and technology  1                 0.560000
                        0                 0.440000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.500000
                     1                 0.500000
Misc                 1                 0.662500
                     0                 0.337500
Person               0                 0.578947
                     1                 0.421053
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Misc                   Date                 0.574074  0.425926           54
                       Misc                 0.348485  0.651515           66
                       Person               0.514286  0.485714           35
Science and technology Date                 0.214286  0.785714           14
                       Misc                 0.285714  0.714286           14
                       Person               0.681818  0.318182           22

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  205
Model:                          Logit   Df Residuals:                      200
Method:                           MLE   Df Model:                            4
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.03537
Time:                        09:26:44   Log-Likelihood:                -136.39
converged:                       True   LL-Null:                       -141.39
Covariance Type:            nonrobust   LLR p-value:                   0.04038
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.4544      1.720     -0.846      0.398      -4.825       1.916
C(topic_grouped)[T.Science and technology]     0.2724      0.345      0.789      0.430      -0.404       0.949
C(answer_type_grouped)[T.Misc]                 0.7212      0.343      2.100      0.036       0.048       1.394
C(answer_type_grouped)[T.Person]              -0.2907      0.381     -0.762      0.446      -1.038       0.457
q_length                                       0.2994      0.365      0.821      0.412      -0.416       1.014
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.6132
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  205
Model:                          Logit   Df Residuals:                      199
Method:                           MLE   Df Model:                            5
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.09571
Time:                        09:26:44   Log-Likelihood:                -127.86
converged:                       True   LL-Null:                       -141.39
Covariance Type:            nonrobust   LLR p-value:                 5.544e-05
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -2.2161      1.808     -1.226      0.220      -5.759       1.327
C(topic_grouped)[T.Science and technology]     0.2071      0.366      0.565      0.572      -0.511       0.925
C(answer_type_grouped)[T.Misc]                 0.9537      0.367      2.596      0.009       0.234       1.674
C(answer_type_grouped)[T.Person]              -0.1352      0.401     -0.337      0.736      -0.920       0.650
q_length                                       0.2661      0.380      0.699      0.484      -0.480       1.012
capabilities_entropy                           1.3436      0.341      3.940      0.000       0.675       2.012
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  205
Model:                          Logit   Df Residuals:                      199
Method:                           MLE   Df Model:                            5
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.06110
Time:                        09:26:44   Log-Likelihood:                -132.75
converged:                       True   LL-Null:                       -141.39
Covariance Type:            nonrobust   LLR p-value:                  0.004003
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -2.0585      1.772     -1.161      0.245      -5.532       1.415
C(topic_grouped)[T.Science and technology]     0.2615      0.351      0.746      0.456      -0.426       0.949
C(answer_type_grouped)[T.Misc]                 0.8032      0.352      2.281      0.023       0.113       1.493
C(answer_type_grouped)[T.Person]              -0.1331      0.392     -0.339      0.734      -0.902       0.636
q_length                                       0.2780      0.372      0.747      0.455      -0.452       1.008
game_entropy                                   0.7774      0.293      2.652      0.008       0.203       1.352
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  205
Model:                          Logit   Df Residuals:                      198
Method:                           MLE   Df Model:                            6
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1054
Time:                        09:26:44   Log-Likelihood:                -126.49
converged:                       True   LL-Null:                       -141.39
Covariance Type:            nonrobust   LLR p-value:                 4.280e-05
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -2.5322      1.838     -1.378      0.168      -6.134       1.070
C(topic_grouped)[T.Science and technology]     0.2031      0.368      0.552      0.581      -0.519       0.925
C(answer_type_grouped)[T.Misc]                 0.9747      0.369      2.640      0.008       0.251       1.698
C(answer_type_grouped)[T.Person]              -0.0539      0.407     -0.132      0.895      -0.852       0.744
q_length                                       0.2561      0.384      0.666      0.505      -0.497       1.009
capabilities_entropy                           1.2060      0.352      3.422      0.001       0.515       1.897
game_entropy                                   0.5069      0.308      1.646      0.100      -0.097       1.111
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing qwen3-235b-a22b-2507 (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/qwen3-235b-a22b-2507_SimpleMC_redacted_cor_temp0.0_1756216549_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    231
1     76
Name: count, dtype: int64

Answer change%: 0.2476 [0.19927855376321882, 0.29583545275143913] (n=307)
P-value vs 25%: 0.921; P-value vs 0%: 9.178e-24
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=76)
P-value vs 25%: 0; P-value vs 33%: 0

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  307
Model:                          Logit   Df Residuals:                      305
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.04598
Time:                        09:26:44   Log-Likelihood:                -163.91
converged:                       True   LL-Null:                       -171.81
Covariance Type:            nonrobust   LLR p-value:                 7.039e-05
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          1.5130      0.660      2.293      0.022       0.220       2.806
p_i_capability    -2.9733      0.743     -4.001      0.000      -4.430      -1.517
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  307
Model:                          Logit   Df Residuals:                      305
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.05240
Time:                        09:26:44   Log-Likelihood:                -162.81
converged:                       True   LL-Null:                       -171.81
Covariance Type:            nonrobust   LLR p-value:                 2.204e-05
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.5443      0.178     -8.661      0.000      -1.894      -1.195
capabilities_entropy     1.0231      0.241      4.249      0.000       0.551       1.495
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.7105 [0.6086, 0.8125] (n=76)
                  P-value vs 33.3%: 4.148e-13

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=3.55, p=0.000491
Wilcoxon delta_p: statistic=4850.00, p=6.61e-07
Mean Δp = 0.0561  [0.0251, 0.0871]
Idea 1 N = 186; 

  Idea 1.5: Calibration Metrics
  NLL: 0.1576, Signed ECE (overconf pos under neg): -0.1123, ECE: 0.1123 (n=256)
  Brier: 0.0441, Reliability (absolute calibration error; lower better): 0.0434, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=256)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.684
Model:                            OLS   Adj. R-squared:                  0.681
Method:                 Least Squares   F-statistic:                     180.6
Date:                Sat, 20 Sep 2025   Prob (F-statistic):           2.70e-62
Time:                        09:26:44   Log-Likelihood:                 48.780
No. Observations:                 254   AIC:                            -89.56
Df Residuals:                     250   BIC:                            -75.41
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.5084      0.085     -5.997      0.000      -0.675      -0.341
p1                    0.6190      0.092      6.762      0.000       0.439       0.799
answer_changed        0.2984      0.150      1.990      0.048       0.003       0.594
p1:answer_changed     0.4129      0.171      2.418      0.016       0.077       0.749
==============================================================================
Omnibus:                       39.735   Durbin-Watson:                   2.086
Prob(Omnibus):                  0.000   Jarque-Bera (JB):              228.906
Skew:                           0.390   Prob(JB):                     1.97e-50
Kurtosis:                       7.585   Cond. No.                         26.4
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-3.93, p=0.000119
Wilcoxon delta_H: statistic=5805.00, p=8.45e-05
Mean ΔH = -0.1943  [-0.2911, -0.0975]
Paired t-test delta_H Changed: statistic=2.19, p=0.0319
Wilcoxon delta_H Changed: statistic=885.00, p=0.0538
Mean ΔH Changed = 0.1628  [0.0171, 0.3086]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=-2.09, p=0.0375
Wilcoxon (p_top2_game vs p_top2_base): statistic=10385.00, p=4.8e-07
Mean Δp_top2 = -0.0099  [-0.0192, -0.0006] (n=256)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=-2.28, p=0.0234
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=13436.00, p=0.0144
Mean ΔH_unchosen_baseline_set = -0.0967  [-0.1797, -0.0136] (n=256)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  256
Model:                          Logit   Df Residuals:                      253
Method:                           MLE   Df Model:                            2
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.07701
Time:                        09:26:44   Log-Likelihood:                -138.62
converged:                       True   LL-Null:                       -150.18
Covariance Type:            nonrobust   LLR p-value:                 9.490e-06
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.4191      0.215     -1.948      0.051      -0.841       0.003
p1_z            -1.3398      0.288     -4.646      0.000      -1.905      -0.775
I(p1_z ** 2)    -0.6430      0.179     -3.586      0.000      -0.994      -0.292
================================================================================
AUC = 0.665

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  307
Model:                          Logit   Df Residuals:                      305
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.05367
Time:                        09:26:44   Log-Likelihood:                -162.59
converged:                       True   LL-Null:                       -171.81
Covariance Type:            nonrobust   LLR p-value:                 1.750e-05
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.6711      0.200     -8.351      0.000      -2.063      -1.279
game_entropy     1.0463      0.246      4.261      0.000       0.565       1.528
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=14780.00, p=5.83e-05
Paired t-test (game_entropy vs capabilities_entropy): statistic=3.16, p=0.00171
Mean capabilities_entropy-game_entropy = -0.1065  [-0.1724, -0.0405] (n=307)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  307
Model:                          Logit   Df Residuals:                      304
Method:                           MLE   Df Model:                            2
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.07868
Time:                        09:26:44   Log-Likelihood:                -158.29
converged:                       True   LL-Null:                       -171.81
Covariance Type:            nonrobust   LLR p-value:                 1.346e-06
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.8588      0.217     -8.581      0.000      -2.283      -1.434
capabilities_entropy     0.7646      0.258      2.967      0.003       0.260       1.270
game_entropy             0.7917      0.263      3.015      0.003       0.277       1.306
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['Sports', 'TV shows', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': None
topic_grouped           answer_changed
Art                     0                 0.763636
                        1                 0.236364
Geography               0                 0.727273
                        1                 0.272727
History                 0                 0.636364
                        1                 0.363636
Misc                    0                 0.733333
                        1                 0.266667
Music                   0                 0.727273
                        1                 0.272727
Other                   0                 0.903226
                        1                 0.096774
Politics                0                 0.745098
                        1                 0.254902
Science and technology  0                 0.745763
                        1                 0.254237
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.717172
                     1                 0.282828
Number               0                 0.636364
                     1                 0.363636
Other                0                 0.821429
                     1                 0.178571
Person               0                 0.850575
                     1                 0.149425
Place                0                 0.571429
                     1                 0.428571
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.583333  0.416667           12
                       Number               0.666667  0.333333            6
                       Other                0.900000  0.100000           10
                       Person               0.869565  0.130435           23
                       Place                0.500000  0.500000            4
Geography              Date                 1.000000  0.000000            4
                       Number               0.636364  0.363636           11
                       Other                1.000000  0.000000            1
                       Place                0.666667  0.333333            6
History                Date                 0.692308  0.307692           13
                       Number               1.000000  0.000000            2
                       Other                0.000000  1.000000            2
                       Person               0.600000  0.400000            5
Misc                   Date                 0.727273  0.272727           11
                       Number               0.833333  0.166667            6
                       Other                0.750000  0.250000           12
                       Person               0.714286  0.285714           14
                       Place                0.500000  0.500000            2
Music                  Date                 0.750000  0.250000            8
                       Number               0.000000  1.000000            2
                       Other                0.666667  0.333333            3
                       Person               1.000000  0.000000            8
                       Place                0.000000  1.000000            1
Other                  Date                 0.777778  0.222222            9
                       Number               0.833333  0.166667            6
                       Other                1.000000  0.000000            5
                       Person               1.000000  0.000000           10
                       Place                1.000000  0.000000            1
Politics               Date                 0.695652  0.304348           23
                       Number               0.500000  0.500000            4
                       Other                0.900000  0.100000           10
                       Person               0.900000  0.100000           10
                       Place                0.500000  0.500000            4
Science and technology Date                 0.736842  0.263158           19
                       Number               0.428571  0.571429            7
                       Other                0.846154  0.153846           13
                       Person               0.823529  0.176471           17
                       Place                0.666667  0.333333            3

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  307
Model:                          Logit   Df Residuals:                      294
Method:                           MLE   Df Model:                           12
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.06156
Time:                        09:26:44   Log-Likelihood:                -161.23
converged:                       True   LL-Null:                       -171.81
Covariance Type:            nonrobust   LLR p-value:                   0.04818
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -0.6168      1.710     -0.361      0.718      -3.968       2.734
C(topic_grouped)[T.Geography]                 -0.5781      0.619     -0.934      0.350      -1.792       0.636
C(topic_grouped)[T.History]                    0.5383      0.571      0.944      0.345      -0.580       1.657
C(topic_grouped)[T.Misc]                       0.1530      0.480      0.319      0.750      -0.788       1.094
C(topic_grouped)[T.Music]                      0.1728      0.595      0.290      0.771      -0.993       1.339
C(topic_grouped)[T.Other]                     -1.2166      0.704     -1.729      0.084      -2.596       0.163
C(topic_grouped)[T.Politics]                  -0.0092      0.487     -0.019      0.985      -0.963       0.945
C(topic_grouped)[T.Science and technology]     0.0517      0.454      0.114      0.909      -0.838       0.941
C(answer_type_grouped)[T.Number]               0.6056      0.417      1.452      0.146      -0.212       1.423
C(answer_type_grouped)[T.Other]               -0.5863      0.428     -1.369      0.171      -1.426       0.253
C(answer_type_grouped)[T.Person]              -0.7971      0.387     -2.061      0.039      -1.555      -0.039
C(answer_type_grouped)[T.Place]                0.8426      0.524      1.607      0.108      -0.185       1.870
q_length                                      -0.0727      0.372     -0.196      0.845      -0.801       0.656
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.3605
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  307
Model:                          Logit   Df Residuals:                      293
Method:                           MLE   Df Model:                           13
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1097
Time:                        09:26:44   Log-Likelihood:                -152.96
converged:                       True   LL-Null:                       -171.81
Covariance Type:            nonrobust   LLR p-value:                 0.0003228
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -2.1780      1.817     -1.198      0.231      -5.740       1.384
C(topic_grouped)[T.Geography]                 -0.5378      0.635     -0.847      0.397      -1.783       0.707
C(topic_grouped)[T.History]                    0.6102      0.590      1.034      0.301      -0.547       1.767
C(topic_grouped)[T.Misc]                       0.1820      0.497      0.366      0.714      -0.792       1.155
C(topic_grouped)[T.Music]                      0.3134      0.622      0.504      0.614      -0.906       1.533
C(topic_grouped)[T.Other]                     -1.2046      0.717     -1.681      0.093      -2.609       0.200
C(topic_grouped)[T.Politics]                  -0.0379      0.499     -0.076      0.939      -1.017       0.941
C(topic_grouped)[T.Science and technology]     0.0108      0.470      0.023      0.982      -0.911       0.933
C(answer_type_grouped)[T.Number]               0.5619      0.434      1.295      0.195      -0.288       1.412
C(answer_type_grouped)[T.Other]               -0.4049      0.443     -0.915      0.360      -1.273       0.463
C(answer_type_grouped)[T.Person]              -0.7214      0.396     -1.822      0.068      -1.497       0.054
C(answer_type_grouped)[T.Place]                0.9694      0.543      1.787      0.074      -0.094       2.033
q_length                                       0.1607      0.391      0.411      0.681      -0.606       0.927
capabilities_entropy                           1.0452      0.258      4.058      0.000       0.540       1.550
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  307
Model:                          Logit   Df Residuals:                      293
Method:                           MLE   Df Model:                           13
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1056
Time:                        09:26:44   Log-Likelihood:                -153.66
converged:                       True   LL-Null:                       -171.81
Covariance Type:            nonrobust   LLR p-value:                 0.0005324
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.5354      1.784     -0.861      0.389      -5.031       1.960
C(topic_grouped)[T.Geography]                 -0.6471      0.642     -1.008      0.313      -1.905       0.611
C(topic_grouped)[T.History]                    0.5085      0.584      0.870      0.384      -0.637       1.654
C(topic_grouped)[T.Misc]                       0.2183      0.491      0.444      0.657      -0.745       1.181
C(topic_grouped)[T.Music]                      0.1556      0.621      0.251      0.802      -1.061       1.372
C(topic_grouped)[T.Other]                     -1.1953      0.710     -1.684      0.092      -2.586       0.196
C(topic_grouped)[T.Politics]                  -0.0346      0.498     -0.070      0.945      -1.010       0.941
C(topic_grouped)[T.Science and technology]    -0.0144      0.473     -0.030      0.976      -0.941       0.912
C(answer_type_grouped)[T.Number]               0.7893      0.437      1.805      0.071      -0.068       1.646
C(answer_type_grouped)[T.Other]               -0.2347      0.448     -0.524      0.601      -1.114       0.644
C(answer_type_grouped)[T.Person]              -0.5178      0.401     -1.290      0.197      -1.305       0.269
C(answer_type_grouped)[T.Place]                1.1008      0.557      1.975      0.048       0.009       2.193
q_length                                      -0.0247      0.384     -0.064      0.949      -0.777       0.728
game_entropy                                   1.0145      0.264      3.844      0.000       0.497       1.532
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  307
Model:                          Logit   Df Residuals:                      292
Method:                           MLE   Df Model:                           14
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1305
Time:                        09:26:44   Log-Likelihood:                -149.39
converged:                       True   LL-Null:                       -171.81
Covariance Type:            nonrobust   LLR p-value:                 4.322e-05
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -2.5087      1.855     -1.352      0.176      -6.145       1.128
C(topic_grouped)[T.Geography]                 -0.5658      0.645     -0.877      0.380      -1.830       0.698
C(topic_grouped)[T.History]                    0.5897      0.599      0.985      0.325      -0.584       1.763
C(topic_grouped)[T.Misc]                       0.2509      0.502      0.499      0.618      -0.734       1.236
C(topic_grouped)[T.Music]                      0.2721      0.635      0.429      0.668      -0.972       1.516
C(topic_grouped)[T.Other]                     -1.1844      0.722     -1.640      0.101      -2.600       0.231
C(topic_grouped)[T.Politics]                  -0.0320      0.506     -0.063      0.950      -1.025       0.961
C(topic_grouped)[T.Science and technology]    -0.0073      0.482     -0.015      0.988      -0.952       0.937
C(answer_type_grouped)[T.Number]               0.7238      0.447      1.619      0.105      -0.152       1.600
C(answer_type_grouped)[T.Other]               -0.1769      0.457     -0.387      0.699      -1.072       0.718
C(answer_type_grouped)[T.Person]              -0.5077      0.408     -1.246      0.213      -1.306       0.291
C(answer_type_grouped)[T.Place]                1.1472      0.563      2.038      0.042       0.044       2.251
q_length                                       0.1378      0.397      0.347      0.729      -0.641       0.916
capabilities_entropy                           0.8113      0.275      2.950      0.003       0.272       1.350
game_entropy                                   0.7542      0.282      2.677      0.007       0.202       1.307
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing qwen3-235b-a22b-2507 (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/qwen3-235b-a22b-2507_SimpleMC_redacted_temp0.0_1756212978_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    114
1     79
Name: count, dtype: int64

Answer change%: 0.4093 [0.3399554018984067, 0.478697447842526] (n=193)
P-value vs 25%: 6.747e-06; P-value vs 0%: 6.21e-31
Phase 2 self-accuracy: 0.5063 [0.39608135926201626, 0.6165768685860851] (n=79)
P-value vs 25%: 5.19e-06; P-value vs 33%: 0.00206

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  193
Model:                          Logit   Df Residuals:                      191
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.01791
Time:                        09:26:44   Log-Likelihood:                -128.25
converged:                       True   LL-Null:                       -130.59
Covariance Type:            nonrobust   LLR p-value:                   0.03054
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          0.8962      0.604      1.484      0.138      -0.287       2.080
p_i_capability    -1.5567      0.724     -2.149      0.032      -2.977      -0.137
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  193
Model:                          Logit   Df Residuals:                      191
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.01544
Time:                        09:26:44   Log-Likelihood:                -128.57
converged:                       True   LL-Null:                       -130.59
Covariance Type:            nonrobust   LLR p-value:                   0.04465
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -0.6819      0.219     -3.118      0.002      -1.110      -0.253
capabilities_entropy     0.4918      0.246      1.996      0.046       0.009       0.975
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.6076 [0.4999, 0.7153] (n=79)
                  P-value vs 33.3%: 5.965e-07

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=1.54, p=0.127
Wilcoxon delta_p: statistic=2049.00, p=0.391
Mean Δp = 0.0385  [-0.0105, 0.0876]
Idea 1 N = 97; 

  Idea 1.5: Calibration Metrics
  NLL: 10.4050, Signed ECE (overconf pos under neg): 0.0960, ECE: 0.0960 (n=169)
  Brier: 0.0269, Reliability (absolute calibration error; lower better): 0.0262, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=169)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.711
Model:                            OLS   Adj. R-squared:                  0.706
Method:                 Least Squares   F-statistic:                     138.4
Date:                Sat, 20 Sep 2025   Prob (F-statistic):           2.64e-45
Time:                        09:26:44   Log-Likelihood:                 26.112
No. Observations:                 173   AIC:                            -44.22
Df Residuals:                     169   BIC:                            -31.61
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.5821      0.101     -5.761      0.000      -0.782      -0.383
p1                    0.7361      0.117      6.284      0.000       0.505       0.967
answer_changed        0.3922      0.135      2.914      0.004       0.126       0.658
p1:answer_changed     0.2645      0.161      1.648      0.101      -0.052       0.581
==============================================================================
Omnibus:                       12.179   Durbin-Watson:                   1.849
Prob(Omnibus):                  0.002   Jarque-Bera (JB):               32.095
Skew:                           0.036   Prob(JB):                     1.07e-07
Kurtosis:                       5.109   Cond. No.                         21.8
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-2.28, p=0.0247
Wilcoxon delta_H: statistic=1786.00, p=0.0336
Mean ΔH = -0.1536  [-0.2855, -0.0217]
Paired t-test delta_H Changed: statistic=2.78, p=0.00696
Wilcoxon delta_H Changed: statistic=996.00, p=0.0349
Mean ΔH Changed = 0.1774  [0.0521, 0.3027]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=-0.19, p=0.852
Wilcoxon (p_top2_game vs p_top2_base): statistic=6557.00, p=0.142
Mean Δp_top2 = -0.0013  [-0.0147, 0.0121] (n=173)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=-0.17, p=0.866
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=7141.00, p=0.744
Mean ΔH_unchosen_baseline_set = -0.0082  [-0.1034, 0.0870] (n=173)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  173
Model:                          Logit   Df Residuals:                      170
Method:                           MLE   Df Model:                            2
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.02403
Time:                        09:26:44   Log-Likelihood:                -115.79
converged:                       True   LL-Null:                       -118.64
Covariance Type:            nonrobust   LLR p-value:                   0.05779
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.4861      0.251     -1.934      0.053      -0.979       0.007
p1_z            -0.1433      0.209     -0.685      0.493      -0.553       0.267
I(p1_z ** 2)     0.2431      0.203      1.199      0.231      -0.154       0.641
================================================================================
AUC = 0.590

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  193
Model:                          Logit   Df Residuals:                      191
Method:                           MLE   Df Model:                            1
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.04796
Time:                        09:26:44   Log-Likelihood:                -124.32
converged:                       True   LL-Null:                       -130.59
Covariance Type:            nonrobust   LLR p-value:                 0.0004012
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.0321      0.251     -4.119      0.000      -1.523      -0.541
game_entropy     0.9885      0.287      3.441      0.001       0.426       1.552
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=8662.00, p=0.589
Paired t-test (game_entropy vs capabilities_entropy): statistic=0.43, p=0.67
Mean capabilities_entropy-game_entropy = -0.0226  [-0.1260, 0.0809] (n=193)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  193
Model:                          Logit   Df Residuals:                      190
Method:                           MLE   Df Model:                            2
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.05601
Time:                        09:26:44   Log-Likelihood:                -123.27
converged:                       True   LL-Null:                       -130.59
Covariance Type:            nonrobust   LLR p-value:                 0.0006659
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.2264      0.288     -4.251      0.000      -1.792      -0.661
capabilities_entropy     0.3710      0.256      1.450      0.147      -0.131       0.873
game_entropy             0.9256      0.291      3.183      0.001       0.356       1.496
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['Video games', 'History']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.850000
                        1                 0.150000
Geography               0                 0.500000
                        1                 0.500000
Music                   0                 0.666667
                        1                 0.333333
Other                   1                 0.515152
                        0                 0.484848
Politics                1                 0.538462
                        0                 0.461538
Science and technology  0                 0.538462
                        1                 0.461538
Sports                  0                 0.714286
                        1                 0.285714
TV shows                0                 0.714286
                        1                 0.285714
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.600000
                     1                 0.400000
Number               1                 0.558824
                     0                 0.441176
Other                0                 0.660714
                     1                 0.339286
Person               0                 0.606061
                     1                 0.393939
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.888889  0.111111            9
                       Number               0.333333  0.666667            3
                       Other                1.000000  0.000000            4
                       Person               1.000000  0.000000            4
Geography              Date                 0.636364  0.363636           11
                       Number               0.428571  0.571429            7
                       Other                0.250000  0.750000            4
Music                  Date                 0.750000  0.250000            4
                       Number               0.000000  1.000000            2
                       Other                0.750000  0.250000            8
                       Person               0.750000  0.250000            4
Other                  Date                 0.363636  0.636364           11
                       Number               0.250000  0.750000            4
                       Other                0.600000  0.400000           15
                       Person               0.666667  0.333333            3
Politics               Date                 0.461538  0.538462           13
                       Number               0.000000  1.000000            2
                       Other                1.000000  0.000000            6
                       Person               0.000000  1.000000            5
Science and technology Date                 0.625000  0.375000           16
                       Number               0.428571  0.571429            7
                       Other                0.000000  1.000000            3
                       Person               0.615385  0.384615           13
Sports                 Date                 0.666667  0.333333            6
                       Number               0.750000  0.250000            8
                       Other                0.666667  0.333333            6
                       Person               1.000000  0.000000            1
TV shows               Number               1.000000  0.000000            1
                       Other                0.700000  0.300000           10
                       Person               0.666667  0.333333            3

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  193
Model:                          Logit   Df Residuals:                      181
Method:                           MLE   Df Model:                           11
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.07928
Time:                        09:26:44   Log-Likelihood:                -120.23
converged:                       True   LL-Null:                       -130.59
Covariance Type:            nonrobust   LLR p-value:                   0.03654
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      0.7944      2.072      0.383      0.701      -3.267       4.856
C(topic_grouped)[T.Geography]                  1.6074      0.776      2.070      0.038       0.086       3.129
C(topic_grouped)[T.Music]                      1.1707      0.824      1.421      0.155      -0.444       2.785
C(topic_grouped)[T.Other]                      1.9439      0.739      2.629      0.009       0.495       3.393
C(topic_grouped)[T.Politics]                   2.0915      0.761      2.747      0.006       0.599       3.584
C(topic_grouped)[T.Science and technology]     1.6346      0.725      2.253      0.024       0.213       3.056
C(topic_grouped)[T.Sports]                     0.7035      0.815      0.864      0.388      -0.893       2.300
C(topic_grouped)[T.TV shows]                   1.0115      0.903      1.120      0.263      -0.759       2.782
C(answer_type_grouped)[T.Number]               0.8877      0.459      1.933      0.053      -0.012       1.788
C(answer_type_grouped)[T.Other]               -0.2051      0.418     -0.490      0.624      -1.025       0.614
C(answer_type_grouped)[T.Person]              -0.0510      0.475     -0.107      0.914      -0.981       0.879
q_length                                      -0.5947      0.440     -1.352      0.177      -1.457       0.268
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.6265
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  193
Model:                          Logit   Df Residuals:                      180
Method:                           MLE   Df Model:                           12
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                 0.08458
Time:                        09:26:44   Log-Likelihood:                -119.54
converged:                       True   LL-Null:                       -130.59
Covariance Type:            nonrobust   LLR p-value:                   0.03653
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      0.3709      2.102      0.176      0.860      -3.749       4.491
C(topic_grouped)[T.Geography]                  1.4900      0.785      1.898      0.058      -0.049       3.029
C(topic_grouped)[T.Music]                      1.1824      0.827      1.429      0.153      -0.439       2.804
C(topic_grouped)[T.Other]                      1.8955      0.743      2.553      0.011       0.440       3.351
C(topic_grouped)[T.Politics]                   1.9902      0.767      2.593      0.010       0.486       3.494
C(topic_grouped)[T.Science and technology]     1.5322      0.731      2.095      0.036       0.099       2.966
C(topic_grouped)[T.Sports]                     0.6705      0.817      0.821      0.412      -0.930       2.271
C(topic_grouped)[T.TV shows]                   0.8894      0.913      0.974      0.330      -0.900       2.679
C(answer_type_grouped)[T.Number]               0.8757      0.462      1.896      0.058      -0.029       1.781
C(answer_type_grouped)[T.Other]               -0.1642      0.422     -0.389      0.697      -0.991       0.662
C(answer_type_grouped)[T.Person]              -0.0010      0.477     -0.002      0.998      -0.935       0.933
q_length                                      -0.5344      0.441     -1.211      0.226      -1.400       0.331
capabilities_entropy                           0.3154      0.269      1.174      0.240      -0.211       0.842
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  193
Model:                          Logit   Df Residuals:                      180
Method:                           MLE   Df Model:                           12
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1311
Time:                        09:26:44   Log-Likelihood:                -113.47
converged:                       True   LL-Null:                       -130.59
Covariance Type:            nonrobust   LLR p-value:                 0.0006187
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      0.1766      2.166      0.082      0.935      -4.069       4.422
C(topic_grouped)[T.Geography]                  1.6496      0.800      2.061      0.039       0.081       3.218
C(topic_grouped)[T.Music]                      1.2729      0.851      1.496      0.135      -0.395       2.941
C(topic_grouped)[T.Other]                      2.0538      0.763      2.691      0.007       0.558       3.550
C(topic_grouped)[T.Politics]                   2.1336      0.792      2.694      0.007       0.581       3.686
C(topic_grouped)[T.Science and technology]     1.7622      0.749      2.351      0.019       0.293       3.231
C(topic_grouped)[T.Sports]                     0.6671      0.845      0.790      0.430      -0.988       2.323
C(topic_grouped)[T.TV shows]                   0.9607      0.925      1.038      0.299      -0.853       2.774
C(answer_type_grouped)[T.Number]               1.0612      0.480      2.209      0.027       0.120       2.003
C(answer_type_grouped)[T.Other]               -0.0572      0.437     -0.131      0.896      -0.913       0.798
C(answer_type_grouped)[T.Person]               0.1075      0.504      0.213      0.831      -0.880       1.095
q_length                                      -0.6592      0.456     -1.447      0.148      -1.552       0.234
game_entropy                                   1.1074      0.312      3.546      0.000       0.495       1.720
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  193
Model:                          Logit   Df Residuals:                      179
Method:                           MLE   Df Model:                           13
Date:                Sat, 20 Sep 2025   Pseudo R-squ.:                  0.1321
Time:                        09:26:44   Log-Likelihood:                -113.33
converged:                       True   LL-Null:                       -130.59
Covariance Type:            nonrobust   LLR p-value:                  0.001009
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -0.0135      2.196     -0.006      0.995      -4.317       4.290
C(topic_grouped)[T.Geography]                  1.5955      0.809      1.972      0.049       0.010       3.181
C(topic_grouped)[T.Music]                      1.2731      0.851      1.496      0.135      -0.395       2.941
C(topic_grouped)[T.Other]                      2.0248      0.766      2.642      0.008       0.523       3.527
C(topic_grouped)[T.Politics]                   2.0805      0.799      2.603      0.009       0.514       3.647
C(topic_grouped)[T.Science and technology]     1.7058      0.757      2.252      0.024       0.221       3.190
C(topic_grouped)[T.Sports]                     0.6546      0.845      0.775      0.438      -1.001       2.311
C(topic_grouped)[T.TV shows]                   0.8996      0.935      0.962      0.336      -0.933       2.732
C(answer_type_grouped)[T.Number]               1.0480      0.481      2.179      0.029       0.105       1.991
C(answer_type_grouped)[T.Other]               -0.0358      0.439     -0.082      0.935      -0.896       0.825
C(answer_type_grouped)[T.Person]               0.1308      0.506      0.258      0.796      -0.861       1.123
q_length                                      -0.6270      0.458     -1.368      0.171      -1.525       0.271
capabilities_entropy                           0.1465      0.284      0.515      0.606      -0.411       0.704
game_entropy                                   1.0788      0.317      3.406      0.001       0.458       1.700
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.
