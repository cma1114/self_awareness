
--- Analyzing claude-3-5-sonnet-20241022 (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/claude-3-5-sonnet-20241022_SimpleMC_redacted_cor_temp0.0_1753745296_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    247
1     53
Name: count, dtype: int64

Answer change%: 0.1767 [0.13350953025765339, 0.21982380307567995] (n=300)
P-value vs 25%: 0.0008672; P-value vs 0%: 1.03e-15
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=53)
P-value vs 25%: 0; P-value vs 33%: 0

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  300
Model:                          Logit   Df Residuals:                      298
Method:                           MLE   Df Model:                            1
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                  0.1042
Time:                        20:58:12   Log-Likelihood:                -125.32
converged:                       True   LL-Null:                       -139.89
Covariance Type:            nonrobust   LLR p-value:                 6.728e-08
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          1.4638      0.562      2.605      0.009       0.363       2.565
p_i_capability    -4.0545      0.775     -5.229      0.000      -5.574      -2.535
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  300
Model:                          Logit   Df Residuals:                      298
Method:                           MLE   Df Model:                            1
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                  0.1201
Time:                        20:58:12   Log-Likelihood:                -123.09
converged:                       True   LL-Null:                       -139.89
Covariance Type:            nonrobust   LLR p-value:                 6.778e-09
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -3.1261      0.370     -8.455      0.000      -3.851      -2.401
capabilities_entropy     1.6202      0.296      5.471      0.000       1.040       2.201
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.6604 [0.5329, 0.7879] (n=53)
                  P-value vs 33.3%: 4.97e-07

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=6.08, p=4.51e-09
Wilcoxon delta_p: statistic=4942.50, p=5.05e-09
Mean Δp = 0.0644  [0.0437, 0.0852]
Idea 1 N = 247; 

  Idea 1.5: Calibration Metrics
  NLL: 0.2738, Signed ECE (overconf pos under neg): -0.2103, ECE: 0.2103 (n=300)
  Brier: 0.0822, Reliability (absolute calibration error; lower better): 0.0817, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=300)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.506
Model:                            OLS   Adj. R-squared:                  0.501
Method:                 Least Squares   F-statistic:                     100.9
Date:                Tue, 26 Aug 2025   Prob (F-statistic):           5.29e-45
Time:                        20:58:12   Log-Likelihood:                 141.41
No. Observations:                 300   AIC:                            -274.8
Df Residuals:                     296   BIC:                            -260.0
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.1429      0.044     -3.252      0.001      -0.229      -0.056
p1                    0.2533      0.052      4.837      0.000       0.150       0.356
answer_changed       -0.0364      0.089     -0.408      0.684      -0.212       0.139
p1:answer_changed     0.6395      0.126      5.081      0.000       0.392       0.887
==============================================================================
Omnibus:                       17.550   Durbin-Watson:                   2.055
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               18.922
Skew:                           0.594   Prob(JB):                     7.78e-05
Kurtosis:                       3.321   Cond. No.                         23.1
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-0.21, p=0.836
Wilcoxon delta_H: statistic=9540.50, p=0.792
Mean ΔH = -0.0048  [-0.0499, 0.0403]
Paired t-test delta_H Changed: statistic=1.53, p=0.131
Wilcoxon delta_H Changed: statistic=568.00, p=0.192
Mean ΔH Changed = 0.0831  [-0.0231, 0.1892]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=-7.60, p=3.83e-13
Wilcoxon (p_top2_game vs p_top2_base): statistic=7520.00, p=9.58e-13
Mean Δp_top2 = -0.0421  [-0.0530, -0.0313] (n=300)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=0.51, p=0.614
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=15211.50, p=0.677
Mean ΔH_unchosen_baseline_set = 0.0107  [-0.0309, 0.0524] (n=300)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  300
Model:                          Logit   Df Residuals:                      297
Method:                           MLE   Df Model:                            2
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                  0.1287
Time:                        20:58:12   Log-Likelihood:                -121.89
converged:                       True   LL-Null:                       -139.89
Covariance Type:            nonrobust   LLR p-value:                 1.524e-08
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.3636      0.227     -6.017      0.000      -1.808      -0.919
p1_z            -1.2878      0.257     -5.013      0.000      -1.791      -0.784
I(p1_z ** 2)    -0.4810      0.188     -2.553      0.011      -0.850      -0.112
================================================================================
AUC = 0.733

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  300
Model:                          Logit   Df Residuals:                      298
Method:                           MLE   Df Model:                            1
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                  0.1868
Time:                        20:58:12   Log-Likelihood:                -113.76
converged:                       True   LL-Null:                       -139.89
Covariance Type:            nonrobust   LLR p-value:                 4.854e-13
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -4.4449      0.596     -7.456      0.000      -5.613      -3.276
game_entropy     2.2685      0.388      5.845      0.000       1.508       3.029
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=7157.50, p=9.12e-14
Paired t-test (game_entropy vs capabilities_entropy): statistic=7.95, p=3.94e-14
Mean capabilities_entropy-game_entropy = -0.2181  [-0.2719, -0.1643] (n=300)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  300
Model:                          Logit   Df Residuals:                      297
Method:                           MLE   Df Model:                            2
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                  0.1959
Time:                        20:58:12   Log-Likelihood:                -112.49
converged:                       True   LL-Null:                       -139.89
Covariance Type:            nonrobust   LLR p-value:                 1.261e-12
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -4.5271      0.593     -7.631      0.000      -5.690      -3.364
capabilities_entropy     0.5777      0.366      1.578      0.115      -0.140       1.295
game_entropy             1.8882      0.449      4.203      0.000       1.008       2.769
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.914894
                        1                 0.085106
Geography               0                 0.739130
                        1                 0.260870
Misc                    0                 0.897959
                        1                 0.102041
Music                   0                 0.833333
                        1                 0.166667
Other                   0                 0.750000
                        1                 0.250000
Politics                0                 0.800000
                        1                 0.200000
Science and technology  0                 0.807692
                        1                 0.192308
Sports                  0                 0.739130
                        1                 0.260870
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.740000
                     1                 0.260000
Number               0                 0.800000
                     1                 0.200000
Other                0                 0.840909
                     1                 0.159091
Person               0                 0.922078
                     1                 0.077922
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.900000  0.100000           10
                       Number               0.666667  0.333333            6
                       Other                0.916667  0.083333           12
                       Person               1.000000  0.000000           19
Geography              Date                 0.428571  0.571429            7
                       Number               0.888889  0.111111            9
                       Other                0.857143  0.142857            7
Misc                   Date                 0.812500  0.187500           16
                       Number               0.833333  0.166667            6
                       Other                0.941176  0.058824           17
                       Person               1.000000  0.000000           10
Music                  Date                 0.714286  0.285714            7
                       Other                0.857143  0.142857            7
                       Person               0.900000  0.100000           10
Other                  Date                 0.727273  0.272727           11
                       Number               1.000000  0.000000            2
                       Other                0.800000  0.200000           10
                       Person               0.666667  0.333333            9
Politics               Date                 0.772727  0.227273           22
                       Number               0.666667  0.333333            3
                       Other                0.750000  0.250000           16
                       Person               1.000000  0.000000            9
Science and technology Date                 0.700000  0.300000           20
                       Number               0.800000  0.200000            5
                       Other                0.846154  0.153846           13
                       Person               0.928571  0.071429           14
Sports                 Date                 0.714286  0.285714            7
                       Number               0.750000  0.250000            4
                       Other                0.666667  0.333333            6
                       Person               0.833333  0.166667            6

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  300
Model:                          Logit   Df Residuals:                      288
Method:                           MLE   Df Model:                           11
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                 0.06485
Time:                        20:58:13   Log-Likelihood:                -130.82
converged:                       True   LL-Null:                       -139.89
Covariance Type:            nonrobust   LLR p-value:                   0.07830
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -2.0237      1.997     -1.013      0.311      -5.938       1.891
C(topic_grouped)[T.Geography]                  1.0155      0.727      1.397      0.162      -0.409       2.440
C(topic_grouped)[T.Misc]                       0.0089      0.714      0.013      0.990      -1.391       1.409
C(topic_grouped)[T.Music]                      0.7732      0.774      0.999      0.318      -0.744       2.290
C(topic_grouped)[T.Other]                      1.1670      0.676      1.727      0.084      -0.157       2.491
C(topic_grouped)[T.Politics]                   0.7248      0.662      1.095      0.274      -0.572       2.022
C(topic_grouped)[T.Science and technology]     0.7623      0.645      1.182      0.237      -0.502       2.027
C(topic_grouped)[T.Sports]                     1.2140      0.718      1.690      0.091      -0.194       2.622
C(answer_type_grouped)[T.Number]              -0.3523      0.509     -0.692      0.489      -1.351       0.646
C(answer_type_grouped)[T.Other]               -0.5899      0.377     -1.565      0.118      -1.329       0.149
C(answer_type_grouped)[T.Person]              -1.3668      0.495     -2.762      0.006      -2.337      -0.397
q_length                                       0.0622      0.430      0.145      0.885      -0.781       0.905
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.8267
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  300
Model:                          Logit   Df Residuals:                      287
Method:                           MLE   Df Model:                           12
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                  0.1813
Time:                        20:58:13   Log-Likelihood:                -114.53
converged:                       True   LL-Null:                       -139.89
Covariance Type:            nonrobust   LLR p-value:                 1.041e-06
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -4.5335      2.241     -2.023      0.043      -8.926      -0.141
C(topic_grouped)[T.Geography]                  0.9103      0.778      1.171      0.242      -0.614       2.434
C(topic_grouped)[T.Misc]                      -0.1407      0.750     -0.188      0.851      -1.610       1.329
C(topic_grouped)[T.Music]                      0.2905      0.824      0.353      0.724      -1.325       1.906
C(topic_grouped)[T.Other]                      1.0563      0.727      1.453      0.146      -0.368       2.481
C(topic_grouped)[T.Politics]                   0.8163      0.687      1.188      0.235      -0.530       2.162
C(topic_grouped)[T.Science and technology]     0.8638      0.682      1.266      0.206      -0.474       2.201
C(topic_grouped)[T.Sports]                     1.4235      0.770      1.848      0.065      -0.086       2.933
C(answer_type_grouped)[T.Number]              -0.7293      0.549     -1.329      0.184      -1.805       0.346
C(answer_type_grouped)[T.Other]               -0.4348      0.407     -1.068      0.286      -1.233       0.363
C(answer_type_grouped)[T.Person]              -1.2289      0.520     -2.362      0.018      -2.248      -0.209
q_length                                       0.2467      0.469      0.526      0.599      -0.672       1.166
capabilities_entropy                           1.7147      0.324      5.300      0.000       1.081       2.349
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  300
Model:                          Logit   Df Residuals:                      287
Method:                           MLE   Df Model:                           12
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                  0.2407
Time:                        20:58:13   Log-Likelihood:                -106.22
converged:                       True   LL-Null:                       -139.89
Covariance Type:            nonrobust   LLR p-value:                 1.005e-09
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -8.5103      2.650     -3.212      0.001     -13.704      -3.317
C(topic_grouped)[T.Geography]                  1.0529      0.779      1.351      0.177      -0.475       2.580
C(topic_grouped)[T.Misc]                      -0.2706      0.759     -0.357      0.721      -1.758       1.217
C(topic_grouped)[T.Music]                     -0.0102      0.830     -0.012      0.990      -1.637       1.616
C(topic_grouped)[T.Other]                      0.8277      0.730      1.134      0.257      -0.603       2.259
C(topic_grouped)[T.Politics]                   0.7862      0.705      1.115      0.265      -0.596       2.168
C(topic_grouped)[T.Science and technology]     0.9109      0.708      1.287      0.198      -0.476       2.298
C(topic_grouped)[T.Sports]                     1.3183      0.776      1.698      0.089      -0.203       2.840
C(answer_type_grouped)[T.Number]              -0.7445      0.556     -1.338      0.181      -1.835       0.346
C(answer_type_grouped)[T.Other]                0.0886      0.430      0.206      0.837      -0.754       0.931
C(answer_type_grouped)[T.Person]              -0.7232      0.543     -1.331      0.183      -1.788       0.342
q_length                                       0.7431      0.533      1.395      0.163      -0.301       1.787
game_entropy                                   2.5068      0.442      5.668      0.000       1.640       3.374
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  300
Model:                          Logit   Df Residuals:                      286
Method:                           MLE   Df Model:                           13
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                  0.2553
Time:                        20:58:13   Log-Likelihood:                -104.18
converged:                       True   LL-Null:                       -139.89
Covariance Type:            nonrobust   LLR p-value:                 4.374e-10
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -8.4710      2.673     -3.169      0.002     -13.711      -3.231
C(topic_grouped)[T.Geography]                  0.9327      0.794      1.174      0.240      -0.624       2.490
C(topic_grouped)[T.Misc]                      -0.3803      0.769     -0.494      0.621      -1.888       1.128
C(topic_grouped)[T.Music]                     -0.1455      0.843     -0.173      0.863      -1.798       1.507
C(topic_grouped)[T.Other]                      0.7841      0.741      1.059      0.290      -0.667       2.236
C(topic_grouped)[T.Politics]                   0.8220      0.708      1.161      0.246      -0.566       2.210
C(topic_grouped)[T.Science and technology]     0.8493      0.717      1.185      0.236      -0.556       2.254
C(topic_grouped)[T.Sports]                     1.3611      0.782      1.740      0.082      -0.172       2.894
C(answer_type_grouped)[T.Number]              -0.8885      0.574     -1.549      0.121      -2.013       0.236
C(answer_type_grouped)[T.Other]                0.0440      0.435      0.101      0.919      -0.808       0.896
C(answer_type_grouped)[T.Person]              -0.7945      0.548     -1.449      0.147      -1.869       0.280
q_length                                       0.7137      0.537      1.330      0.184      -0.338       1.766
capabilities_entropy                           0.7673      0.385      1.995      0.046       0.013       1.521
game_entropy                                   2.0503      0.494      4.152      0.000       1.082       3.018
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing claude-3-5-sonnet-20241022 (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/claude-3-5-sonnet-20241022_SimpleMC_redacted_temp0.0_1753644934_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    116
1     84
Name: count, dtype: int64

Answer change%: 0.4200 [0.3515975377372609, 0.4884024622627391] (n=200)
P-value vs 25%: 1.11e-06; P-value vs 0%: 2.342e-33
Phase 2 self-accuracy: 0.5714 [0.46560046363803614, 0.6772566792191067] (n=84)
P-value vs 25%: 2.634e-09; P-value vs 33%: 1.007e-05

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  200
Model:                          Logit   Df Residuals:                      198
Method:                           MLE   Df Model:                            1
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                 0.09308
Time:                        20:58:13   Log-Likelihood:                -123.39
converged:                       True   LL-Null:                       -136.06
Covariance Type:            nonrobust   LLR p-value:                 4.834e-07
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          1.9541      0.498      3.927      0.000       0.979       2.929
p_i_capability    -3.8391      0.821     -4.675      0.000      -5.449      -2.229
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  200
Model:                          Logit   Df Residuals:                      198
Method:                           MLE   Df Model:                            1
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                  0.1096
Time:                        20:58:13   Log-Likelihood:                -121.15
converged:                       True   LL-Null:                       -136.06
Covariance Type:            nonrobust   LLR p-value:                 4.750e-08
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.6873      0.525     -5.121      0.000      -3.716      -1.659
capabilities_entropy     1.7229      0.351      4.908      0.000       1.035       2.411
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.6786 [0.5787, 0.7784] (n=84)
                  P-value vs 33.3%: 1.243e-11

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=4.63, p=9.61e-06
Wilcoxon delta_p: statistic=1580.00, p=2.94e-05
Mean Δp = 0.0736  [0.0425, 0.1047]
Idea 1 N = 116; 

  Idea 1.5: Calibration Metrics
  NLL: 2.2591, Signed ECE (overconf pos under neg): 0.1590, ECE: 0.1590 (n=200)
  Brier: 0.0387, Reliability (absolute calibration error; lower better): 0.0380, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=200)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.583
Model:                            OLS   Adj. R-squared:                  0.577
Method:                 Least Squares   F-statistic:                     91.46
Date:                Tue, 26 Aug 2025   Prob (F-statistic):           4.74e-37
Time:                        20:58:13   Log-Likelihood:                 120.37
No. Observations:                 200   AIC:                            -232.7
Df Residuals:                     196   BIC:                            -219.6
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.1716      0.041     -4.169      0.000      -0.253      -0.090
p1                    0.3671      0.059      6.249      0.000       0.251       0.483
answer_changed       -0.0370      0.065     -0.565      0.573      -0.166       0.092
p1:answer_changed     0.5859      0.110      5.338      0.000       0.369       0.802
==============================================================================
Omnibus:                        0.153   Durbin-Watson:                   1.958
Prob(Omnibus):                  0.926   Jarque-Bera (JB):                0.286
Skew:                           0.043   Prob(JB):                        0.867
Kurtosis:                       2.836   Cond. No.                         18.1
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-0.80, p=0.423
Wilcoxon delta_H: statistic=2573.00, p=0.199
Mean ΔH = -0.0270  [-0.0927, 0.0388]
Paired t-test delta_H Changed: statistic=3.63, p=0.000493
Wilcoxon delta_H Changed: statistic=951.00, p=0.0002
Mean ΔH Changed = 0.1237  [0.0569, 0.1905]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=-4.43, p=1.57e-05
Wilcoxon (p_top2_game vs p_top2_base): statistic=6023.00, p=1.74e-05
Mean Δp_top2 = -0.0335  [-0.0483, -0.0187] (n=200)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=1.47, p=0.143
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=8276.00, p=0.163
Mean ΔH_unchosen_baseline_set = 0.0363  [-0.0121, 0.0847] (n=200)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  200
Model:                          Logit   Df Residuals:                      197
Method:                           MLE   Df Model:                            2
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                  0.1088
Time:                        20:58:13   Log-Likelihood:                -121.25
converged:                       True   LL-Null:                       -136.06
Covariance Type:            nonrobust   LLR p-value:                 3.723e-07
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.0512      0.222     -0.231      0.818      -0.486       0.384
p1_z            -0.7524      0.178     -4.227      0.000      -1.101      -0.404
I(p1_z ** 2)    -0.3890      0.193     -2.016      0.044      -0.767      -0.011
================================================================================
AUC = 0.701

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  200
Model:                          Logit   Df Residuals:                      198
Method:                           MLE   Df Model:                            1
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                 0.05575
Time:                        20:58:13   Log-Likelihood:                -128.47
converged:                       True   LL-Null:                       -136.06
Covariance Type:            nonrobust   LLR p-value:                 9.821e-05
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -2.2740      0.585     -3.885      0.000      -3.421      -1.127
game_entropy     1.3042      0.367      3.550      0.000       0.584       2.024
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=5654.00, p=1.84e-06
Paired t-test (game_entropy vs capabilities_entropy): statistic=5.11, p=7.47e-07
Mean capabilities_entropy-game_entropy = -0.1362  [-0.1884, -0.0840] (n=200)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  200
Model:                          Logit   Df Residuals:                      197
Method:                           MLE   Df Model:                            2
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                  0.1098
Time:                        20:58:13   Log-Likelihood:                -121.13
converged:                       True   LL-Null:                       -136.06
Covariance Type:            nonrobust   LLR p-value:                 3.271e-07
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.7621      0.627     -4.405      0.000      -3.991      -1.533
capabilities_entropy     1.6591      0.452      3.671      0.000       0.773       2.545
game_entropy             0.1078      0.483      0.223      0.824      -0.839       1.055
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'Video games', 'History']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.607143
                        1                 0.392857
Geography               0                 0.571429
                        1                 0.428571
Misc                    0                 0.720000
                        1                 0.280000
Music                   0                 0.562500
                        1                 0.437500
Other                   1                 0.600000
                        0                 0.400000
Politics                0                 0.666667
                        1                 0.333333
Science and technology  0                 0.500000
                        1                 0.500000
Sports                  0                 0.647059
                        1                 0.352941
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 1                 0.521739
                     0                 0.478261
Number               0                 0.604651
                     1                 0.395349
Other                0                 0.644444
                     1                 0.355556
Person               0                 0.651163
                     1                 0.348837
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.454545  0.545455           11
                       Number               0.666667  0.333333            3
                       Other                1.000000  0.000000            6
                       Person               0.500000  0.500000            8
Geography              Date                 0.625000  0.375000            8
                       Number               0.666667  0.333333            9
                       Other                0.250000  0.750000            4
Misc                   Date                 0.571429  0.428571            7
                       Number               0.333333  0.666667            3
                       Other                0.900000  0.100000           10
                       Person               0.800000  0.200000            5
Music                  Date                 0.400000  0.600000            5
                       Number               0.750000  0.250000            4
                       Other                0.400000  0.600000            5
                       Person               1.000000  0.000000            2
Other                  Date                 0.285714  0.714286            7
                       Number               0.600000  0.400000            5
                       Other                0.500000  0.500000            4
                       Person               0.250000  0.750000            4
Politics               Date                 0.642857  0.357143           14
                       Number               0.333333  0.666667            3
                       Other                0.750000  0.250000            4
                       Person               0.833333  0.166667            6
Science and technology Date                 0.400000  0.600000           15
                       Number               0.444444  0.555556            9
                       Other                0.333333  0.666667            6
                       Person               0.687500  0.312500           16
Sports                 Date                 0.000000  1.000000            2
                       Number               0.857143  0.142857            7
                       Other                0.666667  0.333333            6
                       Person               0.500000  0.500000            2

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  200
Model:                          Logit   Df Residuals:                      188
Method:                           MLE   Df Model:                           11
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                 0.05898
Time:                        20:58:13   Log-Likelihood:                -128.03
converged:                       True   LL-Null:                       -136.06
Covariance Type:            nonrobust   LLR p-value:                    0.1393
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -3.5450      1.888     -1.877      0.060      -7.246       0.156
C(topic_grouped)[T.Geography]                  0.1243      0.615      0.202      0.840      -1.081       1.330
C(topic_grouped)[T.Misc]                      -0.4950      0.607     -0.815      0.415      -1.685       0.695
C(topic_grouped)[T.Music]                      0.2765      0.656      0.422      0.673      -1.009       1.562
C(topic_grouped)[T.Other]                      0.9684      0.621      1.560      0.119      -0.249       2.185
C(topic_grouped)[T.Politics]                  -0.4647      0.583     -0.798      0.425      -1.607       0.677
C(topic_grouped)[T.Science and technology]     0.5025      0.504      0.997      0.319      -0.486       1.491
C(topic_grouped)[T.Sports]                    -0.0895      0.666     -0.134      0.893      -1.395       1.216
C(answer_type_grouped)[T.Number]              -0.6653      0.424     -1.571      0.116      -1.495       0.165
C(answer_type_grouped)[T.Other]               -0.5896      0.417     -1.415      0.157      -1.406       0.227
C(answer_type_grouped)[T.Person]              -0.7236      0.424     -1.705      0.088      -1.556       0.108
q_length                                       0.7762      0.403      1.924      0.054      -0.014       1.567
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 1.3228
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  200
Model:                          Logit   Df Residuals:                      187
Method:                           MLE   Df Model:                           12
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                  0.1493
Time:                        20:58:13   Log-Likelihood:                -115.74
converged:                       True   LL-Null:                       -136.06
Covariance Type:            nonrobust   LLR p-value:                 5.641e-05
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -5.5221      2.113     -2.613      0.009      -9.664      -1.380
C(topic_grouped)[T.Geography]                 -0.0293      0.647     -0.045      0.964      -1.297       1.239
C(topic_grouped)[T.Misc]                      -0.3695      0.645     -0.573      0.567      -1.634       0.895
C(topic_grouped)[T.Music]                      0.5099      0.707      0.721      0.471      -0.875       1.895
C(topic_grouped)[T.Other]                      1.2316      0.685      1.798      0.072      -0.111       2.575
C(topic_grouped)[T.Politics]                  -0.1812      0.636     -0.285      0.776      -1.427       1.065
C(topic_grouped)[T.Science and technology]     0.5178      0.537      0.964      0.335      -0.535       1.570
C(topic_grouped)[T.Sports]                    -0.1449      0.709     -0.204      0.838      -1.534       1.244
C(answer_type_grouped)[T.Number]              -0.3906      0.446     -0.876      0.381      -1.265       0.484
C(answer_type_grouped)[T.Other]               -0.3742      0.449     -0.834      0.404      -1.254       0.505
C(answer_type_grouped)[T.Person]              -0.2743      0.471     -0.582      0.560      -1.198       0.649
q_length                                       0.6339      0.434      1.462      0.144      -0.216       1.484
capabilities_entropy                           1.7024      0.375      4.541      0.000       0.968       2.437
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  200
Model:                          Logit   Df Residuals:                      187
Method:                           MLE   Df Model:                           12
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                  0.1118
Time:                        20:58:13   Log-Likelihood:                -120.85
converged:                       True   LL-Null:                       -136.06
Covariance Type:            nonrobust   LLR p-value:                  0.002421
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -6.2098      2.132     -2.913      0.004     -10.388      -2.032
C(topic_grouped)[T.Geography]                  0.2156      0.639      0.337      0.736      -1.038       1.469
C(topic_grouped)[T.Misc]                      -0.4860      0.624     -0.779      0.436      -1.709       0.737
C(topic_grouped)[T.Music]                      0.4263      0.685      0.622      0.534      -0.917       1.769
C(topic_grouped)[T.Other]                      1.0457      0.649      1.612      0.107      -0.226       2.317
C(topic_grouped)[T.Politics]                  -0.3166      0.608     -0.521      0.603      -1.509       0.876
C(topic_grouped)[T.Science and technology]     0.6075      0.525      1.158      0.247      -0.421       1.636
C(topic_grouped)[T.Sports]                    -0.0508      0.686     -0.074      0.941      -1.395       1.294
C(answer_type_grouped)[T.Number]              -0.8091      0.439     -1.841      0.066      -1.670       0.052
C(answer_type_grouped)[T.Other]               -0.5265      0.434     -1.213      0.225      -1.378       0.325
C(answer_type_grouped)[T.Person]              -0.3228      0.459     -0.703      0.482      -1.223       0.577
q_length                                       0.8716      0.421      2.071      0.038       0.047       1.696
game_entropy                                   1.3937      0.398      3.499      0.000       0.613       2.174
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  200
Model:                          Logit   Df Residuals:                      186
Method:                           MLE   Df Model:                           13
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                  0.1502
Time:                        20:58:13   Log-Likelihood:                -115.62
converged:                       True   LL-Null:                       -136.06
Covariance Type:            nonrobust   LLR p-value:                 9.976e-05
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -5.8332      2.209     -2.640      0.008     -10.164      -1.503
C(topic_grouped)[T.Geography]                  0.0079      0.652      0.012      0.990      -1.270       1.286
C(topic_grouped)[T.Misc]                      -0.3751      0.644     -0.583      0.560      -1.637       0.887
C(topic_grouped)[T.Music]                      0.5186      0.708      0.733      0.464      -0.869       1.906
C(topic_grouped)[T.Other]                      1.2263      0.685      1.791      0.073      -0.116       2.568
C(topic_grouped)[T.Politics]                  -0.1798      0.635     -0.283      0.777      -1.425       1.065
C(topic_grouped)[T.Science and technology]     0.5356      0.538      0.995      0.320      -0.519       1.591
C(topic_grouped)[T.Sports]                    -0.1344      0.708     -0.190      0.849      -1.523       1.254
C(answer_type_grouped)[T.Number]              -0.4496      0.462     -0.973      0.330      -1.355       0.456
C(answer_type_grouped)[T.Other]               -0.3839      0.449     -0.854      0.393      -1.265       0.497
C(answer_type_grouped)[T.Person]              -0.2528      0.474     -0.533      0.594      -1.182       0.676
q_length                                       0.6647      0.438      1.516      0.129      -0.194       1.524
capabilities_entropy                           1.5436      0.493      3.132      0.002       0.578       2.509
game_entropy                                   0.2604      0.530      0.492      0.623      -0.778       1.298
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing claude-3-haiku-20240307 (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/claude-3-haiku-20240307_SimpleMC_redacted_cor_temp0.0_1754173427_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    124
1     27
Name: count, dtype: int64

Answer change%: 0.1788 [0.11768906596126844, 0.23992682807846666] (n=151)
P-value vs 25%: 0.02243; P-value vs 0%: 9.808e-09
Phase 2 self-accuracy: 0.0741 [0.0, 0.17285826494558254] (n=27)
P-value vs 25%: 0.0004821; P-value vs 33%: 2.787e-07

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  151
Model:                          Logit   Df Residuals:                      149
Method:                           MLE   Df Model:                            1
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                 0.05849
Time:                        20:58:13   Log-Likelihood:                -66.760
converged:                       True   LL-Null:                       -70.907
Covariance Type:            nonrobust   LLR p-value:                  0.003977
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          2.0996      1.229      1.708      0.088      -0.310       4.509
p_i_capability    -4.1053      1.395     -2.943      0.003      -6.840      -1.371
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  151
Model:                          Logit   Df Residuals:                      149
Method:                           MLE   Df Model:                            1
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                 0.07001
Time:                        20:58:13   Log-Likelihood:                -65.943
converged:                       True   LL-Null:                       -70.907
Covariance Type:            nonrobust   LLR p-value:                  0.001628
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.5813      0.422     -6.123      0.000      -3.408      -1.755
capabilities_entropy     2.1784      0.691      3.154      0.002       0.825       3.532
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.3704 [0.1882, 0.5525] (n=27)
                  P-value vs 33.3%: 0.6902

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=-0.60, p=0.55
Wilcoxon delta_p: statistic=524.00, p=0.378
Mean Δp = -0.0073  [-0.0311, 0.0165]
Idea 1 N = 124; 

  Idea 1.5: Calibration Metrics
  NLL: 0.1291, Signed ECE (overconf pos under neg): -0.1033, ECE: 0.1033 (n=151)
  Brier: 0.0321, Reliability (absolute calibration error; lower better): 0.0319, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=151)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.872
Model:                            OLS   Adj. R-squared:                  0.869
Method:                 Least Squares   F-statistic:                     334.1
Date:                Tue, 26 Aug 2025   Prob (F-statistic):           2.07e-65
Time:                        20:58:13   Log-Likelihood:                 122.73
No. Observations:                 151   AIC:                            -237.5
Df Residuals:                     147   BIC:                            -225.4
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.8486      0.086     -9.870      0.000      -1.019      -0.679
p1                    0.9164      0.093      9.849      0.000       0.733       1.100
answer_changed        0.9107      0.130      7.004      0.000       0.654       1.168
p1:answer_changed    -0.1833      0.148     -1.243      0.216      -0.475       0.108
==============================================================================
Omnibus:                       56.469   Durbin-Watson:                   2.146
Prob(Omnibus):                  0.000   Jarque-Bera (JB):              147.529
Skew:                           1.539   Prob(JB):                     9.22e-33
Kurtosis:                       6.738   Cond. No.                         33.5
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-1.48, p=0.14
Wilcoxon delta_H: statistic=449.00, p=0.104
Mean ΔH = -0.0808  [-0.1874, 0.0259]
Paired t-test delta_H Changed: statistic=6.19, p=1.5e-06
Wilcoxon delta_H Changed: statistic=21.00, p=5.25e-05
Mean ΔH Changed = 0.7561  [0.5169, 0.9954]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=-0.70, p=0.482
Wilcoxon (p_top2_game vs p_top2_base): statistic=929.00, p=0.0958
Mean Δp_top2 = -0.0028  [-0.0106, 0.0050] (n=151)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=1.23, p=0.221
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=1242.00, p=0.252
Mean ΔH_unchosen_baseline_set = 0.0689  [-0.0410, 0.1788] (n=151)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  151
Model:                          Logit   Df Residuals:                      148
Method:                           MLE   Df Model:                            2
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                 0.05851
Time:                        20:58:13   Log-Likelihood:                -66.758
converged:                       True   LL-Null:                       -70.907
Covariance Type:            nonrobust   LLR p-value:                   0.01579
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.6158      0.287     -5.628      0.000      -2.179      -1.053
p1_z            -0.4961      0.503     -0.987      0.324      -1.481       0.489
I(p1_z ** 2)     0.0102      0.191      0.054      0.957      -0.364       0.385
================================================================================
AUC = 0.616

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  151
Model:                          Logit   Df Residuals:                      149
Method:                           MLE   Df Model:                            1
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                  0.1956
Time:                        20:58:13   Log-Likelihood:                -57.040
converged:                       True   LL-Null:                       -70.907
Covariance Type:            nonrobust   LLR p-value:                 1.392e-07
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -3.3551      0.476     -7.042      0.000      -4.289      -2.421
game_entropy     3.4579      0.713      4.849      0.000       2.060       4.856
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=1165.00, p=0.799
Paired t-test (game_entropy vs capabilities_entropy): statistic=0.44, p=0.662
Mean capabilities_entropy-game_entropy = -0.0134  [-0.0733, 0.0465] (n=151)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  151
Model:                          Logit   Df Residuals:                      148
Method:                           MLE   Df Model:                            2
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                  0.2609
Time:                        20:58:13   Log-Likelihood:                -52.409
converged:                       True   LL-Null:                       -70.907
Covariance Type:            nonrobust   LLR p-value:                 9.262e-09
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -4.6054      0.707     -6.514      0.000      -5.991      -3.220
capabilities_entropy     2.3533      0.765      3.077      0.002       0.855       3.852
game_entropy             3.5802      0.754      4.746      0.000       2.102       5.059
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['Video games', 'Sports', 'History', 'TV shows']
                  Grouped rare answer_type into 'Misc'/'Other': None
topic_grouped           answer_changed
Art                     0                 0.800000
                        1                 0.200000
Geography               0                 0.571429
                        1                 0.428571
Misc                    0                 0.814815
                        1                 0.185185
Music                   0                 0.909091
                        1                 0.090909
Other                   0                 0.714286
                        1                 0.285714
Politics                0                 0.913043
                        1                 0.086957
Science and technology  0                 0.933333
                        1                 0.066667
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.730769
                     1                 0.269231
Number               0                 0.733333
                     1                 0.266667
Other                0                 0.897436
                     1                 0.102564
Person               0                 0.870968
                     1                 0.129032
Place                0                 0.928571
                     1                 0.071429
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.500000  0.500000            6
                       Number               1.000000  0.000000            1
                       Other                0.800000  0.200000            5
                       Person               0.909091  0.090909           11
                       Place                1.000000  0.000000            2
Geography              Date                 0.000000  1.000000            2
                       Number               0.500000  0.500000            6
                       Other                1.000000  0.000000            3
                       Place                0.666667  0.333333            3
Misc                   Date                 0.777778  0.222222            9
                       Number               1.000000  0.000000            3
                       Other                0.875000  0.125000            8
                       Person               0.600000  0.400000            5
                       Place                1.000000  0.000000            2
Music                  Date                 0.800000  0.200000            5
                       Other                1.000000  0.000000            3
                       Person               1.000000  0.000000            3
Other                  Date                 0.700000  0.300000           10
                       Number               1.000000  0.000000            1
                       Other                0.500000  0.500000            4
                       Person               0.750000  0.250000            4
                       Place                1.000000  0.000000            2
Politics               Date                 0.875000  0.125000            8
                       Number               0.000000  1.000000            1
                       Other                1.000000  0.000000            6
                       Person               1.000000  0.000000            4
                       Place                1.000000  0.000000            4
Science and technology Date                 0.833333  0.166667           12
                       Number               1.000000  0.000000            3
                       Other                1.000000  0.000000           10
                       Person               1.000000  0.000000            4
                       Place                1.000000  0.000000            1

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  151
Model:                          Logit   Df Residuals:                      139
Method:                           MLE   Df Model:                           11
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                  0.1593
Time:                        20:58:13   Log-Likelihood:                -59.609
converged:                       True   LL-Null:                       -70.907
Covariance Type:            nonrobust   LLR p-value:                   0.02014
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      4.2291      3.197      1.323      0.186      -2.037      10.495
C(topic_grouped)[T.Geography]                  1.3462      0.911      1.478      0.139      -0.439       3.131
C(topic_grouped)[T.Misc]                      -0.1695      0.749     -0.226      0.821      -1.637       1.298
C(topic_grouped)[T.Music]                     -1.1478      1.201     -0.955      0.339      -3.503       1.207
C(topic_grouped)[T.Other]                      0.2370      0.749      0.316      0.752      -1.231       1.705
C(topic_grouped)[T.Politics]                  -0.8091      0.944     -0.858      0.391      -2.658       1.040
C(topic_grouped)[T.Science and technology]    -1.3061      0.942     -1.386      0.166      -3.153       0.541
C(answer_type_grouped)[T.Number]              -0.6007      0.880     -0.682      0.495      -2.326       1.125
C(answer_type_grouped)[T.Other]               -1.5112      0.675     -2.239      0.025      -2.834      -0.188
C(answer_type_grouped)[T.Person]              -0.9859      0.668     -1.475      0.140      -2.296       0.324
C(answer_type_grouped)[T.Place]               -2.1337      1.190     -1.794      0.073      -4.465       0.198
q_length                                      -1.0870      0.714     -1.523      0.128      -2.486       0.312
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.4401
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  151
Model:                          Logit   Df Residuals:                      138
Method:                           MLE   Df Model:                           12
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                  0.2107
Time:                        20:58:13   Log-Likelihood:                -55.964
converged:                       True   LL-Null:                       -70.907
Covariance Type:            nonrobust   LLR p-value:                  0.002905
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      2.0862      3.507      0.595      0.552      -4.787       8.960
C(topic_grouped)[T.Geography]                  1.2866      0.963      1.336      0.182      -0.601       3.174
C(topic_grouped)[T.Misc]                      -0.1941      0.795     -0.244      0.807      -1.752       1.364
C(topic_grouped)[T.Music]                     -1.5440      1.302     -1.186      0.236      -4.096       1.008
C(topic_grouped)[T.Other]                      0.1792      0.781      0.229      0.819      -1.352       1.710
C(topic_grouped)[T.Politics]                  -1.0527      1.020     -1.032      0.302      -3.052       0.947
C(topic_grouped)[T.Science and technology]    -1.3995      0.976     -1.434      0.152      -3.313       0.514
C(answer_type_grouped)[T.Number]              -0.8045      0.955     -0.842      0.400      -2.676       1.067
C(answer_type_grouped)[T.Other]               -1.2957      0.690     -1.879      0.060      -2.647       0.056
C(answer_type_grouped)[T.Person]              -0.8594      0.696     -1.235      0.217      -2.223       0.504
C(answer_type_grouped)[T.Place]               -2.4607      1.247     -1.974      0.048      -4.904      -0.017
q_length                                      -0.8358      0.769     -1.087      0.277      -2.342       0.671
capabilities_entropy                           2.2412      0.866      2.587      0.010       0.543       3.939
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  151
Model:                          Logit   Df Residuals:                      138
Method:                           MLE   Df Model:                           12
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                  0.3537
Time:                        20:58:13   Log-Likelihood:                -45.830
converged:                       True   LL-Null:                       -70.907
Covariance Type:            nonrobust   LLR p-value:                 1.313e-06
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      3.7620      3.595      1.046      0.295      -3.284      10.808
C(topic_grouped)[T.Geography]                  1.1110      1.022      1.087      0.277      -0.892       3.114
C(topic_grouped)[T.Misc]                      -0.5655      0.884     -0.640      0.522      -2.298       1.167
C(topic_grouped)[T.Music]                     -1.6200      1.423     -1.138      0.255      -4.409       1.169
C(topic_grouped)[T.Other]                     -0.8702      0.951     -0.915      0.360      -2.734       0.993
C(topic_grouped)[T.Politics]                  -2.2579      1.212     -1.862      0.063      -4.634       0.118
C(topic_grouped)[T.Science and technology]    -1.6951      1.060     -1.599      0.110      -3.773       0.383
C(answer_type_grouped)[T.Number]               0.0430      1.003      0.043      0.966      -1.923       2.009
C(answer_type_grouped)[T.Other]               -1.3449      0.795     -1.692      0.091      -2.903       0.213
C(answer_type_grouped)[T.Person]              -1.0178      0.834     -1.221      0.222      -2.652       0.616
C(answer_type_grouped)[T.Place]               -1.2589      1.282     -0.982      0.326      -3.771       1.253
q_length                                      -1.4171      0.814     -1.740      0.082      -3.013       0.179
game_entropy                                   4.3035      0.994      4.329      0.000       2.355       6.252
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  151
Model:                          Logit   Df Residuals:                      137
Method:                           MLE   Df Model:                           13
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                  0.3937
Time:                        20:58:13   Log-Likelihood:                -42.991
converged:                       True   LL-Null:                       -70.907
Covariance Type:            nonrobust   LLR p-value:                 2.887e-07
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      1.6693      3.856      0.433      0.665      -5.889       9.227
C(topic_grouped)[T.Geography]                  1.1444      1.101      1.039      0.299      -1.014       3.303
C(topic_grouped)[T.Misc]                      -0.5945      0.947     -0.628      0.530      -2.451       1.262
C(topic_grouped)[T.Music]                     -1.6502      1.379     -1.197      0.231      -4.353       1.052
C(topic_grouped)[T.Other]                     -0.8392      0.976     -0.860      0.390      -2.752       1.073
C(topic_grouped)[T.Politics]                  -2.4242      1.263     -1.919      0.055      -4.900       0.052
C(topic_grouped)[T.Science and technology]    -1.6247      1.067     -1.523      0.128      -3.715       0.466
C(answer_type_grouped)[T.Number]              -0.0381      1.095     -0.035      0.972      -2.183       2.107
C(answer_type_grouped)[T.Other]               -1.0597      0.826     -1.283      0.200      -2.679       0.559
C(answer_type_grouped)[T.Person]              -0.8407      0.844     -0.996      0.319      -2.495       0.813
C(answer_type_grouped)[T.Place]               -1.5437      1.373     -1.124      0.261      -4.235       1.148
q_length                                      -1.1995      0.851     -1.409      0.159      -2.868       0.469
capabilities_entropy                           2.1495      0.947      2.270      0.023       0.293       4.006
game_entropy                                   4.3408      1.022      4.246      0.000       2.337       6.345
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing claude-3-haiku-20240307 (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/claude-3-haiku-20240307_SimpleMC_redacted_temp0.0_1754183680_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    253
1     96
Name: count, dtype: int64

Answer change%: 0.2751 [0.2282220396630573, 0.32192122681258745] (n=349)
P-value vs 25%: 0.2942; P-value vs 0%: 1.207e-30
Phase 2 self-accuracy: 0.3438 [0.2487401820076643, 0.4387598179923357] (n=96)
P-value vs 25%: 0.05312; P-value vs 33%: 0.8245

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  349
Model:                          Logit   Df Residuals:                      347
Method:                           MLE   Df Model:                            1
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                 0.03241
Time:                        20:58:13   Log-Likelihood:                -198.64
converged:                       True   LL-Null:                       -205.30
Covariance Type:            nonrobust   LLR p-value:                 0.0002643
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          1.8955      0.787      2.409      0.016       0.353       3.438
p_i_capability    -3.2051      0.875     -3.663      0.000      -4.920      -1.490
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  349
Model:                          Logit   Df Residuals:                      347
Method:                           MLE   Df Model:                            1
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                 0.03280
Time:                        20:58:13   Log-Likelihood:                -198.56
converged:                       True   LL-Null:                       -205.30
Covariance Type:            nonrobust   LLR p-value:                 0.0002427
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.6404      0.224     -7.318      0.000      -2.080      -1.201
capabilities_entropy     1.4480      0.394      3.676      0.000       0.676       2.220
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.2917 [0.2007, 0.3826] (n=96)
                  P-value vs 33.3%: 0.3691

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=0.88, p=0.379
Wilcoxon delta_p: statistic=2777.00, p=0.0896
Mean Δp = 0.0075  [-0.0092, 0.0241]
Idea 1 N = 253; 

  Idea 1.5: Calibration Metrics
  NLL: 4.1953, Signed ECE (overconf pos under neg): 0.0394, ECE: 0.0394 (n=349)
  Brier: 0.0097, Reliability (absolute calibration error; lower better): 0.0095, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=349)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.898
Model:                            OLS   Adj. R-squared:                  0.897
Method:                 Least Squares   F-statistic:                     1013.
Date:                Tue, 26 Aug 2025   Prob (F-statistic):          1.22e-170
Time:                        20:58:13   Log-Likelihood:                 255.98
No. Observations:                 349   AIC:                            -504.0
Df Residuals:                     345   BIC:                            -488.5
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.7557      0.066    -11.391      0.000      -0.886      -0.625
p1                    0.8307      0.072     11.575      0.000       0.690       0.972
answer_changed        0.6078      0.091      6.690      0.000       0.429       0.786
p1:answer_changed     0.1952      0.101      1.936      0.054      -0.003       0.393
==============================================================================
Omnibus:                       41.234   Durbin-Watson:                   2.008
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               65.374
Skew:                           0.738   Prob(JB):                     6.37e-15
Kurtosis:                       4.523   Cond. No.                         35.1
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=1.05, p=0.295
Wilcoxon delta_H: statistic=3025.00, p=0.311
Mean ΔH = 0.0427  [-0.0371, 0.1225]
Paired t-test delta_H Changed: statistic=13.10, p=5.22e-23
Wilcoxon delta_H Changed: statistic=234.00, p=1.87e-14
Mean ΔH Changed = 0.8910  [0.7577, 1.0243]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=-0.31, p=0.761
Wilcoxon (p_top2_game vs p_top2_base): statistic=8305.50, p=0.175
Mean Δp_top2 = -0.0007  [-0.0049, 0.0036] (n=349)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=6.84, p=3.63e-11
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=5563.00, p=1.51e-10
Mean ΔH_unchosen_baseline_set = 0.2760  [0.1969, 0.3551] (n=349)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  349
Model:                          Logit   Df Residuals:                      346
Method:                           MLE   Df Model:                            2
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                 0.03923
Time:                        20:58:13   Log-Likelihood:                -197.24
converged:                       True   LL-Null:                       -205.30
Covariance Type:            nonrobust   LLR p-value:                 0.0003176
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.2387      0.195     -6.342      0.000      -1.621      -0.856
p1_z             0.1423      0.357      0.398      0.691      -0.558       0.843
I(p1_z ** 2)     0.2456      0.153      1.604      0.109      -0.054       0.546
================================================================================
AUC = 0.581

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  349
Model:                          Logit   Df Residuals:                      347
Method:                           MLE   Df Model:                            1
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                  0.1058
Time:                        20:58:13   Log-Likelihood:                -183.58
converged:                       True   LL-Null:                       -205.30
Covariance Type:            nonrobust   LLR p-value:                 4.390e-11
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -2.2785      0.252     -9.039      0.000      -2.773      -1.784
game_entropy     2.4114      0.386      6.241      0.000       1.654       3.169
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=6739.00, p=0.000741
Paired t-test (game_entropy vs capabilities_entropy): statistic=3.06, p=0.00236
Mean capabilities_entropy-game_entropy = -0.0624  [-0.1023, -0.0225] (n=349)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  349
Model:                          Logit   Df Residuals:                      346
Method:                           MLE   Df Model:                            2
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                  0.1211
Time:                        20:58:13   Log-Likelihood:                -180.44
converged:                       True   LL-Null:                       -205.30
Covariance Type:            nonrobust   LLR p-value:                 1.597e-11
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.6924      0.310     -8.674      0.000      -3.301      -2.084
capabilities_entropy     1.0684      0.421      2.536      0.011       0.243       1.894
game_entropy             2.2619      0.393      5.758      0.000       1.492       3.032
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.720000
                        1                 0.280000
Geography               0                 0.600000
                        1                 0.400000
Misc                    0                 0.733333
                        1                 0.266667
Music                   0                 0.724138
                        1                 0.275862
Other                   0                 0.709677
                        1                 0.290323
Politics                0                 0.833333
                        1                 0.166667
Science and technology  0                 0.705882
                        1                 0.294118
Sports                  0                 0.718750
                        1                 0.281250
TV shows                0                 0.720000
                        1                 0.280000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.735043
                     1                 0.264957
Number               0                 0.746032
                     1                 0.253968
Other                0                 0.712500
                     1                 0.287500
Person               0                 0.707865
                     1                 0.292135
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.800000  0.200000           15
                       Number               0.375000  0.625000            8
                       Other                0.636364  0.363636           11
                       Person               0.875000  0.125000           16
Geography              Date                 0.615385  0.384615           13
                       Number               0.666667  0.333333           12
                       Other                0.400000  0.600000            5
Misc                   Date                 0.538462  0.461538           13
                       Number               1.000000  0.000000            5
                       Other                0.857143  0.142857            7
                       Person               0.800000  0.200000            5
Music                  Date                 0.428571  0.571429            7
                       Number               1.000000  0.000000            4
                       Other                0.777778  0.222222            9
                       Person               0.777778  0.222222            9
Other                  Date                 0.875000  0.125000            8
                       Number               0.833333  0.166667            6
                       Other                0.500000  0.500000            8
                       Person               0.666667  0.333333            9
Politics               Date                 0.892857  0.107143           28
                       Number               0.800000  0.200000            5
                       Other                0.900000  0.100000           10
                       Person               0.636364  0.363636           11
Science and technology Date                 0.782609  0.217391           23
                       Number               0.727273  0.272727           11
                       Other                0.875000  0.125000            8
                       Person               0.576923  0.423077           26
Sports                 Date                 0.625000  0.375000            8
                       Number               0.818182  0.181818           11
                       Other                0.666667  0.333333            9
                       Person               0.750000  0.250000            4
TV shows               Date                 0.500000  0.500000            2
                       Number               1.000000  0.000000            1
                       Other                0.692308  0.307692           13
                       Person               0.777778  0.222222            9

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  349
Model:                          Logit   Df Residuals:                      336
Method:                           MLE   Df Model:                           12
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                 0.01719
Time:                        20:58:13   Log-Likelihood:                -201.77
converged:                       True   LL-Null:                       -205.30
Covariance Type:            nonrobust   LLR p-value:                    0.8536
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.6799      1.543     -1.089      0.276      -4.703       1.344
C(topic_grouped)[T.Geography]                  0.6589      0.504      1.307      0.191      -0.329       1.647
C(topic_grouped)[T.Misc]                      -0.0531      0.523     -0.102      0.919      -1.078       0.972
C(topic_grouped)[T.Music]                     -0.0201      0.524     -0.038      0.969      -1.046       1.006
C(topic_grouped)[T.Other]                      0.0609      0.507      0.120      0.904      -0.933       1.055
C(topic_grouped)[T.Politics]                  -0.6882      0.491     -1.402      0.161      -1.650       0.274
C(topic_grouped)[T.Science and technology]     0.0639      0.415      0.154      0.877      -0.749       0.876
C(topic_grouped)[T.Sports]                     0.0605      0.511      0.119      0.906      -0.941       1.062
C(topic_grouped)[T.TV shows]                  -0.0424      0.556     -0.076      0.939      -1.132       1.047
C(answer_type_grouped)[T.Number]              -0.2152      0.369     -0.583      0.560      -0.939       0.509
C(answer_type_grouped)[T.Other]                0.1055      0.340      0.310      0.756      -0.561       0.772
C(answer_type_grouped)[T.Person]               0.1676      0.331      0.507      0.612      -0.480       0.816
q_length                                       0.1540      0.331      0.466      0.642      -0.494       0.802
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.4433
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  349
Model:                          Logit   Df Residuals:                      335
Method:                           MLE   Df Model:                           13
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                 0.05088
Time:                        20:58:13   Log-Likelihood:                -194.85
converged:                       True   LL-Null:                       -205.30
Covariance Type:            nonrobust   LLR p-value:                   0.07514
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -2.6374      1.612     -1.636      0.102      -5.798       0.523
C(topic_grouped)[T.Geography]                  0.7564      0.516      1.466      0.143      -0.255       1.768
C(topic_grouped)[T.Misc]                      -0.0631      0.534     -0.118      0.906      -1.110       0.984
C(topic_grouped)[T.Music]                     -0.0826      0.541     -0.153      0.879      -1.142       0.977
C(topic_grouped)[T.Other]                      0.0442      0.520      0.085      0.932      -0.975       1.063
C(topic_grouped)[T.Politics]                  -0.6481      0.499     -1.298      0.194      -1.626       0.330
C(topic_grouped)[T.Science and technology]     0.0468      0.424      0.110      0.912      -0.784       0.877
C(topic_grouped)[T.Sports]                    -0.0210      0.523     -0.040      0.968      -1.046       1.004
C(topic_grouped)[T.TV shows]                  -0.0508      0.567     -0.089      0.929      -1.162       1.061
C(answer_type_grouped)[T.Number]              -0.1735      0.377     -0.460      0.646      -0.913       0.566
C(answer_type_grouped)[T.Other]                0.1352      0.348      0.389      0.697      -0.546       0.816
C(answer_type_grouped)[T.Person]               0.2726      0.341      0.800      0.423      -0.395       0.940
q_length                                       0.2042      0.341      0.599      0.549      -0.464       0.872
capabilities_entropy                           1.4985      0.405      3.700      0.000       0.705       2.292
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  349
Model:                          Logit   Df Residuals:                      335
Method:                           MLE   Df Model:                           13
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                  0.1296
Time:                        20:58:13   Log-Likelihood:                -178.68
converged:                       True   LL-Null:                       -205.30
Covariance Type:            nonrobust   LLR p-value:                 8.260e-07
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -3.9283      1.731     -2.270      0.023      -7.320      -0.536
C(topic_grouped)[T.Geography]                  0.8341      0.546      1.526      0.127      -0.237       1.905
C(topic_grouped)[T.Misc]                       0.1279      0.562      0.228      0.820      -0.973       1.229
C(topic_grouped)[T.Music]                      0.1111      0.579      0.192      0.848      -1.023       1.245
C(topic_grouped)[T.Other]                      0.4776      0.545      0.877      0.381      -0.590       1.545
C(topic_grouped)[T.Politics]                  -0.6858      0.525     -1.305      0.192      -1.716       0.344
C(topic_grouped)[T.Science and technology]     0.2485      0.445      0.558      0.577      -0.624       1.121
C(topic_grouped)[T.Sports]                    -0.0719      0.557     -0.129      0.897      -1.163       1.019
C(topic_grouped)[T.TV shows]                  -0.2836      0.623     -0.455      0.649      -1.504       0.937
C(answer_type_grouped)[T.Number]              -0.4394      0.396     -1.108      0.268      -1.216       0.338
C(answer_type_grouped)[T.Other]               -0.1621      0.370     -0.438      0.661      -0.888       0.563
C(answer_type_grouped)[T.Person]               0.0010      0.355      0.003      0.998      -0.695       0.697
q_length                                       0.3465      0.363      0.954      0.340      -0.365       1.058
game_entropy                                   2.6446      0.420      6.293      0.000       1.821       3.468
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  349
Model:                          Logit   Df Residuals:                      334
Method:                           MLE   Df Model:                           14
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                  0.1446
Time:                        20:58:13   Log-Likelihood:                -175.60
converged:                       True   LL-Null:                       -205.30
Covariance Type:            nonrobust   LLR p-value:                 1.504e-07
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -4.4099      1.766     -2.497      0.013      -7.872      -0.948
C(topic_grouped)[T.Geography]                  0.8725      0.548      1.591      0.112      -0.202       1.947
C(topic_grouped)[T.Misc]                       0.1055      0.564      0.187      0.852      -1.001       1.212
C(topic_grouped)[T.Music]                      0.0369      0.590      0.063      0.950      -1.120       1.194
C(topic_grouped)[T.Other]                      0.4250      0.548      0.776      0.438      -0.649       1.499
C(topic_grouped)[T.Politics]                  -0.6724      0.527     -1.275      0.202      -1.706       0.361
C(topic_grouped)[T.Science and technology]     0.2118      0.448      0.473      0.636      -0.666       1.089
C(topic_grouped)[T.Sports]                    -0.1405      0.563     -0.249      0.803      -1.245       0.963
C(topic_grouped)[T.TV shows]                  -0.3050      0.634     -0.481      0.630      -1.547       0.937
C(answer_type_grouped)[T.Number]              -0.3915      0.399     -0.980      0.327      -1.174       0.391
C(answer_type_grouped)[T.Other]               -0.1437      0.371     -0.387      0.699      -0.872       0.584
C(answer_type_grouped)[T.Person]               0.0778      0.364      0.214      0.831      -0.636       0.791
q_length                                       0.3587      0.368      0.974      0.330      -0.363       1.080
capabilities_entropy                           1.0930      0.437      2.504      0.012       0.237       1.949
game_entropy                                   2.4834      0.428      5.805      0.000       1.645       3.322
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing claude-3-sonnet-20240229 (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/claude-3-sonnet-20240229_SimpleMC_redacted_cor_temp0.0_1751757346_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    72
1    31
Name: count, dtype: int64

Answer change%: 0.3010 [0.21239012459732437, 0.3895516229754911] (n=103)
P-value vs 25%: 0.2594; P-value vs 0%: 2.75e-11
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=45)
P-value vs 25%: 0; P-value vs 33%: 0

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  103
Model:                          Logit   Df Residuals:                      101
Method:                           MLE   Df Model:                            1
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                  0.2813
Time:                        20:58:13   Log-Likelihood:                -45.281
converged:                       True   LL-Null:                       -63.004
Covariance Type:            nonrobust   LLR p-value:                 2.625e-09
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          4.2926      1.030      4.169      0.000       2.274       6.311
p_i_capability    -7.9623      1.656     -4.807      0.000     -11.209      -4.716
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  103
Model:                          Logit   Df Residuals:                      101
Method:                           MLE   Df Model:                            1
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                  0.2596
Time:                        20:58:13   Log-Likelihood:                -46.649
converged:                       True   LL-Null:                       -63.004
Covariance Type:            nonrobust   LLR p-value:                 1.070e-08
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -4.7674      1.007     -4.733      0.000      -6.741      -2.793
capabilities_entropy     3.2495      0.734      4.426      0.000       1.810       4.688
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.3226 [0.1580, 0.4871] (n=31)
                  P-value vs 33.3%: 0.8981
                  Grouped rare topic into 'Misc'/'Other': ['History', 'Video games', 'TV shows']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.750000
                        1                 0.250000
Geography               0                 0.545455
                        1                 0.454545
Misc                    0                 1.000000
Music                   0                 0.777778
                        1                 0.222222
Other                   0                 0.857143
                        1                 0.142857
Politics                0                 0.642857
                        1                 0.357143
Science and technology  0                 0.571429
                        1                 0.428571
Sports                  0                 0.571429
                        1                 0.428571
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.615385
                     1                 0.384615
Number               0                 0.625000
                     1                 0.375000
Other                0                 0.846154
                     1                 0.153846
Person               0                 0.727273
                     1                 0.272727
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.500000  0.500000            6
                       Number               1.000000  0.000000            3
                       Other                1.000000  0.000000            4
                       Person               0.727273  0.272727           11
Geography              Date                 0.333333  0.666667            3
                       Number               0.600000  0.400000            5
                       Other                0.666667  0.333333            3
Misc                   Date                 1.000000  0.000000            6
                       Number               1.000000  0.000000            2
                       Other                1.000000  0.000000            2
Music                  Date                 1.000000  0.000000            3
                       Number               0.000000  1.000000            1
                       Other                1.000000  0.000000            3
                       Person               0.500000  0.500000            2
Other                  Date                 1.000000  0.000000            3
                       Other                0.666667  0.333333            3
                       Person               1.000000  0.000000            1
Politics               Date                 0.428571  0.571429            7
                       Other                0.800000  0.200000            5
                       Person               1.000000  0.000000            2
Science and technology Date                 0.500000  0.500000           10
                       Number               0.500000  0.500000            4
                       Other                1.000000  0.000000            4
                       Person               0.333333  0.666667            3
Sports                 Date                 0.000000  1.000000            1
                       Number               0.000000  1.000000            1
                       Other                0.500000  0.500000            2
                       Person               1.000000  0.000000            3

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  103
Model:                          Logit   Df Residuals:                       91
Method:                           MLE   Df Model:                           11
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                  0.1408
Time:                        20:58:13   Log-Likelihood:                -54.135
converged:                      False   LL-Null:                       -63.004
Covariance Type:            nonrobust   LLR p-value:                   0.08787
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.1646      2.873     -0.405      0.685      -6.796       4.467
C(topic_grouped)[T.Geography]                  0.8828      0.855      1.033      0.302      -0.793       2.559
C(topic_grouped)[T.Misc]                     -36.2788   3.55e+07  -1.02e-06      1.000   -6.95e+07    6.95e+07
C(topic_grouped)[T.Music]                     -0.1123      0.965     -0.116      0.907      -2.004       1.780
C(topic_grouped)[T.Other]                     -0.6922      1.229     -0.563      0.573      -3.100       1.716
C(topic_grouped)[T.Politics]                   0.4759      0.805      0.591      0.555      -1.102       2.054
C(topic_grouped)[T.Science and technology]     0.6441      0.693      0.929      0.353      -0.715       2.003
C(topic_grouped)[T.Sports]                     1.0102      0.928      1.088      0.277      -0.809       2.830
C(answer_type_grouped)[T.Number]              -0.3444      0.712     -0.484      0.628      -1.739       1.050
C(answer_type_grouped)[T.Other]               -1.4414      0.676     -2.132      0.033      -2.766      -0.116
C(answer_type_grouped)[T.Person]              -0.6881      0.654     -1.052      0.293      -1.970       0.594
q_length                                       0.1369      0.622      0.220      0.826      -1.083       1.357
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 1.0570
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  103
Model:                          Logit   Df Residuals:                       90
Method:                           MLE   Df Model:                           12
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                  0.3885
Time:                        20:58:13   Log-Likelihood:                -38.524
converged:                      False   LL-Null:                       -63.004
Covariance Type:            nonrobust   LLR p-value:                 2.127e-06
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -7.5113      3.728     -2.015      0.044     -14.818      -0.205
C(topic_grouped)[T.Geography]                  2.1552      1.085      1.987      0.047       0.030       4.281
C(topic_grouped)[T.Misc]                     -18.4557   6356.270     -0.003      0.998   -1.25e+04    1.24e+04
C(topic_grouped)[T.Music]                      1.1908      1.190      1.000      0.317      -1.142       3.524
C(topic_grouped)[T.Other]                      1.0080      1.465      0.688      0.492      -1.864       3.880
C(topic_grouped)[T.Politics]                   1.4511      1.060      1.369      0.171      -0.626       3.528
C(topic_grouped)[T.Science and technology]     1.6025      0.910      1.760      0.078      -0.182       3.387
C(topic_grouped)[T.Sports]                     1.4324      1.062      1.348      0.178      -0.650       3.514
C(answer_type_grouped)[T.Number]              -0.8913      0.840     -1.061      0.289      -2.538       0.755
C(answer_type_grouped)[T.Other]               -1.0660      0.914     -1.166      0.244      -2.858       0.726
C(answer_type_grouped)[T.Person]              -0.1953      0.785     -0.249      0.804      -1.734       1.343
q_length                                       0.2327      0.749      0.311      0.756      -1.235       1.701
capabilities_entropy                           4.0661      1.012      4.017      0.000       2.082       6.050
==============================================================================================================

                  Model 6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length (after removing deterministic categories: defaultdict(<class 'list'>, {'topic_grouped': ['Misc']}))
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                   93
Model:                          Logit   Df Residuals:                       82
Method:                           MLE   Df Model:                           10
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                 0.08550
Time:                        20:58:13   Log-Likelihood:                -54.135
converged:                       True   LL-Null:                       -59.196
Covariance Type:            nonrobust   LLR p-value:                    0.4298
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.1646      2.873     -0.405      0.685      -6.796       4.467
C(topic_grouped)[T.Geography]                  0.8828      0.855      1.033      0.302      -0.793       2.559
C(topic_grouped)[T.Music]                     -0.1123      0.965     -0.116      0.907      -2.004       1.780
C(topic_grouped)[T.Other]                     -0.6922      1.229     -0.563      0.573      -3.100       1.716
C(topic_grouped)[T.Politics]                   0.4759      0.805      0.591      0.555      -1.102       2.054
C(topic_grouped)[T.Science and technology]     0.6441      0.693      0.929      0.353      -0.715       2.003
C(topic_grouped)[T.Sports]                     1.0102      0.928      1.088      0.277      -0.809       2.830
C(answer_type_grouped)[T.Number]              -0.3444      0.712     -0.484      0.628      -1.739       1.050
C(answer_type_grouped)[T.Other]               -1.4414      0.676     -2.132      0.033      -2.766      -0.116
C(answer_type_grouped)[T.Person]              -0.6881      0.654     -1.052      0.293      -1.970       0.594
q_length                                       0.1369      0.622      0.220      0.826      -1.083       1.357
==============================================================================================================

                  Model 6.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                   93
Model:                          Logit   Df Residuals:                       81
Method:                           MLE   Df Model:                           11
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                  0.3492
Time:                        20:58:13   Log-Likelihood:                -38.524
converged:                       True   LL-Null:                       -59.196
Covariance Type:            nonrobust   LLR p-value:                 2.103e-05
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -7.5113      3.728     -2.015      0.044     -14.818      -0.205
C(topic_grouped)[T.Geography]                  2.1552      1.085      1.987      0.047       0.030       4.281
C(topic_grouped)[T.Music]                      1.1908      1.190      1.000      0.317      -1.142       3.524
C(topic_grouped)[T.Other]                      1.0080      1.465      0.688      0.492      -1.864       3.880
C(topic_grouped)[T.Politics]                   1.4511      1.060      1.369      0.171      -0.626       3.528
C(topic_grouped)[T.Science and technology]     1.6025      0.910      1.760      0.078      -0.182       3.387
C(topic_grouped)[T.Sports]                     1.4324      1.062      1.348      0.178      -0.650       3.514
C(answer_type_grouped)[T.Number]              -0.8913      0.840     -1.061      0.289      -2.538       0.755
C(answer_type_grouped)[T.Other]               -1.0660      0.914     -1.166      0.244      -2.858       0.726
C(answer_type_grouped)[T.Person]              -0.1953      0.785     -0.249      0.804      -1.734       1.343
q_length                                       0.2327      0.749      0.311      0.756      -1.235       1.701
capabilities_entropy                           4.0661      1.012      4.017      0.000       2.082       6.050
==============================================================================================================

--- Analyzing claude-3-sonnet-20240229 (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/claude-3-sonnet-20240229_SimpleMC_redacted_temp0.0_1751717606_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    135
1     92
Name: count, dtype: int64

Answer change%: 0.4053 [0.3414202867752806, 0.469152400449389] (n=227)
P-value vs 25%: 1.884e-06; P-value vs 0%: 1.631e-35
Phase 2 self-accuracy: 0.3333 [0.2571283860895982, 0.4095382805770684] (n=147)
P-value vs 25%: 0.03209; P-value vs 33%: 0.9932

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  227
Model:                          Logit   Df Residuals:                      225
Method:                           MLE   Df Model:                            1
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                 0.09670
Time:                        20:58:13   Log-Likelihood:                -138.43
converged:                       True   LL-Null:                       -153.25
Covariance Type:            nonrobust   LLR p-value:                 5.205e-08
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          2.4080      0.556      4.332      0.000       1.319       3.498
p_i_capability    -4.1122      0.804     -5.112      0.000      -5.689      -2.536
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  227
Model:                          Logit   Df Residuals:                      225
Method:                           MLE   Df Model:                            1
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                 0.09490
Time:                        20:58:13   Log-Likelihood:                -138.70
converged:                       True   LL-Null:                       -153.25
Covariance Type:            nonrobust   LLR p-value:                 6.928e-08
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.1787      0.397     -5.487      0.000      -2.957      -1.401
capabilities_entropy     1.5917      0.317      5.027      0.000       0.971       2.212
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.3152 [0.2203, 0.4102] (n=92)
                  P-value vs 33.3%: 0.7084
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': None
topic_grouped           answer_changed
Art                     1                 0.516129
                        0                 0.483871
Geography               0                 0.555556
                        1                 0.444444
Misc                    0                 0.705882
                        1                 0.294118
Music                   0                 0.777778
                        1                 0.222222
Other                   1                 0.583333
                        0                 0.416667
Politics                0                 0.621622
                        1                 0.378378
Science and technology  0                 0.651163
                        1                 0.348837
Sports                  0                 0.500000
                        1                 0.500000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.521127
                     1                 0.478873
Number               1                 0.533333
                     0                 0.466667
Other                0                 0.711538
                     1                 0.288462
Person               0                 0.625000
                     1                 0.375000
Place                0                 0.666667
                     1                 0.333333
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.454545  0.545455           11
                       Number               0.400000  0.600000            5
                       Other                0.714286  0.285714            7
                       Person               0.285714  0.714286            7
                       Place                1.000000  0.000000            1
Geography              Date                 0.571429  0.428571            7
                       Number               0.500000  0.500000            4
                       Other                1.000000  0.000000            1
                       Place                0.500000  0.500000            6
Misc                   Date                 0.555556  0.444444            9
                       Number               1.000000  0.000000            2
                       Other                0.666667  0.333333           12
                       Person               0.800000  0.200000           10
                       Place                1.000000  0.000000            1
Music                  Date                 0.400000  0.600000            5
                       Number               1.000000  0.000000            2
                       Other                0.800000  0.200000            5
                       Person               1.000000  0.000000            5
                       Place                1.000000  0.000000            1
Other                  Date                 0.166667  0.833333            6
                       Number               0.000000  1.000000            2
                       Other                0.833333  0.166667            6
                       Person               0.375000  0.625000            8
                       Place                0.500000  0.500000            2
Politics               Date                 0.800000  0.200000           15
                       Number               0.500000  0.500000            2
                       Other                0.714286  0.285714            7
                       Person               0.250000  0.750000            8
                       Place                0.600000  0.400000            5
Science and technology Date                 0.416667  0.583333           12
                       Number               0.400000  0.600000            5
                       Other                0.750000  0.250000            8
                       Person               0.812500  0.187500           16
                       Place                1.000000  0.000000            2
Sports                 Date                 0.500000  0.500000            6
                       Number               0.375000  0.625000            8
                       Other                0.500000  0.500000            6
                       Person               1.000000  0.000000            2

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  227
Model:                          Logit   Df Residuals:                      214
Method:                           MLE   Df Model:                           12
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                 0.06191
Time:                        20:58:13   Log-Likelihood:                -143.76
converged:                       True   LL-Null:                       -153.25
Covariance Type:            nonrobust   LLR p-value:                   0.08917
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      2.7571      1.820      1.515      0.130      -0.809       6.324
C(topic_grouped)[T.Geography]                 -0.3784      0.633     -0.598      0.550      -1.619       0.862
C(topic_grouped)[T.Misc]                      -0.8002      0.533     -1.503      0.133      -1.844       0.244
C(topic_grouped)[T.Music]                     -1.3256      0.682     -1.945      0.052      -2.661       0.010
C(topic_grouped)[T.Other]                      0.3867      0.561      0.689      0.491      -0.713       1.486
C(topic_grouped)[T.Politics]                  -0.4144      0.514     -0.807      0.420      -1.421       0.593
C(topic_grouped)[T.Science and technology]    -0.6982      0.493     -1.415      0.157      -1.665       0.269
C(topic_grouped)[T.Sports]                    -0.1085      0.579     -0.187      0.851      -1.244       1.027
C(answer_type_grouped)[T.Number]               0.2188      0.463      0.472      0.637      -0.689       1.127
C(answer_type_grouped)[T.Other]               -0.9163      0.411     -2.230      0.026      -1.722      -0.111
C(answer_type_grouped)[T.Person]              -0.4479      0.385     -1.164      0.244      -1.202       0.306
C(answer_type_grouped)[T.Place]               -0.6179      0.580     -1.064      0.287      -1.756       0.520
q_length                                      -0.5338      0.391     -1.364      0.172      -1.301       0.233
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 1.0886
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  227
Model:                          Logit   Df Residuals:                      213
Method:                           MLE   Df Model:                           13
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                  0.1667
Time:                        20:58:13   Log-Likelihood:                -127.70
converged:                       True   LL-Null:                       -153.25
Covariance Type:            nonrobust   LLR p-value:                 1.930e-06
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      1.5126      1.992      0.759      0.448      -2.392       5.417
C(topic_grouped)[T.Geography]                 -0.1094      0.686     -0.160      0.873      -1.454       1.235
C(topic_grouped)[T.Misc]                      -0.7348      0.575     -1.278      0.201      -1.862       0.392
C(topic_grouped)[T.Music]                     -1.3253      0.742     -1.786      0.074      -2.780       0.129
C(topic_grouped)[T.Other]                      0.5766      0.612      0.943      0.346      -0.622       1.775
C(topic_grouped)[T.Politics]                  -0.1786      0.568     -0.315      0.753      -1.291       0.934
C(topic_grouped)[T.Science and technology]    -0.6960      0.543     -1.281      0.200      -1.761       0.369
C(topic_grouped)[T.Sports]                    -0.5458      0.634     -0.861      0.389      -1.788       0.696
C(answer_type_grouped)[T.Number]               0.4888      0.496      0.985      0.325      -0.484       1.461
C(answer_type_grouped)[T.Other]               -1.0124      0.443     -2.288      0.022      -1.880      -0.145
C(answer_type_grouped)[T.Person]               0.0339      0.430      0.079      0.937      -0.808       0.876
C(answer_type_grouped)[T.Place]               -0.7525      0.625     -1.205      0.228      -1.977       0.472
q_length                                      -0.7657      0.433     -1.770      0.077      -1.614       0.082
capabilities_entropy                           1.8780      0.362      5.187      0.000       1.168       2.588
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing claude-sonnet-4-20250514 (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/claude-sonnet-4-20250514_SimpleMC_redacted_cor_temp0.0_1751759842_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    155
1     64
Name: count, dtype: int64

Answer change%: 0.2922 [0.2320039907301435, 0.35247089511460533] (n=219)
P-value vs 25%: 0.1693; P-value vs 0%: 1.92e-21
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=64)
P-value vs 25%: 0; P-value vs 33%: 0
                  Grouped rare topic into 'Misc'/'Other': ['History', 'TV shows', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': None
topic_grouped           answer_changed
Art                     0                 0.815789
                        1                 0.184211
Geography               0                 0.619048
                        1                 0.380952
Misc                    0                 0.828571
                        1                 0.171429
Music                   0                 0.809524
                        1                 0.190476
Other                   0                 0.666667
                        1                 0.333333
Politics                0                 0.645161
                        1                 0.354839
Science and technology  0                 0.650000
                        1                 0.350000
Sports                  1                 0.533333
                        0                 0.466667
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.671053
                     1                 0.328947
Number               0                 0.612903
                     1                 0.387097
Other                0                 0.784314
                     1                 0.215686
Person               0                 0.760870
                     1                 0.239130
Place                0                 0.666667
                     1                 0.333333
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.666667  0.333333            9
                       Number               1.000000  0.000000            3
                       Other                1.000000  0.000000            8
                       Person               0.800000  0.200000           15
                       Place                0.666667  0.333333            3
Geography              Date                 0.250000  0.750000            4
                       Number               0.666667  0.333333            9
                       Other                1.000000  0.000000            3
                       Place                0.600000  0.400000            5
Misc                   Date                 0.846154  0.153846           13
                       Number               1.000000  0.000000            4
                       Other                0.692308  0.307692           13
                       Person               1.000000  0.000000            4
                       Place                1.000000  0.000000            1
Music                  Date                 0.875000  0.125000            8
                       Number               0.333333  0.666667            3
                       Other                1.000000  0.000000            2
                       Person               1.000000  0.000000            7
                       Place                0.000000  1.000000            1
Other                  Date                 0.500000  0.500000            6
                       Number               0.500000  0.500000            4
                       Other                0.750000  0.250000            4
                       Person               1.000000  0.000000            3
                       Place                1.000000  0.000000            1
Politics               Date                 0.666667  0.333333           15
                       Number               0.000000  1.000000            1
                       Other                0.800000  0.200000            5
                       Person               0.428571  0.571429            7
                       Place                1.000000  0.000000            3
Science and technology Date                 0.647059  0.352941           17
                       Number               0.500000  0.500000            4
                       Other                0.750000  0.250000           12
                       Person               0.666667  0.333333            6
                       Place                0.000000  1.000000            1
Sports                 Date                 0.500000  0.500000            4
                       Number               0.333333  0.666667            3
                       Other                0.500000  0.500000            4
                       Person               0.500000  0.500000            4

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  219
Model:                          Logit   Df Residuals:                      206
Method:                           MLE   Df Model:                           12
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                 0.06208
Time:                        20:58:13   Log-Likelihood:                -124.09
converged:                       True   LL-Null:                       -132.31
Covariance Type:            nonrobust   LLR p-value:                    0.1725
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      0.7720      1.902      0.406      0.685      -2.956       4.500
C(topic_grouped)[T.Geography]                  0.7513      0.656      1.146      0.252      -0.534       2.036
C(topic_grouped)[T.Misc]                      -0.0925      0.629     -0.147      0.883      -1.325       1.140
C(topic_grouped)[T.Music]                     -0.0722      0.704     -0.103      0.918      -1.451       1.307
C(topic_grouped)[T.Other]                      0.6066      0.673      0.901      0.368      -0.713       1.926
C(topic_grouped)[T.Politics]                   0.9553      0.585      1.632      0.103      -0.192       2.103
C(topic_grouped)[T.Science and technology]     0.8830      0.551      1.603      0.109      -0.197       1.963
C(topic_grouped)[T.Sports]                     1.5514      0.678      2.288      0.022       0.222       2.881
C(answer_type_grouped)[T.Number]               0.2174      0.482      0.451      0.652      -0.726       1.161
C(answer_type_grouped)[T.Other]               -0.6122      0.436     -1.404      0.160      -1.467       0.243
C(answer_type_grouped)[T.Person]              -0.3787      0.450     -0.842      0.400      -1.260       0.503
C(answer_type_grouped)[T.Place]                0.0553      0.633      0.087      0.930      -1.184       1.295
q_length                                      -0.4545      0.413     -1.100      0.271      -1.264       0.355
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing claude-sonnet-4-20250514 (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/claude-sonnet-4-20250514_SimpleMC_redacted_temp0.0_1751719035_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
1    181
0    100
Name: count, dtype: int64

Answer change%: 0.6441 [0.5881487577930817, 0.7001074699649255] (n=281)
P-value vs 25%: 2.573e-43; P-value vs 0%: 1.272e-112
Phase 2 self-accuracy: 0.4917 [0.41888122543484535, 0.5645441889297955] (n=181)
P-value vs 25%: 7.784e-11; P-value vs 33%: 1.945e-05
                  Grouped rare topic into 'Misc'/'Other': ['History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     1                 0.702703
                        0                 0.297297
Geography               1                 0.565217
                        0                 0.434783
Misc                    1                 0.550000
                        0                 0.450000
Music                   1                 0.578947
                        0                 0.421053
Other                   1                 0.823529
                        0                 0.176471
Politics                1                 0.673913
                        0                 0.326087
Science and technology  0                 0.534483
                        1                 0.465517
Sports                  1                 0.680000
                        0                 0.320000
TV shows                1                 0.894737
                        0                 0.105263
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 1                 0.569892
                     0                 0.430108
Number               1                 0.638298
                     0                 0.361702
Other                1                 0.716418
                     0                 0.283582
Person               1                 0.675676
                     0                 0.324324
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.666667  0.333333           12
                       Number               0.166667  0.833333            6
                       Other                0.285714  0.714286            7
                       Person               0.000000  1.000000           12
Geography              Date                 0.454545  0.545455           11
                       Number               0.444444  0.555556            9
                       Other                0.333333  0.666667            3
Misc                   Date                 0.444444  0.555556            9
                       Number               0.250000  0.750000            4
                       Other                0.500000  0.500000            4
                       Person               0.666667  0.333333            3
Music                  Date                 0.250000  0.750000            4
                       Number               1.000000  0.000000            1
                       Other                0.444444  0.555556            9
                       Person               0.400000  0.600000            5
Other                  Date                 0.166667  0.833333           12
                       Number               0.000000  1.000000            3
                       Other                0.111111  0.888889            9
                       Person               0.300000  0.700000           10
Politics               Date                 0.380952  0.619048           21
                       Number               0.000000  1.000000            5
                       Other                0.333333  0.666667           12
                       Person               0.375000  0.625000            8
Science and technology Date                 0.666667  0.333333           18
                       Number               0.600000  0.400000           10
                       Other                0.333333  0.666667            6
                       Person               0.458333  0.541667           24
Sports                 Date                 0.000000  1.000000            5
                       Number               0.500000  0.500000            8
                       Other                0.250000  0.750000            8
                       Person               0.500000  0.500000            4
TV shows               Date                 0.000000  1.000000            1
                       Number               0.000000  1.000000            1
                       Other                0.111111  0.888889            9
                       Person               0.125000  0.875000            8

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  281
Model:                          Logit   Df Residuals:                      268
Method:                           MLE   Df Model:                           12
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                 0.06840
Time:                        20:58:13   Log-Likelihood:                -170.42
converged:                       True   LL-Null:                       -182.93
Covariance Type:            nonrobust   LLR p-value:                   0.01470
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      1.8370      1.680      1.093      0.274      -1.456       5.130
C(topic_grouped)[T.Geography]                 -0.5521      0.571     -0.967      0.334      -1.672       0.567
C(topic_grouped)[T.Misc]                      -0.5744      0.583     -0.986      0.324      -1.717       0.568
C(topic_grouped)[T.Music]                     -0.6319      0.599     -1.054      0.292      -1.807       0.543
C(topic_grouped)[T.Other]                      0.7131      0.580      1.229      0.219      -0.424       1.850
C(topic_grouped)[T.Politics]                  -0.0307      0.488     -0.063      0.950      -0.987       0.926
C(topic_grouped)[T.Science and technology]    -0.9925      0.451     -2.201      0.028      -1.876      -0.109
C(topic_grouped)[T.Sports]                    -0.1326      0.569     -0.233      0.816      -1.248       0.982
C(topic_grouped)[T.TV shows]                   1.1218      0.840      1.336      0.182      -0.524       2.768
C(answer_type_grouped)[T.Number]               0.4025      0.390      1.033      0.301      -0.361       1.166
C(answer_type_grouped)[T.Other]                0.4397      0.368      1.194      0.233      -0.282       1.162
C(answer_type_grouped)[T.Person]               0.4146      0.358      1.158      0.247      -0.287       1.116
q_length                                      -0.2797      0.360     -0.777      0.437      -0.985       0.426
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing deepseek-chat (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/deepseek-chat_SimpleMC_redacted_cor_temp0.0_1753737594_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    218
1     43
Name: count, dtype: int64

Answer change%: 0.1648 [0.11974709374965062, 0.20975482195916165] (n=261)
P-value vs 25%: 0.0002051; P-value vs 0%: 7.227e-13
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=43)
P-value vs 25%: 0; P-value vs 33%: 0

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  261
Model:                          Logit   Df Residuals:                      259
Method:                           MLE   Df Model:                            1
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                  0.2002
Time:                        20:58:13   Log-Likelihood:                -93.402
converged:                       True   LL-Null:                       -116.79
Covariance Type:            nonrobust   LLR p-value:                 7.974e-12
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          5.8367      1.207      4.837      0.000       3.472       8.202
p_i_capability    -8.4418      1.362     -6.198      0.000     -11.111      -5.772
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  261
Model:                          Logit   Df Residuals:                      259
Method:                           MLE   Df Model:                            1
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                  0.1897
Time:                        20:58:13   Log-Likelihood:                -94.634
converged:                       True   LL-Null:                       -116.79
Covariance Type:            nonrobust   LLR p-value:                 2.805e-11
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -3.3796      0.361     -9.358      0.000      -4.087      -2.672
capabilities_entropy     3.5372      0.583      6.063      0.000       2.394       4.681
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.6047 [0.4585, 0.7508] (n=43)
                  P-value vs 33.3%: 0.0002738

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=-1.50, p=0.135
Wilcoxon delta_p: statistic=636.00, p=0.261
Mean Δp = -0.0080  [-0.0184, 0.0025]
Idea 1 N = 218; 

  Idea 1.5: Calibration Metrics
  NLL: 0.1026, Signed ECE (overconf pos under neg): -0.0880, ECE: 0.0880 (n=261)
  Brier: 0.0210, Reliability (absolute calibration error; lower better): 0.0208, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=261)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.930
Model:                            OLS   Adj. R-squared:                  0.929
Method:                 Least Squares   F-statistic:                     1135.
Date:                Tue, 26 Aug 2025   Prob (F-statistic):          6.79e-148
Time:                        20:58:13   Log-Likelihood:                 318.61
No. Observations:                 261   AIC:                            -629.2
Df Residuals:                     257   BIC:                            -615.0
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.7781      0.061    -12.836      0.000      -0.897      -0.659
p1                    0.8218      0.064     12.746      0.000       0.695       0.949
answer_changed        0.8793      0.078     11.250      0.000       0.725       1.033
p1:answer_changed    -0.1083      0.089     -1.218      0.224      -0.284       0.067
==============================================================================
Omnibus:                       42.698   Durbin-Watson:                   2.046
Prob(Omnibus):                  0.000   Jarque-Bera (JB):              414.855
Skew:                           0.018   Prob(JB):                     8.23e-91
Kurtosis:                       9.176   Cond. No.                         42.8
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-0.26, p=0.791
Wilcoxon delta_H: statistic=747.00, p=0.847
Mean ΔH = -0.0073  [-0.0615, 0.0469]
Paired t-test delta_H Changed: statistic=4.73, p=2.55e-05
Wilcoxon delta_H Changed: statistic=163.00, p=9.13e-05
Mean ΔH Changed = 0.5311  [0.3110, 0.7512]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=1.65, p=0.101
Wilcoxon (p_top2_game vs p_top2_base): statistic=2322.50, p=0.984
Mean Δp_top2 = 0.0032  [-0.0006, 0.0071] (n=261)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=2.55, p=0.0115
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=1724.00, p=0.0129
Mean ΔH_unchosen_baseline_set = 0.0814  [0.0187, 0.1440] (n=261)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  261
Model:                          Logit   Df Residuals:                      258
Method:                           MLE   Df Model:                            2
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                  0.2114
Time:                        20:58:13   Log-Likelihood:                -92.094
converged:                       True   LL-Null:                       -116.79
Covariance Type:            nonrobust   LLR p-value:                 1.885e-11
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.6656      0.233     -7.153      0.000      -2.122      -1.209
p1_z            -1.6044      0.417     -3.846      0.000      -2.422      -0.787
I(p1_z ** 2)    -0.2500      0.149     -1.674      0.094      -0.543       0.043
================================================================================
AUC = 0.787

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  261
Model:                          Logit   Df Residuals:                      259
Method:                           MLE   Df Model:                            1
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                  0.2499
Time:                        20:58:13   Log-Likelihood:                -87.603
converged:                       True   LL-Null:                       -116.79
Covariance Type:            nonrobust   LLR p-value:                 2.171e-14
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -3.9058      0.407     -9.588      0.000      -4.704      -3.107
game_entropy     4.8595      0.732      6.642      0.000       3.425       6.294
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=2089.00, p=0.382
Paired t-test (game_entropy vs capabilities_entropy): statistic=-1.11, p=0.268
Mean capabilities_entropy-game_entropy = 0.0199  [-0.0153, 0.0552] (n=261)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  261
Model:                          Logit   Df Residuals:                      258
Method:                           MLE   Df Model:                            2
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                  0.3498
Time:                        20:58:13   Log-Likelihood:                -75.931
converged:                       True   LL-Null:                       -116.79
Covariance Type:            nonrobust   LLR p-value:                 1.803e-18
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -5.1823      0.568     -9.127      0.000      -6.295      -4.069
capabilities_entropy     3.0083      0.637      4.725      0.000       1.761       4.256
game_entropy             4.3991      0.793      5.545      0.000       2.844       5.954
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['Music', 'TV shows', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.950000
                        1                 0.050000
Geography               0                 0.666667
                        1                 0.333333
History                 0                 0.894737
                        1                 0.105263
Misc                    0                 0.800000
                        1                 0.200000
Other                   0                 0.826087
                        1                 0.173913
Politics                0                 0.772727
                        1                 0.227273
Science and technology  0                 0.893617
                        1                 0.106383
Sports                  0                 0.888889
                        1                 0.111111
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.830000
                     1                 0.170000
Number               0                 0.771429
                     1                 0.228571
Other                0                 0.821918
                     1                 0.178082
Person               0                 0.905660
                     1                 0.094340
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 1.000000  0.000000           13
                       Number               1.000000  0.000000            5
                       Other                0.875000  0.125000            8
                       Person               0.928571  0.071429           14
Geography              Date                 0.400000  0.600000           10
                       Number               0.833333  0.166667           12
                       Other                0.750000  0.250000            8
History                Date                 0.818182  0.181818           11
                       Number               1.000000  0.000000            2
                       Other                1.000000  0.000000            3
                       Person               1.000000  0.000000            3
Misc                   Date                 1.000000  0.000000           11
                       Number               0.666667  0.333333            3
                       Other                0.705882  0.294118           17
                       Person               0.777778  0.222222            9
Other                  Date                 0.777778  0.222222            9
                       Number               0.500000  0.500000            2
                       Other                0.857143  0.142857            7
                       Person               1.000000  0.000000            5
Politics               Date                 0.750000  0.250000           20
                       Number               0.666667  0.333333            3
                       Other                0.846154  0.153846           13
                       Person               0.750000  0.250000            8
Science and technology Date                 0.952381  0.047619           21
                       Number               0.666667  0.333333            6
                       Other                0.818182  0.181818           11
                       Person               1.000000  0.000000            9
Sports                 Date                 0.800000  0.200000            5
                       Number               0.500000  0.500000            2
                       Other                1.000000  0.000000            6
                       Person               1.000000  0.000000            5

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  261
Model:                          Logit   Df Residuals:                      249
Method:                           MLE   Df Model:                           11
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                 0.06455
Time:                        20:58:13   Log-Likelihood:                -109.25
converged:                       True   LL-Null:                       -116.79
Covariance Type:            nonrobust   LLR p-value:                    0.1790
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -3.4823      2.265     -1.537      0.124      -7.922       0.957
C(topic_grouped)[T.Geography]                  2.0649      0.841      2.454      0.014       0.416       3.714
C(topic_grouped)[T.History]                    0.7299      1.048      0.697      0.486      -1.324       2.783
C(topic_grouped)[T.Misc]                       1.5304      0.833      1.838      0.066      -0.101       3.162
C(topic_grouped)[T.Other]                      1.3452      0.914      1.472      0.141      -0.446       3.137
C(topic_grouped)[T.Politics]                   1.6278      0.827      1.969      0.049       0.008       3.248
C(topic_grouped)[T.Science and technology]     0.7194      0.876      0.821      0.412      -0.998       2.437
C(topic_grouped)[T.Sports]                     0.8563      1.048      0.817      0.414      -1.197       2.910
C(answer_type_grouped)[T.Number]               0.1830      0.523      0.350      0.726      -0.841       1.207
C(answer_type_grouped)[T.Other]               -0.0313      0.422     -0.074      0.941      -0.859       0.797
C(answer_type_grouped)[T.Person]              -0.4679      0.560     -0.835      0.404      -1.566       0.631
q_length                                       0.1482      0.474      0.312      0.755      -0.781       1.078
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.4285
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  261
Model:                          Logit   Df Residuals:                      248
Method:                           MLE   Df Model:                           12
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                  0.2390
Time:                        20:58:13   Log-Likelihood:                -88.870
converged:                       True   LL-Null:                       -116.79
Covariance Type:            nonrobust   LLR p-value:                 1.281e-07
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -6.0442      2.643     -2.287      0.022     -11.224      -0.865
C(topic_grouped)[T.Geography]                  2.0774      0.946      2.195      0.028       0.223       3.932
C(topic_grouped)[T.History]                    0.4871      1.196      0.407      0.684      -1.857       2.832
C(topic_grouped)[T.Misc]                       1.2958      0.923      1.405      0.160      -0.512       3.104
C(topic_grouped)[T.Other]                      0.9273      1.058      0.877      0.381      -1.146       3.001
C(topic_grouped)[T.Politics]                   1.1982      0.926      1.295      0.195      -0.616       3.012
C(topic_grouped)[T.Science and technology]     0.8067      0.975      0.827      0.408      -1.105       2.719
C(topic_grouped)[T.Sports]                     1.3932      1.113      1.252      0.211      -0.788       3.574
C(answer_type_grouped)[T.Number]               0.0975      0.602      0.162      0.871      -1.082       1.277
C(answer_type_grouped)[T.Other]                0.0504      0.479      0.105      0.916      -0.888       0.989
C(answer_type_grouped)[T.Person]              -0.5701      0.672     -0.849      0.396      -1.887       0.747
q_length                                       0.3470      0.549      0.632      0.527      -0.729       1.423
capabilities_entropy                           3.5709      0.613      5.828      0.000       2.370       4.772
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  261
Model:                          Logit   Df Residuals:                      248
Method:                           MLE   Df Model:                           12
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                  0.2950
Time:                        20:58:13   Log-Likelihood:                -82.334
converged:                       True   LL-Null:                       -116.79
Covariance Type:            nonrobust   LLR p-value:                 5.123e-10
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -4.7463      2.757     -1.721      0.085     -10.150       0.658
C(topic_grouped)[T.Geography]                  1.8006      0.899      2.003      0.045       0.039       3.562
C(topic_grouped)[T.History]                    0.8499      1.062      0.800      0.424      -1.232       2.932
C(topic_grouped)[T.Misc]                       0.8807      0.897      0.982      0.326      -0.878       2.639
C(topic_grouped)[T.Other]                      0.8078      1.004      0.805      0.421      -1.160       2.776
C(topic_grouped)[T.Politics]                   0.6762      0.901      0.751      0.453      -1.089       2.441
C(topic_grouped)[T.Science and technology]    -0.1664      0.979     -0.170      0.865      -2.085       1.752
C(topic_grouped)[T.Sports]                     0.4717      1.108      0.426      0.670      -1.699       2.643
C(answer_type_grouped)[T.Number]              -0.5539      0.652     -0.849      0.396      -1.833       0.725
C(answer_type_grouped)[T.Other]               -0.4464      0.514     -0.869      0.385      -1.454       0.561
C(answer_type_grouped)[T.Person]              -0.7462      0.672     -1.111      0.267      -2.063       0.570
q_length                                       0.0789      0.587      0.135      0.893      -1.071       1.229
game_entropy                                   5.0954      0.834      6.108      0.000       3.460       6.730
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  261
Model:                          Logit   Df Residuals:                      247
Method:                           MLE   Df Model:                           13
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                  0.3890
Time:                        20:58:13   Log-Likelihood:                -71.357
converged:                       True   LL-Null:                       -116.79
Covariance Type:            nonrobust   LLR p-value:                 9.559e-14
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -7.1677      3.109     -2.306      0.021     -13.261      -1.074
C(topic_grouped)[T.Geography]                  1.8074      0.959      1.885      0.059      -0.072       3.687
C(topic_grouped)[T.History]                    0.5256      1.190      0.442      0.659      -1.807       2.858
C(topic_grouped)[T.Misc]                       0.7816      0.938      0.833      0.405      -1.057       2.620
C(topic_grouped)[T.Other]                      0.1875      1.103      0.170      0.865      -1.975       2.350
C(topic_grouped)[T.Politics]                   0.3209      0.972      0.330      0.741      -1.585       2.227
C(topic_grouped)[T.Science and technology]    -0.1336      1.049     -0.127      0.899      -2.190       1.923
C(topic_grouped)[T.Sports]                     0.9139      1.146      0.798      0.425      -1.332       3.160
C(answer_type_grouped)[T.Number]              -0.5727      0.721     -0.794      0.427      -1.986       0.840
C(answer_type_grouped)[T.Other]               -0.3294      0.556     -0.592      0.554      -1.420       0.761
C(answer_type_grouped)[T.Person]              -0.6600      0.732     -0.902      0.367      -2.094       0.774
q_length                                       0.3338      0.648      0.515      0.606      -0.936       1.603
capabilities_entropy                           3.1410      0.699      4.496      0.000       1.772       4.510
game_entropy                                   4.6270      0.890      5.197      0.000       2.882       6.372
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing deepseek-chat (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/deepseek-chat_SimpleMC_redacted_temp0.0_1753645078_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    157
1     82
Name: count, dtype: int64

Answer change%: 0.3431 [0.2829085004403012, 0.4032839681789457] (n=239)
P-value vs 25%: 0.002433; P-value vs 0%: 5.55e-29
Phase 2 self-accuracy: 0.5732 [0.46611491632694646, 0.6802265470876876] (n=82)
P-value vs 25%: 3.287e-09; P-value vs 33%: 1.097e-05

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  239
Model:                          Logit   Df Residuals:                      237
Method:                           MLE   Df Model:                            1
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                  0.1088
Time:                        20:58:13   Log-Likelihood:                -136.97
converged:                       True   LL-Null:                       -153.69
Covariance Type:            nonrobust   LLR p-value:                 7.316e-09
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          4.8256      1.088      4.436      0.000       2.693       6.958
p_i_capability    -6.2125      1.213     -5.120      0.000      -8.591      -3.834
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  239
Model:                          Logit   Df Residuals:                      237
Method:                           MLE   Df Model:                            1
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                  0.1039
Time:                        20:58:13   Log-Likelihood:                -137.72
converged:                       True   LL-Null:                       -153.69
Covariance Type:            nonrobust   LLR p-value:                 1.583e-08
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.9550      0.290     -6.740      0.000      -2.523      -1.387
capabilities_entropy     2.5189      0.489      5.155      0.000       1.561       3.477
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.6829 [0.5822, 0.7836] (n=82)
                  P-value vs 33.3%: 1.024e-11

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=1.12, p=0.265
Wilcoxon delta_p: statistic=1259.50, p=0.161
Mean Δp = 0.0112  [-0.0085, 0.0310]
Idea 1 N = 157; 

  Idea 1.5: Calibration Metrics
  NLL: 3.9693, Signed ECE (overconf pos under neg): 0.0518, ECE: 0.0518 (n=239)
  Brier: 0.0123, Reliability (absolute calibration error; lower better): 0.0120, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=239)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.898
Model:                            OLS   Adj. R-squared:                  0.897
Method:                 Least Squares   F-statistic:                     691.0
Date:                Tue, 26 Aug 2025   Prob (F-statistic):          3.07e-116
Time:                        20:58:13   Log-Likelihood:                 177.20
No. Observations:                 239   AIC:                            -346.4
Df Residuals:                     235   BIC:                            -332.5
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.6776      0.096     -7.091      0.000      -0.866      -0.489
p1                    0.7470      0.103      7.243      0.000       0.544       0.950
answer_changed        0.7382      0.114      6.455      0.000       0.513       0.964
p1:answer_changed     0.0412      0.128      0.323      0.747      -0.211       0.293
==============================================================================
Omnibus:                       33.012   Durbin-Watson:                   1.828
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               90.522
Skew:                           0.584   Prob(JB):                     2.21e-20
Kurtosis:                       5.779   Cond. No.                         40.0
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=1.35, p=0.178
Wilcoxon delta_H: statistic=1267.00, p=0.173
Mean ΔH = 0.0598  [-0.0269, 0.1465]
Paired t-test delta_H Changed: statistic=9.40, p=1.3e-14
Wilcoxon delta_H Changed: statistic=236.00, p=1.24e-11
Mean ΔH Changed = 0.6285  [0.4974, 0.7596]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=0.76, p=0.451
Wilcoxon (p_top2_game vs p_top2_base): statistic=5241.50, p=0.119
Mean Δp_top2 = 0.0022  [-0.0035, 0.0079] (n=239)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=6.24, p=2.04e-09
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=2930.00, p=2.23e-09
Mean ΔH_unchosen_baseline_set = 0.2549  [0.1748, 0.3351] (n=239)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  239
Model:                          Logit   Df Residuals:                      236
Method:                           MLE   Df Model:                            2
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                  0.1133
Time:                        20:58:13   Log-Likelihood:                -136.27
converged:                       True   LL-Null:                       -153.69
Covariance Type:            nonrobust   LLR p-value:                 2.722e-08
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.5200      0.198     -2.632      0.008      -0.907      -0.133
p1_z            -1.1447      0.312     -3.665      0.000      -1.757      -0.533
I(p1_z ** 2)    -0.1778      0.146     -1.216      0.224      -0.464       0.109
================================================================================
AUC = 0.739

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  239
Model:                          Logit   Df Residuals:                      237
Method:                           MLE   Df Model:                            1
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                 0.07871
Time:                        20:58:13   Log-Likelihood:                -141.60
converged:                       True   LL-Null:                       -153.69
Covariance Type:            nonrobust   LLR p-value:                 8.714e-07
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.8306      0.293     -6.249      0.000      -2.405      -1.256
game_entropy     2.2508      0.483      4.659      0.000       1.304       3.198
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=5956.00, p=0.768
Paired t-test (game_entropy vs capabilities_entropy): statistic=0.17, p=0.869
Mean capabilities_entropy-game_entropy = -0.0043  [-0.0556, 0.0469] (n=239)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  239
Model:                          Logit   Df Residuals:                      236
Method:                           MLE   Df Model:                            2
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                  0.1655
Time:                        20:58:13   Log-Likelihood:                -128.26
converged:                       True   LL-Null:                       -153.69
Covariance Type:            nonrobust   LLR p-value:                 8.985e-12
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.9916      0.404     -7.410      0.000      -3.783      -2.200
capabilities_entropy     2.3744      0.494      4.807      0.000       1.406       3.342
game_entropy             2.0836      0.494      4.214      0.000       1.114       3.053
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'Geography', 'Video games', 'History']
                  Grouped rare answer_type into 'Misc'/'Other': None
topic_grouped           answer_changed
Art                     0                 0.657143
                        1                 0.342857
Misc                    0                 0.586957
                        1                 0.413043
Music                   0                 0.695652
                        1                 0.304348
Other                   0                 0.689655
                        1                 0.310345
Politics                0                 0.636364
                        1                 0.363636
Science and technology  0                 0.725490
                        1                 0.274510
Sports                  0                 0.590909
                        1                 0.409091
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.579710
                     1                 0.420290
Number               0                 0.744186
                     1                 0.255814
Other                0                 0.636364
                     1                 0.363636
Person               0                 0.716418
                     1                 0.283582
Place                0                 0.562500
                     1                 0.437500
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.625000  0.375000            8
                       Number               0.750000  0.250000            4
                       Other                0.428571  0.571429            7
                       Person               0.769231  0.230769           13
                       Place                0.666667  0.333333            3
Misc                   Date                 0.545455  0.454545           11
                       Number               0.900000  0.100000           10
                       Other                0.636364  0.363636           11
                       Person               0.400000  0.600000           10
                       Place                0.250000  0.750000            4
Music                  Date                 0.571429  0.428571            7
                       Number               1.000000  0.000000            4
                       Other                0.400000  0.600000            5
                       Person               0.800000  0.200000            5
                       Place                1.000000  0.000000            2
Other                  Date                 0.555556  0.444444            9
                       Number               0.800000  0.200000            5
                       Other                1.000000  0.000000            5
                       Person               0.625000  0.375000            8
                       Place                0.500000  0.500000            2
Politics               Date                 0.625000  0.375000           16
                       Number               0.666667  0.333333            3
                       Other                0.666667  0.333333            6
                       Person               0.571429  0.428571            7
                       Place                1.000000  0.000000            1
Science and technology Date                 0.571429  0.428571           14
                       Number               0.625000  0.375000            8
                       Other                0.666667  0.333333            6
                       Person               0.857143  0.142857           21
                       Place                1.000000  0.000000            2
Sports                 Date                 0.500000  0.500000            4
                       Number               0.555556  0.444444            9
                       Other                0.750000  0.250000            4
                       Person               1.000000  0.000000            3
                       Place                0.000000  1.000000            2

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  239
Model:                          Logit   Df Residuals:                      227
Method:                           MLE   Df Model:                           11
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                 0.02671
Time:                        20:58:13   Log-Likelihood:                -149.59
converged:                       True   LL-Null:                       -153.69
Covariance Type:            nonrobust   LLR p-value:                    0.6944
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      0.2981      1.758      0.170      0.865      -3.147       3.743
C(topic_grouped)[T.Misc]                       0.3159      0.474      0.667      0.505      -0.612       1.244
C(topic_grouped)[T.Music]                     -0.2294      0.586     -0.392      0.695      -1.377       0.918
C(topic_grouped)[T.Other]                     -0.1804      0.545     -0.331      0.741      -1.248       0.887
C(topic_grouped)[T.Politics]                  -0.0100      0.522     -0.019      0.985      -1.034       1.014
C(topic_grouped)[T.Science and technology]    -0.3008      0.481     -0.625      0.532      -1.244       0.643
C(topic_grouped)[T.Sports]                     0.4047      0.582      0.695      0.487      -0.736       1.545
C(answer_type_grouped)[T.Number]              -0.8499      0.444     -1.914      0.056      -1.720       0.020
C(answer_type_grouped)[T.Other]               -0.3110      0.404     -0.769      0.442      -1.104       0.482
C(answer_type_grouped)[T.Person]              -0.5956      0.375     -1.590      0.112      -1.330       0.139
C(answer_type_grouped)[T.Place]               -0.0296      0.574     -0.052      0.959      -1.155       1.096
q_length                                      -0.1289      0.376     -0.343      0.731      -0.865       0.607
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.5031
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  239
Model:                          Logit   Df Residuals:                      226
Method:                           MLE   Df Model:                           12
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                  0.1306
Time:                        20:58:13   Log-Likelihood:                -133.62
converged:                       True   LL-Null:                       -153.69
Covariance Type:            nonrobust   LLR p-value:                 6.811e-05
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.0699      1.912     -0.560      0.576      -4.818       2.678
C(topic_grouped)[T.Misc]                       0.6145      0.508      1.211      0.226      -0.380       1.609
C(topic_grouped)[T.Music]                     -0.0299      0.627     -0.048      0.962      -1.258       1.198
C(topic_grouped)[T.Other]                     -0.1020      0.597     -0.171      0.864      -1.272       1.068
C(topic_grouped)[T.Politics]                   0.1300      0.558      0.233      0.816      -0.964       1.224
C(topic_grouped)[T.Science and technology]    -0.2502      0.521     -0.480      0.631      -1.271       0.771
C(topic_grouped)[T.Sports]                     0.3260      0.644      0.506      0.613      -0.936       1.588
C(answer_type_grouped)[T.Number]              -0.8829      0.484     -1.823      0.068      -1.832       0.066
C(answer_type_grouped)[T.Other]               -0.2193      0.426     -0.515      0.607      -1.054       0.616
C(answer_type_grouped)[T.Person]              -0.5324      0.403     -1.322      0.186      -1.322       0.257
C(answer_type_grouped)[T.Place]               -0.2306      0.619     -0.372      0.710      -1.444       0.983
q_length                                      -0.1530      0.404     -0.379      0.705      -0.944       0.638
capabilities_entropy                           2.5799      0.499      5.171      0.000       1.602       3.558
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  239
Model:                          Logit   Df Residuals:                      226
Method:                           MLE   Df Model:                           12
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                  0.1087
Time:                        20:58:13   Log-Likelihood:                -136.98
converged:                       True   LL-Null:                       -153.69
Covariance Type:            nonrobust   LLR p-value:                 0.0008325
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -0.6932      1.864     -0.372      0.710      -4.346       2.960
C(topic_grouped)[T.Misc]                       0.0768      0.508      0.151      0.880      -0.920       1.073
C(topic_grouped)[T.Music]                     -0.1679      0.608     -0.276      0.782      -1.360       1.024
C(topic_grouped)[T.Other]                     -0.2717      0.584     -0.465      0.642      -1.417       0.874
C(topic_grouped)[T.Politics]                   0.0719      0.546      0.132      0.895      -0.999       1.142
C(topic_grouped)[T.Science and technology]    -0.5035      0.512     -0.983      0.326      -1.507       0.501
C(topic_grouped)[T.Sports]                     0.5082      0.605      0.840      0.401      -0.678       1.694
C(answer_type_grouped)[T.Number]              -1.0345      0.472     -2.192      0.028      -1.960      -0.109
C(answer_type_grouped)[T.Other]               -0.2701      0.426     -0.634      0.526      -1.105       0.565
C(answer_type_grouped)[T.Person]              -0.5027      0.397     -1.266      0.206      -1.281       0.276
C(answer_type_grouped)[T.Place]               -0.1650      0.630     -0.262      0.793      -1.400       1.070
q_length                                      -0.1741      0.396     -0.440      0.660      -0.950       0.602
game_entropy                                   2.4272      0.514      4.718      0.000       1.419       3.435
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  239
Model:                          Logit   Df Residuals:                      225
Method:                           MLE   Df Model:                           13
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                  0.1941
Time:                        20:58:13   Log-Likelihood:                -123.86
converged:                       True   LL-Null:                       -153.69
Covariance Type:            nonrobust   LLR p-value:                 6.031e-08
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.8134      1.991     -0.911      0.362      -5.715       2.088
C(topic_grouped)[T.Misc]                       0.3807      0.538      0.707      0.479      -0.674       1.436
C(topic_grouped)[T.Music]                      0.0338      0.657      0.051      0.959      -1.254       1.322
C(topic_grouped)[T.Other]                     -0.1783      0.622     -0.287      0.774      -1.397       1.040
C(topic_grouped)[T.Politics]                   0.2258      0.590      0.383      0.702      -0.931       1.383
C(topic_grouped)[T.Science and technology]    -0.4244      0.541     -0.785      0.433      -1.485       0.636
C(topic_grouped)[T.Sports]                     0.4522      0.665      0.680      0.497      -0.852       1.756
C(answer_type_grouped)[T.Number]              -1.0963      0.522     -2.102      0.036      -2.118      -0.074
C(answer_type_grouped)[T.Other]               -0.1722      0.449     -0.383      0.701      -1.052       0.708
C(answer_type_grouped)[T.Person]              -0.4332      0.418     -1.037      0.300      -1.252       0.385
C(answer_type_grouped)[T.Place]               -0.3716      0.668     -0.557      0.578      -1.680       0.937
q_length                                      -0.2214      0.423     -0.524      0.601      -1.050       0.607
capabilities_entropy                           2.4303      0.511      4.758      0.000       1.429       3.431
game_entropy                                   2.2573      0.531      4.254      0.000       1.217       3.297
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing gemini-1.5-pro (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/gemini-1.5-pro_SimpleMC_redacted_cor_temp0.0_1751757561_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    217
1     23
Name: count, dtype: int64

Answer change%: 0.0958 [0.05859201783934817, 0.1330746488273185] (n=240)
P-value vs 25%: 4.914e-16; P-value vs 0%: 4.569e-07
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=23)
P-value vs 25%: 0; P-value vs 33%: 0
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 1.000000
Geography               0                 0.900000
                        1                 0.100000
History                 0                 0.900000
                        1                 0.100000
Misc                    0                 0.727273
                        1                 0.272727
Music                   0                 0.888889
                        1                 0.111111
Other                   0                 0.875000
                        1                 0.125000
Politics                0                 0.926829
                        1                 0.073171
Science and technology  0                 0.906977
                        1                 0.093023
Sports                  0                 0.950000
                        1                 0.050000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.930000
                     1                 0.070000
Number               0                 0.878788
                     1                 0.121212
Other                0                 0.901639
                     1                 0.098361
Person               0                 0.869565
                     1                 0.130435
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 1.000000  0.000000           12
                       Number               1.000000  0.000000            4
                       Other                1.000000  0.000000            7
                       Person               1.000000  0.000000            9
Geography              Date                 0.875000  0.125000            8
                       Number               0.857143  0.142857            7
                       Other                1.000000  0.000000            5
History                Date                 1.000000  0.000000           11
                       Number               0.666667  0.333333            3
                       Other                0.666667  0.333333            3
                       Person               1.000000  0.000000            3
Misc                   Date                 0.600000  0.400000            5
                       Number               0.666667  0.333333            3
                       Other                0.900000  0.100000           10
                       Person               0.500000  0.500000            4
Music                  Date                 1.000000  0.000000            6
                       Other                0.750000  0.250000            4
                       Person               0.875000  0.125000            8
Other                  Date                 1.000000  0.000000           11
                       Number               1.000000  0.000000            4
                       Other                0.571429  0.428571            7
                       Person               1.000000  0.000000            2
Politics               Date                 0.913043  0.086957           23
                       Number               1.000000  0.000000            1
                       Other                1.000000  0.000000           11
                       Person               0.833333  0.166667            6
Science and technology Date                 0.882353  0.117647           17
                       Number               0.857143  0.142857            7
                       Other                1.000000  0.000000           11
                       Person               0.875000  0.125000            8
Sports                 Date                 1.000000  0.000000            7
                       Number               1.000000  0.000000            4
                       Other                1.000000  0.000000            3
                       Person               0.833333  0.166667            6

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  240
Model:                          Logit   Df Residuals:                      227
Method:                           MLE   Df Model:                           12
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                 0.09948
Time:                        20:58:13   Log-Likelihood:                -68.259
converged:                      False   LL-Null:                       -75.799
Covariance Type:            nonrobust   LLR p-value:                    0.2370
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                    -23.9418    2.4e+04     -0.001      0.999    -4.7e+04    4.69e+04
C(topic_grouped)[T.Geography]                 21.5785    2.4e+04      0.001      0.999   -4.69e+04     4.7e+04
C(topic_grouped)[T.History]                   21.5604    2.4e+04      0.001      0.999   -4.69e+04     4.7e+04
C(topic_grouped)[T.Misc]                      22.7395    2.4e+04      0.001      0.999   -4.69e+04     4.7e+04
C(topic_grouped)[T.Music]                     21.4924    2.4e+04      0.001      0.999   -4.69e+04     4.7e+04
C(topic_grouped)[T.Other]                     21.8492    2.4e+04      0.001      0.999   -4.69e+04     4.7e+04
C(topic_grouped)[T.Politics]                  21.2773    2.4e+04      0.001      0.999   -4.69e+04     4.7e+04
C(topic_grouped)[T.Science and technology]    21.4292    2.4e+04      0.001      0.999   -4.69e+04     4.7e+04
C(topic_grouped)[T.Sports]                    20.6494    2.4e+04      0.001      0.999   -4.69e+04     4.7e+04
C(answer_type_grouped)[T.Number]               0.5238      0.701      0.747      0.455      -0.850       1.898
C(answer_type_grouped)[T.Other]                0.1267      0.612      0.207      0.836      -1.072       1.326
C(answer_type_grouped)[T.Person]               0.8073      0.632      1.277      0.202      -0.432       2.047
q_length                                      -0.0163      0.637     -0.026      0.980      -1.264       1.231
==============================================================================================================

Possibly complete quasi-separation: A fraction 0.13 of observations can be
perfectly predicted. This might indicate that there is complete
quasi-separation. In this case some parameters will not be identified.

                  Model 6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length (after removing deterministic categories: defaultdict(<class 'list'>, {'topic_grouped': ['Art']}))
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  208
Model:                          Logit   Df Residuals:                      196
Method:                           MLE   Df Model:                           11
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                 0.05623
Time:                        20:58:13   Log-Likelihood:                -68.259
converged:                       True   LL-Null:                       -72.326
Covariance Type:            nonrobust   LLR p-value:                    0.7013
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -2.3633      2.899     -0.815      0.415      -8.046       3.320
C(topic_grouped)[T.History]                   -0.0181      1.083     -0.017      0.987      -2.141       2.105
C(topic_grouped)[T.Misc]                       1.1610      0.924      1.256      0.209      -0.651       2.973
C(topic_grouped)[T.Music]                     -0.0861      1.137     -0.076      0.940      -2.314       2.142
C(topic_grouped)[T.Other]                      0.2707      0.983      0.275      0.783      -1.656       2.197
C(topic_grouped)[T.Politics]                  -0.3012      1.025     -0.294      0.769      -2.311       1.708
C(topic_grouped)[T.Science and technology]    -0.1494      0.946     -0.158      0.875      -2.003       1.704
C(topic_grouped)[T.Sports]                    -0.9292      1.297     -0.716      0.474      -3.472       1.614
C(answer_type_grouped)[T.Number]               0.5238      0.701      0.747      0.455      -0.850       1.898
C(answer_type_grouped)[T.Other]                0.1267      0.612      0.207      0.836      -1.072       1.326
C(answer_type_grouped)[T.Person]               0.8073      0.632      1.277      0.202      -0.432       2.047
q_length                                      -0.0163      0.637     -0.026      0.980      -1.264       1.231
==============================================================================================================

--- Analyzing gemini-1.5-pro (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/gemini-1.5-pro_SimpleMC_redacted_temp0.0_1751722404_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    196
1     64
Name: count, dtype: int64

Answer change%: 0.2462 [0.1937930680496052, 0.29851462425808717] (n=260)
P-value vs 25%: 0.8855; P-value vs 0%: 3.142e-20
Phase 2 self-accuracy: 0.5000 [0.37750225096624657, 0.6224977490337534] (n=64)
P-value vs 25%: 6.334e-05; P-value vs 33%: 0.00754
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'Video games', 'History']
                  Grouped rare answer_type into 'Misc'/'Other': None
topic_grouped           answer_changed
Art                     0                 0.813953
                        1                 0.186047
Geography               0                 0.791667
                        1                 0.208333
Misc                    0                 0.718750
                        1                 0.281250
Music                   0                 0.727273
                        1                 0.272727
Other                   0                 0.750000
                        1                 0.250000
Politics                0                 0.777778
                        1                 0.222222
Science and technology  0                 0.709091
                        1                 0.290909
Sports                  0                 0.750000
                        1                 0.250000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.826087
                     1                 0.173913
Number               0                 0.800000
                     1                 0.200000
Other                0                 0.666667
                     1                 0.333333
Person               0                 0.716216
                     1                 0.283784
Place                0                 0.777778
                     1                 0.222222
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.888889  0.111111            9
                       Number               0.800000  0.200000            5
                       Other                0.800000  0.200000           10
                       Person               0.777778  0.222222           18
                       Place                1.000000  0.000000            1
Geography              Date                 0.857143  0.142857            7
                       Number               0.727273  0.272727           11
                       Other                1.000000  0.000000            1
                       Place                0.800000  0.200000            5
Misc                   Date                 0.857143  0.142857            7
                       Number               1.000000  0.000000            3
                       Other                0.615385  0.384615           13
                       Person               0.625000  0.375000            8
                       Place                1.000000  0.000000            1
Music                  Date                 0.833333  0.166667            6
                       Number               1.000000  0.000000            4
                       Other                0.428571  0.571429            7
                       Person               1.000000  0.000000            4
                       Place                0.000000  1.000000            1
Other                  Date                 0.857143  0.142857            7
                       Number               1.000000  0.000000            3
                       Other                0.500000  0.500000            4
                       Person               0.636364  0.363636           11
                       Place                1.000000  0.000000            3
Politics               Date                 0.769231  0.230769           13
                       Number               0.800000  0.200000            5
                       Other                1.000000  0.000000            7
                       Person               0.666667  0.333333            9
                       Place                0.500000  0.500000            2
Science and technology Date                 0.777778  0.222222           18
                       Number               0.714286  0.285714            7
                       Other                0.600000  0.400000            5
                       Person               0.681818  0.318182           22
                       Place                0.666667  0.333333            3
Sports                 Date                 1.000000  0.000000            2
                       Number               0.714286  0.285714            7
                       Other                0.571429  0.428571            7
                       Person               1.000000  0.000000            2
                       Place                1.000000  0.000000            2

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  260
Model:                          Logit   Df Residuals:                      247
Method:                           MLE   Df Model:                           12
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                 0.02651
Time:                        20:58:13   Log-Likelihood:                -141.25
converged:                       True   LL-Null:                       -145.10
Covariance Type:            nonrobust   LLR p-value:                    0.8085
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.7378      1.858     -0.935      0.350      -5.380       1.904
C(topic_grouped)[T.Geography]                  0.5081      0.687      0.739      0.460      -0.839       1.855
C(topic_grouped)[T.Misc]                       0.4966      0.566      0.877      0.380      -0.613       1.606
C(topic_grouped)[T.Music]                      0.5491      0.634      0.866      0.387      -0.694       1.792
C(topic_grouped)[T.Other]                      0.4649      0.595      0.781      0.435      -0.702       1.632
C(topic_grouped)[T.Politics]                   0.3673      0.573      0.641      0.522      -0.756       1.491
C(topic_grouped)[T.Science and technology]     0.7373      0.503      1.467      0.142      -0.248       1.723
C(topic_grouped)[T.Sports]                     0.4222      0.671      0.629      0.529      -0.892       1.737
C(answer_type_grouped)[T.Number]               0.1904      0.506      0.377      0.706      -0.800       1.181
C(answer_type_grouped)[T.Other]                0.9273      0.452      2.054      0.040       0.042       1.812
C(answer_type_grouped)[T.Person]               0.6626      0.425      1.558      0.119      -0.171       1.496
C(answer_type_grouped)[T.Place]                0.2951      0.663      0.445      0.656      -1.005       1.595
q_length                                      -0.0666      0.391     -0.170      0.865      -0.834       0.700
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing gemini-2.0-flash-001 (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/gemini-2.0-flash-001_SimpleMC_redacted_cor_temp0.0_1754323767_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    144
1     69
Name: count, dtype: int64

Answer change%: 0.3239 [0.261096672709652, 0.38679065123401] (n=213)
P-value vs 25%: 0.02111; P-value vs 0%: 5.38e-24
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=69)
P-value vs 25%: 0; P-value vs 33%: 0

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  213
Model:                          Logit   Df Residuals:                      211
Method:                           MLE   Df Model:                            1
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                 0.02213
Time:                        20:58:13   Log-Likelihood:                -131.18
converged:                       True   LL-Null:                       -134.15
Covariance Type:            nonrobust   LLR p-value:                   0.01483
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          1.9811      1.131      1.751      0.080      -0.236       4.198
p_i_capability    -2.9024      1.201     -2.417      0.016      -5.256      -0.549
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  213
Model:                          Logit   Df Residuals:                      211
Method:                           MLE   Df Model:                            1
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                 0.03534
Time:                        20:58:13   Log-Likelihood:                -129.41
converged:                       True   LL-Null:                       -134.15
Covariance Type:            nonrobust   LLR p-value:                  0.002075
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.0267      0.180     -5.697      0.000      -1.380      -0.673
capabilities_entropy     1.2061      0.398      3.031      0.002       0.426       1.986
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.5926 [0.4615, 0.7236] (n=54)
                  P-value vs 33.3%: 0.0001056

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=4.82, p=7.9e-06
Wilcoxon delta_p: statistic=428.00, p=3.95e-07
Mean Δp = 0.0925  [0.0548, 0.1301]
Idea 1 N = 73; 

  Idea 1.5: Calibration Metrics
  NLL: 0.1035, Signed ECE (overconf pos under neg): -0.0852, ECE: 0.0852 (n=127)
  Brier: 0.0262, Reliability (absolute calibration error; lower better): 0.0256, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=127)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.840
Model:                            OLS   Adj. R-squared:                  0.836
Method:                 Least Squares   F-statistic:                     215.4
Date:                Tue, 26 Aug 2025   Prob (F-statistic):           8.88e-49
Time:                        20:58:13   Log-Likelihood:                 65.798
No. Observations:                 127   AIC:                            -123.6
Df Residuals:                     123   BIC:                            -112.2
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.3932      0.117     -3.351      0.001      -0.625      -0.161
p1                    0.5236      0.125      4.184      0.000       0.276       0.771
answer_changed        0.3697      0.177      2.089      0.039       0.019       0.720
p1:answer_changed     0.3202      0.192      1.665      0.098      -0.060       0.701
==============================================================================
Omnibus:                        4.798   Durbin-Watson:                   1.826
Prob(Omnibus):                  0.091   Jarque-Bera (JB):                2.740
Skew:                           0.120   Prob(JB):                        0.254
Kurtosis:                       2.322   Cond. No.                         33.4
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-2.98, p=0.00388
Wilcoxon delta_H: statistic=816.00, p=0.0033
Mean ΔH = -0.2012  [-0.3334, -0.0691]
Paired t-test delta_H Changed: statistic=2.24, p=0.0292
Wilcoxon delta_H Changed: statistic=462.00, p=0.0157
Mean ΔH Changed = 0.1635  [0.0205, 0.3064]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=-6.17, p=8.56e-09
Wilcoxon (p_top2_game vs p_top2_base): statistic=697.00, p=5.42e-16
Mean Δp_top2 = -0.0393  [-0.0518, -0.0268] (n=127)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=-0.89, p=0.376
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=3770.00, p=0.479
Mean ΔH_unchosen_baseline_set = -0.0462  [-0.1481, 0.0557] (n=127)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  127
Model:                          Logit   Df Residuals:                      124
Method:                           MLE   Df Model:                            2
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                 0.03700
Time:                        20:58:13   Log-Likelihood:                -83.399
converged:                       True   LL-Null:                       -86.603
Covariance Type:            nonrobust   LLR p-value:                   0.04060
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept        0.0980      0.262      0.375      0.708      -0.415       0.611
p1_z            -0.9620      0.389     -2.473      0.013      -1.725      -0.199
I(p1_z ** 2)    -0.4082      0.191     -2.136      0.033      -0.783      -0.034
================================================================================
AUC = 0.628

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  213
Model:                          Logit   Df Residuals:                      211
Method:                           MLE   Df Model:                            1
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                  0.1328
Time:                        20:58:13   Log-Likelihood:                -116.34
converged:                       True   LL-Null:                       -134.15
Covariance Type:            nonrobust   LLR p-value:                 2.389e-09
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.7265      0.251     -6.871      0.000      -2.219      -1.234
game_entropy     1.7071      0.306      5.586      0.000       1.108       2.306
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=3422.00, p=8.44e-19
Paired t-test (game_entropy vs capabilities_entropy): statistic=8.23, p=1.92e-14
Mean capabilities_entropy-game_entropy = -0.2904  [-0.3596, -0.2212] (n=213)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  213
Model:                          Logit   Df Residuals:                      210
Method:                           MLE   Df Model:                            2
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                  0.1365
Time:                        20:58:13   Log-Likelihood:                -115.84
converged:                       True   LL-Null:                       -134.15
Covariance Type:            nonrobust   LLR p-value:                 1.115e-08
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.7756      0.258     -6.874      0.000      -2.282      -1.269
capabilities_entropy     0.4418      0.442      1.000      0.317      -0.424       1.308
game_entropy             1.6030      0.322      4.975      0.000       0.971       2.235
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': None
topic_grouped           answer_changed
Art                     0                 0.764706
                        1                 0.235294
Geography               0                 0.555556
                        1                 0.444444
Misc                    0                 0.733333
                        1                 0.266667
Music                   0                 0.695652
                        1                 0.304348
Other                   0                 0.625000
                        1                 0.375000
Politics                0                 0.705882
                        1                 0.294118
Science and technology  0                 0.651163
                        1                 0.348837
Sports                  0                 0.533333
                        1                 0.466667
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.594937
                     1                 0.405063
Number               1                 0.521739
                     0                 0.478261
Other                0                 0.681818
                     1                 0.318182
Person               0                 0.865385
                     1                 0.134615
Place                0                 0.733333
                     1                 0.266667
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.500000  0.500000            8
                       Number               1.000000  0.000000            2
                       Other                0.714286  0.285714            7
                       Person               0.866667  0.133333           15
                       Place                1.000000  0.000000            2
Geography              Date                 0.200000  0.800000            5
                       Number               0.500000  0.500000            6
                       Other                1.000000  0.000000            2
                       Place                0.800000  0.200000            5
Misc                   Date                 0.769231  0.230769           13
                       Number               1.000000  0.000000            2
                       Other                0.500000  0.500000           10
                       Person               1.000000  0.000000            4
                       Place                1.000000  0.000000            1
Music                  Date                 0.750000  0.250000            8
                       Number               0.500000  0.500000            2
                       Other                0.333333  0.666667            3
                       Person               0.888889  0.111111            9
                       Place                0.000000  1.000000            1
Other                  Date                 0.428571  0.571429            7
                       Other                1.000000  0.000000            3
                       Person               0.750000  0.250000            4
                       Place                0.500000  0.500000            2
Politics               Date                 0.631579  0.368421           19
                       Number               0.500000  0.500000            2
                       Other                0.833333  0.166667            6
                       Person               1.000000  0.000000            4
                       Place                0.666667  0.333333            3
Science and technology Date                 0.625000  0.375000           16
                       Number               0.200000  0.800000            5
                       Other                0.600000  0.400000           10
                       Person               0.916667  0.083333           12
Sports                 Date                 0.333333  0.666667            3
                       Number               0.250000  0.750000            4
                       Other                1.000000  0.000000            3
                       Person               0.500000  0.500000            4
                       Place                1.000000  0.000000            1

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  213
Model:                          Logit   Df Residuals:                      200
Method:                           MLE   Df Model:                           12
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                 0.07628
Time:                        20:58:13   Log-Likelihood:                -123.92
converged:                       True   LL-Null:                       -134.15
Covariance Type:            nonrobust   LLR p-value:                   0.05876
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.9551      2.056     -0.951      0.342      -5.984       2.074
C(topic_grouped)[T.Geography]                  0.4981      0.681      0.732      0.464      -0.836       1.832
C(topic_grouped)[T.Misc]                      -0.2452      0.605     -0.405      0.685      -1.431       0.941
C(topic_grouped)[T.Music]                      0.2556      0.638      0.401      0.689      -0.994       1.506
C(topic_grouped)[T.Other]                      0.4900      0.688      0.713      0.476      -0.858       1.838
C(topic_grouped)[T.Politics]                  -0.2318      0.605     -0.383      0.701      -1.417       0.954
C(topic_grouped)[T.Science and technology]     0.2216      0.553      0.401      0.689      -0.862       1.305
C(topic_grouped)[T.Sports]                     0.7983      0.699      1.142      0.254      -0.572       2.169
C(answer_type_grouped)[T.Number]               0.2430      0.510      0.476      0.634      -0.756       1.242
C(answer_type_grouped)[T.Other]               -0.3542      0.409     -0.866      0.387      -1.156       0.447
C(answer_type_grouped)[T.Person]              -1.5708      0.487     -3.229      0.001      -2.524      -0.617
C(answer_type_grouped)[T.Place]               -0.7920      0.662     -1.197      0.231      -2.089       0.505
q_length                                       0.3252      0.452      0.720      0.471      -0.560       1.210
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.2219
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  213
Model:                          Logit   Df Residuals:                      199
Method:                           MLE   Df Model:                           13
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                  0.1005
Time:                        20:58:13   Log-Likelihood:                -120.67
converged:                       True   LL-Null:                       -134.15
Covariance Type:            nonrobust   LLR p-value:                   0.01262
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.9353      2.095     -0.924      0.356      -6.041       2.171
C(topic_grouped)[T.Geography]                  0.5476      0.689      0.795      0.427      -0.803       1.898
C(topic_grouped)[T.Misc]                      -0.2967      0.614     -0.483      0.629      -1.500       0.907
C(topic_grouped)[T.Music]                      0.1797      0.650      0.276      0.782      -1.095       1.454
C(topic_grouped)[T.Other]                      0.3488      0.696      0.501      0.616      -1.016       1.714
C(topic_grouped)[T.Politics]                  -0.3398      0.618     -0.550      0.582      -1.551       0.871
C(topic_grouped)[T.Science and technology]     0.1750      0.557      0.314      0.753      -0.917       1.267
C(topic_grouped)[T.Sports]                     0.6431      0.730      0.881      0.379      -0.788       2.075
C(answer_type_grouped)[T.Number]               0.0514      0.527      0.098      0.922      -0.982       1.085
C(answer_type_grouped)[T.Other]               -0.4361      0.421     -1.035      0.300      -1.261       0.389
C(answer_type_grouped)[T.Person]              -1.5456      0.491     -3.145      0.002      -2.509      -0.582
C(answer_type_grouped)[T.Place]               -0.8286      0.667     -1.242      0.214      -2.136       0.479
q_length                                       0.2859      0.461      0.621      0.535      -0.617       1.189
capabilities_entropy                           1.0676      0.422      2.528      0.011       0.240       1.895
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  213
Model:                          Logit   Df Residuals:                      199
Method:                           MLE   Df Model:                           13
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                  0.1639
Time:                        20:58:13   Log-Likelihood:                -112.16
converged:                       True   LL-Null:                       -134.15
Covariance Type:            nonrobust   LLR p-value:                 3.087e-05
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.1761      2.196     -0.536      0.592      -5.480       3.128
C(topic_grouped)[T.Geography]                 -0.1210      0.732     -0.165      0.869      -1.555       1.313
C(topic_grouped)[T.Misc]                      -0.6247      0.638     -0.980      0.327      -1.874       0.625
C(topic_grouped)[T.Music]                     -0.2767      0.687     -0.402      0.687      -1.624       1.071
C(topic_grouped)[T.Other]                     -0.1709      0.751     -0.227      0.820      -1.643       1.301
C(topic_grouped)[T.Politics]                  -0.5474      0.641     -0.855      0.393      -1.803       0.708
C(topic_grouped)[T.Science and technology]     0.0307      0.578      0.053      0.958      -1.101       1.163
C(topic_grouped)[T.Sports]                     0.3492      0.743      0.470      0.638      -1.107       1.806
C(answer_type_grouped)[T.Number]               0.1922      0.550      0.349      0.727      -0.886       1.270
C(answer_type_grouped)[T.Other]                0.1062      0.449      0.237      0.813      -0.774       0.986
C(answer_type_grouped)[T.Person]              -1.0235      0.524     -1.952      0.051      -2.051       0.004
C(answer_type_grouped)[T.Place]               -0.0430      0.724     -0.059      0.953      -1.462       1.376
q_length                                      -0.0305      0.486     -0.063      0.950      -0.983       0.922
game_entropy                                   1.5954      0.348      4.588      0.000       0.914       2.277
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  213
Model:                          Logit   Df Residuals:                      198
Method:                           MLE   Df Model:                           14
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                  0.1664
Time:                        20:58:13   Log-Likelihood:                -111.82
converged:                       True   LL-Null:                       -134.15
Covariance Type:            nonrobust   LLR p-value:                 4.651e-05
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.1915      2.206     -0.540      0.589      -5.514       3.131
C(topic_grouped)[T.Geography]                 -0.0701      0.734     -0.095      0.924      -1.509       1.369
C(topic_grouped)[T.Misc]                      -0.6245      0.641     -0.974      0.330      -1.882       0.633
C(topic_grouped)[T.Music]                     -0.2581      0.686     -0.376      0.707      -1.603       1.087
C(topic_grouped)[T.Other]                     -0.1801      0.752     -0.240      0.811      -1.654       1.293
C(topic_grouped)[T.Politics]                  -0.5600      0.643     -0.872      0.383      -1.819       0.699
C(topic_grouped)[T.Science and technology]     0.0260      0.578      0.045      0.964      -1.108       1.160
C(topic_grouped)[T.Sports]                     0.3066      0.753      0.407      0.684      -1.169       1.782
C(answer_type_grouped)[T.Number]               0.1325      0.554      0.239      0.811      -0.953       1.218
C(answer_type_grouped)[T.Other]                0.0463      0.457      0.101      0.919      -0.850       0.943
C(answer_type_grouped)[T.Person]              -1.0503      0.528     -1.991      0.046      -2.084      -0.016
C(answer_type_grouped)[T.Place]               -0.1032      0.724     -0.143      0.887      -1.522       1.315
q_length                                      -0.0278      0.488     -0.057      0.955      -0.985       0.929
capabilities_entropy                           0.3733      0.459      0.814      0.416      -0.525       1.272
game_entropy                                   1.4900      0.370      4.028      0.000       0.765       2.215
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing gemini-2.0-flash-001 (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/gemini-2.0-flash-001_SimpleMC_redacted_temp0.0_1754323560_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    162
1    125
Name: count, dtype: int64

Answer change%: 0.4355 [0.37817628993036156, 0.4929038494424607] (n=287)
P-value vs 25%: 2.307e-10; P-value vs 0%: 4.365e-50
Phase 2 self-accuracy: 0.5120 [0.424372993427672, 0.599627006572328] (n=125)
P-value vs 25%: 4.623e-09; P-value vs 33%: 6.236e-05

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  287
Model:                          Logit   Df Residuals:                      285
Method:                           MLE   Df Model:                            1
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                 0.03279
Time:                        20:58:13   Log-Likelihood:                -190.10
converged:                       True   LL-Null:                       -196.54
Covariance Type:            nonrobust   LLR p-value:                 0.0003303
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          2.2527      0.732      3.076      0.002       0.817       3.688
p_i_capability    -2.8272      0.811     -3.486      0.000      -4.417      -1.238
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  287
Model:                          Logit   Df Residuals:                      285
Method:                           MLE   Df Model:                            1
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                 0.03692
Time:                        20:58:13   Log-Likelihood:                -189.29
converged:                       True   LL-Null:                       -196.54
Covariance Type:            nonrobust   LLR p-value:                 0.0001393
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -0.6595      0.163     -4.055      0.000      -0.978      -0.341
capabilities_entropy     0.9902      0.266      3.721      0.000       0.469       1.512
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.5253 [0.4269, 0.6236] (n=99)
                  P-value vs 33.3%: 0.0001313

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=3.76, p=0.000273
Wilcoxon delta_p: statistic=1884.00, p=0.000129
Mean Δp = 0.0672  [0.0322, 0.1023]
Idea 1 N = 113; 

  Idea 1.5: Calibration Metrics
  NLL: 5.5241, Signed ECE (overconf pos under neg): 0.0656, ECE: 0.0656 (n=211)
  Brier: 0.0164, Reliability (absolute calibration error; lower better): 0.0158, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=211)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.837
Model:                            OLS   Adj. R-squared:                  0.835
Method:                 Least Squares   F-statistic:                     350.0
Date:                Tue, 26 Aug 2025   Prob (F-statistic):           3.80e-80
Time:                        20:58:13   Log-Likelihood:                 94.331
No. Observations:                 208   AIC:                            -180.7
Df Residuals:                     204   BIC:                            -167.3
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.3700      0.091     -4.046      0.000      -0.550      -0.190
p1                    0.4917      0.102      4.843      0.000       0.292       0.692
answer_changed        0.2362      0.118      1.998      0.047       0.003       0.469
p1:answer_changed     0.5320      0.135      3.949      0.000       0.266       0.798
==============================================================================
Omnibus:                        5.694   Durbin-Watson:                   1.817
Prob(Omnibus):                  0.058   Jarque-Bera (JB):                5.328
Skew:                           0.365   Prob(JB):                       0.0697
Kurtosis:                       3.286   Cond. No.                         29.1
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-3.13, p=0.0022
Wilcoxon delta_H: statistic=2197.00, p=0.00337
Mean ΔH = -0.1868  [-0.3035, -0.0700]
Paired t-test delta_H Changed: statistic=1.35, p=0.179
Wilcoxon delta_H Changed: statistic=2090.00, p=0.179
Mean ΔH Changed = 0.0858  [-0.0385, 0.2102]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=-4.04, p=7.4e-05
Wilcoxon (p_top2_game vs p_top2_base): statistic=6067.00, p=5.23e-09
Mean Δp_top2 = -0.0239  [-0.0355, -0.0123] (n=212)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=-1.34, p=0.181
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=10212.00, p=0.228
Mean ΔH_unchosen_baseline_set = -0.0595  [-0.1463, 0.0274] (n=212)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  212
Model:                          Logit   Df Residuals:                      209
Method:                           MLE   Df Model:                            2
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                 0.02513
Time:                        20:58:13   Log-Likelihood:                -142.80
converged:                       True   LL-Null:                       -146.48
Covariance Type:            nonrobust   LLR p-value:                   0.02521
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.1750      0.204     -0.857      0.392      -0.575       0.225
p1_z            -0.3345      0.208     -1.607      0.108      -0.743       0.074
I(p1_z ** 2)     0.0441      0.155      0.285      0.775      -0.259       0.347
================================================================================
AUC = 0.612

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  287
Model:                          Logit   Df Residuals:                      285
Method:                           MLE   Df Model:                            1
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                 0.06151
Time:                        20:58:13   Log-Likelihood:                -184.45
converged:                       True   LL-Null:                       -196.54
Covariance Type:            nonrobust   LLR p-value:                 8.786e-07
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.9897      0.200     -4.954      0.000      -1.381      -0.598
game_entropy     1.1554      0.244      4.734      0.000       0.677       1.634
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=11275.00, p=2.52e-11
Paired t-test (game_entropy vs capabilities_entropy): statistic=6.89, p=3.61e-11
Mean capabilities_entropy-game_entropy = -0.2203  [-0.2830, -0.1576] (n=287)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  287
Model:                          Logit   Df Residuals:                      284
Method:                           MLE   Df Model:                            2
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                 0.07232
Time:                        20:58:13   Log-Likelihood:                -182.33
converged:                       True   LL-Null:                       -196.54
Covariance Type:            nonrobust   LLR p-value:                 6.710e-07
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.1062      0.210     -5.256      0.000      -1.519      -0.694
capabilities_entropy     0.5935      0.289      2.056      0.040       0.028       1.159
game_entropy             0.9585      0.262      3.662      0.000       0.445       1.472
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'Music', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.609756
                        1                 0.390244
Geography               1                 0.692308
                        0                 0.307692
Misc                    0                 0.622951
                        1                 0.377049
Other                   0                 0.611111
                        1                 0.388889
Politics                0                 0.581395
                        1                 0.418605
Science and technology  0                 0.545455
                        1                 0.454545
Sports                  0                 0.560000
                        1                 0.440000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.500000
                     1                 0.500000
Number               1                 0.581818
                     0                 0.418182
Other                0                 0.702703
                     1                 0.297297
Person               0                 0.617647
                     1                 0.382353
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.615385  0.384615           13
                       Number               0.571429  0.428571            7
                       Other                0.666667  0.333333            9
                       Person               0.583333  0.416667           12
Geography              Date                 0.300000  0.700000           10
                       Number               0.250000  0.750000           12
                       Other                0.500000  0.500000            4
Misc                   Date                 0.571429  0.428571           14
                       Number               0.444444  0.555556            9
                       Other                0.791667  0.208333           24
                       Person               0.500000  0.500000           14
Other                  Date                 0.545455  0.454545           11
                       Number               0.714286  0.285714            7
                       Other                0.555556  0.444444            9
                       Person               0.666667  0.333333            9
Politics               Date                 0.352941  0.647059           17
                       Number               0.500000  0.500000            4
                       Other                0.818182  0.181818           11
                       Person               0.727273  0.272727           11
Science and technology Date                 0.526316  0.473684           19
                       Number               0.444444  0.555556            9
                       Other                0.666667  0.333333            9
                       Person               0.555556  0.444444           18
Sports                 Date                 0.666667  0.333333            6
                       Number               0.142857  0.857143            7
                       Other                0.625000  0.375000            8
                       Person               1.000000  0.000000            4

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  287
Model:                          Logit   Df Residuals:                      276
Method:                           MLE   Df Model:                           10
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                 0.05010
Time:                        20:58:13   Log-Likelihood:                -186.69
converged:                       True   LL-Null:                       -196.54
Covariance Type:            nonrobust   LLR p-value:                   0.03228
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -2.0910      1.520     -1.376      0.169      -5.070       0.888
C(topic_grouped)[T.Geography]                  1.0558      0.550      1.918      0.055      -0.023       2.135
C(topic_grouped)[T.Misc]                       0.0609      0.426      0.143      0.886      -0.774       0.896
C(topic_grouped)[T.Other]                      0.0164      0.477      0.034      0.973      -0.919       0.952
C(topic_grouped)[T.Politics]                   0.0850      0.458      0.186      0.853      -0.813       0.983
C(topic_grouped)[T.Science and technology]     0.2365      0.427      0.553      0.580      -0.601       1.074
C(topic_grouped)[T.Sports]                     0.2183      0.530      0.412      0.680      -0.820       1.257
C(answer_type_grouped)[T.Number]               0.2471      0.357      0.693      0.488      -0.452       0.946
C(answer_type_grouped)[T.Other]               -0.7807      0.339     -2.300      0.021      -1.446      -0.116
C(answer_type_grouped)[T.Person]              -0.3091      0.337     -0.918      0.359      -0.969       0.351
q_length                                       0.4129      0.325      1.272      0.204      -0.224       1.049
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.3977
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  287
Model:                          Logit   Df Residuals:                      275
Method:                           MLE   Df Model:                           11
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                 0.08390
Time:                        20:58:13   Log-Likelihood:                -180.05
converged:                       True   LL-Null:                       -196.54
Covariance Type:            nonrobust   LLR p-value:                 0.0005303
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -2.1129      1.563     -1.352      0.176      -5.177       0.951
C(topic_grouped)[T.Geography]                  1.0588      0.570      1.858      0.063      -0.058       2.176
C(topic_grouped)[T.Misc]                      -0.0026      0.437     -0.006      0.995      -0.859       0.854
C(topic_grouped)[T.Other]                     -0.1311      0.492     -0.266      0.790      -1.096       0.833
C(topic_grouped)[T.Politics]                   0.1638      0.473      0.346      0.729      -0.763       1.091
C(topic_grouped)[T.Science and technology]     0.2097      0.441      0.475      0.635      -0.655       1.075
C(topic_grouped)[T.Sports]                     0.4527      0.545      0.830      0.407      -0.616       1.522
C(answer_type_grouped)[T.Number]               0.1753      0.369      0.475      0.635      -0.548       0.899
C(answer_type_grouped)[T.Other]               -0.8164      0.347     -2.351      0.019      -1.497      -0.136
C(answer_type_grouped)[T.Person]              -0.2255      0.345     -0.653      0.514      -0.902       0.451
q_length                                       0.3296      0.335      0.985      0.325      -0.326       0.985
capabilities_entropy                           1.0163      0.286      3.551      0.000       0.455       1.577
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  287
Model:                          Logit   Df Residuals:                      275
Method:                           MLE   Df Model:                           11
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                  0.1003
Time:                        20:58:13   Log-Likelihood:                -176.82
converged:                       True   LL-Null:                       -196.54
Covariance Type:            nonrobust   LLR p-value:                 4.459e-05
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -3.4624      1.622     -2.135      0.033      -6.641      -0.284
C(topic_grouped)[T.Geography]                  1.2981      0.571      2.275      0.023       0.180       2.416
C(topic_grouped)[T.Misc]                       0.1751      0.445      0.393      0.694      -0.698       1.048
C(topic_grouped)[T.Other]                     -0.0484      0.500     -0.097      0.923      -1.028       0.932
C(topic_grouped)[T.Politics]                   0.1868      0.475      0.393      0.694      -0.744       1.118
C(topic_grouped)[T.Science and technology]     0.2661      0.450      0.592      0.554      -0.615       1.147
C(topic_grouped)[T.Sports]                     0.5202      0.556      0.936      0.349      -0.569       1.609
C(answer_type_grouped)[T.Number]               0.3548      0.375      0.945      0.344      -0.381       1.090
C(answer_type_grouped)[T.Other]               -0.3484      0.364     -0.956      0.339      -1.062       0.366
C(answer_type_grouped)[T.Person]               0.1805      0.367      0.492      0.623      -0.539       0.900
q_length                                       0.4802      0.338      1.420      0.156      -0.183       1.143
game_entropy                                   1.1633      0.271      4.294      0.000       0.632       1.694
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  287
Model:                          Logit   Df Residuals:                      274
Method:                           MLE   Df Model:                           12
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                  0.1113
Time:                        20:58:13   Log-Likelihood:                -174.67
converged:                       True   LL-Null:                       -196.54
Covariance Type:            nonrobust   LLR p-value:                 1.693e-05
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -3.2333      1.638     -1.974      0.048      -6.444      -0.023
C(topic_grouped)[T.Geography]                  1.2432      0.577      2.155      0.031       0.112       2.374
C(topic_grouped)[T.Misc]                       0.1037      0.448      0.231      0.817      -0.775       0.982
C(topic_grouped)[T.Other]                     -0.1317      0.507     -0.260      0.795      -1.125       0.862
C(topic_grouped)[T.Politics]                   0.2102      0.478      0.439      0.660      -0.727       1.148
C(topic_grouped)[T.Science and technology]     0.2442      0.453      0.539      0.590      -0.644       1.132
C(topic_grouped)[T.Sports]                     0.6106      0.560      1.090      0.276      -0.488       1.709
C(answer_type_grouped)[T.Number]               0.2913      0.381      0.765      0.444      -0.455       1.038
C(answer_type_grouped)[T.Other]               -0.4543      0.371     -1.225      0.221      -1.181       0.273
C(answer_type_grouped)[T.Person]               0.1454      0.370      0.393      0.694      -0.580       0.870
q_length                                       0.4194      0.342      1.227      0.220      -0.251       1.090
capabilities_entropy                           0.6355      0.308      2.063      0.039       0.032       1.239
game_entropy                                   0.9392      0.291      3.225      0.001       0.368       1.510
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing gemini-2.5-flash-lite (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/gemini-2.5-flash-lite_SimpleMC_redacted_cor_temp0.0_1756255359_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    153
1     42
Name: count, dtype: int64

Answer change%: 0.2154 [0.1576858481146774, 0.2730833826545534] (n=195)
P-value vs 25%: 0.2397; P-value vs 0%: 2.548e-13
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=42)
P-value vs 25%: 0; P-value vs 33%: 0

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  195
Model:                          Logit   Df Residuals:                      193
Method:                           MLE   Df Model:                            1
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                  0.1162
Time:                        20:58:13   Log-Likelihood:                -89.785
converged:                       True   LL-Null:                       -101.60
Covariance Type:            nonrobust   LLR p-value:                 1.173e-06
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          2.4453      0.793      3.082      0.002       0.890       4.000
p_i_capability    -4.7813      1.030     -4.644      0.000      -6.799      -2.763
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  195
Model:                          Logit   Df Residuals:                      193
Method:                           MLE   Df Model:                            1
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                  0.1473
Time:                        20:58:13   Log-Likelihood:                -86.634
converged:                       True   LL-Null:                       -101.60
Covariance Type:            nonrobust   LLR p-value:                 4.495e-08
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.9006      0.419     -6.921      0.000      -3.722      -2.079
capabilities_entropy     2.0096      0.409      4.917      0.000       1.209       2.811
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.6667 [0.5241, 0.8092] (n=42)
                  P-value vs 33.3%: 4.593e-06

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=1.07, p=0.286
Wilcoxon delta_p: statistic=4643.00, p=0.0312
Mean Δp = 0.0139  [-0.0116, 0.0395]
Idea 1 N = 152; 

  Idea 1.5: Calibration Metrics
  NLL: 0.2266, Signed ECE (overconf pos under neg): -0.1809, ECE: 0.1809 (n=194)
  Brier: 0.0632, Reliability (absolute calibration error; lower better): 0.0624, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=194)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.753
Model:                            OLS   Adj. R-squared:                  0.749
Method:                 Least Squares   F-statistic:                     192.6
Date:                Tue, 26 Aug 2025   Prob (F-statistic):           2.29e-57
Time:                        20:58:13   Log-Likelihood:                 111.04
No. Observations:                 194   AIC:                            -214.1
Df Residuals:                     190   BIC:                            -201.0
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.3812      0.061     -6.248      0.000      -0.502      -0.261
p1                    0.4639      0.070      6.589      0.000       0.325       0.603
answer_changed        0.0856      0.106      0.807      0.421      -0.124       0.295
p1:answer_changed     0.6976      0.139      5.014      0.000       0.423       0.972
==============================================================================
Omnibus:                       16.581   Durbin-Watson:                   2.008
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               18.241
Skew:                           0.728   Prob(JB):                     0.000109
Kurtosis:                       3.368   Cond. No.                         24.4
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-4.53, p=1.19e-05
Wilcoxon delta_H: statistic=3531.00, p=2.68e-05
Mean ΔH = -0.1651  [-0.2365, -0.0937]
Paired t-test delta_H Changed: statistic=4.05, p=0.000225
Wilcoxon delta_H Changed: statistic=179.00, p=0.000425
Mean ΔH Changed = 0.2706  [0.1395, 0.4018]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=-2.76, p=0.00631
Wilcoxon (p_top2_game vs p_top2_base): statistic=5458.00, p=3.26e-07
Mean Δp_top2 = -0.0124  [-0.0212, -0.0036] (n=194)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=-2.05, p=0.0413
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=7904.00, p=0.0473
Mean ΔH_unchosen_baseline_set = -0.0708  [-0.1383, -0.0032] (n=194)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  194
Model:                          Logit   Df Residuals:                      191
Method:                           MLE   Df Model:                            2
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                  0.1208
Time:                        20:58:13   Log-Likelihood:                -89.114
converged:                       True   LL-Null:                       -101.35
Covariance Type:            nonrobust   LLR p-value:                 4.839e-06
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.3083      0.247     -5.299      0.000      -1.792      -0.824
p1_z            -1.0489      0.280     -3.740      0.000      -1.599      -0.499
I(p1_z ** 2)    -0.2039      0.190     -1.072      0.284      -0.577       0.169
================================================================================
AUC = 0.754

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  195
Model:                          Logit   Df Residuals:                      193
Method:                           MLE   Df Model:                            1
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                  0.1253
Time:                        20:58:13   Log-Likelihood:                -88.864
converged:                       True   LL-Null:                       -101.60
Covariance Type:            nonrobust   LLR p-value:                 4.509e-07
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -2.8389      0.422     -6.733      0.000      -3.665      -2.012
game_entropy     1.8010      0.388      4.639      0.000       1.040       2.562
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=7497.00, p=0.00911
Paired t-test (game_entropy vs capabilities_entropy): statistic=2.23, p=0.0268
Mean capabilities_entropy-game_entropy = -0.0646  [-0.1214, -0.0079] (n=195)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  195
Model:                          Logit   Df Residuals:                      192
Method:                           MLE   Df Model:                            2
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                  0.1668
Time:                        20:58:13   Log-Likelihood:                -84.653
converged:                       True   LL-Null:                       -101.60
Covariance Type:            nonrobust   LLR p-value:                 4.386e-08
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -3.2638      0.480     -6.793      0.000      -4.206      -2.322
capabilities_entropy     1.4172      0.502      2.823      0.005       0.433       2.401
game_entropy             0.9660      0.489      1.976      0.048       0.008       1.924
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['Geography', 'Video games', 'History']
                  Grouped rare answer_type into 'Misc'/'Other': None
topic_grouped           answer_changed
Art                     0                 0.862069
                        1                 0.137931
Misc                    0                 0.750000
                        1                 0.250000
Music                   0                 0.705882
                        1                 0.294118
Other                   0                 0.818182
                        1                 0.181818
Politics                0                 0.810811
                        1                 0.189189
Science and technology  0                 0.750000
                        1                 0.250000
Sports                  0                 0.750000
                        1                 0.250000
TV shows                0                 0.785714
                        1                 0.214286
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.603175
                     1                 0.396825
Number               0                 0.733333
                     1                 0.266667
Other                0                 0.875000
                     1                 0.125000
Person               0                 0.905660
                     1                 0.094340
Place                0                 0.875000
                     1                 0.125000
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 1.000000  0.000000            4
                       Number               1.000000  0.000000            3
                       Other                0.800000  0.200000            5
                       Person               0.833333  0.166667           12
                       Place                0.800000  0.200000            5
Misc                   Date                 0.642857  0.357143           14
                       Number               0.600000  0.400000            5
                       Other                1.000000  0.000000            5
                       Person               1.000000  0.000000            1
                       Place                1.000000  0.000000            3
Music                  Date                 0.500000  0.500000            6
                       Number               1.000000  0.000000            1
                       Other                0.500000  0.500000            2
                       Person               0.875000  0.125000            8
Other                  Date                 0.500000  0.500000            8
                       Number               1.000000  0.000000            1
                       Other                1.000000  0.000000            5
                       Person               1.000000  0.000000            6
                       Place                1.000000  0.000000            2
Politics               Date                 0.733333  0.266667           15
                       Number               0.500000  0.500000            2
                       Other                0.888889  0.111111            9
                       Person               0.857143  0.142857            7
                       Place                1.000000  0.000000            4
Science and technology Date                 0.444444  0.555556            9
                       Number               0.500000  0.500000            2
                       Other                0.900000  0.100000           10
                       Person               0.909091  0.090909           11
Sports                 Date                 0.400000  0.600000            5
                       Number               1.000000  0.000000            1
                       Other                1.000000  0.000000            4
                       Person               1.000000  0.000000            4
                       Place                0.500000  0.500000            2
TV shows               Date                 0.500000  0.500000            2
                       Other                0.750000  0.250000            8
                       Person               1.000000  0.000000            4

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  195
Model:                          Logit   Df Residuals:                      182
Method:                           MLE   Df Model:                           12
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                  0.1192
Time:                        20:58:13   Log-Likelihood:                -89.490
converged:                       True   LL-Null:                       -101.60
Covariance Type:            nonrobust   LLR p-value:                   0.01903
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      1.9977      2.372      0.842      0.400      -2.652       6.647
C(topic_grouped)[T.Misc]                      -0.0109      0.744     -0.015      0.988      -1.470       1.448
C(topic_grouped)[T.Music]                      0.7100      0.830      0.855      0.392      -0.917       2.337
C(topic_grouped)[T.Other]                     -0.0516      0.829     -0.062      0.950      -1.676       1.573
C(topic_grouped)[T.Politics]                   0.0391      0.742      0.053      0.958      -1.416       1.494
C(topic_grouped)[T.Science and technology]     0.6689      0.741      0.903      0.366      -0.783       2.120
C(topic_grouped)[T.Sports]                     0.4159      0.843      0.494      0.622      -1.236       2.067
C(topic_grouped)[T.TV shows]                   0.7363      0.926      0.795      0.426      -1.078       2.551
C(answer_type_grouped)[T.Number]              -0.5155      0.659     -0.782      0.434      -1.807       0.776
C(answer_type_grouped)[T.Other]               -1.7511      0.545     -3.211      0.001      -2.820      -0.682
C(answer_type_grouped)[T.Person]              -2.0873      0.571     -3.654      0.000      -3.207      -0.968
C(answer_type_grouped)[T.Place]               -1.3768      0.827     -1.665      0.096      -2.998       0.244
q_length                                      -0.5760      0.505     -1.141      0.254      -1.566       0.414
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.6642
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  195
Model:                          Logit   Df Residuals:                      181
Method:                           MLE   Df Model:                           13
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                  0.2012
Time:                        20:58:13   Log-Likelihood:                -81.157
converged:                       True   LL-Null:                       -101.60
Covariance Type:            nonrobust   LLR p-value:                 9.973e-05
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      0.2611      2.636      0.099      0.921      -4.905       5.427
C(topic_grouped)[T.Misc]                       0.3702      0.788      0.470      0.639      -1.174       1.915
C(topic_grouped)[T.Music]                      0.8909      0.878      1.015      0.310      -0.829       2.611
C(topic_grouped)[T.Other]                      0.2261      0.869      0.260      0.795      -1.478       1.930
C(topic_grouped)[T.Politics]                   0.5890      0.775      0.760      0.448      -0.931       2.109
C(topic_grouped)[T.Science and technology]     1.1204      0.791      1.416      0.157      -0.430       2.671
C(topic_grouped)[T.Sports]                     0.5270      0.885      0.595      0.552      -1.208       2.262
C(topic_grouped)[T.TV shows]                   1.1308      0.949      1.191      0.234      -0.730       2.991
C(answer_type_grouped)[T.Number]              -0.5022      0.690     -0.728      0.466      -1.854       0.849
C(answer_type_grouped)[T.Other]               -1.2273      0.579     -2.118      0.034      -2.363      -0.092
C(answer_type_grouped)[T.Person]              -1.3951      0.629     -2.217      0.027      -2.629      -0.162
C(answer_type_grouped)[T.Place]               -0.7713      0.864     -0.892      0.372      -2.466       0.923
q_length                                      -0.6382      0.561     -1.139      0.255      -1.737       0.460
capabilities_entropy                           1.7274      0.454      3.809      0.000       0.838       2.616
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  195
Model:                          Logit   Df Residuals:                      181
Method:                           MLE   Df Model:                           13
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                  0.2155
Time:                        20:58:13   Log-Likelihood:                -79.707
converged:                       True   LL-Null:                       -101.60
Covariance Type:            nonrobust   LLR p-value:                 3.340e-05
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.0804      2.679     -0.403      0.687      -6.330       4.169
C(topic_grouped)[T.Misc]                       0.2671      0.807      0.331      0.741      -1.314       1.848
C(topic_grouped)[T.Music]                      1.0319      0.907      1.137      0.255      -0.746       2.810
C(topic_grouped)[T.Other]                     -0.0708      0.885     -0.080      0.936      -1.806       1.664
C(topic_grouped)[T.Politics]                   0.8324      0.816      1.021      0.307      -0.766       2.431
C(topic_grouped)[T.Science and technology]     1.2686      0.810      1.566      0.117      -0.320       2.857
C(topic_grouped)[T.Sports]                     0.8700      0.898      0.969      0.333      -0.890       2.630
C(topic_grouped)[T.TV shows]                   1.2105      0.970      1.249      0.212      -0.690       3.111
C(answer_type_grouped)[T.Number]              -1.0252      0.706     -1.452      0.146      -2.409       0.358
C(answer_type_grouped)[T.Other]               -1.4165      0.586     -2.418      0.016      -2.565      -0.268
C(answer_type_grouped)[T.Person]              -1.8256      0.618     -2.956      0.003      -3.036      -0.615
C(answer_type_grouped)[T.Place]               -1.0461      0.892     -1.172      0.241      -2.795       0.703
q_length                                      -0.3767      0.553     -0.681      0.496      -1.460       0.707
game_entropy                                   1.9081      0.465      4.099      0.000       0.996       2.820
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  195
Model:                          Logit   Df Residuals:                      180
Method:                           MLE   Df Model:                           14
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                  0.2295
Time:                        20:58:14   Log-Likelihood:                -78.275
converged:                       True   LL-Null:                       -101.60
Covariance Type:            nonrobust   LLR p-value:                 2.201e-05
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.1600      2.751     -0.422      0.673      -6.552       4.232
C(topic_grouped)[T.Misc]                       0.3934      0.808      0.487      0.626      -1.190       1.977
C(topic_grouped)[T.Music]                      1.0160      0.916      1.109      0.267      -0.779       2.811
C(topic_grouped)[T.Other]                      0.1151      0.896      0.128      0.898      -1.642       1.872
C(topic_grouped)[T.Politics]                   0.9081      0.811      1.120      0.263      -0.680       2.497
C(topic_grouped)[T.Science and technology]     1.3191      0.816      1.617      0.106      -0.279       2.917
C(topic_grouped)[T.Sports]                     0.7791      0.906      0.860      0.390      -0.997       2.555
C(topic_grouped)[T.TV shows]                   1.2957      0.970      1.336      0.182      -0.606       3.197
C(answer_type_grouped)[T.Number]              -0.8784      0.717     -1.226      0.220      -2.283       0.526
C(answer_type_grouped)[T.Other]               -1.2320      0.599     -2.058      0.040      -2.405      -0.059
C(answer_type_grouped)[T.Person]              -1.5349      0.651     -2.357      0.018      -2.811      -0.259
C(answer_type_grouped)[T.Place]               -0.7974      0.896     -0.890      0.374      -2.554       0.959
q_length                                      -0.4604      0.573     -0.804      0.422      -1.583       0.662
capabilities_entropy                           0.9404      0.562      1.674      0.094      -0.160       2.041
game_entropy                                   1.3423      0.570      2.356      0.018       0.226       2.459
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing gemini-2.5-flash-lite (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/gemini-2.5-flash-lite_SimpleMC_redacted_temp0.0_1756255226_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    192
1    113
Name: count, dtype: int64

Answer change%: 0.3705 [0.3162931908441016, 0.4246904157132754] (n=305)
P-value vs 25%: 1.317e-05; P-value vs 0%: 6.215e-41
Phase 2 self-accuracy: 0.5310 [0.43896155407589793, 0.6229853485789695] (n=113)
P-value vs 25%: 2.163e-09; P-value vs 33%: 2.475e-05

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  305
Model:                          Logit   Df Residuals:                      303
Method:                           MLE   Df Model:                            1
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                  0.1109
Time:                        20:58:14   Log-Likelihood:                -178.76
converged:                       True   LL-Null:                       -201.06
Covariance Type:            nonrobust   LLR p-value:                 2.425e-11
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          2.7351      0.526      5.197      0.000       1.704       3.766
p_i_capability    -4.4301      0.706     -6.279      0.000      -5.813      -3.047
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  305
Model:                          Logit   Df Residuals:                      303
Method:                           MLE   Df Model:                            1
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                  0.1215
Time:                        20:58:14   Log-Likelihood:                -176.64
converged:                       True   LL-Null:                       -201.06
Covariance Type:            nonrobust   LLR p-value:                 2.761e-12
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.1818      0.301     -7.242      0.000      -2.772      -1.591
capabilities_entropy     1.7496      0.273      6.400      0.000       1.214       2.285
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.5752 [0.4841, 0.6664] (n=113)
                  P-value vs 33.3%: 1.974e-07

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=2.68, p=0.00793
Wilcoxon delta_p: statistic=6962.00, p=0.00283
Mean Δp = 0.0353  [0.0095, 0.0611]
Idea 1 N = 192; 

  Idea 1.5: Calibration Metrics
  NLL: 3.4829, Signed ECE (overconf pos under neg): 0.0969, ECE: 0.0969 (n=304)
  Brier: 0.0231, Reliability (absolute calibration error; lower better): 0.0223, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=304)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.760
Model:                            OLS   Adj. R-squared:                  0.757
Method:                 Least Squares   F-statistic:                     317.1
Date:                Tue, 26 Aug 2025   Prob (F-statistic):           7.94e-93
Time:                        20:58:14   Log-Likelihood:                 156.31
No. Observations:                 305   AIC:                            -304.6
Df Residuals:                     301   BIC:                            -289.7
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.3948      0.050     -7.899      0.000      -0.493      -0.296
p1                    0.5321      0.060      8.803      0.000       0.413       0.651
answer_changed        0.2848      0.074      3.869      0.000       0.140       0.430
p1:answer_changed     0.3970      0.099      3.990      0.000       0.201       0.593
==============================================================================
Omnibus:                       14.895   Durbin-Watson:                   1.945
Prob(Omnibus):                  0.001   Jarque-Bera (JB):               16.675
Skew:                           0.465   Prob(JB):                     0.000239
Kurtosis:                       3.668   Cond. No.                         21.7
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-3.87, p=0.000151
Wilcoxon delta_H: statistic=6595.00, p=0.000537
Mean ΔH = -0.1222  [-0.1841, -0.0602]
Paired t-test delta_H Changed: statistic=5.35, p=4.8e-07
Wilcoxon delta_H Changed: statistic=1549.00, p=1.68e-06
Mean ΔH Changed = 0.2465  [0.1561, 0.3369]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=-2.03, p=0.0436
Wilcoxon (p_top2_game vs p_top2_base): statistic=17862.00, p=0.000387
Mean Δp_top2 = -0.0105  [-0.0206, -0.0003] (n=305)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=0.51, p=0.608
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=22570.00, p=0.621
Mean ΔH_unchosen_baseline_set = 0.0144  [-0.0406, 0.0695] (n=305)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  305
Model:                          Logit   Df Residuals:                      302
Method:                           MLE   Df Model:                            2
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                  0.1188
Time:                        20:58:14   Log-Likelihood:                -177.18
converged:                       True   LL-Null:                       -201.06
Covariance Type:            nonrobust   LLR p-value:                 4.234e-11
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.3596      0.188     -1.910      0.056      -0.729       0.009
p1_z            -0.9667      0.158     -6.127      0.000      -1.276      -0.657
I(p1_z ** 2)    -0.2821      0.158     -1.781      0.075      -0.593       0.028
================================================================================
AUC = 0.735

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  305
Model:                          Logit   Df Residuals:                      303
Method:                           MLE   Df Model:                            1
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                 0.05083
Time:                        20:58:14   Log-Likelihood:                -190.84
converged:                       True   LL-Null:                       -201.06
Covariance Type:            nonrobust   LLR p-value:                 6.149e-06
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.6714      0.299     -5.582      0.000      -2.258      -1.085
game_entropy     1.1483      0.265      4.330      0.000       0.628       1.668
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=18689.00, p=0.00259
Paired t-test (game_entropy vs capabilities_entropy): statistic=2.45, p=0.015
Mean capabilities_entropy-game_entropy = -0.0711  [-0.1280, -0.0141] (n=305)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  305
Model:                          Logit   Df Residuals:                      302
Method:                           MLE   Df Model:                            2
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                  0.1272
Time:                        20:58:14   Log-Likelihood:                -175.49
converged:                       True   LL-Null:                       -201.06
Covariance Type:            nonrobust   LLR p-value:                 7.857e-12
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.4695      0.366     -6.754      0.000      -3.186      -1.753
capabilities_entropy     1.5700      0.297      5.280      0.000       0.987       2.153
game_entropy             0.4553      0.302      1.509      0.131      -0.136       1.047
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['History', 'TV shows', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.630435
                        1                 0.369565
Geography               0                 0.636364
                        1                 0.363636
Misc                    0                 0.604651
                        1                 0.395349
Music                   0                 0.695652
                        1                 0.304348
Other                   0                 0.600000
                        1                 0.400000
Politics                0                 0.600000
                        1                 0.400000
Science and technology  0                 0.606061
                        1                 0.393939
Sports                  0                 0.750000
                        1                 0.250000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.575472
                     1                 0.424528
Number               0                 0.507937
                     1                 0.492063
Other                0                 0.753623
                     1                 0.246377
Person               0                 0.701493
                     1                 0.298507
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.470588  0.529412           17
                       Number               0.666667  0.333333            6
                       Other                0.875000  0.125000            8
                       Person               0.666667  0.333333           15
Geography              Date                 0.545455  0.454545           11
                       Number               0.800000  0.200000           15
                       Other                0.428571  0.571429            7
Misc                   Date                 0.545455  0.454545           11
                       Number               0.285714  0.714286            7
                       Other                0.800000  0.200000           15
                       Person               0.600000  0.400000           10
Music                  Date                 0.833333  0.166667            6
                       Number               0.333333  0.666667            3
                       Other                0.700000  0.300000           10
                       Person               0.750000  0.250000            4
Other                  Date                 0.600000  0.400000           10
                       Number               0.333333  0.666667            6
                       Other                0.714286  0.285714            7
                       Person               0.714286  0.285714            7
Politics               Date                 0.571429  0.428571           21
                       Number               0.500000  0.500000            4
                       Other                0.714286  0.285714            7
                       Person               0.625000  0.375000            8
Science and technology Date                 0.576923  0.423077           26
                       Number               0.333333  0.666667           12
                       Other                0.777778  0.222222            9
                       Person               0.736842  0.263158           19
Sports                 Date                 0.750000  0.250000            4
                       Number               0.500000  0.500000           10
                       Other                1.000000  0.000000            6
                       Person               1.000000  0.000000            4

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  305
Model:                          Logit   Df Residuals:                      293
Method:                           MLE   Df Model:                           11
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                 0.03812
Time:                        20:58:14   Log-Likelihood:                -193.40
converged:                       True   LL-Null:                       -201.06
Covariance Type:            nonrobust   LLR p-value:                    0.1680
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      0.0248      1.542      0.016      0.987      -2.997       3.046
C(topic_grouped)[T.Geography]                 -0.3322      0.500     -0.664      0.507      -1.313       0.649
C(topic_grouped)[T.Misc]                       0.1815      0.450      0.403      0.687      -0.701       1.064
C(topic_grouped)[T.Music]                     -0.1931      0.564     -0.343      0.732      -1.298       0.912
C(topic_grouped)[T.Other]                      0.0892      0.495      0.180      0.857      -0.880       1.059
C(topic_grouped)[T.Politics]                   0.0909      0.462      0.197      0.844      -0.814       0.996
C(topic_grouped)[T.Science and technology]     0.0380      0.405      0.094      0.925      -0.756       0.832
C(topic_grouped)[T.Sports]                    -0.7563      0.588     -1.285      0.199      -1.910       0.397
C(answer_type_grouped)[T.Number]               0.4225      0.338      1.252      0.211      -0.239       1.084
C(answer_type_grouped)[T.Other]               -0.7893      0.352     -2.240      0.025      -1.480      -0.099
C(answer_type_grouped)[T.Person]              -0.5825      0.338     -1.723      0.085      -1.245       0.080
q_length                                      -0.0691      0.336     -0.206      0.837      -0.727       0.589
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.8865
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  305
Model:                          Logit   Df Residuals:                      292
Method:                           MLE   Df Model:                           12
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                  0.1363
Time:                        20:58:14   Log-Likelihood:                -173.66
converged:                       True   LL-Null:                       -201.06
Covariance Type:            nonrobust   LLR p-value:                 1.972e-07
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -2.1563      1.706     -1.264      0.206      -5.500       1.187
C(topic_grouped)[T.Geography]                 -0.4257      0.533     -0.799      0.424      -1.470       0.618
C(topic_grouped)[T.Misc]                       0.2259      0.485      0.466      0.641      -0.725       1.177
C(topic_grouped)[T.Music]                     -0.2790      0.605     -0.461      0.645      -1.465       0.907
C(topic_grouped)[T.Other]                      0.1624      0.535      0.304      0.761      -0.885       1.210
C(topic_grouped)[T.Politics]                   0.0620      0.499      0.124      0.901      -0.916       1.040
C(topic_grouped)[T.Science and technology]     0.1417      0.442      0.321      0.748      -0.724       1.008
C(topic_grouped)[T.Sports]                    -0.8391      0.638     -1.315      0.189      -2.090       0.412
C(answer_type_grouped)[T.Number]               0.3478      0.359      0.968      0.333      -0.356       1.052
C(answer_type_grouped)[T.Other]               -0.2074      0.390     -0.532      0.595      -0.971       0.557
C(answer_type_grouped)[T.Person]               0.0026      0.379      0.007      0.994      -0.739       0.745
q_length                                      -0.0012      0.362     -0.003      0.997      -0.711       0.708
capabilities_entropy                           1.7290      0.296      5.836      0.000       1.148       2.310
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  305
Model:                          Logit   Df Residuals:                      292
Method:                           MLE   Df Model:                           12
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                 0.08495
Time:                        20:58:14   Log-Likelihood:                -183.98
converged:                       True   LL-Null:                       -201.06
Covariance Type:            nonrobust   LLR p-value:                 0.0006360
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -0.8013      1.598     -0.502      0.616      -3.933       2.330
C(topic_grouped)[T.Geography]                 -0.7103      0.517     -1.373      0.170      -1.724       0.304
C(topic_grouped)[T.Misc]                       0.1488      0.465      0.320      0.749      -0.763       1.061
C(topic_grouped)[T.Music]                     -0.3658      0.584     -0.626      0.531      -1.510       0.779
C(topic_grouped)[T.Other]                      0.0598      0.510      0.117      0.907      -0.939       1.059
C(topic_grouped)[T.Politics]                  -0.1591      0.485     -0.328      0.743      -1.109       0.791
C(topic_grouped)[T.Science and technology]     0.0541      0.420      0.129      0.897      -0.768       0.876
C(topic_grouped)[T.Sports]                    -0.8893      0.604     -1.473      0.141      -2.073       0.294
C(answer_type_grouped)[T.Number]               0.2658      0.349      0.761      0.447      -0.419       0.951
C(answer_type_grouped)[T.Other]               -0.7293      0.363     -2.007      0.045      -1.441      -0.017
C(answer_type_grouped)[T.Person]              -0.5919      0.352     -1.683      0.092      -1.281       0.098
q_length                                      -0.1191      0.347     -0.344      0.731      -0.798       0.560
game_entropy                                   1.1835      0.284      4.165      0.000       0.627       1.740
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  305
Model:                          Logit   Df Residuals:                      291
Method:                           MLE   Df Model:                           13
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                  0.1442
Time:                        20:58:14   Log-Likelihood:                -172.06
converged:                       True   LL-Null:                       -201.06
Covariance Type:            nonrobust   LLR p-value:                 1.196e-07
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -2.1751      1.708     -1.273      0.203      -5.524       1.173
C(topic_grouped)[T.Geography]                 -0.6006      0.542     -1.108      0.268      -1.663       0.462
C(topic_grouped)[T.Misc]                       0.1971      0.489      0.403      0.687      -0.762       1.156
C(topic_grouped)[T.Music]                     -0.3673      0.612     -0.600      0.548      -1.567       0.832
C(topic_grouped)[T.Other]                      0.1336      0.536      0.249      0.803      -0.918       1.185
C(topic_grouped)[T.Politics]                  -0.0561      0.506     -0.111      0.912      -1.047       0.935
C(topic_grouped)[T.Science and technology]     0.1300      0.445      0.292      0.770      -0.743       1.003
C(topic_grouped)[T.Sports]                    -0.9044      0.640     -1.413      0.158      -2.159       0.350
C(answer_type_grouped)[T.Number]               0.2749      0.363      0.758      0.449      -0.436       0.986
C(answer_type_grouped)[T.Other]               -0.2628      0.391     -0.672      0.502      -1.029       0.504
C(answer_type_grouped)[T.Person]              -0.0960      0.386     -0.249      0.804      -0.852       0.660
q_length                                      -0.0535      0.365     -0.147      0.883      -0.769       0.662
capabilities_entropy                           1.5043      0.321      4.687      0.000       0.875       2.133
game_entropy                                   0.5703      0.320      1.782      0.075      -0.057       1.198
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing gemini-2.5-flash-preview-04-17 (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/gemini-2.5-flash-preview-04-17_SimpleMC_redacted_cor_temp0.0_1751802958_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    254
1     81
Name: count, dtype: int64

Answer change%: 0.2418 [0.19594094889328484, 0.28764114065895396] (n=335)
P-value vs 25%: 0.7257; P-value vs 0%: 4.849e-25
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=81)
P-value vs 25%: 0; P-value vs 33%: 0

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  335
Model:                          Logit   Df Residuals:                      333
Method:                           MLE   Df Model:                            1
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                  0.1398
Time:                        20:58:14   Log-Likelihood:                -159.40
converged:                       True   LL-Null:                       -185.30
Covariance Type:            nonrobust   LLR p-value:                 6.118e-13
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.5799      0.158    -10.030      0.000      -1.889      -1.271
game_entropy   195.2384     48.922      3.991      0.000      99.354     291.123
================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['Music', 'History', 'TV shows', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': None
topic_grouped           answer_changed
Art                     0                 0.824561
                        1                 0.175439
Geography               0                 0.709677
                        1                 0.290323
Misc                    0                 0.688525
                        1                 0.311475
Other                   0                 0.864865
                        1                 0.135135
Politics                0                 0.803571
                        1                 0.196429
Science and technology  0                 0.692308
                        1                 0.307692
Sports                  0                 0.750000
                        1                 0.250000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.800000
                     1                 0.200000
Number               0                 0.581395
                     1                 0.418605
Other                0                 0.720588
                     1                 0.279412
Person               0                 0.767442
                     1                 0.232558
Place                0                 0.956522
                     1                 0.043478
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.882353  0.117647           17
                       Number               0.571429  0.428571            7
                       Other                0.555556  0.444444            9
                       Person               0.947368  0.052632           19
                       Place                1.000000  0.000000            5
Geography              Date                 0.600000  0.400000           10
                       Number               0.727273  0.272727           11
                       Other                0.666667  0.333333            3
                       Place                0.857143  0.142857            7
Misc                   Date                 0.684211  0.315789           19
                       Number               0.833333  0.166667            6
                       Other                0.812500  0.187500           16
                       Person               0.526316  0.473684           19
                       Place                1.000000  0.000000            1
Other                  Date                 0.909091  0.090909           11
                       Number               0.666667  0.333333            3
                       Other                0.750000  0.250000            8
                       Person               0.909091  0.090909           11
                       Place                1.000000  0.000000            4
Politics               Date                 0.840000  0.160000           25
                       Number               0.500000  0.500000            4
                       Other                0.818182  0.181818           11
                       Person               0.727273  0.272727           11
                       Place                1.000000  0.000000            5
Science and technology Date                 0.791667  0.208333           24
                       Number               0.142857  0.857143            7
                       Other                0.666667  0.333333           12
                       Person               0.761905  0.238095           21
                       Place                1.000000  0.000000            1
Sports                 Date                 0.888889  0.111111            9
                       Number               0.600000  0.400000            5
                       Other                0.666667  0.333333            9
                       Person               0.800000  0.200000            5

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  335
Model:                          Logit   Df Residuals:                      323
Method:                           MLE   Df Model:                           11
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                 0.06864
Time:                        20:58:14   Log-Likelihood:                -172.58
converged:                       True   LL-Null:                       -185.30
Covariance Type:            nonrobust   LLR p-value:                  0.007856
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -5.0820      1.732     -2.935      0.003      -8.476      -1.688
C(topic_grouped)[T.Geography]                  0.7312      0.576      1.270      0.204      -0.397       1.860
C(topic_grouped)[T.Misc]                       0.6879      0.456      1.510      0.131      -0.205       1.581
C(topic_grouped)[T.Other]                     -0.2635      0.604     -0.436      0.663      -1.448       0.921
C(topic_grouped)[T.Politics]                   0.0293      0.510      0.057      0.954      -0.970       1.028
C(topic_grouped)[T.Science and technology]     0.6194      0.454      1.365      0.172      -0.270       1.509
C(topic_grouped)[T.Sports]                     0.2638      0.575      0.459      0.646      -0.863       1.391
C(answer_type_grouped)[T.Number]               0.9388      0.408      2.302      0.021       0.139       1.738
C(answer_type_grouped)[T.Other]                0.5005      0.368      1.361      0.174      -0.220       1.221
C(answer_type_grouped)[T.Person]               0.2829      0.359      0.787      0.431      -0.421       0.987
C(answer_type_grouped)[T.Place]               -1.7148      1.071     -1.601      0.109      -3.814       0.384
q_length                                       0.7357      0.373      1.973      0.048       0.005       1.467
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  335
Model:                          Logit   Df Residuals:                      322
Method:                           MLE   Df Model:                           12
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                  0.1910
Time:                        20:58:14   Log-Likelihood:                -149.91
converged:                       True   LL-Null:                       -185.30
Covariance Type:            nonrobust   LLR p-value:                 2.289e-10
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -5.3904      1.870     -2.883      0.004      -9.055      -1.726
C(topic_grouped)[T.Geography]                  0.5168      0.623      0.829      0.407      -0.705       1.738
C(topic_grouped)[T.Misc]                       0.5107      0.491      1.041      0.298      -0.451       1.472
C(topic_grouped)[T.Other]                     -0.4398      0.642     -0.685      0.493      -1.698       0.819
C(topic_grouped)[T.Politics]                  -0.0134      0.540     -0.025      0.980      -1.072       1.045
C(topic_grouped)[T.Science and technology]     0.5636      0.477      1.182      0.237      -0.371       1.498
C(topic_grouped)[T.Sports]                    -0.3507      0.699     -0.502      0.616      -1.721       1.020
C(answer_type_grouped)[T.Number]               0.8223      0.461      1.784      0.074      -0.081       1.726
C(answer_type_grouped)[T.Other]                0.5234      0.399      1.311      0.190      -0.259       1.306
C(answer_type_grouped)[T.Person]               0.3381      0.389      0.868      0.385      -0.425       1.101
C(answer_type_grouped)[T.Place]               -1.4849      1.085     -1.369      0.171      -3.612       0.642
q_length                                       0.7377      0.403      1.830      0.067      -0.052       1.528
game_entropy                                 198.7938     53.793      3.696      0.000      93.361     304.226
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing gemini-2.5-flash-preview-04-17 (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/gemini-2.5-flash-preview-04-17_SimpleMC_redacted_temp0.0_1751726354_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
1    95
0    70
Name: count, dtype: int64

Answer change%: 0.5758 [0.5003468713811036, 0.651168280134048] (n=165)
P-value vs 25%: 2.526e-17; P-value vs 0%: 1.257e-50
Phase 2 self-accuracy: 0.6000 [0.501487370995732, 0.6985126290042679] (n=95)
P-value vs 25%: 3.32e-12; P-value vs 33%: 1.084e-07

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  165
Model:                          Logit   Df Residuals:                      163
Method:                           MLE   Df Model:                            1
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                0.004136
Time:                        20:58:14   Log-Likelihood:                -112.00
converged:                       True   LL-Null:                       -112.47
Covariance Type:            nonrobust   LLR p-value:                    0.3348
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept        0.3225      0.159      2.032      0.042       0.011       0.634
game_entropy    -1.3116      1.724     -0.761      0.447      -4.691       2.068
================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['Video games', 'History']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.500000
                        1                 0.500000
Geography               1                 0.846154
                        0                 0.153846
Misc                    1                 0.700000
                        0                 0.300000
Music                   1                 0.555556
                        0                 0.444444
Other                   0                 0.666667
                        1                 0.333333
Politics                1                 0.571429
                        0                 0.428571
Science and technology  1                 0.606061
                        0                 0.393939
Sports                  0                 0.500000
                        1                 0.500000
TV shows                1                 0.533333
                        0                 0.466667
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 1                 0.685185
                     0                 0.314815
Number               1                 0.571429
                     0                 0.428571
Other                1                 0.571429
                     0                 0.428571
Person               0                 0.588235
                     1                 0.411765
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.500000  0.500000            4
                       Number               0.000000  1.000000            2
                       Other                0.500000  0.500000            4
                       Person               0.625000  0.375000            8
Geography              Date                 0.200000  0.800000            5
                       Number               0.142857  0.857143            7
                       Other                0.000000  1.000000            1
Misc                   Date                 0.000000  1.000000            9
                       Number               1.000000  0.000000            3
                       Other                0.500000  0.500000            6
                       Person               0.000000  1.000000            2
Music                  Date                 0.600000  0.400000            5
                       Number               0.333333  0.666667            3
                       Other                0.285714  0.714286            7
                       Person               0.666667  0.333333            3
Other                  Date                 0.571429  0.428571            7
                       Number               0.750000  0.250000            4
                       Other                0.500000  0.500000            2
                       Person               1.000000  0.000000            2
Politics               Date                 0.363636  0.636364           11
                       Number               0.500000  0.500000            2
                       Other                0.500000  0.500000            4
                       Person               0.500000  0.500000            4
Science and technology Date                 0.272727  0.727273           11
                       Number               0.571429  0.428571            7
                       Other                0.333333  0.666667            6
                       Person               0.444444  0.555556            9
Sports                 Number               0.333333  0.666667            6
                       Other                0.333333  0.666667            3
                       Person               1.000000  0.000000            3
TV shows               Date                 0.000000  1.000000            2
                       Number               0.000000  1.000000            1
                       Other                0.555556  0.444444            9
                       Person               0.666667  0.333333            3

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  165
Model:                          Logit   Df Residuals:                      152
Method:                           MLE   Df Model:                           12
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                 0.09603
Time:                        20:58:14   Log-Likelihood:                -101.67
converged:                       True   LL-Null:                       -112.47
Covariance Type:            nonrobust   LLR p-value:                   0.04225
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      5.6234      2.182      2.577      0.010       1.347       9.900
C(topic_grouped)[T.Geography]                  1.4261      0.975      1.463      0.143      -0.484       3.337
C(topic_grouped)[T.Misc]                       0.6672      0.723      0.923      0.356      -0.750       2.085
C(topic_grouped)[T.Music]                     -0.1730      0.709     -0.244      0.807      -1.563       1.217
C(topic_grouped)[T.Other]                     -1.2137      0.771     -1.574      0.116      -2.725       0.298
C(topic_grouped)[T.Politics]                   0.0357      0.686      0.052      0.958      -1.308       1.379
C(topic_grouped)[T.Science and technology]     0.3225      0.622      0.518      0.604      -0.897       1.542
C(topic_grouped)[T.Sports]                     0.0480      0.791      0.061      0.952      -1.502       1.598
C(topic_grouped)[T.TV shows]                  -0.1671      0.745     -0.224      0.823      -1.628       1.293
C(answer_type_grouped)[T.Number]              -0.7750      0.514     -1.507      0.132      -1.783       0.233
C(answer_type_grouped)[T.Other]               -0.6826      0.481     -1.421      0.155      -1.624       0.259
C(answer_type_grouped)[T.Person]              -1.3108      0.504     -2.600      0.009      -2.299      -0.323
q_length                                      -1.0545      0.448     -2.355      0.019      -1.932      -0.177
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  165
Model:                          Logit   Df Residuals:                      151
Method:                           MLE   Df Model:                           13
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                  0.1184
Time:                        20:58:14   Log-Likelihood:                -99.147
converged:                       True   LL-Null:                       -112.47
Covariance Type:            nonrobust   LLR p-value:                   0.01392
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      6.1634      2.230      2.764      0.006       1.793      10.534
C(topic_grouped)[T.Geography]                  2.2164      1.188      1.866      0.062      -0.111       4.544
C(topic_grouped)[T.Misc]                       0.7075      0.728      0.972      0.331      -0.719       2.134
C(topic_grouped)[T.Music]                     -0.1818      0.712     -0.255      0.799      -1.577       1.214
C(topic_grouped)[T.Other]                     -1.2448      0.775     -1.607      0.108      -2.763       0.273
C(topic_grouped)[T.Politics]                   0.0173      0.689      0.025      0.980      -1.334       1.369
C(topic_grouped)[T.Science and technology]     0.3478      0.626      0.556      0.578      -0.879       1.574
C(topic_grouped)[T.Sports]                     0.1300      0.794      0.164      0.870      -1.427       1.687
C(topic_grouped)[T.TV shows]                  -0.1769      0.747     -0.237      0.813      -1.641       1.287
C(answer_type_grouped)[T.Number]              -0.9845      0.532     -1.850      0.064      -2.028       0.058
C(answer_type_grouped)[T.Other]               -0.8003      0.490     -1.633      0.102      -1.761       0.160
C(answer_type_grouped)[T.Person]              -1.4104      0.512     -2.755      0.006      -2.414      -0.407
q_length                                      -1.1515      0.457     -2.520      0.012      -2.047      -0.256
game_entropy                                  -3.3319      2.139     -1.558      0.119      -7.524       0.860
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing gpt-4.1-2025-04-14 (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/gpt-4.1-2025-04-14_SimpleMC_redacted_cor_temp0.0_1751719329_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    192
1     63
Name: count, dtype: int64

Answer change%: 0.2471 [0.19412189864559706, 0.29999574841322646] (n=255)
P-value vs 25%: 0.9133; P-value vs 0%: 5.841e-20
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=63)
P-value vs 25%: 0; P-value vs 33%: 0

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  255
Model:                          Logit   Df Residuals:                      253
Method:                           MLE   Df Model:                            1
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                 0.02635
Time:                        20:58:14   Log-Likelihood:                -138.81
converged:                       True   LL-Null:                       -142.57
Covariance Type:            nonrobust   LLR p-value:                  0.006123
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          1.1245      0.808      1.392      0.164      -0.458       2.707
p_i_capability    -2.4865      0.893     -2.784      0.005      -4.237      -0.736
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  255
Model:                          Logit   Df Residuals:                      253
Method:                           MLE   Df Model:                            1
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                 0.03999
Time:                        20:58:14   Log-Likelihood:                -136.86
converged:                       True   LL-Null:                       -142.57
Covariance Type:            nonrobust   LLR p-value:                 0.0007338
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.4564      0.187     -7.793      0.000      -1.823      -1.090
capabilities_entropy     0.9907      0.291      3.400      0.001       0.420       1.562
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.8140 [0.6976, 0.9303] (n=43)
                  P-value vs 33.3%: 5.546e-16

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=-3.15, p=0.0024
Wilcoxon delta_p: statistic=620.00, p=0.000727
Mean Δp = -0.0672  [-0.1089, -0.0254]
Idea 1 N = 69; 

  Idea 1.5: Calibration Metrics
  NLL: 0.2128, Signed ECE (overconf pos under neg): -0.1706, ECE: 0.1706 (n=106)
  Brier: 0.0601, Reliability (absolute calibration error; lower better): 0.0595, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=106)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.910
Model:                            OLS   Adj. R-squared:                  0.908
Method:                 Least Squares   F-statistic:                     344.6
Date:                Tue, 26 Aug 2025   Prob (F-statistic):           3.23e-53
Time:                        20:58:14   Log-Likelihood:                 66.237
No. Observations:                 106   AIC:                            -124.5
Df Residuals:                     102   BIC:                            -113.8
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.6408      0.076     -8.446      0.000      -0.791      -0.490
p1                    0.6906      0.089      7.732      0.000       0.513       0.868
answer_changed        0.3124      0.131      2.393      0.019       0.053       0.571
p1:answer_changed     0.5854      0.154      3.796      0.000       0.280       0.891
==============================================================================
Omnibus:                        5.771   Durbin-Watson:                   1.919
Prob(Omnibus):                  0.056   Jarque-Bera (JB):                5.278
Skew:                           0.441   Prob(JB):                       0.0714
Kurtosis:                       3.647   Cond. No.                         23.4
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=2.42, p=0.0182
Wilcoxon delta_H: statistic=933.00, p=0.101
Mean ΔH = 0.1330  [0.0252, 0.2407]
Paired t-test delta_H Changed: statistic=3.61, p=0.000937
Wilcoxon delta_H Changed: statistic=135.00, p=0.000729
Mean ΔH Changed = 0.2836  [0.1294, 0.4377]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=3.27, p=0.00145
Wilcoxon (p_top2_game vs p_top2_base): statistic=1813.00, p=0.00127
Mean Δp_top2 = 0.0174  [0.0070, 0.0278] (n=106)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=4.08, p=8.64e-05
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=1766.00, p=0.000749
Mean ΔH_unchosen_baseline_set = 0.1855  [0.0965, 0.2746] (n=106)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  106
Model:                          Logit   Df Residuals:                      103
Method:                           MLE   Df Model:                            2
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                0.001866
Time:                        20:58:14   Log-Likelihood:                -68.439
converged:                       True   LL-Null:                       -68.567
Covariance Type:            nonrobust   LLR p-value:                    0.8799
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.4835      0.346     -1.398      0.162      -1.161       0.194
p1_z            -0.1041      0.265     -0.392      0.695      -0.624       0.416
I(p1_z ** 2)    -0.1413      0.285     -0.495      0.620      -0.700       0.418
================================================================================
AUC = 0.543

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  255
Model:                          Logit   Df Residuals:                      253
Method:                           MLE   Df Model:                            1
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                 0.09798
Time:                        20:58:14   Log-Likelihood:                -128.60
converged:                       True   LL-Null:                       -142.57
Covariance Type:            nonrobust   LLR p-value:                 1.253e-07
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.6701      0.196     -8.503      0.000      -2.055      -1.285
game_entropy     1.8718      0.364      5.135      0.000       1.157       2.586
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=9075.00, p=0.282
Paired t-test (game_entropy vs capabilities_entropy): statistic=-2.03, p=0.0433
Mean capabilities_entropy-game_entropy = 0.0537  [0.0019, 0.1054] (n=255)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  255
Model:                          Logit   Df Residuals:                      252
Method:                           MLE   Df Model:                            2
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                 0.09980
Time:                        20:58:14   Log-Likelihood:                -128.34
converged:                       True   LL-Null:                       -142.57
Covariance Type:            nonrobust   LLR p-value:                 6.622e-07
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.7113      0.206     -8.309      0.000      -2.115      -1.308
capabilities_entropy     0.2596      0.358      0.725      0.468      -0.442       0.961
game_entropy             1.7124      0.424      4.041      0.000       0.882       2.543
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': None
topic_grouped           answer_changed
Art                     0                 0.780488
                        1                 0.219512
Geography               0                 0.650000
                        1                 0.350000
Misc                    0                 0.729730
                        1                 0.270270
Music                   0                 0.700000
                        1                 0.300000
Other                   0                 0.781250
                        1                 0.218750
Politics                0                 0.675000
                        1                 0.325000
Science and technology  0                 0.837209
                        1                 0.162791
Sports                  0                 0.818182
                        1                 0.181818
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.710145
                     1                 0.289855
Number               0                 0.615385
                     1                 0.384615
Other                0                 0.800000
                     1                 0.200000
Person               0                 0.833333
                     1                 0.166667
Place                0                 0.636364
                     1                 0.363636
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.800000  0.200000            5
                       Number               0.500000  0.500000            4
                       Other                0.750000  0.250000            8
                       Person               0.894737  0.105263           19
                       Place                0.600000  0.400000            5
Geography              Date                 0.428571  0.571429            7
                       Number               0.750000  0.250000            4
                       Other                1.000000  0.000000            3
                       Place                0.666667  0.333333            6
Misc                   Date                 0.666667  0.333333            9
                       Number               1.000000  0.000000            4
                       Other                0.615385  0.384615           13
                       Person               0.888889  0.111111            9
                       Place                0.500000  0.500000            2
Music                  Date                 0.500000  0.500000            6
                       Number               0.000000  1.000000            1
                       Other                1.000000  0.000000            3
                       Person               0.800000  0.200000           10
Other                  Date                 0.625000  0.375000            8
                       Number               0.750000  0.250000            4
                       Other                0.714286  0.285714            7
                       Person               0.900000  0.100000           10
                       Place                1.000000  0.000000            3
Politics               Date                 0.687500  0.312500           16
                       Number               0.666667  0.333333            3
                       Other                0.888889  0.111111            9
                       Person               0.500000  0.500000            8
                       Place                0.500000  0.500000            4
Science and technology Date                 0.916667  0.083333           12
                       Number               0.333333  0.666667            3
                       Other                0.909091  0.090909           11
                       Person               0.823529  0.176471           17
Sports                 Date                 1.000000  0.000000            6
                       Number               0.333333  0.666667            3
                       Other                0.833333  0.166667            6
                       Person               1.000000  0.000000            5
                       Place                0.500000  0.500000            2

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  255
Model:                          Logit   Df Residuals:                      242
Method:                           MLE   Df Model:                           12
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                 0.04284
Time:                        20:58:14   Log-Likelihood:                -136.46
converged:                       True   LL-Null:                       -142.57
Covariance Type:            nonrobust   LLR p-value:                    0.4286
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.5869      1.873     -0.847      0.397      -5.258       2.084
C(topic_grouped)[T.Geography]                  0.2701      0.632      0.427      0.669      -0.969       1.509
C(topic_grouped)[T.Misc]                       0.2312      0.545      0.424      0.672      -0.838       1.300
C(topic_grouped)[T.Music]                      0.5152      0.635      0.812      0.417      -0.729       1.759
C(topic_grouped)[T.Other]                     -0.0955      0.583     -0.164      0.870      -1.238       1.047
C(topic_grouped)[T.Politics]                   0.3926      0.536      0.733      0.464      -0.658       1.443
C(topic_grouped)[T.Science and technology]    -0.3490      0.581     -0.601      0.548      -1.488       0.790
C(topic_grouped)[T.Sports]                    -0.3608      0.685     -0.526      0.599      -1.704       0.983
C(answer_type_grouped)[T.Number]               0.4800      0.494      0.972      0.331      -0.488       1.448
C(answer_type_grouped)[T.Other]               -0.4270      0.428     -0.998      0.318      -1.266       0.412
C(answer_type_grouped)[T.Person]              -0.6460      0.421     -1.534      0.125      -1.471       0.179
C(answer_type_grouped)[T.Place]                0.3135      0.541      0.580      0.562      -0.747       1.373
q_length                                       0.1272      0.405      0.314      0.753      -0.666       0.920
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.2957
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  255
Model:                          Logit   Df Residuals:                      241
Method:                           MLE   Df Model:                           13
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                 0.07638
Time:                        20:58:14   Log-Likelihood:                -131.68
converged:                       True   LL-Null:                       -142.57
Covariance Type:            nonrobust   LLR p-value:                   0.05889
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -2.6739      1.970     -1.357      0.175      -6.535       1.187
C(topic_grouped)[T.Geography]                  0.2122      0.644      0.329      0.742      -1.051       1.475
C(topic_grouped)[T.Misc]                       0.2188      0.560      0.391      0.696      -0.879       1.317
C(topic_grouped)[T.Music]                      0.5179      0.648      0.799      0.424      -0.753       1.789
C(topic_grouped)[T.Other]                     -0.1770      0.597     -0.296      0.767      -1.348       0.994
C(topic_grouped)[T.Politics]                   0.4609      0.545      0.846      0.397      -0.607       1.529
C(topic_grouped)[T.Science and technology]    -0.3084      0.591     -0.522      0.602      -1.467       0.850
C(topic_grouped)[T.Sports]                    -0.4246      0.711     -0.597      0.550      -1.818       0.969
C(answer_type_grouped)[T.Number]               0.4299      0.507      0.848      0.396      -0.564       1.423
C(answer_type_grouped)[T.Other]               -0.1350      0.450     -0.300      0.764      -1.017       0.747
C(answer_type_grouped)[T.Person]              -0.3916      0.436     -0.898      0.369      -1.246       0.463
C(answer_type_grouped)[T.Place]                0.6904      0.560      1.234      0.217      -0.406       1.787
q_length                                       0.2548      0.421      0.605      0.545      -0.570       1.080
capabilities_entropy                           0.9910      0.319      3.109      0.002       0.366       1.616
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  255
Model:                          Logit   Df Residuals:                      241
Method:                           MLE   Df Model:                           13
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                  0.1366
Time:                        20:58:14   Log-Likelihood:                -123.09
converged:                       True   LL-Null:                       -142.57
Covariance Type:            nonrobust   LLR p-value:                 0.0002041
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -2.7800      2.023     -1.374      0.169      -6.745       1.185
C(topic_grouped)[T.Geography]                  0.5021      0.666      0.754      0.451      -0.804       1.808
C(topic_grouped)[T.Misc]                       0.4017      0.579      0.694      0.488      -0.733       1.536
C(topic_grouped)[T.Music]                      0.3817      0.697      0.547      0.584      -0.985       1.748
C(topic_grouped)[T.Other]                     -0.0640      0.622     -0.103      0.918      -1.284       1.156
C(topic_grouped)[T.Politics]                   0.7322      0.568      1.289      0.197      -0.381       1.846
C(topic_grouped)[T.Science and technology]    -0.2757      0.615     -0.449      0.654      -1.480       0.929
C(topic_grouped)[T.Sports]                    -0.6277      0.748     -0.839      0.402      -2.094       0.839
C(answer_type_grouped)[T.Number]               0.4328      0.531      0.815      0.415      -0.608       1.473
C(answer_type_grouped)[T.Other]                0.2793      0.479      0.583      0.560      -0.659       1.218
C(answer_type_grouped)[T.Person]              -0.0951      0.470     -0.203      0.839      -1.015       0.825
C(answer_type_grouped)[T.Place]                0.8730      0.588      1.485      0.138      -0.279       2.025
q_length                                       0.1552      0.432      0.359      0.720      -0.692       1.002
game_entropy                                   2.0591      0.418      4.927      0.000       1.240       2.878
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  255
Model:                          Logit   Df Residuals:                      240
Method:                           MLE   Df Model:                           14
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                  0.1390
Time:                        20:58:14   Log-Likelihood:                -122.75
converged:                       True   LL-Null:                       -142.57
Covariance Type:            nonrobust   LLR p-value:                 0.0002909
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -3.0409      2.059     -1.477      0.140      -7.077       0.995
C(topic_grouped)[T.Geography]                  0.4690      0.668      0.703      0.482      -0.839       1.778
C(topic_grouped)[T.Misc]                       0.3852      0.582      0.662      0.508      -0.755       1.526
C(topic_grouped)[T.Music]                      0.3911      0.699      0.560      0.576      -0.978       1.760
C(topic_grouped)[T.Other]                     -0.0967      0.624     -0.155      0.877      -1.320       1.127
C(topic_grouped)[T.Politics]                   0.7276      0.569      1.280      0.201      -0.387       1.842
C(topic_grouped)[T.Science and technology]    -0.2697      0.615     -0.439      0.661      -1.475       0.935
C(topic_grouped)[T.Sports]                    -0.6234      0.754     -0.827      0.408      -2.101       0.854
C(answer_type_grouped)[T.Number]               0.4266      0.533      0.800      0.424      -0.618       1.472
C(answer_type_grouped)[T.Other]                0.3248      0.484      0.671      0.502      -0.623       1.273
C(answer_type_grouped)[T.Person]              -0.0589      0.472     -0.125      0.901      -0.984       0.866
C(answer_type_grouped)[T.Place]                0.9482      0.593      1.600      0.110      -0.213       2.110
q_length                                       0.1957      0.437      0.448      0.655      -0.661       1.053
capabilities_entropy                           0.3145      0.375      0.838      0.402      -0.421       1.050
game_entropy                                   1.8896      0.462      4.088      0.000       0.984       2.796
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing gpt-4.1-2025-04-14 (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/gpt-4.1-2025-04-14_SimpleMC_redacted_temp0.0_1751719704_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
1    128
0    109
Name: count, dtype: int64

Answer change%: 0.5401 [0.47663260876685, 0.6035361676044579] (n=237)
P-value vs 25%: 3.234e-19; P-value vs 0%: 1.752e-62
Phase 2 self-accuracy: 0.5781 [0.49256990530408606, 0.6636800946959139] (n=128)
P-value vs 25%: 5.607e-14; P-value vs 33%: 1.96e-08

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  237
Model:                          Logit   Df Residuals:                      235
Method:                           MLE   Df Model:                            1
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                 0.03888
Time:                        20:58:14   Log-Likelihood:                -157.16
converged:                       True   LL-Null:                       -163.51
Covariance Type:            nonrobust   LLR p-value:                 0.0003627
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          2.1835      0.610      3.578      0.000       0.987       3.380
p_i_capability    -2.4550      0.715     -3.434      0.001      -3.856      -1.054
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  237
Model:                          Logit   Df Residuals:                      235
Method:                           MLE   Df Model:                            1
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                 0.04234
Time:                        20:58:14   Log-Likelihood:                -156.59
converged:                       True   LL-Null:                       -163.51
Covariance Type:            nonrobust   LLR p-value:                 0.0001983
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -0.3639      0.194     -1.873      0.061      -0.745       0.017
capabilities_entropy     0.8794      0.245      3.597      0.000       0.400       1.359
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.6757 [0.5886, 0.7628] (n=111)
                  P-value vs 33.3%: 1.31e-14

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=-3.16, p=0.00243
Wilcoxon delta_p: statistic=617.00, p=0.0018
Mean Δp = -0.0691  [-0.1119, -0.0262]
Idea 1 N = 66; 

  Idea 1.5: Calibration Metrics
  NLL: 5.3504, Signed ECE (overconf pos under neg): 0.0988, ECE: 0.0988 (n=159)
  Brier: 0.0244, Reliability (absolute calibration error; lower better): 0.0235, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=159)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.900
Model:                            OLS   Adj. R-squared:                  0.899
Method:                 Least Squares   F-statistic:                     467.6
Date:                Tue, 26 Aug 2025   Prob (F-statistic):           2.04e-77
Time:                        20:58:14   Log-Likelihood:                 94.851
No. Observations:                 159   AIC:                            -181.7
Df Residuals:                     155   BIC:                            -169.4
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.6045      0.079     -7.630      0.000      -0.761      -0.448
p1                    0.6563      0.095      6.912      0.000       0.469       0.844
answer_changed        0.5081      0.095      5.375      0.000       0.321       0.695
p1:answer_changed     0.3560      0.116      3.070      0.003       0.127       0.585
==============================================================================
Omnibus:                        6.557   Durbin-Watson:                   1.768
Prob(Omnibus):                  0.038   Jarque-Bera (JB):                8.016
Skew:                          -0.269   Prob(JB):                       0.0182
Kurtosis:                       3.959   Cond. No.                         25.9
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=3.83, p=0.000289
Wilcoxon delta_H: statistic=687.00, p=0.00751
Mean ΔH = 0.2445  [0.1195, 0.3696]
Paired t-test delta_H Changed: statistic=4.80, p=6.03e-06
Wilcoxon delta_H Changed: statistic=1004.00, p=5.98e-06
Mean ΔH Changed = 0.2656  [0.1572, 0.3739]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=5.40, p=2.44e-07
Wilcoxon (p_top2_game vs p_top2_base): statistic=3312.00, p=1.59e-07
Mean Δp_top2 = 0.0401  [0.0256, 0.0547] (n=159)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=6.16, p=5.71e-09
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=3280.00, p=1.18e-07
Mean ΔH_unchosen_baseline_set = 0.2568  [0.1751, 0.3385] (n=159)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  159
Model:                          Logit   Df Residuals:                      156
Method:                           MLE   Df Model:                            2
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                 0.02713
Time:                        20:58:14   Log-Likelihood:                -104.98
converged:                       True   LL-Null:                       -107.91
Covariance Type:            nonrobust   LLR p-value:                   0.05354
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept        0.1629      0.250      0.652      0.514      -0.327       0.653
p1_z            -0.2723      0.194     -1.406      0.160      -0.652       0.107
I(p1_z ** 2)     0.2034      0.203      1.001      0.317      -0.195       0.602
================================================================================
AUC = 0.562

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  237
Model:                          Logit   Df Residuals:                      235
Method:                           MLE   Df Model:                            1
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                 0.04549
Time:                        20:58:14   Log-Likelihood:                -156.07
converged:                       True   LL-Null:                       -163.51
Covariance Type:            nonrobust   LLR p-value:                 0.0001147
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.3281      0.184     -1.786      0.074      -0.688       0.032
game_entropy     1.1969      0.323      3.711      0.000       0.565       1.829
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=8372.00, p=2.67e-06
Paired t-test (game_entropy vs capabilities_entropy): statistic=-5.11, p=6.54e-07
Mean capabilities_entropy-game_entropy = 0.1901  [0.1172, 0.2630] (n=237)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  237
Model:                          Logit   Df Residuals:                      234
Method:                           MLE   Df Model:                            2
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                 0.06425
Time:                        20:58:14   Log-Likelihood:                -153.01
converged:                       True   LL-Null:                       -163.51
Covariance Type:            nonrobust   LLR p-value:                 2.737e-05
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -0.5897      0.215     -2.737      0.006      -1.012      -0.167
capabilities_entropy     0.6400      0.262      2.444      0.015       0.127       1.153
game_entropy             0.9043      0.344      2.631      0.009       0.231       1.578
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'Video games', 'History']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     1                 0.575758
                        0                 0.424242
Geography               1                 0.652174
                        0                 0.347826
Misc                    1                 0.540541
                        0                 0.459459
Music                   0                 0.500000
                        1                 0.500000
Other                   1                 0.631579
                        0                 0.368421
Politics                1                 0.514286
                        0                 0.485714
Science and technology  1                 0.528302
                        0                 0.471698
Sports                  0                 0.647059
                        1                 0.352941
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 1                 0.562500
                     0                 0.437500
Number               1                 0.647059
                     0                 0.352941
Other                0                 0.540000
                     1                 0.460000
Person               0                 0.550000
                     1                 0.450000
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.533333  0.466667           15
                       Number               0.200000  0.800000            5
                       Other                0.200000  0.800000            5
                       Person               0.500000  0.500000            8
Geography              Date                 0.428571  0.571429            7
                       Number               0.357143  0.642857           14
                       Other                0.000000  1.000000            2
Misc                   Date                 0.285714  0.714286           14
                       Number               0.200000  0.800000            5
                       Other                0.750000  0.250000           12
                       Person               0.500000  0.500000            6
Music                  Date                 0.666667  0.333333            6
                       Number               0.333333  0.666667            3
                       Other                0.444444  0.555556            9
                       Person               0.500000  0.500000            2
Other                  Date                 0.400000  0.600000           10
                       Number               0.333333  0.666667            3
                       Other                0.500000  0.500000            4
                       Person               0.000000  1.000000            2
Politics               Date                 0.526316  0.473684           19
                       Number               0.000000  1.000000            3
                       Other                0.571429  0.428571            7
                       Person               0.500000  0.500000            6
Science and technology Date                 0.363636  0.636364           22
                       Number               0.363636  0.636364           11
                       Other                0.714286  0.285714            7
                       Person               0.615385  0.384615           13
Sports                 Date                 0.333333  0.666667            3
                       Number               0.714286  0.285714            7
                       Other                0.500000  0.500000            4
                       Person               1.000000  0.000000            3

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  237
Model:                          Logit   Df Residuals:                      225
Method:                           MLE   Df Model:                           11
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                 0.04009
Time:                        20:58:14   Log-Likelihood:                -156.96
converged:                       True   LL-Null:                       -163.51
Covariance Type:            nonrobust   LLR p-value:                    0.2862
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      3.6201      1.721      2.103      0.035       0.247       6.993
C(topic_grouped)[T.Geography]                 -0.0428      0.597     -0.072      0.943      -1.214       1.128
C(topic_grouped)[T.Misc]                      -0.0935      0.496     -0.189      0.850      -1.066       0.879
C(topic_grouped)[T.Music]                     -0.3283      0.591     -0.555      0.579      -1.487       0.831
C(topic_grouped)[T.Other]                      0.1417      0.607      0.233      0.815      -1.048       1.332
C(topic_grouped)[T.Politics]                  -0.0975      0.504     -0.194      0.847      -1.085       0.890
C(topic_grouped)[T.Science and technology]    -0.1997      0.458     -0.436      0.663      -1.098       0.698
C(topic_grouped)[T.Sports]                    -0.9916      0.648     -1.531      0.126      -2.261       0.278
C(answer_type_grouped)[T.Number]               0.4721      0.391      1.206      0.228      -0.295       1.239
C(answer_type_grouped)[T.Other]               -0.4371      0.367     -1.190      0.234      -1.157       0.283
C(answer_type_grouped)[T.Person]              -0.5443      0.396     -1.373      0.170      -1.321       0.233
q_length                                      -0.7092      0.368     -1.927      0.054      -1.431       0.012
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.6136
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  237
Model:                          Logit   Df Residuals:                      224
Method:                           MLE   Df Model:                           12
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                 0.07637
Time:                        20:58:14   Log-Likelihood:                -151.03
converged:                       True   LL-Null:                       -163.51
Covariance Type:            nonrobust   LLR p-value:                   0.01495
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      2.7973      1.770      1.580      0.114      -0.672       6.267
C(topic_grouped)[T.Geography]                 -0.0709      0.609     -0.116      0.907      -1.265       1.123
C(topic_grouped)[T.Misc]                      -0.2271      0.510     -0.445      0.656      -1.228       0.773
C(topic_grouped)[T.Music]                     -0.2771      0.612     -0.453      0.651      -1.477       0.923
C(topic_grouped)[T.Other]                      0.2225      0.621      0.358      0.720      -0.994       1.439
C(topic_grouped)[T.Politics]                  -0.0407      0.517     -0.079      0.937      -1.055       0.973
C(topic_grouped)[T.Science and technology]    -0.2928      0.471     -0.622      0.534      -1.215       0.630
C(topic_grouped)[T.Sports]                    -0.8598      0.660     -1.302      0.193      -2.154       0.435
C(answer_type_grouped)[T.Number]               0.6627      0.403      1.643      0.100      -0.128       1.453
C(answer_type_grouped)[T.Other]               -0.2715      0.379     -0.716      0.474      -1.015       0.472
C(answer_type_grouped)[T.Person]              -0.2379      0.419     -0.568      0.570      -1.059       0.583
q_length                                      -0.6667      0.376     -1.774      0.076      -1.403       0.070
capabilities_entropy                           0.8654      0.259      3.343      0.001       0.358       1.373
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  237
Model:                          Logit   Df Residuals:                      224
Method:                           MLE   Df Model:                           12
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                 0.08841
Time:                        20:58:14   Log-Likelihood:                -149.06
converged:                       True   LL-Null:                       -163.51
Covariance Type:            nonrobust   LLR p-value:                  0.004060
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      3.1327      1.776      1.764      0.078      -0.349       6.614
C(topic_grouped)[T.Geography]                  0.1909      0.621      0.307      0.759      -1.026       1.408
C(topic_grouped)[T.Misc]                       0.0131      0.518      0.025      0.980      -1.002       1.029
C(topic_grouped)[T.Music]                     -0.0322      0.622     -0.052      0.959      -1.252       1.188
C(topic_grouped)[T.Other]                      0.4742      0.635      0.746      0.456      -0.771       1.720
C(topic_grouped)[T.Politics]                   0.2230      0.529      0.421      0.673      -0.814       1.260
C(topic_grouped)[T.Science and technology]    -0.0054      0.479     -0.011      0.991      -0.944       0.933
C(topic_grouped)[T.Sports]                    -1.0463      0.680     -1.539      0.124      -2.378       0.286
C(answer_type_grouped)[T.Number]               0.5685      0.404      1.406      0.160      -0.224       1.361
C(answer_type_grouped)[T.Other]               -0.4062      0.379     -1.071      0.284      -1.150       0.338
C(answer_type_grouped)[T.Person]              -0.1835      0.419     -0.439      0.661      -1.004       0.637
q_length                                      -0.7818      0.380     -2.059      0.040      -1.526      -0.037
game_entropy                                   1.3355      0.351      3.806      0.000       0.648       2.023
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  237
Model:                          Logit   Df Residuals:                      223
Method:                           MLE   Df Model:                           13
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                  0.1032
Time:                        20:58:14   Log-Likelihood:                -146.64
converged:                       True   LL-Null:                       -163.51
Covariance Type:            nonrobust   LLR p-value:                  0.001314
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      2.7105      1.806      1.500      0.133      -0.830       6.251
C(topic_grouped)[T.Geography]                  0.1175      0.627      0.188      0.851      -1.111       1.346
C(topic_grouped)[T.Misc]                      -0.1147      0.526     -0.218      0.827      -1.146       0.917
C(topic_grouped)[T.Music]                     -0.0595      0.637     -0.093      0.926      -1.308       1.189
C(topic_grouped)[T.Other]                      0.4306      0.639      0.674      0.500      -0.822       1.683
C(topic_grouped)[T.Politics]                   0.1887      0.534      0.353      0.724      -0.859       1.236
C(topic_grouped)[T.Science and technology]    -0.1243      0.487     -0.255      0.799      -1.080       0.831
C(topic_grouped)[T.Sports]                    -0.9521      0.681     -1.398      0.162      -2.287       0.383
C(answer_type_grouped)[T.Number]               0.6805      0.410      1.659      0.097      -0.123       1.484
C(answer_type_grouped)[T.Other]               -0.3053      0.387     -0.790      0.430      -1.063       0.452
C(answer_type_grouped)[T.Person]              -0.0485      0.430     -0.113      0.910      -0.891       0.794
q_length                                      -0.7463      0.385     -1.941      0.052      -1.500       0.007
capabilities_entropy                           0.6015      0.277      2.175      0.030       0.059       1.144
game_entropy                                   1.0740      0.371      2.893      0.004       0.346       1.802
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing gpt-4o-2024-08-06 (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/gpt-4o-2024-08-06_SimpleMC_redacted_cor_temp0.0_1751718574_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    219
1     34
Name: count, dtype: int64

Answer change%: 0.1344 [0.09236030966488987, 0.1764143938924224] (n=253)
P-value vs 25%: 6.98e-08; P-value vs 0%: 3.675e-10
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=34)
P-value vs 25%: 0; P-value vs 33%: 0

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  253
Model:                          Logit   Df Residuals:                      251
Method:                           MLE   Df Model:                            1
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                 0.05688
Time:                        20:58:14   Log-Likelihood:                -94.166
converged:                       True   LL-Null:                       -99.845
Covariance Type:            nonrobust   LLR p-value:                 0.0007512
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept         -0.5531      0.396     -1.396      0.163      -1.329       0.223
p_i_capability    -1.9053      0.556     -3.427      0.001      -2.995      -0.816
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  253
Model:                          Logit   Df Residuals:                      251
Method:                           MLE   Df Model:                            1
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                  0.2515
Time:                        20:58:14   Log-Likelihood:                -74.731
converged:                       True   LL-Null:                       -99.845
Covariance Type:            nonrobust   LLR p-value:                 1.370e-12
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -3.9837      0.518     -7.685      0.000      -5.000      -2.968
capabilities_entropy     2.2588      0.390      5.793      0.000       1.495       3.023
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.8235 [0.6954, 0.9517] (n=34)
                  P-value vs 33.3%: 6.49e-14

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=-1.01, p=0.313
Wilcoxon delta_p: statistic=9073.00, p=0.541
Mean Δp = -0.0086  [-0.0252, 0.0080]
Idea 1 N = 195; 

  Idea 1.5: Calibration Metrics
  NLL: 0.2565, Signed ECE (overconf pos under neg): -0.1930, ECE: 0.1930 (n=228)
  Brier: 0.0821, Reliability (absolute calibration error; lower better): 0.0814, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=228)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.610
Model:                            OLS   Adj. R-squared:                  0.605
Method:                 Least Squares   F-statistic:                     116.9
Date:                Tue, 26 Aug 2025   Prob (F-statistic):           1.36e-45
Time:                        20:58:14   Log-Likelihood:                 184.25
No. Observations:                 228   AIC:                            -360.5
Df Residuals:                     224   BIC:                            -346.8
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.2253      0.035     -6.419      0.000      -0.294      -0.156
p1                    0.2561      0.040      6.333      0.000       0.176       0.336
answer_changed       -0.1126      0.077     -1.459      0.146      -0.265       0.039
p1:answer_changed     0.8441      0.122      6.930      0.000       0.604       1.084
==============================================================================
Omnibus:                       20.031   Durbin-Watson:                   1.911
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               41.569
Skew:                           0.422   Prob(JB):                     9.40e-10
Kurtosis:                       4.914   Cond. No.                         26.1
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-0.07, p=0.945
Wilcoxon delta_H: statistic=9275.00, p=0.912
Mean ΔH = -0.0023  [-0.0672, 0.0627]
Paired t-test delta_H Changed: statistic=4.98, p=2.12e-05
Wilcoxon delta_H Changed: statistic=61.00, p=2.48e-05
Mean ΔH Changed = 0.3370  [0.2043, 0.4697]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=2.83, p=0.00511
Wilcoxon (p_top2_game vs p_top2_base): statistic=12174.00, p=0.378
Mean Δp_top2 = 0.0124  [0.0038, 0.0210] (n=228)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=1.51, p=0.132
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=11137.00, p=0.0862
Mean ΔH_unchosen_baseline_set = 0.0468  [-0.0139, 0.1075] (n=228)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  228
Model:                          Logit   Df Residuals:                      225
Method:                           MLE   Df Model:                            2
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                  0.2483
Time:                        20:58:14   Log-Likelihood:                -70.860
converged:                       True   LL-Null:                       -94.271
Covariance Type:            nonrobust   LLR p-value:                 6.803e-11
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -2.1998      0.333     -6.602      0.000      -2.853      -1.547
p1_z            -1.8008      0.445     -4.048      0.000      -2.673      -0.929
I(p1_z ** 2)    -0.3882      0.277     -1.402      0.161      -0.931       0.155
================================================================================
AUC = 0.849

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  253
Model:                          Logit   Df Residuals:                      251
Method:                           MLE   Df Model:                            1
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                  0.2274
Time:                        20:58:14   Log-Likelihood:                -77.135
converged:                       True   LL-Null:                       -99.845
Covariance Type:            nonrobust   LLR p-value:                 1.591e-11
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -3.7950      0.481     -7.894      0.000      -4.737      -2.853
game_entropy     2.2341      0.390      5.727      0.000       1.470       2.999
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=15119.00, p=0.417
Paired t-test (game_entropy vs capabilities_entropy): statistic=-1.51, p=0.132
Mean capabilities_entropy-game_entropy = 0.0290  [-0.0087, 0.0666] (n=253)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  253
Model:                          Logit   Df Residuals:                      250
Method:                           MLE   Df Model:                            2
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                  0.2606
Time:                        20:58:14   Log-Likelihood:                -73.830
converged:                       True   LL-Null:                       -99.845
Covariance Type:            nonrobust   LLR p-value:                 5.034e-12
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -4.1192      0.542     -7.603      0.000      -5.181      -3.057
capabilities_entropy     1.5756      0.632      2.492      0.013       0.336       2.815
game_entropy             0.8805      0.659      1.336      0.181      -0.411       2.172
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': None
topic_grouped           answer_changed
Art                     0                 0.880952
                        1                 0.119048
Geography               0                 0.863636
                        1                 0.136364
Misc                    0                 0.761905
                        1                 0.238095
Music                   0                 0.850000
                        1                 0.150000
Other                   0                 0.925926
                        1                 0.074074
Politics                0                 0.897436
                        1                 0.102564
Science and technology  0                 0.863636
                        1                 0.136364
Sports                  0                 0.857143
                        1                 0.142857
TV shows                0                 0.823529
                        1                 0.176471
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.824324
                     1                 0.175676
Number               0                 0.756757
                     1                 0.243243
Other                0                 0.933333
                     1                 0.066667
Person               0                 0.906250
                     1                 0.093750
Place                0                 0.888889
                     1                 0.111111
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.500000  0.500000            6
                       Number               0.714286  0.285714            7
                       Other                1.000000  0.000000            6
                       Person               1.000000  0.000000           19
                       Place                1.000000  0.000000            4
Geography              Date                 0.833333  0.166667            6
                       Number               0.750000  0.250000            8
                       Other                1.000000  0.000000            3
                       Place                1.000000  0.000000            5
Misc                   Date                 0.636364  0.363636           11
                       Number               0.666667  0.333333            3
                       Other                1.000000  0.000000            3
                       Person               1.000000  0.000000            2
                       Place                1.000000  0.000000            2
Music                  Date                 1.000000  0.000000            4
                       Number               1.000000  0.000000            2
                       Other                0.750000  0.250000            4
                       Person               0.800000  0.200000           10
Other                  Date                 0.900000  0.100000           10
                       Number               1.000000  0.000000            3
                       Other                1.000000  0.000000            4
                       Person               1.000000  0.000000            7
                       Place                0.666667  0.333333            3
Politics               Date                 0.800000  0.200000           15
                       Number               1.000000  0.000000            5
                       Other                1.000000  0.000000           11
                       Person               0.833333  0.166667            6
                       Place                1.000000  0.000000            2
Science and technology Date                 0.941176  0.058824           17
                       Number               0.428571  0.571429            7
                       Other                1.000000  0.000000           10
                       Person               0.900000  0.100000           10
Sports                 Date                 1.000000  0.000000            4
                       Number               1.000000  0.000000            1
                       Other                0.750000  0.250000            8
                       Person               1.000000  0.000000            6
                       Place                0.500000  0.500000            2
TV shows               Date                 1.000000  0.000000            1
                       Number               1.000000  0.000000            1
                       Other                0.909091  0.090909           11
                       Person               0.500000  0.500000            4

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  253
Model:                          Logit   Df Residuals:                      239
Method:                           MLE   Df Model:                           13
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                 0.06442
Time:                        20:58:14   Log-Likelihood:                -93.413
converged:                       True   LL-Null:                       -99.845
Covariance Type:            nonrobust   LLR p-value:                    0.4584
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.7654      2.337     -0.756      0.450      -6.345       2.814
C(topic_grouped)[T.Geography]                 -0.2411      0.819     -0.294      0.769      -1.847       1.365
C(topic_grouped)[T.Misc]                       0.6025      0.738      0.817      0.414      -0.844       2.049
C(topic_grouped)[T.Music]                      0.3899      0.812      0.480      0.631      -1.202       1.982
C(topic_grouped)[T.Other]                     -0.6444      0.896     -0.719      0.472      -2.401       1.112
C(topic_grouped)[T.Politics]                  -0.2725      0.752     -0.362      0.717      -1.747       1.202
C(topic_grouped)[T.Science and technology]     0.0183      0.685      0.027      0.979      -1.324       1.361
C(topic_grouped)[T.Sports]                     0.4684      0.817      0.573      0.567      -1.134       2.070
C(topic_grouped)[T.TV shows]                   1.0253      0.872      1.176      0.239      -0.683       2.733
C(answer_type_grouped)[T.Number]               0.4512      0.512      0.881      0.378      -0.552       1.455
C(answer_type_grouped)[T.Other]               -1.3599      0.659     -2.062      0.039      -2.652      -0.067
C(answer_type_grouped)[T.Person]              -0.8353      0.567     -1.473      0.141      -1.947       0.276
C(answer_type_grouped)[T.Place]               -0.4599      0.840     -0.548      0.584      -2.106       1.186
q_length                                       0.0383      0.502      0.076      0.939      -0.946       1.023
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.6088
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  253
Model:                          Logit   Df Residuals:                      238
Method:                           MLE   Df Model:                           14
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                  0.3082
Time:                        20:58:14   Log-Likelihood:                -69.076
converged:                       True   LL-Null:                       -99.845
Covariance Type:            nonrobust   LLR p-value:                 6.296e-08
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -6.5944      3.086     -2.137      0.033     -12.643      -0.546
C(topic_grouped)[T.Geography]                 -0.0463      0.905     -0.051      0.959      -1.821       1.728
C(topic_grouped)[T.Misc]                       1.6452      0.880      1.870      0.062      -0.080       3.370
C(topic_grouped)[T.Music]                      1.2979      0.998      1.301      0.193      -0.658       3.254
C(topic_grouped)[T.Other]                     -0.8084      0.984     -0.821      0.411      -2.737       1.121
C(topic_grouped)[T.Politics]                   0.1784      0.871      0.205      0.838      -1.528       1.885
C(topic_grouped)[T.Science and technology]     0.5194      0.806      0.645      0.519      -1.060       2.099
C(topic_grouped)[T.Sports]                     0.9907      0.974      1.017      0.309      -0.919       2.900
C(topic_grouped)[T.TV shows]                   1.4959      1.127      1.327      0.184      -0.713       3.705
C(answer_type_grouped)[T.Number]               0.1942      0.582      0.334      0.739      -0.946       1.335
C(answer_type_grouped)[T.Other]               -0.5622      0.831     -0.676      0.499      -2.191       1.067
C(answer_type_grouped)[T.Person]               0.6822      0.733      0.931      0.352      -0.754       2.118
C(answer_type_grouped)[T.Place]                0.0493      0.999      0.049      0.961      -1.909       2.007
q_length                                       0.3443      0.641      0.537      0.591      -0.913       1.601
capabilities_entropy                           2.6796      0.489      5.484      0.000       1.722       3.637
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  253
Model:                          Logit   Df Residuals:                      238
Method:                           MLE   Df Model:                           14
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                  0.2721
Time:                        20:58:14   Log-Likelihood:                -72.676
converged:                       True   LL-Null:                       -99.845
Covariance Type:            nonrobust   LLR p-value:                 1.125e-06
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -4.0180      2.775     -1.448      0.148      -9.456       1.420
C(topic_grouped)[T.Geography]                 -0.4800      0.904     -0.531      0.596      -2.252       1.292
C(topic_grouped)[T.Misc]                       0.9467      0.854      1.108      0.268      -0.728       2.621
C(topic_grouped)[T.Music]                      0.5839      0.969      0.603      0.547      -1.315       2.483
C(topic_grouped)[T.Other]                     -1.2566      0.971     -1.294      0.196      -3.160       0.647
C(topic_grouped)[T.Politics]                  -0.1779      0.829     -0.215      0.830      -1.802       1.446
C(topic_grouped)[T.Science and technology]    -0.0469      0.779     -0.060      0.952      -1.573       1.479
C(topic_grouped)[T.Sports]                     0.8533      0.916      0.932      0.351      -0.941       2.648
C(topic_grouped)[T.TV shows]                   0.7573      1.054      0.719      0.472      -1.308       2.822
C(answer_type_grouped)[T.Number]              -0.0751      0.577     -0.130      0.896      -1.206       1.056
C(answer_type_grouped)[T.Other]               -0.6686      0.795     -0.841      0.400      -2.227       0.890
C(answer_type_grouped)[T.Person]               0.0059      0.670      0.009      0.993      -1.308       1.319
C(answer_type_grouped)[T.Place]               -0.5396      0.954     -0.565      0.572      -2.410       1.331
q_length                                       0.0226      0.601      0.038      0.970      -1.155       1.201
game_entropy                                   2.4382      0.444      5.487      0.000       1.567       3.309
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  253
Model:                          Logit   Df Residuals:                      237
Method:                           MLE   Df Model:                           15
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                  0.3167
Time:                        20:58:14   Log-Likelihood:                -68.219
converged:                       True   LL-Null:                       -99.845
Covariance Type:            nonrobust   LLR p-value:                 6.905e-08
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -6.1587      3.074     -2.004      0.045     -12.183      -0.134
C(topic_grouped)[T.Geography]                 -0.2080      0.916     -0.227      0.820      -2.004       1.588
C(topic_grouped)[T.Misc]                       1.4747      0.891      1.655      0.098      -0.272       3.221
C(topic_grouped)[T.Music]                      1.1699      1.030      1.136      0.256      -0.848       3.188
C(topic_grouped)[T.Other]                     -1.0534      1.001     -1.052      0.293      -3.015       0.909
C(topic_grouped)[T.Politics]                   0.0481      0.869      0.055      0.956      -1.655       1.752
C(topic_grouped)[T.Science and technology]     0.3351      0.816      0.411      0.681      -1.264       1.935
C(topic_grouped)[T.Sports]                     0.9890      0.973      1.017      0.309      -0.917       2.895
C(topic_grouped)[T.TV shows]                   1.2071      1.133      1.065      0.287      -1.014       3.428
C(answer_type_grouped)[T.Number]               0.0484      0.594      0.081      0.935      -1.117       1.213
C(answer_type_grouped)[T.Other]               -0.5466      0.840     -0.651      0.515      -2.193       1.099
C(answer_type_grouped)[T.Person]               0.5918      0.732      0.809      0.419      -0.842       2.026
C(answer_type_grouped)[T.Place]               -0.1178      1.010     -0.117      0.907      -2.097       1.861
q_length                                       0.2586      0.643      0.402      0.687      -1.001       1.518
capabilities_entropy                           1.9996      0.703      2.843      0.004       0.621       3.378
game_entropy                                   0.8891      0.683      1.302      0.193      -0.449       2.227
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing gpt-4o-2024-08-06 (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/gpt-4o-2024-08-06_SimpleMC_redacted_temp0.0_1751721962_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    161
1     86
Name: count, dtype: int64

Answer change%: 0.3482 [0.2887674164022944, 0.4075888589013493] (n=247)
P-value vs 25%: 0.0012; P-value vs 0%: 1.544e-30
Phase 2 self-accuracy: 0.5349 [0.42946704305053107, 0.640300398809934] (n=86)
P-value vs 25%: 1.179e-07; P-value vs 33%: 0.0001744

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  247
Model:                          Logit   Df Residuals:                      245
Method:                           MLE   Df Model:                            1
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                 0.09470
Time:                        20:58:14   Log-Likelihood:                -144.52
converged:                       True   LL-Null:                       -159.64
Covariance Type:            nonrobust   LLR p-value:                 3.824e-08
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          1.8397      0.494      3.724      0.000       0.872       2.808
p_i_capability    -3.7765      0.748     -5.049      0.000      -5.242      -2.311
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  247
Model:                          Logit   Df Residuals:                      245
Method:                           MLE   Df Model:                            1
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                  0.1232
Time:                        20:58:14   Log-Likelihood:                -139.98
converged:                       True   LL-Null:                       -159.64
Covariance Type:            nonrobust   LLR p-value:                 3.584e-10
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.6007      0.410     -6.345      0.000      -3.404      -1.797
capabilities_entropy     1.7299      0.313      5.525      0.000       1.116       2.344
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.6977 [0.6006, 0.7947] (n=86)
                  P-value vs 33.3%: 1.883e-13

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=-2.21, p=0.0283
Wilcoxon delta_p: statistic=5004.00, p=0.0477
Mean Δp = -0.0284  [-0.0536, -0.0033]
Idea 1 N = 156; 

  Idea 1.5: Calibration Metrics
  NLL: 3.0529, Signed ECE (overconf pos under neg): 0.1417, ECE: 0.1417 (n=242)
  Brier: 0.0369, Reliability (absolute calibration error; lower better): 0.0359, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=242)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.740
Model:                            OLS   Adj. R-squared:                  0.736
Method:                 Least Squares   F-statistic:                     225.4
Date:                Tue, 26 Aug 2025   Prob (F-statistic):           2.97e-69
Time:                        20:58:14   Log-Likelihood:                 138.67
No. Observations:                 242   AIC:                            -269.3
Df Residuals:                     238   BIC:                            -255.4
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.3257      0.044     -7.349      0.000      -0.413      -0.238
p1                    0.4022      0.058      6.925      0.000       0.288       0.517
answer_changed        0.1449      0.069      2.092      0.037       0.008       0.281
p1:answer_changed     0.5805      0.106      5.486      0.000       0.372       0.789
==============================================================================
Omnibus:                        0.442   Durbin-Watson:                   2.150
Prob(Omnibus):                  0.802   Jarque-Bera (JB):                0.220
Skew:                           0.037   Prob(JB):                        0.896
Kurtosis:                       3.128   Cond. No.                         19.5
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=2.41, p=0.0173
Wilcoxon delta_H: statistic=4767.00, p=0.0164
Mean ΔH = 0.0806  [0.0149, 0.1462]
Paired t-test delta_H Changed: statistic=6.47, p=5.87e-09
Wilcoxon delta_H Changed: statistic=585.00, p=3.11e-08
Mean ΔH Changed = 0.2825  [0.1970, 0.3681]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=4.03, p=7.54e-05
Wilcoxon (p_top2_game vs p_top2_base): statistic=9735.00, p=5.22e-06
Mean Δp_top2 = 0.0218  [0.0112, 0.0324] (n=242)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=5.59, p=6.11e-08
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=8900.00, p=1.03e-07
Mean ΔH_unchosen_baseline_set = 0.1524  [0.0989, 0.2058] (n=242)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  242
Model:                          Logit   Df Residuals:                      239
Method:                           MLE   Df Model:                            2
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                  0.1263
Time:                        20:58:14   Log-Likelihood:                -137.58
converged:                       True   LL-Null:                       -157.47
Covariance Type:            nonrobust   LLR p-value:                 2.295e-09
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.7708      0.215     -3.580      0.000      -1.193      -0.349
p1_z            -0.9374      0.164     -5.709      0.000      -1.259      -0.616
I(p1_z ** 2)     0.0543      0.179      0.303      0.762      -0.297       0.406
================================================================================
AUC = 0.734

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  247
Model:                          Logit   Df Residuals:                      245
Method:                           MLE   Df Model:                            1
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                 0.08111
Time:                        20:58:14   Log-Likelihood:                -146.69
converged:                       True   LL-Null:                       -159.64
Covariance Type:            nonrobust   LLR p-value:                 3.604e-07
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.9655      0.330     -5.953      0.000      -2.613      -1.318
game_entropy     1.3294      0.280      4.754      0.000       0.781       1.877
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=10429.00, p=1.39e-05
Paired t-test (game_entropy vs capabilities_entropy): statistic=-4.14, p=4.75e-05
Mean capabilities_entropy-game_entropy = 0.1086  [0.0572, 0.1601] (n=247)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  247
Model:                          Logit   Df Residuals:                      244
Method:                           MLE   Df Model:                            2
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                  0.1259
Time:                        20:58:14   Log-Likelihood:                -139.54
converged:                       True   LL-Null:                       -159.64
Covariance Type:            nonrobust   LLR p-value:                 1.865e-09
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.6703      0.418     -6.393      0.000      -3.489      -1.852
capabilities_entropy     1.4775      0.410      3.606      0.000       0.675       2.280
game_entropy             0.3544      0.380      0.933      0.351      -0.390       1.099
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['History', 'TV shows', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.545455
                        1                 0.454545
Geography               0                 0.590909
                        1                 0.409091
Misc                    0                 0.555556
                        1                 0.444444
Music                   0                 0.850000
                        1                 0.150000
Other                   0                 0.760000
                        1                 0.240000
Politics                0                 0.605263
                        1                 0.394737
Science and technology  0                 0.685185
                        1                 0.314815
Sports                  0                 0.736842
                        1                 0.263158
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.578947
                     1                 0.421053
Number               0                 0.756098
                     1                 0.243902
Other                0                 0.709091
                     1                 0.290909
Person               0                 0.642857
                     1                 0.357143
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.466667  0.533333           15
                       Number               1.000000  0.000000            2
                       Other                0.750000  0.250000            8
                       Person               0.375000  0.625000            8
Geography              Date                 0.444444  0.555556            9
                       Number               0.700000  0.300000           10
                       Other                0.666667  0.333333            3
Misc                   Date                 0.727273  0.272727           11
                       Number               0.600000  0.400000            5
                       Other                0.636364  0.363636           11
                       Person               0.222222  0.777778            9
Music                  Date                 0.875000  0.125000            8
                       Number               1.000000  0.000000            2
                       Other                0.875000  0.125000            8
                       Person               0.500000  0.500000            2
Other                  Date                 0.750000  0.250000            8
                       Number               1.000000  0.000000            4
                       Other                0.714286  0.285714            7
                       Person               0.666667  0.333333            6
Politics               Date                 0.523810  0.476190           21
                       Number               1.000000  0.000000            1
                       Other                0.714286  0.285714            7
                       Person               0.666667  0.333333            9
Science and technology Date                 0.555556  0.444444           18
                       Number               0.571429  0.428571            7
                       Other                0.555556  0.444444            9
                       Person               0.900000  0.100000           20
Sports                 Date                 0.400000  0.600000            5
                       Number               0.800000  0.200000           10
                       Other                1.000000  0.000000            2
                       Person               1.000000  0.000000            2

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  247
Model:                          Logit   Df Residuals:                      235
Method:                           MLE   Df Model:                           11
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                 0.04703
Time:                        20:58:14   Log-Likelihood:                -152.13
converged:                       True   LL-Null:                       -159.64
Covariance Type:            nonrobust   LLR p-value:                    0.1817
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      1.3918      1.804      0.771      0.440      -2.144       4.928
C(topic_grouped)[T.Geography]                 -0.0053      0.591     -0.009      0.993      -1.164       1.154
C(topic_grouped)[T.Misc]                       0.0929      0.493      0.188      0.851      -0.874       1.060
C(topic_grouped)[T.Music]                     -1.5194      0.724     -2.098      0.036      -2.939      -0.100
C(topic_grouped)[T.Other]                     -0.9044      0.590     -1.532      0.125      -2.061       0.252
C(topic_grouped)[T.Politics]                  -0.2483      0.494     -0.503      0.615      -1.216       0.719
C(topic_grouped)[T.Science and technology]    -0.5480      0.463     -1.183      0.237      -1.456       0.360
C(topic_grouped)[T.Sports]                    -0.5546      0.661     -0.839      0.401      -1.850       0.741
C(answer_type_grouped)[T.Number]              -0.8194      0.454     -1.805      0.071      -1.709       0.070
C(answer_type_grouped)[T.Other]               -0.5586      0.377     -1.482      0.138      -1.298       0.180
C(answer_type_grouped)[T.Person]              -0.2978      0.367     -0.812      0.417      -1.016       0.421
q_length                                      -0.2966      0.392     -0.757      0.449      -1.065       0.471
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 1.0530
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  247
Model:                          Logit   Df Residuals:                      234
Method:                           MLE   Df Model:                           12
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                  0.1709
Time:                        20:58:14   Log-Likelihood:                -132.36
converged:                       True   LL-Null:                       -159.64
Covariance Type:            nonrobust   LLR p-value:                 2.180e-07
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -0.8592      1.993     -0.431      0.666      -4.766       3.047
C(topic_grouped)[T.Geography]                 -0.1904      0.661     -0.288      0.773      -1.487       1.106
C(topic_grouped)[T.Misc]                      -0.2708      0.541     -0.501      0.616      -1.330       0.789
C(topic_grouped)[T.Music]                     -1.8263      0.780     -2.342      0.019      -3.355      -0.298
C(topic_grouped)[T.Other]                     -0.9398      0.637     -1.475      0.140      -2.189       0.309
C(topic_grouped)[T.Politics]                  -0.5345      0.549     -0.973      0.330      -1.611       0.542
C(topic_grouped)[T.Science and technology]    -0.8244      0.515     -1.602      0.109      -1.833       0.184
C(topic_grouped)[T.Sports]                    -0.7095      0.714     -0.994      0.320      -2.109       0.690
C(answer_type_grouped)[T.Number]              -0.7721      0.486     -1.587      0.112      -1.725       0.181
C(answer_type_grouped)[T.Other]               -0.1218      0.415     -0.294      0.769      -0.935       0.692
C(answer_type_grouped)[T.Person]               0.4048      0.423      0.956      0.339      -0.425       1.235
q_length                                      -0.2891      0.424     -0.683      0.495      -1.119       0.541
capabilities_entropy                           1.9033      0.347      5.485      0.000       1.223       2.583
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  247
Model:                          Logit   Df Residuals:                      234
Method:                           MLE   Df Model:                           12
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                  0.1393
Time:                        20:58:14   Log-Likelihood:                -137.40
converged:                       True   LL-Null:                       -159.64
Covariance Type:            nonrobust   LLR p-value:                 1.265e-05
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -0.9182      1.961     -0.468      0.640      -4.761       2.925
C(topic_grouped)[T.Geography]                  0.0454      0.636      0.071      0.943      -1.202       1.293
C(topic_grouped)[T.Misc]                       0.0599      0.527      0.114      0.909      -0.973       1.093
C(topic_grouped)[T.Music]                     -1.7426      0.764     -2.282      0.023      -3.239      -0.246
C(topic_grouped)[T.Other]                     -0.9950      0.623     -1.596      0.110      -2.217       0.227
C(topic_grouped)[T.Politics]                  -0.2130      0.528     -0.403      0.687      -1.248       0.822
C(topic_grouped)[T.Science and technology]    -0.6657      0.501     -1.330      0.184      -1.647       0.316
C(topic_grouped)[T.Sports]                    -0.3832      0.699     -0.548      0.583      -1.753       0.986
C(answer_type_grouped)[T.Number]              -0.9708      0.482     -2.014      0.044      -1.915      -0.026
C(answer_type_grouped)[T.Other]               -0.4692      0.403     -1.163      0.245      -1.260       0.321
C(answer_type_grouped)[T.Person]               0.2390      0.407      0.587      0.557      -0.559       1.037
q_length                                      -0.1476      0.415     -0.356      0.722      -0.960       0.665
game_entropy                                   1.5427      0.309      4.992      0.000       0.937       2.148
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  247
Model:                          Logit   Df Residuals:                      233
Method:                           MLE   Df Model:                           13
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                  0.1776
Time:                        20:58:14   Log-Likelihood:                -131.29
converged:                       True   LL-Null:                       -159.64
Covariance Type:            nonrobust   LLR p-value:                 2.035e-07
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.2375      2.016     -0.614      0.539      -5.189       2.714
C(topic_grouped)[T.Geography]                 -0.1461      0.665     -0.220      0.826      -1.449       1.157
C(topic_grouped)[T.Misc]                      -0.2138      0.544     -0.393      0.694      -1.280       0.852
C(topic_grouped)[T.Music]                     -1.8331      0.782     -2.345      0.019      -3.365      -0.301
C(topic_grouped)[T.Other]                     -0.9939      0.639     -1.555      0.120      -2.247       0.259
C(topic_grouped)[T.Politics]                  -0.4696      0.551     -0.853      0.394      -1.549       0.609
C(topic_grouped)[T.Science and technology]    -0.8315      0.517     -1.607      0.108      -1.846       0.183
C(topic_grouped)[T.Sports]                    -0.6302      0.718     -0.877      0.380      -2.038       0.778
C(answer_type_grouped)[T.Number]              -0.8451      0.492     -1.717      0.086      -1.810       0.120
C(answer_type_grouped)[T.Other]               -0.1931      0.421     -0.458      0.647      -1.018       0.632
C(answer_type_grouped)[T.Person]               0.4660      0.428      1.089      0.276      -0.372       1.304
q_length                                      -0.2348      0.426     -0.551      0.582      -1.070       0.601
capabilities_entropy                           1.4852      0.444      3.347      0.001       0.616       2.355
game_entropy                                   0.5954      0.409      1.456      0.145      -0.206       1.397
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing grok-3-latest (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/grok-3-latest_SimpleMC_redacted_cor_temp0.0_1751718904_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    239
1     56
Name: count, dtype: int64

Answer change%: 0.1898 [0.1450789637260746, 0.23458205322307796] (n=295)
P-value vs 25%: 0.008408; P-value vs 0%: 9.259e-17
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=56)
P-value vs 25%: 0; P-value vs 33%: 0

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  295
Model:                          Logit   Df Residuals:                      293
Method:                           MLE   Df Model:                            1
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                 0.04532
Time:                        20:58:14   Log-Likelihood:                -136.87
converged:                       True   LL-Null:                       -143.36
Covariance Type:            nonrobust   LLR p-value:                 0.0003122
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          1.0602      0.709      1.495      0.135      -0.330       2.450
p_i_capability    -2.8200      0.790     -3.568      0.000      -4.369      -1.271
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  295
Model:                          Logit   Df Residuals:                      293
Method:                           MLE   Df Model:                            1
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                  0.1139
Time:                        20:58:14   Log-Likelihood:                -127.04
converged:                       True   LL-Null:                       -143.36
Covariance Type:            nonrobust   LLR p-value:                 1.105e-08
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.1461      0.217     -9.868      0.000      -2.572      -1.720
capabilities_entropy     1.8634      0.335      5.563      0.000       1.207       2.520
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.6071 [0.4792, 0.7351] (n=56)
                  P-value vs 33.3%: 2.723e-05

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=2.25, p=0.0251
Wilcoxon delta_p: statistic=8867.00, p=1.1e-06
Mean Δp = 0.0216  [0.0028, 0.0403]
Idea 1 N = 236; 

  Idea 1.5: Calibration Metrics
  NLL: 0.0975, Signed ECE (overconf pos under neg): -0.0791, ECE: 0.0791 (n=292)
  Brier: 0.0258, Reliability (absolute calibration error; lower better): 0.0253, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=292)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.809
Model:                            OLS   Adj. R-squared:                  0.807
Method:                 Least Squares   F-statistic:                     405.3
Date:                Tue, 26 Aug 2025   Prob (F-statistic):          5.22e-103
Time:                        20:58:14   Log-Likelihood:                 188.02
No. Observations:                 292   AIC:                            -368.0
Df Residuals:                     288   BIC:                            -353.3
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.5177      0.065     -8.004      0.000      -0.645      -0.390
p1                    0.5725      0.068      8.408      0.000       0.438       0.707
answer_changed        0.5053      0.107      4.729      0.000       0.295       0.716
p1:answer_changed     0.2204      0.121      1.820      0.070      -0.018       0.459
==============================================================================
Omnibus:                      113.981   Durbin-Watson:                   2.070
Prob(Omnibus):                  0.000   Jarque-Bera (JB):              366.918
Skew:                           1.740   Prob(JB):                     2.11e-80
Kurtosis:                       7.248   Cond. No.                         31.8
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-6.47, p=5.52e-10
Wilcoxon delta_H: statistic=7546.00, p=8.74e-10
Mean ΔH = -0.2331  [-0.3037, -0.1625]
Paired t-test delta_H Changed: statistic=0.20, p=0.844
Wilcoxon delta_H Changed: statistic=760.00, p=0.757
Mean ΔH Changed = 0.0133  [-0.1180, 0.1446]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=-4.70, p=3.94e-06
Wilcoxon (p_top2_game vs p_top2_base): statistic=6853.00, p=7.83e-24
Mean Δp_top2 = -0.0171  [-0.0242, -0.0100] (n=292)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=-5.76, p=2.14e-08
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=13389.00, p=3.03e-08
Mean ΔH_unchosen_baseline_set = -0.1858  [-0.2491, -0.1226] (n=292)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  292
Model:                          Logit   Df Residuals:                      289
Method:                           MLE   Df Model:                            2
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                  0.1172
Time:                        20:58:14   Log-Likelihood:                -126.00
converged:                       True   LL-Null:                       -142.73
Covariance Type:            nonrobust   LLR p-value:                 5.414e-08
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.2012      0.196     -6.131      0.000      -1.585      -0.817
p1_z            -1.5249      0.314     -4.855      0.000      -2.141      -0.909
I(p1_z ** 2)    -0.4255      0.137     -3.108      0.002      -0.694      -0.157
================================================================================
AUC = 0.777

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  295
Model:                          Logit   Df Residuals:                      293
Method:                           MLE   Df Model:                            1
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                  0.2834
Time:                        20:58:14   Log-Likelihood:                -102.73
converged:                       True   LL-Null:                       -143.36
Covariance Type:            nonrobust   LLR p-value:                 1.976e-19
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -3.2033      0.333     -9.614      0.000      -3.856      -2.550
game_entropy     2.7416      0.353      7.761      0.000       2.049       3.434
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=11281.00, p=6.3e-13
Paired t-test (game_entropy vs capabilities_entropy): statistic=5.81, p=1.6e-08
Mean capabilities_entropy-game_entropy = -0.1619  [-0.2165, -0.1073] (n=295)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  295
Model:                          Logit   Df Residuals:                      292
Method:                           MLE   Df Model:                            2
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                  0.3008
Time:                        20:58:14   Log-Likelihood:                -100.24
converged:                       True   LL-Null:                       -143.36
Covariance Type:            nonrobust   LLR p-value:                 1.878e-19
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -3.3861      0.356     -9.510      0.000      -4.084      -2.688
capabilities_entropy     0.9021      0.402      2.243      0.025       0.114       1.690
game_entropy             2.4695      0.372      6.646      0.000       1.741       3.198
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['Other', 'Sports', 'Music', 'Geography', 'History', 'TV shows', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.875000
                        1                 0.125000
Misc                    0                 0.768212
                        1                 0.231788
Politics                0                 0.833333
                        1                 0.166667
Science and technology  0                 0.854167
                        1                 0.145833
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.811881
                     1                 0.188119
Number               0                 0.700000
                     1                 0.300000
Other                0                 0.857143
                     1                 0.142857
Person               0                 0.809524
                     1                 0.190476
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.714286  0.285714           14
                       Number               1.000000  0.000000            5
                       Other                0.923077  0.076923           13
                       Person               0.937500  0.062500           16
Misc                   Date                 0.782609  0.217391           46
                       Number               0.692308  0.307692           26
                       Other                0.803922  0.196078           51
                       Person               0.750000  0.250000           28
Politics               Date                 0.900000  0.100000           20
                       Number               0.500000  0.500000            4
                       Other                0.923077  0.076923           13
                       Person               0.727273  0.272727           11
Science and technology Date                 0.857143  0.142857           21
                       Number               0.600000  0.400000            5
                       Other                0.928571  0.071429           14
                       Person               0.875000  0.125000            8

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  295
Model:                          Logit   Df Residuals:                      287
Method:                           MLE   Df Model:                            7
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                 0.02877
Time:                        20:58:14   Log-Likelihood:                -139.24
converged:                       True   LL-Null:                       -143.36
Covariance Type:            nonrobust   LLR p-value:                    0.3111
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -3.1743      1.971     -1.611      0.107      -7.037       0.689
C(topic_grouped)[T.Misc]                       0.7405      0.484      1.531      0.126      -0.208       1.689
C(topic_grouped)[T.Politics]                   0.2887      0.599      0.482      0.630      -0.886       1.463
C(topic_grouped)[T.Science and technology]     0.1590      0.608      0.262      0.794      -1.032       1.350
C(answer_type_grouped)[T.Number]               0.5048      0.438      1.153      0.249      -0.353       1.363
C(answer_type_grouped)[T.Other]               -0.3776      0.397     -0.951      0.342      -1.156       0.401
C(answer_type_grouped)[T.Person]               0.0321      0.416      0.077      0.939      -0.783       0.848
q_length                                       0.2799      0.431      0.649      0.516      -0.565       1.125
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.2838
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  295
Model:                          Logit   Df Residuals:                      286
Method:                           MLE   Df Model:                            8
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                  0.1426
Time:                        20:58:14   Log-Likelihood:                -122.92
converged:                       True   LL-Null:                       -143.36
Covariance Type:            nonrobust   LLR p-value:                 2.181e-06
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -4.7818      2.136     -2.239      0.025      -8.968      -0.595
C(topic_grouped)[T.Misc]                       0.4999      0.518      0.966      0.334      -0.515       1.515
C(topic_grouped)[T.Politics]                   0.2532      0.630      0.402      0.688      -0.981       1.487
C(topic_grouped)[T.Science and technology]    -0.0525      0.641     -0.082      0.935      -1.309       1.204
C(answer_type_grouped)[T.Number]               0.2995      0.465      0.644      0.520      -0.612       1.211
C(answer_type_grouped)[T.Other]               -0.7288      0.439     -1.660      0.097      -1.589       0.132
C(answer_type_grouped)[T.Person]              -0.1966      0.447     -0.440      0.660      -1.072       0.679
q_length                                       0.5509      0.463      1.189      0.235      -0.357       1.459
capabilities_entropy                           1.9587      0.356      5.500      0.000       1.261       2.657
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  295
Model:                          Logit   Df Residuals:                      286
Method:                           MLE   Df Model:                            8
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                  0.2974
Time:                        20:58:14   Log-Likelihood:                -100.72
converged:                       True   LL-Null:                       -143.36
Covariance Type:            nonrobust   LLR p-value:                 4.199e-15
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -3.3399      2.382     -1.402      0.161      -8.009       1.329
C(topic_grouped)[T.Misc]                       0.7105      0.572      1.241      0.215      -0.411       1.832
C(topic_grouped)[T.Politics]                   0.7880      0.713      1.106      0.269      -0.609       2.185
C(topic_grouped)[T.Science and technology]     0.4657      0.710      0.656      0.512      -0.927       1.858
C(answer_type_grouped)[T.Number]               0.1932      0.535      0.361      0.718      -0.856       1.242
C(answer_type_grouped)[T.Other]               -0.5559      0.470     -1.183      0.237      -1.477       0.365
C(answer_type_grouped)[T.Person]              -0.2072      0.502     -0.413      0.680      -1.191       0.777
q_length                                      -0.0624      0.525     -0.119      0.905      -1.091       0.966
game_entropy                                   2.7447      0.363      7.564      0.000       2.033       3.456
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  295
Model:                          Logit   Df Residuals:                      285
Method:                           MLE   Df Model:                            9
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                  0.3171
Time:                        20:58:14   Log-Likelihood:                -97.904
converged:                       True   LL-Null:                       -143.36
Covariance Type:            nonrobust   LLR p-value:                 1.065e-15
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -4.2451      2.427     -1.749      0.080      -9.002       0.512
C(topic_grouped)[T.Misc]                       0.5698      0.585      0.974      0.330      -0.576       1.716
C(topic_grouped)[T.Politics]                   0.6826      0.713      0.957      0.339      -0.715       2.080
C(topic_grouped)[T.Science and technology]     0.3120      0.724      0.431      0.667      -1.107       1.731
C(answer_type_grouped)[T.Number]               0.1786      0.535      0.334      0.738      -0.870       1.227
C(answer_type_grouped)[T.Other]               -0.7157      0.491     -1.457      0.145      -1.678       0.247
C(answer_type_grouped)[T.Person]              -0.2755      0.505     -0.546      0.585      -1.265       0.714
q_length                                       0.1328      0.531      0.250      0.803      -0.908       1.174
capabilities_entropy                           0.9953      0.419      2.376      0.018       0.174       1.816
game_entropy                                   2.4412      0.381      6.409      0.000       1.695       3.188
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing grok-3-latest (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/grok-3-latest_SimpleMC_redacted_temp0.0_1751719937_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
1    111
0     94
Name: count, dtype: int64

Answer change%: 0.5415 [0.473254252367988, 0.6096725769003047] (n=205)
P-value vs 25%: 5.518e-17; P-value vs 0%: 1.388e-54
Phase 2 self-accuracy: 0.5405 [0.447831019784466, 0.6332500612966151] (n=111)
P-value vs 25%: 8.134e-10; P-value vs 33%: 1.146e-05

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  205
Model:                          Logit   Df Residuals:                      203
Method:                           MLE   Df Model:                            1
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                 0.05674
Time:                        20:58:14   Log-Likelihood:                -133.37
converged:                       True   LL-Null:                       -141.39
Covariance Type:            nonrobust   LLR p-value:                 6.183e-05
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          3.0605      0.787      3.887      0.000       1.517       4.604
p_i_capability    -3.4778      0.918     -3.787      0.000      -5.278      -1.678
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  205
Model:                          Logit   Df Residuals:                      203
Method:                           MLE   Df Model:                            1
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                 0.05585
Time:                        20:58:14   Log-Likelihood:                -133.49
converged:                       True   LL-Null:                       -141.39
Covariance Type:            nonrobust   LLR p-value:                 7.060e-05
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -0.5727      0.238     -2.407      0.016      -1.039      -0.106
capabilities_entropy     1.2345      0.323      3.818      0.000       0.601       1.868
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.5946 [0.5033, 0.6859] (n=111)
                  P-value vs 33.3%: 2.066e-08

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=4.05, p=0.000107
Wilcoxon delta_p: statistic=1146.00, p=4.18e-05
Mean Δp = 0.0783  [0.0404, 0.1162]
Idea 1 N = 94; 

  Idea 1.5: Calibration Metrics
  NLL: 5.1560, Signed ECE (overconf pos under neg): 0.0779, ECE: 0.0779 (n=205)
  Brier: 0.0196, Reliability (absolute calibration error; lower better): 0.0189, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=205)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.804
Model:                            OLS   Adj. R-squared:                  0.801
Method:                 Least Squares   F-statistic:                     275.5
Date:                Tue, 26 Aug 2025   Prob (F-statistic):           6.27e-71
Time:                        20:58:14   Log-Likelihood:                 90.653
No. Observations:                 205   AIC:                            -173.3
Df Residuals:                     201   BIC:                            -160.0
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.3689      0.096     -3.829      0.000      -0.559      -0.179
p1                    0.5107      0.108      4.709      0.000       0.297       0.725
answer_changed        0.2595      0.117      2.210      0.028       0.028       0.491
p1:answer_changed     0.4590      0.137      3.350      0.001       0.189       0.729
==============================================================================
Omnibus:                       25.083   Durbin-Watson:                   2.070
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               79.040
Skew:                          -0.420   Prob(JB):                     6.86e-18
Kurtosis:                       5.924   Cond. No.                         30.1
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-3.34, p=0.00121
Wilcoxon delta_H: statistic=1381.00, p=0.00132
Mean ΔH = -0.1752  [-0.2780, -0.0723]
Paired t-test delta_H Changed: statistic=0.68, p=0.495
Wilcoxon delta_H Changed: statistic=2839.00, p=0.429
Mean ΔH Changed = 0.0335  [-0.0625, 0.1294]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=-4.61, p=6.98e-06
Wilcoxon (p_top2_game vs p_top2_base): statistic=6151.00, p=2.2e-07
Mean Δp_top2 = -0.0280  [-0.0399, -0.0161] (n=205)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=-1.71, p=0.0895
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=9163.00, p=0.101
Mean ΔH_unchosen_baseline_set = -0.0622  [-0.1336, 0.0093] (n=205)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  205
Model:                          Logit   Df Residuals:                      202
Method:                           MLE   Df Model:                            2
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                 0.06024
Time:                        20:58:14   Log-Likelihood:                -132.87
converged:                       True   LL-Null:                       -141.39
Covariance Type:            nonrobust   LLR p-value:                 0.0001999
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept        0.3526      0.218      1.616      0.106      -0.075       0.780
p1_z            -0.7140      0.196     -3.643      0.000      -1.098      -0.330
I(p1_z ** 2)    -0.1678      0.166     -1.009      0.313      -0.494       0.158
================================================================================
AUC = 0.669

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  205
Model:                          Logit   Df Residuals:                      203
Method:                           MLE   Df Model:                            1
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                 0.02882
Time:                        20:58:14   Log-Likelihood:                -137.31
converged:                       True   LL-Null:                       -141.39
Covariance Type:            nonrobust   LLR p-value:                  0.004308
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.4745      0.268     -1.772      0.076      -0.999       0.050
game_entropy     0.7936      0.283      2.802      0.005       0.238       1.349
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=6854.00, p=1.33e-05
Paired t-test (game_entropy vs capabilities_entropy): statistic=4.93, p=1.66e-06
Mean capabilities_entropy-game_entropy = -0.2027  [-0.2832, -0.1222] (n=205)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  205
Model:                          Logit   Df Residuals:                      202
Method:                           MLE   Df Model:                            2
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                 0.06786
Time:                        20:58:14   Log-Likelihood:                -131.80
converged:                       True   LL-Null:                       -141.39
Covariance Type:            nonrobust   LLR p-value:                 6.814e-05
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -0.9235      0.311     -2.973      0.003      -1.532      -0.315
capabilities_entropy     1.0838      0.335      3.234      0.001       0.427       1.741
game_entropy             0.5462      0.299      1.829      0.067      -0.039       1.131
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['Politics', 'Art', 'Geography', 'Other', 'Music', 'Sports', 'TV shows', 'Video games', 'History']
                  Grouped rare answer_type into 'Misc'/'Other': ['Number', 'Other', 'Place']
topic_grouped           answer_changed
Misc                    1                 0.535484
                        0                 0.464516
Science and technology  1                 0.560000
                        0                 0.440000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.500000
                     1                 0.500000
Misc                 1                 0.662500
                     0                 0.337500
Person               0                 0.578947
                     1                 0.421053
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Misc                   Date                 0.574074  0.425926           54
                       Misc                 0.348485  0.651515           66
                       Person               0.514286  0.485714           35
Science and technology Date                 0.214286  0.785714           14
                       Misc                 0.285714  0.714286           14
                       Person               0.681818  0.318182           22

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  205
Model:                          Logit   Df Residuals:                      200
Method:                           MLE   Df Model:                            4
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                 0.03537
Time:                        20:58:14   Log-Likelihood:                -136.39
converged:                       True   LL-Null:                       -141.39
Covariance Type:            nonrobust   LLR p-value:                   0.04038
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.4544      1.720     -0.846      0.398      -4.825       1.916
C(topic_grouped)[T.Science and technology]     0.2724      0.345      0.789      0.430      -0.404       0.949
C(answer_type_grouped)[T.Misc]                 0.7212      0.343      2.100      0.036       0.048       1.394
C(answer_type_grouped)[T.Person]              -0.2907      0.381     -0.762      0.446      -1.038       0.457
q_length                                       0.2994      0.365      0.821      0.412      -0.416       1.014
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.6132
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  205
Model:                          Logit   Df Residuals:                      199
Method:                           MLE   Df Model:                            5
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                 0.09571
Time:                        20:58:14   Log-Likelihood:                -127.86
converged:                       True   LL-Null:                       -141.39
Covariance Type:            nonrobust   LLR p-value:                 5.544e-05
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -2.2161      1.808     -1.226      0.220      -5.759       1.327
C(topic_grouped)[T.Science and technology]     0.2071      0.366      0.565      0.572      -0.511       0.925
C(answer_type_grouped)[T.Misc]                 0.9537      0.367      2.596      0.009       0.234       1.674
C(answer_type_grouped)[T.Person]              -0.1352      0.401     -0.337      0.736      -0.920       0.650
q_length                                       0.2661      0.380      0.699      0.484      -0.480       1.012
capabilities_entropy                           1.3436      0.341      3.940      0.000       0.675       2.012
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  205
Model:                          Logit   Df Residuals:                      199
Method:                           MLE   Df Model:                            5
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                 0.06110
Time:                        20:58:14   Log-Likelihood:                -132.75
converged:                       True   LL-Null:                       -141.39
Covariance Type:            nonrobust   LLR p-value:                  0.004003
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -2.0585      1.772     -1.161      0.245      -5.532       1.415
C(topic_grouped)[T.Science and technology]     0.2615      0.351      0.746      0.456      -0.426       0.949
C(answer_type_grouped)[T.Misc]                 0.8032      0.352      2.281      0.023       0.113       1.493
C(answer_type_grouped)[T.Person]              -0.1331      0.392     -0.339      0.734      -0.902       0.636
q_length                                       0.2780      0.372      0.747      0.455      -0.452       1.008
game_entropy                                   0.7774      0.293      2.652      0.008       0.203       1.352
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  205
Model:                          Logit   Df Residuals:                      198
Method:                           MLE   Df Model:                            6
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                  0.1054
Time:                        20:58:14   Log-Likelihood:                -126.49
converged:                       True   LL-Null:                       -141.39
Covariance Type:            nonrobust   LLR p-value:                 4.280e-05
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -2.5322      1.838     -1.378      0.168      -6.134       1.070
C(topic_grouped)[T.Science and technology]     0.2031      0.368      0.552      0.581      -0.519       0.925
C(answer_type_grouped)[T.Misc]                 0.9747      0.369      2.640      0.008       0.251       1.698
C(answer_type_grouped)[T.Person]              -0.0539      0.407     -0.132      0.895      -0.852       0.744
q_length                                       0.2561      0.384      0.666      0.505      -0.497       1.009
capabilities_entropy                           1.2060      0.352      3.422      0.001       0.515       1.897
game_entropy                                   0.5069      0.308      1.646      0.100      -0.097       1.111
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing qwen3-235b-a22b-2507 (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/qwen3-235b-a22b-2507_SimpleMC_redacted_cor_temp0.0_1756216549_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    231
1     76
Name: count, dtype: int64

Answer change%: 0.2476 [0.19927855376321882, 0.29583545275143913] (n=307)
P-value vs 25%: 0.921; P-value vs 0%: 9.178e-24
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=76)
P-value vs 25%: 0; P-value vs 33%: 0

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  307
Model:                          Logit   Df Residuals:                      305
Method:                           MLE   Df Model:                            1
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                 0.04598
Time:                        20:58:14   Log-Likelihood:                -163.91
converged:                       True   LL-Null:                       -171.81
Covariance Type:            nonrobust   LLR p-value:                 7.039e-05
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          1.5130      0.660      2.293      0.022       0.220       2.806
p_i_capability    -2.9733      0.743     -4.001      0.000      -4.430      -1.517
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  307
Model:                          Logit   Df Residuals:                      305
Method:                           MLE   Df Model:                            1
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                 0.05240
Time:                        20:58:14   Log-Likelihood:                -162.81
converged:                       True   LL-Null:                       -171.81
Covariance Type:            nonrobust   LLR p-value:                 2.204e-05
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.5443      0.178     -8.661      0.000      -1.894      -1.195
capabilities_entropy     1.0231      0.241      4.249      0.000       0.551       1.495
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.7105 [0.6086, 0.8125] (n=76)
                  P-value vs 33.3%: 4.148e-13

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=3.55, p=0.000491
Wilcoxon delta_p: statistic=4850.00, p=6.61e-07
Mean Δp = 0.0561  [0.0251, 0.0871]
Idea 1 N = 186; 

  Idea 1.5: Calibration Metrics
  NLL: 0.1576, Signed ECE (overconf pos under neg): -0.1123, ECE: 0.1123 (n=256)
  Brier: 0.0441, Reliability (absolute calibration error; lower better): 0.0434, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=256)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.684
Model:                            OLS   Adj. R-squared:                  0.681
Method:                 Least Squares   F-statistic:                     180.6
Date:                Tue, 26 Aug 2025   Prob (F-statistic):           2.70e-62
Time:                        20:58:14   Log-Likelihood:                 48.780
No. Observations:                 254   AIC:                            -89.56
Df Residuals:                     250   BIC:                            -75.41
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.5084      0.085     -5.997      0.000      -0.675      -0.341
p1                    0.6190      0.092      6.762      0.000       0.439       0.799
answer_changed        0.2984      0.150      1.990      0.048       0.003       0.594
p1:answer_changed     0.4129      0.171      2.418      0.016       0.077       0.749
==============================================================================
Omnibus:                       39.735   Durbin-Watson:                   2.086
Prob(Omnibus):                  0.000   Jarque-Bera (JB):              228.906
Skew:                           0.390   Prob(JB):                     1.97e-50
Kurtosis:                       7.585   Cond. No.                         26.4
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-3.93, p=0.000119
Wilcoxon delta_H: statistic=5805.00, p=8.45e-05
Mean ΔH = -0.1943  [-0.2911, -0.0975]
Paired t-test delta_H Changed: statistic=2.19, p=0.0319
Wilcoxon delta_H Changed: statistic=885.00, p=0.0538
Mean ΔH Changed = 0.1628  [0.0171, 0.3086]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=-2.09, p=0.0375
Wilcoxon (p_top2_game vs p_top2_base): statistic=10385.00, p=4.8e-07
Mean Δp_top2 = -0.0099  [-0.0192, -0.0006] (n=256)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=-2.28, p=0.0234
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=13436.00, p=0.0144
Mean ΔH_unchosen_baseline_set = -0.0967  [-0.1797, -0.0136] (n=256)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  256
Model:                          Logit   Df Residuals:                      253
Method:                           MLE   Df Model:                            2
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                 0.07701
Time:                        20:58:14   Log-Likelihood:                -138.62
converged:                       True   LL-Null:                       -150.18
Covariance Type:            nonrobust   LLR p-value:                 9.490e-06
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.4191      0.215     -1.948      0.051      -0.841       0.003
p1_z            -1.3398      0.288     -4.646      0.000      -1.905      -0.775
I(p1_z ** 2)    -0.6430      0.179     -3.586      0.000      -0.994      -0.292
================================================================================
AUC = 0.665

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  307
Model:                          Logit   Df Residuals:                      305
Method:                           MLE   Df Model:                            1
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                 0.05367
Time:                        20:58:14   Log-Likelihood:                -162.59
converged:                       True   LL-Null:                       -171.81
Covariance Type:            nonrobust   LLR p-value:                 1.750e-05
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.6711      0.200     -8.351      0.000      -2.063      -1.279
game_entropy     1.0463      0.246      4.261      0.000       0.565       1.528
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=14780.00, p=5.83e-05
Paired t-test (game_entropy vs capabilities_entropy): statistic=3.16, p=0.00171
Mean capabilities_entropy-game_entropy = -0.1065  [-0.1724, -0.0405] (n=307)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  307
Model:                          Logit   Df Residuals:                      304
Method:                           MLE   Df Model:                            2
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                 0.07868
Time:                        20:58:14   Log-Likelihood:                -158.29
converged:                       True   LL-Null:                       -171.81
Covariance Type:            nonrobust   LLR p-value:                 1.346e-06
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.8588      0.217     -8.581      0.000      -2.283      -1.434
capabilities_entropy     0.7646      0.258      2.967      0.003       0.260       1.270
game_entropy             0.7917      0.263      3.015      0.003       0.277       1.306
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['Sports', 'TV shows', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': None
topic_grouped           answer_changed
Art                     0                 0.763636
                        1                 0.236364
Geography               0                 0.727273
                        1                 0.272727
History                 0                 0.636364
                        1                 0.363636
Misc                    0                 0.733333
                        1                 0.266667
Music                   0                 0.727273
                        1                 0.272727
Other                   0                 0.903226
                        1                 0.096774
Politics                0                 0.745098
                        1                 0.254902
Science and technology  0                 0.745763
                        1                 0.254237
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.717172
                     1                 0.282828
Number               0                 0.636364
                     1                 0.363636
Other                0                 0.821429
                     1                 0.178571
Person               0                 0.850575
                     1                 0.149425
Place                0                 0.571429
                     1                 0.428571
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.583333  0.416667           12
                       Number               0.666667  0.333333            6
                       Other                0.900000  0.100000           10
                       Person               0.869565  0.130435           23
                       Place                0.500000  0.500000            4
Geography              Date                 1.000000  0.000000            4
                       Number               0.636364  0.363636           11
                       Other                1.000000  0.000000            1
                       Place                0.666667  0.333333            6
History                Date                 0.692308  0.307692           13
                       Number               1.000000  0.000000            2
                       Other                0.000000  1.000000            2
                       Person               0.600000  0.400000            5
Misc                   Date                 0.727273  0.272727           11
                       Number               0.833333  0.166667            6
                       Other                0.750000  0.250000           12
                       Person               0.714286  0.285714           14
                       Place                0.500000  0.500000            2
Music                  Date                 0.750000  0.250000            8
                       Number               0.000000  1.000000            2
                       Other                0.666667  0.333333            3
                       Person               1.000000  0.000000            8
                       Place                0.000000  1.000000            1
Other                  Date                 0.777778  0.222222            9
                       Number               0.833333  0.166667            6
                       Other                1.000000  0.000000            5
                       Person               1.000000  0.000000           10
                       Place                1.000000  0.000000            1
Politics               Date                 0.695652  0.304348           23
                       Number               0.500000  0.500000            4
                       Other                0.900000  0.100000           10
                       Person               0.900000  0.100000           10
                       Place                0.500000  0.500000            4
Science and technology Date                 0.736842  0.263158           19
                       Number               0.428571  0.571429            7
                       Other                0.846154  0.153846           13
                       Person               0.823529  0.176471           17
                       Place                0.666667  0.333333            3

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  307
Model:                          Logit   Df Residuals:                      294
Method:                           MLE   Df Model:                           12
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                 0.06156
Time:                        20:58:14   Log-Likelihood:                -161.23
converged:                       True   LL-Null:                       -171.81
Covariance Type:            nonrobust   LLR p-value:                   0.04818
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -0.6168      1.710     -0.361      0.718      -3.968       2.734
C(topic_grouped)[T.Geography]                 -0.5781      0.619     -0.934      0.350      -1.792       0.636
C(topic_grouped)[T.History]                    0.5383      0.571      0.944      0.345      -0.580       1.657
C(topic_grouped)[T.Misc]                       0.1530      0.480      0.319      0.750      -0.788       1.094
C(topic_grouped)[T.Music]                      0.1728      0.595      0.290      0.771      -0.993       1.339
C(topic_grouped)[T.Other]                     -1.2166      0.704     -1.729      0.084      -2.596       0.163
C(topic_grouped)[T.Politics]                  -0.0092      0.487     -0.019      0.985      -0.963       0.945
C(topic_grouped)[T.Science and technology]     0.0517      0.454      0.114      0.909      -0.838       0.941
C(answer_type_grouped)[T.Number]               0.6056      0.417      1.452      0.146      -0.212       1.423
C(answer_type_grouped)[T.Other]               -0.5863      0.428     -1.369      0.171      -1.426       0.253
C(answer_type_grouped)[T.Person]              -0.7971      0.387     -2.061      0.039      -1.555      -0.039
C(answer_type_grouped)[T.Place]                0.8426      0.524      1.607      0.108      -0.185       1.870
q_length                                      -0.0727      0.372     -0.196      0.845      -0.801       0.656
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.3605
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  307
Model:                          Logit   Df Residuals:                      293
Method:                           MLE   Df Model:                           13
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                  0.1097
Time:                        20:58:14   Log-Likelihood:                -152.96
converged:                       True   LL-Null:                       -171.81
Covariance Type:            nonrobust   LLR p-value:                 0.0003228
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -2.1780      1.817     -1.198      0.231      -5.740       1.384
C(topic_grouped)[T.Geography]                 -0.5378      0.635     -0.847      0.397      -1.783       0.707
C(topic_grouped)[T.History]                    0.6102      0.590      1.034      0.301      -0.547       1.767
C(topic_grouped)[T.Misc]                       0.1820      0.497      0.366      0.714      -0.792       1.155
C(topic_grouped)[T.Music]                      0.3134      0.622      0.504      0.614      -0.906       1.533
C(topic_grouped)[T.Other]                     -1.2046      0.717     -1.681      0.093      -2.609       0.200
C(topic_grouped)[T.Politics]                  -0.0379      0.499     -0.076      0.939      -1.017       0.941
C(topic_grouped)[T.Science and technology]     0.0108      0.470      0.023      0.982      -0.911       0.933
C(answer_type_grouped)[T.Number]               0.5619      0.434      1.295      0.195      -0.288       1.412
C(answer_type_grouped)[T.Other]               -0.4049      0.443     -0.915      0.360      -1.273       0.463
C(answer_type_grouped)[T.Person]              -0.7214      0.396     -1.822      0.068      -1.497       0.054
C(answer_type_grouped)[T.Place]                0.9694      0.543      1.787      0.074      -0.094       2.033
q_length                                       0.1607      0.391      0.411      0.681      -0.606       0.927
capabilities_entropy                           1.0452      0.258      4.058      0.000       0.540       1.550
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  307
Model:                          Logit   Df Residuals:                      293
Method:                           MLE   Df Model:                           13
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                  0.1056
Time:                        20:58:14   Log-Likelihood:                -153.66
converged:                       True   LL-Null:                       -171.81
Covariance Type:            nonrobust   LLR p-value:                 0.0005324
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.5354      1.784     -0.861      0.389      -5.031       1.960
C(topic_grouped)[T.Geography]                 -0.6471      0.642     -1.008      0.313      -1.905       0.611
C(topic_grouped)[T.History]                    0.5085      0.584      0.870      0.384      -0.637       1.654
C(topic_grouped)[T.Misc]                       0.2183      0.491      0.444      0.657      -0.745       1.181
C(topic_grouped)[T.Music]                      0.1556      0.621      0.251      0.802      -1.061       1.372
C(topic_grouped)[T.Other]                     -1.1953      0.710     -1.684      0.092      -2.586       0.196
C(topic_grouped)[T.Politics]                  -0.0346      0.498     -0.070      0.945      -1.010       0.941
C(topic_grouped)[T.Science and technology]    -0.0144      0.473     -0.030      0.976      -0.941       0.912
C(answer_type_grouped)[T.Number]               0.7893      0.437      1.805      0.071      -0.068       1.646
C(answer_type_grouped)[T.Other]               -0.2347      0.448     -0.524      0.601      -1.114       0.644
C(answer_type_grouped)[T.Person]              -0.5178      0.401     -1.290      0.197      -1.305       0.269
C(answer_type_grouped)[T.Place]                1.1008      0.557      1.975      0.048       0.009       2.193
q_length                                      -0.0247      0.384     -0.064      0.949      -0.777       0.728
game_entropy                                   1.0145      0.264      3.844      0.000       0.497       1.532
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  307
Model:                          Logit   Df Residuals:                      292
Method:                           MLE   Df Model:                           14
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                  0.1305
Time:                        20:58:14   Log-Likelihood:                -149.39
converged:                       True   LL-Null:                       -171.81
Covariance Type:            nonrobust   LLR p-value:                 4.322e-05
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -2.5087      1.855     -1.352      0.176      -6.145       1.128
C(topic_grouped)[T.Geography]                 -0.5658      0.645     -0.877      0.380      -1.830       0.698
C(topic_grouped)[T.History]                    0.5897      0.599      0.985      0.325      -0.584       1.763
C(topic_grouped)[T.Misc]                       0.2509      0.502      0.499      0.618      -0.734       1.236
C(topic_grouped)[T.Music]                      0.2721      0.635      0.429      0.668      -0.972       1.516
C(topic_grouped)[T.Other]                     -1.1844      0.722     -1.640      0.101      -2.600       0.231
C(topic_grouped)[T.Politics]                  -0.0320      0.506     -0.063      0.950      -1.025       0.961
C(topic_grouped)[T.Science and technology]    -0.0073      0.482     -0.015      0.988      -0.952       0.937
C(answer_type_grouped)[T.Number]               0.7238      0.447      1.619      0.105      -0.152       1.600
C(answer_type_grouped)[T.Other]               -0.1769      0.457     -0.387      0.699      -1.072       0.718
C(answer_type_grouped)[T.Person]              -0.5077      0.408     -1.246      0.213      -1.306       0.291
C(answer_type_grouped)[T.Place]                1.1472      0.563      2.038      0.042       0.044       2.251
q_length                                       0.1378      0.397      0.347      0.729      -0.641       0.916
capabilities_entropy                           0.8113      0.275      2.950      0.003       0.272       1.350
game_entropy                                   0.7542      0.282      2.677      0.007       0.202       1.307
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing qwen3-235b-a22b-2507 (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/qwen3-235b-a22b-2507_SimpleMC_redacted_temp0.0_1756212978_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    114
1     79
Name: count, dtype: int64

Answer change%: 0.4093 [0.3399554018984067, 0.478697447842526] (n=193)
P-value vs 25%: 6.747e-06; P-value vs 0%: 6.21e-31
Phase 2 self-accuracy: 0.5063 [0.39608135926201626, 0.6165768685860851] (n=79)
P-value vs 25%: 5.19e-06; P-value vs 33%: 0.00206

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  193
Model:                          Logit   Df Residuals:                      191
Method:                           MLE   Df Model:                            1
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                 0.01791
Time:                        20:58:14   Log-Likelihood:                -128.25
converged:                       True   LL-Null:                       -130.59
Covariance Type:            nonrobust   LLR p-value:                   0.03054
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          0.8962      0.604      1.484      0.138      -0.287       2.080
p_i_capability    -1.5567      0.724     -2.149      0.032      -2.977      -0.137
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  193
Model:                          Logit   Df Residuals:                      191
Method:                           MLE   Df Model:                            1
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                 0.01544
Time:                        20:58:14   Log-Likelihood:                -128.57
converged:                       True   LL-Null:                       -130.59
Covariance Type:            nonrobust   LLR p-value:                   0.04465
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -0.6819      0.219     -3.118      0.002      -1.110      -0.253
capabilities_entropy     0.4918      0.246      1.996      0.046       0.009       0.975
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.6076 [0.4999, 0.7153] (n=79)
                  P-value vs 33.3%: 5.965e-07

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=1.54, p=0.127
Wilcoxon delta_p: statistic=2049.00, p=0.391
Mean Δp = 0.0385  [-0.0105, 0.0876]
Idea 1 N = 97; 

  Idea 1.5: Calibration Metrics
  NLL: 10.4050, Signed ECE (overconf pos under neg): 0.0960, ECE: 0.0960 (n=169)
  Brier: 0.0269, Reliability (absolute calibration error; lower better): 0.0262, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=169)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.711
Model:                            OLS   Adj. R-squared:                  0.706
Method:                 Least Squares   F-statistic:                     138.4
Date:                Tue, 26 Aug 2025   Prob (F-statistic):           2.64e-45
Time:                        20:58:14   Log-Likelihood:                 26.112
No. Observations:                 173   AIC:                            -44.22
Df Residuals:                     169   BIC:                            -31.61
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.5821      0.101     -5.761      0.000      -0.782      -0.383
p1                    0.7361      0.117      6.284      0.000       0.505       0.967
answer_changed        0.3922      0.135      2.914      0.004       0.126       0.658
p1:answer_changed     0.2645      0.161      1.648      0.101      -0.052       0.581
==============================================================================
Omnibus:                       12.179   Durbin-Watson:                   1.849
Prob(Omnibus):                  0.002   Jarque-Bera (JB):               32.095
Skew:                           0.036   Prob(JB):                     1.07e-07
Kurtosis:                       5.109   Cond. No.                         21.8
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-2.28, p=0.0247
Wilcoxon delta_H: statistic=1786.00, p=0.0336
Mean ΔH = -0.1536  [-0.2855, -0.0217]
Paired t-test delta_H Changed: statistic=2.78, p=0.00696
Wilcoxon delta_H Changed: statistic=996.00, p=0.0349
Mean ΔH Changed = 0.1774  [0.0521, 0.3027]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=-0.19, p=0.852
Wilcoxon (p_top2_game vs p_top2_base): statistic=6557.00, p=0.142
Mean Δp_top2 = -0.0013  [-0.0147, 0.0121] (n=173)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=-0.17, p=0.866
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=7141.00, p=0.744
Mean ΔH_unchosen_baseline_set = -0.0082  [-0.1034, 0.0870] (n=173)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  173
Model:                          Logit   Df Residuals:                      170
Method:                           MLE   Df Model:                            2
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                 0.02403
Time:                        20:58:14   Log-Likelihood:                -115.79
converged:                       True   LL-Null:                       -118.64
Covariance Type:            nonrobust   LLR p-value:                   0.05779
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.4861      0.251     -1.934      0.053      -0.979       0.007
p1_z            -0.1433      0.209     -0.685      0.493      -0.553       0.267
I(p1_z ** 2)     0.2431      0.203      1.199      0.231      -0.154       0.641
================================================================================
AUC = 0.590

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  193
Model:                          Logit   Df Residuals:                      191
Method:                           MLE   Df Model:                            1
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                 0.04796
Time:                        20:58:14   Log-Likelihood:                -124.32
converged:                       True   LL-Null:                       -130.59
Covariance Type:            nonrobust   LLR p-value:                 0.0004012
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.0321      0.251     -4.119      0.000      -1.523      -0.541
game_entropy     0.9885      0.287      3.441      0.001       0.426       1.552
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=8662.00, p=0.589
Paired t-test (game_entropy vs capabilities_entropy): statistic=0.43, p=0.67
Mean capabilities_entropy-game_entropy = -0.0226  [-0.1260, 0.0809] (n=193)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  193
Model:                          Logit   Df Residuals:                      190
Method:                           MLE   Df Model:                            2
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                 0.05601
Time:                        20:58:14   Log-Likelihood:                -123.27
converged:                       True   LL-Null:                       -130.59
Covariance Type:            nonrobust   LLR p-value:                 0.0006659
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.2264      0.288     -4.251      0.000      -1.792      -0.661
capabilities_entropy     0.3710      0.256      1.450      0.147      -0.131       0.873
game_entropy             0.9256      0.291      3.183      0.001       0.356       1.496
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['Video games', 'History']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.850000
                        1                 0.150000
Geography               0                 0.500000
                        1                 0.500000
Music                   0                 0.666667
                        1                 0.333333
Other                   1                 0.515152
                        0                 0.484848
Politics                1                 0.538462
                        0                 0.461538
Science and technology  0                 0.538462
                        1                 0.461538
Sports                  0                 0.714286
                        1                 0.285714
TV shows                0                 0.714286
                        1                 0.285714
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.600000
                     1                 0.400000
Number               1                 0.558824
                     0                 0.441176
Other                0                 0.660714
                     1                 0.339286
Person               0                 0.606061
                     1                 0.393939
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.888889  0.111111            9
                       Number               0.333333  0.666667            3
                       Other                1.000000  0.000000            4
                       Person               1.000000  0.000000            4
Geography              Date                 0.636364  0.363636           11
                       Number               0.428571  0.571429            7
                       Other                0.250000  0.750000            4
Music                  Date                 0.750000  0.250000            4
                       Number               0.000000  1.000000            2
                       Other                0.750000  0.250000            8
                       Person               0.750000  0.250000            4
Other                  Date                 0.363636  0.636364           11
                       Number               0.250000  0.750000            4
                       Other                0.600000  0.400000           15
                       Person               0.666667  0.333333            3
Politics               Date                 0.461538  0.538462           13
                       Number               0.000000  1.000000            2
                       Other                1.000000  0.000000            6
                       Person               0.000000  1.000000            5
Science and technology Date                 0.625000  0.375000           16
                       Number               0.428571  0.571429            7
                       Other                0.000000  1.000000            3
                       Person               0.615385  0.384615           13
Sports                 Date                 0.666667  0.333333            6
                       Number               0.750000  0.250000            8
                       Other                0.666667  0.333333            6
                       Person               1.000000  0.000000            1
TV shows               Number               1.000000  0.000000            1
                       Other                0.700000  0.300000           10
                       Person               0.666667  0.333333            3

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  193
Model:                          Logit   Df Residuals:                      181
Method:                           MLE   Df Model:                           11
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                 0.07928
Time:                        20:58:14   Log-Likelihood:                -120.23
converged:                       True   LL-Null:                       -130.59
Covariance Type:            nonrobust   LLR p-value:                   0.03654
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      0.7944      2.072      0.383      0.701      -3.267       4.856
C(topic_grouped)[T.Geography]                  1.6074      0.776      2.070      0.038       0.086       3.129
C(topic_grouped)[T.Music]                      1.1707      0.824      1.421      0.155      -0.444       2.785
C(topic_grouped)[T.Other]                      1.9439      0.739      2.629      0.009       0.495       3.393
C(topic_grouped)[T.Politics]                   2.0915      0.761      2.747      0.006       0.599       3.584
C(topic_grouped)[T.Science and technology]     1.6346      0.725      2.253      0.024       0.213       3.056
C(topic_grouped)[T.Sports]                     0.7035      0.815      0.864      0.388      -0.893       2.300
C(topic_grouped)[T.TV shows]                   1.0115      0.903      1.120      0.263      -0.759       2.782
C(answer_type_grouped)[T.Number]               0.8877      0.459      1.933      0.053      -0.012       1.788
C(answer_type_grouped)[T.Other]               -0.2051      0.418     -0.490      0.624      -1.025       0.614
C(answer_type_grouped)[T.Person]              -0.0510      0.475     -0.107      0.914      -0.981       0.879
q_length                                      -0.5947      0.440     -1.352      0.177      -1.457       0.268
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.6265
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  193
Model:                          Logit   Df Residuals:                      180
Method:                           MLE   Df Model:                           12
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                 0.08458
Time:                        20:58:14   Log-Likelihood:                -119.54
converged:                       True   LL-Null:                       -130.59
Covariance Type:            nonrobust   LLR p-value:                   0.03653
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      0.3709      2.102      0.176      0.860      -3.749       4.491
C(topic_grouped)[T.Geography]                  1.4900      0.785      1.898      0.058      -0.049       3.029
C(topic_grouped)[T.Music]                      1.1824      0.827      1.429      0.153      -0.439       2.804
C(topic_grouped)[T.Other]                      1.8955      0.743      2.553      0.011       0.440       3.351
C(topic_grouped)[T.Politics]                   1.9902      0.767      2.593      0.010       0.486       3.494
C(topic_grouped)[T.Science and technology]     1.5322      0.731      2.095      0.036       0.099       2.966
C(topic_grouped)[T.Sports]                     0.6705      0.817      0.821      0.412      -0.930       2.271
C(topic_grouped)[T.TV shows]                   0.8894      0.913      0.974      0.330      -0.900       2.679
C(answer_type_grouped)[T.Number]               0.8757      0.462      1.896      0.058      -0.029       1.781
C(answer_type_grouped)[T.Other]               -0.1642      0.422     -0.389      0.697      -0.991       0.662
C(answer_type_grouped)[T.Person]              -0.0010      0.477     -0.002      0.998      -0.935       0.933
q_length                                      -0.5344      0.441     -1.211      0.226      -1.400       0.331
capabilities_entropy                           0.3154      0.269      1.174      0.240      -0.211       0.842
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  193
Model:                          Logit   Df Residuals:                      180
Method:                           MLE   Df Model:                           12
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                  0.1311
Time:                        20:58:14   Log-Likelihood:                -113.47
converged:                       True   LL-Null:                       -130.59
Covariance Type:            nonrobust   LLR p-value:                 0.0006187
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      0.1766      2.166      0.082      0.935      -4.069       4.422
C(topic_grouped)[T.Geography]                  1.6496      0.800      2.061      0.039       0.081       3.218
C(topic_grouped)[T.Music]                      1.2729      0.851      1.496      0.135      -0.395       2.941
C(topic_grouped)[T.Other]                      2.0538      0.763      2.691      0.007       0.558       3.550
C(topic_grouped)[T.Politics]                   2.1336      0.792      2.694      0.007       0.581       3.686
C(topic_grouped)[T.Science and technology]     1.7622      0.749      2.351      0.019       0.293       3.231
C(topic_grouped)[T.Sports]                     0.6671      0.845      0.790      0.430      -0.988       2.323
C(topic_grouped)[T.TV shows]                   0.9607      0.925      1.038      0.299      -0.853       2.774
C(answer_type_grouped)[T.Number]               1.0612      0.480      2.209      0.027       0.120       2.003
C(answer_type_grouped)[T.Other]               -0.0572      0.437     -0.131      0.896      -0.913       0.798
C(answer_type_grouped)[T.Person]               0.1075      0.504      0.213      0.831      -0.880       1.095
q_length                                      -0.6592      0.456     -1.447      0.148      -1.552       0.234
game_entropy                                   1.1074      0.312      3.546      0.000       0.495       1.720
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  193
Model:                          Logit   Df Residuals:                      179
Method:                           MLE   Df Model:                           13
Date:                Tue, 26 Aug 2025   Pseudo R-squ.:                  0.1321
Time:                        20:58:14   Log-Likelihood:                -113.33
converged:                       True   LL-Null:                       -130.59
Covariance Type:            nonrobust   LLR p-value:                  0.001009
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -0.0135      2.196     -0.006      0.995      -4.317       4.290
C(topic_grouped)[T.Geography]                  1.5955      0.809      1.972      0.049       0.010       3.181
C(topic_grouped)[T.Music]                      1.2731      0.851      1.496      0.135      -0.395       2.941
C(topic_grouped)[T.Other]                      2.0248      0.766      2.642      0.008       0.523       3.527
C(topic_grouped)[T.Politics]                   2.0805      0.799      2.603      0.009       0.514       3.647
C(topic_grouped)[T.Science and technology]     1.7058      0.757      2.252      0.024       0.221       3.190
C(topic_grouped)[T.Sports]                     0.6546      0.845      0.775      0.438      -1.001       2.311
C(topic_grouped)[T.TV shows]                   0.8996      0.935      0.962      0.336      -0.933       2.732
C(answer_type_grouped)[T.Number]               1.0480      0.481      2.179      0.029       0.105       1.991
C(answer_type_grouped)[T.Other]               -0.0358      0.439     -0.082      0.935      -0.896       0.825
C(answer_type_grouped)[T.Person]               0.1308      0.506      0.258      0.796      -0.861       1.123
q_length                                      -0.6270      0.458     -1.368      0.171      -1.525       0.271
capabilities_entropy                           0.1465      0.284      0.515      0.606      -0.411       0.704
game_entropy                                   1.0788      0.317      3.406      0.001       0.458       1.700
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.
