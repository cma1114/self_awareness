
--- Analyzing claude-3-5-sonnet-20241022 (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/claude-3-5-sonnet-20241022_GPQA_redacted_cor_temp0.0_1753836130_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    164
1     31
Name: count, dtype: int64

Answer change%: 0.1590 [0.1076529058083461, 0.21029581214037182] (n=195)
P-value vs 25%: 0.0005084; P-value vs 0%: 1.269e-09
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=31)
P-value vs 25%: 0; P-value vs 33%: 0

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  195
Model:                          Logit   Df Residuals:                      193
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.2378
Time:                        21:14:14   Log-Likelihood:                -65.093
converged:                       True   LL-Null:                       -85.403
Covariance Type:            nonrobust   LLR p-value:                 1.849e-10
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          2.8308      0.746      3.794      0.000       1.368       4.293
p_i_capability    -6.1355      1.065     -5.759      0.000      -8.224      -4.048
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  195
Model:                          Logit   Df Residuals:                      193
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.2121
Time:                        21:14:14   Log-Likelihood:                -67.286
converged:                       True   LL-Null:                       -85.403
Covariance Type:            nonrobust   LLR p-value:                 1.750e-09
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -3.7487      0.504     -7.431      0.000      -4.737      -2.760
capabilities_entropy     2.1920      0.401      5.466      0.000       1.406       2.978
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.6129 [0.4414, 0.7844] (n=31)
                  P-value vs 33.3%: 0.001395

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=-2.55, p=0.0117
Wilcoxon delta_p: statistic=1341.00, p=0.00189
Mean Δp = -0.0236  [-0.0418, -0.0055]
Idea 1 N = 164; 

  Idea 1.5: Calibration Metrics
  NLL: 0.2495, Signed ECE (overconf pos under neg): -0.1901, ECE: 0.1901 (n=195)
  Brier: 0.0745, Reliability (absolute calibration error; lower better): 0.0740, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=195)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.701
Model:                            OLS   Adj. R-squared:                  0.696
Method:                 Least Squares   F-statistic:                     149.3
Date:                Fri, 19 Sep 2025   Prob (F-statistic):           7.81e-50
Time:                        21:14:14   Log-Likelihood:                 159.23
No. Observations:                 195   AIC:                            -310.5
Df Residuals:                     191   BIC:                            -297.4
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.3328      0.043     -7.787      0.000      -0.417      -0.249
p1                    0.3633      0.049      7.379      0.000       0.266       0.460
answer_changed        0.0872      0.082      1.060      0.290      -0.075       0.249
p1:answer_changed     0.6475      0.124      5.206      0.000       0.402       0.893
==============================================================================
Omnibus:                       37.097   Durbin-Watson:                   1.781
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               86.570
Skew:                           0.845   Prob(JB):                     1.59e-19
Kurtosis:                       5.792   Cond. No.                         25.4
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=0.50, p=0.619
Wilcoxon delta_H: statistic=2041.50, p=0.581
Mean ΔH = 0.0165  [-0.0485, 0.0816]
Paired t-test delta_H Changed: statistic=3.89, p=0.00051
Wilcoxon delta_H Changed: statistic=72.00, p=0.000287
Mean ΔH Changed = 0.2861  [0.1421, 0.4302]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=3.25, p=0.00134
Wilcoxon (p_top2_game vs p_top2_base): statistic=2524.50, p=0.000758
Mean Δp_top2 = 0.0161  [0.0064, 0.0257] (n=195)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=1.92, p=0.0569
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=3068.50, p=0.0443
Mean ΔH_unchosen_baseline_set = 0.0594  [-0.0014, 0.1202] (n=195)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  195
Model:                          Logit   Df Residuals:                      192
Method:                           MLE   Df Model:                            2
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.2953
Time:                        21:14:14   Log-Likelihood:                -60.185
converged:                       True   LL-Null:                       -85.403
Covariance Type:            nonrobust   LLR p-value:                 1.117e-11
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.8414      0.325     -5.672      0.000      -2.478      -1.205
p1_z            -2.3830      0.505     -4.715      0.000      -3.374      -1.392
I(p1_z ** 2)    -0.7422      0.251     -2.962      0.003      -1.233      -0.251
================================================================================
AUC = 0.859

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  195
Model:                          Logit   Df Residuals:                      193
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.2151
Time:                        21:14:14   Log-Likelihood:                -67.032
converged:                       True   LL-Null:                       -85.403
Covariance Type:            nonrobust   LLR p-value:                 1.348e-09
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -3.6188      0.472     -7.669      0.000      -4.544      -2.694
game_entropy     2.3124      0.414      5.590      0.000       1.502       3.123
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=2492.50, p=0.000566
Paired t-test (game_entropy vs capabilities_entropy): statistic=-3.41, p=0.000786
Mean capabilities_entropy-game_entropy = 0.0833  [0.0355, 0.1312] (n=195)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  195
Model:                          Logit   Df Residuals:                      192
Method:                           MLE   Df Model:                            2
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.2398
Time:                        21:14:14   Log-Likelihood:                -64.920
converged:                       True   LL-Null:                       -85.403
Covariance Type:            nonrobust   LLR p-value:                 1.271e-09
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -3.9451      0.522     -7.564      0.000      -4.967      -2.923
capabilities_entropy     1.2341      0.599      2.062      0.039       0.061       2.407
game_entropy             1.3145      0.618      2.128      0.033       0.104       2.525
========================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  195
Model:                          Logit   Df Residuals:                      193
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.02511
Time:                        21:14:14   Log-Likelihood:                -83.259
converged:                       True   LL-Null:                       -85.403
Covariance Type:            nonrobust   LLR p-value:                   0.03835
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept            0.0706      0.852      0.083      0.934      -1.600       1.741
human_difficulty    -0.7689      0.379     -2.028      0.043      -1.512      -0.026
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  195
Model:                          Logit   Df Residuals:                      188
Method:                           MLE   Df Model:                            6
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.06694
Time:                        21:14:14   Log-Likelihood:                -79.686
converged:                       True   LL-Null:                       -85.403
Covariance Type:            nonrobust   LLR p-value:                   0.07586
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                             1.2276      3.242      0.379      0.705      -5.127       7.582
C(domain_grouped)[T.chemistry]        0.9306      0.736      1.264      0.206      -0.513       2.374
C(domain_grouped)[T.physics]          0.8810      0.705      1.250      0.211      -0.501       2.263
human_difficulty                     -0.5722      0.390     -1.467      0.142      -1.336       0.192
q_length                              0.0952      0.367      0.259      0.796      -0.625       0.815
avg_word_length                      -0.6103      0.407     -1.501      0.133      -1.407       0.187
percent_non_alphabetic_whitespace    -0.0163      0.038     -0.423      0.672      -0.092       0.059
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 0.7453
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  195
Model:                          Logit   Df Residuals:                      187
Method:                           MLE   Df Model:                            7
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.2533
Time:                        21:14:15   Log-Likelihood:                -63.773
converged:                       True   LL-Null:                       -85.403
Covariance Type:            nonrobust   LLR p-value:                 2.970e-07
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -0.7111      3.615     -0.197      0.844      -7.797       6.375
C(domain_grouped)[T.chemistry]        0.2493      0.803      0.311      0.756      -1.325       1.823
C(domain_grouped)[T.physics]          0.5808      0.757      0.767      0.443      -0.904       2.065
human_difficulty                     -0.7227      0.466     -1.550      0.121      -1.637       0.191
q_length                             -0.2111      0.409     -0.517      0.605      -1.012       0.590
avg_word_length                      -0.1743      0.411     -0.424      0.672      -0.980       0.632
percent_non_alphabetic_whitespace     0.0207      0.043      0.487      0.627      -0.063       0.104
capabilities_entropy                  2.2519      0.446      5.052      0.000       1.378       3.125
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  195
Model:                          Logit   Df Residuals:                      187
Method:                           MLE   Df Model:                            7
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.2509
Time:                        21:14:15   Log-Likelihood:                -63.974
converged:                       True   LL-Null:                       -85.403
Covariance Type:            nonrobust   LLR p-value:                 3.553e-07
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -1.2384      3.485     -0.355      0.722      -8.069       5.592
C(domain_grouped)[T.chemistry]       -0.1548      0.801     -0.193      0.847      -1.725       1.415
C(domain_grouped)[T.physics]          0.1836      0.792      0.232      0.817      -1.368       1.735
human_difficulty                     -0.9125      0.483     -1.889      0.059      -1.859       0.034
q_length                             -0.0206      0.398     -0.052      0.959      -0.801       0.760
avg_word_length                      -0.0874      0.415     -0.211      0.833      -0.901       0.726
percent_non_alphabetic_whitespace     0.0122      0.044      0.279      0.780      -0.073       0.098
game_entropy                          2.3875      0.472      5.055      0.000       1.462       3.313
=====================================================================================================

                  Model 4.95: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  195
Model:                          Logit   Df Residuals:                      186
Method:                           MLE   Df Model:                            8
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.2767
Time:                        21:14:15   Log-Likelihood:                -61.772
converged:                       True   LL-Null:                       -85.403
Covariance Type:            nonrobust   LLR p-value:                 1.366e-07
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -1.1545      3.597     -0.321      0.748      -8.205       5.896
C(domain_grouped)[T.chemistry]       -0.2128      0.822     -0.259      0.796      -1.824       1.399
C(domain_grouped)[T.physics]          0.2103      0.782      0.269      0.788      -1.322       1.742
human_difficulty                     -0.8659      0.491     -1.763      0.078      -1.828       0.097
q_length                             -0.1791      0.411     -0.435      0.663      -0.985       0.627
avg_word_length                      -0.0288      0.422     -0.068      0.946      -0.856       0.798
percent_non_alphabetic_whitespace     0.0222      0.044      0.505      0.614      -0.064       0.108
capabilities_entropy                  1.3430      0.639      2.103      0.035       0.091       2.595
game_entropy                          1.3299      0.676      1.966      0.049       0.004       2.656
=====================================================================================================

--- Analyzing claude-3-5-sonnet-20241022 (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/claude-3-5-sonnet-20241022_GPQA_redacted_temp0.0_1753884209_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    160
1     92
Name: count, dtype: int64

Answer change%: 0.3651 [0.3056363013863806, 0.4245224287723495] (n=252)
P-value vs 25%: 0.000148; P-value vs 0%: 2.259e-33
Phase 2 self-accuracy: 0.3478 [0.25050275604046973, 0.4451494178725737] (n=92)
P-value vs 25%: 0.04883; P-value vs 33%: 0.7653

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  252
Model:                          Logit   Df Residuals:                      250
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.1444
Time:                        21:14:15   Log-Likelihood:                -141.50
converged:                       True   LL-Null:                       -165.38
Covariance Type:            nonrobust   LLR p-value:                 4.793e-12
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          2.5015      0.492      5.085      0.000       1.537       3.466
p_i_capability    -4.8166      0.774     -6.224      0.000      -6.333      -3.300
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  252
Model:                          Logit   Df Residuals:                      250
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.1593
Time:                        21:14:15   Log-Likelihood:                -139.03
converged:                       True   LL-Null:                       -165.38
Covariance Type:            nonrobust   LLR p-value:                 3.873e-13
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -3.0810      0.451     -6.831      0.000      -3.965      -2.197
capabilities_entropy     2.0218      0.320      6.323      0.000       1.395       2.648
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.6413 [0.5433, 0.7393] (n=92)
                  P-value vs 33.3%: 7.322e-10

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=-2.85, p=0.00489
Wilcoxon delta_p: statistic=3444.50, p=0.00282
Mean Δp = -0.0417  [-0.0703, -0.0131]
Idea 1 N = 160; 

  Idea 1.5: Calibration Metrics
  NLL: 2.6878, Signed ECE (overconf pos under neg): 0.1284, ECE: 0.1284 (n=252)
  Brier: 0.0300, Reliability (absolute calibration error; lower better): 0.0292, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=252)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.696
Model:                            OLS   Adj. R-squared:                  0.692
Method:                 Least Squares   F-statistic:                     188.9
Date:                Fri, 19 Sep 2025   Prob (F-statistic):           9.19e-64
Time:                        21:14:15   Log-Likelihood:                 124.08
No. Observations:                 252   AIC:                            -240.2
Df Residuals:                     248   BIC:                            -226.0
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.3928      0.044     -8.942      0.000      -0.479      -0.306
p1                    0.4817      0.058      8.298      0.000       0.367       0.596
answer_changed        0.1490      0.070      2.132      0.034       0.011       0.287
p1:answer_changed     0.5788      0.112      5.184      0.000       0.359       0.799
==============================================================================
Omnibus:                        6.265   Durbin-Watson:                   2.149
Prob(Omnibus):                  0.044   Jarque-Bera (JB):                6.235
Skew:                           0.351   Prob(JB):                       0.0443
Kurtosis:                       2.681   Cond. No.                         18.8
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-0.07, p=0.941
Wilcoxon delta_H: statistic=4831.00, p=0.829
Mean ΔH = -0.0026  [-0.0718, 0.0665]
Paired t-test delta_H Changed: statistic=8.67, p=1.54e-13
Wilcoxon delta_H Changed: statistic=352.00, p=3.44e-12
Mean ΔH Changed = 0.3432  [0.2656, 0.4208]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=4.99, p=1.12e-06
Wilcoxon (p_top2_game vs p_top2_base): statistic=8744.00, p=3.15e-06
Mean Δp_top2 = 0.0287  [0.0174, 0.0399] (n=252)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=4.32, p=2.24e-05
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=9012.00, p=1.09e-05
Mean ΔH_unchosen_baseline_set = 0.1236  [0.0676, 0.1797] (n=252)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  252
Model:                          Logit   Df Residuals:                      249
Method:                           MLE   Df Model:                            2
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.1535
Time:                        21:14:15   Log-Likelihood:                -139.99
converged:                       True   LL-Null:                       -165.38
Covariance Type:            nonrobust   LLR p-value:                 9.369e-12
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.4340      0.209     -2.078      0.038      -0.843      -0.025
p1_z            -1.0766      0.179     -6.024      0.000      -1.427      -0.726
I(p1_z ** 2)    -0.3229      0.189     -1.713      0.087      -0.693       0.047
================================================================================
AUC = 0.749

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  252
Model:                          Logit   Df Residuals:                      250
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.1327
Time:                        21:14:15   Log-Likelihood:                -143.44
converged:                       True   LL-Null:                       -165.38
Covariance Type:            nonrobust   LLR p-value:                 3.485e-11
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -2.4973      0.368     -6.794      0.000      -3.218      -1.777
game_entropy     1.7767      0.293      6.059      0.000       1.202       2.351
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=8352.00, p=4.56e-07
Paired t-test (game_entropy vs capabilities_entropy): statistic=-5.13, p=5.72e-07
Mean capabilities_entropy-game_entropy = 0.1339  [0.0828, 0.1850] (n=252)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  252
Model:                          Logit   Df Residuals:                      249
Method:                           MLE   Df Model:                            2
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.1756
Time:                        21:14:15   Log-Likelihood:                -136.35
converged:                       True   LL-Null:                       -165.38
Covariance Type:            nonrobust   LLR p-value:                 2.455e-13
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -3.3114      0.469     -7.066      0.000      -4.230      -2.393
capabilities_entropy     1.4473      0.398      3.636      0.000       0.667       2.227
game_entropy             0.8639      0.376      2.299      0.022       0.127       1.601
========================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  252
Model:                          Logit   Df Residuals:                      250
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:               2.524e-05
Time:                        21:14:15   Log-Likelihood:                -165.38
converged:                       True   LL-Null:                       -165.38
Covariance Type:            nonrobust   LLR p-value:                    0.9272
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -0.6016      0.544     -1.106      0.269      -1.668       0.465
human_difficulty     0.0201      0.220      0.091      0.927      -0.411       0.451
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  252
Model:                          Logit   Df Residuals:                      245
Method:                           MLE   Df Model:                            6
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.01358
Time:                        21:14:15   Log-Likelihood:                -163.14
converged:                       True   LL-Null:                       -165.38
Covariance Type:            nonrobust   LLR p-value:                    0.6102
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                             0.5718      2.110      0.271      0.786      -3.563       4.707
C(domain_grouped)[T.chemistry]        0.4259      0.510      0.835      0.403      -0.573       1.425
C(domain_grouped)[T.physics]          0.5765      0.524      1.099      0.272      -0.451       1.605
human_difficulty                      0.1194      0.231      0.517      0.605      -0.334       0.572
q_length                             -0.1144      0.215     -0.532      0.595      -0.536       0.307
avg_word_length                      -0.2459      0.244     -1.008      0.314      -0.724       0.232
percent_non_alphabetic_whitespace    -0.0076      0.024     -0.314      0.753      -0.055       0.040
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 1.1634
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  252
Model:                          Logit   Df Residuals:                      244
Method:                           MLE   Df Model:                            7
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.1698
Time:                        21:14:15   Log-Likelihood:                -137.31
converged:                       True   LL-Null:                       -165.38
Covariance Type:            nonrobust   LLR p-value:                 8.820e-10
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -3.0285      2.412     -1.256      0.209      -7.756       1.699
C(domain_grouped)[T.chemistry]       -0.3808      0.603     -0.632      0.527      -1.562       0.800
C(domain_grouped)[T.physics]          0.0785      0.622      0.126      0.900      -1.141       1.298
human_difficulty                      0.2101      0.259      0.811      0.418      -0.298       0.718
q_length                             -0.1308      0.249     -0.526      0.599      -0.618       0.357
avg_word_length                       0.0200      0.275      0.073      0.942      -0.519       0.559
percent_non_alphabetic_whitespace     0.0190      0.027      0.696      0.487      -0.035       0.073
capabilities_entropy                  2.1040      0.335      6.285      0.000       1.448       2.760
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  252
Model:                          Logit   Df Residuals:                      244
Method:                           MLE   Df Model:                            7
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.1432
Time:                        21:14:15   Log-Likelihood:                -141.70
converged:                       True   LL-Null:                       -165.38
Covariance Type:            nonrobust   LLR p-value:                 4.723e-08
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -2.4706      2.362     -1.046      0.296      -7.099       2.158
C(domain_grouped)[T.chemistry]       -0.0451      0.561     -0.080      0.936      -1.145       1.055
C(domain_grouped)[T.physics]          0.3963      0.575      0.689      0.491      -0.731       1.524
human_difficulty                      0.2073      0.254      0.816      0.415      -0.291       0.705
q_length                             -0.1503      0.238     -0.632      0.528      -0.617       0.316
avg_word_length                       0.0022      0.260      0.008      0.993      -0.506       0.511
percent_non_alphabetic_whitespace     0.0170      0.026      0.653      0.514      -0.034       0.068
game_entropy                          1.8253      0.305      5.982      0.000       1.227       2.423
=====================================================================================================

                  Model 4.95: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  252
Model:                          Logit   Df Residuals:                      243
Method:                           MLE   Df Model:                            8
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.1879
Time:                        21:14:15   Log-Likelihood:                -134.30
converged:                       True   LL-Null:                       -165.38
Covariance Type:            nonrobust   LLR p-value:                 1.753e-10
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -3.6236      2.449     -1.480      0.139      -8.423       1.176
C(domain_grouped)[T.chemistry]       -0.4194      0.598     -0.702      0.483      -1.591       0.752
C(domain_grouped)[T.physics]          0.1023      0.613      0.167      0.868      -1.100       1.304
human_difficulty                      0.2222      0.263      0.844      0.399      -0.294       0.738
q_length                             -0.1293      0.251     -0.515      0.606      -0.621       0.362
avg_word_length                       0.0719      0.274      0.262      0.793      -0.465       0.609
percent_non_alphabetic_whitespace     0.0250      0.027      0.915      0.360      -0.029       0.079
capabilities_entropy                  1.5135      0.407      3.717      0.000       0.716       2.312
game_entropy                          0.9234      0.380      2.432      0.015       0.179       1.668
=====================================================================================================

--- Analyzing claude-3-haiku-20240307 (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/claude-3-haiku-20240307_GPQA_redacted_cor_temp0.0_1751757100_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    99
1    37
Name: count, dtype: int64

Answer change%: 0.2721 [0.19726629981773552, 0.34685134724108796] (n=136)
P-value vs 25%: 0.5632; P-value vs 0%: 1.008e-12
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=37)
P-value vs 25%: 0; P-value vs 33%: 0

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  136
Model:                          Logit   Df Residuals:                      134
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                0.003839
Time:                        21:14:15   Log-Likelihood:                -79.295
converged:                       True   LL-Null:                       -79.600
Covariance Type:            nonrobust   LLR p-value:                    0.4344
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          0.0928      1.366      0.068      0.946      -2.584       2.769
p_i_capability    -1.1998      1.512     -0.793      0.427      -4.163       1.764
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  136
Model:                          Logit   Df Residuals:                      134
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                0.006125
Time:                        21:14:15   Log-Likelihood:                -79.113
converged:                       True   LL-Null:                       -79.600
Covariance Type:            nonrobust   LLR p-value:                    0.3234
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.3008      0.376     -3.461      0.001      -2.037      -0.564
capabilities_entropy     0.7000      0.698      1.003      0.316      -0.668       2.068
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.2162 [0.0836, 0.3489] (n=37)
                  P-value vs 33.3%: 0.08354

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  136
Model:                          Logit   Df Residuals:                      134
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:               0.0002636
Time:                        21:14:15   Log-Likelihood:                -79.579
converged:                       True   LL-Null:                       -79.600
Covariance Type:            nonrobust   LLR p-value:                    0.8377
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -1.1612      0.886     -1.310      0.190      -2.899       0.576
human_difficulty     0.0742      0.362      0.205      0.838      -0.635       0.784
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  136
Model:                          Logit   Df Residuals:                      129
Method:                           MLE   Df Model:                            6
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.06366
Time:                        21:14:15   Log-Likelihood:                -74.533
converged:                       True   LL-Null:                       -79.600
Covariance Type:            nonrobust   LLR p-value:                    0.1191
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -2.2950      2.747     -0.835      0.404      -7.680       3.090
C(domain_grouped)[T.chemistry]        1.7231      0.658      2.619      0.009       0.434       3.012
C(domain_grouped)[T.physics]          1.2626      0.671      1.881      0.060      -0.053       2.578
human_difficulty                      0.1589      0.374      0.424      0.671      -0.575       0.893
q_length                             -0.2847      0.358     -0.796      0.426      -0.986       0.416
avg_word_length                       0.3485      0.259      1.344      0.179      -0.160       0.857
percent_non_alphabetic_whitespace    -0.0338      0.036     -0.929      0.353      -0.105       0.037
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 0.4420
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  136
Model:                          Logit   Df Residuals:                      128
Method:                           MLE   Df Model:                            7
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.07822
Time:                        21:14:15   Log-Likelihood:                -73.374
converged:                       True   LL-Null:                       -79.600
Covariance Type:            nonrobust   LLR p-value:                   0.08663
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -2.9065      2.775     -1.047      0.295      -8.346       2.533
C(domain_grouped)[T.chemistry]        1.7898      0.666      2.689      0.007       0.485       3.094
C(domain_grouped)[T.physics]          1.3056      0.676      1.931      0.053      -0.020       2.631
human_difficulty                      0.2022      0.381      0.530      0.596      -0.545       0.949
q_length                             -0.3351      0.358     -0.935      0.350      -1.037       0.367
avg_word_length                       0.4067      0.265      1.536      0.125      -0.112       0.926
percent_non_alphabetic_whitespace    -0.0403      0.037     -1.079      0.281      -0.113       0.033
capabilities_entropy                  1.1749      0.763      1.539      0.124      -0.321       2.671
=====================================================================================================

--- Analyzing claude-3-haiku-20240307 (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/claude-3-haiku-20240307_GPQA_redacted_temp0.0_1754158953_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    238
1     57
Name: count, dtype: int64

Answer change%: 0.1932 [0.1481655486064766, 0.2382751293596251] (n=295)
P-value vs 25%: 0.01351; P-value vs 0%: 4.263e-17
Phase 2 self-accuracy: 0.2632 [0.14884214151558706, 0.3774736479580971] (n=57)
P-value vs 25%: 0.8215; P-value vs 33%: 0.2311

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  295
Model:                          Logit   Df Residuals:                      293
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.1160
Time:                        21:14:15   Log-Likelihood:                -128.01
converged:                       True   LL-Null:                       -144.80
Covariance Type:            nonrobust   LLR p-value:                 6.805e-09
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          3.1762      0.805      3.944      0.000       1.598       4.755
p_i_capability    -5.3179      0.931     -5.711      0.000      -7.143      -3.493
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  295
Model:                          Logit   Df Residuals:                      293
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.1405
Time:                        21:14:15   Log-Likelihood:                -124.46
converged:                       True   LL-Null:                       -144.80
Covariance Type:            nonrobust   LLR p-value:                 1.791e-10
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.9064      0.306     -9.507      0.000      -3.506      -2.307
capabilities_entropy     2.8476      0.465      6.129      0.000       1.937       3.758
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.4386 [0.3098, 0.5674] (n=57)
                  P-value vs 33.3%: 0.1093

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=-0.11, p=0.916
Wilcoxon delta_p: statistic=1719.00, p=0.409
Mean Δp = -0.0009  [-0.0172, 0.0154]
Idea 1 N = 238; 

  Idea 1.5: Calibration Metrics
  NLL: 4.2117, Signed ECE (overconf pos under neg): 0.0400, ECE: 0.0400 (n=295)
  Brier: 0.0110, Reliability (absolute calibration error; lower better): 0.0108, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=295)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.896
Model:                            OLS   Adj. R-squared:                  0.894
Method:                 Least Squares   F-statistic:                     831.8
Date:                Fri, 19 Sep 2025   Prob (F-statistic):          2.27e-142
Time:                        21:14:15   Log-Likelihood:                 262.11
No. Observations:                 295   AIC:                            -516.2
Df Residuals:                     291   BIC:                            -501.5
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.7563      0.054    -13.998      0.000      -0.863      -0.650
p1                    0.8219      0.058     14.084      0.000       0.707       0.937
answer_changed        0.7436      0.078      9.484      0.000       0.589       0.898
p1:answer_changed     0.0617      0.091      0.676      0.500      -0.118       0.241
==============================================================================
Omnibus:                       64.875   Durbin-Watson:                   1.936
Prob(Omnibus):                  0.000   Jarque-Bera (JB):              199.051
Skew:                           0.954   Prob(JB):                     5.98e-44
Kurtosis:                       6.543   Cond. No.                         31.3
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=2.25, p=0.0253
Wilcoxon delta_H: statistic=1417.50, p=0.0356
Mean ΔH = 0.0856  [0.0111, 0.1601]
Paired t-test delta_H Changed: statistic=6.66, p=1.28e-08
Wilcoxon delta_H Changed: statistic=179.00, p=2.65e-07
Mean ΔH Changed = 0.5699  [0.4021, 0.7378]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=1.28, p=0.202
Wilcoxon (p_top2_game vs p_top2_base): statistic=3725.00, p=0.0575
Mean Δp_top2 = 0.0025  [-0.0013, 0.0063] (n=295)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=4.90, p=1.55e-06
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=2810.50, p=1.54e-06
Mean ΔH_unchosen_baseline_set = 0.1792  [0.1076, 0.2508] (n=295)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  295
Model:                          Logit   Df Residuals:                      292
Method:                           MLE   Df Model:                            2
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.1285
Time:                        21:14:15   Log-Likelihood:                -126.20
converged:                       True   LL-Null:                       -144.80
Covariance Type:            nonrobust   LLR p-value:                 8.328e-09
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.2894      0.222     -5.802      0.000      -1.725      -0.854
p1_z            -1.4134      0.374     -3.778      0.000      -2.147      -0.680
I(p1_z ** 2)    -0.3189      0.167     -1.913      0.056      -0.646       0.008
================================================================================
AUC = 0.741

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  295
Model:                          Logit   Df Residuals:                      293
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.09078
Time:                        21:14:15   Log-Likelihood:                -131.66
converged:                       True   LL-Null:                       -144.80
Covariance Type:            nonrobust   LLR p-value:                 2.939e-07
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -2.7137      0.313     -8.680      0.000      -3.326      -2.101
game_entropy     2.5620      0.503      5.089      0.000       1.575       3.549
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=4529.00, p=0.893
Paired t-test (game_entropy vs capabilities_entropy): statistic=-0.16, p=0.873
Mean capabilities_entropy-game_entropy = 0.0033  [-0.0370, 0.0436] (n=295)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  295
Model:                          Logit   Df Residuals:                      292
Method:                           MLE   Df Model:                            2
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.2039
Time:                        21:14:15   Log-Likelihood:                -115.28
converged:                       True   LL-Null:                       -144.80
Covariance Type:            nonrobust   LLR p-value:                 1.501e-13
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -4.0098      0.441     -9.086      0.000      -4.875      -3.145
capabilities_entropy     2.7036      0.487      5.554      0.000       1.749       3.658
game_entropy             2.3242      0.538      4.319      0.000       1.270       3.379
========================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  295
Model:                          Logit   Df Residuals:                      293
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.01269
Time:                        21:14:15   Log-Likelihood:                -142.97
converged:                       True   LL-Null:                       -144.80
Covariance Type:            nonrobust   LLR p-value:                   0.05527
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -0.2853      0.613     -0.465      0.642      -1.487       0.916
human_difficulty    -0.4923      0.262     -1.881      0.060      -1.005       0.021
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  295
Model:                          Logit   Df Residuals:                      288
Method:                           MLE   Df Model:                            6
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.03493
Time:                        21:14:15   Log-Likelihood:                -139.74
converged:                       True   LL-Null:                       -144.80
Covariance Type:            nonrobust   LLR p-value:                    0.1198
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -1.1408      2.321     -0.492      0.623      -5.689       3.407
C(domain_grouped)[T.chemistry]        0.6781      0.548      1.238      0.216      -0.396       1.752
C(domain_grouped)[T.physics]          0.2172      0.566      0.383      0.701      -0.893       1.327
human_difficulty                     -0.4673      0.278     -1.680      0.093      -1.013       0.078
q_length                              0.3512      0.249      1.409      0.159      -0.137       0.840
avg_word_length                      -0.3698      0.290     -1.275      0.202      -0.938       0.199
percent_non_alphabetic_whitespace    -0.0036      0.027     -0.134      0.894      -0.057       0.050
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 0.4562
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  295
Model:                          Logit   Df Residuals:                      287
Method:                           MLE   Df Model:                            7
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.1598
Time:                        21:14:15   Log-Likelihood:                -121.67
converged:                       True   LL-Null:                       -144.80
Covariance Type:            nonrobust   LLR p-value:                 7.725e-08
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -2.7320      2.585     -1.057      0.291      -7.799       2.335
C(domain_grouped)[T.chemistry]        0.4916      0.580      0.847      0.397      -0.646       1.629
C(domain_grouped)[T.physics]          0.1451      0.605      0.240      0.811      -1.041       1.332
human_difficulty                     -0.4740      0.299     -1.583      0.114      -1.061       0.113
q_length                              0.3124      0.273      1.144      0.252      -0.223       0.847
avg_word_length                      -0.2402      0.317     -0.758      0.449      -0.861       0.381
percent_non_alphabetic_whitespace    -0.0091      0.030     -0.302      0.763      -0.069       0.050
capabilities_entropy                  2.7473      0.478      5.753      0.000       1.811       3.683
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  295
Model:                          Logit   Df Residuals:                      287
Method:                           MLE   Df Model:                            7
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.1181
Time:                        21:14:15   Log-Likelihood:                -127.70
converged:                       True   LL-Null:                       -144.80
Covariance Type:            nonrobust   LLR p-value:                 1.571e-05
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -2.8860      2.463     -1.172      0.241      -7.713       1.941
C(domain_grouped)[T.chemistry]        0.6304      0.563      1.119      0.263      -0.474       1.735
C(domain_grouped)[T.physics]          0.1193      0.587      0.203      0.839      -1.031       1.269
human_difficulty                     -0.3807      0.298     -1.276      0.202      -0.965       0.204
q_length                              0.4127      0.261      1.581      0.114      -0.099       0.924
avg_word_length                      -0.3518      0.302     -1.166      0.244      -0.943       0.240
percent_non_alphabetic_whitespace    -0.0155      0.028     -0.555      0.579      -0.070       0.039
game_entropy                          2.5382      0.525      4.835      0.000       1.509       3.567
=====================================================================================================

                  Model 4.95: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  295
Model:                          Logit   Df Residuals:                      286
Method:                           MLE   Df Model:                            8
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.2209
Time:                        21:14:15   Log-Likelihood:                -112.82
converged:                       True   LL-Null:                       -144.80
Covariance Type:            nonrobust   LLR p-value:                 7.702e-11
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -4.3852      2.679     -1.637      0.102      -9.635       0.865
C(domain_grouped)[T.chemistry]        0.4202      0.599      0.701      0.483      -0.754       1.594
C(domain_grouped)[T.physics]          0.0378      0.629      0.060      0.952      -1.195       1.270
human_difficulty                     -0.4127      0.317     -1.302      0.193      -1.034       0.209
q_length                              0.3660      0.278      1.317      0.188      -0.179       0.911
avg_word_length                      -0.1907      0.323     -0.590      0.555      -0.824       0.442
percent_non_alphabetic_whitespace    -0.0181      0.029     -0.620      0.536      -0.075       0.039
capabilities_entropy                  2.6347      0.499      5.275      0.000       1.656       3.614
game_entropy                          2.3412      0.559      4.188      0.000       1.245       3.437
=====================================================================================================

--- Analyzing claude-3-sonnet-20240229 (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/claude-3-sonnet-20240229_GPQA_redacted_cor_temp0.0_1751757247_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    113
1     33
Name: count, dtype: int64

Answer change%: 0.2260 [0.1581828421354376, 0.2938719523851103] (n=146)
P-value vs 25%: 0.4886; P-value vs 0%: 6.59e-11
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=33)
P-value vs 25%: 0; P-value vs 33%: 0

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  146
Model:                          Logit   Df Residuals:                      144
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:               0.0002159
Time:                        21:14:15   Log-Likelihood:                -78.010
converged:                       True   LL-Null:                       -78.027
Covariance Type:            nonrobust   LLR p-value:                    0.8544
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -1.0829      0.829     -1.306      0.191      -2.708       0.542
human_difficulty    -0.0626      0.341     -0.183      0.855      -0.732       0.606
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  146
Model:                          Logit   Df Residuals:                      139
Method:                           MLE   Df Model:                            6
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.04736
Time:                        21:14:15   Log-Likelihood:                -74.332
converged:                       True   LL-Null:                       -78.027
Covariance Type:            nonrobust   LLR p-value:                    0.2863
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -0.5137      3.069     -0.167      0.867      -6.529       5.502
C(domain_grouped)[T.chemistry]        1.3167      0.618      2.129      0.033       0.104       2.529
C(domain_grouped)[T.physics]          0.7130      0.659      1.081      0.279      -0.579       2.005
human_difficulty                      0.0405      0.363      0.112      0.911      -0.670       0.751
q_length                             -0.3611      0.376     -0.961      0.336      -1.097       0.375
avg_word_length                       0.1496      0.360      0.416      0.678      -0.556       0.855
percent_non_alphabetic_whitespace    -0.0228      0.038     -0.595      0.552      -0.098       0.052
=====================================================================================================

--- Analyzing claude-3-sonnet-20240229 (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/claude-3-sonnet-20240229_GPQA_redacted_temp0.0_1751717405_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    217
1     84
Name: count, dtype: int64

Answer change%: 0.2791 [0.228397789428773, 0.32974174545494794] (n=301)
P-value vs 25%: 0.2608; P-value vs 0%: 3.664e-27
Phase 2 self-accuracy: 0.3333 [0.23252366379347328, 0.43414300287319335] (n=84)
P-value vs 25%: 0.1052; P-value vs 33%: 0.9948

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  301
Model:                          Logit   Df Residuals:                      299
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:               1.628e-05
Time:                        21:14:15   Log-Likelihood:                -178.21
converged:                       True   LL-Null:                       -178.21
Covariance Type:            nonrobust   LLR p-value:                    0.9393
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -0.9899      0.551     -1.796      0.072      -2.070       0.090
human_difficulty     0.0172      0.226      0.076      0.939      -0.425       0.460
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  301
Model:                          Logit   Df Residuals:                      294
Method:                           MLE   Df Model:                            6
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                0.009757
Time:                        21:14:15   Log-Likelihood:                -176.48
converged:                       True   LL-Null:                       -178.21
Covariance Type:            nonrobust   LLR p-value:                    0.7469
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -0.1034      1.945     -0.053      0.958      -3.916       3.709
C(domain_grouped)[T.chemistry]        0.1243      0.444      0.280      0.779      -0.745       0.994
C(domain_grouped)[T.physics]          0.0169      0.446      0.038      0.970      -0.858       0.892
human_difficulty                      0.0133      0.234      0.057      0.955      -0.446       0.473
q_length                              0.1372      0.206      0.667      0.505      -0.266       0.541
avg_word_length                      -0.3292      0.230     -1.429      0.153      -0.781       0.122
percent_non_alphabetic_whitespace    -0.0285      0.025     -1.127      0.260      -0.078       0.021
=====================================================================================================

--- Analyzing claude-sonnet-4-20250514 (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/claude-sonnet-4-20250514_GPQA_redacted_cor_temp0.0_1751759117_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    201
1     57
Name: count, dtype: int64

Answer change%: 0.2209 [0.1703065203425982, 0.2715539447736809] (n=258)
P-value vs 25%: 0.2604; P-value vs 0%: 1.193e-17
Phase 2 self-accuracy: 0.0702 [0.003861665647464513, 0.13648921154551794] (n=57)
P-value vs 25%: 1.067e-07; P-value vs 33%: 7.972e-15

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  258
Model:                          Logit   Df Residuals:                      256
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:               0.0006185
Time:                        21:14:15   Log-Likelihood:                -136.16
converged:                       True   LL-Null:                       -136.25
Covariance Type:            nonrobust   LLR p-value:                    0.6814
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -1.5089      0.626     -2.412      0.016      -2.735      -0.283
human_difficulty     0.1053      0.256      0.411      0.681      -0.397       0.607
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  258
Model:                          Logit   Df Residuals:                      251
Method:                           MLE   Df Model:                            6
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.04056
Time:                        21:14:15   Log-Likelihood:                -130.72
converged:                       True   LL-Null:                       -136.25
Covariance Type:            nonrobust   LLR p-value:                   0.08680
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -5.1356      2.232     -2.301      0.021      -9.510      -0.761
C(domain_grouped)[T.chemistry]        0.3862      0.471      0.820      0.412      -0.537       1.309
C(domain_grouped)[T.physics]          0.0263      0.472      0.056      0.956      -0.900       0.952
human_difficulty                      0.0137      0.276      0.050      0.960      -0.527       0.555
q_length                              0.8150      0.278      2.931      0.003       0.270       1.360
avg_word_length                      -0.2420      0.256     -0.944      0.345      -0.744       0.260
percent_non_alphabetic_whitespace    -0.0082      0.028     -0.293      0.770      -0.063       0.047
=====================================================================================================

--- Analyzing claude-sonnet-4-20250514 (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/claude-sonnet-4-20250514_GPQA_redacted_temp0.0_1751718415_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    101
1     88
Name: count, dtype: int64

Answer change%: 0.4656 [0.3944940889380143, 0.5367228422789169] (n=189)
P-value vs 25%: 2.81e-09; P-value vs 0%: 1.078e-37
Phase 2 self-accuracy: 0.4545 [0.35051159823461064, 0.5585793108562984] (n=88)
P-value vs 25%: 0.0001164; P-value vs 33%: 0.02203

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  189
Model:                          Logit   Df Residuals:                      187
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.01636
Time:                        21:14:15   Log-Likelihood:                -128.42
converged:                       True   LL-Null:                       -130.56
Covariance Type:            nonrobust   LLR p-value:                   0.03875
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept            1.1797      0.663      1.779      0.075      -0.120       2.480
human_difficulty    -0.5516      0.272     -2.030      0.042      -1.084      -0.019
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  189
Model:                          Logit   Df Residuals:                      182
Method:                           MLE   Df Model:                            6
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.02865
Time:                        21:14:15   Log-Likelihood:                -126.82
converged:                       True   LL-Null:                       -130.56
Covariance Type:            nonrobust   LLR p-value:                    0.2788
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                             3.8732      2.421      1.600      0.110      -0.872       8.619
C(domain_grouped)[T.chemistry]        0.0007      0.495      0.001      0.999      -0.970       0.972
C(domain_grouped)[T.physics]         -0.2515      0.520     -0.484      0.629      -1.271       0.768
human_difficulty                     -0.5435      0.282     -1.927      0.054      -1.096       0.009
q_length                             -0.2824      0.241     -1.173      0.241      -0.754       0.189
avg_word_length                      -0.1313      0.259     -0.507      0.612      -0.639       0.377
percent_non_alphabetic_whitespace    -0.0395      0.029     -1.353      0.176      -0.097       0.018
=====================================================================================================

--- Analyzing deepseek-chat (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/deepseek-chat_GPQA_redacted_cor_temp0.0_1753813587_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    184
1     23
Name: count, dtype: int64

Answer change%: 0.1111 [0.0682991223890767, 0.1539230998331455] (n=207)
P-value vs 25%: 2.038e-10; P-value vs 0%: 3.643e-07
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=23)
P-value vs 25%: 0; P-value vs 33%: 0

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  207
Model:                          Logit   Df Residuals:                      205
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.03282
Time:                        21:14:15   Log-Likelihood:                -69.839
converged:                       True   LL-Null:                       -72.208
Covariance Type:            nonrobust   LLR p-value:                   0.02948
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept         -0.1072      0.871     -0.123      0.902      -1.814       1.599
p_i_capability    -2.3972      1.066     -2.248      0.025      -4.487      -0.307
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  207
Model:                          Logit   Df Residuals:                      205
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.05213
Time:                        21:14:15   Log-Likelihood:                -68.444
converged:                       True   LL-Null:                       -72.208
Covariance Type:            nonrobust   LLR p-value:                  0.006072
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.7599      0.371     -7.439      0.000      -3.487      -2.033
capabilities_entropy     1.0446      0.378      2.760      0.006       0.303       1.786
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.2174 [0.0488, 0.3860] (n=23)
                  P-value vs 33.3%: 0.1776

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=18.80, p=2.47e-44
Wilcoxon delta_p: statistic=757.00, p=3.15e-26
Mean Δp = 0.6061  [0.5429, 0.6692]
Idea 1 N = 181; 

  Idea 1.5: Calibration Metrics
  NLL: 4.3205, Signed ECE (overconf pos under neg): -0.4360, ECE: 0.5249 (n=180)
  Brier: 0.5463, Reliability (absolute calibration error; lower better): 0.3652, Resolution (relative calibration quality; higher better): 0.0182, Uncertainty: 0.1981 (n=180)
  AUROC: 0.4183

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.147
Model:                            OLS   Adj. R-squared:                  0.134
Method:                 Least Squares   F-statistic:                     11.47
Date:                Fri, 19 Sep 2025   Prob (F-statistic):           5.67e-07
Time:                        21:14:15   Log-Likelihood:                -101.01
No. Observations:                 204   AIC:                             210.0
Df Residuals:                     200   BIC:                             223.3
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.2063      0.147     -1.399      0.163      -0.497       0.084
p1                    0.9410      0.167      5.625      0.000       0.611       1.271
answer_changed        0.3124      0.394      0.794      0.428      -0.464       1.088
p1:answer_changed    -0.4384      0.489     -0.897      0.371      -1.403       0.526
==============================================================================
Omnibus:                       39.719   Durbin-Watson:                   1.915
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               43.675
Skew:                          -1.073   Prob(JB):                     3.28e-10
Kurtosis:                       2.268   Cond. No.                         29.8
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=5.69, p=5.01e-08
Wilcoxon delta_H: statistic=4498.00, p=1.89e-07
Mean ΔH = 0.3226  [0.2115, 0.4337]
Paired t-test delta_H Changed: statistic=1.89, p=0.0727
Wilcoxon delta_H Changed: statistic=77.00, p=0.065
Mean ΔH Changed = 0.3001  [-0.0119, 0.6122]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=4.27, p=3.02e-05
Wilcoxon (p_top2_game vs p_top2_base): statistic=10327.00, p=0.879
Mean Δp_top2 = 0.0277  [0.0150, 0.0404] (n=204)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=6.01, p=8.51e-09
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=5713.00, p=3.08e-08
Mean ΔH_unchosen_baseline_set = 0.3201  [0.2157, 0.4245] (n=204)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  204
Model:                          Logit   Df Residuals:                      201
Method:                           MLE   Df Model:                            2
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.05808
Time:                        21:14:15   Log-Likelihood:                -67.679
converged:                       True   LL-Null:                       -71.852
Covariance Type:            nonrobust   LLR p-value:                   0.01541
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.7979      0.287     -6.262      0.000      -2.361      -1.235
p1_z            -1.0331      0.380     -2.719      0.007      -1.778      -0.288
I(p1_z ** 2)    -0.4270      0.231     -1.846      0.065      -0.880       0.026
================================================================================
AUC = 0.698

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  207
Model:                          Logit   Df Residuals:                      205
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.04618
Time:                        21:14:15   Log-Likelihood:                -68.874
converged:                       True   LL-Null:                       -72.208
Covariance Type:            nonrobust   LLR p-value:                  0.009813
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -3.0370      0.446     -6.811      0.000      -3.911      -2.163
game_entropy     2.1765      0.793      2.745      0.006       0.623       3.730
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=9199.00, p=0.0697
Paired t-test (game_entropy vs capabilities_entropy): statistic=-3.63, p=0.000353
Mean capabilities_entropy-game_entropy = 0.1293  [0.0596, 0.1991] (n=207)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  207
Model:                          Logit   Df Residuals:                      204
Method:                           MLE   Df Model:                            2
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.07225
Time:                        21:14:15   Log-Likelihood:                -66.992
converged:                       True   LL-Null:                       -72.208
Covariance Type:            nonrobust   LLR p-value:                  0.005425
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -3.2670      0.479     -6.816      0.000      -4.206      -2.328
capabilities_entropy     0.8049      0.410      1.964      0.050       0.002       1.608
game_entropy             1.5166      0.864      1.756      0.079      -0.176       3.209
========================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  207
Model:                          Logit   Df Residuals:                      205
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                0.003904
Time:                        21:14:15   Log-Likelihood:                -71.926
converged:                       True   LL-Null:                       -72.208
Covariance Type:            nonrobust   LLR p-value:                    0.4528
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -1.4011      0.923     -1.517      0.129      -3.211       0.409
human_difficulty    -0.2893      0.388     -0.745      0.456      -1.051       0.472
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  207
Model:                          Logit   Df Residuals:                      200
Method:                           MLE   Df Model:                            6
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.06871
Time:                        21:14:15   Log-Likelihood:                -67.247
converged:                       True   LL-Null:                       -72.208
Covariance Type:            nonrobust   LLR p-value:                    0.1280
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -4.9333      3.648     -1.352      0.176     -12.084       2.217
C(domain_grouped)[T.chemistry]        1.7070      0.739      2.310      0.021       0.259       3.155
C(domain_grouped)[T.physics]          0.4430      0.776      0.571      0.568      -1.078       1.964
human_difficulty                     -0.1444      0.409     -0.353      0.724      -0.947       0.658
q_length                              0.5271      0.390      1.352      0.176      -0.237       1.291
avg_word_length                      -0.1134      0.434     -0.261      0.794      -0.965       0.738
percent_non_alphabetic_whitespace    -0.0371      0.046     -0.801      0.423      -0.128       0.054
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 0.5263
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  207
Model:                          Logit   Df Residuals:                      199
Method:                           MLE   Df Model:                            7
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.1058
Time:                        21:14:15   Log-Likelihood:                -64.570
converged:                       True   LL-Null:                       -72.208
Covariance Type:            nonrobust   LLR p-value:                   0.03261
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -4.8318      3.737     -1.293      0.196     -12.156       2.492
C(domain_grouped)[T.chemistry]        1.4459      0.760      1.903      0.057      -0.044       2.935
C(domain_grouped)[T.physics]          0.3041      0.804      0.378      0.705      -1.271       1.879
human_difficulty                     -0.1663      0.421     -0.395      0.693      -0.991       0.659
q_length                              0.4358      0.382      1.142      0.254      -0.312       1.184
avg_word_length                      -0.0999      0.439     -0.228      0.820      -0.960       0.760
percent_non_alphabetic_whitespace    -0.0399      0.047     -0.857      0.391      -0.131       0.051
capabilities_entropy                  0.9478      0.407      2.331      0.020       0.151       1.745
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  207
Model:                          Logit   Df Residuals:                      199
Method:                           MLE   Df Model:                            7
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.1047
Time:                        21:14:15   Log-Likelihood:                -64.646
converged:                       True   LL-Null:                       -72.208
Covariance Type:            nonrobust   LLR p-value:                   0.03443
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -5.5144      3.796     -1.453      0.146     -12.955       1.926
C(domain_grouped)[T.chemistry]        1.5191      0.753      2.018      0.044       0.044       2.994
C(domain_grouped)[T.physics]          0.2395      0.799      0.300      0.764      -1.327       1.806
human_difficulty                     -0.1708      0.416     -0.410      0.682      -0.987       0.645
q_length                              0.4805      0.394      1.218      0.223      -0.293       1.254
avg_word_length                      -0.0682      0.454     -0.150      0.881      -0.959       0.822
percent_non_alphabetic_whitespace    -0.0378      0.049     -0.777      0.437      -0.133       0.058
game_entropy                          1.9766      0.830      2.380      0.017       0.349       3.604
=====================================================================================================

                  Model 4.95: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  207
Model:                          Logit   Df Residuals:                      198
Method:                           MLE   Df Model:                            8
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.1220
Time:                        21:14:15   Log-Likelihood:                -63.398
converged:                       True   LL-Null:                       -72.208
Covariance Type:            nonrobust   LLR p-value:                   0.02426
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -5.2531      3.823     -1.374      0.169     -12.746       2.240
C(domain_grouped)[T.chemistry]        1.3507      0.766      1.763      0.078      -0.151       2.853
C(domain_grouped)[T.physics]          0.1538      0.818      0.188      0.851      -1.449       1.756
human_difficulty                     -0.1718      0.424     -0.405      0.685      -1.003       0.659
q_length                              0.4157      0.389      1.070      0.285      -0.346       1.177
avg_word_length                      -0.0655      0.452     -0.145      0.885      -0.951       0.820
percent_non_alphabetic_whitespace    -0.0368      0.048     -0.765      0.444      -0.131       0.057
capabilities_entropy                  0.7048      0.441      1.598      0.110      -0.160       1.569
game_entropy                          1.4206      0.906      1.568      0.117      -0.355       3.196
=====================================================================================================

--- Analyzing deepseek-chat (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/deepseek-chat_GPQA_redacted_temp0.0_1753995526_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    188
1     47
Name: count, dtype: int64

Answer change%: 0.2000 [0.1488584188284336, 0.25114158117156643] (n=235)
P-value vs 25%: 0.05534; P-value vs 0%: 1.79e-14
Phase 2 self-accuracy: 0.5208 [0.37950795482256594, 0.6621587118441008] (n=48)
P-value vs 25%: 0.0001726; P-value vs 33%: 0.009189

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  235
Model:                          Logit   Df Residuals:                      233
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                0.009179
Time:                        21:14:15   Log-Likelihood:                -116.52
converged:                       True   LL-Null:                       -117.59
Covariance Type:            nonrobust   LLR p-value:                    0.1418
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept         -0.5075      0.609     -0.834      0.404      -1.701       0.686
p_i_capability    -1.1804      0.803     -1.470      0.141      -2.754       0.393
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  235
Model:                          Logit   Df Residuals:                      233
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.01420
Time:                        21:14:15   Log-Likelihood:                -115.92
converged:                       True   LL-Null:                       -117.59
Covariance Type:            nonrobust   LLR p-value:                   0.06759
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.8517      0.318     -5.824      0.000      -2.475      -1.229
capabilities_entropy     0.5265      0.291      1.808      0.071      -0.044       1.097
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.3404 [0.2050, 0.4759] (n=47)
                  P-value vs 33.3%: 0.9183

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=12.86, p=1.6e-27
Wilcoxon delta_p: statistic=1945.00, p=1.59e-20
Mean Δp = 0.4439  [0.3763, 0.5116]
Idea 1 N = 188; 

  Idea 1.5: Calibration Metrics
  NLL: 3.1653, Signed ECE (overconf pos under neg): 0.0637, ECE: 0.2757 (n=219)
  Brier: 0.2782, Reliability (absolute calibration error; lower better): 0.1358, Resolution (relative calibration quality; higher better): 0.0076, Uncertainty: 0.1493 (n=219)
  AUROC: 0.4169

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.212
Model:                            OLS   Adj. R-squared:                  0.202
Method:                 Least Squares   F-statistic:                     20.72
Date:                Fri, 19 Sep 2025   Prob (F-statistic):           6.30e-12
Time:                        21:14:15   Log-Likelihood:                -123.81
No. Observations:                 235   AIC:                             255.6
Df Residuals:                     231   BIC:                             269.5
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.2987      0.118     -2.537      0.012      -0.531      -0.067
p1                    0.9663      0.148      6.525      0.000       0.675       1.258
answer_changed       -0.2044      0.268     -0.763      0.446      -0.732       0.323
p1:answer_changed     0.4345      0.356      1.222      0.223      -0.266       1.135
==============================================================================
Omnibus:                      167.494   Durbin-Watson:                   2.103
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               39.148
Skew:                          -0.785   Prob(JB):                     3.16e-09
Kurtosis:                       1.761   Cond. No.                         21.5
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=5.78, p=3.09e-08
Wilcoxon delta_H: statistic=4722.00, p=4.08e-08
Mean ΔH = 0.3120  [0.2062, 0.4178]
Paired t-test delta_H Changed: statistic=5.90, p=4.14e-07
Wilcoxon delta_H Changed: statistic=123.00, p=5.08e-06
Mean ΔH Changed = 0.4175  [0.2787, 0.5562]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=8.34, p=6.54e-15
Wilcoxon (p_top2_game vs p_top2_base): statistic=7663.00, p=2.77e-09
Mean Δp_top2 = 0.0575  [0.0440, 0.0710] (n=235)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=7.33, p=3.84e-12
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=6583.00, p=7.8e-12
Mean ΔH_unchosen_baseline_set = 0.3331  [0.2440, 0.4222] (n=235)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  235
Model:                          Logit   Df Residuals:                      232
Method:                           MLE   Df Model:                            2
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.02107
Time:                        21:14:15   Log-Likelihood:                -115.12
converged:                       True   LL-Null:                       -117.59
Covariance Type:            nonrobust   LLR p-value:                   0.08389
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.0909      0.244     -4.471      0.000      -1.569      -0.613
p1_z            -0.3796      0.193     -1.971      0.049      -0.757      -0.002
I(p1_z ** 2)    -0.3383      0.207     -1.634      0.102      -0.744       0.067
================================================================================
AUC = 0.607

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  235
Model:                          Logit   Df Residuals:                      233
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.1012
Time:                        21:14:15   Log-Likelihood:                -105.70
converged:                       True   LL-Null:                       -117.59
Covariance Type:            nonrobust   LLR p-value:                 1.072e-06
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -2.7620      0.355     -7.785      0.000      -3.457      -2.067
game_entropy     2.7216      0.574      4.745      0.000       1.597       3.846
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=5539.00, p=1.45e-15
Paired t-test (game_entropy vs capabilities_entropy): statistic=-9.89, p=1.66e-19
Mean capabilities_entropy-game_entropy = 0.3755  [0.3011, 0.4498] (n=235)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  235
Model:                          Logit   Df Residuals:                      232
Method:                           MLE   Df Model:                            2
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.1044
Time:                        21:14:15   Log-Likelihood:                -105.32
converged:                       True   LL-Null:                       -117.59
Covariance Type:            nonrobust   LLR p-value:                 4.655e-06
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.9490      0.423     -6.974      0.000      -3.778      -2.120
capabilities_entropy     0.2738      0.315      0.870      0.384      -0.343       0.890
game_entropy             2.6131      0.583      4.482      0.000       1.470       3.756
========================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  235
Model:                          Logit   Df Residuals:                      233
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.01669
Time:                        21:14:15   Log-Likelihood:                -115.63
converged:                       True   LL-Null:                       -117.59
Covariance Type:            nonrobust   LLR p-value:                   0.04754
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -0.0204      0.711     -0.029      0.977      -1.413       1.372
human_difficulty    -0.5937      0.308     -1.930      0.054      -1.197       0.009
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  235
Model:                          Logit   Df Residuals:                      228
Method:                           MLE   Df Model:                            6
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.04311
Time:                        21:14:15   Log-Likelihood:                -112.53
converged:                       True   LL-Null:                       -117.59
Covariance Type:            nonrobust   LLR p-value:                    0.1189
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                             0.3232      2.296      0.141      0.888      -4.176       4.822
C(domain_grouped)[T.chemistry]       -0.0690      0.536     -0.129      0.898      -1.120       0.982
C(domain_grouped)[T.physics]         -0.4139      0.583     -0.709      0.478      -1.558       0.730
human_difficulty                     -0.7614      0.328     -2.320      0.020      -1.405      -0.118
q_length                              0.0461      0.273      0.169      0.866      -0.489       0.581
avg_word_length                       0.0903      0.243      0.371      0.710      -0.386       0.566
percent_non_alphabetic_whitespace    -0.0600      0.037     -1.625      0.104      -0.132       0.012
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 0.8326
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  235
Model:                          Logit   Df Residuals:                      227
Method:                           MLE   Df Model:                            7
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.06462
Time:                        21:14:15   Log-Likelihood:                -110.00
converged:                       True   LL-Null:                       -117.59
Covariance Type:            nonrobust   LLR p-value:                   0.03353
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                             0.5623      2.289      0.246      0.806      -3.923       5.048
C(domain_grouped)[T.chemistry]       -0.2248      0.556     -0.404      0.686      -1.315       0.865
C(domain_grouped)[T.physics]         -0.5206      0.604     -0.862      0.389      -1.705       0.663
human_difficulty                     -0.7768      0.332     -2.339      0.019      -1.428      -0.126
q_length                             -0.0513      0.279     -0.184      0.854      -0.599       0.496
avg_word_length                       0.0842      0.240      0.351      0.725      -0.385       0.554
percent_non_alphabetic_whitespace    -0.0723      0.038     -1.899      0.058      -0.147       0.002
capabilities_entropy                  0.6926      0.313      2.213      0.027       0.079       1.306
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  235
Model:                          Logit   Df Residuals:                      227
Method:                           MLE   Df Model:                            7
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.1443
Time:                        21:14:15   Log-Likelihood:                -100.62
converged:                       True   LL-Null:                       -117.59
Covariance Type:            nonrobust   LLR p-value:                 1.763e-05
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                             0.2631      2.377      0.111      0.912      -4.395       4.921
C(domain_grouped)[T.chemistry]       -0.5477      0.572     -0.957      0.339      -1.670       0.574
C(domain_grouped)[T.physics]         -0.7847      0.614     -1.277      0.201      -1.989       0.419
human_difficulty                     -0.7880      0.351     -2.245      0.025      -1.476      -0.100
q_length                             -0.0855      0.297     -0.288      0.773      -0.667       0.496
avg_word_length                       0.0534      0.246      0.217      0.828      -0.429       0.536
percent_non_alphabetic_whitespace    -0.0599      0.040     -1.501      0.133      -0.138       0.018
game_entropy                          2.8427      0.603      4.715      0.000       1.661       4.024
=====================================================================================================

                  Model 4.95: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  235
Model:                          Logit   Df Residuals:                      226
Method:                           MLE   Df Model:                            8
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.1521
Time:                        21:14:15   Log-Likelihood:                -99.707
converged:                       True   LL-Null:                       -117.59
Covariance Type:            nonrobust   LLR p-value:                 1.930e-05
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                             0.4750      2.407      0.197      0.844      -4.243       5.193
C(domain_grouped)[T.chemistry]       -0.6190      0.582     -1.063      0.288      -1.760       0.522
C(domain_grouped)[T.physics]         -0.8498      0.627     -1.356      0.175      -2.078       0.379
human_difficulty                     -0.7903      0.352     -2.245      0.025      -1.480      -0.100
q_length                             -0.1404      0.302     -0.465      0.642      -0.732       0.451
avg_word_length                       0.0364      0.248      0.147      0.883      -0.449       0.522
percent_non_alphabetic_whitespace    -0.0685      0.041     -1.681      0.093      -0.148       0.011
capabilities_entropy                  0.4528      0.337      1.345      0.179      -0.207       1.113
game_entropy                          2.6983      0.610      4.421      0.000       1.502       3.895
=====================================================================================================

--- Analyzing gemini-1.5-pro (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/gemini-1.5-pro_GPQA_redacted_cor_temp0.0_1751757449_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    182
1     19
Name: count, dtype: int64

Answer change%: 0.0945 [0.05408220862790201, 0.1349725177402572] (n=201)
P-value vs 25%: 4.914e-14; P-value vs 0%: 4.633e-06
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=19)
P-value vs 25%: 0; P-value vs 33%: 0

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  201
Model:                          Logit   Df Residuals:                      199
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                0.006038
Time:                        21:14:15   Log-Likelihood:                -62.511
converged:                       True   LL-Null:                       -62.891
Covariance Type:            nonrobust   LLR p-value:                    0.3835
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -3.1667      1.088     -2.909      0.004      -5.300      -1.033
human_difficulty     0.3770      0.433      0.871      0.383      -0.471       1.225
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  201
Model:                          Logit   Df Residuals:                      194
Method:                           MLE   Df Model:                            6
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.02890
Time:                        21:14:15   Log-Likelihood:                -61.073
converged:                       True   LL-Null:                       -62.891
Covariance Type:            nonrobust   LLR p-value:                    0.7259
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -4.4739      3.446     -1.298      0.194     -11.228       2.281
C(domain_grouped)[T.chemistry]        0.8927      0.716      1.247      0.212      -0.510       2.295
C(domain_grouped)[T.physics]          0.0635      0.739      0.086      0.932      -1.386       1.513
human_difficulty                      0.4115      0.449      0.916      0.359      -0.469       1.292
q_length                              0.2464      0.392      0.628      0.530      -0.522       1.015
avg_word_length                      -0.0760      0.400     -0.190      0.850      -0.861       0.709
percent_non_alphabetic_whitespace    -0.0318      0.051     -0.627      0.531      -0.131       0.068
=====================================================================================================

--- Analyzing gemini-1.5-pro (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/gemini-1.5-pro_GPQA_redacted_temp0.0_1751722268_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    187
1     59
Name: count, dtype: int64

Answer change%: 0.2398 [0.1864802956528626, 0.2931945010951049] (n=246)
P-value vs 25%: 0.7089; P-value vs 0%: 1.252e-18
Phase 2 self-accuracy: 0.5085 [0.3809101148274585, 0.6360390377149143] (n=59)
P-value vs 25%: 7.147e-05; P-value vs 33%: 0.007016

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  246
Model:                          Logit   Df Residuals:                      244
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:               1.592e-05
Time:                        21:14:15   Log-Likelihood:                -135.52
converged:                       True   LL-Null:                       -135.52
Covariance Type:            nonrobust   LLR p-value:                    0.9476
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -1.1138      0.624     -1.786      0.074      -2.336       0.108
human_difficulty    -0.0167      0.255     -0.066      0.948      -0.516       0.482
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  246
Model:                          Logit   Df Residuals:                      239
Method:                           MLE   Df Model:                            6
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.01409
Time:                        21:14:15   Log-Likelihood:                -133.61
converged:                       True   LL-Null:                       -135.52
Covariance Type:            nonrobust   LLR p-value:                    0.7010
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                             1.7876      2.380      0.751      0.453      -2.877       6.452
C(domain_grouped)[T.chemistry]       -0.6503      0.491     -1.326      0.185      -1.612       0.311
C(domain_grouped)[T.physics]         -0.4937      0.502     -0.983      0.326      -1.478       0.491
human_difficulty                     -0.0087      0.266     -0.033      0.974      -0.531       0.514
q_length                             -0.0929      0.249     -0.373      0.709      -0.581       0.396
avg_word_length                      -0.3909      0.273     -1.433      0.152      -0.926       0.144
percent_non_alphabetic_whitespace    -0.0102      0.029     -0.352      0.725      -0.067       0.047
=====================================================================================================

--- Analyzing gemini-2.0-flash-001 (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/gemini-2.0-flash-001_GPQA_redacted_cor_temp1.0_1757989025_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    171
1     44
Name: count, dtype: int64

Answer change%: 0.2047 [0.15072310313071696, 0.2585792224506784] (n=215)
P-value vs 25%: 0.09932; P-value vs 0%: 1.023e-13
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=44)
P-value vs 25%: 0; P-value vs 33%: 0

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  215
Model:                          Logit   Df Residuals:                      213
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.06922
Time:                        21:14:15   Log-Likelihood:                -101.42
converged:                       True   LL-Null:                       -108.96
Covariance Type:            nonrobust   LLR p-value:                 0.0001028
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          3.3750      1.266      2.666      0.008       0.894       5.856
p_i_capability    -5.0497      1.346     -3.751      0.000      -7.688      -2.411
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  215
Model:                          Logit   Df Residuals:                      213
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.1085
Time:                        21:14:15   Log-Likelihood:                -97.140
converged:                       True   LL-Null:                       -108.96
Covariance Type:            nonrobust   LLR p-value:                 1.164e-06
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.8665      0.220     -8.485      0.000      -2.298      -1.435
capabilities_entropy     2.1548      0.464      4.642      0.000       1.245       3.065
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.5526 [0.3945, 0.7107] (n=38)
                  P-value vs 33.3%: 0.006552

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=4.02, p=0.000143
Wilcoxon delta_p: statistic=574.00, p=3.29e-05
Mean Δp = 0.0799  [0.0410, 0.1189]
Idea 1 N = 72; 

  Idea 1.5: Calibration Metrics
  NLL: 0.2213, Signed ECE (overconf pos under neg): -0.1305, ECE: 0.1305 (n=110)
  Brier: 0.0697, Reliability (absolute calibration error; lower better): 0.0690, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=110)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.686
Model:                            OLS   Adj. R-squared:                  0.677
Method:                 Least Squares   F-statistic:                     77.24
Date:                Fri, 19 Sep 2025   Prob (F-statistic):           1.47e-26
Time:                        21:14:15   Log-Likelihood:                 22.890
No. Observations:                 110   AIC:                            -37.78
Df Residuals:                     106   BIC:                            -26.98
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.1034      0.161     -0.641      0.523      -0.423       0.217
p1                    0.1979      0.172      1.148      0.254      -0.144       0.540
answer_changed       -0.5310      0.246     -2.157      0.033      -1.019      -0.043
p1:answer_changed     1.2446      0.272      4.582      0.000       0.706       1.783
==============================================================================
Omnibus:                        2.084   Durbin-Watson:                   1.849
Prob(Omnibus):                  0.353   Jarque-Bera (JB):                1.613
Skew:                          -0.130   Prob(JB):                        0.446
Kurtosis:                       3.533   Cond. No.                         30.5
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-1.48, p=0.143
Wilcoxon delta_H: statistic=1104.00, p=0.239
Mean ΔH = -0.1037  [-0.2411, 0.0336]
Paired t-test delta_H Changed: statistic=1.41, p=0.168
Wilcoxon delta_H Changed: statistic=297.00, p=0.293
Mean ΔH Changed = 0.1196  [-0.0470, 0.2862]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=-4.50, p=1.68e-05
Wilcoxon (p_top2_game vs p_top2_base): statistic=1058.00, p=2.71e-09
Mean Δp_top2 = -0.0262  [-0.0376, -0.0148] (n=110)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=-0.48, p=0.631
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=2917.00, p=0.686
Mean ΔH_unchosen_baseline_set = -0.0266  [-0.1347, 0.0816] (n=110)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  110
Model:                          Logit   Df Residuals:                      107
Method:                           MLE   Df Model:                            2
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.04630
Time:                        21:14:15   Log-Likelihood:                -67.622
converged:                       True   LL-Null:                       -70.905
Covariance Type:            nonrobust   LLR p-value:                   0.03753
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.3520      0.269     -1.310      0.190      -0.879       0.175
p1_z            -0.9533      0.394     -2.422      0.015      -1.725      -0.182
I(p1_z ** 2)    -0.3198      0.188     -1.698      0.090      -0.689       0.049
================================================================================
AUC = 0.652

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  215
Model:                          Logit   Df Residuals:                      213
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.1850
Time:                        21:14:15   Log-Likelihood:                -88.800
converged:                       True   LL-Null:                       -108.96
Covariance Type:            nonrobust   LLR p-value:                 2.159e-10
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -2.3508      0.279     -8.435      0.000      -2.897      -1.805
game_entropy     2.0255      0.342      5.919      0.000       1.355       2.696
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=3996.00, p=7.59e-17
Paired t-test (game_entropy vs capabilities_entropy): statistic=6.08, p=5.45e-09
Mean capabilities_entropy-game_entropy = -0.1779  [-0.2353, -0.1206] (n=215)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  215
Model:                          Logit   Df Residuals:                      212
Method:                           MLE   Df Model:                            2
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.2014
Time:                        21:14:15   Log-Likelihood:                -87.011
converged:                       True   LL-Null:                       -108.96
Covariance Type:            nonrobust   LLR p-value:                 2.941e-10
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.4362      0.289     -8.441      0.000      -3.002      -1.870
capabilities_entropy     1.0527      0.553      1.904      0.057      -0.031       2.136
game_entropy             1.6939      0.384      4.413      0.000       0.941       2.446
========================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  215
Model:                          Logit   Df Residuals:                      213
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:               6.494e-05
Time:                        21:14:15   Log-Likelihood:                -108.95
converged:                       True   LL-Null:                       -108.96
Covariance Type:            nonrobust   LLR p-value:                    0.9053
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -1.4430      0.739     -1.952      0.051      -2.892       0.006
human_difficulty     0.0360      0.302      0.119      0.905      -0.557       0.629
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  215
Model:                          Logit   Df Residuals:                      208
Method:                           MLE   Df Model:                            6
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.03518
Time:                        21:14:15   Log-Likelihood:                -105.13
converged:                       True   LL-Null:                       -108.96
Covariance Type:            nonrobust   LLR p-value:                    0.2636
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -0.2816      2.515     -0.112      0.911      -5.212       4.649
C(domain_grouped)[T.chemistry]        1.1724      0.537      2.185      0.029       0.121       2.224
C(domain_grouped)[T.physics]          0.6780      0.515      1.316      0.188      -0.332       1.688
human_difficulty                      0.1167      0.312      0.374      0.708      -0.494       0.728
q_length                             -0.0304      0.270     -0.113      0.910      -0.560       0.499
avg_word_length                      -0.2897      0.295     -0.982      0.326      -0.868       0.288
percent_non_alphabetic_whitespace    -0.0663      0.035     -1.907      0.057      -0.135       0.002
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 0.1784
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  215
Model:                          Logit   Df Residuals:                      207
Method:                           MLE   Df Model:                            7
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.1432
Time:                        21:14:15   Log-Likelihood:                -93.356
converged:                       True   LL-Null:                       -108.96
Covariance Type:            nonrobust   LLR p-value:                 5.700e-05
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -0.0117      2.731     -0.004      0.997      -5.365       5.341
C(domain_grouped)[T.chemistry]        0.9041      0.569      1.588      0.112      -0.212       2.020
C(domain_grouped)[T.physics]          0.5131      0.540      0.950      0.342      -0.546       1.572
human_difficulty                      0.1656      0.337      0.492      0.623      -0.494       0.825
q_length                             -0.1960      0.290     -0.677      0.499      -0.764       0.372
avg_word_length                      -0.2176      0.311     -0.700      0.484      -0.827       0.392
percent_non_alphabetic_whitespace    -0.0820      0.038     -2.170      0.030      -0.156      -0.008
capabilities_entropy                  2.2674      0.493      4.604      0.000       1.302       3.233
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  215
Model:                          Logit   Df Residuals:                      207
Method:                           MLE   Df Model:                            7
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.2065
Time:                        21:14:15   Log-Likelihood:                -86.455
converged:                       True   LL-Null:                       -108.96
Covariance Type:            nonrobust   LLR p-value:                 1.364e-07
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -1.4159      2.796     -0.506      0.613      -6.896       4.064
C(domain_grouped)[T.chemistry]        0.4120      0.604      0.683      0.495      -0.771       1.595
C(domain_grouped)[T.physics]          0.2683      0.570      0.470      0.638      -0.850       1.386
human_difficulty                     -0.0732      0.354     -0.207      0.836      -0.767       0.621
q_length                             -0.0604      0.300     -0.201      0.841      -0.648       0.528
avg_word_length                      -0.0350      0.310     -0.113      0.910      -0.642       0.572
percent_non_alphabetic_whitespace    -0.0664      0.038     -1.733      0.083      -0.142       0.009
game_entropy                          2.0947      0.372      5.625      0.000       1.365       2.825
=====================================================================================================

                  Model 4.95: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  215
Model:                          Logit   Df Residuals:                      206
Method:                           MLE   Df Model:                            8
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.2275
Time:                        21:14:15   Log-Likelihood:                -84.173
converged:                       True   LL-Null:                       -108.96
Covariance Type:            nonrobust   LLR p-value:                 4.943e-08
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -1.1683      2.881     -0.406      0.685      -6.815       4.478
C(domain_grouped)[T.chemistry]        0.3997      0.607      0.659      0.510      -0.790       1.589
C(domain_grouped)[T.physics]          0.2444      0.573      0.426      0.670      -0.879       1.368
human_difficulty                      0.0157      0.362      0.043      0.965      -0.694       0.725
q_length                             -0.1217      0.306     -0.398      0.690      -0.721       0.477
avg_word_length                      -0.0598      0.318     -0.188      0.851      -0.682       0.563
percent_non_alphabetic_whitespace    -0.0759      0.040     -1.891      0.059      -0.155       0.003
capabilities_entropy                  1.2204      0.568      2.147      0.032       0.106       2.334
game_entropy                          1.7108      0.411      4.160      0.000       0.905       2.517
=====================================================================================================

--- Analyzing gemini-2.0-flash-001 (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/gemini-2.0-flash-001_GPQA_redacted_temp1.0_1757988130_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    155
1     77
Name: count, dtype: int64

Answer change%: 0.3319 [0.2713028722391558, 0.39249023120912013] (n=232)
P-value vs 25%: 0.008072; P-value vs 0%: 6.932e-27
Phase 2 self-accuracy: 0.3636 [0.2561906588540613, 0.471082068418666] (n=77)
P-value vs 25%: 0.03818; P-value vs 33%: 0.5763

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  232
Model:                          Logit   Df Residuals:                      230
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.07487
Time:                        21:14:15   Log-Likelihood:                -136.40
converged:                       True   LL-Null:                       -147.44
Covariance Type:            nonrobust   LLR p-value:                 2.617e-06
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          3.8155      1.033      3.694      0.000       1.791       5.840
p_i_capability    -4.9078      1.110     -4.422      0.000      -7.083      -2.732
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  232
Model:                          Logit   Df Residuals:                      230
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.09349
Time:                        21:14:15   Log-Likelihood:                -133.65
converged:                       True   LL-Null:                       -147.44
Covariance Type:            nonrobust   LLR p-value:                 1.516e-07
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.2272      0.184     -6.671      0.000      -1.588      -0.867
capabilities_entropy     1.8213      0.367      4.963      0.000       1.102       2.541
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.4714 [0.3545, 0.5884] (n=70)
                  P-value vs 33.3%: 0.02064

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=5.00, p=2.81e-06
Wilcoxon delta_p: statistic=783.00, p=1.29e-07
Mean Δp = 0.1075  [0.0653, 0.1497]
Idea 1 N = 92; 

  Idea 1.5: Calibration Metrics
  NLL: 8.1218, Signed ECE (overconf pos under neg): 0.0436, ECE: 0.0436 (n=160)
  Brier: 0.0189, Reliability (absolute calibration error; lower better): 0.0185, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=160)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.709
Model:                            OLS   Adj. R-squared:                  0.703
Method:                 Least Squares   F-statistic:                     127.5
Date:                Fri, 19 Sep 2025   Prob (F-statistic):           6.96e-42
Time:                        21:14:15   Log-Likelihood:                 22.591
No. Observations:                 161   AIC:                            -37.18
Df Residuals:                     157   BIC:                            -24.86
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept             0.2873      0.168      1.711      0.089      -0.044       0.619
p1                   -0.1936      0.179     -1.080      0.282      -0.547       0.160
answer_changed       -1.0745      0.215     -4.992      0.000      -1.500      -0.649
p1:answer_changed     1.8684      0.236      7.923      0.000       1.403       2.334
==============================================================================
Omnibus:                        7.394   Durbin-Watson:                   2.069
Prob(Omnibus):                  0.025   Jarque-Bera (JB):               13.483
Skew:                          -0.012   Prob(JB):                      0.00118
Kurtosis:                       4.418   Cond. No.                         33.6
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-2.68, p=0.00869
Wilcoxon delta_H: statistic=1491.00, p=0.0116
Mean ΔH = -0.1572  [-0.2721, -0.0423]
Paired t-test delta_H Changed: statistic=-0.78, p=0.439
Wilcoxon delta_H Changed: statistic=1131.00, p=0.514
Mean ΔH Changed = -0.0579  [-0.2039, 0.0881]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=-5.22, p=5.39e-07
Wilcoxon (p_top2_game vs p_top2_base): statistic=2325.00, p=8.58e-13
Mean Δp_top2 = -0.0326  [-0.0448, -0.0204] (n=162)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=-2.47, p=0.0146
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=5222.00, p=0.0211
Mean ΔH_unchosen_baseline_set = -0.1143  [-0.2051, -0.0235] (n=162)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  162
Model:                          Logit   Df Residuals:                      159
Method:                           MLE   Df Model:                            2
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.03523
Time:                        21:14:15   Log-Likelihood:                -106.89
converged:                       True   LL-Null:                       -110.79
Covariance Type:            nonrobust   LLR p-value:                   0.02018
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.2334      0.248     -0.941      0.347      -0.720       0.253
p1_z            -0.5110      0.316     -1.616      0.106      -1.131       0.109
I(p1_z ** 2)    -0.0446      0.193     -0.231      0.818      -0.423       0.334
================================================================================
AUC = 0.666

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  232
Model:                          Logit   Df Residuals:                      230
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.1322
Time:                        21:14:15   Log-Likelihood:                -127.94
converged:                       True   LL-Null:                       -147.44
Covariance Type:            nonrobust   LLR p-value:                 4.254e-10
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.6478      0.233     -7.086      0.000      -2.104      -1.192
game_entropy     1.6347      0.281      5.824      0.000       1.085       2.185
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=5499.00, p=4.81e-15
Paired t-test (game_entropy vs capabilities_entropy): statistic=7.26, p=5.85e-12
Mean capabilities_entropy-game_entropy = -0.2542  [-0.3228, -0.1856] (n=232)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  232
Model:                          Logit   Df Residuals:                      229
Method:                           MLE   Df Model:                            2
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.1659
Time:                        21:14:15   Log-Likelihood:                -122.98
converged:                       True   LL-Null:                       -147.44
Covariance Type:            nonrobust   LLR p-value:                 2.377e-11
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.8338      0.249     -7.374      0.000      -2.321      -1.346
capabilities_entropy     1.2505      0.403      3.100      0.002       0.460       2.041
game_entropy             1.3300      0.296      4.492      0.000       0.750       1.910
========================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  232
Model:                          Logit   Df Residuals:                      230
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                0.001722
Time:                        21:14:15   Log-Likelihood:                -147.19
converged:                       True   LL-Null:                       -147.44
Covariance Type:            nonrobust   LLR p-value:                    0.4761
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -0.2977      0.581     -0.513      0.608      -1.436       0.840
human_difficulty    -0.1705      0.240     -0.710      0.478      -0.641       0.300
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  232
Model:                          Logit   Df Residuals:                      225
Method:                           MLE   Df Model:                            6
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.02136
Time:                        21:14:15   Log-Likelihood:                -144.29
converged:                       True   LL-Null:                       -147.44
Covariance Type:            nonrobust   LLR p-value:                    0.3907
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -1.8183      2.233     -0.814      0.416      -6.196       2.559
C(domain_grouped)[T.chemistry]        0.2323      0.548      0.424      0.672      -0.842       1.307
C(domain_grouped)[T.physics]         -0.0565      0.581     -0.097      0.923      -1.195       1.082
human_difficulty                     -0.1811      0.257     -0.706      0.480      -0.684       0.322
q_length                              0.4197      0.250      1.679      0.093      -0.070       0.910
avg_word_length                      -0.2574      0.260     -0.989      0.322      -0.767       0.253
percent_non_alphabetic_whitespace     0.0149      0.029      0.519      0.604      -0.041       0.071
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 0.2625
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  232
Model:                          Logit   Df Residuals:                      224
Method:                           MLE   Df Model:                            7
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.1048
Time:                        21:14:15   Log-Likelihood:                -131.99
converged:                       True   LL-Null:                       -147.44
Covariance Type:            nonrobust   LLR p-value:                 6.494e-05
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -1.7532      2.352     -0.745      0.456      -6.363       2.856
C(domain_grouped)[T.chemistry]        0.0567      0.573      0.099      0.921      -1.066       1.179
C(domain_grouped)[T.physics]         -0.2556      0.613     -0.417      0.677      -1.458       0.947
human_difficulty                     -0.2533      0.277     -0.915      0.360      -0.796       0.289
q_length                              0.3368      0.268      1.255      0.209      -0.189       0.863
avg_word_length                      -0.1832      0.272     -0.674      0.500      -0.716       0.349
percent_non_alphabetic_whitespace     0.0053      0.030      0.176      0.860      -0.054       0.065
capabilities_entropy                  1.7658      0.375      4.709      0.000       1.031       2.501
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  232
Model:                          Logit   Df Residuals:                      224
Method:                           MLE   Df Model:                            7
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.1541
Time:                        21:14:15   Log-Likelihood:                -124.71
converged:                       True   LL-Null:                       -147.44
Covariance Type:            nonrobust   LLR p-value:                 1.117e-07
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -3.2361      2.464     -1.313      0.189      -8.066       1.594
C(domain_grouped)[T.chemistry]       -0.2703      0.586     -0.461      0.645      -1.420       0.879
C(domain_grouped)[T.physics]         -0.7842      0.639     -1.228      0.219      -2.036       0.467
human_difficulty                     -0.3215      0.294     -1.092      0.275      -0.899       0.256
q_length                              0.4806      0.276      1.743      0.081      -0.060       1.021
avg_word_length                      -0.0809      0.275     -0.294      0.769      -0.621       0.459
percent_non_alphabetic_whitespace     0.0294      0.031      0.935      0.350      -0.032       0.091
game_entropy                          1.7287      0.299      5.773      0.000       1.142       2.316
=====================================================================================================

                  Model 4.95: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  232
Model:                          Logit   Df Residuals:                      223
Method:                           MLE   Df Model:                            8
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.1831
Time:                        21:14:15   Log-Likelihood:                -120.44
converged:                       True   LL-Null:                       -147.44
Covariance Type:            nonrobust   LLR p-value:                 6.910e-09
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -2.8613      2.516     -1.137      0.255      -7.793       2.070
C(domain_grouped)[T.chemistry]       -0.3242      0.589     -0.550      0.582      -1.479       0.830
C(domain_grouped)[T.physics]         -0.8266      0.648     -1.276      0.202      -2.096       0.443
human_difficulty                     -0.3589      0.307     -1.169      0.242      -0.960       0.243
q_length                              0.4062      0.284      1.432      0.152      -0.150       0.962
avg_word_length                      -0.0610      0.281     -0.217      0.828      -0.611       0.489
percent_non_alphabetic_whitespace     0.0206      0.032      0.636      0.525      -0.043       0.084
capabilities_entropy                  1.1836      0.411      2.880      0.004       0.378       1.989
game_entropy                          1.4517      0.314      4.618      0.000       0.835       2.068
=====================================================================================================

--- Analyzing gemini-2.5-flash-lite_nothink (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/gemini-2.5-flash-lite_nothink_GPQA_redacted_cor_temp1.0_1757983987_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    128
1     43
Name: count, dtype: int64

Answer change%: 0.2515 [0.18643507520540595, 0.3164889014027812] (n=171)
P-value vs 25%: 0.9649; P-value vs 0%: 3.475e-14
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=43)
P-value vs 25%: 0; P-value vs 33%: 0

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  171
Model:                          Logit   Df Residuals:                      169
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.2489
Time:                        21:14:15   Log-Likelihood:                -72.434
converged:                       True   LL-Null:                       -96.433
Covariance Type:            nonrobust   LLR p-value:                 4.267e-12
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          3.9739      0.823      4.831      0.000       2.362       5.586
p_i_capability    -6.4547      1.059     -6.096      0.000      -8.530      -4.379
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  171
Model:                          Logit   Df Residuals:                      169
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.2781
Time:                        21:14:15   Log-Likelihood:                -69.616
converged:                       True   LL-Null:                       -96.433
Covariance Type:            nonrobust   LLR p-value:                 2.415e-13
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.9487      0.412     -7.159      0.000      -3.756      -2.141
capabilities_entropy     2.4127      0.391      6.172      0.000       1.647       3.179
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.3721 [0.2276, 0.5166] (n=43)
                  P-value vs 33.3%: 0.599

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=0.05, p=0.964
Wilcoxon delta_p: statistic=3990.00, p=0.743
Mean Δp = 0.0008  [-0.0332, 0.0348]
Idea 1 N = 128; 

  Idea 1.5: Calibration Metrics
  NLL: 0.3817, Signed ECE (overconf pos under neg): -0.2161, ECE: 0.2161 (n=171)
  Brier: 0.1243, Reliability (absolute calibration error; lower better): 0.1237, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=171)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.441
Model:                            OLS   Adj. R-squared:                  0.431
Method:                 Least Squares   F-statistic:                     43.95
Date:                Fri, 19 Sep 2025   Prob (F-statistic):           5.47e-21
Time:                        21:14:15   Log-Likelihood:                 18.306
No. Observations:                 171   AIC:                            -28.61
Df Residuals:                     167   BIC:                            -16.04
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.4303      0.110     -3.916      0.000      -0.647      -0.213
p1                    0.4819      0.121      3.986      0.000       0.243       0.721
answer_changed       -0.2338      0.166     -1.412      0.160      -0.561       0.093
p1:answer_changed     0.9773      0.220      4.443      0.000       0.543       1.412
==============================================================================
Omnibus:                       26.805   Durbin-Watson:                   1.952
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               81.870
Skew:                           0.561   Prob(JB):                     1.67e-18
Kurtosis:                       6.199   Cond. No.                         23.4
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-1.40, p=0.163
Wilcoxon delta_H: statistic=3664.00, p=0.27
Mean ΔH = -0.0584  [-0.1401, 0.0232]
Paired t-test delta_H Changed: statistic=5.22, p=5.12e-06
Wilcoxon delta_H Changed: statistic=78.00, p=1.49e-07
Mean ΔH Changed = 0.3183  [0.1989, 0.4376]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=3.18, p=0.00174
Wilcoxon (p_top2_game vs p_top2_base): statistic=6363.00, p=0.127
Mean Δp_top2 = 0.0180  [0.0069, 0.0291] (n=171)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=0.98, p=0.326
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=6358.00, p=0.125
Mean ΔH_unchosen_baseline_set = 0.0363  [-0.0359, 0.1085] (n=171)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  171
Model:                          Logit   Df Residuals:                      168
Method:                           MLE   Df Model:                            2
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.2827
Time:                        21:14:15   Log-Likelihood:                -69.172
converged:                       True   LL-Null:                       -96.433
Covariance Type:            nonrobust   LLR p-value:                 1.447e-12
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.0135      0.279     -3.633      0.000      -1.560      -0.467
p1_z            -1.9566      0.363     -5.384      0.000      -2.669      -1.244
I(p1_z ** 2)    -0.5778      0.224     -2.578      0.010      -1.017      -0.139
================================================================================
AUC = 0.853

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  171
Model:                          Logit   Df Residuals:                      169
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.2001
Time:                        21:14:15   Log-Likelihood:                -77.141
converged:                       True   LL-Null:                       -96.433
Covariance Type:            nonrobust   LLR p-value:                 5.243e-10
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -2.4334      0.337     -7.228      0.000      -3.093      -1.774
game_entropy     2.2713      0.408      5.574      0.000       1.473       3.070
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=5378.00, p=0.00232
Paired t-test (game_entropy vs capabilities_entropy): statistic=-3.21, p=0.00156
Mean capabilities_entropy-game_entropy = 0.1133  [0.0442, 0.1823] (n=171)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  171
Model:                          Logit   Df Residuals:                      168
Method:                           MLE   Df Model:                            2
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.3076
Time:                        21:14:15   Log-Likelihood:                -66.774
converged:                       True   LL-Null:                       -96.433
Covariance Type:            nonrobust   LLR p-value:                 1.316e-13
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -3.2774      0.464     -7.068      0.000      -4.186      -2.369
capabilities_entropy     1.8899      0.441      4.283      0.000       1.025       2.755
game_entropy             1.1861      0.499      2.376      0.018       0.208       2.165
========================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  171
Model:                          Logit   Df Residuals:                      169
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                0.006346
Time:                        21:14:15   Log-Likelihood:                -95.821
converged:                       True   LL-Null:                       -96.433
Covariance Type:            nonrobust   LLR p-value:                    0.2686
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -0.2235      0.803     -0.278      0.781      -1.797       1.350
human_difficulty    -0.3691      0.337     -1.095      0.273      -1.030       0.291
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  171
Model:                          Logit   Df Residuals:                      164
Method:                           MLE   Df Model:                            6
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.06710
Time:                        21:14:15   Log-Likelihood:                -89.962
converged:                       True   LL-Null:                       -96.433
Covariance Type:            nonrobust   LLR p-value:                   0.04397
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -5.4997      2.956     -1.861      0.063     -11.293       0.293
C(domain_grouped)[T.chemistry]        1.7951      0.653      2.748      0.006       0.515       3.075
C(domain_grouped)[T.physics]          1.4975      0.666      2.247      0.025       0.191       2.804
human_difficulty                     -0.2247      0.346     -0.650      0.516      -0.902       0.453
q_length                              0.2611      0.327      0.797      0.425      -0.381       0.903
avg_word_length                       0.3883      0.344      1.130      0.259      -0.285       1.062
percent_non_alphabetic_whitespace     0.0332      0.035      0.939      0.348      -0.036       0.103
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 0.5976
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  171
Model:                          Logit   Df Residuals:                      163
Method:                           MLE   Df Model:                            7
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.3140
Time:                        21:14:15   Log-Likelihood:                -66.152
converged:                       True   LL-Null:                       -96.433
Covariance Type:            nonrobust   LLR p-value:                 1.166e-10
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -6.8188      3.496     -1.951      0.051     -13.670       0.032
C(domain_grouped)[T.chemistry]        0.6162      0.762      0.809      0.419      -0.877       2.110
C(domain_grouped)[T.physics]          0.9044      0.812      1.114      0.265      -0.687       2.495
human_difficulty                     -0.4786      0.424     -1.129      0.259      -1.310       0.352
q_length                             -0.0721      0.365     -0.197      0.843      -0.788       0.644
avg_word_length                       0.8831      0.431      2.047      0.041       0.037       1.729
percent_non_alphabetic_whitespace     0.0710      0.045      1.576      0.115      -0.017       0.159
capabilities_entropy                  2.5306      0.438      5.777      0.000       1.672       3.389
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  171
Model:                          Logit   Df Residuals:                      163
Method:                           MLE   Df Model:                            7
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.2459
Time:                        21:14:15   Log-Likelihood:                -72.718
converged:                       True   LL-Null:                       -96.433
Covariance Type:            nonrobust   LLR p-value:                 4.601e-08
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -8.0845      3.471     -2.329      0.020     -14.887      -1.282
C(domain_grouped)[T.chemistry]        1.5958      0.735      2.171      0.030       0.155       3.036
C(domain_grouped)[T.physics]          1.5178      0.763      1.990      0.047       0.023       3.013
human_difficulty                     -0.0627      0.390     -0.161      0.872      -0.827       0.701
q_length                              0.1769      0.358      0.495      0.621      -0.524       0.878
avg_word_length                       0.6580      0.397      1.657      0.097      -0.120       1.436
percent_non_alphabetic_whitespace     0.0545      0.042      1.299      0.194      -0.028       0.137
game_entropy                          2.2537      0.431      5.224      0.000       1.408       3.099
=====================================================================================================

                  Model 4.95: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  171
Model:                          Logit   Df Residuals:                      162
Method:                           MLE   Df Model:                            8
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.3419
Time:                        21:14:15   Log-Likelihood:                -63.461
converged:                       True   LL-Null:                       -96.433
Covariance Type:            nonrobust   LLR p-value:                 3.140e-11
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -8.2087      3.709     -2.213      0.027     -15.477      -0.940
C(domain_grouped)[T.chemistry]        0.7591      0.792      0.959      0.338      -0.793       2.311
C(domain_grouped)[T.physics]          1.0884      0.842      1.293      0.196      -0.562       2.739
human_difficulty                     -0.3540      0.439     -0.807      0.420      -1.214       0.506
q_length                             -0.0179      0.373     -0.048      0.962      -0.750       0.714
avg_word_length                       0.9439      0.449      2.103      0.035       0.064       1.824
percent_non_alphabetic_whitespace     0.0758      0.047      1.627      0.104      -0.015       0.167
capabilities_entropy                  1.9949      0.494      4.038      0.000       1.027       2.963
game_entropy                          1.1925      0.518      2.301      0.021       0.177       2.208
=====================================================================================================

--- Analyzing gemini-2.5-flash-lite_nothink (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/gemini-2.5-flash-lite_nothink_GPQA_redacted_temp1.0_1757983795_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    161
1    115
Name: count, dtype: int64

Answer change%: 0.4167 [0.35850372999560914, 0.4748296033377242] (n=276)
P-value vs 25%: 1.951e-08; P-value vs 0%: 8.777e-45
Phase 2 self-accuracy: 0.4870 [0.39560382972708724, 0.5783092137511736] (n=115)
P-value vs 25%: 3.698e-07; P-value vs 33%: 0.0009561

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  276
Model:                          Logit   Df Residuals:                      274
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.1054
Time:                        21:14:15   Log-Likelihood:                -167.70
converged:                       True   LL-Null:                       -187.46
Covariance Type:            nonrobust   LLR p-value:                 3.266e-10
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          2.5257      0.497      5.086      0.000       1.552       3.499
p_i_capability    -3.9619      0.671     -5.900      0.000      -5.278      -2.646
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  276
Model:                          Logit   Df Residuals:                      274
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.1053
Time:                        21:14:15   Log-Likelihood:                -167.72
converged:                       True   LL-Null:                       -187.46
Covariance Type:            nonrobust   LLR p-value:                 3.315e-10
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.6856      0.274     -6.151      0.000      -2.223      -1.148
capabilities_entropy     1.3786      0.236      5.854      0.000       0.917       1.840
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.4696 [0.3784, 0.5608] (n=115)
                  P-value vs 33.3%: 0.003419

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=0.25, p=0.8
Wilcoxon delta_p: statistic=6059.00, p=0.436
Mean Δp = 0.0043  [-0.0289, 0.0374]
Idea 1 N = 161; 

  Idea 1.5: Calibration Metrics
  NLL: 3.5892, Signed ECE (overconf pos under neg): 0.1354, ECE: 0.1354 (n=276)
  Brier: 0.0535, Reliability (absolute calibration error; lower better): 0.0528, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=276)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.432
Model:                            OLS   Adj. R-squared:                  0.425
Method:                 Least Squares   F-statistic:                     68.85
Date:                Fri, 19 Sep 2025   Prob (F-statistic):           3.71e-33
Time:                        21:14:15   Log-Likelihood:                -5.6819
No. Observations:                 276   AIC:                             19.36
Df Residuals:                     272   BIC:                             33.85
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.2250      0.084     -2.678      0.008      -0.390      -0.060
p1                    0.2872      0.102      2.807      0.005       0.086       0.489
answer_changed       -0.2247      0.118     -1.912      0.057      -0.456       0.007
p1:answer_changed     0.9013      0.160      5.645      0.000       0.587       1.216
==============================================================================
Omnibus:                        2.874   Durbin-Watson:                   2.082
Prob(Omnibus):                  0.238   Jarque-Bera (JB):                2.564
Skew:                          -0.183   Prob(JB):                        0.277
Kurtosis:                       3.298   Cond. No.                         19.9
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=1.84, p=0.0679
Wilcoxon delta_H: statistic=5432.00, p=0.0662
Mean ΔH = 0.0720  [-0.0048, 0.1488]
Paired t-test delta_H Changed: statistic=6.16, p=1.14e-08
Wilcoxon delta_H Changed: statistic=1317.00, p=1.78e-08
Mean ΔH Changed = 0.2827  [0.1927, 0.3727]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=5.98, p=6.83e-09
Wilcoxon (p_top2_game vs p_top2_base): statistic=11715.00, p=2.49e-08
Mean Δp_top2 = 0.0345  [0.0232, 0.0457] (n=276)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=5.26, p=2.96e-07
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=12278.00, p=2.61e-07
Mean ΔH_unchosen_baseline_set = 0.1598  [0.1002, 0.2194] (n=276)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  276
Model:                          Logit   Df Residuals:                      273
Method:                           MLE   Df Model:                            2
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.1097
Time:                        21:14:15   Log-Likelihood:                -166.89
converged:                       True   LL-Null:                       -187.46
Covariance Type:            nonrobust   LLR p-value:                 1.165e-09
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.2011      0.193     -1.040      0.298      -0.580       0.178
p1_z            -0.8748      0.148     -5.898      0.000      -1.166      -0.584
I(p1_z ** 2)    -0.2039      0.159     -1.282      0.200      -0.516       0.108
================================================================================
AUC = 0.721

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  276
Model:                          Logit   Df Residuals:                      274
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.09767
Time:                        21:14:15   Log-Likelihood:                -169.15
converged:                       True   LL-Null:                       -187.46
Covariance Type:            nonrobust   LLR p-value:                 1.438e-09
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.5449      0.255     -6.047      0.000      -2.046      -1.044
game_entropy     1.5097      0.266      5.669      0.000       0.988       2.032
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=12151.00, p=1.56e-07
Paired t-test (game_entropy vs capabilities_entropy): statistic=-5.35, p=1.86e-07
Mean capabilities_entropy-game_entropy = 0.1645  [0.1042, 0.2248] (n=276)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  276
Model:                          Logit   Df Residuals:                      273
Method:                           MLE   Df Model:                            2
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.1302
Time:                        21:14:15   Log-Likelihood:                -163.05
converged:                       True   LL-Null:                       -187.46
Covariance Type:            nonrobust   LLR p-value:                 2.506e-11
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.0179      0.306     -6.585      0.000      -2.618      -1.417
capabilities_entropy     0.9397      0.274      3.428      0.001       0.402       1.477
game_entropy             0.9439      0.313      3.020      0.003       0.331       1.556
========================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  276
Model:                          Logit   Df Residuals:                      274
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:               8.896e-05
Time:                        21:14:15   Log-Likelihood:                -187.44
converged:                       True   LL-Null:                       -187.46
Covariance Type:            nonrobust   LLR p-value:                    0.8551
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -0.2477      0.501     -0.494      0.621      -1.230       0.735
human_difficulty    -0.0375      0.206     -0.183      0.855      -0.440       0.365
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  276
Model:                          Logit   Df Residuals:                      269
Method:                           MLE   Df Model:                            6
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.02242
Time:                        21:14:15   Log-Likelihood:                -183.25
converged:                       True   LL-Null:                       -187.46
Covariance Type:            nonrobust   LLR p-value:                    0.2099
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -1.8580      1.860     -0.999      0.318      -5.504       1.788
C(domain_grouped)[T.chemistry]        0.5323      0.462      1.153      0.249      -0.372       1.437
C(domain_grouped)[T.physics]          0.8860      0.469      1.891      0.059      -0.032       1.804
human_difficulty                      0.0483      0.218      0.221      0.825      -0.379       0.476
q_length                              0.1481      0.201      0.735      0.462      -0.247       0.543
avg_word_length                      -0.0620      0.197     -0.315      0.753      -0.448       0.324
percent_non_alphabetic_whitespace     0.0214      0.022      0.970      0.332      -0.022       0.065
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 0.9362
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  276
Model:                          Logit   Df Residuals:                      268
Method:                           MLE   Df Model:                            7
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.1256
Time:                        21:14:15   Log-Likelihood:                -163.90
converged:                       True   LL-Null:                       -187.46
Covariance Type:            nonrobust   LLR p-value:                 5.320e-08
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -3.4443      2.013     -1.711      0.087      -7.389       0.500
C(domain_grouped)[T.chemistry]       -0.0998      0.512     -0.195      0.845      -1.103       0.903
C(domain_grouped)[T.physics]          0.5910      0.511      1.156      0.248      -0.411       1.593
human_difficulty                      0.1336      0.237      0.564      0.573      -0.331       0.598
q_length                              0.0222      0.218      0.102      0.919      -0.404       0.449
avg_word_length                       0.1499      0.205      0.733      0.464      -0.251       0.551
percent_non_alphabetic_whitespace     0.0369      0.023      1.600      0.110      -0.008       0.082
capabilities_entropy                  1.4647      0.253      5.783      0.000       0.968       1.961
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  276
Model:                          Logit   Df Residuals:                      268
Method:                           MLE   Df Model:                            7
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.1211
Time:                        21:14:15   Log-Likelihood:                -164.76
converged:                       True   LL-Null:                       -187.46
Covariance Type:            nonrobust   LLR p-value:                 1.150e-07
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -2.6335      2.007     -1.312      0.189      -6.567       1.300
C(domain_grouped)[T.chemistry]        0.2901      0.498      0.582      0.560      -0.686       1.267
C(domain_grouped)[T.physics]          0.8622      0.507      1.699      0.089      -0.132       1.857
human_difficulty                      0.0925      0.238      0.388      0.698      -0.375       0.560
q_length                              0.0263      0.218      0.121      0.904      -0.401       0.454
avg_word_length                      -0.0200      0.204     -0.098      0.922      -0.420       0.380
percent_non_alphabetic_whitespace     0.0290      0.024      1.208      0.227      -0.018       0.076
game_entropy                          1.5663      0.276      5.667      0.000       1.025       2.108
=====================================================================================================

                  Model 4.95: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  276
Model:                          Logit   Df Residuals:                      267
Method:                           MLE   Df Model:                            8
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.1525
Time:                        21:14:15   Log-Likelihood:                -158.87
converged:                       True   LL-Null:                       -187.46
Covariance Type:            nonrobust   LLR p-value:                 1.666e-09
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -3.4582      2.071     -1.670      0.095      -7.516       0.600
C(domain_grouped)[T.chemistry]       -0.0470      0.522     -0.090      0.928      -1.070       0.976
C(domain_grouped)[T.physics]          0.6717      0.523      1.285      0.199      -0.353       1.697
human_difficulty                      0.1486      0.245      0.607      0.544      -0.332       0.629
q_length                             -0.0160      0.224     -0.072      0.943      -0.454       0.422
avg_word_length                       0.1073      0.209      0.515      0.607      -0.301       0.516
percent_non_alphabetic_whitespace     0.0365      0.024      1.530      0.126      -0.010       0.083
capabilities_entropy                  0.9889      0.294      3.367      0.001       0.413       1.565
game_entropy                          1.0020      0.321      3.119      0.002       0.372       1.632
=====================================================================================================

--- Analyzing gemini-2.5-flash-lite_think (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/gemini-2.5-flash-lite_think_GPQA_redacted_cor_temp1.0_1758169794_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    152
1    136
Name: count, dtype: int64

Answer change%: 0.4722 [0.414565412594486, 0.5298790318499584] (n=288)
P-value vs 25%: 4.216e-14; P-value vs 0%: 5.487e-58
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=136)
P-value vs 25%: 0; P-value vs 33%: 0

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  288
Model:                          Logit   Df Residuals:                      286
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.01641
Time:                        21:14:15   Log-Likelihood:                -195.91
converged:                       True   LL-Null:                       -199.18
Covariance Type:            nonrobust   LLR p-value:                   0.01057
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept         61.8264     38.046      1.625      0.104     -12.742     136.395
p_i_capability   -62.0123     38.076     -1.629      0.103    -136.641      12.616
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  288
Model:                          Logit   Df Residuals:                      286
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.01461
Time:                        21:14:15   Log-Likelihood:                -196.27
converged:                       True   LL-Null:                       -199.18
Covariance Type:            nonrobust   LLR p-value:                   0.01584
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -0.1898      0.124     -1.532      0.125      -0.433       0.053
capabilities_entropy     7.8696      4.591      1.714      0.086      -1.128      16.867
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.1148 [0.0582, 0.1713] (n=122)
                  P-value vs 33.3%: 3.596e-14

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=2.02, p=0.0454
Wilcoxon delta_p: statistic=2530.00, p=0.000223
Mean Δp = 0.0109  [0.0003, 0.0214]
Idea 1 N = 127; 

  Idea 1.5: Calibration Metrics
  NLL: 0.0022, Signed ECE (overconf pos under neg): -0.0021, ECE: 0.0021 (n=245)
  Brier: 0.0001, Reliability (absolute calibration error; lower better): 0.0001, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=245)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.991
Model:                            OLS   Adj. R-squared:                  0.991
Method:                 Least Squares   F-statistic:                     7492.
Date:                Fri, 19 Sep 2025   Prob (F-statistic):          2.21e-212
Time:                        21:14:15   Log-Likelihood:                 350.62
No. Observations:                 213   AIC:                            -693.2
Df Residuals:                     209   BIC:                            -679.8
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -2.1474      2.417     -0.889      0.375      -6.912       2.617
p1                    2.1598      2.418      0.893      0.373      -2.608       6.927
answer_changed        2.0311      2.549      0.797      0.426      -2.994       7.056
p1:answer_changed    -1.0448      2.551     -0.410      0.683      -6.074       3.984
==============================================================================
Omnibus:                      367.172   Durbin-Watson:                   2.064
Prob(Omnibus):                  0.000   Jarque-Bera (JB):            66492.417
Skew:                           8.948   Prob(JB):                         0.00
Kurtosis:                      87.686   Cond. No.                     2.36e+03
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The condition number is large, 2.36e+03. This might indicate that there are
strong multicollinearity or other numerical problems.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-3.40, p=0.000916
Wilcoxon delta_H: statistic=2546.00, p=0.00026
Mean ΔH = -0.1781  [-0.2809, -0.0753]
Paired t-test delta_H Changed: statistic=22.80, p=7.24e-45
Wilcoxon delta_H Changed: statistic=28.00, p=8.59e-21
Mean ΔH Changed = 0.9826  [0.8982, 1.0671]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=-1.87, p=0.0628
Wilcoxon (p_top2_game vs p_top2_base): statistic=6776.00, p=8.2e-14
Mean Δp_top2 = -0.0021  [-0.0044, 0.0001] (n=245)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=7.55, p=8.53e-13
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=7692.00, p=3.09e-11
Mean ΔH_unchosen_baseline_set = 0.3809  [0.2821, 0.4798] (n=245)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  245
Model:                          Logit   Df Residuals:                      242
Method:                           MLE   Df Model:                            2
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.03475
Time:                        21:14:15   Log-Likelihood:                -163.76
converged:                       True   LL-Null:                       -169.66
Covariance Type:            nonrobust   LLR p-value:                  0.002753
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.5941      0.326     -1.822      0.068      -1.233       0.045
p1_z             2.3857      1.613      1.479      0.139      -0.776       5.548
I(p1_z ** 2)     3.6155      2.215      1.632      0.103      -0.726       7.956
================================================================================
AUC = 0.587

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  288
Model:                          Logit   Df Residuals:                      286
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                0.001747
Time:                        21:14:15   Log-Likelihood:                -198.83
converged:                       True   LL-Null:                       -199.18
Covariance Type:            nonrobust   LLR p-value:                    0.4042
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.1375      0.122     -1.125      0.261      -0.377       0.102
game_entropy     0.5537      0.676      0.819      0.413      -0.771       1.879
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=11233.00, p=1.3e-11
Paired t-test (game_entropy vs capabilities_entropy): statistic=3.60, p=0.000368
Mean capabilities_entropy-game_entropy = -0.0353  [-0.0545, -0.0161] (n=288)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  288
Model:                          Logit   Df Residuals:                      285
Method:                           MLE   Df Model:                            2
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.01462
Time:                        21:14:15   Log-Likelihood:                -196.27
converged:                       True   LL-Null:                       -199.18
Covariance Type:            nonrobust   LLR p-value:                   0.05435
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -0.1884      0.126     -1.494      0.135      -0.435       0.059
capabilities_entropy     7.9329      4.710      1.684      0.092      -1.299      17.165
game_entropy            -0.0462      0.777     -0.059      0.953      -1.569       1.477
========================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  288
Model:                          Logit   Df Residuals:                      286
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                0.003073
Time:                        21:14:15   Log-Likelihood:                -198.57
converged:                       True   LL-Null:                       -199.18
Covariance Type:            nonrobust   LLR p-value:                    0.2685
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -0.6619      0.513     -1.290      0.197      -1.668       0.344
human_difficulty     0.2397      0.217      1.103      0.270      -0.186       0.666
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  288
Model:                          Logit   Df Residuals:                      281
Method:                           MLE   Df Model:                            6
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.01427
Time:                        21:14:15   Log-Likelihood:                -196.34
converged:                       True   LL-Null:                       -199.18
Covariance Type:            nonrobust   LLR p-value:                    0.4595
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -1.3635      1.643     -0.830      0.407      -4.585       1.857
C(domain_grouped)[T.chemistry]        0.0704      0.378      0.186      0.852      -0.671       0.812
C(domain_grouped)[T.physics]         -0.3864      0.357     -1.083      0.279      -1.085       0.313
human_difficulty                      0.2309      0.229      1.009      0.313      -0.218       0.679
q_length                              0.0724      0.205      0.353      0.724      -0.330       0.475
avg_word_length                       0.0633      0.182      0.348      0.728      -0.293       0.419
percent_non_alphabetic_whitespace     0.0195      0.021      0.913      0.361      -0.022       0.061
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 0.0126
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  288
Model:                          Logit   Df Residuals:                      280
Method:                           MLE   Df Model:                            7
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.02501
Time:                        21:14:15   Log-Likelihood:                -194.20
converged:                       True   LL-Null:                       -199.18
Covariance Type:            nonrobust   LLR p-value:                    0.1908
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -1.0963      1.659     -0.661      0.509      -4.348       2.156
C(domain_grouped)[T.chemistry]       -0.0736      0.386     -0.190      0.849      -0.831       0.684
C(domain_grouped)[T.physics]         -0.4033      0.357     -1.129      0.259      -1.104       0.297
human_difficulty                      0.1715      0.232      0.739      0.460      -0.283       0.626
q_length                              0.0308      0.208      0.148      0.882      -0.376       0.438
avg_word_length                       0.0827      0.183      0.452      0.651      -0.276       0.441
percent_non_alphabetic_whitespace     0.0211      0.021      0.981      0.327      -0.021       0.063
capabilities_entropy                  6.8608      4.502      1.524      0.127      -1.962      15.684
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  288
Model:                          Logit   Df Residuals:                      280
Method:                           MLE   Df Model:                            7
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.01515
Time:                        21:14:15   Log-Likelihood:                -196.17
converged:                       True   LL-Null:                       -199.18
Covariance Type:            nonrobust   LLR p-value:                    0.5359
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -1.3410      1.645     -0.815      0.415      -4.565       1.883
C(domain_grouped)[T.chemistry]        0.0396      0.382      0.104      0.918      -0.709       0.788
C(domain_grouped)[T.physics]         -0.3898      0.357     -1.093      0.275      -1.089       0.310
human_difficulty                      0.2197      0.230      0.956      0.339      -0.231       0.670
q_length                              0.0643      0.206      0.312      0.755      -0.339       0.468
avg_word_length                       0.0716      0.182      0.392      0.695      -0.286       0.429
percent_non_alphabetic_whitespace     0.0202      0.021      0.944      0.345      -0.022       0.062
game_entropy                          0.3997      0.682      0.586      0.558      -0.936       1.735
=====================================================================================================

                  Model 4.95: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  288
Model:                          Logit   Df Residuals:                      279
Method:                           MLE   Df Model:                            8
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.02505
Time:                        21:14:15   Log-Likelihood:                -194.19
converged:                       True   LL-Null:                       -199.18
Covariance Type:            nonrobust   LLR p-value:                    0.2665
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -1.1025      1.660     -0.664      0.507      -4.355       2.151
C(domain_grouped)[T.chemistry]       -0.0692      0.388     -0.179      0.858      -0.829       0.691
C(domain_grouped)[T.physics]         -0.4025      0.357     -1.126      0.260      -1.103       0.298
human_difficulty                      0.1732      0.232      0.746      0.456      -0.282       0.629
q_length                              0.0325      0.208      0.156      0.876      -0.375       0.440
avg_word_length                       0.0815      0.183      0.445      0.656      -0.277       0.440
percent_non_alphabetic_whitespace     0.0210      0.022      0.975      0.329      -0.021       0.063
capabilities_entropy                  6.9929      4.610      1.517      0.129      -2.042      16.028
game_entropy                         -0.1027      0.789     -0.130      0.896      -1.648       1.443
=====================================================================================================

--- Analyzing gemini-2.5-flash-lite_think (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/gemini-2.5-flash-lite_think_GPQA_redacted_temp1.0_1758161989_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
1    93
0    66
Name: count, dtype: int64

Answer change%: 0.5849 [0.5083167578154234, 0.6614945629392935] (n=159)
P-value vs 25%: 1.031e-17; P-value vs 0%: 1.186e-50
Phase 2 self-accuracy: 0.5161 [0.41456251894610774, 0.6176955455700213] (n=93)
P-value vs 25%: 2.813e-07; P-value vs 33%: 0.0004095

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  159
Model:                          Logit   Df Residuals:                      157
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.03610
Time:                        21:14:15   Log-Likelihood:                -104.01
converged:                       True   LL-Null:                       -107.91
Covariance Type:            nonrobust   LLR p-value:                  0.005252
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept        148.8903     84.094      1.771      0.077     -15.930     313.711
p_i_capability  -148.7424     84.168     -1.767      0.077    -313.709      16.224
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  159
Model:                          Logit   Df Residuals:                      157
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.03396
Time:                        21:14:15   Log-Likelihood:                -104.24
converged:                       True   LL-Null:                       -107.91
Covariance Type:            nonrobust   LLR p-value:                  0.006782
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept                0.1412      0.183      0.773      0.440      -0.217       0.499
capabilities_entropy    16.9748      9.495      1.788      0.074      -1.636      35.586
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.2024 [0.1165, 0.2883] (n=84)
                  P-value vs 33.3%: 0.002815

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=1.42, p=0.161
Wilcoxon delta_p: statistic=582.00, p=0.0521
Mean Δp = 0.0026  [-0.0010, 0.0062]
Idea 1 N = 57; 

  Idea 1.5: Calibration Metrics
  NLL: 9.3676, Signed ECE (overconf pos under neg): 0.0038, ECE: 0.0038 (n=63)
  Brier: 0.0004, Reliability (absolute calibration error; lower better): 0.0003, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=63)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.995
Model:                            OLS   Adj. R-squared:                  0.995
Method:                 Least Squares   F-statistic:                     7030.
Date:                Fri, 19 Sep 2025   Prob (F-statistic):          4.52e-117
Time:                        21:14:15   Log-Likelihood:                 206.89
No. Observations:                 105   AIC:                            -405.8
Df Residuals:                     101   BIC:                            -395.2
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -1.2052      3.330     -0.362      0.718      -7.810       5.400
p1                    1.2087      3.332      0.363      0.718      -5.401       7.819
answer_changed        0.6853      3.332      0.206      0.837      -5.925       7.296
p1:answer_changed     0.2998      3.335      0.090      0.929      -6.316       6.916
==============================================================================
Omnibus:                      158.988   Durbin-Watson:                   2.096
Prob(Omnibus):                  0.000   Jarque-Bera (JB):             7161.527
Skew:                          -5.655   Prob(JB):                         0.00
Kurtosis:                      41.846   Cond. No.                     3.14e+03
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The condition number is large, 3.14e+03. This might indicate that there are
strong multicollinearity or other numerical problems.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-3.77, p=0.000399
Wilcoxon delta_H: statistic=402.00, p=0.000744
Mean ΔH = -0.2539  [-0.3861, -0.1218]
Paired t-test delta_H Changed: statistic=20.94, p=2.7e-33
Wilcoxon delta_H Changed: statistic=0.00, p=2.46e-14
Mean ΔH Changed = 1.0390  [0.9418, 1.1363]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=-0.27, p=0.788
Wilcoxon (p_top2_game vs p_top2_base): statistic=2833.00, p=0.000175
Mean Δp_top2 = -0.0007  [-0.0061, 0.0046] (n=134)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=7.14, p=5.56e-11
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=1801.00, p=1.5e-09
Mean ΔH_unchosen_baseline_set = 0.4890  [0.3547, 0.6233] (n=134)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  134
Model:                          Logit   Df Residuals:                      131
Method:                           MLE   Df Model:                            2
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.05397
Time:                        21:14:15   Log-Likelihood:                -86.452
converged:                       True   LL-Null:                       -91.384
Covariance Type:            nonrobust   LLR p-value:                  0.007211
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept        1.2404      0.844      1.470      0.142      -0.413       2.894
p1_z           -21.2986     18.287     -1.165      0.244     -57.141      14.544
I(p1_z ** 2)    93.4113    100.027      0.934      0.350    -102.639     289.461
================================================================================
AUC = 0.589

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  159
Model:                          Logit   Df Residuals:                      157
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.01769
Time:                        21:14:15   Log-Likelihood:                -106.00
converged:                       True   LL-Null:                       -107.91
Covariance Type:            nonrobust   LLR p-value:                   0.05069
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept        0.2464      0.169      1.454      0.146      -0.086       0.579
game_entropy     2.5185      1.864      1.351      0.177      -1.135       6.172
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=4685.00, p=0.00397
Paired t-test (game_entropy vs capabilities_entropy): statistic=1.34, p=0.182
Mean capabilities_entropy-game_entropy = -0.0230  [-0.0566, 0.0106] (n=159)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  159
Model:                          Logit   Df Residuals:                      156
Method:                           MLE   Df Model:                            2
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.04629
Time:                        21:14:15   Log-Likelihood:                -102.91
converged:                       True   LL-Null:                       -107.91
Covariance Type:            nonrobust   LLR p-value:                  0.006774
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept                0.0602      0.191      0.315      0.753      -0.315       0.435
capabilities_entropy    16.4703      9.438      1.745      0.081      -2.029      34.969
game_entropy             2.4926      2.028      1.229      0.219      -1.482       6.467
========================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  159
Model:                          Logit   Df Residuals:                      157
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.01728
Time:                        21:14:15   Log-Likelihood:                -106.04
converged:                       True   LL-Null:                       -107.91
Covariance Type:            nonrobust   LLR p-value:                   0.05344
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -0.9854      0.714     -1.380      0.168      -2.385       0.414
human_difficulty     0.5337      0.281      1.897      0.058      -0.018       1.085
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  159
Model:                          Logit   Df Residuals:                      152
Method:                           MLE   Df Model:                            6
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.02296
Time:                        21:14:15   Log-Likelihood:                -105.43
converged:                       True   LL-Null:                       -107.91
Covariance Type:            nonrobust   LLR p-value:                    0.5495
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                             0.1190      2.816      0.042      0.966      -5.400       5.638
C(domain_grouped)[T.chemistry]        0.2347      0.529      0.443      0.658      -0.803       1.272
C(domain_grouped)[T.physics]          0.1084      0.597      0.182      0.856      -1.062       1.279
human_difficulty                      0.5649      0.298      1.898      0.058      -0.018       1.148
q_length                             -0.0234      0.253     -0.093      0.926      -0.519       0.472
avg_word_length                      -0.2421      0.317     -0.764      0.445      -0.863       0.379
percent_non_alphabetic_whitespace    -0.0086      0.033     -0.265      0.791      -0.072       0.055
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 0.0303
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  159
Model:                          Logit   Df Residuals:                      151
Method:                           MLE   Df Model:                            7
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.05025
Time:                        21:14:15   Log-Likelihood:                -102.48
converged:                       True   LL-Null:                       -107.91
Covariance Type:            nonrobust   LLR p-value:                    0.1455
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                             0.5077      2.843      0.179      0.858      -5.064       6.080
C(domain_grouped)[T.chemistry]        0.0497      0.542      0.092      0.927      -1.012       1.111
C(domain_grouped)[T.physics]          0.0168      0.602      0.028      0.978      -1.163       1.196
human_difficulty                      0.4925      0.300      1.640      0.101      -0.096       1.081
q_length                             -0.1101      0.264     -0.417      0.677      -0.628       0.407
avg_word_length                      -0.2012      0.318     -0.632      0.527      -0.825       0.422
percent_non_alphabetic_whitespace    -0.0020      0.033     -0.061      0.951      -0.066       0.062
capabilities_entropy                 15.1199      9.950      1.520      0.129      -4.381      34.621
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  159
Model:                          Logit   Df Residuals:                      151
Method:                           MLE   Df Model:                            7
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.03824
Time:                        21:14:15   Log-Likelihood:                -103.78
converged:                       True   LL-Null:                       -107.91
Covariance Type:            nonrobust   LLR p-value:                    0.3109
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                             0.4053      2.827      0.143      0.886      -5.136       5.947
C(domain_grouped)[T.chemistry]        0.2624      0.530      0.495      0.621      -0.777       1.301
C(domain_grouped)[T.physics]         -0.0153      0.600     -0.026      0.980      -1.192       1.161
human_difficulty                      0.5414      0.299      1.809      0.070      -0.045       1.128
q_length                             -0.0581      0.254     -0.228      0.819      -0.556       0.440
avg_word_length                      -0.2600      0.319     -0.816      0.414      -0.884       0.364
percent_non_alphabetic_whitespace    -0.0108      0.033     -0.330      0.742      -0.075       0.053
game_entropy                          2.6230      1.999      1.312      0.189      -1.295       6.541
=====================================================================================================

                  Model 4.95: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  159
Model:                          Logit   Df Residuals:                      150
Method:                           MLE   Df Model:                            8
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.06156
Time:                        21:14:15   Log-Likelihood:                -101.26
converged:                       True   LL-Null:                       -107.91
Covariance Type:            nonrobust   LLR p-value:                    0.1024
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                             0.8643      2.861      0.302      0.763      -4.743       6.471
C(domain_grouped)[T.chemistry]        0.0774      0.542      0.143      0.887      -0.986       1.141
C(domain_grouped)[T.physics]         -0.0718      0.605     -0.119      0.905      -1.257       1.113
human_difficulty                      0.4772      0.302      1.581      0.114      -0.114       1.069
q_length                             -0.1508      0.266     -0.566      0.571      -0.673       0.371
avg_word_length                      -0.2293      0.320     -0.716      0.474      -0.857       0.399
percent_non_alphabetic_whitespace    -0.0051      0.033     -0.155      0.877      -0.069       0.059
capabilities_entropy                 15.0439      9.866      1.525      0.127      -4.293      34.381
game_entropy                          2.6495      2.190      1.210      0.226      -1.644       6.943
=====================================================================================================

--- Analyzing gemini-2.5-flash-preview-04-17 (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/gemini-2.5-flash-preview-04-17_GPQA_redacted_cor_temp0.0_1751803003_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    240
1     97
Name: count, dtype: int64

Answer change%: 0.2878 [0.2394951544724986, 0.33617250131385157] (n=337)
P-value vs 25%: 0.125; P-value vs 0%: 1.8e-31
Phase 2 self-accuracy: 0.1649 [0.09109122787824837, 0.23880567933824648] (n=97)
P-value vs 25%: 0.02401; P-value vs 33%: 8.211e-06

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  336
Model:                          Logit   Df Residuals:                      334
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.01462
Time:                        21:14:16   Log-Likelihood:                -198.98
converged:                       True   LL-Null:                       -201.93
Covariance Type:            nonrobust   LLR p-value:                   0.01512
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.0049      0.130     -7.759      0.000      -1.259      -0.751
game_entropy     0.9209      0.379      2.433      0.015       0.179       1.663
================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  337
Model:                          Logit   Df Residuals:                      335
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:               2.698e-06
Time:                        21:14:16   Log-Likelihood:                -202.27
converged:                       True   LL-Null:                       -202.27
Covariance Type:            nonrobust   LLR p-value:                    0.9736
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -0.8895      0.510     -1.744      0.081      -1.889       0.110
human_difficulty    -0.0071      0.214     -0.033      0.974      -0.427       0.413
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  337
Model:                          Logit   Df Residuals:                      330
Method:                           MLE   Df Model:                            6
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.03083
Time:                        21:14:16   Log-Likelihood:                -196.03
converged:                       True   LL-Null:                       -202.27
Covariance Type:            nonrobust   LLR p-value:                   0.05226
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -3.3519      1.822     -1.840      0.066      -6.922       0.219
C(domain_grouped)[T.chemistry]        0.7622      0.446      1.708      0.088      -0.112       1.637
C(domain_grouped)[T.physics]          1.1576      0.438      2.645      0.008       0.300       2.016
human_difficulty                      0.1191      0.220      0.541      0.589      -0.313       0.551
q_length                              0.1165      0.209      0.558      0.577      -0.293       0.526
avg_word_length                       0.0852      0.196      0.434      0.664      -0.299       0.469
percent_non_alphabetic_whitespace     0.0280      0.021      1.324      0.186      -0.013       0.069
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  336
Model:                          Logit   Df Residuals:                      328
Method:                           MLE   Df Model:                            7
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.04147
Time:                        21:14:16   Log-Likelihood:                -193.55
converged:                       True   LL-Null:                       -201.93
Covariance Type:            nonrobust   LLR p-value:                   0.01910
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -3.1546      1.831     -1.723      0.085      -6.743       0.433
C(domain_grouped)[T.chemistry]        0.6346      0.453      1.401      0.161      -0.253       1.522
C(domain_grouped)[T.physics]          1.1002      0.441      2.497      0.013       0.237       1.964
human_difficulty                      0.0612      0.223      0.274      0.784      -0.376       0.498
q_length                              0.1040      0.211      0.492      0.622      -0.310       0.518
avg_word_length                       0.0912      0.196      0.464      0.642      -0.294       0.476
percent_non_alphabetic_whitespace     0.0249      0.021      1.170      0.242      -0.017       0.067
game_entropy                          0.7908      0.388      2.038      0.042       0.030       1.551
=====================================================================================================

--- Analyzing gemini-2.5-flash-preview-04-17 (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/gemini-2.5-flash-preview-04-17_GPQA_redacted_temp0.0_1751720035_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
1    55
0    51
Name: count, dtype: int64

Answer change%: 0.5189 [0.42375145415210347, 0.6139843949045003] (n=106)
P-value vs 25%: 3.02e-08; P-value vs 0%: 1.112e-26
Phase 2 self-accuracy: 0.5455 [0.4138609695693659, 0.6770481213397249] (n=55)
P-value vs 25%: 1.08e-05; P-value vs 33%: 0.001554

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  105
Model:                          Logit   Df Residuals:                      103
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:               0.0001199
Time:                        21:14:16   Log-Likelihood:                -72.653
converged:                       True   LL-Null:                       -72.661
Covariance Type:            nonrobust   LLR p-value:                    0.8950
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept        0.1076      0.216      0.497      0.619      -0.316       0.532
game_entropy    -0.0673      0.510     -0.132      0.895      -1.066       0.932
================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  106
Model:                          Logit   Df Residuals:                      104
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:               0.0002191
Time:                        21:14:16   Log-Likelihood:                -73.382
converged:                       True   LL-Null:                       -73.398
Covariance Type:            nonrobust   LLR p-value:                    0.8577
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -0.0799      0.888     -0.090      0.928      -1.821       1.661
human_difficulty     0.0614      0.343      0.179      0.858      -0.610       0.733
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  106
Model:                          Logit   Df Residuals:                       99
Method:                           MLE   Df Model:                            6
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.04391
Time:                        21:14:16   Log-Likelihood:                -70.175
converged:                       True   LL-Null:                       -73.398
Covariance Type:            nonrobust   LLR p-value:                    0.3751
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                             2.5922      3.331      0.778      0.436      -3.937       9.122
C(domain_grouped)[T.chemistry]       -0.1831      0.629     -0.291      0.771      -1.415       1.049
C(domain_grouped)[T.physics]         -0.5180      0.706     -0.734      0.463      -1.901       0.865
human_difficulty                      0.3090      0.379      0.815      0.415      -0.435       1.053
q_length                             -0.2675      0.306     -0.875      0.382      -0.867       0.332
avg_word_length                      -0.3980      0.381     -1.045      0.296      -1.145       0.349
percent_non_alphabetic_whitespace     0.0452      0.045      1.005      0.315      -0.043       0.133
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  105
Model:                          Logit   Df Residuals:                       97
Method:                           MLE   Df Model:                            7
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.04885
Time:                        21:14:16   Log-Likelihood:                -69.112
converged:                       True   LL-Null:                       -72.661
Covariance Type:            nonrobust   LLR p-value:                    0.4186
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                             3.5214      3.434      1.025      0.305      -3.209      10.252
C(domain_grouped)[T.chemistry]       -0.1013      0.648     -0.156      0.876      -1.371       1.168
C(domain_grouped)[T.physics]         -0.5955      0.713     -0.836      0.403      -1.992       0.801
human_difficulty                      0.3363      0.384      0.875      0.381      -0.417       1.089
q_length                             -0.2922      0.308     -0.949      0.343      -0.896       0.312
avg_word_length                      -0.5443      0.402     -1.354      0.176      -1.332       0.244
percent_non_alphabetic_whitespace     0.0307      0.046      0.664      0.507      -0.060       0.121
game_entropy                         -0.2588      0.551     -0.470      0.639      -1.339       0.821
=====================================================================================================

--- Analyzing gemini-2.5-flash_nothink (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/gemini-2.5-flash_nothink_GPQA_redacted_cor_temp1.0_1758161812_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    170
1     48
Name: count, dtype: int64

Answer change%: 0.2202 [0.16517769325735276, 0.2751892792197115] (n=218)
P-value vs 25%: 0.288; P-value vs 0%: 4.31e-15
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=48)
P-value vs 25%: 0; P-value vs 33%: 0

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  218
Model:                          Logit   Df Residuals:                      216
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.1296
Time:                        21:14:16   Log-Likelihood:                -100.02
converged:                       True   LL-Null:                       -114.92
Covariance Type:            nonrobust   LLR p-value:                 4.804e-08
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          2.0105      0.624      3.220      0.001       0.787       3.234
p_i_capability    -4.1883      0.803     -5.216      0.000      -5.762      -2.614
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  218
Model:                          Logit   Df Residuals:                      216
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.1408
Time:                        21:14:16   Log-Likelihood:                -98.740
converged:                       True   LL-Null:                       -114.92
Covariance Type:            nonrobust   LLR p-value:                 1.285e-08
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.4311      0.313     -7.768      0.000      -3.044      -1.818
capabilities_entropy     1.5067      0.283      5.323      0.000       0.952       2.061
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.6250 [0.4880, 0.7620] (n=48)
                  P-value vs 33.3%: 2.993e-05

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=9.00, p=4.85e-16
Wilcoxon delta_p: statistic=1540.00, p=8.19e-19
Mean Δp = 0.1145  [0.0895, 0.1394]
Idea 1 N = 169; 

  Idea 1.5: Calibration Metrics
  NLL: 0.2317, Signed ECE (overconf pos under neg): -0.1735, ECE: 0.1735 (n=218)
  Brier: 0.0726, Reliability (absolute calibration error; lower better): 0.0718, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=218)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.531
Model:                            OLS   Adj. R-squared:                  0.524
Method:                 Least Squares   F-statistic:                     80.40
Date:                Fri, 19 Sep 2025   Prob (F-statistic):           8.07e-35
Time:                        21:14:16   Log-Likelihood:                 99.863
No. Observations:                 217   AIC:                            -191.7
Df Residuals:                     213   BIC:                            -178.2
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept             0.0228      0.058      0.391      0.697      -0.092       0.138
p1                    0.1051      0.066      1.602      0.111      -0.024       0.234
answer_changed       -0.2526      0.096     -2.637      0.009      -0.441      -0.064
p1:answer_changed     0.8680      0.126      6.910      0.000       0.620       1.116
==============================================================================
Omnibus:                       14.390   Durbin-Watson:                   1.799
Prob(Omnibus):                  0.001   Jarque-Bera (JB):               15.635
Skew:                           0.572   Prob(JB):                     0.000403
Kurtosis:                       3.647   Cond. No.                         21.1
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-4.31, p=2.72e-05
Wilcoxon delta_H: statistic=4568.00, p=2.66e-05
Mean ΔH = -0.1642  [-0.2387, -0.0896]
Paired t-test delta_H Changed: statistic=-1.83, p=0.0732
Wilcoxon delta_H Changed: statistic=403.00, p=0.058
Mean ΔH Changed = -0.1017  [-0.2104, 0.0071]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=-11.74, p=5.99e-25
Wilcoxon (p_top2_game vs p_top2_base): statistic=1140.00, p=5.29e-31
Mean Δp_top2 = -0.0809  [-0.0945, -0.0674] (n=218)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=-4.69, p=4.88e-06
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=7635.00, p=3.98e-06
Mean ΔH_unchosen_baseline_set = -0.1504  [-0.2133, -0.0875] (n=218)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  218
Model:                          Logit   Df Residuals:                      215
Method:                           MLE   Df Model:                            2
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.1545
Time:                        21:14:16   Log-Likelihood:                -97.156
converged:                       True   LL-Null:                       -114.92
Covariance Type:            nonrobust   LLR p-value:                 1.936e-08
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.1233      0.234     -4.806      0.000      -1.581      -0.665
p1_z            -1.3991      0.291     -4.810      0.000      -1.969      -0.829
I(p1_z ** 2)    -0.4316      0.182     -2.375      0.018      -0.788      -0.075
================================================================================
AUC = 0.782

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  218
Model:                          Logit   Df Residuals:                      216
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.1803
Time:                        21:14:16   Log-Likelihood:                -94.196
converged:                       True   LL-Null:                       -114.92
Covariance Type:            nonrobust   LLR p-value:                 1.214e-10
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -3.7179      0.553     -6.729      0.000      -4.801      -2.635
game_entropy     1.9968      0.371      5.386      0.000       1.270       2.723
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=1591.00, p=1.33e-28
Paired t-test (game_entropy vs capabilities_entropy): statistic=13.34, p=4.95e-30
Mean capabilities_entropy-game_entropy = -0.3989  [-0.4575, -0.3403] (n=218)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  218
Model:                          Logit   Df Residuals:                      215
Method:                           MLE   Df Model:                            2
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.1889
Time:                        21:14:16   Log-Likelihood:                -93.213
converged:                       True   LL-Null:                       -114.92
Covariance Type:            nonrobust   LLR p-value:                 3.752e-10
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -3.5895      0.549     -6.538      0.000      -4.665      -2.513
capabilities_entropy     0.5451      0.393      1.388      0.165      -0.225       1.315
game_entropy             1.5467      0.485      3.188      0.001       0.596       2.498
========================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  218
Model:                          Logit   Df Residuals:                      216
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:               0.0004477
Time:                        21:14:16   Log-Likelihood:                -114.87
converged:                       True   LL-Null:                       -114.92
Covariance Type:            nonrobust   LLR p-value:                    0.7484
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -1.0321      0.741     -1.392      0.164      -2.485       0.421
human_difficulty    -0.0979      0.305     -0.321      0.749      -0.696       0.501
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  218
Model:                          Logit   Df Residuals:                      211
Method:                           MLE   Df Model:                            6
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.03084
Time:                        21:14:16   Log-Likelihood:                -111.37
converged:                       True   LL-Null:                       -114.92
Covariance Type:            nonrobust   LLR p-value:                    0.3127
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -3.0227      2.445     -1.236      0.216      -7.815       1.770
C(domain_grouped)[T.chemistry]        1.0796      0.525      2.057      0.040       0.051       2.108
C(domain_grouped)[T.physics]          0.6149      0.530      1.161      0.246      -0.423       1.653
human_difficulty                      0.0245      0.314      0.078      0.938      -0.591       0.639
q_length                              0.3539      0.280      1.265      0.206      -0.194       0.902
avg_word_length                      -0.2059      0.276     -0.745      0.456      -0.748       0.336
percent_non_alphabetic_whitespace    -0.0138      0.029     -0.480      0.631      -0.070       0.043
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 0.6210
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  218
Model:                          Logit   Df Residuals:                      210
Method:                           MLE   Df Model:                            7
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.1459
Time:                        21:14:16   Log-Likelihood:                -98.145
converged:                       True   LL-Null:                       -114.92
Covariance Type:            nonrobust   LLR p-value:                 2.097e-05
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -3.0390      2.563     -1.186      0.236      -8.062       1.984
C(domain_grouped)[T.chemistry]        0.4030      0.572      0.704      0.481      -0.719       1.525
C(domain_grouped)[T.physics]          0.0484      0.586      0.083      0.934      -1.100       1.197
human_difficulty                     -0.0647      0.347     -0.186      0.852      -0.746       0.616
q_length                              0.0638      0.303      0.210      0.833      -0.531       0.658
avg_word_length                       0.0429      0.282      0.152      0.879      -0.510       0.595
percent_non_alphabetic_whitespace     0.0038      0.029      0.132      0.895      -0.053       0.060
capabilities_entropy                  1.4794      0.309      4.789      0.000       0.874       2.085
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  218
Model:                          Logit   Df Residuals:                      210
Method:                           MLE   Df Model:                            7
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.1846
Time:                        21:14:16   Log-Likelihood:                -93.706
converged:                       True   LL-Null:                       -114.92
Covariance Type:            nonrobust   LLR p-value:                 4.315e-07
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -4.2532      2.631     -1.617      0.106      -9.410       0.903
C(domain_grouped)[T.chemistry]        0.3208      0.574      0.559      0.576      -0.804       1.446
C(domain_grouped)[T.physics]          0.1784      0.591      0.302      0.763      -0.981       1.337
human_difficulty                     -0.0847      0.356     -0.238      0.812      -0.782       0.612
q_length                              0.1356      0.298      0.455      0.649      -0.449       0.720
avg_word_length                      -0.0170      0.283     -0.060      0.952      -0.572       0.538
percent_non_alphabetic_whitespace    -0.0154      0.029     -0.539      0.590      -0.071       0.041
game_entropy                          1.9574      0.391      5.009      0.000       1.191       2.723
=====================================================================================================

                  Model 4.95: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  218
Model:                          Logit   Df Residuals:                      209
Method:                           MLE   Df Model:                            8
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.1918
Time:                        21:14:16   Log-Likelihood:                -92.872
converged:                       True   LL-Null:                       -114.92
Covariance Type:            nonrobust   LLR p-value:                 5.475e-07
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -3.8997      2.647     -1.473      0.141      -9.089       1.289
C(domain_grouped)[T.chemistry]        0.2315      0.582      0.398      0.691      -0.910       1.373
C(domain_grouped)[T.physics]          0.0364      0.607      0.060      0.952      -1.153       1.226
human_difficulty                     -0.1106      0.360     -0.307      0.759      -0.816       0.595
q_length                              0.0715      0.305      0.234      0.815      -0.526       0.669
avg_word_length                       0.0302      0.285      0.106      0.916      -0.528       0.588
percent_non_alphabetic_whitespace    -0.0096      0.029     -0.332      0.740      -0.066       0.047
capabilities_entropy                  0.5318      0.415      1.280      0.200      -0.282       1.346
game_entropy                          1.5485      0.499      3.104      0.002       0.571       2.526
=====================================================================================================

--- Analyzing gemini-2.5-flash_nothink (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/gemini-2.5-flash_nothink_GPQA_redacted_temp1.0_1758161699_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    144
1     85
Name: count, dtype: int64

Answer change%: 0.3712 [0.30860624113884105, 0.433751837463779] (n=229)
P-value vs 25%: 0.0001472; P-value vs 0%: 3.025e-31
Phase 2 self-accuracy: 0.5059 [0.39959573806129894, 0.6121689678210539] (n=85)
P-value vs 25%: 2.375e-06; P-value vs 33%: 0.001433

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  229
Model:                          Logit   Df Residuals:                      227
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.03339
Time:                        21:14:16   Log-Likelihood:                -146.00
converged:                       True   LL-Null:                       -151.04
Covariance Type:            nonrobust   LLR p-value:                  0.001493
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          0.8154      0.445      1.830      0.067      -0.058       1.689
p_i_capability    -1.9707      0.632     -3.116      0.002      -3.210      -0.731
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  229
Model:                          Logit   Df Residuals:                      227
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.03054
Time:                        21:14:16   Log-Likelihood:                -146.43
converged:                       True   LL-Null:                       -151.04
Covariance Type:            nonrobust   LLR p-value:                  0.002387
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.2556      0.290     -4.331      0.000      -1.824      -0.687
capabilities_entropy     0.6717      0.226      2.967      0.003       0.228       1.115
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.6588 [0.5580, 0.7596] (n=85)
                  P-value vs 33.3%: 2.459e-10

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=10.52, p=1.62e-19
Wilcoxon delta_p: statistic=1089.00, p=1.74e-16
Mean Δp = 0.1519  [0.1236, 0.1803]
Idea 1 N = 144; 

  Idea 1.5: Calibration Metrics
  NLL: 3.1572, Signed ECE (overconf pos under neg): 0.1155, ECE: 0.1155 (n=229)
  Brier: 0.0264, Reliability (absolute calibration error; lower better): 0.0256, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=229)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.643
Model:                            OLS   Adj. R-squared:                  0.638
Method:                 Least Squares   F-statistic:                     133.0
Date:                Fri, 19 Sep 2025   Prob (F-statistic):           2.48e-49
Time:                        21:14:16   Log-Likelihood:                 125.61
No. Observations:                 226   AIC:                            -243.2
Df Residuals:                     222   BIC:                            -229.5
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.0674      0.039     -1.710      0.089      -0.145       0.010
p1                    0.3006      0.052      5.824      0.000       0.199       0.402
answer_changed       -0.1172      0.064     -1.843      0.067      -0.243       0.008
p1:answer_changed     0.6647      0.091      7.298      0.000       0.485       0.844
==============================================================================
Omnibus:                        1.039   Durbin-Watson:                   1.931
Prob(Omnibus):                  0.595   Jarque-Bera (JB):                1.039
Skew:                           0.033   Prob(JB):                        0.595
Kurtosis:                       2.674   Cond. No.                         16.5
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-7.70, p=2.04e-12
Wilcoxon delta_H: statistic=1732.00, p=3.5e-12
Mean ΔH = -0.2450  [-0.3074, -0.1826]
Paired t-test delta_H Changed: statistic=-2.13, p=0.0365
Wilcoxon delta_H Changed: statistic=1294.00, p=0.0194
Mean ΔH Changed = -0.0895  [-0.1721, -0.0069]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=-15.70, p=3.87e-38
Wilcoxon (p_top2_game vs p_top2_base): statistic=1338.00, p=4.58e-32
Mean Δp_top2 = -0.1137  [-0.1279, -0.0995] (n=229)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=-7.25, p=6.26e-12
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=6167.00, p=3.06e-12
Mean ΔH_unchosen_baseline_set = -0.1873  [-0.2379, -0.1367] (n=229)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  229
Model:                          Logit   Df Residuals:                      226
Method:                           MLE   Df Model:                            2
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.04022
Time:                        21:14:16   Log-Likelihood:                -144.97
converged:                       True   LL-Null:                       -151.04
Covariance Type:            nonrobust   LLR p-value:                  0.002301
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.2957      0.226     -1.309      0.191      -0.739       0.147
p1_z            -0.4752      0.147     -3.222      0.001      -0.764      -0.186
I(p1_z ** 2)    -0.2687      0.188     -1.429      0.153      -0.637       0.100
================================================================================
AUC = 0.629

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  229
Model:                          Logit   Df Residuals:                      227
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.03844
Time:                        21:14:16   Log-Likelihood:                -145.24
converged:                       True   LL-Null:                       -151.04
Covariance Type:            nonrobust   LLR p-value:                 0.0006556
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -2.0669      0.517     -4.001      0.000      -3.079      -1.054
game_entropy     1.0348      0.325      3.186      0.001       0.398       1.671
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=2406.00, p=7.99e-27
Paired t-test (game_entropy vs capabilities_entropy): statistic=12.98, p=3.14e-29
Mean capabilities_entropy-game_entropy = -0.4010  [-0.4615, -0.3404] (n=229)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  229
Model:                          Logit   Df Residuals:                      226
Method:                           MLE   Df Model:                            2
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.04162
Time:                        21:14:16   Log-Likelihood:                -144.76
converged:                       True   LL-Null:                       -151.04
Covariance Type:            nonrobust   LLR p-value:                  0.001861
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.9812      0.518     -3.823      0.000      -2.997      -0.965
capabilities_entropy     0.2954      0.303      0.976      0.329      -0.298       0.889
game_entropy             0.7618      0.425      1.793      0.073      -0.071       1.594
========================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  229
Model:                          Logit   Df Residuals:                      227
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                0.001200
Time:                        21:14:16   Log-Likelihood:                -150.86
converged:                       True   LL-Null:                       -151.04
Covariance Type:            nonrobust   LLR p-value:                    0.5472
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -0.8481      0.551     -1.538      0.124      -1.929       0.233
human_difficulty     0.1357      0.225      0.602      0.547      -0.306       0.577
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  229
Model:                          Logit   Df Residuals:                      222
Method:                           MLE   Df Model:                            6
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.02444
Time:                        21:14:16   Log-Likelihood:                -147.35
converged:                       True   LL-Null:                       -151.04
Covariance Type:            nonrobust   LLR p-value:                    0.2869
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -2.6255      2.152     -1.220      0.222      -6.843       1.592
C(domain_grouped)[T.chemistry]       -0.1018      0.489     -0.208      0.835      -1.060       0.856
C(domain_grouped)[T.physics]         -0.1662      0.507     -0.328      0.743      -1.160       0.828
human_difficulty                     -0.0354      0.239     -0.148      0.882      -0.504       0.433
q_length                              0.3660      0.230      1.594      0.111      -0.084       0.816
avg_word_length                       0.0935      0.239      0.391      0.696      -0.375       0.562
percent_non_alphabetic_whitespace    -0.0359      0.030     -1.184      0.236      -0.095       0.024
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 1.0479
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  229
Model:                          Logit   Df Residuals:                      221
Method:                           MLE   Df Model:                            7
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.05967
Time:                        21:14:16   Log-Likelihood:                -142.03
converged:                       True   LL-Null:                       -151.04
Covariance Type:            nonrobust   LLR p-value:                   0.01186
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -3.6577      2.297     -1.593      0.111      -8.159       0.843
C(domain_grouped)[T.chemistry]       -0.4089      0.509     -0.803      0.422      -1.407       0.589
C(domain_grouped)[T.physics]         -0.4409      0.525     -0.840      0.401      -1.470       0.588
human_difficulty                     -0.0717      0.245     -0.293      0.769      -0.551       0.408
q_length                              0.3541      0.236      1.499      0.134      -0.109       0.817
avg_word_length                       0.2148      0.265      0.811      0.417      -0.304       0.734
percent_non_alphabetic_whitespace    -0.0286      0.032     -0.891      0.373      -0.091       0.034
capabilities_entropy                  0.7662      0.243      3.154      0.002       0.290       1.242
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  229
Model:                          Logit   Df Residuals:                      221
Method:                           MLE   Df Model:                            7
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.07086
Time:                        21:14:16   Log-Likelihood:                -140.34
converged:                       True   LL-Null:                       -151.04
Covariance Type:            nonrobust   LLR p-value:                  0.003212
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -3.9327      2.314     -1.700      0.089      -8.467       0.602
C(domain_grouped)[T.chemistry]       -0.6579      0.537     -1.225      0.221      -1.711       0.395
C(domain_grouped)[T.physics]         -0.6698      0.552     -1.213      0.225      -1.752       0.412
human_difficulty                     -0.0429      0.244     -0.176      0.861      -0.521       0.436
q_length                              0.2928      0.239      1.223      0.221      -0.177       0.762
avg_word_length                       0.1731      0.261      0.663      0.508      -0.339       0.685
percent_non_alphabetic_whitespace    -0.0354      0.033     -1.087      0.277      -0.099       0.028
game_entropy                          1.2487      0.361      3.460      0.001       0.541       1.956
=====================================================================================================

                  Model 4.95: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  229
Model:                          Logit   Df Residuals:                      220
Method:                           MLE   Df Model:                            8
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.07490
Time:                        21:14:16   Log-Likelihood:                -139.73
converged:                       True   LL-Null:                       -151.04
Covariance Type:            nonrobust   LLR p-value:                  0.003879
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -4.1134      2.351     -1.750      0.080      -8.721       0.494
C(domain_grouped)[T.chemistry]       -0.6586      0.536     -1.230      0.219      -1.708       0.391
C(domain_grouped)[T.physics]         -0.6692      0.550     -1.217      0.224      -1.747       0.409
human_difficulty                     -0.0547      0.245     -0.223      0.824      -0.535       0.426
q_length                              0.3065      0.240      1.277      0.202      -0.164       0.777
avg_word_length                       0.2137      0.271      0.790      0.430      -0.317       0.744
percent_non_alphabetic_whitespace    -0.0323      0.033     -0.981      0.327      -0.097       0.032
capabilities_entropy                  0.3417      0.311      1.098      0.272      -0.268       0.951
game_entropy                          0.9429      0.451      2.089      0.037       0.058       1.828
=====================================================================================================

--- Analyzing gemini-2.5-flash_think (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/gemini-2.5-flash_think_GPQA_redacted_cor_temp1.0_1758262922_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    280
1     55
Name: count, dtype: int64

Answer change%: 0.1642 [0.12451101895488054, 0.20384719000034335] (n=335)
P-value vs 25%: 2.232e-05; P-value vs 0%: 4.982e-16
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=55)
P-value vs 25%: 0; P-value vs 33%: 0

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  310
Model:                          Logit   Df Residuals:                      308
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                0.001033
Time:                        21:14:16   Log-Likelihood:                -140.06
converged:                       True   LL-Null:                       -140.21
Covariance Type:            nonrobust   LLR p-value:                    0.5905
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept         -1.0631      0.992     -1.072      0.284      -3.007       0.880
p_i_capability    -0.5794      1.058     -0.547      0.584      -2.654       1.495
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  335
Model:                          Logit   Df Residuals:                      333
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:               0.0009671
Time:                        21:14:16   Log-Likelihood:                -149.44
converged:                       True   LL-Null:                       -149.59
Covariance Type:            nonrobust   LLR p-value:                    0.5907
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.6781      0.177     -9.507      0.000      -2.024      -1.332
capabilities_entropy     0.1721      0.316      0.544      0.587      -0.448       0.792
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.1154 [0.0285, 0.2022] (n=52)
                  P-value vs 33.3%: 8.685e-07

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=3.80, p=0.00018
Wilcoxon delta_p: statistic=14553.00, p=0.568
Mean Δp = 0.0505  [0.0245, 0.0765]
Idea 1 N = 246; 

  Idea 1.5: Calibration Metrics
  NLL: 0.4692, Signed ECE (overconf pos under neg): -0.1469, ECE: 0.1469 (n=309)
  Brier: 0.1169, Reliability (absolute calibration error; lower better): 0.1166, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=309)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.719
Model:                            OLS   Adj. R-squared:                  0.716
Method:                 Least Squares   F-statistic:                     237.4
Date:                Fri, 19 Sep 2025   Prob (F-statistic):           2.36e-76
Time:                        21:14:16   Log-Likelihood:                 75.870
No. Observations:                 282   AIC:                            -143.7
Df Residuals:                     278   BIC:                            -129.2
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept             0.5617      0.091      6.203      0.000       0.383       0.740
p1                   -0.5407      0.095     -5.695      0.000      -0.728      -0.354
answer_changed       -0.6740      0.226     -2.988      0.003      -1.118      -0.230
p1:answer_changed     1.6400      0.241      6.804      0.000       1.165       2.115
==============================================================================
Omnibus:                      104.833   Durbin-Watson:                   1.986
Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1260.420
Skew:                           1.129   Prob(JB):                    2.01e-274
Kurtosis:                      13.108   Cond. No.                         41.8
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=1.67, p=0.0954
Wilcoxon delta_H: statistic=14471.00, p=0.0775
Mean ΔH = 0.0631  [-0.0108, 0.1370]
Paired t-test delta_H Changed: statistic=7.85, p=2.48e-10
Wilcoxon delta_H Changed: statistic=97.00, p=7e-08
Mean ΔH Changed = 0.7040  [0.5283, 0.8798]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=3.76, p=0.000203
Wilcoxon (p_top2_game vs p_top2_base): statistic=17450.00, p=3.57e-05
Mean Δp_top2 = 0.0093  [0.0045, 0.0141] (n=309)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=4.58, p=6.77e-06
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=17164.00, p=1.59e-05
Mean ΔH_unchosen_baseline_set = 0.1710  [0.0978, 0.2441] (n=309)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  309
Model:                          Logit   Df Residuals:                      306
Method:                           MLE   Df Model:                            2
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                0.003790
Time:                        21:14:16   Log-Likelihood:                -139.49
converged:                       True   LL-Null:                       -140.03
Covariance Type:            nonrobust   LLR p-value:                    0.5882
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.4812      0.202     -7.315      0.000      -1.878      -1.084
p1_z            -0.3519      0.340     -1.036      0.300      -1.018       0.314
I(p1_z ** 2)    -0.1243      0.145     -0.855      0.392      -0.409       0.161
================================================================================
AUC = 0.533

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  335
Model:                          Logit   Df Residuals:                      333
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.02822
Time:                        21:14:16   Log-Likelihood:                -145.37
converged:                       True   LL-Null:                       -149.59
Covariance Type:            nonrobust   LLR p-value:                  0.003666
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.8548      0.174    -10.632      0.000      -2.197      -1.513
game_entropy     1.2174      0.403      3.021      0.003       0.427       2.007
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=19370.00, p=7.67e-07
Paired t-test (game_entropy vs capabilities_entropy): statistic=-5.43, p=1.1e-07
Mean capabilities_entropy-game_entropy = 0.1337  [0.0854, 0.1820] (n=335)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  335
Model:                          Logit   Df Residuals:                      332
Method:                           MLE   Df Model:                            2
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.02914
Time:                        21:14:16   Log-Likelihood:                -145.23
converged:                       True   LL-Null:                       -149.59
Covariance Type:            nonrobust   LLR p-value:                   0.01279
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.8171      0.187     -9.695      0.000      -2.184      -1.450
capabilities_entropy    -0.1864      0.359     -0.519      0.604      -0.890       0.517
game_entropy             1.3069      0.439      2.977      0.003       0.446       2.167
========================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  335
Model:                          Logit   Df Residuals:                      333
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:               0.0005827
Time:                        21:14:16   Log-Likelihood:                -149.50
converged:                       True   LL-Null:                       -149.59
Covariance Type:            nonrobust   LLR p-value:                    0.6763
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -1.8810      0.627     -3.001      0.003      -3.110      -0.652
human_difficulty     0.1086      0.260      0.418      0.676      -0.400       0.618
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  335
Model:                          Logit   Df Residuals:                      328
Method:                           MLE   Df Model:                            6
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.05542
Time:                        21:14:16   Log-Likelihood:                -141.30
converged:                       True   LL-Null:                       -149.59
Covariance Type:            nonrobust   LLR p-value:                   0.01095
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                             0.4365      2.051      0.213      0.831      -3.583       4.456
C(domain_grouped)[T.chemistry]        0.3655      0.492      0.742      0.458      -0.600       1.331
C(domain_grouped)[T.physics]         -0.1663      0.501     -0.332      0.740      -1.148       0.816
human_difficulty                      0.2808      0.287      0.979      0.327      -0.281       0.843
q_length                             -0.7008      0.248     -2.820      0.005      -1.188      -0.214
avg_word_length                       0.2129      0.212      1.005      0.315      -0.202       0.628
percent_non_alphabetic_whitespace     0.0330      0.024      1.371      0.170      -0.014       0.080
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 0.2824
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  335
Model:                          Logit   Df Residuals:                      327
Method:                           MLE   Df Model:                            7
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.05618
Time:                        21:14:16   Log-Likelihood:                -141.19
converged:                       True   LL-Null:                       -149.59
Covariance Type:            nonrobust   LLR p-value:                   0.01869
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                             0.5654      2.063      0.274      0.784      -3.478       4.609
C(domain_grouped)[T.chemistry]        0.2991      0.513      0.583      0.560      -0.707       1.305
C(domain_grouped)[T.physics]         -0.1982      0.508     -0.390      0.696      -1.194       0.797
human_difficulty                      0.2483      0.294      0.843      0.399      -0.329       0.825
q_length                             -0.7200      0.252     -2.855      0.004      -1.214      -0.226
avg_word_length                       0.2225      0.211      1.053      0.292      -0.192       0.637
percent_non_alphabetic_whitespace     0.0336      0.024      1.398      0.162      -0.013       0.081
capabilities_entropy                  0.1693      0.353      0.479      0.632      -0.523       0.862
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  335
Model:                          Logit   Df Residuals:                      327
Method:                           MLE   Df Model:                            7
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.07833
Time:                        21:14:16   Log-Likelihood:                -137.87
converged:                       True   LL-Null:                       -149.59
Covariance Type:            nonrobust   LLR p-value:                  0.001431
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                             1.4135      2.138      0.661      0.509      -2.777       5.604
C(domain_grouped)[T.chemistry]        0.0792      0.518      0.153      0.878      -0.936       1.094
C(domain_grouped)[T.physics]         -0.2636      0.517     -0.510      0.610      -1.277       0.750
human_difficulty                      0.1935      0.293      0.661      0.509      -0.380       0.767
q_length                             -0.7978      0.258     -3.095      0.002      -1.303      -0.293
avg_word_length                       0.1615      0.218      0.740      0.459      -0.266       0.589
percent_non_alphabetic_whitespace     0.0290      0.024      1.189      0.234      -0.019       0.077
game_entropy                          1.1966      0.453      2.641      0.008       0.308       2.085
=====================================================================================================

                  Model 4.95: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  335
Model:                          Logit   Df Residuals:                      326
Method:                           MLE   Df Model:                            8
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.07881
Time:                        21:14:16   Log-Likelihood:                -137.80
converged:                       True   LL-Null:                       -149.59
Covariance Type:            nonrobust   LLR p-value:                  0.002697
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                             1.3613      2.152      0.633      0.527      -2.856       5.579
C(domain_grouped)[T.chemistry]        0.1212      0.530      0.229      0.819      -0.917       1.159
C(domain_grouped)[T.physics]         -0.2428      0.519     -0.468      0.640      -1.260       0.774
human_difficulty                      0.2170      0.300      0.724      0.469      -0.371       0.805
q_length                             -0.7872      0.259     -3.037      0.002      -1.295      -0.279
avg_word_length                       0.1502      0.222      0.676      0.499      -0.285       0.586
percent_non_alphabetic_whitespace     0.0282      0.025      1.150      0.250      -0.020       0.076
capabilities_entropy                 -0.1473      0.395     -0.373      0.709      -0.921       0.626
game_entropy                          1.2575      0.483      2.606      0.009       0.312       2.203
=====================================================================================================

--- Analyzing gemini-2.5-flash_think (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/gemini-2.5-flash_think_GPQA_redacted_temp1.0_1758250419_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    63
1    49
Name: count, dtype: int64

Answer change%: 0.4375 [0.34562668822468495, 0.529373311775315] (n=112)
P-value vs 25%: 6.334e-05; P-value vs 0%: 1.026e-20
Phase 2 self-accuracy: 0.7755 [0.6586835034090578, 0.8923369047542075] (n=49)
P-value vs 25%: 1.183e-18; P-value vs 33%: 1.138e-13

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  101
Model:                          Logit   Df Residuals:                       99
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.01211
Time:                        21:14:16   Log-Likelihood:                -68.331
converged:                       True   LL-Null:                       -69.169
Covariance Type:            nonrobust   LLR p-value:                    0.1955
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          1.3282      1.258      1.056      0.291      -1.137       3.794
p_i_capability    -1.7538      1.372     -1.279      0.201      -4.442       0.934
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  112
Model:                          Logit   Df Residuals:                      110
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.01568
Time:                        21:14:16   Log-Likelihood:                -75.552
converged:                       True   LL-Null:                       -76.755
Covariance Type:            nonrobust   LLR p-value:                    0.1208
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -0.4928      0.249     -1.979      0.048      -0.981      -0.005
capabilities_entropy     0.5910      0.384      1.539      0.124      -0.162       1.344
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.0682 [0.0000, 0.1427] (n=44)
                  P-value vs 33.3%: 2.998e-12

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=2.87, p=0.00587
Wilcoxon delta_p: statistic=448.00, p=0.0282
Mean Δp = 0.1072  [0.0341, 0.1803]
Idea 1 N = 53; 

  Idea 1.5: Calibration Metrics
  NLL: 10.3454, Signed ECE (overconf pos under neg): 0.0076, ECE: 0.0076 (n=38)
  Brier: 0.0018, Reliability (absolute calibration error; lower better): 0.0018, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=38)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.740
Model:                            OLS   Adj. R-squared:                  0.729
Method:                 Least Squares   F-statistic:                     70.14
Date:                Fri, 19 Sep 2025   Prob (F-statistic):           1.39e-21
Time:                        21:14:16   Log-Likelihood:                 6.5415
No. Observations:                  78   AIC:                            -5.083
Df Residuals:                      74   BIC:                             4.344
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept             0.5266      0.263      2.000      0.049       0.002       1.051
p1                   -0.4467      0.278     -1.604      0.113      -1.001       0.108
answer_changed       -0.8250      0.426     -1.938      0.056      -1.673       0.023
p1:answer_changed     1.7451      0.459      3.805      0.000       0.831       2.659
==============================================================================
Omnibus:                       25.293   Durbin-Watson:                   2.004
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               50.498
Skew:                           1.144   Prob(JB):                     1.08e-11
Kurtosis:                       6.209   Cond. No.                         37.9
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=2.08, p=0.0425
Wilcoxon delta_H: statistic=567.00, p=0.0392
Mean ΔH = 0.1703  [0.0095, 0.3310]
Paired t-test delta_H Changed: statistic=6.19, p=1.92e-07
Wilcoxon delta_H Changed: statistic=100.00, p=5.44e-07
Mean ΔH Changed = 0.5713  [0.3905, 0.7522]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=0.72, p=0.473
Wilcoxon (p_top2_game vs p_top2_base): statistic=1876.00, p=0.0178
Mean Δp_top2 = 0.0055  [-0.0095, 0.0205] (n=101)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=5.38, p=4.98e-07
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=1162.00, p=1.68e-06
Mean ΔH_unchosen_baseline_set = 0.3450  [0.2192, 0.4707] (n=101)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  101
Model:                          Logit   Df Residuals:                       98
Method:                           MLE   Df Model:                            2
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.01636
Time:                        21:14:16   Log-Likelihood:                -68.037
converged:                       True   LL-Null:                       -69.169
Covariance Type:            nonrobust   LLR p-value:                    0.3225
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.1335      0.263     -0.508      0.611      -0.648       0.381
p1_z            -0.4782      0.350     -1.366      0.172      -1.164       0.208
I(p1_z ** 2)    -0.1292      0.169     -0.766      0.444      -0.460       0.201
================================================================================
AUC = 0.632

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  112
Model:                          Logit   Df Residuals:                      110
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:               0.0002787
Time:                        21:14:16   Log-Likelihood:                -76.734
converged:                       True   LL-Null:                       -76.755
Covariance Type:            nonrobust   LLR p-value:                    0.8361
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.2262      0.226     -1.002      0.316      -0.669       0.216
game_entropy    -0.0944      0.457     -0.206      0.836      -0.991       0.802
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=2629.00, p=0.12
Paired t-test (game_entropy vs capabilities_entropy): statistic=-2.36, p=0.0199
Mean capabilities_entropy-game_entropy = 0.1356  [0.0231, 0.2481] (n=112)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  112
Model:                          Logit   Df Residuals:                      109
Method:                           MLE   Df Model:                            2
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.01692
Time:                        21:14:16   Log-Likelihood:                -75.456
converged:                       True   LL-Null:                       -76.755
Covariance Type:            nonrobust   LLR p-value:                    0.2728
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -0.4485      0.268     -1.672      0.095      -0.974       0.077
capabilities_entropy     0.6165      0.390      1.582      0.114      -0.147       1.380
game_entropy            -0.2043      0.469     -0.435      0.663      -1.124       0.716
========================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  112
Model:                          Logit   Df Residuals:                      110
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.03711
Time:                        21:14:16   Log-Likelihood:                -73.907
converged:                       True   LL-Null:                       -76.755
Covariance Type:            nonrobust   LLR p-value:                   0.01699
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept            1.8198      0.916      1.987      0.047       0.025       3.615
human_difficulty    -0.8302      0.362     -2.295      0.022      -1.539      -0.121
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  112
Model:                          Logit   Df Residuals:                      105
Method:                           MLE   Df Model:                            6
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.04573
Time:                        21:14:16   Log-Likelihood:                -73.245
converged:                       True   LL-Null:                       -76.755
Covariance Type:            nonrobust   LLR p-value:                    0.3190
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                             2.5418      3.285      0.774      0.439      -3.897       8.980
C(domain_grouped)[T.chemistry]        0.3078      0.583      0.528      0.598      -0.836       1.451
C(domain_grouped)[T.physics]          0.2576      0.678      0.380      0.704      -1.072       1.587
human_difficulty                     -0.8097      0.385     -2.100      0.036      -1.565      -0.054
q_length                              0.0661      0.300      0.220      0.826      -0.522       0.654
avg_word_length                      -0.2780      0.390     -0.712      0.476      -1.043       0.487
percent_non_alphabetic_whitespace    -0.0111      0.039     -0.283      0.778      -0.088       0.066
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 0.4028
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  112
Model:                          Logit   Df Residuals:                      104
Method:                           MLE   Df Model:                            7
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.05342
Time:                        21:14:16   Log-Likelihood:                -72.655
converged:                       True   LL-Null:                       -76.755
Covariance Type:            nonrobust   LLR p-value:                    0.3153
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                             2.6732      3.298      0.811      0.418      -3.790       9.136
C(domain_grouped)[T.chemistry]        0.1092      0.615      0.177      0.859      -1.097       1.315
C(domain_grouped)[T.physics]          0.2142      0.683      0.314      0.754      -1.125       1.553
human_difficulty                     -0.7986      0.386     -2.070      0.038      -1.555      -0.042
q_length                              0.0146      0.306      0.048      0.962      -0.585       0.614
avg_word_length                      -0.2581      0.393     -0.657      0.511      -1.028       0.512
percent_non_alphabetic_whitespace    -0.0130      0.040     -0.326      0.744      -0.091       0.065
capabilities_entropy                  0.4630      0.429      1.080      0.280      -0.377       1.303
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  112
Model:                          Logit   Df Residuals:                      104
Method:                           MLE   Df Model:                            7
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.04807
Time:                        21:14:16   Log-Likelihood:                -73.066
converged:                       True   LL-Null:                       -76.755
Covariance Type:            nonrobust   LLR p-value:                    0.3905
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                             2.2731      3.319      0.685      0.493      -4.231       8.777
C(domain_grouped)[T.chemistry]        0.4033      0.605      0.667      0.505      -0.782       1.588
C(domain_grouped)[T.physics]          0.3275      0.688      0.476      0.634      -1.020       1.675
human_difficulty                     -0.8029      0.387     -2.077      0.038      -1.560      -0.045
q_length                              0.0914      0.303      0.302      0.763      -0.503       0.685
avg_word_length                      -0.2625      0.393     -0.669      0.504      -1.032       0.507
percent_non_alphabetic_whitespace    -0.0064      0.040     -0.159      0.873      -0.085       0.073
game_entropy                         -0.2996      0.502     -0.597      0.551      -1.284       0.684
=====================================================================================================

                  Model 4.95: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  112
Model:                          Logit   Df Residuals:                      103
Method:                           MLE   Df Model:                            8
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.05594
Time:                        21:14:16   Log-Likelihood:                -72.462
converged:                       True   LL-Null:                       -76.755
Covariance Type:            nonrobust   LLR p-value:                    0.3783
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                             2.3985      3.329      0.720      0.471      -4.127       8.924
C(domain_grouped)[T.chemistry]        0.2059      0.634      0.325      0.745      -1.038       1.449
C(domain_grouped)[T.physics]          0.2863      0.692      0.414      0.679      -1.070       1.643
human_difficulty                     -0.7906      0.387     -2.044      0.041      -1.549      -0.032
q_length                              0.0404      0.309      0.131      0.896      -0.564       0.645
avg_word_length                      -0.2429      0.395     -0.615      0.538      -1.017       0.531
percent_non_alphabetic_whitespace    -0.0081      0.041     -0.199      0.842      -0.088       0.071
capabilities_entropy                  0.4697      0.430      1.092      0.275      -0.373       1.313
game_entropy                         -0.3121      0.503     -0.620      0.535      -1.298       0.674
=====================================================================================================

--- Analyzing gpt-4.1-2025-04-14 (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/gpt-4.1-2025-04-14_GPQA_redacted_cor_temp1.0_1757988295_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    155
1     63
Name: count, dtype: int64

Answer change%: 0.2890 [0.22881812910545582, 0.3491635222706909] (n=218)
P-value vs 25%: 0.2041; P-value vs 0%: 4.817e-21
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=63)
P-value vs 25%: 0; P-value vs 33%: 0

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  218
Model:                          Logit   Df Residuals:                      216
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.1334
Time:                        21:14:16   Log-Likelihood:                -113.58
converged:                       True   LL-Null:                       -131.07
Covariance Type:            nonrobust   LLR p-value:                 3.336e-09
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          6.3840      1.485      4.298      0.000       3.473       9.295
p_i_capability    -7.7251      1.551     -4.981      0.000     -10.765      -4.685
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  218
Model:                          Logit   Df Residuals:                      216
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.1589
Time:                        21:14:16   Log-Likelihood:                -110.24
converged:                       True   LL-Null:                       -131.07
Covariance Type:            nonrobust   LLR p-value:                 1.085e-10
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.4466      0.190     -7.629      0.000      -1.818      -1.075
capabilities_entropy     2.7475      0.493      5.576      0.000       1.782       3.713
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.6000 [0.4377, 0.7623] (n=35)
                  P-value vs 33.3%: 0.001281

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=0.95, p=0.358
Wilcoxon delta_p: statistic=57.00, p=0.378
Mean Δp = 0.0506  [-0.0541, 0.1554]
Idea 1 N = 17; 

  Idea 1.5: Calibration Metrics
  NLL: 0.1895, Signed ECE (overconf pos under neg): -0.1547, ECE: 0.1547 (n=41)
  Brier: 0.0504, Reliability (absolute calibration error; lower better): 0.0498, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=41)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.881
Model:                            OLS   Adj. R-squared:                  0.871
Method:                 Least Squares   F-statistic:                     91.34
Date:                Fri, 19 Sep 2025   Prob (F-statistic):           3.66e-17
Time:                        21:14:16   Log-Likelihood:                 24.394
No. Observations:                  41   AIC:                            -40.79
Df Residuals:                      37   BIC:                            -33.93
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -1.1909      0.294     -4.044      0.000      -1.788      -0.594
p1                    1.3273      0.313      4.244      0.000       0.694       1.961
answer_changed        1.2169      0.326      3.734      0.001       0.557       1.877
p1:answer_changed    -0.4320      0.358     -1.206      0.235      -1.158       0.294
==============================================================================
Omnibus:                        3.529   Durbin-Watson:                   1.541
Prob(Omnibus):                  0.171   Jarque-Bera (JB):                2.922
Skew:                          -0.146   Prob(JB):                        0.232
Kurtosis:                       4.275   Cond. No.                         44.0
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=0.03, p=0.979
Wilcoxon delta_H: statistic=71.00, p=0.818
Mean ΔH = 0.0030  [-0.2179, 0.2239]
Paired t-test delta_H Changed: statistic=0.68, p=0.505
Wilcoxon delta_H Changed: statistic=97.00, p=0.136
Mean ΔH Changed = 0.0512  [-0.0972, 0.1997]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=0.17, p=0.866
Wilcoxon (p_top2_game vs p_top2_base): statistic=357.00, p=0.348
Mean Δp_top2 = 0.0017  [-0.0180, 0.0214] (n=41)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=0.49, p=0.626
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=368.00, p=0.426
Mean ΔH_unchosen_baseline_set = 0.0312  [-0.0935, 0.1560] (n=41)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                   41
Model:                          Logit   Df Residuals:                       38
Method:                           MLE   Df Model:                            2
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.1920
Time:                        21:14:16   Log-Likelihood:                -22.477
converged:                       True   LL-Null:                       -27.819
Covariance Type:            nonrobust   LLR p-value:                  0.004789
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept        0.7936      0.581      1.366      0.172      -0.345       1.932
p1_z            -1.3762      0.500     -2.754      0.006      -2.356      -0.397
I(p1_z ** 2)    -0.2998      0.482     -0.622      0.534      -1.245       0.645
================================================================================
AUC = 0.801

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  218
Model:                          Logit   Df Residuals:                      216
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.07878
Time:                        21:14:16   Log-Likelihood:                -120.75
converged:                       True   LL-Null:                       -131.07
Covariance Type:            nonrobust   LLR p-value:                 5.509e-06
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.2635      0.180     -7.032      0.000      -1.616      -0.911
game_entropy     1.9515      0.452      4.316      0.000       1.065       2.838
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=5411.00, p=0.738
Paired t-test (game_entropy vs capabilities_entropy): statistic=-0.48, p=0.631
Mean capabilities_entropy-game_entropy = 0.0126  [-0.0386, 0.0637] (n=218)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  218
Model:                          Logit   Df Residuals:                      215
Method:                           MLE   Df Model:                            2
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.1810
Time:                        21:14:16   Log-Likelihood:                -107.34
converged:                       True   LL-Null:                       -131.07
Covariance Type:            nonrobust   LLR p-value:                 4.955e-11
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.5960      0.206     -7.763      0.000      -1.999      -1.193
capabilities_entropy     2.3785      0.507      4.692      0.000       1.385       3.372
game_entropy             1.2235      0.506      2.416      0.016       0.231       2.216
========================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  218
Model:                          Logit   Df Residuals:                      216
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:               0.0005544
Time:                        21:14:16   Log-Likelihood:                -131.00
converged:                       True   LL-Null:                       -131.07
Covariance Type:            nonrobust   LLR p-value:                    0.7030
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -0.6641      0.636     -1.044      0.296      -1.910       0.582
human_difficulty    -0.0998      0.262     -0.381      0.703      -0.613       0.414
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  218
Model:                          Logit   Df Residuals:                      211
Method:                           MLE   Df Model:                            6
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.03971
Time:                        21:14:16   Log-Likelihood:                -125.87
converged:                       True   LL-Null:                       -131.07
Covariance Type:            nonrobust   LLR p-value:                    0.1084
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -0.0536      2.403     -0.022      0.982      -4.764       4.657
C(domain_grouped)[T.chemistry]        0.9806      0.459      2.138      0.032       0.082       1.879
C(domain_grouped)[T.physics]          0.1418      0.448      0.316      0.752      -0.737       1.020
human_difficulty                     -0.0374      0.278     -0.135      0.893      -0.582       0.507
q_length                              0.3364      0.255      1.321      0.186      -0.163       0.836
avg_word_length                      -0.5937      0.314     -1.893      0.058      -1.209       0.021
percent_non_alphabetic_whitespace    -0.0536      0.034     -1.572      0.116      -0.120       0.013
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 0.1724
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  218
Model:                          Logit   Df Residuals:                      210
Method:                           MLE   Df Model:                            7
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.1735
Time:                        21:14:16   Log-Likelihood:                -108.32
converged:                       True   LL-Null:                       -131.07
Covariance Type:            nonrobust   LLR p-value:                 1.096e-07
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -2.2710      2.716     -0.836      0.403      -7.594       3.052
C(domain_grouped)[T.chemistry]        0.4524      0.508      0.891      0.373      -0.543       1.447
C(domain_grouped)[T.physics]         -0.1440      0.494     -0.291      0.771      -1.112       0.824
human_difficulty                     -0.0307      0.307     -0.100      0.920      -0.633       0.571
q_length                              0.3772      0.283      1.331      0.183      -0.178       0.933
avg_word_length                      -0.2748      0.342     -0.804      0.421      -0.944       0.395
percent_non_alphabetic_whitespace    -0.0200      0.037     -0.538      0.591      -0.093       0.053
capabilities_entropy                  2.6395      0.511      5.169      0.000       1.639       3.640
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  218
Model:                          Logit   Df Residuals:                      210
Method:                           MLE   Df Model:                            7
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.1037
Time:                        21:14:16   Log-Likelihood:                -117.48
converged:                       True   LL-Null:                       -131.07
Covariance Type:            nonrobust   LLR p-value:                 0.0003093
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -0.4769      2.513     -0.190      0.849      -5.402       4.449
C(domain_grouped)[T.chemistry]        0.8357      0.479      1.746      0.081      -0.102       1.774
C(domain_grouped)[T.physics]          0.0259      0.466      0.056      0.956      -0.888       0.940
human_difficulty                     -0.0188      0.291     -0.064      0.949      -0.590       0.552
q_length                              0.2244      0.264      0.851      0.395      -0.292       0.741
avg_word_length                      -0.4274      0.318     -1.342      0.180      -1.052       0.197
percent_non_alphabetic_whitespace    -0.0488      0.036     -1.358      0.174      -0.119       0.022
game_entropy                          1.8207      0.464      3.924      0.000       0.911       2.730
=====================================================================================================

                  Model 4.95: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  218
Model:                          Logit   Df Residuals:                      209
Method:                           MLE   Df Model:                            8
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.1928
Time:                        21:14:16   Log-Likelihood:                -105.80
converged:                       True   LL-Null:                       -131.07
Covariance Type:            nonrobust   LLR p-value:                 3.226e-08
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -2.1520      2.751     -0.782      0.434      -7.545       3.241
C(domain_grouped)[T.chemistry]        0.4155      0.514      0.808      0.419      -0.593       1.424
C(domain_grouped)[T.physics]         -0.1939      0.502     -0.386      0.699      -1.177       0.790
human_difficulty                     -0.0202      0.315     -0.064      0.949      -0.637       0.597
q_length                              0.2892      0.286      1.011      0.312      -0.272       0.850
avg_word_length                      -0.2152      0.340     -0.633      0.527      -0.882       0.451
percent_non_alphabetic_whitespace    -0.0209      0.038     -0.546      0.585      -0.096       0.054
capabilities_entropy                  2.3079      0.525      4.397      0.000       1.279       3.337
game_entropy                          1.1597      0.516      2.246      0.025       0.148       2.172
=====================================================================================================

--- Analyzing gpt-4.1-2025-04-14 (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/gpt-4.1-2025-04-14_GPQA_redacted_temp1.0_1757987232_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    118
1    111
Name: count, dtype: int64

Answer change%: 0.4847 [0.41998738629837884, 0.5494449281121015] (n=229)
P-value vs 25%: 1.185e-12; P-value vs 0%: 9.046e-49
Phase 2 self-accuracy: 0.4595 [0.3667499387033849, 0.5521689802155341] (n=111)
P-value vs 25%: 9.504e-06; P-value vs 33%: 0.007507

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  229
Model:                          Logit   Df Residuals:                      227
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.02008
Time:                        21:14:16   Log-Likelihood:                -155.44
converged:                       True   LL-Null:                       -158.62
Covariance Type:            nonrobust   LLR p-value:                   0.01160
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          1.8624      0.798      2.333      0.020       0.298       3.427
p_i_capability    -2.1494      0.876     -2.455      0.014      -3.866      -0.433
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  229
Model:                          Logit   Df Residuals:                      227
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.02753
Time:                        21:14:16   Log-Likelihood:                -154.26
converged:                       True   LL-Null:                       -158.62
Covariance Type:            nonrobust   LLR p-value:                  0.003122
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -0.3734      0.171     -2.181      0.029      -0.709      -0.038
capabilities_entropy     0.8335      0.290      2.875      0.004       0.265       1.402
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.6818 [0.5694, 0.7942] (n=66)
                  P-value vs 33.3%: 1.214e-09

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=-1.47, p=0.152
Wilcoxon delta_p: statistic=203.00, p=0.0674
Mean Δp = -0.0559  [-0.1306, 0.0188]
Idea 1 N = 35; 

  Idea 1.5: Calibration Metrics
  NLL: 6.2138, Signed ECE (overconf pos under neg): 0.0742, ECE: 0.0742 (n=78)
  Brier: 0.0189, Reliability (absolute calibration error; lower better): 0.0183, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=78)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.898
Model:                            OLS   Adj. R-squared:                  0.894
Method:                 Least Squares   F-statistic:                     217.1
Date:                Fri, 19 Sep 2025   Prob (F-statistic):           1.38e-36
Time:                        21:14:16   Log-Likelihood:                 43.505
No. Observations:                  78   AIC:                            -79.01
Df Residuals:                      74   BIC:                            -69.58
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.7551      0.106     -7.111      0.000      -0.967      -0.544
p1                    0.8417      0.125      6.760      0.000       0.594       1.090
answer_changed        0.6888      0.139      4.945      0.000       0.411       0.966
p1:answer_changed     0.1376      0.168      0.818      0.416      -0.198       0.473
==============================================================================
Omnibus:                        2.014   Durbin-Watson:                   2.011
Prob(Omnibus):                  0.365   Jarque-Bera (JB):                1.474
Skew:                           0.039   Prob(JB):                        0.479
Kurtosis:                       3.669   Cond. No.                         23.7
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=1.10, p=0.281
Wilcoxon delta_H: statistic=239.00, p=0.219
Mean ΔH = 0.1075  [-0.0848, 0.2998]
Paired t-test delta_H Changed: statistic=4.26, p=0.000114
Wilcoxon delta_H Changed: statistic=166.00, p=0.000109
Mean ΔH Changed = 0.3889  [0.2098, 0.5681]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=3.55, p=0.000653
Wilcoxon (p_top2_game vs p_top2_base): statistic=849.00, p=0.000573
Mean Δp_top2 = 0.0332  [0.0149, 0.0515] (n=78)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=3.84, p=0.000249
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=801.00, p=0.00023
Mean ΔH_unchosen_baseline_set = 0.2627  [0.1287, 0.3967] (n=78)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                   78
Model:                          Logit   Df Residuals:                       75
Method:                           MLE   Df Model:                            2
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.02954
Time:                        21:14:16   Log-Likelihood:                -52.069
converged:                       True   LL-Null:                       -53.655
Covariance Type:            nonrobust   LLR p-value:                    0.2049
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept        0.5560      0.376      1.478      0.139      -0.181       1.293
p1_z            -0.5237      0.299     -1.753      0.080      -1.109       0.062
I(p1_z ** 2)    -0.3425      0.290     -1.183      0.237      -0.910       0.225
================================================================================
AUC = 0.599

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  229
Model:                          Logit   Df Residuals:                      227
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.03700
Time:                        21:14:16   Log-Likelihood:                -152.75
converged:                       True   LL-Null:                       -158.62
Covariance Type:            nonrobust   LLR p-value:                 0.0006123
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.3593      0.160     -2.242      0.025      -0.673      -0.045
game_entropy     1.2289      0.375      3.274      0.001       0.493       1.965
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=7926.00, p=0.00101
Paired t-test (game_entropy vs capabilities_entropy): statistic=-3.82, p=0.000175
Mean capabilities_entropy-game_entropy = 0.1290  [0.0628, 0.1953] (n=229)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  229
Model:                          Logit   Df Residuals:                      226
Method:                           MLE   Df Model:                            2
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.04960
Time:                        21:14:16   Log-Likelihood:                -150.76
converged:                       True   LL-Null:                       -158.62
Covariance Type:            nonrobust   LLR p-value:                 0.0003830
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -0.5297      0.183     -2.887      0.004      -0.889      -0.170
capabilities_entropy     0.6005      0.304      1.976      0.048       0.005       1.196
game_entropy             1.0056      0.391      2.570      0.010       0.239       1.772
========================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  229
Model:                          Logit   Df Residuals:                      227
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                0.002000
Time:                        21:14:16   Log-Likelihood:                -158.31
converged:                       True   LL-Null:                       -158.62
Covariance Type:            nonrobust   LLR p-value:                    0.4257
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept            0.3741      0.563      0.664      0.507      -0.730       1.478
human_difficulty    -0.1838      0.231     -0.795      0.427      -0.637       0.270
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  229
Model:                          Logit   Df Residuals:                      222
Method:                           MLE   Df Model:                            6
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                0.008213
Time:                        21:14:16   Log-Likelihood:                -157.32
converged:                       True   LL-Null:                       -158.62
Covariance Type:            nonrobust   LLR p-value:                    0.8565
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                             0.3052      1.927      0.158      0.874      -3.471       4.081
C(domain_grouped)[T.chemistry]       -0.0711      0.534     -0.133      0.894      -1.117       0.975
C(domain_grouped)[T.physics]         -0.1298      0.565     -0.230      0.818      -1.236       0.977
human_difficulty                     -0.1958      0.242     -0.808      0.419      -0.671       0.279
q_length                              0.2021      0.222      0.911      0.363      -0.233       0.637
avg_word_length                      -0.1913      0.208     -0.918      0.359      -0.600       0.217
percent_non_alphabetic_whitespace    -0.0139      0.022     -0.621      0.534      -0.058       0.030
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 0.3786
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  229
Model:                          Logit   Df Residuals:                      221
Method:                           MLE   Df Model:                            7
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.03447
Time:                        21:14:16   Log-Likelihood:                -153.16
converged:                       True   LL-Null:                       -158.62
Covariance Type:            nonrobust   LLR p-value:                    0.1414
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -0.3441      1.961     -0.176      0.861      -4.187       3.499
C(domain_grouped)[T.chemistry]       -0.1890      0.540     -0.350      0.726      -1.248       0.870
C(domain_grouped)[T.physics]         -0.3434      0.575     -0.597      0.550      -1.471       0.784
human_difficulty                     -0.1695      0.249     -0.682      0.495      -0.657       0.318
q_length                              0.2345      0.227      1.034      0.301      -0.210       0.679
avg_word_length                      -0.1438      0.209     -0.689      0.491      -0.553       0.265
percent_non_alphabetic_whitespace    -0.0127      0.023     -0.559      0.576      -0.057       0.032
capabilities_entropy                  0.8428      0.301      2.803      0.005       0.253       1.432
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  229
Model:                          Logit   Df Residuals:                      221
Method:                           MLE   Df Model:                            7
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.04000
Time:                        21:14:16   Log-Likelihood:                -152.28
converged:                       True   LL-Null:                       -158.62
Covariance Type:            nonrobust   LLR p-value:                   0.08005
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                             0.0186      1.943      0.010      0.992      -3.790       3.827
C(domain_grouped)[T.chemistry]       -0.2525      0.538     -0.469      0.639      -1.307       0.802
C(domain_grouped)[T.physics]         -0.2144      0.568     -0.378      0.706      -1.327       0.898
human_difficulty                     -0.1400      0.248     -0.564      0.573      -0.626       0.346
q_length                              0.1150      0.226      0.508      0.611      -0.328       0.558
avg_word_length                      -0.0934      0.211     -0.442      0.658      -0.507       0.320
percent_non_alphabetic_whitespace    -0.0076      0.023     -0.336      0.737      -0.052       0.037
game_entropy                          1.1853      0.389      3.050      0.002       0.423       1.947
=====================================================================================================

                  Model 4.95: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  229
Model:                          Logit   Df Residuals:                      220
Method:                           MLE   Df Model:                            8
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.05316
Time:                        21:14:16   Log-Likelihood:                -150.19
converged:                       True   LL-Null:                       -158.62
Covariance Type:            nonrobust   LLR p-value:                   0.03154
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -0.4001      1.968     -0.203      0.839      -4.258       3.458
C(domain_grouped)[T.chemistry]       -0.3038      0.542     -0.561      0.575      -1.365       0.758
C(domain_grouped)[T.physics]         -0.3594      0.576     -0.624      0.532      -1.488       0.769
human_difficulty                     -0.1332      0.251     -0.530      0.596      -0.626       0.360
q_length                              0.1560      0.230      0.678      0.498      -0.295       0.607
avg_word_length                      -0.0778      0.211     -0.369      0.712      -0.491       0.336
percent_non_alphabetic_whitespace    -0.0082      0.023     -0.357      0.721      -0.053       0.037
capabilities_entropy                  0.6316      0.313      2.015      0.044       0.017       1.246
game_entropy                          0.9581      0.404      2.374      0.018       0.167       1.749
=====================================================================================================

--- Analyzing gpt-4o-2024-08-06 (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/gpt-4o-2024-08-06_GPQA_redacted_cor_temp1.0_1757988603_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    160
1     26
Name: count, dtype: int64

Answer change%: 0.1398 [0.08995099303667545, 0.1896188994364428] (n=186)
P-value vs 25%: 1.459e-05; P-value vs 0%: 3.847e-08
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=26)
P-value vs 25%: 0; P-value vs 33%: 0

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  186
Model:                          Logit   Df Residuals:                      184
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.3039
Time:                        21:14:16   Log-Likelihood:                -52.379
converged:                       True   LL-Null:                       -75.251
Covariance Type:            nonrobust   LLR p-value:                 1.348e-11
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          3.1094      0.808      3.847      0.000       1.525       4.693
p_i_capability    -7.0202      1.279     -5.488      0.000      -9.527      -4.513
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  186
Model:                          Logit   Df Residuals:                      184
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.2799
Time:                        21:14:16   Log-Likelihood:                -54.189
converged:                       True   LL-Null:                       -75.251
Covariance Type:            nonrobust   LLR p-value:                 8.568e-11
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -4.0601      0.613     -6.628      0.000      -5.261      -2.860
capabilities_entropy     2.3393      0.449      5.212      0.000       1.460       3.219
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.7308 [0.5603, 0.9013] (n=26)
                  P-value vs 33.3%: 4.905e-06

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=-1.89, p=0.0606
Wilcoxon delta_p: statistic=3255.00, p=0.00488
Mean Δp = -0.0238  [-0.0484, 0.0009]
Idea 1 N = 134; 

  Idea 1.5: Calibration Metrics
  NLL: 0.2819, Signed ECE (overconf pos under neg): -0.2083, ECE: 0.2083 (n=160)
  Brier: 0.0929, Reliability (absolute calibration error; lower better): 0.0921, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=160)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.609
Model:                            OLS   Adj. R-squared:                  0.601
Method:                 Least Squares   F-statistic:                     80.82
Date:                Fri, 19 Sep 2025   Prob (F-statistic):           1.34e-31
Time:                        21:14:16   Log-Likelihood:                 103.42
No. Observations:                 160   AIC:                            -198.8
Df Residuals:                     156   BIC:                            -186.5
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.3311      0.048     -6.943      0.000      -0.425      -0.237
p1                    0.3660      0.055      6.625      0.000       0.257       0.475
answer_changed        0.1213      0.104      1.164      0.246      -0.085       0.327
p1:answer_changed     0.6200      0.173      3.586      0.000       0.278       0.961
==============================================================================
Omnibus:                       29.415   Durbin-Watson:                   1.801
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               44.045
Skew:                           0.979   Prob(JB):                     2.73e-10
Kurtosis:                       4.666   Cond. No.                         25.7
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=0.90, p=0.37
Wilcoxon delta_H: statistic=4090.00, p=0.337
Mean ΔH = 0.0381  [-0.0448, 0.1210]
Paired t-test delta_H Changed: statistic=5.40, p=1.32e-05
Wilcoxon delta_H Changed: statistic=18.00, p=7.54e-06
Mean ΔH Changed = 0.5275  [0.3362, 0.7188]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=4.29, p=3.04e-05
Wilcoxon (p_top2_game vs p_top2_base): statistic=3953.00, p=2.27e-05
Mean Δp_top2 = 0.0288  [0.0157, 0.0420] (n=160)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=2.85, p=0.00494
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=4768.00, p=0.00439
Mean ΔH_unchosen_baseline_set = 0.1176  [0.0367, 0.1985] (n=160)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  160
Model:                          Logit   Df Residuals:                      157
Method:                           MLE   Df Model:                            2
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.2846
Time:                        21:14:16   Log-Likelihood:                -50.796
converged:                       True   LL-Null:                       -71.007
Covariance Type:            nonrobust   LLR p-value:                 1.670e-09
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -2.1338      0.410     -5.201      0.000      -2.938      -1.330
p1_z            -2.0359      0.565     -3.602      0.000      -3.144      -0.928
I(p1_z ** 2)    -0.4798      0.354     -1.356      0.175      -1.173       0.214
================================================================================
AUC = 0.864

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  186
Model:                          Logit   Df Residuals:                      184
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.1313
Time:                        21:14:16   Log-Likelihood:                -65.374
converged:                       True   LL-Null:                       -75.251
Covariance Type:            nonrobust   LLR p-value:                 8.808e-06
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -2.9068      0.397     -7.314      0.000      -3.686      -2.128
game_entropy     1.6033      0.380      4.222      0.000       0.859       2.348
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=5586.00, p=2.34e-05
Paired t-test (game_entropy vs capabilities_entropy): statistic=-3.86, p=0.000156
Mean capabilities_entropy-game_entropy = 0.1197  [0.0589, 0.1805] (n=186)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  186
Model:                          Logit   Df Residuals:                      183
Method:                           MLE   Df Model:                            2
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.2822
Time:                        21:14:16   Log-Likelihood:                -54.014
converged:                       True   LL-Null:                       -75.251
Covariance Type:            nonrobust   LLR p-value:                 5.988e-10
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -4.0408      0.614     -6.582      0.000      -5.244      -2.838
capabilities_entropy     2.5637      0.593      4.322      0.000       1.401       3.726
game_entropy            -0.3315      0.563     -0.589      0.556      -1.434       0.771
========================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  186
Model:                          Logit   Df Residuals:                      184
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:               4.863e-08
Time:                        21:14:16   Log-Likelihood:                -75.251
converged:                       True   LL-Null:                       -75.251
Covariance Type:            nonrobust   LLR p-value:                    0.9978
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -1.8146      0.931     -1.949      0.051      -3.640       0.011
human_difficulty    -0.0010      0.377     -0.003      0.998      -0.740       0.738
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  186
Model:                          Logit   Df Residuals:                      179
Method:                           MLE   Df Model:                            6
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.1021
Time:                        21:14:16   Log-Likelihood:                -67.569
converged:                       True   LL-Null:                       -75.251
Covariance Type:            nonrobust   LLR p-value:                   0.01761
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -0.5029      3.625     -0.139      0.890      -7.607       6.602
C(domain_grouped)[T.chemistry]        2.8618      1.085      2.638      0.008       0.735       4.988
C(domain_grouped)[T.physics]          2.1718      1.080      2.011      0.044       0.055       4.289
human_difficulty                      0.2723      0.386      0.706      0.480      -0.484       1.028
q_length                             -0.3332      0.398     -0.837      0.403      -1.113       0.447
avg_word_length                      -0.3835      0.418     -0.918      0.359      -1.203       0.436
percent_non_alphabetic_whitespace    -0.0447      0.042     -1.075      0.282      -0.126       0.037
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 0.6094
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  186
Model:                          Logit   Df Residuals:                      178
Method:                           MLE   Df Model:                            7
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.3236
Time:                        21:14:16   Log-Likelihood:                -50.902
converged:                       True   LL-Null:                       -75.251
Covariance Type:            nonrobust   LLR p-value:                 2.601e-08
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -1.7563      4.099     -0.428      0.668      -9.789       6.277
C(domain_grouped)[T.chemistry]        1.7326      1.174      1.476      0.140      -0.568       4.033
C(domain_grouped)[T.physics]          1.7084      1.166      1.465      0.143      -0.577       3.994
human_difficulty                      0.4707      0.435      1.083      0.279      -0.381       1.322
q_length                             -0.7838      0.495     -1.584      0.113      -1.754       0.186
avg_word_length                      -0.0216      0.456     -0.047      0.962      -0.916       0.873
percent_non_alphabetic_whitespace    -0.0280      0.039     -0.718      0.473      -0.104       0.048
capabilities_entropy                  2.3496      0.508      4.630      0.000       1.355       3.344
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  186
Model:                          Logit   Df Residuals:                      178
Method:                           MLE   Df Model:                            7
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.1945
Time:                        21:14:16   Log-Likelihood:                -60.615
converged:                       True   LL-Null:                       -75.251
Covariance Type:            nonrobust   LLR p-value:                 0.0001291
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -0.9110      3.853     -0.236      0.813      -8.462       6.640
C(domain_grouped)[T.chemistry]        2.2047      1.101      2.002      0.045       0.046       4.363
C(domain_grouped)[T.physics]          1.9425      1.093      1.777      0.076      -0.200       4.085
human_difficulty                      0.4308      0.412      1.046      0.295      -0.376       1.238
q_length                             -0.5723      0.442     -1.296      0.195      -1.438       0.293
avg_word_length                      -0.2350      0.441     -0.533      0.594      -1.098       0.629
percent_non_alphabetic_whitespace    -0.0311      0.041     -0.760      0.447      -0.111       0.049
game_entropy                          1.4674      0.413      3.549      0.000       0.657       2.278
=====================================================================================================

                  Model 4.95: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  186
Model:                          Logit   Df Residuals:                      177
Method:                           MLE   Df Model:                            8
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.3252
Time:                        21:14:16   Log-Likelihood:                -50.780
converged:                       True   LL-Null:                       -75.251
Covariance Type:            nonrobust   LLR p-value:                 6.524e-08
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -1.6140      4.113     -0.392      0.695      -9.676       6.448
C(domain_grouped)[T.chemistry]        1.7336      1.173      1.478      0.139      -0.565       4.032
C(domain_grouped)[T.physics]          1.6765      1.166      1.437      0.151      -0.610       3.963
human_difficulty                      0.4478      0.437      1.024      0.306      -0.409       1.305
q_length                             -0.7802      0.495     -1.576      0.115      -1.750       0.190
avg_word_length                      -0.0337      0.457     -0.074      0.941      -0.930       0.862
percent_non_alphabetic_whitespace    -0.0289      0.039     -0.742      0.458      -0.105       0.048
capabilities_entropy                  2.5334      0.632      4.009      0.000       1.295       3.772
game_entropy                         -0.2859      0.580     -0.493      0.622      -1.422       0.850
=====================================================================================================

--- Analyzing gpt-4o-2024-08-06 (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/gpt-4o-2024-08-06_GPQA_redacted_temp1.0_1757987499_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    162
1     99
Name: count, dtype: int64

Answer change%: 0.3793 [0.32044462831901316, 0.4381760613361592] (n=261)
P-value vs 25%: 1.666e-05; P-value vs 0%: 1.455e-36
Phase 2 self-accuracy: 0.4646 [0.36640108170924235, 0.5628918475836869] (n=99)
P-value vs 25%: 1.851e-05; P-value vs 33%: 0.008632

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  261
Model:                          Logit   Df Residuals:                      259
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.07801
Time:                        21:14:16   Log-Likelihood:                -159.72
converged:                       True   LL-Null:                       -173.23
Covariance Type:            nonrobust   LLR p-value:                 2.006e-07
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          1.7251      0.458      3.765      0.000       0.827       2.623
p_i_capability    -3.3114      0.672     -4.931      0.000      -4.628      -1.995
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  261
Model:                          Logit   Df Residuals:                      259
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.05702
Time:                        21:14:16   Log-Likelihood:                -163.36
converged:                       True   LL-Null:                       -173.23
Covariance Type:            nonrobust   LLR p-value:                 8.808e-06
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.5968      0.303     -5.275      0.000      -2.190      -1.003
capabilities_entropy     1.0038      0.237      4.235      0.000       0.539       1.468
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.7172 [0.6285, 0.8059] (n=99)
                  P-value vs 33.3%: 2.253e-17

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=-3.77, p=0.000227
Wilcoxon delta_p: statistic=4402.00, p=0.000759
Mean Δp = -0.0569  [-0.0864, -0.0273]
Idea 1 N = 159; 

  Idea 1.5: Calibration Metrics
  NLL: 3.3744, Signed ECE (overconf pos under neg): 0.1191, ECE: 0.1191 (n=258)
  Brier: 0.0289, Reliability (absolute calibration error; lower better): 0.0281, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=258)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.770
Model:                            OLS   Adj. R-squared:                  0.767
Method:                 Least Squares   F-statistic:                     283.2
Date:                Fri, 19 Sep 2025   Prob (F-statistic):           1.06e-80
Time:                        21:14:16   Log-Likelihood:                 126.39
No. Observations:                 258   AIC:                            -244.8
Df Residuals:                     254   BIC:                            -230.6
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.4513      0.043    -10.388      0.000      -0.537      -0.366
p1                    0.5365      0.057      9.436      0.000       0.425       0.648
answer_changed        0.2490      0.067      3.718      0.000       0.117       0.381
p1:answer_changed     0.4843      0.099      4.898      0.000       0.290       0.679
==============================================================================
Omnibus:                       11.968   Durbin-Watson:                   1.855
Prob(Omnibus):                  0.003   Jarque-Bera (JB):                5.489
Skew:                           0.066   Prob(JB):                       0.0643
Kurtosis:                       2.298   Cond. No.                         17.9
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=5.87, p=2.44e-08
Wilcoxon delta_H: statistic=3048.00, p=1.23e-08
Mean ΔH = 0.2078  [0.1385, 0.2771]
Paired t-test delta_H Changed: statistic=9.23, p=5.63e-15
Wilcoxon delta_H Changed: statistic=417.00, p=6.82e-13
Mean ΔH Changed = 0.3554  [0.2800, 0.4309]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=7.16, p=8.37e-12
Wilcoxon (p_top2_game vs p_top2_base): statistic=8014.00, p=4.35e-13
Mean Δp_top2 = 0.0439  [0.0319, 0.0559] (n=258)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=9.92, p=7.75e-20
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=5941.00, p=2.91e-19
Mean ΔH_unchosen_baseline_set = 0.2644  [0.2122, 0.3167] (n=258)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  258
Model:                          Logit   Df Residuals:                      255
Method:                           MLE   Df Model:                            2
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.07712
Time:                        21:14:16   Log-Likelihood:                -158.54
converged:                       True   LL-Null:                       -171.79
Covariance Type:            nonrobust   LLR p-value:                 1.762e-06
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.3713      0.200     -1.859      0.063      -0.763       0.020
p1_z            -0.6926      0.145     -4.763      0.000      -0.978      -0.408
I(p1_z ** 2)    -0.1732      0.163     -1.060      0.289      -0.493       0.147
================================================================================
AUC = 0.684

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  261
Model:                          Logit   Df Residuals:                      259
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.05637
Time:                        21:14:16   Log-Likelihood:                -163.47
converged:                       True   LL-Null:                       -173.23
Covariance Type:            nonrobust   LLR p-value:                 9.895e-06
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.4447      0.269     -5.380      0.000      -1.971      -0.918
game_entropy     1.0573      0.249      4.253      0.000       0.570       1.545
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=9896.00, p=3.68e-09
Paired t-test (game_entropy vs capabilities_entropy): statistic=-6.11, p=3.66e-09
Mean capabilities_entropy-game_entropy = 0.1924  [0.1307, 0.2541] (n=261)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  261
Model:                          Logit   Df Residuals:                      258
Method:                           MLE   Df Model:                            2
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.07070
Time:                        21:14:16   Log-Likelihood:                -160.98
converged:                       True   LL-Null:                       -173.23
Covariance Type:            nonrobust   LLR p-value:                 4.797e-06
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.7838      0.319     -5.599      0.000      -2.408      -1.159
capabilities_entropy     0.6365      0.289      2.204      0.028       0.071       1.203
game_entropy             0.6569      0.304      2.158      0.031       0.060       1.253
========================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  261
Model:                          Logit   Df Residuals:                      259
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.01021
Time:                        21:14:16   Log-Likelihood:                -171.46
converged:                       True   LL-Null:                       -173.23
Covariance Type:            nonrobust   LLR p-value:                   0.06001
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept            0.4877      0.540      0.904      0.366      -0.570       1.546
human_difficulty    -0.4209      0.227     -1.855      0.064      -0.866       0.024
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  261
Model:                          Logit   Df Residuals:                      254
Method:                           MLE   Df Model:                            6
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.02791
Time:                        21:14:16   Log-Likelihood:                -168.40
converged:                       True   LL-Null:                       -173.23
Covariance Type:            nonrobust   LLR p-value:                    0.1392
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                             2.2232      1.984      1.121      0.262      -1.665       6.111
C(domain_grouped)[T.chemistry]       -0.9060      0.482     -1.880      0.060      -1.850       0.038
C(domain_grouped)[T.physics]         -0.5532      0.501     -1.104      0.270      -1.535       0.429
human_difficulty                     -0.4719      0.238     -1.982      0.047      -0.938      -0.005
q_length                              0.0408      0.211      0.194      0.846      -0.372       0.454
avg_word_length                      -0.2360      0.222     -1.066      0.287      -0.670       0.198
percent_non_alphabetic_whitespace    -0.0134      0.025     -0.528      0.597      -0.063       0.036
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 1.0537
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  261
Model:                          Logit   Df Residuals:                      253
Method:                           MLE   Df Model:                            7
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.09261
Time:                        21:14:16   Log-Likelihood:                -157.19
converged:                       True   LL-Null:                       -173.23
Covariance Type:            nonrobust   LLR p-value:                 3.914e-05
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                             1.4584      1.994      0.731      0.464      -2.449       5.366
C(domain_grouped)[T.chemistry]       -1.5332      0.525     -2.922      0.003      -2.562      -0.505
C(domain_grouped)[T.physics]         -1.1651      0.547     -2.132      0.033      -2.236      -0.094
human_difficulty                     -0.5040      0.253     -1.993      0.046      -1.000      -0.008
q_length                             -0.0159      0.218     -0.073      0.942      -0.444       0.412
avg_word_length                      -0.1512      0.215     -0.703      0.482      -0.573       0.270
percent_non_alphabetic_whitespace    -0.0048      0.026     -0.187      0.852      -0.055       0.046
capabilities_entropy                  1.1484      0.257      4.469      0.000       0.645       1.652
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  261
Model:                          Logit   Df Residuals:                      253
Method:                           MLE   Df Model:                            7
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.08766
Time:                        21:14:16   Log-Likelihood:                -158.05
converged:                       True   LL-Null:                       -173.23
Covariance Type:            nonrobust   LLR p-value:                 8.120e-05
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                             1.3962      2.019      0.692      0.489      -2.560       5.353
C(domain_grouped)[T.chemistry]       -1.3943      0.512     -2.725      0.006      -2.397      -0.391
C(domain_grouped)[T.physics]         -1.0435      0.531     -1.965      0.049      -2.084      -0.003
human_difficulty                     -0.4907      0.248     -1.982      0.047      -0.976      -0.005
q_length                             -0.0174      0.221     -0.079      0.937      -0.450       0.415
avg_word_length                      -0.1211      0.219     -0.553      0.581      -0.550       0.308
percent_non_alphabetic_whitespace    -0.0052      0.026     -0.200      0.842      -0.057       0.046
game_entropy                          1.1694      0.270      4.339      0.000       0.641       1.698
=====================================================================================================

                  Model 4.95: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  261
Model:                          Logit   Df Residuals:                      252
Method:                           MLE   Df Model:                            8
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.1072
Time:                        21:14:16   Log-Likelihood:                -154.66
converged:                       True   LL-Null:                       -173.23
Covariance Type:            nonrobust   LLR p-value:                 1.081e-05
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                             1.2116      2.017      0.601      0.548      -2.742       5.165
C(domain_grouped)[T.chemistry]       -1.6180      0.528     -3.065      0.002      -2.653      -0.583
C(domain_grouped)[T.physics]         -1.2628      0.549     -2.300      0.021      -2.339      -0.187
human_difficulty                     -0.5143      0.254     -2.021      0.043      -1.013      -0.016
q_length                             -0.0325      0.222     -0.147      0.883      -0.467       0.402
avg_word_length                      -0.1070      0.218     -0.490      0.624      -0.535       0.321
percent_non_alphabetic_whitespace    -0.0028      0.026     -0.107      0.915      -0.054       0.049
capabilities_entropy                  0.7779      0.303      2.564      0.010       0.183       1.373
game_entropy                          0.7091      0.319      2.223      0.026       0.084       1.334
=====================================================================================================

--- Analyzing gpt-4o-mini (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/gpt-4o-mini_GPQA_redacted_cor_temp1.0_1757988839_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    113
1     33
Name: count, dtype: int64

Answer change%: 0.2260 [0.1581828421354376, 0.2938719523851103] (n=146)
P-value vs 25%: 0.4886; P-value vs 0%: 6.59e-11
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=33)
P-value vs 25%: 0; P-value vs 33%: 0

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  146
Model:                          Logit   Df Residuals:                      144
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.1703
Time:                        21:14:16   Log-Likelihood:                -64.739
converged:                       True   LL-Null:                       -78.027
Covariance Type:            nonrobust   LLR p-value:                 2.533e-07
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          2.9507      0.858      3.437      0.001       1.268       4.633
p_i_capability    -5.2358      1.089     -4.808      0.000      -7.370      -3.101
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  146
Model:                          Logit   Df Residuals:                      144
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.1747
Time:                        21:14:16   Log-Likelihood:                -64.395
converged:                       True   LL-Null:                       -78.027
Covariance Type:            nonrobust   LLR p-value:                 1.775e-07
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.5187      0.389     -6.476      0.000      -3.281      -1.756
capabilities_entropy     1.8910      0.396      4.771      0.000       1.114       2.668
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.6250 [0.4573, 0.7927] (n=32)
                  P-value vs 33.3%: 0.0006543

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=-1.78, p=0.0788
Wilcoxon delta_p: statistic=1846.00, p=0.0563
Mean Δp = -0.0288  [-0.0605, 0.0030]
Idea 1 N = 97; 

  Idea 1.5: Calibration Metrics
  NLL: 0.2284, Signed ECE (overconf pos under neg): -0.1759, ECE: 0.1759 (n=129)
  Brier: 0.0691, Reliability (absolute calibration error; lower better): 0.0684, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=129)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.873
Model:                            OLS   Adj. R-squared:                  0.870
Method:                 Least Squares   F-statistic:                     285.6
Date:                Fri, 19 Sep 2025   Prob (F-statistic):           9.57e-56
Time:                        21:14:16   Log-Likelihood:                 95.175
No. Observations:                 129   AIC:                            -182.4
Df Residuals:                     125   BIC:                            -170.9
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.5962      0.063     -9.393      0.000      -0.722      -0.471
p1                    0.6504      0.071      9.102      0.000       0.509       0.792
answer_changed        0.4667      0.096      4.838      0.000       0.276       0.658
p1:answer_changed     0.4112      0.125      3.287      0.001       0.164       0.659
==============================================================================
Omnibus:                       24.455   Durbin-Watson:                   1.949
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               42.303
Skew:                           0.867   Prob(JB):                     6.52e-10
Kurtosis:                       5.205   Cond. No.                         21.9
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=1.27, p=0.207
Wilcoxon delta_H: statistic=2040.00, p=0.293
Mean ΔH = 0.0639  [-0.0347, 0.1626]
Paired t-test delta_H Changed: statistic=3.47, p=0.00154
Wilcoxon delta_H Changed: statistic=91.00, p=0.000773
Mean ΔH Changed = 0.3026  [0.1319, 0.4734]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=2.74, p=0.00697
Wilcoxon (p_top2_game vs p_top2_base): statistic=2735.00, p=0.000612
Mean Δp_top2 = 0.0181  [0.0052, 0.0311] (n=129)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=2.78, p=0.00633
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=3022.00, p=0.00853
Mean ΔH_unchosen_baseline_set = 0.1231  [0.0362, 0.2101] (n=129)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  129
Model:                          Logit   Df Residuals:                      126
Method:                           MLE   Df Model:                            2
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.1602
Time:                        21:14:16   Log-Likelihood:                -60.686
converged:                       True   LL-Null:                       -72.265
Covariance Type:            nonrobust   LLR p-value:                 9.359e-06
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.2278      0.317     -3.874      0.000      -1.849      -0.607
p1_z            -1.0947      0.332     -3.294      0.001      -1.746      -0.443
I(p1_z ** 2)    -0.1125      0.251     -0.449      0.653      -0.604       0.379
================================================================================
AUC = 0.794

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  146
Model:                          Logit   Df Residuals:                      144
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.08577
Time:                        21:14:16   Log-Likelihood:                -71.335
converged:                       True   LL-Null:                       -78.027
Covariance Type:            nonrobust   LLR p-value:                 0.0002537
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.9838      0.318     -6.236      0.000      -2.607      -1.360
game_entropy     1.5455      0.436      3.544      0.000       0.691       2.400
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=3519.00, p=0.00103
Paired t-test (game_entropy vs capabilities_entropy): statistic=-3.18, p=0.00183
Mean capabilities_entropy-game_entropy = 0.1235  [0.0473, 0.1997] (n=146)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  146
Model:                          Logit   Df Residuals:                      143
Method:                           MLE   Df Model:                            2
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.1805
Time:                        21:14:16   Log-Likelihood:                -63.945
converged:                       True   LL-Null:                       -78.027
Covariance Type:            nonrobust   LLR p-value:                 7.663e-07
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.6283      0.414     -6.354      0.000      -3.439      -1.817
capabilities_entropy     1.6674      0.456      3.658      0.000       0.774       2.561
game_entropy             0.5171      0.542      0.955      0.340      -0.545       1.579
========================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  146
Model:                          Logit   Df Residuals:                      144
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.03781
Time:                        21:14:16   Log-Likelihood:                -75.077
converged:                       True   LL-Null:                       -78.027
Covariance Type:            nonrobust   LLR p-value:                   0.01514
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept            0.8980      0.907      0.990      0.322      -0.880       2.676
human_difficulty    -0.9075      0.388     -2.337      0.019      -1.669      -0.146
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  146
Model:                          Logit   Df Residuals:                      139
Method:                           MLE   Df Model:                            6
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.04677
Time:                        21:14:16   Log-Likelihood:                -74.377
converged:                       True   LL-Null:                       -78.027
Covariance Type:            nonrobust   LLR p-value:                    0.2941
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                             0.6098      2.965      0.206      0.837      -5.202       6.422
C(domain_grouped)[T.chemistry]        0.3701      0.664      0.558      0.577      -0.931       1.671
C(domain_grouped)[T.physics]          0.4227      0.626      0.675      0.499      -0.804       1.650
human_difficulty                     -0.8325      0.394     -2.112      0.035      -1.605      -0.060
q_length                              0.1461      0.349      0.419      0.675      -0.537       0.829
avg_word_length                      -0.1937      0.345     -0.561      0.575      -0.871       0.483
percent_non_alphabetic_whitespace    -0.0206      0.040     -0.518      0.604      -0.099       0.057
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 0.5330
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  146
Model:                          Logit   Df Residuals:                      138
Method:                           MLE   Df Model:                            7
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.1995
Time:                        21:14:16   Log-Likelihood:                -62.460
converged:                       True   LL-Null:                       -78.027
Covariance Type:            nonrobust   LLR p-value:                 5.876e-05
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -0.1146      2.912     -0.039      0.969      -5.822       5.593
C(domain_grouped)[T.chemistry]       -0.5506      0.789     -0.698      0.485      -2.097       0.996
C(domain_grouped)[T.physics]         -0.2616      0.712     -0.367      0.713      -1.657       1.134
human_difficulty                     -0.7470      0.447     -1.671      0.095      -1.623       0.129
q_length                             -0.0116      0.360     -0.032      0.974      -0.717       0.694
avg_word_length                      -0.0272      0.303     -0.090      0.928      -0.620       0.566
percent_non_alphabetic_whitespace    -0.0235      0.047     -0.503      0.615      -0.115       0.068
capabilities_entropy                  1.9587      0.439      4.463      0.000       1.099       2.819
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  146
Model:                          Logit   Df Residuals:                      138
Method:                           MLE   Df Model:                            7
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.1211
Time:                        21:14:16   Log-Likelihood:                -68.581
converged:                       True   LL-Null:                       -78.027
Covariance Type:            nonrobust   LLR p-value:                  0.008533
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                             0.1989      3.004      0.066      0.947      -5.689       6.087
C(domain_grouped)[T.chemistry]       -0.2174      0.726     -0.299      0.765      -1.641       1.206
C(domain_grouped)[T.physics]         -0.1316      0.681     -0.193      0.847      -1.466       1.203
human_difficulty                     -0.8433      0.414     -2.037      0.042      -1.655      -0.032
q_length                              0.1115      0.363      0.307      0.759      -0.601       0.824
avg_word_length                      -0.1632      0.329     -0.496      0.620      -0.808       0.482
percent_non_alphabetic_whitespace     0.0022      0.042      0.052      0.959      -0.080       0.084
game_entropy                          1.5667      0.477      3.282      0.001       0.631       2.502
=====================================================================================================

                  Model 4.95: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  146
Model:                          Logit   Df Residuals:                      137
Method:                           MLE   Df Model:                            8
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.2040
Time:                        21:14:16   Log-Likelihood:                -62.113
converged:                       True   LL-Null:                       -78.027
Covariance Type:            nonrobust   LLR p-value:                 0.0001000
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -0.1645      2.917     -0.056      0.955      -5.882       5.553
C(domain_grouped)[T.chemistry]       -0.6164      0.793     -0.778      0.437      -2.170       0.937
C(domain_grouped)[T.physics]         -0.3622      0.726     -0.499      0.618      -1.785       1.061
human_difficulty                     -0.7517      0.450     -1.672      0.094      -1.633       0.129
q_length                             -0.0003      0.362     -0.001      0.999      -0.710       0.709
avg_word_length                      -0.0469      0.305     -0.154      0.878      -0.644       0.551
percent_non_alphabetic_whitespace    -0.0156      0.047     -0.329      0.742      -0.109       0.077
capabilities_entropy                  1.7265      0.511      3.375      0.001       0.724       2.729
game_entropy                          0.4931      0.589      0.838      0.402      -0.661       1.647
=====================================================================================================

--- Analyzing gpt-4o-mini (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/gpt-4o-mini_GPQA_redacted_temp1.0_1757987785_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    190
1    111
Name: count, dtype: int64

Answer change%: 0.3688 [0.31426572728217506, 0.42327580095702755] (n=301)
P-value vs 25%: 1.947e-05; P-value vs 0%: 3.91e-40
Phase 2 self-accuracy: 0.4685 [0.3756378379014432, 0.5612990990354938] (n=111)
P-value vs 25%: 3.977e-06; P-value vs 33%: 0.004234

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  301
Model:                          Logit   Df Residuals:                      299
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.07439
Time:                        21:14:16   Log-Likelihood:                -183.41
converged:                       True   LL-Null:                       -198.15
Covariance Type:            nonrobust   LLR p-value:                 5.646e-08
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          2.1075      0.513      4.109      0.000       1.102       3.113
p_i_capability    -3.4462      0.658     -5.234      0.000      -4.737      -2.156
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  301
Model:                          Logit   Df Residuals:                      299
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.06029
Time:                        21:14:16   Log-Likelihood:                -186.20
converged:                       True   LL-Null:                       -198.15
Covariance Type:            nonrobust   LLR p-value:                 1.019e-06
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.3946      0.228     -6.104      0.000      -1.842      -0.947
capabilities_entropy     1.0666      0.227      4.708      0.000       0.623       1.511
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.7838 [0.7072, 0.8604] (n=111)
                  P-value vs 33.3%: 9.497e-31

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=-2.39, p=0.0181
Wilcoxon delta_p: statistic=6340.00, p=0.0182
Mean Δp = -0.0318  [-0.0579, -0.0057]
Idea 1 N = 178; 

  Idea 1.5: Calibration Metrics
  NLL: 5.0791, Signed ECE (overconf pos under neg): 0.0874, ECE: 0.0874 (n=289)
  Brier: 0.0220, Reliability (absolute calibration error; lower better): 0.0212, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=289)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.815
Model:                            OLS   Adj. R-squared:                  0.813
Method:                 Least Squares   F-statistic:                     419.0
Date:                Fri, 19 Sep 2025   Prob (F-statistic):          4.00e-104
Time:                        21:14:16   Log-Likelihood:                 148.23
No. Observations:                 289   AIC:                            -288.5
Df Residuals:                     285   BIC:                            -273.8
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.4682      0.051     -9.133      0.000      -0.569      -0.367
p1                    0.5344      0.061      8.713      0.000       0.414       0.655
answer_changed        0.3035      0.073      4.140      0.000       0.159       0.448
p1:answer_changed     0.4459      0.094      4.720      0.000       0.260       0.632
==============================================================================
Omnibus:                        7.380   Durbin-Watson:                   1.902
Prob(Omnibus):                  0.025   Jarque-Bera (JB):                7.415
Skew:                           0.362   Prob(JB):                       0.0245
Kurtosis:                       2.699   Cond. No.                         21.2
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=4.51, p=1.16e-05
Wilcoxon delta_H: statistic=4927.00, p=1.02e-05
Mean ΔH = 0.1674  [0.0947, 0.2402]
Paired t-test delta_H Changed: statistic=7.04, p=1.72e-10
Wilcoxon delta_H Changed: statistic=995.00, p=8.46e-10
Mean ΔH Changed = 0.2867  [0.2069, 0.3664]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=5.19, p=3.96e-07
Wilcoxon (p_top2_game vs p_top2_base): statistic=13375.00, p=9.88e-08
Mean Δp_top2 = 0.0229  [0.0143, 0.0316] (n=289)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=7.66, p=2.92e-13
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=10521.00, p=3.54e-13
Mean ΔH_unchosen_baseline_set = 0.2132  [0.1586, 0.2678] (n=289)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  289
Model:                          Logit   Df Residuals:                      286
Method:                           MLE   Df Model:                            2
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.06265
Time:                        21:14:16   Log-Likelihood:                -180.42
converged:                       True   LL-Null:                       -192.48
Covariance Type:            nonrobust   LLR p-value:                 5.788e-06
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.5369      0.200     -2.685      0.007      -0.929      -0.145
p1_z            -0.5976      0.141     -4.233      0.000      -0.874      -0.321
I(p1_z ** 2)     0.0287      0.163      0.176      0.860      -0.291       0.348
================================================================================
AUC = 0.672

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  301
Model:                          Logit   Df Residuals:                      299
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.1094
Time:                        21:14:16   Log-Likelihood:                -176.47
converged:                       True   LL-Null:                       -198.15
Covariance Type:            nonrobust   LLR p-value:                 4.560e-11
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.7240      0.243     -7.092      0.000      -2.200      -1.248
game_entropy     1.6869      0.276      6.113      0.000       1.146       2.228
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=17053.00, p=0.000241
Paired t-test (game_entropy vs capabilities_entropy): statistic=-3.66, p=0.000303
Mean capabilities_entropy-game_entropy = 0.1060  [0.0492, 0.1628] (n=301)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  301
Model:                          Logit   Df Residuals:                      298
Method:                           MLE   Df Model:                            2
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.1160
Time:                        21:14:16   Log-Likelihood:                -175.16
converged:                       True   LL-Null:                       -198.15
Covariance Type:            nonrobust   LLR p-value:                 1.036e-10
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.8976      0.271     -6.992      0.000      -2.430      -1.366
capabilities_entropy     0.4342      0.268      1.621      0.105      -0.091       0.959
game_entropy             1.4331      0.316      4.539      0.000       0.814       2.052
========================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  301
Model:                          Logit   Df Residuals:                      299
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                0.001849
Time:                        21:14:16   Log-Likelihood:                -197.78
converged:                       True   LL-Null:                       -198.15
Covariance Type:            nonrobust   LLR p-value:                    0.3920
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -0.1225      0.499     -0.245      0.806      -1.101       0.856
human_difficulty    -0.1774      0.208     -0.853      0.394      -0.585       0.230
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  301
Model:                          Logit   Df Residuals:                      294
Method:                           MLE   Df Model:                            6
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.01388
Time:                        21:14:16   Log-Likelihood:                -195.40
converged:                       True   LL-Null:                       -198.15
Covariance Type:            nonrobust   LLR p-value:                    0.4814
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -1.6457      1.877     -0.877      0.380      -5.324       2.032
C(domain_grouped)[T.chemistry]       -0.3005      0.393     -0.764      0.445      -1.071       0.470
C(domain_grouped)[T.physics]         -0.1830      0.405     -0.452      0.651      -0.977       0.611
human_difficulty                     -0.2697      0.217     -1.242      0.214      -0.696       0.156
q_length                              0.3592      0.200      1.799      0.072      -0.032       0.750
avg_word_length                      -0.0290      0.218     -0.133      0.894      -0.457       0.399
percent_non_alphabetic_whitespace    -0.0043      0.023     -0.191      0.849      -0.049       0.040
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 0.7598
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  301
Model:                          Logit   Df Residuals:                      293
Method:                           MLE   Df Model:                            7
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.07924
Time:                        21:14:16   Log-Likelihood:                -182.45
converged:                       True   LL-Null:                       -198.15
Covariance Type:            nonrobust   LLR p-value:                 5.236e-05
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -2.3591      1.990     -1.186      0.236      -6.259       1.540
C(domain_grouped)[T.chemistry]       -0.8164      0.426     -1.916      0.055      -1.652       0.019
C(domain_grouped)[T.physics]         -0.5266      0.432     -1.219      0.223      -1.373       0.320
human_difficulty                     -0.2556      0.225     -1.138      0.255      -0.696       0.185
q_length                              0.3037      0.209      1.452      0.146      -0.106       0.714
avg_word_length                       0.0604      0.233      0.260      0.795      -0.396       0.516
percent_non_alphabetic_whitespace    -0.0007      0.024     -0.031      0.975      -0.048       0.047
capabilities_entropy                  1.1716      0.241      4.870      0.000       0.700       1.643
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  301
Model:                          Logit   Df Residuals:                      293
Method:                           MLE   Df Model:                            7
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.1223
Time:                        21:14:16   Log-Likelihood:                -173.92
converged:                       True   LL-Null:                       -198.15
Covariance Type:            nonrobust   LLR p-value:                 2.908e-08
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -3.0277      2.059     -1.470      0.142      -7.064       1.009
C(domain_grouped)[T.chemistry]       -0.7096      0.431     -1.645      0.100      -1.555       0.136
C(domain_grouped)[T.physics]         -0.4245      0.444     -0.955      0.339      -1.296       0.446
human_difficulty                     -0.1006      0.237     -0.425      0.671      -0.564       0.363
q_length                              0.2840      0.220      1.292      0.196      -0.147       0.715
avg_word_length                       0.0531      0.233      0.228      0.820      -0.403       0.510
percent_non_alphabetic_whitespace     0.0091      0.025      0.368      0.713      -0.039       0.057
game_entropy                          1.7364      0.286      6.069      0.000       1.176       2.297
=====================================================================================================

                  Model 4.95: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  301
Model:                          Logit   Df Residuals:                      292
Method:                           MLE   Df Model:                            8
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.1329
Time:                        21:14:16   Log-Likelihood:                -171.82
converged:                       True   LL-Null:                       -198.15
Covariance Type:            nonrobust   LLR p-value:                 1.258e-08
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -3.1513      2.079     -1.515      0.130      -7.227       0.924
C(domain_grouped)[T.chemistry]       -0.9027      0.445     -2.027      0.043      -1.776      -0.030
C(domain_grouped)[T.physics]         -0.5550      0.453     -1.225      0.220      -1.443       0.333
human_difficulty                     -0.1262      0.238     -0.530      0.596      -0.593       0.340
q_length                              0.2772      0.221      1.257      0.209      -0.155       0.709
avg_word_length                       0.0787      0.236      0.333      0.739      -0.385       0.542
percent_non_alphabetic_whitespace     0.0086      0.025      0.344      0.731      -0.040       0.058
capabilities_entropy                  0.5709      0.279      2.047      0.041       0.024       1.118
game_entropy                          1.4331      0.321      4.459      0.000       0.803       2.063
=====================================================================================================

--- Analyzing grok-3-latest (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/grok-3-latest_GPQA_redacted_cor_temp0.0_1751718817_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    176
1     27
Name: count, dtype: int64

Answer change%: 0.1330 [0.08629144308167455, 0.17971840913507423] (n=203)
P-value vs 25%: 9.165e-07; P-value vs 0%: 2.398e-08
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=27)
P-value vs 25%: 0; P-value vs 33%: 0

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  203
Model:                          Logit   Df Residuals:                      201
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.01292
Time:                        21:14:16   Log-Likelihood:                -78.560
converged:                       True   LL-Null:                       -79.588
Covariance Type:            nonrobust   LLR p-value:                    0.1516
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept         -0.9051      0.653     -1.386      0.166      -2.185       0.375
p_i_capability    -1.0939      0.717     -1.526      0.127      -2.499       0.311
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  197
Model:                          Logit   Df Residuals:                      195
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.1313
Time:                        21:14:16   Log-Likelihood:                -66.767
converged:                       True   LL-Null:                       -76.856
Covariance Type:            nonrobust   LLR p-value:                 7.057e-06
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.5266      0.293     -8.620      0.000      -3.101      -1.952
capabilities_entropy     2.6194      0.578      4.531      0.000       1.486       3.753
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.8462 [0.7075, 0.9848] (n=26)
                  P-value vs 33.3%: 4.248e-13

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=2.86, p=0.00484
Wilcoxon delta_p: statistic=3648.00, p=1.21e-07
Mean Δp = 0.0304  [0.0096, 0.0513]
Idea 1 N = 166; 

  Idea 1.5: Calibration Metrics
  NLL: 0.0495, Signed ECE (overconf pos under neg): -0.0419, ECE: 0.0419 (n=192)
  Brier: 0.0114, Reliability (absolute calibration error; lower better): 0.0110, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=192)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.780
Model:                            OLS   Adj. R-squared:                  0.776
Method:                 Least Squares   F-statistic:                     221.9
Date:                Fri, 19 Sep 2025   Prob (F-statistic):           1.65e-61
Time:                        21:14:16   Log-Likelihood:                 115.13
No. Observations:                 192   AIC:                            -222.3
Df Residuals:                     188   BIC:                            -209.2
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.5241      0.124     -4.216      0.000      -0.769      -0.279
p1                    0.5713      0.128      4.476      0.000       0.320       0.823
answer_changed        0.4907      0.205      2.398      0.017       0.087       0.894
p1:answer_changed     0.3074      0.223      1.378      0.170      -0.133       0.747
==============================================================================
Omnibus:                      124.076   Durbin-Watson:                   2.289
Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1012.982
Skew:                           2.384   Prob(JB):                    1.08e-220
Kurtosis:                      13.192   Cond. No.                         46.7
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-0.46, p=0.645
Wilcoxon delta_H: statistic=6698.00, p=0.708
Mean ΔH = -0.0172  [-0.0900, 0.0556]
Paired t-test delta_H Changed: statistic=1.73, p=0.0952
Wilcoxon delta_H Changed: statistic=94.00, p=0.0382
Mean ΔH Changed = 0.1548  [-0.0202, 0.3297]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=-2.18, p=0.0307
Wilcoxon (p_top2_game vs p_top2_base): statistic=4378.00, p=2.34e-10
Mean Δp_top2 = -0.0042  [-0.0080, -0.0004] (n=192)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=0.18, p=0.859
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=9058.00, p=0.789
Mean ΔH_unchosen_baseline_set = 0.0061  [-0.0615, 0.0737] (n=192)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  192
Model:                          Logit   Df Residuals:                      189
Method:                           MLE   Df Model:                            2
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.1330
Time:                        21:14:16   Log-Likelihood:                -66.010
converged:                       True   LL-Null:                       -76.139
Covariance Type:            nonrobust   LLR p-value:                 3.992e-05
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.7695      0.259     -6.834      0.000      -2.277      -1.262
p1_z            -1.5785      0.442     -3.572      0.000      -2.445      -0.712
I(p1_z ** 2)    -0.3139      0.140     -2.237      0.025      -0.589      -0.039
================================================================================
AUC = 0.855

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  203
Model:                          Logit   Df Residuals:                      201
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.1439
Time:                        21:14:16   Log-Likelihood:                -68.133
converged:                       True   LL-Null:                       -79.588
Covariance Type:            nonrobust   LLR p-value:                 1.698e-06
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -2.7143      0.324     -8.388      0.000      -3.349      -2.080
game_entropy     2.2806      0.483      4.721      0.000       1.334       3.227
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=5887.00, p=1.41e-06
Paired t-test (game_entropy vs capabilities_entropy): statistic=3.39, p=0.000841
Mean capabilities_entropy-game_entropy = -0.0871  [-0.1374, -0.0368] (n=197)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  197
Model:                          Logit   Df Residuals:                      194
Method:                           MLE   Df Model:                            2
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.1859
Time:                        21:14:16   Log-Likelihood:                -62.565
converged:                       True   LL-Null:                       -76.856
Covariance Type:            nonrobust   LLR p-value:                 6.218e-07
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.9546      0.363     -8.145      0.000      -3.666      -2.244
capabilities_entropy     1.9153      0.634      3.020      0.003       0.672       3.158
game_entropy             1.6376      0.549      2.984      0.003       0.562       2.713
========================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  203
Model:                          Logit   Df Residuals:                      201
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:               2.610e-07
Time:                        21:14:16   Log-Likelihood:                -79.588
converged:                       True   LL-Null:                       -79.588
Covariance Type:            nonrobust   LLR p-value:                    0.9949
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -1.8808      0.970     -1.940      0.052      -3.781       0.019
human_difficulty     0.0025      0.392      0.006      0.995      -0.767       0.772
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  203
Model:                          Logit   Df Residuals:                      196
Method:                           MLE   Df Model:                            6
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.04482
Time:                        21:14:16   Log-Likelihood:                -76.021
converged:                       True   LL-Null:                       -79.588
Covariance Type:            nonrobust   LLR p-value:                    0.3086
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -1.4091      3.302     -0.427      0.670      -7.880       5.062
C(domain_grouped)[T.chemistry]        1.3831      0.726      1.904      0.057      -0.041       2.807
C(domain_grouped)[T.physics]          1.0309      0.718      1.435      0.151      -0.377       2.439
human_difficulty                      0.2455      0.411      0.598      0.550      -0.559       1.050
q_length                             -0.4366      0.349     -1.249      0.212      -1.121       0.248
avg_word_length                       0.1122      0.373      0.301      0.764      -0.619       0.843
percent_non_alphabetic_whitespace     0.0009      0.037      0.024      0.981      -0.072       0.073
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 0.1592
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  197
Model:                          Logit   Df Residuals:                      189
Method:                           MLE   Df Model:                            7
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.1652
Time:                        21:14:16   Log-Likelihood:                -64.163
converged:                       True   LL-Null:                       -76.856
Covariance Type:            nonrobust   LLR p-value:                 0.0006481
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -3.8867      3.591     -1.082      0.279     -10.926       3.152
C(domain_grouped)[T.chemistry]        1.1964      0.779      1.536      0.125      -0.331       2.723
C(domain_grouped)[T.physics]          0.7942      0.803      0.989      0.323      -0.780       2.368
human_difficulty                      0.1017      0.456      0.223      0.823      -0.791       0.995
q_length                             -0.3409      0.373     -0.913      0.361      -1.073       0.391
avg_word_length                       0.4570      0.392      1.164      0.244      -0.312       1.226
percent_non_alphabetic_whitespace     0.0190      0.038      0.500      0.617      -0.055       0.093
capabilities_entropy                  2.6809      0.619      4.333      0.000       1.468       3.894
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  203
Model:                          Logit   Df Residuals:                      195
Method:                           MLE   Df Model:                            7
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.1835
Time:                        21:14:16   Log-Likelihood:                -64.983
converged:                       True   LL-Null:                       -79.588
Covariance Type:            nonrobust   LLR p-value:                 0.0001324
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -4.8303      3.694     -1.308      0.191     -12.070       2.410
C(domain_grouped)[T.chemistry]        1.2992      0.769      1.688      0.091      -0.209       2.807
C(domain_grouped)[T.physics]          1.3918      0.791      1.760      0.078      -0.159       2.942
human_difficulty                      0.1868      0.442      0.422      0.673      -0.680       1.054
q_length                             -0.2744      0.375     -0.732      0.464      -1.009       0.460
avg_word_length                       0.4482      0.405      1.107      0.268      -0.346       1.242
percent_non_alphabetic_whitespace     0.0061      0.039      0.157      0.875      -0.070       0.082
game_entropy                          2.4121      0.534      4.519      0.000       1.366       3.458
=====================================================================================================

                  Model 4.95: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  197
Model:                          Logit   Df Residuals:                      188
Method:                           MLE   Df Model:                            8
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.2188
Time:                        21:14:16   Log-Likelihood:                -60.041
converged:                       True   LL-Null:                       -76.856
Covariance Type:            nonrobust   LLR p-value:                 4.738e-05
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -6.0550      3.884     -1.559      0.119     -13.668       1.558
C(domain_grouped)[T.chemistry]        1.1115      0.801      1.388      0.165      -0.458       2.681
C(domain_grouped)[T.physics]          1.0367      0.844      1.228      0.219      -0.618       2.691
human_difficulty                      0.0533      0.470      0.113      0.910      -0.868       0.974
q_length                             -0.1986      0.385     -0.516      0.606      -0.953       0.556
avg_word_length                       0.6497      0.422      1.539      0.124      -0.178       1.477
percent_non_alphabetic_whitespace     0.0224      0.040      0.561      0.574      -0.056       0.101
capabilities_entropy                  1.9893      0.681      2.919      0.004       0.654       3.325
game_entropy                          1.7255      0.596      2.895      0.004       0.557       2.894
=====================================================================================================

--- Analyzing grok-3-latest (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/grok-3-latest_GPQA_redacted_temp0.0_1751719817_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    152
1     92
Name: count, dtype: int64

Answer change%: 0.3770 [0.3162386124390582, 0.43785974821667945] (n=244)
P-value vs 25%: 4.224e-05; P-value vs 0%: 5.561e-34
Phase 2 self-accuracy: 0.4130 [0.31243026290616926, 0.5136566936155699] (n=92)
P-value vs 25%: 0.001493; P-value vs 33%: 0.1189

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  244
Model:                          Logit   Df Residuals:                      242
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                0.004668
Time:                        21:14:16   Log-Likelihood:                -160.92
converged:                       True   LL-Null:                       -161.67
Covariance Type:            nonrobust   LLR p-value:                    0.2192
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          0.0796      0.489      0.163      0.871      -0.880       1.039
p_i_capability    -0.6865      0.558     -1.231      0.218      -1.779       0.406
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  236
Model:                          Logit   Df Residuals:                      234
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.04144
Time:                        21:14:16   Log-Likelihood:                -149.90
converged:                       True   LL-Null:                       -156.38
Covariance Type:            nonrobust   LLR p-value:                 0.0003180
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -0.9763      0.195     -5.000      0.000      -1.359      -0.594
capabilities_entropy     1.1107      0.315      3.530      0.000       0.494       1.727
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.6705 [0.5722, 0.7687] (n=88)
                  P-value vs 33.3%: 1.72e-11

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=2.32, p=0.0218
Wilcoxon delta_p: statistic=3667.00, p=0.00835
Mean Δp = 0.0355  [0.0055, 0.0656]
Idea 1 N = 140; 

  Idea 1.5: Calibration Metrics
  NLL: 6.9395, Signed ECE (overconf pos under neg): 0.0391, ECE: 0.0391 (n=228)
  Brier: 0.0077, Reliability (absolute calibration error; lower better): 0.0072, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=228)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.842
Model:                            OLS   Adj. R-squared:                  0.840
Method:                 Least Squares   F-statistic:                     398.8
Date:                Fri, 19 Sep 2025   Prob (F-statistic):           1.59e-89
Time:                        21:14:16   Log-Likelihood:                 102.59
No. Observations:                 228   AIC:                            -197.2
Df Residuals:                     224   BIC:                            -183.5
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.4915      0.091     -5.423      0.000      -0.670      -0.313
p1                    0.5765      0.098      5.877      0.000       0.383       0.770
answer_changed        0.3728      0.129      2.886      0.004       0.118       0.627
p1:answer_changed     0.4151      0.144      2.876      0.004       0.131       0.699
==============================================================================
Omnibus:                       61.929   Durbin-Watson:                   1.909
Prob(Omnibus):                  0.000   Jarque-Bera (JB):              174.381
Skew:                           1.169   Prob(JB):                     1.36e-38
Kurtosis:                       6.591   Cond. No.                         30.8
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=0.92, p=0.361
Wilcoxon delta_H: statistic=4447.00, p=0.31
Mean ΔH = 0.0384  [-0.0437, 0.1205]
Paired t-test delta_H Changed: statistic=3.81, p=0.000261
Wilcoxon delta_H Changed: statistic=1189.00, p=0.00138
Mean ΔH Changed = 0.1657  [0.0804, 0.2510]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=-0.78, p=0.435
Wilcoxon (p_top2_game vs p_top2_base): statistic=10793.00, p=0.0234
Mean Δp_top2 = -0.0033  [-0.0115, 0.0049] (n=228)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=2.83, p=0.00507
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=10313.00, p=0.006
Mean ΔH_unchosen_baseline_set = 0.0875  [0.0269, 0.1482] (n=228)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  228
Model:                          Logit   Df Residuals:                      225
Method:                           MLE   Df Model:                            2
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.03840
Time:                        21:14:16   Log-Likelihood:                -146.22
converged:                       True   LL-Null:                       -152.06
Covariance Type:            nonrobust   LLR p-value:                  0.002914
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.2462      0.191     -1.290      0.197      -0.620       0.128
p1_z            -0.7452      0.243     -3.071      0.002      -1.221      -0.270
I(p1_z ** 2)    -0.2382      0.136     -1.752      0.080      -0.505       0.028
================================================================================
AUC = 0.682

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  244
Model:                          Logit   Df Residuals:                      242
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.06762
Time:                        21:14:16   Log-Likelihood:                -150.74
converged:                       True   LL-Null:                       -161.67
Covariance Type:            nonrobust   LLR p-value:                 2.926e-06
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.2537      0.221     -5.660      0.000      -1.688      -0.820
game_entropy     1.3743      0.305      4.502      0.000       0.776       1.972
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=10374.00, p=0.000587
Paired t-test (game_entropy vs capabilities_entropy): statistic=3.36, p=0.000895
Mean capabilities_entropy-game_entropy = -0.1095  [-0.1732, -0.0457] (n=236)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  236
Model:                          Logit   Df Residuals:                      233
Method:                           MLE   Df Model:                            2
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.07774
Time:                        21:14:16   Log-Likelihood:                -144.23
converged:                       True   LL-Null:                       -156.38
Covariance Type:            nonrobust   LLR p-value:                 5.252e-06
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.4017      0.243     -5.759      0.000      -1.879      -0.925
capabilities_entropy     0.7207      0.339      2.127      0.033       0.057       1.385
game_entropy             1.0842      0.327      3.316      0.001       0.443       1.725
========================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  244
Model:                          Logit   Df Residuals:                      242
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                0.003023
Time:                        21:14:16   Log-Likelihood:                -161.19
converged:                       True   LL-Null:                       -161.67
Covariance Type:            nonrobust   LLR p-value:                    0.3228
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept            0.0030      0.528      0.006      0.996      -1.033       1.039
human_difficulty    -0.2172      0.221     -0.983      0.326      -0.650       0.216
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  244
Model:                          Logit   Df Residuals:                      237
Method:                           MLE   Df Model:                            6
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                0.009695
Time:                        21:14:16   Log-Likelihood:                -160.11
converged:                       True   LL-Null:                       -161.67
Covariance Type:            nonrobust   LLR p-value:                    0.7917
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -0.1246      1.894     -0.066      0.948      -3.836       3.587
C(domain_grouped)[T.chemistry]       -0.3424      0.492     -0.696      0.486      -1.306       0.622
C(domain_grouped)[T.physics]         -0.2761      0.524     -0.527      0.598      -1.302       0.750
human_difficulty                     -0.2927      0.229     -1.278      0.201      -0.741       0.156
q_length                              0.0399      0.216      0.185      0.853      -0.383       0.463
avg_word_length                       0.0966      0.203      0.476      0.634      -0.301       0.494
percent_non_alphabetic_whitespace    -0.0111      0.025     -0.443      0.658      -0.060       0.038
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 0.4085
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  236
Model:                          Logit   Df Residuals:                      228
Method:                           MLE   Df Model:                            7
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.05943
Time:                        21:14:16   Log-Likelihood:                -147.09
converged:                       True   LL-Null:                       -156.38
Covariance Type:            nonrobust   LLR p-value:                  0.009585
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -0.6814      1.994     -0.342      0.733      -4.590       3.227
C(domain_grouped)[T.chemistry]       -0.8037      0.533     -1.508      0.132      -1.848       0.241
C(domain_grouped)[T.physics]         -0.8598      0.573     -1.500      0.134      -1.983       0.264
human_difficulty                     -0.3086      0.240     -1.284      0.199      -0.780       0.163
q_length                              0.1188      0.228      0.522      0.602      -0.327       0.565
avg_word_length                       0.1017      0.213      0.477      0.634      -0.316       0.520
percent_non_alphabetic_whitespace    -0.0051      0.026     -0.198      0.843      -0.056       0.046
capabilities_entropy                  1.2261      0.327      3.746      0.000       0.585       1.868
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  244
Model:                          Logit   Df Residuals:                      236
Method:                           MLE   Df Model:                            7
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.08222
Time:                        21:14:16   Log-Likelihood:                -148.38
converged:                       True   LL-Null:                       -161.67
Covariance Type:            nonrobust   LLR p-value:                 0.0003954
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -1.8079      2.022     -0.894      0.371      -5.771       2.156
C(domain_grouped)[T.chemistry]       -0.4108      0.522     -0.788      0.431      -1.433       0.612
C(domain_grouped)[T.physics]         -0.2334      0.559     -0.418      0.676      -1.328       0.861
human_difficulty                     -0.3425      0.243     -1.408      0.159      -0.819       0.134
q_length                              0.0508      0.229      0.222      0.825      -0.398       0.500
avg_word_length                       0.2698      0.218      1.236      0.217      -0.158       0.698
percent_non_alphabetic_whitespace     0.0066      0.026      0.252      0.801      -0.045       0.058
game_entropy                          1.4603      0.314      4.646      0.000       0.844       2.076
=====================================================================================================

                  Model 4.95: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  236
Model:                          Logit   Df Residuals:                      227
Method:                           MLE   Df Model:                            8
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.09730
Time:                        21:14:16   Log-Likelihood:                -141.17
converged:                       True   LL-Null:                       -156.38
Covariance Type:            nonrobust   LLR p-value:                 0.0001772
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -1.5771      2.056     -0.767      0.443      -5.607       2.453
C(domain_grouped)[T.chemistry]       -0.7979      0.553     -1.442      0.149      -1.883       0.287
C(domain_grouped)[T.physics]         -0.7115      0.597     -1.191      0.234      -1.882       0.459
human_difficulty                     -0.3562      0.248     -1.435      0.151      -0.843       0.130
q_length                              0.0955      0.235      0.407      0.684      -0.364       0.555
avg_word_length                       0.2152      0.222      0.970      0.332      -0.220       0.650
percent_non_alphabetic_whitespace     0.0069      0.027      0.258      0.797      -0.045       0.059
capabilities_entropy                  0.8262      0.353      2.337      0.019       0.133       1.519
game_entropy                          1.1423      0.338      3.383      0.001       0.481       1.804
=====================================================================================================

--- Analyzing qwen3-235b-a22b-2507 (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/qwen3-235b-a22b-2507_GPQA_redacted_cor_temp0.0_1756235281_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    158
1     46
Name: count, dtype: int64

Answer change%: 0.2255 [0.16814324946958045, 0.2828371426872823] (n=204)
P-value vs 25%: 0.4022; P-value vs 0%: 1.292e-14
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=46)
P-value vs 25%: 0; P-value vs 33%: 0

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  204
Model:                          Logit   Df Residuals:                      202
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.1071
Time:                        21:14:16   Log-Likelihood:                -97.224
converged:                       True   LL-Null:                       -108.89
Covariance Type:            nonrobust   LLR p-value:                 1.365e-06
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          3.8099      1.096      3.476      0.001       1.662       5.958
p_i_capability    -5.5422      1.200     -4.619      0.000      -7.894      -3.190
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  204
Model:                          Logit   Df Residuals:                      202
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.1148
Time:                        21:14:16   Log-Likelihood:                -96.390
converged:                       True   LL-Null:                       -108.89
Covariance Type:            nonrobust   LLR p-value:                 5.737e-07
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.8433      0.231     -7.973      0.000      -2.296      -1.390
capabilities_entropy     1.8670      0.387      4.820      0.000       1.108       2.626
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.6739 [0.5384, 0.8094] (n=46)
                  P-value vs 33.3%: 8.328e-07

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=2.53, p=0.0125
Wilcoxon delta_p: statistic=2167.00, p=1.29e-05
Mean Δp = 0.0369  [0.0084, 0.0655]
Idea 1 N = 127; 

  Idea 1.5: Calibration Metrics
  NLL: 0.1297, Signed ECE (overconf pos under neg): -0.0886, ECE: 0.0886 (n=173)
  Brier: 0.0355, Reliability (absolute calibration error; lower better): 0.0352, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=173)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.766
Model:                            OLS   Adj. R-squared:                  0.762
Method:                 Least Squares   F-statistic:                     184.3
Date:                Fri, 19 Sep 2025   Prob (F-statistic):           4.79e-53
Time:                        21:14:16   Log-Likelihood:                 67.991
No. Observations:                 173   AIC:                            -128.0
Df Residuals:                     169   BIC:                            -115.4
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.5837      0.127     -4.596      0.000      -0.834      -0.333
p1                    0.6530      0.133      4.920      0.000       0.391       0.915
answer_changed        0.2509      0.174      1.444      0.151      -0.092       0.594
p1:answer_changed     0.5122      0.192      2.672      0.008       0.134       0.891
==============================================================================
Omnibus:                       39.530   Durbin-Watson:                   1.839
Prob(Omnibus):                  0.000   Jarque-Bera (JB):              136.379
Skew:                           0.833   Prob(JB):                     2.43e-30
Kurtosis:                       7.018   Cond. No.                         33.2
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-7.12, p=7.31e-11
Wilcoxon delta_H: statistic=1563.00, p=1.77e-09
Mean ΔH = -0.3803  [-0.4850, -0.2756]
Paired t-test delta_H Changed: statistic=0.37, p=0.715
Wilcoxon delta_H Changed: statistic=528.00, p=0.891
Mean ΔH Changed = 0.0312  [-0.1353, 0.1976]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=-1.82, p=0.0703
Wilcoxon (p_top2_game vs p_top2_base): statistic=4087.00, p=2.97e-07
Mean Δp_top2 = -0.0069  [-0.0144, 0.0005] (n=173)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=-5.74, p=4.22e-08
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=4119.00, p=2.42e-07
Mean ΔH_unchosen_baseline_set = -0.2709  [-0.3634, -0.1784] (n=173)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  173
Model:                          Logit   Df Residuals:                      170
Method:                           MLE   Df Model:                            2
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.1071
Time:                        21:14:17   Log-Likelihood:                -89.455
converged:                       True   LL-Null:                       -100.19
Covariance Type:            nonrobust   LLR p-value:                 2.177e-05
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.8721      0.235     -3.703      0.000      -1.334      -0.411
p1_z            -1.2006      0.361     -3.327      0.001      -1.908      -0.493
I(p1_z ** 2)    -0.2542      0.164     -1.551      0.121      -0.575       0.067
================================================================================
AUC = 0.696

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  204
Model:                          Logit   Df Residuals:                      202
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.2242
Time:                        21:14:17   Log-Likelihood:                -84.476
converged:                       True   LL-Null:                       -108.89
Covariance Type:            nonrobust   LLR p-value:                 2.798e-12
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -2.4859      0.306     -8.125      0.000      -3.086      -1.886
game_entropy     2.5448      0.408      6.232      0.000       1.744       3.345
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=5755.00, p=2.83e-05
Paired t-test (game_entropy vs capabilities_entropy): statistic=3.46, p=0.000651
Mean capabilities_entropy-game_entropy = -0.1167  [-0.1827, -0.0506] (n=204)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  204
Model:                          Logit   Df Residuals:                      201
Method:                           MLE   Df Model:                            2
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.2572
Time:                        21:14:17   Log-Likelihood:                -80.886
converged:                       True   LL-Null:                       -108.89
Covariance Type:            nonrobust   LLR p-value:                 6.893e-13
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.7208      0.335     -8.114      0.000      -3.378      -2.064
capabilities_entropy     1.1604      0.437      2.655      0.008       0.304       2.017
game_entropy             2.2339      0.427      5.237      0.000       1.398       3.070
========================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  204
Model:                          Logit   Df Residuals:                      202
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:               0.0005795
Time:                        21:14:17   Log-Likelihood:                -108.83
converged:                       True   LL-Null:                       -108.89
Covariance Type:            nonrobust   LLR p-value:                    0.7224
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -0.9834      0.724     -1.359      0.174      -2.402       0.435
human_difficulty    -0.1061      0.299     -0.355      0.723      -0.693       0.481
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  204
Model:                          Logit   Df Residuals:                      197
Method:                           MLE   Df Model:                            6
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.03486
Time:                        21:14:17   Log-Likelihood:                -105.09
converged:                       True   LL-Null:                       -108.89
Covariance Type:            nonrobust   LLR p-value:                    0.2695
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -3.9412      2.457     -1.604      0.109      -8.757       0.875
C(domain_grouped)[T.chemistry]        1.1318      0.543      2.086      0.037       0.068       2.195
C(domain_grouped)[T.physics]          0.4552      0.543      0.838      0.402      -0.609       1.520
human_difficulty                      0.0222      0.318      0.070      0.944      -0.601       0.645
q_length                              0.2448      0.298      0.822      0.411      -0.339       0.829
avg_word_length                       0.0869      0.270      0.322      0.747      -0.442       0.616
percent_non_alphabetic_whitespace     0.0202      0.033      0.620      0.536      -0.044       0.084
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 0.2549
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  204
Model:                          Logit   Df Residuals:                      196
Method:                           MLE   Df Model:                            7
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.1269
Time:                        21:14:17   Log-Likelihood:                -95.070
converged:                       True   LL-Null:                       -108.89
Covariance Type:            nonrobust   LLR p-value:                 0.0002557
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -4.2236      2.534     -1.667      0.096      -9.190       0.742
C(domain_grouped)[T.chemistry]        0.5214      0.589      0.885      0.376      -0.634       1.676
C(domain_grouped)[T.physics]          0.1488      0.569      0.262      0.794      -0.965       1.263
human_difficulty                      0.1048      0.339      0.309      0.757      -0.560       0.769
q_length                              0.1519      0.316      0.480      0.631      -0.468       0.772
avg_word_length                       0.1638      0.274      0.598      0.550      -0.373       0.700
percent_non_alphabetic_whitespace     0.0289      0.035      0.831      0.406      -0.039       0.097
capabilities_entropy                  1.7586      0.408      4.307      0.000       0.958       2.559
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  204
Model:                          Logit   Df Residuals:                      196
Method:                           MLE   Df Model:                            7
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.2436
Time:                        21:14:17   Log-Likelihood:                -82.359
converged:                       True   LL-Null:                       -108.89
Covariance Type:            nonrobust   LLR p-value:                 3.607e-09
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -4.9650      2.788     -1.781      0.075     -10.430       0.500
C(domain_grouped)[T.chemistry]        0.3176      0.634      0.501      0.616      -0.925       1.560
C(domain_grouped)[T.physics]          0.0486      0.631      0.077      0.939      -1.189       1.286
human_difficulty                      0.0042      0.367      0.011      0.991      -0.715       0.723
q_length                             -0.0245      0.356     -0.069      0.945      -0.722       0.673
avg_word_length                       0.4268      0.302      1.415      0.157      -0.165       1.018
percent_non_alphabetic_whitespace     0.0526      0.037      1.433      0.152      -0.019       0.124
game_entropy                          2.5990      0.434      5.993      0.000       1.749       3.449
=====================================================================================================

                  Model 4.95: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  204
Model:                          Logit   Df Residuals:                      195
Method:                           MLE   Df Model:                            8
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                  0.2741
Time:                        21:14:17   Log-Likelihood:                -79.044
converged:                       True   LL-Null:                       -108.89
Covariance Type:            nonrobust   LLR p-value:                 5.364e-10
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -5.0341      2.808     -1.793      0.073     -10.537       0.469
C(domain_grouped)[T.chemistry]       -0.0027      0.653     -0.004      0.997      -1.282       1.277
C(domain_grouped)[T.physics]         -0.1090      0.634     -0.172      0.864      -1.352       1.134
human_difficulty                      0.1065      0.376      0.283      0.777      -0.631       0.844
q_length                             -0.0875      0.366     -0.239      0.811      -0.805       0.630
avg_word_length                       0.4503      0.296      1.522      0.128      -0.129       1.030
percent_non_alphabetic_whitespace     0.0531      0.037      1.427      0.154      -0.020       0.126
capabilities_entropy                  1.1656      0.458      2.547      0.011       0.269       2.063
game_entropy                          2.3551      0.449      5.242      0.000       1.474       3.236
=====================================================================================================

--- Analyzing qwen3-235b-a22b-2507 (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/qwen3-235b-a22b-2507_GPQA_redacted_temp0.0_1756233720_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    168
1     75
Name: count, dtype: int64

Answer change%: 0.3086 [0.25056233030625347, 0.36672162031103045] (n=243)
P-value vs 25%: 0.04782; P-value vs 0%: 2.107e-25
Phase 2 self-accuracy: 0.4800 [0.36693198969084995, 0.59306801030915] (n=75)
P-value vs 25%: 6.694e-05; P-value vs 33%: 0.01083

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  243
Model:                          Logit   Df Residuals:                      241
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.02900
Time:                        21:14:17   Log-Likelihood:                -145.82
converged:                       True   LL-Null:                       -150.18
Covariance Type:            nonrobust   LLR p-value:                  0.003162
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          1.0815      0.648      1.669      0.095      -0.189       2.352
p_i_capability    -2.2194      0.752     -2.951      0.003      -3.694      -0.745
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  243
Model:                          Logit   Df Residuals:                      241
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.02743
Time:                        21:14:17   Log-Likelihood:                -146.06
converged:                       True   LL-Null:                       -150.18
Covariance Type:            nonrobust   LLR p-value:                  0.004098
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.1772      0.198     -5.959      0.000      -1.564      -0.790
capabilities_entropy     0.7165      0.250      2.862      0.004       0.226       1.207
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.7467 [0.6482, 0.8451] (n=75)
                  P-value vs 33.3%: 1.866e-16

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=1.25, p=0.213
Wilcoxon delta_p: statistic=3603.00, p=0.0302
Mean Δp = 0.0231  [-0.0130, 0.0592]
Idea 1 N = 136; 

  Idea 1.5: Calibration Metrics
  NLL: 12.1265, Signed ECE (overconf pos under neg): 0.0554, ECE: 0.0554 (n=194)
  Brier: 0.0143, Reliability (absolute calibration error; lower better): 0.0137, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=194)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.804
Model:                            OLS   Adj. R-squared:                  0.801
Method:                 Least Squares   F-statistic:                     270.7
Date:                Fri, 19 Sep 2025   Prob (F-statistic):           8.80e-70
Time:                        21:14:17   Log-Likelihood:                 70.927
No. Observations:                 202   AIC:                            -133.9
Df Residuals:                     198   BIC:                            -120.6
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.6584      0.076     -8.619      0.000      -0.809      -0.508
p1                    0.7796      0.086      9.092      0.000       0.610       0.949
answer_changed        0.3227      0.117      2.751      0.006       0.091       0.554
p1:answer_changed     0.4306      0.136      3.164      0.002       0.162       0.699
==============================================================================
Omnibus:                       26.421   Durbin-Watson:                   2.053
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               96.830
Skew:                           0.396   Prob(JB):                     9.41e-22
Kurtosis:                       6.298   Cond. No.                         22.7
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-4.32, p=3e-05
Wilcoxon delta_H: statistic=2819.00, p=0.000155
Mean ΔH = -0.2194  [-0.3189, -0.1199]
Paired t-test delta_H Changed: statistic=0.19, p=0.85
Wilcoxon delta_H Changed: statistic=1107.00, p=0.842
Mean ΔH Changed = 0.0132  [-0.1235, 0.1499]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=-0.06, p=0.951
Wilcoxon (p_top2_game vs p_top2_base): statistic=7480.00, p=0.000607
Mean Δp_top2 = -0.0003  [-0.0092, 0.0086] (n=203)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=-3.42, p=0.000756
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=7503.00, p=0.00134
Mean ΔH_unchosen_baseline_set = -0.1426  [-0.2244, -0.0609] (n=203)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  203
Model:                          Logit   Df Residuals:                      200
Method:                           MLE   Df Model:                            2
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.01895
Time:                        21:14:17   Log-Likelihood:                -126.31
converged:                       True   LL-Null:                       -128.75
Covariance Type:            nonrobust   LLR p-value:                   0.08722
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.7860      0.243     -3.232      0.001      -1.263      -0.309
p1_z            -0.2543      0.246     -1.035      0.301      -0.736       0.227
I(p1_z ** 2)     0.0634      0.192      0.331      0.741      -0.312       0.439
================================================================================
AUC = 0.592

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  243
Model:                          Logit   Df Residuals:                      241
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.07500
Time:                        21:14:17   Log-Likelihood:                -138.91
converged:                       True   LL-Null:                       -150.18
Covariance Type:            nonrobust   LLR p-value:                 2.074e-06
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.5965      0.238     -6.717      0.000      -2.062      -1.131
game_entropy     1.3516      0.295      4.578      0.000       0.773       1.930
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=12093.00, p=0.11
Paired t-test (game_entropy vs capabilities_entropy): statistic=1.13, p=0.259
Mean capabilities_entropy-game_entropy = -0.0470  [-0.1286, 0.0345] (n=243)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  243
Model:                          Logit   Df Residuals:                      240
Method:                           MLE   Df Model:                            2
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.08611
Time:                        21:14:17   Log-Likelihood:                -137.24
converged:                       True   LL-Null:                       -150.18
Covariance Type:            nonrobust   LLR p-value:                 2.419e-06
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.7747      0.261     -6.793      0.000      -2.287      -1.263
capabilities_entropy     0.4890      0.267      1.834      0.067      -0.034       1.012
game_entropy             1.2316      0.302      4.081      0.000       0.640       1.823
========================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  243
Model:                          Logit   Df Residuals:                      241
Method:                           MLE   Df Model:                            1
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:               5.022e-06
Time:                        21:14:17   Log-Likelihood:                -150.18
converged:                       True   LL-Null:                       -150.18
Covariance Type:            nonrobust   LLR p-value:                    0.9690
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -0.7845      0.583     -1.345      0.179      -1.927       0.358
human_difficulty    -0.0093      0.239     -0.039      0.969      -0.478       0.459
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  243
Model:                          Logit   Df Residuals:                      236
Method:                           MLE   Df Model:                            6
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.01012
Time:                        21:14:17   Log-Likelihood:                -148.66
converged:                       True   LL-Null:                       -150.18
Covariance Type:            nonrobust   LLR p-value:                    0.8039
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                             0.3420      2.104      0.163      0.871      -3.781       4.465
C(domain_grouped)[T.chemistry]        0.4099      0.512      0.800      0.424      -0.594       1.414
C(domain_grouped)[T.physics]          0.1191      0.538      0.221      0.825      -0.936       1.174
human_difficulty                      0.0384      0.252      0.153      0.879      -0.455       0.532
q_length                             -0.2603      0.219     -1.190      0.234      -0.689       0.168
avg_word_length                       0.0127      0.232      0.055      0.956      -0.443       0.468
percent_non_alphabetic_whitespace    -0.0015      0.024     -0.061      0.952      -0.049       0.046
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 0.4798
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  243
Model:                          Logit   Df Residuals:                      235
Method:                           MLE   Df Model:                            7
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.03513
Time:                        21:14:17   Log-Likelihood:                -144.90
converged:                       True   LL-Null:                       -150.18
Covariance Type:            nonrobust   LLR p-value:                    0.1594
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -0.2601      2.148     -0.121      0.904      -4.471       3.951
C(domain_grouped)[T.chemistry]        0.2881      0.521      0.553      0.580      -0.734       1.310
C(domain_grouped)[T.physics]          0.0078      0.548      0.014      0.989      -1.067       1.082
human_difficulty                      0.0577      0.257      0.225      0.822      -0.445       0.561
q_length                             -0.2226      0.222     -1.003      0.316      -0.658       0.212
avg_word_length                       0.0237      0.237      0.100      0.920      -0.441       0.488
percent_non_alphabetic_whitespace     0.0020      0.025      0.082      0.935      -0.047       0.051
capabilities_entropy                  0.6930      0.253      2.735      0.006       0.196       1.190
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  243
Model:                          Logit   Df Residuals:                      235
Method:                           MLE   Df Model:                            7
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.08914
Time:                        21:14:17   Log-Likelihood:                -136.79
converged:                       True   LL-Null:                       -150.18
Covariance Type:            nonrobust   LLR p-value:                 0.0003663
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -1.4167      2.209     -0.641      0.521      -5.747       2.914
C(domain_grouped)[T.chemistry]        0.3558      0.531      0.671      0.503      -0.684       1.396
C(domain_grouped)[T.physics]          0.0434      0.556      0.078      0.938      -1.045       1.132
human_difficulty                      0.0871      0.261      0.334      0.738      -0.424       0.598
q_length                             -0.2759      0.231     -1.196      0.232      -0.728       0.176
avg_word_length                       0.2010      0.240      0.837      0.403      -0.270       0.672
percent_non_alphabetic_whitespace     0.0090      0.026      0.345      0.730      -0.042       0.060
game_entropy                          1.4345      0.308      4.657      0.000       0.831       2.038
=====================================================================================================

                  Model 4.95: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  243
Model:                          Logit   Df Residuals:                      234
Method:                           MLE   Df Model:                            8
Date:                Fri, 19 Sep 2025   Pseudo R-squ.:                 0.09860
Time:                        21:14:17   Log-Likelihood:                -135.37
converged:                       True   LL-Null:                       -150.18
Covariance Type:            nonrobust   LLR p-value:                 0.0002472
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -1.6319      2.230     -0.732      0.464      -6.002       2.738
C(domain_grouped)[T.chemistry]        0.2807      0.536      0.524      0.601      -0.770       1.331
C(domain_grouped)[T.physics]         -0.0250      0.562     -0.044      0.965      -1.127       1.077
human_difficulty                      0.0914      0.263      0.348      0.728      -0.424       0.607
q_length                             -0.2550      0.233     -1.093      0.274      -0.712       0.202
avg_word_length                       0.1947      0.243      0.801      0.423      -0.282       0.671
percent_non_alphabetic_whitespace     0.0099      0.026      0.374      0.709      -0.042       0.062
capabilities_entropy                  0.4573      0.270      1.692      0.091      -0.072       0.987
game_entropy                          1.3254      0.315      4.209      0.000       0.708       1.943
=====================================================================================================
