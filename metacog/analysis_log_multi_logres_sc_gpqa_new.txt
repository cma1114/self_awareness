
--- Analyzing claude-3-5-sonnet-20241022 (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/claude-3-5-sonnet-20241022_GPQA_redacted_cor_temp0.0_1753836130_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    164
1     31
Name: count, dtype: int64

Answer change%: 0.1590 [0.1076529058083461, 0.21029581214037182] (n=195)
P-value vs 25%: 0.0005084; P-value vs 0%: 1.269e-09
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=31)
P-value vs 25%: 0; P-value vs 33%: 0

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  195
Model:                          Logit   Df Residuals:                      193
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.2378
Time:                        17:34:55   Log-Likelihood:                -65.093
converged:                       True   LL-Null:                       -85.403
Covariance Type:            nonrobust   LLR p-value:                 1.849e-10
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          2.8308      0.746      3.794      0.000       1.368       4.293
p_i_capability    -6.1355      1.065     -5.759      0.000      -8.224      -4.048
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  195
Model:                          Logit   Df Residuals:                      193
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.2121
Time:                        17:34:55   Log-Likelihood:                -67.286
converged:                       True   LL-Null:                       -85.403
Covariance Type:            nonrobust   LLR p-value:                 1.750e-09
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -3.7487      0.504     -7.431      0.000      -4.737      -2.760
capabilities_entropy     2.1920      0.401      5.466      0.000       1.406       2.978
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.6129 [0.4414, 0.7844] (n=31)
                  P-value vs 33.3%: 0.001395

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=-2.55, p=0.0117
Wilcoxon delta_p: statistic=1341.00, p=0.00189
Mean Δp = -0.0236  [-0.0418, -0.0055]
Idea 1 N = 164; 

  Idea 1.5: Calibration Metrics
  NLL: 0.2495, Signed ECE (overconf pos under neg): -0.1901, ECE: 0.1901 (n=195)
  Brier: 0.0745, Reliability (absolute calibration error; lower better): 0.0740, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=195)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.701
Model:                            OLS   Adj. R-squared:                  0.696
Method:                 Least Squares   F-statistic:                     149.3
Date:                Sat, 09 Aug 2025   Prob (F-statistic):           7.81e-50
Time:                        17:34:55   Log-Likelihood:                 159.23
No. Observations:                 195   AIC:                            -310.5
Df Residuals:                     191   BIC:                            -297.4
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.3328      0.043     -7.787      0.000      -0.417      -0.249
p1                    0.3633      0.049      7.379      0.000       0.266       0.460
answer_changed        0.0872      0.082      1.060      0.290      -0.075       0.249
p1:answer_changed     0.6475      0.124      5.206      0.000       0.402       0.893
==============================================================================
Omnibus:                       37.097   Durbin-Watson:                   1.781
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               86.570
Skew:                           0.845   Prob(JB):                     1.59e-19
Kurtosis:                       5.792   Cond. No.                         25.4
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=0.50, p=0.619
Wilcoxon delta_H: statistic=2041.50, p=0.581
Mean ΔH = 0.0165  [-0.0485, 0.0816]
Paired t-test delta_H Changed: statistic=3.89, p=0.00051
Wilcoxon delta_H Changed: statistic=72.00, p=0.000287
Mean ΔH Changed = 0.2861  [0.1421, 0.4302]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=3.25, p=0.00134
Wilcoxon (p_top2_game vs p_top2_base): statistic=2524.50, p=0.000758
Mean Δp_top2 = 0.0161  [0.0064, 0.0257] (n=195)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=1.92, p=0.0569
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=3068.50, p=0.0443
Mean ΔH_unchosen_baseline_set = 0.0594  [-0.0014, 0.1202] (n=195)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  195
Model:                          Logit   Df Residuals:                      192
Method:                           MLE   Df Model:                            2
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.2953
Time:                        17:34:55   Log-Likelihood:                -60.185
converged:                       True   LL-Null:                       -85.403
Covariance Type:            nonrobust   LLR p-value:                 1.117e-11
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.8414      0.325     -5.672      0.000      -2.478      -1.205
p1_z            -2.3830      0.505     -4.715      0.000      -3.374      -1.392
I(p1_z ** 2)    -0.7422      0.251     -2.962      0.003      -1.233      -0.251
================================================================================
AUC = 0.859

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  195
Model:                          Logit   Df Residuals:                      193
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.2151
Time:                        17:34:55   Log-Likelihood:                -67.032
converged:                       True   LL-Null:                       -85.403
Covariance Type:            nonrobust   LLR p-value:                 1.348e-09
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -3.6188      0.472     -7.669      0.000      -4.544      -2.694
game_entropy     2.3124      0.414      5.590      0.000       1.502       3.123
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=2492.50, p=0.000566
Paired t-test (game_entropy vs capabilities_entropy): statistic=-3.41, p=0.000786
Mean capabilities_entropy-game_entropy = 0.0833  [0.0355, 0.1312] (n=195)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  195
Model:                          Logit   Df Residuals:                      192
Method:                           MLE   Df Model:                            2
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.2398
Time:                        17:34:55   Log-Likelihood:                -64.920
converged:                       True   LL-Null:                       -85.403
Covariance Type:            nonrobust   LLR p-value:                 1.271e-09
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -3.9451      0.522     -7.564      0.000      -4.967      -2.923
capabilities_entropy     1.2341      0.599      2.062      0.039       0.061       2.407
game_entropy             1.3145      0.618      2.128      0.033       0.104       2.525
========================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  195
Model:                          Logit   Df Residuals:                      193
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.02511
Time:                        17:34:55   Log-Likelihood:                -83.259
converged:                       True   LL-Null:                       -85.403
Covariance Type:            nonrobust   LLR p-value:                   0.03835
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept            0.0706      0.852      0.083      0.934      -1.600       1.741
human_difficulty    -0.7689      0.379     -2.028      0.043      -1.512      -0.026
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  195
Model:                          Logit   Df Residuals:                      188
Method:                           MLE   Df Model:                            6
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.06694
Time:                        17:34:55   Log-Likelihood:                -79.686
converged:                       True   LL-Null:                       -85.403
Covariance Type:            nonrobust   LLR p-value:                   0.07586
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                             1.2276      3.242      0.379      0.705      -5.127       7.582
C(domain_grouped)[T.chemistry]        0.9306      0.736      1.264      0.206      -0.513       2.374
C(domain_grouped)[T.physics]          0.8810      0.705      1.250      0.211      -0.501       2.263
human_difficulty                     -0.5722      0.390     -1.467      0.142      -1.336       0.192
q_length                              0.0952      0.367      0.259      0.796      -0.625       0.815
avg_word_length                      -0.6103      0.407     -1.501      0.133      -1.407       0.187
percent_non_alphabetic_whitespace    -0.0163      0.038     -0.423      0.672      -0.092       0.059
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 0.7453
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  195
Model:                          Logit   Df Residuals:                      187
Method:                           MLE   Df Model:                            7
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.2533
Time:                        17:34:55   Log-Likelihood:                -63.773
converged:                       True   LL-Null:                       -85.403
Covariance Type:            nonrobust   LLR p-value:                 2.970e-07
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -0.7111      3.615     -0.197      0.844      -7.797       6.375
C(domain_grouped)[T.chemistry]        0.2493      0.803      0.311      0.756      -1.325       1.823
C(domain_grouped)[T.physics]          0.5808      0.757      0.767      0.443      -0.904       2.065
human_difficulty                     -0.7227      0.466     -1.550      0.121      -1.637       0.191
q_length                             -0.2111      0.409     -0.517      0.605      -1.012       0.590
avg_word_length                      -0.1743      0.411     -0.424      0.672      -0.980       0.632
percent_non_alphabetic_whitespace     0.0207      0.043      0.487      0.627      -0.063       0.104
capabilities_entropy                  2.2519      0.446      5.052      0.000       1.378       3.125
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  195
Model:                          Logit   Df Residuals:                      187
Method:                           MLE   Df Model:                            7
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.2509
Time:                        17:34:55   Log-Likelihood:                -63.974
converged:                       True   LL-Null:                       -85.403
Covariance Type:            nonrobust   LLR p-value:                 3.553e-07
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -1.2384      3.485     -0.355      0.722      -8.069       5.592
C(domain_grouped)[T.chemistry]       -0.1548      0.801     -0.193      0.847      -1.725       1.415
C(domain_grouped)[T.physics]          0.1836      0.792      0.232      0.817      -1.368       1.735
human_difficulty                     -0.9125      0.483     -1.889      0.059      -1.859       0.034
q_length                             -0.0206      0.398     -0.052      0.959      -0.801       0.760
avg_word_length                      -0.0874      0.415     -0.211      0.833      -0.901       0.726
percent_non_alphabetic_whitespace     0.0122      0.044      0.279      0.780      -0.073       0.098
game_entropy                          2.3875      0.472      5.055      0.000       1.462       3.313
=====================================================================================================

                  Model 4.95: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  195
Model:                          Logit   Df Residuals:                      186
Method:                           MLE   Df Model:                            8
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.2767
Time:                        17:34:55   Log-Likelihood:                -61.772
converged:                       True   LL-Null:                       -85.403
Covariance Type:            nonrobust   LLR p-value:                 1.366e-07
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -1.1545      3.597     -0.321      0.748      -8.205       5.896
C(domain_grouped)[T.chemistry]       -0.2128      0.822     -0.259      0.796      -1.824       1.399
C(domain_grouped)[T.physics]          0.2103      0.782      0.269      0.788      -1.322       1.742
human_difficulty                     -0.8659      0.491     -1.763      0.078      -1.828       0.097
q_length                             -0.1791      0.411     -0.435      0.663      -0.985       0.627
avg_word_length                      -0.0288      0.422     -0.068      0.946      -0.856       0.798
percent_non_alphabetic_whitespace     0.0222      0.044      0.505      0.614      -0.064       0.108
capabilities_entropy                  1.3430      0.639      2.103      0.035       0.091       2.595
game_entropy                          1.3299      0.676      1.966      0.049       0.004       2.656
=====================================================================================================

--- Analyzing claude-3-5-sonnet-20241022 (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/claude-3-5-sonnet-20241022_GPQA_redacted_temp0.0_1753884209_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    160
1     92
Name: count, dtype: int64

Answer change%: 0.3651 [0.3056363013863806, 0.4245224287723495] (n=252)
P-value vs 25%: 0.000148; P-value vs 0%: 2.259e-33
Phase 2 self-accuracy: 0.3478 [0.25050275604046973, 0.4451494178725737] (n=92)
P-value vs 25%: 0.04883; P-value vs 33%: 0.7653

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  252
Model:                          Logit   Df Residuals:                      250
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1444
Time:                        17:34:55   Log-Likelihood:                -141.50
converged:                       True   LL-Null:                       -165.38
Covariance Type:            nonrobust   LLR p-value:                 4.793e-12
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          2.5015      0.492      5.085      0.000       1.537       3.466
p_i_capability    -4.8166      0.774     -6.224      0.000      -6.333      -3.300
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  252
Model:                          Logit   Df Residuals:                      250
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1593
Time:                        17:34:55   Log-Likelihood:                -139.03
converged:                       True   LL-Null:                       -165.38
Covariance Type:            nonrobust   LLR p-value:                 3.873e-13
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -3.0810      0.451     -6.831      0.000      -3.965      -2.197
capabilities_entropy     2.0218      0.320      6.323      0.000       1.395       2.648
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.6413 [0.5433, 0.7393] (n=92)
                  P-value vs 33.3%: 7.322e-10

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=-2.85, p=0.00489
Wilcoxon delta_p: statistic=3444.50, p=0.00282
Mean Δp = -0.0417  [-0.0703, -0.0131]
Idea 1 N = 160; 

  Idea 1.5: Calibration Metrics
  NLL: 2.6878, Signed ECE (overconf pos under neg): 0.1284, ECE: 0.1284 (n=252)
  Brier: 0.0300, Reliability (absolute calibration error; lower better): 0.0292, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=252)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.696
Model:                            OLS   Adj. R-squared:                  0.692
Method:                 Least Squares   F-statistic:                     188.9
Date:                Sat, 09 Aug 2025   Prob (F-statistic):           9.19e-64
Time:                        17:34:55   Log-Likelihood:                 124.08
No. Observations:                 252   AIC:                            -240.2
Df Residuals:                     248   BIC:                            -226.0
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.3928      0.044     -8.942      0.000      -0.479      -0.306
p1                    0.4817      0.058      8.298      0.000       0.367       0.596
answer_changed        0.1490      0.070      2.132      0.034       0.011       0.287
p1:answer_changed     0.5788      0.112      5.184      0.000       0.359       0.799
==============================================================================
Omnibus:                        6.265   Durbin-Watson:                   2.149
Prob(Omnibus):                  0.044   Jarque-Bera (JB):                6.235
Skew:                           0.351   Prob(JB):                       0.0443
Kurtosis:                       2.681   Cond. No.                         18.8
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-0.07, p=0.941
Wilcoxon delta_H: statistic=4831.00, p=0.829
Mean ΔH = -0.0026  [-0.0718, 0.0665]
Paired t-test delta_H Changed: statistic=8.67, p=1.54e-13
Wilcoxon delta_H Changed: statistic=352.00, p=3.44e-12
Mean ΔH Changed = 0.3432  [0.2656, 0.4208]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=4.99, p=1.12e-06
Wilcoxon (p_top2_game vs p_top2_base): statistic=8744.00, p=3.15e-06
Mean Δp_top2 = 0.0287  [0.0174, 0.0399] (n=252)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=4.32, p=2.24e-05
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=9012.00, p=1.09e-05
Mean ΔH_unchosen_baseline_set = 0.1236  [0.0676, 0.1797] (n=252)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  252
Model:                          Logit   Df Residuals:                      249
Method:                           MLE   Df Model:                            2
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1535
Time:                        17:34:55   Log-Likelihood:                -139.99
converged:                       True   LL-Null:                       -165.38
Covariance Type:            nonrobust   LLR p-value:                 9.369e-12
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.4340      0.209     -2.078      0.038      -0.843      -0.025
p1_z            -1.0766      0.179     -6.024      0.000      -1.427      -0.726
I(p1_z ** 2)    -0.3229      0.189     -1.713      0.087      -0.693       0.047
================================================================================
AUC = 0.749

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  252
Model:                          Logit   Df Residuals:                      250
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1327
Time:                        17:34:55   Log-Likelihood:                -143.44
converged:                       True   LL-Null:                       -165.38
Covariance Type:            nonrobust   LLR p-value:                 3.485e-11
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -2.4973      0.368     -6.794      0.000      -3.218      -1.777
game_entropy     1.7767      0.293      6.059      0.000       1.202       2.351
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=8352.00, p=4.56e-07
Paired t-test (game_entropy vs capabilities_entropy): statistic=-5.13, p=5.72e-07
Mean capabilities_entropy-game_entropy = 0.1339  [0.0828, 0.1850] (n=252)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  252
Model:                          Logit   Df Residuals:                      249
Method:                           MLE   Df Model:                            2
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1756
Time:                        17:34:55   Log-Likelihood:                -136.35
converged:                       True   LL-Null:                       -165.38
Covariance Type:            nonrobust   LLR p-value:                 2.455e-13
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -3.3114      0.469     -7.066      0.000      -4.230      -2.393
capabilities_entropy     1.4473      0.398      3.636      0.000       0.667       2.227
game_entropy             0.8639      0.376      2.299      0.022       0.127       1.601
========================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  252
Model:                          Logit   Df Residuals:                      250
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:               2.524e-05
Time:                        17:34:55   Log-Likelihood:                -165.38
converged:                       True   LL-Null:                       -165.38
Covariance Type:            nonrobust   LLR p-value:                    0.9272
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -0.6016      0.544     -1.106      0.269      -1.668       0.465
human_difficulty     0.0201      0.220      0.091      0.927      -0.411       0.451
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  252
Model:                          Logit   Df Residuals:                      245
Method:                           MLE   Df Model:                            6
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.01358
Time:                        17:34:55   Log-Likelihood:                -163.14
converged:                       True   LL-Null:                       -165.38
Covariance Type:            nonrobust   LLR p-value:                    0.6102
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                             0.5718      2.110      0.271      0.786      -3.563       4.707
C(domain_grouped)[T.chemistry]        0.4259      0.510      0.835      0.403      -0.573       1.425
C(domain_grouped)[T.physics]          0.5765      0.524      1.099      0.272      -0.451       1.605
human_difficulty                      0.1194      0.231      0.517      0.605      -0.334       0.572
q_length                             -0.1144      0.215     -0.532      0.595      -0.536       0.307
avg_word_length                      -0.2459      0.244     -1.008      0.314      -0.724       0.232
percent_non_alphabetic_whitespace    -0.0076      0.024     -0.314      0.753      -0.055       0.040
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 1.1634
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  252
Model:                          Logit   Df Residuals:                      244
Method:                           MLE   Df Model:                            7
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1698
Time:                        17:34:55   Log-Likelihood:                -137.31
converged:                       True   LL-Null:                       -165.38
Covariance Type:            nonrobust   LLR p-value:                 8.820e-10
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -3.0285      2.412     -1.256      0.209      -7.756       1.699
C(domain_grouped)[T.chemistry]       -0.3808      0.603     -0.632      0.527      -1.562       0.800
C(domain_grouped)[T.physics]          0.0785      0.622      0.126      0.900      -1.141       1.298
human_difficulty                      0.2101      0.259      0.811      0.418      -0.298       0.718
q_length                             -0.1308      0.249     -0.526      0.599      -0.618       0.357
avg_word_length                       0.0200      0.275      0.073      0.942      -0.519       0.559
percent_non_alphabetic_whitespace     0.0190      0.027      0.696      0.487      -0.035       0.073
capabilities_entropy                  2.1040      0.335      6.285      0.000       1.448       2.760
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  252
Model:                          Logit   Df Residuals:                      244
Method:                           MLE   Df Model:                            7
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1432
Time:                        17:34:55   Log-Likelihood:                -141.70
converged:                       True   LL-Null:                       -165.38
Covariance Type:            nonrobust   LLR p-value:                 4.723e-08
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -2.4706      2.362     -1.046      0.296      -7.099       2.158
C(domain_grouped)[T.chemistry]       -0.0451      0.561     -0.080      0.936      -1.145       1.055
C(domain_grouped)[T.physics]          0.3963      0.575      0.689      0.491      -0.731       1.524
human_difficulty                      0.2073      0.254      0.816      0.415      -0.291       0.705
q_length                             -0.1503      0.238     -0.632      0.528      -0.617       0.316
avg_word_length                       0.0022      0.260      0.008      0.993      -0.506       0.511
percent_non_alphabetic_whitespace     0.0170      0.026      0.653      0.514      -0.034       0.068
game_entropy                          1.8253      0.305      5.982      0.000       1.227       2.423
=====================================================================================================

                  Model 4.95: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  252
Model:                          Logit   Df Residuals:                      243
Method:                           MLE   Df Model:                            8
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1879
Time:                        17:34:56   Log-Likelihood:                -134.30
converged:                       True   LL-Null:                       -165.38
Covariance Type:            nonrobust   LLR p-value:                 1.753e-10
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -3.6236      2.449     -1.480      0.139      -8.423       1.176
C(domain_grouped)[T.chemistry]       -0.4194      0.598     -0.702      0.483      -1.591       0.752
C(domain_grouped)[T.physics]          0.1023      0.613      0.167      0.868      -1.100       1.304
human_difficulty                      0.2222      0.263      0.844      0.399      -0.294       0.738
q_length                             -0.1293      0.251     -0.515      0.606      -0.621       0.362
avg_word_length                       0.0719      0.274      0.262      0.793      -0.465       0.609
percent_non_alphabetic_whitespace     0.0250      0.027      0.915      0.360      -0.029       0.079
capabilities_entropy                  1.5135      0.407      3.717      0.000       0.716       2.312
game_entropy                          0.9234      0.380      2.432      0.015       0.179       1.668
=====================================================================================================

--- Analyzing claude-3-haiku-20240307 (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/claude-3-haiku-20240307_GPQA_redacted_cor_temp0.0_1751757100_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    99
1    37
Name: count, dtype: int64

Answer change%: 0.2721 [0.19726629981773552, 0.34685134724108796] (n=136)
P-value vs 25%: 0.5632; P-value vs 0%: 1.008e-12
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=37)
P-value vs 25%: 0; P-value vs 33%: 0

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  136
Model:                          Logit   Df Residuals:                      134
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                0.003839
Time:                        17:34:56   Log-Likelihood:                -79.295
converged:                       True   LL-Null:                       -79.600
Covariance Type:            nonrobust   LLR p-value:                    0.4344
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          0.0928      1.366      0.068      0.946      -2.584       2.769
p_i_capability    -1.1998      1.512     -0.793      0.427      -4.163       1.764
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  136
Model:                          Logit   Df Residuals:                      134
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                0.006125
Time:                        17:34:56   Log-Likelihood:                -79.113
converged:                       True   LL-Null:                       -79.600
Covariance Type:            nonrobust   LLR p-value:                    0.3234
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.3008      0.376     -3.461      0.001      -2.037      -0.564
capabilities_entropy     0.7000      0.698      1.003      0.316      -0.668       2.068
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.2162 [0.0836, 0.3489] (n=37)
                  P-value vs 33.3%: 0.08354

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  136
Model:                          Logit   Df Residuals:                      134
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:               0.0002636
Time:                        17:34:56   Log-Likelihood:                -79.579
converged:                       True   LL-Null:                       -79.600
Covariance Type:            nonrobust   LLR p-value:                    0.8377
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -1.1612      0.886     -1.310      0.190      -2.899       0.576
human_difficulty     0.0742      0.362      0.205      0.838      -0.635       0.784
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  136
Model:                          Logit   Df Residuals:                      129
Method:                           MLE   Df Model:                            6
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.06366
Time:                        17:34:56   Log-Likelihood:                -74.533
converged:                       True   LL-Null:                       -79.600
Covariance Type:            nonrobust   LLR p-value:                    0.1191
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -2.2950      2.747     -0.835      0.404      -7.680       3.090
C(domain_grouped)[T.chemistry]        1.7231      0.658      2.619      0.009       0.434       3.012
C(domain_grouped)[T.physics]          1.2626      0.671      1.881      0.060      -0.053       2.578
human_difficulty                      0.1589      0.374      0.424      0.671      -0.575       0.893
q_length                             -0.2847      0.358     -0.796      0.426      -0.986       0.416
avg_word_length                       0.3485      0.259      1.344      0.179      -0.160       0.857
percent_non_alphabetic_whitespace    -0.0338      0.036     -0.929      0.353      -0.105       0.037
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 0.4420
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  136
Model:                          Logit   Df Residuals:                      128
Method:                           MLE   Df Model:                            7
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.07822
Time:                        17:34:56   Log-Likelihood:                -73.374
converged:                       True   LL-Null:                       -79.600
Covariance Type:            nonrobust   LLR p-value:                   0.08663
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -2.9065      2.775     -1.047      0.295      -8.346       2.533
C(domain_grouped)[T.chemistry]        1.7898      0.666      2.689      0.007       0.485       3.094
C(domain_grouped)[T.physics]          1.3056      0.676      1.931      0.053      -0.020       2.631
human_difficulty                      0.2022      0.381      0.530      0.596      -0.545       0.949
q_length                             -0.3351      0.358     -0.935      0.350      -1.037       0.367
avg_word_length                       0.4067      0.265      1.536      0.125      -0.112       0.926
percent_non_alphabetic_whitespace    -0.0403      0.037     -1.079      0.281      -0.113       0.033
capabilities_entropy                  1.1749      0.763      1.539      0.124      -0.321       2.671
=====================================================================================================

--- Analyzing claude-3-haiku-20240307 (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/claude-3-haiku-20240307_GPQA_redacted_temp0.0_1754158953_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    238
1     57
Name: count, dtype: int64

Answer change%: 0.1932 [0.1481655486064766, 0.2382751293596251] (n=295)
P-value vs 25%: 0.01351; P-value vs 0%: 4.263e-17
Phase 2 self-accuracy: 0.2632 [0.14884214151558706, 0.3774736479580971] (n=57)
P-value vs 25%: 0.8215; P-value vs 33%: 0.2311

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  295
Model:                          Logit   Df Residuals:                      293
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1160
Time:                        17:34:56   Log-Likelihood:                -128.01
converged:                       True   LL-Null:                       -144.80
Covariance Type:            nonrobust   LLR p-value:                 6.805e-09
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          3.1762      0.805      3.944      0.000       1.598       4.755
p_i_capability    -5.3179      0.931     -5.711      0.000      -7.143      -3.493
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  295
Model:                          Logit   Df Residuals:                      293
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1405
Time:                        17:34:56   Log-Likelihood:                -124.46
converged:                       True   LL-Null:                       -144.80
Covariance Type:            nonrobust   LLR p-value:                 1.791e-10
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.9064      0.306     -9.507      0.000      -3.506      -2.307
capabilities_entropy     2.8476      0.465      6.129      0.000       1.937       3.758
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.4386 [0.3098, 0.5674] (n=57)
                  P-value vs 33.3%: 0.1093

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=-0.11, p=0.916
Wilcoxon delta_p: statistic=1719.00, p=0.409
Mean Δp = -0.0009  [-0.0172, 0.0154]
Idea 1 N = 238; 

  Idea 1.5: Calibration Metrics
  NLL: 4.2117, Signed ECE (overconf pos under neg): 0.0400, ECE: 0.0400 (n=295)
  Brier: 0.0110, Reliability (absolute calibration error; lower better): 0.0108, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=295)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.896
Model:                            OLS   Adj. R-squared:                  0.894
Method:                 Least Squares   F-statistic:                     831.8
Date:                Sat, 09 Aug 2025   Prob (F-statistic):          2.27e-142
Time:                        17:34:56   Log-Likelihood:                 262.11
No. Observations:                 295   AIC:                            -516.2
Df Residuals:                     291   BIC:                            -501.5
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.7563      0.054    -13.998      0.000      -0.863      -0.650
p1                    0.8219      0.058     14.084      0.000       0.707       0.937
answer_changed        0.7436      0.078      9.484      0.000       0.589       0.898
p1:answer_changed     0.0617      0.091      0.676      0.500      -0.118       0.241
==============================================================================
Omnibus:                       64.875   Durbin-Watson:                   1.936
Prob(Omnibus):                  0.000   Jarque-Bera (JB):              199.051
Skew:                           0.954   Prob(JB):                     5.98e-44
Kurtosis:                       6.543   Cond. No.                         31.3
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=2.25, p=0.0253
Wilcoxon delta_H: statistic=1417.50, p=0.0356
Mean ΔH = 0.0856  [0.0111, 0.1601]
Paired t-test delta_H Changed: statistic=6.66, p=1.28e-08
Wilcoxon delta_H Changed: statistic=179.00, p=2.65e-07
Mean ΔH Changed = 0.5699  [0.4021, 0.7378]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=1.28, p=0.202
Wilcoxon (p_top2_game vs p_top2_base): statistic=3725.00, p=0.0575
Mean Δp_top2 = 0.0025  [-0.0013, 0.0063] (n=295)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=4.90, p=1.55e-06
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=2810.50, p=1.54e-06
Mean ΔH_unchosen_baseline_set = 0.1792  [0.1076, 0.2508] (n=295)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  295
Model:                          Logit   Df Residuals:                      292
Method:                           MLE   Df Model:                            2
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1285
Time:                        17:34:56   Log-Likelihood:                -126.20
converged:                       True   LL-Null:                       -144.80
Covariance Type:            nonrobust   LLR p-value:                 8.328e-09
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.2894      0.222     -5.802      0.000      -1.725      -0.854
p1_z            -1.4134      0.374     -3.778      0.000      -2.147      -0.680
I(p1_z ** 2)    -0.3189      0.167     -1.913      0.056      -0.646       0.008
================================================================================
AUC = 0.741

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  295
Model:                          Logit   Df Residuals:                      293
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.09078
Time:                        17:34:56   Log-Likelihood:                -131.66
converged:                       True   LL-Null:                       -144.80
Covariance Type:            nonrobust   LLR p-value:                 2.939e-07
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -2.7137      0.313     -8.680      0.000      -3.326      -2.101
game_entropy     2.5620      0.503      5.089      0.000       1.575       3.549
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=4529.00, p=0.893
Paired t-test (game_entropy vs capabilities_entropy): statistic=-0.16, p=0.873
Mean capabilities_entropy-game_entropy = 0.0033  [-0.0370, 0.0436] (n=295)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  295
Model:                          Logit   Df Residuals:                      292
Method:                           MLE   Df Model:                            2
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.2039
Time:                        17:34:56   Log-Likelihood:                -115.28
converged:                       True   LL-Null:                       -144.80
Covariance Type:            nonrobust   LLR p-value:                 1.501e-13
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -4.0098      0.441     -9.086      0.000      -4.875      -3.145
capabilities_entropy     2.7036      0.487      5.554      0.000       1.749       3.658
game_entropy             2.3242      0.538      4.319      0.000       1.270       3.379
========================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  295
Model:                          Logit   Df Residuals:                      293
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.01269
Time:                        17:34:56   Log-Likelihood:                -142.97
converged:                       True   LL-Null:                       -144.80
Covariance Type:            nonrobust   LLR p-value:                   0.05527
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -0.2853      0.613     -0.465      0.642      -1.487       0.916
human_difficulty    -0.4923      0.262     -1.881      0.060      -1.005       0.021
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  295
Model:                          Logit   Df Residuals:                      288
Method:                           MLE   Df Model:                            6
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.03493
Time:                        17:34:56   Log-Likelihood:                -139.74
converged:                       True   LL-Null:                       -144.80
Covariance Type:            nonrobust   LLR p-value:                    0.1198
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -1.1408      2.321     -0.492      0.623      -5.689       3.407
C(domain_grouped)[T.chemistry]        0.6781      0.548      1.238      0.216      -0.396       1.752
C(domain_grouped)[T.physics]          0.2172      0.566      0.383      0.701      -0.893       1.327
human_difficulty                     -0.4673      0.278     -1.680      0.093      -1.013       0.078
q_length                              0.3512      0.249      1.409      0.159      -0.137       0.840
avg_word_length                      -0.3698      0.290     -1.275      0.202      -0.938       0.199
percent_non_alphabetic_whitespace    -0.0036      0.027     -0.134      0.894      -0.057       0.050
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 0.4562
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  295
Model:                          Logit   Df Residuals:                      287
Method:                           MLE   Df Model:                            7
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1598
Time:                        17:34:56   Log-Likelihood:                -121.67
converged:                       True   LL-Null:                       -144.80
Covariance Type:            nonrobust   LLR p-value:                 7.725e-08
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -2.7320      2.585     -1.057      0.291      -7.799       2.335
C(domain_grouped)[T.chemistry]        0.4916      0.580      0.847      0.397      -0.646       1.629
C(domain_grouped)[T.physics]          0.1451      0.605      0.240      0.811      -1.041       1.332
human_difficulty                     -0.4740      0.299     -1.583      0.114      -1.061       0.113
q_length                              0.3124      0.273      1.144      0.252      -0.223       0.847
avg_word_length                      -0.2402      0.317     -0.758      0.449      -0.861       0.381
percent_non_alphabetic_whitespace    -0.0091      0.030     -0.302      0.763      -0.069       0.050
capabilities_entropy                  2.7473      0.478      5.753      0.000       1.811       3.683
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  295
Model:                          Logit   Df Residuals:                      287
Method:                           MLE   Df Model:                            7
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1181
Time:                        17:34:56   Log-Likelihood:                -127.70
converged:                       True   LL-Null:                       -144.80
Covariance Type:            nonrobust   LLR p-value:                 1.571e-05
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -2.8860      2.463     -1.172      0.241      -7.713       1.941
C(domain_grouped)[T.chemistry]        0.6304      0.563      1.119      0.263      -0.474       1.735
C(domain_grouped)[T.physics]          0.1193      0.587      0.203      0.839      -1.031       1.269
human_difficulty                     -0.3807      0.298     -1.276      0.202      -0.965       0.204
q_length                              0.4127      0.261      1.581      0.114      -0.099       0.924
avg_word_length                      -0.3518      0.302     -1.166      0.244      -0.943       0.240
percent_non_alphabetic_whitespace    -0.0155      0.028     -0.555      0.579      -0.070       0.039
game_entropy                          2.5382      0.525      4.835      0.000       1.509       3.567
=====================================================================================================

                  Model 4.95: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  295
Model:                          Logit   Df Residuals:                      286
Method:                           MLE   Df Model:                            8
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.2209
Time:                        17:34:56   Log-Likelihood:                -112.82
converged:                       True   LL-Null:                       -144.80
Covariance Type:            nonrobust   LLR p-value:                 7.702e-11
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -4.3852      2.679     -1.637      0.102      -9.635       0.865
C(domain_grouped)[T.chemistry]        0.4202      0.599      0.701      0.483      -0.754       1.594
C(domain_grouped)[T.physics]          0.0378      0.629      0.060      0.952      -1.195       1.270
human_difficulty                     -0.4127      0.317     -1.302      0.193      -1.034       0.209
q_length                              0.3660      0.278      1.317      0.188      -0.179       0.911
avg_word_length                      -0.1907      0.323     -0.590      0.555      -0.824       0.442
percent_non_alphabetic_whitespace    -0.0181      0.029     -0.620      0.536      -0.075       0.039
capabilities_entropy                  2.6347      0.499      5.275      0.000       1.656       3.614
game_entropy                          2.3412      0.559      4.188      0.000       1.245       3.437
=====================================================================================================

--- Analyzing claude-3-sonnet-20240229 (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/claude-3-sonnet-20240229_GPQA_redacted_cor_temp0.0_1751757247_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    113
1     33
Name: count, dtype: int64

Answer change%: 0.2260 [0.1581828421354376, 0.2938719523851103] (n=146)
P-value vs 25%: 0.4886; P-value vs 0%: 6.59e-11
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=33)
P-value vs 25%: 0; P-value vs 33%: 0

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  146
Model:                          Logit   Df Residuals:                      144
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.2443
Time:                        17:34:56   Log-Likelihood:                -58.967
converged:                       True   LL-Null:                       -78.027
Covariance Type:            nonrobust   LLR p-value:                 6.653e-10
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          3.7068      0.883      4.200      0.000       1.977       5.437
p_i_capability    -6.6888      1.231     -5.432      0.000      -9.102      -4.275
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  146
Model:                          Logit   Df Residuals:                      144
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1919
Time:                        17:34:56   Log-Likelihood:                -63.056
converged:                       True   LL-Null:                       -78.027
Covariance Type:            nonrobust   LLR p-value:                 4.451e-08
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -3.2847      0.525     -6.254      0.000      -4.314      -2.255
capabilities_entropy     2.1799      0.442      4.930      0.000       1.313       3.047
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.3333 [0.1725, 0.4942] (n=33)
                  P-value vs 33.3%: 1

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  146
Model:                          Logit   Df Residuals:                      144
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:               0.0002159
Time:                        17:34:56   Log-Likelihood:                -78.010
converged:                       True   LL-Null:                       -78.027
Covariance Type:            nonrobust   LLR p-value:                    0.8544
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -1.0829      0.829     -1.306      0.191      -2.708       0.542
human_difficulty    -0.0626      0.341     -0.183      0.855      -0.732       0.606
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  146
Model:                          Logit   Df Residuals:                      139
Method:                           MLE   Df Model:                            6
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.04736
Time:                        17:34:56   Log-Likelihood:                -74.332
converged:                       True   LL-Null:                       -78.027
Covariance Type:            nonrobust   LLR p-value:                    0.2863
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -0.5137      3.069     -0.167      0.867      -6.529       5.502
C(domain_grouped)[T.chemistry]        1.3167      0.618      2.129      0.033       0.104       2.529
C(domain_grouped)[T.physics]          0.7130      0.659      1.081      0.279      -0.579       2.005
human_difficulty                      0.0405      0.363      0.112      0.911      -0.670       0.751
q_length                             -0.3611      0.376     -0.961      0.336      -1.097       0.375
avg_word_length                       0.1496      0.360      0.416      0.678      -0.556       0.855
percent_non_alphabetic_whitespace    -0.0228      0.038     -0.595      0.552      -0.098       0.052
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 0.7921
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  146
Model:                          Logit   Df Residuals:                      138
Method:                           MLE   Df Model:                            7
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.2170
Time:                        17:34:56   Log-Likelihood:                -61.095
converged:                       True   LL-Null:                       -78.027
Covariance Type:            nonrobust   LLR p-value:                 1.826e-05
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -0.4599      3.487     -0.132      0.895      -7.294       6.374
C(domain_grouped)[T.chemistry]        0.1399      0.723      0.194      0.847      -1.277       1.557
C(domain_grouped)[T.physics]         -0.0521      0.769     -0.068      0.946      -1.559       1.455
human_difficulty                      0.0009      0.403      0.002      0.998      -0.790       0.792
q_length                             -0.5973      0.417     -1.434      0.152      -1.414       0.219
avg_word_length                       0.1874      0.409      0.458      0.647      -0.614       0.989
percent_non_alphabetic_whitespace    -0.0364      0.046     -0.794      0.427      -0.126       0.053
capabilities_entropy                  2.2844      0.499      4.576      0.000       1.306       3.263
=====================================================================================================

--- Analyzing claude-3-sonnet-20240229 (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/claude-3-sonnet-20240229_GPQA_redacted_temp0.0_1751717405_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    217
1     84
Name: count, dtype: int64

Answer change%: 0.2791 [0.228397789428773, 0.32974174545494794] (n=301)
P-value vs 25%: 0.2608; P-value vs 0%: 3.664e-27
Phase 2 self-accuracy: 0.3333 [0.23252366379347328, 0.43414300287319335] (n=84)
P-value vs 25%: 0.1052; P-value vs 33%: 0.9948

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  301
Model:                          Logit   Df Residuals:                      299
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1487
Time:                        17:34:56   Log-Likelihood:                -151.71
converged:                       True   LL-Null:                       -178.21
Covariance Type:            nonrobust   LLR p-value:                 3.338e-13
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          2.4087      0.499      4.829      0.000       1.431       3.386
p_i_capability    -4.9920      0.756     -6.604      0.000      -6.474      -3.510
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  301
Model:                          Logit   Df Residuals:                      299
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1540
Time:                        17:34:56   Log-Likelihood:                -150.77
converged:                       True   LL-Null:                       -178.21
Covariance Type:            nonrobust   LLR p-value:                 1.276e-13
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -3.1822      0.395     -8.063      0.000      -3.956      -2.409
capabilities_entropy     2.0147      0.304      6.631      0.000       1.419       2.610
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.3571 [0.2547, 0.4596] (n=84)
                  P-value vs 33.3%: 0.6488

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  301
Model:                          Logit   Df Residuals:                      299
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:               1.628e-05
Time:                        17:34:56   Log-Likelihood:                -178.21
converged:                       True   LL-Null:                       -178.21
Covariance Type:            nonrobust   LLR p-value:                    0.9393
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -0.9899      0.551     -1.796      0.072      -2.070       0.090
human_difficulty     0.0172      0.226      0.076      0.939      -0.425       0.460
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  301
Model:                          Logit   Df Residuals:                      294
Method:                           MLE   Df Model:                            6
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                0.009757
Time:                        17:34:56   Log-Likelihood:                -176.48
converged:                       True   LL-Null:                       -178.21
Covariance Type:            nonrobust   LLR p-value:                    0.7469
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -0.1034      1.945     -0.053      0.958      -3.916       3.709
C(domain_grouped)[T.chemistry]        0.1243      0.444      0.280      0.779      -0.745       0.994
C(domain_grouped)[T.physics]          0.0169      0.446      0.038      0.970      -0.858       0.892
human_difficulty                      0.0133      0.234      0.057      0.955      -0.446       0.473
q_length                              0.1372      0.206      0.667      0.505      -0.266       0.541
avg_word_length                      -0.3292      0.230     -1.429      0.153      -0.781       0.122
percent_non_alphabetic_whitespace    -0.0285      0.025     -1.127      0.260      -0.078       0.021
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 0.9932
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  301
Model:                          Logit   Df Residuals:                      293
Method:                           MLE   Df Model:                            7
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1690
Time:                        17:34:56   Log-Likelihood:                -148.09
converged:                       True   LL-Null:                       -178.21
Covariance Type:            nonrobust   LLR p-value:                 1.345e-10
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -2.7349      2.106     -1.298      0.194      -6.863       1.393
C(domain_grouped)[T.chemistry]       -0.9336      0.516     -1.808      0.071      -1.945       0.078
C(domain_grouped)[T.physics]         -1.1870      0.539     -2.200      0.028      -2.244      -0.130
human_difficulty                     -0.0431      0.256     -0.168      0.866      -0.546       0.460
q_length                              0.1484      0.240      0.619      0.536      -0.321       0.618
avg_word_length                      -0.1121      0.231     -0.486      0.627      -0.564       0.340
percent_non_alphabetic_whitespace    -0.0053      0.029     -0.184      0.854      -0.062       0.051
capabilities_entropy                  2.2502      0.342      6.579      0.000       1.580       2.921
=====================================================================================================

--- Analyzing claude-sonnet-4-20250514 (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/claude-sonnet-4-20250514_GPQA_redacted_cor_temp0.0_1751759117_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    201
1     57
Name: count, dtype: int64

Answer change%: 0.2209 [0.1703065203425982, 0.2715539447736809] (n=258)
P-value vs 25%: 0.2604; P-value vs 0%: 1.193e-17
Phase 2 self-accuracy: 0.0702 [0.003861665647464513, 0.13648921154551794] (n=57)
P-value vs 25%: 1.067e-07; P-value vs 33%: 7.972e-15

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  258
Model:                          Logit   Df Residuals:                      256
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:               0.0006185
Time:                        17:34:56   Log-Likelihood:                -136.16
converged:                       True   LL-Null:                       -136.25
Covariance Type:            nonrobust   LLR p-value:                    0.6814
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -1.5089      0.626     -2.412      0.016      -2.735      -0.283
human_difficulty     0.1053      0.256      0.411      0.681      -0.397       0.607
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  258
Model:                          Logit   Df Residuals:                      251
Method:                           MLE   Df Model:                            6
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.04056
Time:                        17:34:56   Log-Likelihood:                -130.72
converged:                       True   LL-Null:                       -136.25
Covariance Type:            nonrobust   LLR p-value:                   0.08680
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -5.1356      2.232     -2.301      0.021      -9.510      -0.761
C(domain_grouped)[T.chemistry]        0.3862      0.471      0.820      0.412      -0.537       1.309
C(domain_grouped)[T.physics]          0.0263      0.472      0.056      0.956      -0.900       0.952
human_difficulty                      0.0137      0.276      0.050      0.960      -0.527       0.555
q_length                              0.8150      0.278      2.931      0.003       0.270       1.360
avg_word_length                      -0.2420      0.256     -0.944      0.345      -0.744       0.260
percent_non_alphabetic_whitespace    -0.0082      0.028     -0.293      0.770      -0.063       0.047
=====================================================================================================

--- Analyzing claude-sonnet-4-20250514 (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/claude-sonnet-4-20250514_GPQA_redacted_temp0.0_1751718415_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    101
1     88
Name: count, dtype: int64

Answer change%: 0.4656 [0.3944940889380143, 0.5367228422789169] (n=189)
P-value vs 25%: 2.81e-09; P-value vs 0%: 1.078e-37
Phase 2 self-accuracy: 0.4545 [0.35051159823461064, 0.5585793108562984] (n=88)
P-value vs 25%: 0.0001164; P-value vs 33%: 0.02203

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  189
Model:                          Logit   Df Residuals:                      187
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.01636
Time:                        17:34:56   Log-Likelihood:                -128.42
converged:                       True   LL-Null:                       -130.56
Covariance Type:            nonrobust   LLR p-value:                   0.03875
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept            1.1797      0.663      1.779      0.075      -0.120       2.480
human_difficulty    -0.5516      0.272     -2.030      0.042      -1.084      -0.019
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  189
Model:                          Logit   Df Residuals:                      182
Method:                           MLE   Df Model:                            6
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.02865
Time:                        17:34:56   Log-Likelihood:                -126.82
converged:                       True   LL-Null:                       -130.56
Covariance Type:            nonrobust   LLR p-value:                    0.2788
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                             3.8732      2.421      1.600      0.110      -0.872       8.619
C(domain_grouped)[T.chemistry]        0.0007      0.495      0.001      0.999      -0.970       0.972
C(domain_grouped)[T.physics]         -0.2515      0.520     -0.484      0.629      -1.271       0.768
human_difficulty                     -0.5435      0.282     -1.927      0.054      -1.096       0.009
q_length                             -0.2824      0.241     -1.173      0.241      -0.754       0.189
avg_word_length                      -0.1313      0.259     -0.507      0.612      -0.639       0.377
percent_non_alphabetic_whitespace    -0.0395      0.029     -1.353      0.176      -0.097       0.018
=====================================================================================================

--- Analyzing deepseek-chat (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/deepseek-chat_GPQA_redacted_cor_temp0.0_1753813587_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    186
1     23
Name: count, dtype: int64

Answer change%: 0.1100 [0.06762018961975388, 0.15247550416015043] (n=209)
P-value vs 25%: 1.012e-10; P-value vs 0%: 3.701e-07
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=23)
P-value vs 25%: 0; P-value vs 33%: 0

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  209
Model:                          Logit   Df Residuals:                      207
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1702
Time:                        17:34:56   Log-Likelihood:                -60.113
converged:                       True   LL-Null:                       -72.443
Covariance Type:            nonrobust   LLR p-value:                 6.841e-07
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          7.5856      2.058      3.686      0.000       3.552      11.619
p_i_capability   -10.6088      2.266     -4.682      0.000     -15.050      -6.168
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  209
Model:                          Logit   Df Residuals:                      207
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1871
Time:                        17:34:56   Log-Likelihood:                -58.888
converged:                       True   LL-Null:                       -72.443
Covariance Type:            nonrobust   LLR p-value:                 1.923e-07
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -4.2027      0.517     -8.131      0.000      -5.216      -3.190
capabilities_entropy     4.8796      0.960      5.085      0.000       2.999       6.761
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.6522 [0.4575, 0.8468] (n=23)
                  P-value vs 33.3%: 0.001325

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=2.43, p=0.016
Wilcoxon delta_p: statistic=315.50, p=0.0225
Mean Δp = 0.0158  [0.0031, 0.0286]
Idea 1 N = 186; 

  Idea 1.5: Calibration Metrics
  NLL: 0.0715, Signed ECE (overconf pos under neg): -0.0653, ECE: 0.0653 (n=209)
  Brier: 0.0099, Reliability (absolute calibration error; lower better): 0.0097, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=209)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.886
Model:                            OLS   Adj. R-squared:                  0.884
Method:                 Least Squares   F-statistic:                     531.6
Date:                Sat, 09 Aug 2025   Prob (F-statistic):           2.11e-96
Time:                        17:34:56   Log-Likelihood:                 218.19
No. Observations:                 209   AIC:                            -428.4
Df Residuals:                     205   BIC:                            -415.0
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.5497      0.113     -4.861      0.000      -0.773      -0.327
p1                    0.5975      0.119      5.008      0.000       0.362       0.833
answer_changed        0.6006      0.159      3.768      0.000       0.286       0.915
p1:answer_changed     0.2450      0.178      1.378      0.170      -0.106       0.596
==============================================================================
Omnibus:                      121.855   Durbin-Watson:                   2.029
Prob(Omnibus):                  0.000   Jarque-Bera (JB):              715.186
Skew:                           2.279   Prob(JB):                    5.00e-156
Kurtosis:                      10.833   Cond. No.                         62.4
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=1.68, p=0.0941
Wilcoxon delta_H: statistic=362.50, p=0.0801
Mean ΔH = 0.0547  [-0.0090, 0.1184]
Paired t-test delta_H Changed: statistic=4.02, p=0.000575
Wilcoxon delta_H Changed: statistic=41.00, p=0.00316
Mean ΔH Changed = 0.5451  [0.2793, 0.8109]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=-1.14, p=0.256
Wilcoxon (p_top2_game vs p_top2_base): statistic=916.50, p=0.409
Mean Δp_top2 = -0.0012  [-0.0034, 0.0009] (n=209)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=3.19, p=0.00166
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=658.50, p=0.00167
Mean ΔH_unchosen_baseline_set = 0.1087  [0.0418, 0.1755] (n=209)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  209
Model:                          Logit   Df Residuals:                      206
Method:                           MLE   Df Model:                            2
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.2098
Time:                        17:34:56   Log-Likelihood:                -57.242
converged:                       True   LL-Null:                       -72.443
Covariance Type:            nonrobust   LLR p-value:                 2.503e-07
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -2.1119      0.282     -7.492      0.000      -2.664      -1.559
p1_z            -1.9761      0.529     -3.734      0.000      -3.013      -0.939
I(p1_z ** 2)    -0.3239      0.134     -2.408      0.016      -0.587      -0.060
================================================================================
AUC = 0.815

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  209
Model:                          Logit   Df Residuals:                      207
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.04680
Time:                        17:34:56   Log-Likelihood:                -69.053
converged:                       True   LL-Null:                       -72.443
Covariance Type:            nonrobust   LLR p-value:                  0.009219
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -3.0548      0.446     -6.855      0.000      -3.928      -2.181
game_entropy     2.1953      0.793      2.770      0.006       0.642       3.749
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=846.00, p=0.194
Paired t-test (game_entropy vs capabilities_entropy): statistic=1.42, p=0.157
Mean capabilities_entropy-game_entropy = -0.0229  [-0.0546, 0.0087] (n=209)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  209
Model:                          Logit   Df Residuals:                      206
Method:                           MLE   Df Model:                            2
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.2004
Time:                        17:34:56   Log-Likelihood:                -57.927
converged:                       True   LL-Null:                       -72.443
Covariance Type:            nonrobust   LLR p-value:                 4.964e-07
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -4.6733      0.642     -7.280      0.000      -5.931      -3.415
capabilities_entropy     4.5918      0.986      4.658      0.000       2.660       6.524
game_entropy             1.3441      0.925      1.453      0.146      -0.469       3.157
========================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  209
Model:                          Logit   Df Residuals:                      207
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                0.004156
Time:                        17:34:56   Log-Likelihood:                -72.142
converged:                       True   LL-Null:                       -72.443
Covariance Type:            nonrobust   LLR p-value:                    0.4378
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -1.3877      0.925     -1.500      0.134      -3.201       0.425
human_difficulty    -0.2995      0.389     -0.770      0.442      -1.062       0.463
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  209
Model:                          Logit   Df Residuals:                      202
Method:                           MLE   Df Model:                            6
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.06732
Time:                        17:34:56   Log-Likelihood:                -67.566
converged:                       True   LL-Null:                       -72.443
Covariance Type:            nonrobust   LLR p-value:                    0.1354
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -4.9432      3.651     -1.354      0.176     -12.100       2.213
C(domain_grouped)[T.chemistry]        1.6750      0.738      2.269      0.023       0.228       3.122
C(domain_grouped)[T.physics]          0.4135      0.777      0.532      0.595      -1.109       1.936
human_difficulty                     -0.1641      0.410     -0.400      0.689      -0.967       0.639
q_length                              0.5313      0.387      1.374      0.170      -0.227       1.289
avg_word_length                      -0.1082      0.435     -0.249      0.804      -0.962       0.745
percent_non_alphabetic_whitespace    -0.0351      0.046     -0.759      0.448      -0.126       0.055
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 0.3732
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  209
Model:                          Logit   Df Residuals:                      201
Method:                           MLE   Df Model:                            7
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.2387
Time:                        17:34:56   Log-Likelihood:                -55.149
converged:                       True   LL-Null:                       -72.443
Covariance Type:            nonrobust   LLR p-value:                 1.337e-05
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -8.1590      4.066     -2.007      0.045     -16.128      -0.190
C(domain_grouped)[T.chemistry]        1.1519      0.789      1.459      0.145      -0.395       2.699
C(domain_grouped)[T.physics]         -0.0475      0.865     -0.055      0.956      -1.742       1.647
human_difficulty                     -0.1135      0.463     -0.245      0.806      -1.021       0.794
q_length                              0.5466      0.425      1.285      0.199      -0.287       1.380
avg_word_length                       0.1637      0.443      0.369      0.712      -0.705       1.033
percent_non_alphabetic_whitespace    -0.0454      0.051     -0.893      0.372      -0.145       0.054
capabilities_entropy                  5.1244      1.102      4.652      0.000       2.965       7.283
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  209
Model:                          Logit   Df Residuals:                      201
Method:                           MLE   Df Model:                            7
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1043
Time:                        17:34:56   Log-Likelihood:                -64.887
converged:                       True   LL-Null:                       -72.443
Covariance Type:            nonrobust   LLR p-value:                   0.03460
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -5.5394      3.800     -1.458      0.145     -12.988       1.909
C(domain_grouped)[T.chemistry]        1.4898      0.752      1.981      0.048       0.016       2.964
C(domain_grouped)[T.physics]          0.2131      0.800      0.266      0.790      -1.355       1.781
human_difficulty                     -0.1882      0.417     -0.451      0.652      -1.005       0.629
q_length                              0.4844      0.392      1.234      0.217      -0.285       1.253
avg_word_length                      -0.0628      0.456     -0.138      0.890      -0.956       0.830
percent_non_alphabetic_whitespace    -0.0360      0.049     -0.743      0.457      -0.131       0.059
game_entropy                          2.0056      0.830      2.417      0.016       0.379       3.632
=====================================================================================================

                  Model 4.95: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  209
Model:                          Logit   Df Residuals:                      200
Method:                           MLE   Df Model:                            8
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.2515
Time:                        17:34:56   Log-Likelihood:                -54.223
converged:                       True   LL-Null:                       -72.443
Covariance Type:            nonrobust   LLR p-value:                 1.458e-05
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -8.5918      4.121     -2.085      0.037     -16.668      -0.515
C(domain_grouped)[T.chemistry]        1.0175      0.800      1.272      0.203      -0.550       2.585
C(domain_grouped)[T.physics]         -0.1905      0.886     -0.215      0.830      -1.927       1.546
human_difficulty                     -0.1279      0.468     -0.273      0.785      -1.046       0.790
q_length                              0.5338      0.425      1.256      0.209      -0.299       1.367
avg_word_length                       0.1951      0.452      0.432      0.666      -0.690       1.080
percent_non_alphabetic_whitespace    -0.0424      0.052     -0.822      0.411      -0.144       0.059
capabilities_entropy                  4.8206      1.112      4.335      0.000       2.641       7.000
game_entropy                          1.3409      0.952      1.409      0.159      -0.524       3.206
=====================================================================================================

--- Analyzing deepseek-chat (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/deepseek-chat_GPQA_redacted_temp0.0_1753995526_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    190
1     48
Name: count, dtype: int64

Answer change%: 0.2017 [0.1507029913524324, 0.25265835318538277] (n=238)
P-value vs 25%: 0.0632; P-value vs 0%: 8.896e-15
Phase 2 self-accuracy: 0.5208 [0.37950795482256594, 0.6621587118441008] (n=48)
P-value vs 25%: 0.0001726; P-value vs 33%: 0.009189

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  238
Model:                          Logit   Df Residuals:                      236
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.05175
Time:                        17:34:56   Log-Likelihood:                -113.46
converged:                       True   LL-Null:                       -119.65
Covariance Type:            nonrobust   LLR p-value:                 0.0004330
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          2.0605      0.962      2.142      0.032       0.175       3.946
p_i_capability    -3.9138      1.096     -3.570      0.000      -6.063      -1.765
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  238
Model:                          Logit   Df Residuals:                      236
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.06043
Time:                        17:34:56   Log-Likelihood:                -112.42
converged:                       True   LL-Null:                       -119.65
Covariance Type:            nonrobust   LLR p-value:                 0.0001431
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.3300      0.315     -7.400      0.000      -2.947      -1.713
capabilities_entropy     1.8574      0.486      3.825      0.000       0.906       2.809
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.4375 [0.2972, 0.5778] (n=48)
                  P-value vs 33.3%: 0.1457

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=-1.24, p=0.217
Wilcoxon delta_p: statistic=1376.00, p=0.524
Mean Δp = -0.0103  [-0.0267, 0.0060]
Idea 1 N = 190; 

  Idea 1.5: Calibration Metrics
  NLL: 4.1283, Signed ECE (overconf pos under neg): 0.0401, ECE: 0.0401 (n=238)
  Brier: 0.0087, Reliability (absolute calibration error; lower better): 0.0086, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=238)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.913
Model:                            OLS   Adj. R-squared:                  0.912
Method:                 Least Squares   F-statistic:                     817.1
Date:                Sat, 09 Aug 2025   Prob (F-statistic):          1.18e-123
Time:                        17:34:56   Log-Likelihood:                 219.79
No. Observations:                 238   AIC:                            -431.6
Df Residuals:                     234   BIC:                            -417.7
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.6391      0.057    -11.132      0.000      -0.752      -0.526
p1                    0.6899      0.063     11.035      0.000       0.567       0.813
answer_changed        0.5881      0.092      6.365      0.000       0.406       0.770
p1:answer_changed     0.2432      0.106      2.299      0.022       0.035       0.452
==============================================================================
Omnibus:                       45.761   Durbin-Watson:                   2.027
Prob(Omnibus):                  0.000   Jarque-Bera (JB):              181.618
Skew:                           0.700   Prob(JB):                     3.65e-40
Kurtosis:                       7.044   Cond. No.                         33.1
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=0.24, p=0.814
Wilcoxon delta_H: statistic=1447.50, p=0.784
Mean ΔH = 0.0092  [-0.0673, 0.0856]
Paired t-test delta_H Changed: statistic=7.61, p=9.82e-10
Wilcoxon delta_H Changed: statistic=97.00, p=4.62e-07
Mean ΔH Changed = 0.7205  [0.5349, 0.9061]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=1.33, p=0.185
Wilcoxon (p_top2_game vs p_top2_base): statistic=2904.00, p=0.365
Mean Δp_top2 = 0.0029  [-0.0014, 0.0071] (n=238)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=3.73, p=0.000237
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=2485.50, p=0.000346
Mean ΔH_unchosen_baseline_set = 0.1526  [0.0725, 0.2328] (n=238)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  238
Model:                          Logit   Df Residuals:                      235
Method:                           MLE   Df Model:                            2
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.05953
Time:                        17:34:56   Log-Likelihood:                -112.53
converged:                       True   LL-Null:                       -119.65
Covariance Type:            nonrobust   LLR p-value:                 0.0008068
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.2715      0.212     -5.995      0.000      -1.687      -0.856
p1_z            -0.9206      0.337     -2.731      0.006      -1.581      -0.260
I(p1_z ** 2)    -0.1913      0.142     -1.349      0.177      -0.469       0.087
================================================================================
AUC = 0.696

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  238
Model:                          Logit   Df Residuals:                      236
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1005
Time:                        17:34:56   Log-Likelihood:                -107.63
converged:                       True   LL-Null:                       -119.65
Covariance Type:            nonrobust   LLR p-value:                 9.437e-07
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -2.7479      0.352     -7.816      0.000      -3.437      -2.059
game_entropy     2.7260      0.572      4.766      0.000       1.605       3.847
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=3193.50, p=0.812
Paired t-test (game_entropy vs capabilities_entropy): statistic=-0.66, p=0.508
Mean capabilities_entropy-game_entropy = 0.0136  [-0.0266, 0.0538] (n=238)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  238
Model:                          Logit   Df Residuals:                      235
Method:                           MLE   Df Model:                            2
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1216
Time:                        17:34:56   Log-Likelihood:                -105.10
converged:                       True   LL-Null:                       -119.65
Covariance Type:            nonrobust   LLR p-value:                 4.807e-07
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -3.1645      0.414     -7.641      0.000      -3.976      -2.353
capabilities_entropy     1.2458      0.542      2.298      0.022       0.183       2.309
game_entropy             2.2918      0.607      3.775      0.000       1.102       3.482
========================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  238
Model:                          Logit   Df Residuals:                      236
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.01342
Time:                        17:34:56   Log-Likelihood:                -118.04
converged:                       True   LL-Null:                       -119.65
Covariance Type:            nonrobust   LLR p-value:                   0.07310
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -0.1518      0.703     -0.216      0.829      -1.530       1.226
human_difficulty    -0.5303      0.303     -1.752      0.080      -1.124       0.063
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  238
Model:                          Logit   Df Residuals:                      231
Method:                           MLE   Df Model:                            6
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.03776
Time:                        17:34:56   Log-Likelihood:                -115.13
converged:                       True   LL-Null:                       -119.65
Covariance Type:            nonrobust   LLR p-value:                    0.1716
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                             0.1345      2.285      0.059      0.953      -4.344       4.613
C(domain_grouped)[T.chemistry]       -0.0366      0.533     -0.069      0.945      -1.081       1.008
C(domain_grouped)[T.physics]         -0.4273      0.580     -0.737      0.461      -1.564       0.709
human_difficulty                     -0.6881      0.323     -2.131      0.033      -1.321      -0.055
q_length                              0.0629      0.271      0.232      0.816      -0.468       0.594
avg_word_length                       0.0693      0.242      0.286      0.775      -0.405       0.544
percent_non_alphabetic_whitespace    -0.0567      0.036     -1.559      0.119      -0.128       0.015
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 0.4696
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  238
Model:                          Logit   Df Residuals:                      230
Method:                           MLE   Df Model:                            7
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1092
Time:                        17:34:56   Log-Likelihood:                -106.59
converged:                       True   LL-Null:                       -119.65
Covariance Type:            nonrobust   LLR p-value:                 0.0004782
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                             0.6388      2.342      0.273      0.785      -3.951       5.228
C(domain_grouped)[T.chemistry]       -0.5098      0.560     -0.910      0.363      -1.608       0.589
C(domain_grouped)[T.physics]         -0.9854      0.625     -1.578      0.115      -2.210       0.239
human_difficulty                     -0.7726      0.344     -2.244      0.025      -1.447      -0.098
q_length                             -0.0393      0.284     -0.138      0.890      -0.596       0.518
avg_word_length                       0.0038      0.243      0.016      0.987      -0.473       0.481
percent_non_alphabetic_whitespace    -0.0682      0.039     -1.753      0.080      -0.144       0.008
capabilities_entropy                  2.1702      0.527      4.122      0.000       1.138       3.202
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  238
Model:                          Logit   Df Residuals:                      230
Method:                           MLE   Df Model:                            7
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1374
Time:                        17:34:56   Log-Likelihood:                -103.20
converged:                       True   LL-Null:                       -119.65
Covariance Type:            nonrobust   LLR p-value:                 2.778e-05
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                             0.0560      2.360      0.024      0.981      -4.570       4.682
C(domain_grouped)[T.chemistry]       -0.4983      0.567     -0.879      0.379      -1.609       0.613
C(domain_grouped)[T.physics]         -0.7862      0.610     -1.289      0.197      -1.981       0.409
human_difficulty                     -0.7041      0.345     -2.043      0.041      -1.380      -0.029
q_length                             -0.0703      0.294     -0.239      0.811      -0.646       0.506
avg_word_length                       0.0339      0.245      0.139      0.890      -0.446       0.513
percent_non_alphabetic_whitespace    -0.0561      0.039     -1.434      0.152      -0.133       0.021
game_entropy                          2.8205      0.598      4.718      0.000       1.649       3.992
=====================================================================================================

                  Model 4.95: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  238
Model:                          Logit   Df Residuals:                      229
Method:                           MLE   Df Model:                            8
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1660
Time:                        17:34:56   Log-Likelihood:                -99.785
converged:                       True   LL-Null:                       -119.65
Covariance Type:            nonrobust   LLR p-value:                 3.601e-06
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                             0.4443      2.408      0.184      0.854      -4.276       5.164
C(domain_grouped)[T.chemistry]       -0.7646      0.585     -1.306      0.191      -1.912       0.383
C(domain_grouped)[T.physics]         -1.1005      0.637     -1.727      0.084      -2.349       0.148
human_difficulty                     -0.7564      0.358     -2.112      0.035      -1.458      -0.054
q_length                             -0.1278      0.299     -0.428      0.669      -0.713       0.457
avg_word_length                      -0.0054      0.253     -0.021      0.983      -0.502       0.491
percent_non_alphabetic_whitespace    -0.0611      0.040     -1.527      0.127      -0.139       0.017
capabilities_entropy                  1.5572      0.586      2.658      0.008       0.409       2.705
game_entropy                          2.3095      0.638      3.621      0.000       1.059       3.559
=====================================================================================================

--- Analyzing gemini-1.5-pro (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/gemini-1.5-pro_GPQA_redacted_cor_temp0.0_1751757449_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    182
1     19
Name: count, dtype: int64

Answer change%: 0.0945 [0.05408220862790201, 0.1349725177402572] (n=201)
P-value vs 25%: 4.914e-14; P-value vs 0%: 4.633e-06
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=19)
P-value vs 25%: 0; P-value vs 33%: 0

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  201
Model:                          Logit   Df Residuals:                      199
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                0.006038
Time:                        17:34:56   Log-Likelihood:                -62.511
converged:                       True   LL-Null:                       -62.891
Covariance Type:            nonrobust   LLR p-value:                    0.3835
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -3.1667      1.088     -2.909      0.004      -5.300      -1.033
human_difficulty     0.3770      0.433      0.871      0.383      -0.471       1.225
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  201
Model:                          Logit   Df Residuals:                      194
Method:                           MLE   Df Model:                            6
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.02890
Time:                        17:34:56   Log-Likelihood:                -61.073
converged:                       True   LL-Null:                       -62.891
Covariance Type:            nonrobust   LLR p-value:                    0.7259
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -4.4739      3.446     -1.298      0.194     -11.228       2.281
C(domain_grouped)[T.chemistry]        0.8927      0.716      1.247      0.212      -0.510       2.295
C(domain_grouped)[T.physics]          0.0635      0.739      0.086      0.932      -1.386       1.513
human_difficulty                      0.4115      0.449      0.916      0.359      -0.469       1.292
q_length                              0.2464      0.392      0.628      0.530      -0.522       1.015
avg_word_length                      -0.0760      0.400     -0.190      0.850      -0.861       0.709
percent_non_alphabetic_whitespace    -0.0318      0.051     -0.627      0.531      -0.131       0.068
=====================================================================================================

--- Analyzing gemini-1.5-pro (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/gemini-1.5-pro_GPQA_redacted_temp0.0_1751722268_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    187
1     59
Name: count, dtype: int64

Answer change%: 0.2398 [0.1864802956528626, 0.2931945010951049] (n=246)
P-value vs 25%: 0.7089; P-value vs 0%: 1.252e-18
Phase 2 self-accuracy: 0.5085 [0.3809101148274585, 0.6360390377149143] (n=59)
P-value vs 25%: 7.147e-05; P-value vs 33%: 0.007016

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  246
Model:                          Logit   Df Residuals:                      244
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:               1.592e-05
Time:                        17:34:56   Log-Likelihood:                -135.52
converged:                       True   LL-Null:                       -135.52
Covariance Type:            nonrobust   LLR p-value:                    0.9476
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -1.1138      0.624     -1.786      0.074      -2.336       0.108
human_difficulty    -0.0167      0.255     -0.066      0.948      -0.516       0.482
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  246
Model:                          Logit   Df Residuals:                      239
Method:                           MLE   Df Model:                            6
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.01409
Time:                        17:34:56   Log-Likelihood:                -133.61
converged:                       True   LL-Null:                       -135.52
Covariance Type:            nonrobust   LLR p-value:                    0.7010
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                             1.7876      2.380      0.751      0.453      -2.877       6.452
C(domain_grouped)[T.chemistry]       -0.6503      0.491     -1.326      0.185      -1.612       0.311
C(domain_grouped)[T.physics]         -0.4937      0.502     -0.983      0.326      -1.478       0.491
human_difficulty                     -0.0087      0.266     -0.033      0.974      -0.531       0.514
q_length                             -0.0929      0.249     -0.373      0.709      -0.581       0.396
avg_word_length                      -0.3909      0.273     -1.433      0.152      -0.926       0.144
percent_non_alphabetic_whitespace    -0.0102      0.029     -0.352      0.725      -0.067       0.047
=====================================================================================================

--- Analyzing gemini-2.0-flash-001 (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/gemini-2.0-flash-001_GPQA_redacted_cor_temp0.0_1754323678_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    164
1     35
Name: count, dtype: int64

Answer change%: 0.1759 [0.12298320323961232, 0.22877559073023696] (n=199)
P-value vs 25%: 0.006025; P-value vs 0%: 7.179e-11
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=35)
P-value vs 25%: 0; P-value vs 33%: 0

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  199
Model:                          Logit   Df Residuals:                      197
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1716
Time:                        17:34:56   Log-Likelihood:                -76.670
converged:                       True   LL-Null:                       -92.552
Covariance Type:            nonrobust   LLR p-value:                 1.740e-08
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          4.9952      1.236      4.042      0.000       2.573       7.418
p_i_capability    -7.1469      1.350     -5.293      0.000      -9.793      -4.500
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  199
Model:                          Logit   Df Residuals:                      197
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.2029
Time:                        17:34:56   Log-Likelihood:                -73.778
converged:                       True   LL-Null:                       -92.552
Covariance Type:            nonrobust   LLR p-value:                 8.915e-10
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.3206      0.269     -8.635      0.000      -2.847      -1.794
capabilities_entropy     2.7318      0.477      5.725      0.000       1.797       3.667
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.7037 [0.5315, 0.8759] (n=27)
                  P-value vs 33.3%: 2.502e-05

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=2.39, p=0.0199
Wilcoxon delta_p: statistic=525.00, p=0.000346
Mean Δp = 0.0451  [0.0081, 0.0821]
Idea 1 N = 65; 

  Idea 1.5: Calibration Metrics
  NLL: 0.1349, Signed ECE (overconf pos under neg): -0.1078, ECE: 0.1078 (n=92)
  Brier: 0.0386, Reliability (absolute calibration error; lower better): 0.0381, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=92)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.825
Model:                            OLS   Adj. R-squared:                  0.819
Method:                 Least Squares   F-statistic:                     138.3
Date:                Sat, 09 Aug 2025   Prob (F-statistic):           3.38e-33
Time:                        17:34:56   Log-Likelihood:                 53.996
No. Observations:                  92   AIC:                            -99.99
Df Residuals:                      88   BIC:                            -89.90
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.3829      0.125     -3.058      0.003      -0.632      -0.134
p1                    0.4561      0.132      3.450      0.001       0.193       0.719
answer_changed        0.2135      0.170      1.258      0.212      -0.124       0.551
p1:answer_changed     0.5735      0.194      2.950      0.004       0.187       0.960
==============================================================================
Omnibus:                       30.015   Durbin-Watson:                   2.131
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               58.442
Skew:                           1.259   Prob(JB):                     2.04e-13
Kurtosis:                       5.985   Cond. No.                         28.7
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-3.82, p=0.000307
Wilcoxon delta_H: statistic=549.00, p=0.000624
Mean ΔH = -0.2734  [-0.4138, -0.1330]
Paired t-test delta_H Changed: statistic=-0.94, p=0.356
Wilcoxon delta_H Changed: statistic=151.00, p=0.374
Mean ΔH Changed = -0.1168  [-0.3606, 0.1270]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=-4.42, p=2.76e-05
Wilcoxon (p_top2_game vs p_top2_base): statistic=697.00, p=1.97e-08
Mean Δp_top2 = -0.0331  [-0.0478, -0.0184] (n=92)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=-3.64, p=0.000451
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=1265.00, p=0.000666
Mean ΔH_unchosen_baseline_set = -0.2275  [-0.3499, -0.1050] (n=92)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                   92
Model:                          Logit   Df Residuals:                       89
Method:                           MLE   Df Model:                            2
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1649
Time:                        17:34:56   Log-Likelihood:                -46.500
converged:                       True   LL-Null:                       -55.682
Covariance Type:            nonrobust   LLR p-value:                 0.0001029
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.5249      0.423     -1.240      0.215      -1.355       0.305
p1_z            -1.5872      0.544     -2.916      0.004      -2.654      -0.520
I(p1_z ** 2)    -0.5140      0.366     -1.404      0.160      -1.232       0.204
================================================================================
AUC = 0.765

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  199
Model:                          Logit   Df Residuals:                      197
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.2889
Time:                        17:34:56   Log-Likelihood:                -65.810
converged:                       True   LL-Null:                       -92.552
Covariance Type:            nonrobust   LLR p-value:                 2.605e-13
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -2.8242      0.332     -8.503      0.000      -3.475      -2.173
game_entropy     2.6580      0.417      6.377      0.000       1.841       3.475
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=3663.00, p=1.08e-14
Paired t-test (game_entropy vs capabilities_entropy): statistic=4.93, p=1.77e-06
Mean capabilities_entropy-game_entropy = -0.1314  [-0.1836, -0.0791] (n=199)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  199
Model:                          Logit   Df Residuals:                      196
Method:                           MLE   Df Model:                            2
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.3136
Time:                        17:34:56   Log-Likelihood:                -63.524
converged:                       True   LL-Null:                       -92.552
Covariance Type:            nonrobust   LLR p-value:                 2.473e-13
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.9223      0.345     -8.478      0.000      -3.598      -2.247
capabilities_entropy     1.2772      0.595      2.145      0.032       0.110       2.444
game_entropy             2.0990      0.480      4.375      0.000       1.159       3.039
========================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  199
Model:                          Logit   Df Residuals:                      197
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                0.001984
Time:                        17:34:56   Log-Likelihood:                -92.369
converged:                       True   LL-Null:                       -92.552
Covariance Type:            nonrobust   LLR p-value:                    0.5445
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -2.0490      0.858     -2.387      0.017      -3.731      -0.367
human_difficulty     0.2120      0.349      0.607      0.544      -0.473       0.897
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  199
Model:                          Logit   Df Residuals:                      192
Method:                           MLE   Df Model:                            6
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.07865
Time:                        17:34:56   Log-Likelihood:                -85.274
converged:                       True   LL-Null:                       -92.552
Covariance Type:            nonrobust   LLR p-value:                   0.02399
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -2.1669      2.862     -0.757      0.449      -7.775       3.442
C(domain_grouped)[T.chemistry]        2.3038      0.813      2.835      0.005       0.711       3.897
C(domain_grouped)[T.physics]          1.4164      0.809      1.751      0.080      -0.169       3.002
human_difficulty                      0.4777      0.367      1.300      0.194      -0.243       1.198
q_length                             -0.1619      0.312     -0.519      0.604      -0.773       0.449
avg_word_length                      -0.2008      0.332     -0.605      0.545      -0.851       0.450
percent_non_alphabetic_whitespace    -0.0267      0.035     -0.770      0.441      -0.095       0.041
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 0.1846
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  199
Model:                          Logit   Df Residuals:                      191
Method:                           MLE   Df Model:                            7
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.2418
Time:                        17:34:56   Log-Likelihood:                -70.173
converged:                       True   LL-Null:                       -92.552
Covariance Type:            nonrobust   LLR p-value:                 1.523e-07
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -2.9397      3.157     -0.931      0.352      -9.127       3.248
C(domain_grouped)[T.chemistry]        1.6495      0.858      1.922      0.055      -0.032       3.331
C(domain_grouped)[T.physics]          0.8223      0.861      0.955      0.340      -0.866       2.510
human_difficulty                      0.4879      0.422      1.157      0.247      -0.339       1.315
q_length                             -0.2829      0.345     -0.821      0.412      -0.958       0.392
avg_word_length                       0.0686      0.356      0.193      0.847      -0.628       0.765
percent_non_alphabetic_whitespace    -0.0250      0.040     -0.631      0.528      -0.103       0.053
capabilities_entropy                  2.6443      0.526      5.026      0.000       1.613       3.675
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  199
Model:                          Logit   Df Residuals:                      191
Method:                           MLE   Df Model:                            7
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.3252
Time:                        17:34:56   Log-Likelihood:                -62.456
converged:                       True   LL-Null:                       -92.552
Covariance Type:            nonrobust   LLR p-value:                 1.382e-10
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -2.8723      3.392     -0.847      0.397      -9.520       3.776
C(domain_grouped)[T.chemistry]        1.3571      0.888      1.529      0.126      -0.383       3.097
C(domain_grouped)[T.physics]          0.6372      0.905      0.704      0.481      -1.136       2.410
human_difficulty                      0.2658      0.461      0.577      0.564      -0.637       1.169
q_length                             -0.4460      0.362     -1.231      0.218      -1.156       0.264
avg_word_length                       0.2776      0.363      0.764      0.445      -0.434       0.989
percent_non_alphabetic_whitespace    -0.0153      0.041     -0.377      0.706      -0.095       0.064
game_entropy                          2.7078      0.467      5.801      0.000       1.793       3.623
=====================================================================================================

                  Model 4.95: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  199
Model:                          Logit   Df Residuals:                      190
Method:                           MLE   Df Model:                            8
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.3504
Time:                        17:34:56   Log-Likelihood:                -60.124
converged:                       True   LL-Null:                       -92.552
Covariance Type:            nonrobust   LLR p-value:                 5.151e-11
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -2.8859      3.474     -0.831      0.406      -9.694       3.922
C(domain_grouped)[T.chemistry]        1.2249      0.906      1.352      0.176      -0.551       3.001
C(domain_grouped)[T.physics]          0.4456      0.931      0.479      0.632      -1.379       2.270
human_difficulty                      0.3459      0.476      0.727      0.468      -0.587       1.279
q_length                             -0.5025      0.379     -1.327      0.185      -1.245       0.240
avg_word_length                       0.3082      0.367      0.840      0.401      -0.411       1.028
percent_non_alphabetic_whitespace    -0.0145      0.042     -0.347      0.728      -0.096       0.067
capabilities_entropy                  1.3353      0.622      2.146      0.032       0.116       2.555
game_entropy                          2.1833      0.514      4.246      0.000       1.176       3.191
=====================================================================================================

--- Analyzing gemini-2.0-flash-001 (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/gemini-2.0-flash-001_GPQA_redacted_temp0.0_1754323457_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    156
1     92
Name: count, dtype: int64

Answer change%: 0.3710 [0.3108466606772935, 0.43108882319367425] (n=248)
P-value vs 25%: 8.027e-05; P-value vs 0%: 1.141e-33
Phase 2 self-accuracy: 0.4783 [0.37618729896707037, 0.5803344401633644] (n=92)
P-value vs 25%: 1.171e-05; P-value vs 33%: 0.005283

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  248
Model:                          Logit   Df Residuals:                      246
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.03471
Time:                        17:34:56   Log-Likelihood:                -157.87
converged:                       True   LL-Null:                       -163.55
Covariance Type:            nonrobust   LLR p-value:                 0.0007532
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          2.5266      0.942      2.683      0.007       0.681       4.373
p_i_capability    -3.3395      1.019     -3.276      0.001      -5.337      -1.342
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  248
Model:                          Logit   Df Residuals:                      246
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.04701
Time:                        17:34:56   Log-Likelihood:                -155.86
converged:                       True   LL-Null:                       -163.55
Covariance Type:            nonrobust   LLR p-value:                 8.812e-05
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -0.9321      0.173     -5.377      0.000      -1.272      -0.592
capabilities_entropy     1.2200      0.321      3.805      0.000       0.592       1.848
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.6456 [0.5401, 0.7510] (n=79)
                  P-value vs 33.3%: 6.562e-09

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=4.46, p=2.06e-05
Wilcoxon delta_p: statistic=1277.00, p=2.46e-06
Mean Δp = 0.0805  [0.0452, 0.1159]
Idea 1 N = 104; 

  Idea 1.5: Calibration Metrics
  NLL: 7.0499, Signed ECE (overconf pos under neg): 0.0400, ECE: 0.0400 (n=181)
  Brier: 0.0091, Reliability (absolute calibration error; lower better): 0.0087, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=181)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.812
Model:                            OLS   Adj. R-squared:                  0.809
Method:                 Least Squares   F-statistic:                     258.4
Date:                Sat, 09 Aug 2025   Prob (F-statistic):           8.63e-65
Time:                        17:34:56   Log-Likelihood:                 75.779
No. Observations:                 183   AIC:                            -143.6
Df Residuals:                     179   BIC:                            -130.7
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.4268      0.107     -3.977      0.000      -0.638      -0.215
p1                    0.5559      0.116      4.780      0.000       0.326       0.785
answer_changed        0.3665      0.153      2.390      0.018       0.064       0.669
p1:answer_changed     0.3385      0.170      1.992      0.048       0.003       0.674
==============================================================================
Omnibus:                        7.485   Durbin-Watson:                   1.899
Prob(Omnibus):                  0.024   Jarque-Bera (JB):                5.018
Skew:                           0.259   Prob(JB):                       0.0813
Kurtosis:                       2.376   Cond. No.                         32.2
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-3.29, p=0.00137
Wilcoxon delta_H: statistic=1773.00, p=0.00191
Mean ΔH = -0.1752  [-0.2796, -0.0708]
Paired t-test delta_H Changed: statistic=1.07, p=0.286
Wilcoxon delta_H Changed: statistic=1390.00, p=0.353
Mean ΔH Changed = 0.0610  [-0.0502, 0.1721]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=-5.14, p=7.16e-07
Wilcoxon (p_top2_game vs p_top2_base): statistic=3607.00, p=2.02e-11
Mean Δp_top2 = -0.0265  [-0.0366, -0.0164] (n=183)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=-1.84, p=0.0672
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=7138.00, p=0.0745
Mean ΔH_unchosen_baseline_set = -0.0733  [-0.1512, 0.0047] (n=183)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  183
Model:                          Logit   Df Residuals:                      180
Method:                           MLE   Df Model:                            2
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.02795
Time:                        17:34:56   Log-Likelihood:                -121.63
converged:                       True   LL-Null:                       -125.13
Covariance Type:            nonrobust   LLR p-value:                   0.03026
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.0103      0.213     -0.048      0.961      -0.427       0.407
p1_z            -0.6903      0.271     -2.549      0.011      -1.221      -0.160
I(p1_z ** 2)    -0.2724      0.152     -1.793      0.073      -0.570       0.025
================================================================================
AUC = 0.626

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  248
Model:                          Logit   Df Residuals:                      246
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.09146
Time:                        17:34:56   Log-Likelihood:                -148.59
converged:                       True   LL-Null:                       -163.55
Covariance Type:            nonrobust   LLR p-value:                 4.513e-08
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.3854      0.223     -6.218      0.000      -1.822      -0.949
game_entropy     1.3584      0.260      5.217      0.000       0.848       1.869
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=5959.00, p=5.19e-17
Paired t-test (game_entropy vs capabilities_entropy): statistic=8.72, p=4.2e-16
Mean capabilities_entropy-game_entropy = -0.2734  [-0.3349, -0.2120] (n=248)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  248
Model:                          Logit   Df Residuals:                      245
Method:                           MLE   Df Model:                            2
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.09748
Time:                        17:34:56   Log-Likelihood:                -147.61
converged:                       True   LL-Null:                       -163.55
Covariance Type:            nonrobust   LLR p-value:                 1.192e-07
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.4339      0.227     -6.329      0.000      -1.878      -0.990
capabilities_entropy     0.5145      0.367      1.401      0.161      -0.205       1.234
game_entropy             1.1639      0.293      3.969      0.000       0.589       1.739
========================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  248
Model:                          Logit   Df Residuals:                      246
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                0.006883
Time:                        17:34:56   Log-Likelihood:                -162.42
converged:                       True   LL-Null:                       -163.55
Covariance Type:            nonrobust   LLR p-value:                    0.1335
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept            0.2521      0.538      0.469      0.639      -0.802       1.306
human_difficulty    -0.3301      0.222     -1.486      0.137      -0.765       0.105
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  248
Model:                          Logit   Df Residuals:                      241
Method:                           MLE   Df Model:                            6
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.03269
Time:                        17:34:56   Log-Likelihood:                -158.20
converged:                       True   LL-Null:                       -163.55
Covariance Type:            nonrobust   LLR p-value:                   0.09838
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -0.9409      2.128     -0.442      0.658      -5.113       3.231
C(domain_grouped)[T.chemistry]       -0.1142      0.452     -0.253      0.801      -1.000       0.772
C(domain_grouped)[T.physics]         -0.3024      0.477     -0.634      0.526      -1.237       0.632
human_difficulty                     -0.2969      0.240     -1.238      0.216      -0.767       0.173
q_length                              0.3717      0.231      1.607      0.108      -0.082       0.825
avg_word_length                      -0.2637      0.243     -1.086      0.278      -0.740       0.212
percent_non_alphabetic_whitespace     0.0331      0.026      1.288      0.198      -0.017       0.083
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 0.3146
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  248
Model:                          Logit   Df Residuals:                      240
Method:                           MLE   Df Model:                            7
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.07347
Time:                        17:34:56   Log-Likelihood:                -151.53
converged:                       True   LL-Null:                       -163.55
Covariance Type:            nonrobust   LLR p-value:                  0.001125
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -1.8711      2.151     -0.870      0.384      -6.087       2.345
C(domain_grouped)[T.chemistry]       -0.2021      0.465     -0.435      0.663      -1.113       0.708
C(domain_grouped)[T.physics]         -0.3846      0.491     -0.783      0.434      -1.348       0.578
human_difficulty                     -0.2430      0.247     -0.986      0.324      -0.726       0.240
q_length                              0.3443      0.238      1.448      0.148      -0.122       0.810
avg_word_length                      -0.1426      0.239     -0.597      0.550      -0.611       0.325
percent_non_alphabetic_whitespace     0.0443      0.027      1.656      0.098      -0.008       0.097
capabilities_entropy                  1.1784      0.331      3.559      0.000       0.530       1.827
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  248
Model:                          Logit   Df Residuals:                      240
Method:                           MLE   Df Model:                            7
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1189
Time:                        17:34:56   Log-Likelihood:                -144.10
converged:                       True   LL-Null:                       -163.55
Covariance Type:            nonrobust   LLR p-value:                 2.044e-06
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -1.6243      2.192     -0.741      0.459      -5.921       2.672
C(domain_grouped)[T.chemistry]       -0.5152      0.479     -1.076      0.282      -1.453       0.423
C(domain_grouped)[T.physics]         -0.8047      0.513     -1.569      0.117      -1.810       0.200
human_difficulty                     -0.1787      0.255     -0.701      0.483      -0.678       0.321
q_length                              0.3273      0.248      1.320      0.187      -0.159       0.813
avg_word_length                      -0.2392      0.241     -0.992      0.321      -0.712       0.233
percent_non_alphabetic_whitespace     0.0403      0.027      1.501      0.133      -0.012       0.093
game_entropy                          1.3910      0.276      5.049      0.000       0.851       1.931
=====================================================================================================

                  Model 4.95: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  248
Model:                          Logit   Df Residuals:                      239
Method:                           MLE   Df Model:                            8
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1240
Time:                        17:34:56   Log-Likelihood:                -143.27
converged:                       True   LL-Null:                       -163.55
Covariance Type:            nonrobust   LLR p-value:                 2.526e-06
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -1.9116      2.204     -0.867      0.386      -6.232       2.408
C(domain_grouped)[T.chemistry]       -0.5052      0.480     -1.052      0.293      -1.446       0.436
C(domain_grouped)[T.physics]         -0.7852      0.515     -1.524      0.128      -1.795       0.225
human_difficulty                     -0.1704      0.256     -0.666      0.506      -0.672       0.331
q_length                              0.3217      0.249      1.292      0.196      -0.166       0.810
avg_word_length                      -0.1943      0.241     -0.806      0.420      -0.667       0.278
percent_non_alphabetic_whitespace     0.0442      0.027      1.620      0.105      -0.009       0.098
capabilities_entropy                  0.4851      0.377      1.286      0.198      -0.254       1.224
game_entropy                          1.2138      0.307      3.958      0.000       0.613       1.815
=====================================================================================================

--- Analyzing gemini-2.5-flash-preview-04-17 (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/gemini-2.5-flash-preview-04-17_GPQA_redacted_cor_temp0.0_1751803003_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    240
1     97
Name: count, dtype: int64

Answer change%: 0.2878 [0.2394951544724986, 0.33617250131385157] (n=337)
P-value vs 25%: 0.125; P-value vs 0%: 1.8e-31
Phase 2 self-accuracy: 0.1649 [0.09109122787824837, 0.23880567933824648] (n=97)
P-value vs 25%: 0.02401; P-value vs 33%: 8.211e-06

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  336
Model:                          Logit   Df Residuals:                      334
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.01462
Time:                        17:34:56   Log-Likelihood:                -198.98
converged:                       True   LL-Null:                       -201.93
Covariance Type:            nonrobust   LLR p-value:                   0.01512
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.0049      0.130     -7.759      0.000      -1.259      -0.751
game_entropy     0.9209      0.379      2.433      0.015       0.179       1.663
================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  337
Model:                          Logit   Df Residuals:                      335
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:               2.698e-06
Time:                        17:34:56   Log-Likelihood:                -202.27
converged:                       True   LL-Null:                       -202.27
Covariance Type:            nonrobust   LLR p-value:                    0.9736
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -0.8895      0.510     -1.744      0.081      -1.889       0.110
human_difficulty    -0.0071      0.214     -0.033      0.974      -0.427       0.413
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  337
Model:                          Logit   Df Residuals:                      330
Method:                           MLE   Df Model:                            6
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.03083
Time:                        17:34:56   Log-Likelihood:                -196.03
converged:                       True   LL-Null:                       -202.27
Covariance Type:            nonrobust   LLR p-value:                   0.05226
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -3.3519      1.822     -1.840      0.066      -6.922       0.219
C(domain_grouped)[T.chemistry]        0.7622      0.446      1.708      0.088      -0.112       1.637
C(domain_grouped)[T.physics]          1.1576      0.438      2.645      0.008       0.300       2.016
human_difficulty                      0.1191      0.220      0.541      0.589      -0.313       0.551
q_length                              0.1165      0.209      0.558      0.577      -0.293       0.526
avg_word_length                       0.0852      0.196      0.434      0.664      -0.299       0.469
percent_non_alphabetic_whitespace     0.0280      0.021      1.324      0.186      -0.013       0.069
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  336
Model:                          Logit   Df Residuals:                      328
Method:                           MLE   Df Model:                            7
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.04147
Time:                        17:34:56   Log-Likelihood:                -193.55
converged:                       True   LL-Null:                       -201.93
Covariance Type:            nonrobust   LLR p-value:                   0.01910
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -3.1546      1.831     -1.723      0.085      -6.743       0.433
C(domain_grouped)[T.chemistry]        0.6346      0.453      1.401      0.161      -0.253       1.522
C(domain_grouped)[T.physics]          1.1002      0.441      2.497      0.013       0.237       1.964
human_difficulty                      0.0612      0.223      0.274      0.784      -0.376       0.498
q_length                              0.1040      0.211      0.492      0.622      -0.310       0.518
avg_word_length                       0.0912      0.196      0.464      0.642      -0.294       0.476
percent_non_alphabetic_whitespace     0.0249      0.021      1.170      0.242      -0.017       0.067
game_entropy                          0.7908      0.388      2.038      0.042       0.030       1.551
=====================================================================================================

--- Analyzing gemini-2.5-flash-preview-04-17 (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/gemini-2.5-flash-preview-04-17_GPQA_redacted_temp0.0_1751720035_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
1    55
0    51
Name: count, dtype: int64

Answer change%: 0.5189 [0.42375145415210347, 0.6139843949045003] (n=106)
P-value vs 25%: 3.02e-08; P-value vs 0%: 1.112e-26
Phase 2 self-accuracy: 0.5455 [0.4138609695693659, 0.6770481213397249] (n=55)
P-value vs 25%: 1.08e-05; P-value vs 33%: 0.001554

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  105
Model:                          Logit   Df Residuals:                      103
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:               0.0001199
Time:                        17:34:56   Log-Likelihood:                -72.653
converged:                       True   LL-Null:                       -72.661
Covariance Type:            nonrobust   LLR p-value:                    0.8950
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept        0.1076      0.216      0.497      0.619      -0.316       0.532
game_entropy    -0.0673      0.510     -0.132      0.895      -1.066       0.932
================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  106
Model:                          Logit   Df Residuals:                      104
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:               0.0002191
Time:                        17:34:56   Log-Likelihood:                -73.382
converged:                       True   LL-Null:                       -73.398
Covariance Type:            nonrobust   LLR p-value:                    0.8577
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -0.0799      0.888     -0.090      0.928      -1.821       1.661
human_difficulty     0.0614      0.343      0.179      0.858      -0.610       0.733
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  106
Model:                          Logit   Df Residuals:                       99
Method:                           MLE   Df Model:                            6
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.04391
Time:                        17:34:56   Log-Likelihood:                -70.175
converged:                       True   LL-Null:                       -73.398
Covariance Type:            nonrobust   LLR p-value:                    0.3751
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                             2.5922      3.331      0.778      0.436      -3.937       9.122
C(domain_grouped)[T.chemistry]       -0.1831      0.629     -0.291      0.771      -1.415       1.049
C(domain_grouped)[T.physics]         -0.5180      0.706     -0.734      0.463      -1.901       0.865
human_difficulty                      0.3090      0.379      0.815      0.415      -0.435       1.053
q_length                             -0.2675      0.306     -0.875      0.382      -0.867       0.332
avg_word_length                      -0.3980      0.381     -1.045      0.296      -1.145       0.349
percent_non_alphabetic_whitespace     0.0452      0.045      1.005      0.315      -0.043       0.133
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  105
Model:                          Logit   Df Residuals:                       97
Method:                           MLE   Df Model:                            7
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.04885
Time:                        17:34:56   Log-Likelihood:                -69.112
converged:                       True   LL-Null:                       -72.661
Covariance Type:            nonrobust   LLR p-value:                    0.4186
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                             3.5214      3.434      1.025      0.305      -3.209      10.252
C(domain_grouped)[T.chemistry]       -0.1013      0.648     -0.156      0.876      -1.371       1.168
C(domain_grouped)[T.physics]         -0.5955      0.713     -0.836      0.403      -1.992       0.801
human_difficulty                      0.3363      0.384      0.875      0.381      -0.417       1.089
q_length                             -0.2922      0.308     -0.949      0.343      -0.896       0.312
avg_word_length                      -0.5443      0.402     -1.354      0.176      -1.332       0.244
percent_non_alphabetic_whitespace     0.0307      0.046      0.664      0.507      -0.060       0.121
game_entropy                         -0.2588      0.551     -0.470      0.639      -1.339       0.821
=====================================================================================================

--- Analyzing gpt-4.1-2025-04-14 (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/gpt-4.1-2025-04-14_GPQA_redacted_cor_temp0.0_1751719236_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    153
1     54
Name: count, dtype: int64

Answer change%: 0.2609 [0.2010511134765667, 0.32068801695821586] (n=207)
P-value vs 25%: 0.7217; P-value vs 0%: 1.258e-17
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=54)
P-value vs 25%: 0; P-value vs 33%: 0

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  207
Model:                          Logit   Df Residuals:                      205
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.04034
Time:                        17:34:56   Log-Likelihood:                -114.02
converged:                       True   LL-Null:                       -118.81
Covariance Type:            nonrobust   LLR p-value:                  0.001960
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          2.5279      1.175      2.152      0.031       0.226       4.830
p_i_capability    -3.7925      1.242     -3.055      0.002      -6.226      -1.359
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  207
Model:                          Logit   Df Residuals:                      205
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.05198
Time:                        17:34:56   Log-Likelihood:                -112.63
converged:                       True   LL-Null:                       -118.81
Covariance Type:            nonrobust   LLR p-value:                 0.0004405
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.3320      0.187     -7.110      0.000      -1.699      -0.965
capabilities_entropy     1.4053      0.404      3.478      0.001       0.613       2.197
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.4074 [0.2221, 0.5927] (n=27)
                  P-value vs 33.3%: 0.4334

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=-2.82, p=0.0303
Wilcoxon delta_p: statistic=1.00, p=0.0312
Mean Δp = -0.2023  [-0.3429, -0.0617]
Idea 1 N = 7; 

  Idea 1.5: Calibration Metrics
  NLL: 0.3157, Signed ECE (overconf pos under neg): -0.2449, ECE: 0.2449 (n=20)
  Brier: 0.0954, Reliability (absolute calibration error; lower better): 0.0948, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=20)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.964
Model:                            OLS   Adj. R-squared:                  0.957
Method:                 Least Squares   F-statistic:                     141.8
Date:                Sat, 09 Aug 2025   Prob (F-statistic):           9.77e-12
Time:                        17:34:56   Log-Likelihood:                 19.524
No. Observations:                  20   AIC:                            -31.05
Df Residuals:                      16   BIC:                            -27.07
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.8719      0.175     -4.979      0.000      -1.243      -0.501
p1                    0.9172      0.234      3.919      0.001       0.421       1.413
answer_changed        0.7994      0.208      3.836      0.001       0.358       1.241
p1:answer_changed     0.0929      0.274      0.339      0.739      -0.488       0.674
==============================================================================
Omnibus:                        0.977   Durbin-Watson:                   2.767
Prob(Omnibus):                  0.613   Jarque-Bera (JB):                0.296
Skew:                          -0.292   Prob(JB):                        0.863
Kurtosis:                       3.118   Cond. No.                         29.3
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=1.54, p=0.174
Wilcoxon delta_H: statistic=7.00, p=0.297
Mean ΔH = 0.4243  [-0.1147, 0.9632]
Paired t-test delta_H Changed: statistic=2.84, p=0.0149
Wilcoxon delta_H Changed: statistic=13.00, p=0.0215
Mean ΔH Changed = 0.2715  [0.0841, 0.4588]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=3.08, p=0.00618
Wilcoxon (p_top2_game vs p_top2_base): statistic=53.00, p=0.0532
Mean Δp_top2 = 0.0515  [0.0187, 0.0844] (n=20)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=2.92, p=0.00879
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=34.00, p=0.00639
Mean ΔH_unchosen_baseline_set = 0.3249  [0.1068, 0.5431] (n=20)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                   20
Model:                          Logit   Df Residuals:                       17
Method:                           MLE   Df Model:                            2
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.03866
Time:                        17:34:56   Log-Likelihood:                -12.448
converged:                       True   LL-Null:                       -12.949
Covariance Type:            nonrobust   LLR p-value:                    0.6061
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept        0.1927      0.669      0.288      0.773      -1.118       1.504
p1_z             0.3427      0.534      0.642      0.521      -0.704       1.390
I(p1_z ** 2)     0.4661      0.539      0.865      0.387      -0.590       1.522
================================================================================
AUC = 0.538

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  207
Model:                          Logit   Df Residuals:                      205
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1057
Time:                        17:34:56   Log-Likelihood:                -106.26
converged:                       True   LL-Null:                       -118.81
Covariance Type:            nonrobust   LLR p-value:                 5.426e-07
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.4417      0.191     -7.559      0.000      -1.815      -1.068
game_entropy     2.8143      0.615      4.579      0.000       1.610       4.019
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=3457.00, p=0.00909
Paired t-test (game_entropy vs capabilities_entropy): statistic=-2.33, p=0.0205
Mean capabilities_entropy-game_entropy = 0.0559  [0.0090, 0.1029] (n=207)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  207
Model:                          Logit   Df Residuals:                      204
Method:                           MLE   Df Model:                            2
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1155
Time:                        17:34:56   Log-Likelihood:                -105.08
converged:                       True   LL-Null:                       -118.81
Covariance Type:            nonrobust   LLR p-value:                 1.094e-06
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.5316      0.203     -7.550      0.000      -1.929      -1.134
capabilities_entropy     0.7226      0.463      1.560      0.119      -0.185       1.631
game_entropy             2.4298      0.657      3.696      0.000       1.141       3.718
========================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  207
Model:                          Logit   Df Residuals:                      205
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                0.001317
Time:                        17:34:56   Log-Likelihood:                -118.65
converged:                       True   LL-Null:                       -118.81
Covariance Type:            nonrobust   LLR p-value:                    0.5758
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -1.4145      0.689     -2.054      0.040      -2.764      -0.065
human_difficulty     0.1548      0.277      0.559      0.576      -0.388       0.697
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  207
Model:                          Logit   Df Residuals:                      200
Method:                           MLE   Df Model:                            6
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.07449
Time:                        17:34:56   Log-Likelihood:                -109.96
converged:                       True   LL-Null:                       -118.81
Covariance Type:            nonrobust   LLR p-value:                  0.007028
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -2.4816      2.550     -0.973      0.330      -7.479       2.516
C(domain_grouped)[T.chemistry]        1.3720      0.525      2.615      0.009       0.344       2.400
C(domain_grouped)[T.physics]          0.6865      0.519      1.322      0.186      -0.331       1.705
human_difficulty                      0.3803      0.298      1.275      0.202      -0.204       0.965
q_length                              0.1931      0.268      0.721      0.471      -0.332       0.718
avg_word_length                      -0.3498      0.331     -1.055      0.291      -1.000       0.300
percent_non_alphabetic_whitespace     0.0220      0.033      0.672      0.502      -0.042       0.086
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 0.1733
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  207
Model:                          Logit   Df Residuals:                      199
Method:                           MLE   Df Model:                            7
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1045
Time:                        17:34:56   Log-Likelihood:                -106.40
converged:                       True   LL-Null:                       -118.81
Covariance Type:            nonrobust   LLR p-value:                 0.0008146
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -2.8013      2.583     -1.085      0.278      -7.864       2.261
C(domain_grouped)[T.chemistry]        1.1144      0.541      2.058      0.040       0.053       2.175
C(domain_grouped)[T.physics]          0.5592      0.527      1.061      0.288      -0.473       1.592
human_difficulty                      0.4537      0.304      1.494      0.135      -0.141       1.049
q_length                              0.1639      0.274      0.598      0.550      -0.373       0.700
avg_word_length                      -0.2992      0.339     -0.883      0.377      -0.963       0.365
percent_non_alphabetic_whitespace     0.0221      0.034      0.658      0.510      -0.044       0.088
capabilities_entropy                  1.1313      0.428      2.641      0.008       0.292       1.971
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  207
Model:                          Logit   Df Residuals:                      199
Method:                           MLE   Df Model:                            7
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1607
Time:                        17:34:56   Log-Likelihood:                -99.719
converged:                       True   LL-Null:                       -118.81
Covariance Type:            nonrobust   LLR p-value:                 2.796e-06
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -2.2842      2.727     -0.838      0.402      -7.630       3.061
C(domain_grouped)[T.chemistry]        1.2311      0.561      2.195      0.028       0.132       2.330
C(domain_grouped)[T.physics]          0.7237      0.548      1.321      0.187      -0.350       1.798
human_difficulty                      0.3503      0.310      1.131      0.258      -0.257       0.957
q_length                              0.0985      0.289      0.341      0.733      -0.468       0.666
avg_word_length                      -0.3292      0.357     -0.923      0.356      -1.028       0.370
percent_non_alphabetic_whitespace     0.0221      0.035      0.631      0.528      -0.046       0.091
game_entropy                          2.6977      0.644      4.190      0.000       1.436       3.960
=====================================================================================================

                  Model 4.95: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  207
Model:                          Logit   Df Residuals:                      198
Method:                           MLE   Df Model:                            8
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1639
Time:                        17:34:56   Log-Likelihood:                -99.333
converged:                       True   LL-Null:                       -118.81
Covariance Type:            nonrobust   LLR p-value:                 5.012e-06
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -2.4317      2.727     -0.892      0.373      -7.777       2.913
C(domain_grouped)[T.chemistry]        1.1546      0.569      2.030      0.042       0.040       2.270
C(domain_grouped)[T.physics]          0.6735      0.551      1.222      0.222      -0.407       1.754
human_difficulty                      0.3912      0.315      1.240      0.215      -0.227       1.009
q_length                              0.0993      0.289      0.343      0.731      -0.468       0.666
avg_word_length                      -0.3183      0.357     -0.892      0.373      -1.018       0.381
percent_non_alphabetic_whitespace     0.0208      0.035      0.595      0.552      -0.048       0.089
capabilities_entropy                  0.4385      0.496      0.885      0.376      -0.533       1.410
game_entropy                          2.4750      0.690      3.588      0.000       1.123       3.827
=====================================================================================================

--- Analyzing gpt-4.1-2025-04-14 (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/gpt-4.1-2025-04-14_GPQA_redacted_temp0.0_1751719593_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    123
1    117
Name: count, dtype: int64

Answer change%: 0.4875 [0.42426220548487903, 0.550737794515121] (n=240)
P-value vs 25%: 1.826e-13; P-value vs 0%: 1.405e-51
Phase 2 self-accuracy: 0.4359 [0.3460457243491281, 0.5257491474457436] (n=117)
P-value vs 25%: 5.013e-05; P-value vs 33%: 0.0248

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  240
Model:                          Logit   Df Residuals:                      238
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.03651
Time:                        17:34:56   Log-Likelihood:                -160.21
converged:                       True   LL-Null:                       -166.28
Covariance Type:            nonrobust   LLR p-value:                 0.0004933
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          2.1370      0.669      3.196      0.001       0.827       3.447
p_i_capability    -2.5236      0.751     -3.360      0.001      -3.996      -1.052
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  240
Model:                          Logit   Df Residuals:                      238
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.03705
Time:                        17:34:56   Log-Likelihood:                -160.12
converged:                       True   LL-Null:                       -166.28
Covariance Type:            nonrobust   LLR p-value:                 0.0004479
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -0.4419      0.173     -2.548      0.011      -0.782      -0.102
capabilities_entropy     0.8770      0.257      3.414      0.001       0.373       1.381
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.5714 [0.4609, 0.6820] (n=77)
                  P-value vs 33.3%: 2.423e-05

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=-2.98, p=0.0051
Wilcoxon delta_p: statistic=167.00, p=0.00254
Mean Δp = -0.1033  [-0.1713, -0.0353]
Idea 1 N = 38; 

  Idea 1.5: Calibration Metrics
  NLL: 5.4874, Signed ECE (overconf pos under neg): 0.0885, ECE: 0.0885 (n=85)
  Brier: 0.0229, Reliability (absolute calibration error; lower better): 0.0223, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=85)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.889
Model:                            OLS   Adj. R-squared:                  0.885
Method:                 Least Squares   F-statistic:                     215.5
Date:                Sat, 09 Aug 2025   Prob (F-statistic):           1.66e-38
Time:                        17:34:56   Log-Likelihood:                 45.057
No. Observations:                  85   AIC:                            -82.11
Df Residuals:                      81   BIC:                            -72.34
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.7597      0.104     -7.295      0.000      -0.967      -0.552
p1                    0.8363      0.129      6.472      0.000       0.579       1.093
answer_changed        0.6952      0.130      5.354      0.000       0.437       0.954
p1:answer_changed     0.1413      0.167      0.845      0.401      -0.191       0.474
==============================================================================
Omnibus:                        5.301   Durbin-Watson:                   2.003
Prob(Omnibus):                  0.071   Jarque-Bera (JB):                4.900
Skew:                          -0.406   Prob(JB):                       0.0863
Kurtosis:                       3.850   Cond. No.                         23.2
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=2.51, p=0.0167
Wilcoxon delta_H: statistic=189.00, p=0.0076
Mean ΔH = 0.2235  [0.0488, 0.3982]
Paired t-test delta_H Changed: statistic=4.90, p=1.23e-05
Wilcoxon delta_H Changed: statistic=193.00, p=3.94e-05
Mean ΔH Changed = 0.3850  [0.2310, 0.5389]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=5.66, p=2.09e-07
Wilcoxon (p_top2_game vs p_top2_base): statistic=514.00, p=8.64e-09
Mean Δp_top2 = 0.0532  [0.0348, 0.0716] (n=85)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=5.28, p=1e-06
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=763.00, p=3.1e-06
Mean ΔH_unchosen_baseline_set = 0.3128  [0.1967, 0.4289] (n=85)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                   85
Model:                          Logit   Df Residuals:                       82
Method:                           MLE   Df Model:                            2
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.03311
Time:                        17:34:56   Log-Likelihood:                -56.505
converged:                       True   LL-Null:                       -58.440
Covariance Type:            nonrobust   LLR p-value:                    0.1444
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept        0.1214      0.343      0.353      0.724      -0.552       0.794
p1_z            -0.4140      0.234     -1.772      0.076      -0.872       0.044
I(p1_z ** 2)     0.1066      0.274      0.389      0.697      -0.430       0.643
================================================================================
AUC = 0.607

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  240
Model:                          Logit   Df Residuals:                      238
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.03572
Time:                        17:34:56   Log-Likelihood:                -160.34
converged:                       True   LL-Null:                       -166.28
Covariance Type:            nonrobust   LLR p-value:                 0.0005675
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.3622      0.160     -2.269      0.023      -0.675      -0.049
game_entropy     1.1419      0.343      3.329      0.001       0.470       1.814
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=7893.50, p=1.9e-06
Paired t-test (game_entropy vs capabilities_entropy): statistic=-4.91, p=1.67e-06
Mean capabilities_entropy-game_entropy = 0.1721  [0.1034, 0.2407] (n=240)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  240
Model:                          Logit   Df Residuals:                      237
Method:                           MLE   Df Model:                            2
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.05438
Time:                        17:34:56   Log-Likelihood:                -157.24
converged:                       True   LL-Null:                       -166.28
Covariance Type:            nonrobust   LLR p-value:                 0.0001184
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -0.5823      0.185     -3.143      0.002      -0.945      -0.219
capabilities_entropy     0.6681      0.271      2.462      0.014       0.136       1.200
game_entropy             0.8546      0.362      2.363      0.018       0.146       1.563
========================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  240
Model:                          Logit   Df Residuals:                      238
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                0.003044
Time:                        17:34:56   Log-Likelihood:                -165.77
converged:                       True   LL-Null:                       -166.28
Covariance Type:            nonrobust   LLR p-value:                    0.3143
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept            0.4839      0.548      0.884      0.377      -0.589       1.557
human_difficulty    -0.2276      0.227     -1.003      0.316      -0.672       0.217
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  240
Model:                          Logit   Df Residuals:                      233
Method:                           MLE   Df Model:                            6
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                0.006197
Time:                        17:34:56   Log-Likelihood:                -165.25
converged:                       True   LL-Null:                       -166.28
Covariance Type:            nonrobust   LLR p-value:                    0.9140
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -0.7043      1.944     -0.362      0.717      -4.515       3.106
C(domain_grouped)[T.chemistry]        0.1100      0.523      0.210      0.833      -0.915       1.135
C(domain_grouped)[T.physics]          0.3240      0.548      0.591      0.554      -0.750       1.398
human_difficulty                     -0.2075      0.236     -0.878      0.380      -0.671       0.256
q_length                              0.0859      0.221      0.389      0.697      -0.347       0.519
avg_word_length                       0.0723      0.200      0.361      0.718      -0.320       0.465
percent_non_alphabetic_whitespace     0.0123      0.023      0.544      0.587      -0.032       0.056
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 0.4513
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  240
Model:                          Logit   Df Residuals:                      232
Method:                           MLE   Df Model:                            7
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.04359
Time:                        17:34:56   Log-Likelihood:                -159.03
converged:                       True   LL-Null:                       -166.28
Covariance Type:            nonrobust   LLR p-value:                   0.04302
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -1.3854      2.004     -0.691      0.489      -5.313       2.543
C(domain_grouped)[T.chemistry]        0.1031      0.542      0.190      0.849      -0.959       1.165
C(domain_grouped)[T.physics]          0.3872      0.569      0.681      0.496      -0.727       1.502
human_difficulty                     -0.1252      0.243     -0.516      0.606      -0.601       0.350
q_length                             -0.0193      0.228     -0.085      0.932      -0.465       0.427
avg_word_length                       0.1991      0.209      0.952      0.341      -0.211       0.609
percent_non_alphabetic_whitespace     0.0228      0.024      0.947      0.344      -0.024       0.070
capabilities_entropy                  0.9181      0.268      3.421      0.001       0.392       1.444
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  240
Model:                          Logit   Df Residuals:                      232
Method:                           MLE   Df Model:                            7
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.03953
Time:                        17:34:56   Log-Likelihood:                -159.71
converged:                       True   LL-Null:                       -166.28
Covariance Type:            nonrobust   LLR p-value:                   0.06863
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -1.3371      1.995     -0.670      0.503      -5.247       2.573
C(domain_grouped)[T.chemistry]        0.1060      0.536      0.198      0.843      -0.944       1.156
C(domain_grouped)[T.physics]          0.3463      0.561      0.617      0.537      -0.753       1.446
human_difficulty                     -0.0767      0.244     -0.314      0.754      -0.556       0.402
q_length                              0.0196      0.226      0.087      0.931      -0.424       0.463
avg_word_length                       0.1543      0.205      0.751      0.452      -0.248       0.557
percent_non_alphabetic_whitespace     0.0148      0.023      0.638      0.524      -0.031       0.060
game_entropy                          1.1399      0.354      3.222      0.001       0.447       1.833
=====================================================================================================

                  Model 4.95: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  240
Model:                          Logit   Df Residuals:                      231
Method:                           MLE   Df Model:                            8
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.06051
Time:                        17:34:56   Log-Likelihood:                -156.22
converged:                       True   LL-Null:                       -166.28
Covariance Type:            nonrobust   LLR p-value:                  0.009883
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -1.7031      2.032     -0.838      0.402      -5.685       2.279
C(domain_grouped)[T.chemistry]        0.0957      0.545      0.176      0.861      -0.973       1.165
C(domain_grouped)[T.physics]          0.3875      0.572      0.678      0.498      -0.733       1.508
human_difficulty                     -0.0449      0.249     -0.181      0.857      -0.532       0.443
q_length                             -0.0489      0.231     -0.212      0.832      -0.501       0.403
avg_word_length                       0.2341      0.211      1.112      0.266      -0.179       0.647
percent_non_alphabetic_whitespace     0.0224      0.024      0.920      0.357      -0.025       0.070
capabilities_entropy                  0.7285      0.280      2.602      0.009       0.180       1.277
game_entropy                          0.8642      0.370      2.336      0.019       0.139       1.589
=====================================================================================================

--- Analyzing gpt-4o-2024-08-06 (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/gpt-4o-2024-08-06_GPQA_redacted_cor_temp0.0_1751718481_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    150
1     34
Name: count, dtype: int64

Answer change%: 0.1848 [0.1287028101886291, 0.2408624072026752] (n=184)
P-value vs 25%: 0.02265; P-value vs 0%: 1.06e-10
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=34)
P-value vs 25%: 0; P-value vs 33%: 0

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  184
Model:                          Logit   Df Residuals:                      182
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.09039
Time:                        17:34:56   Log-Likelihood:                -80.097
converged:                       True   LL-Null:                       -88.057
Covariance Type:            nonrobust   LLR p-value:                 6.613e-05
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          0.1915      0.442      0.433      0.665      -0.676       1.059
p_i_capability    -2.3808      0.605     -3.936      0.000      -3.566      -1.195
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  184
Model:                          Logit   Df Residuals:                      182
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.3513
Time:                        17:34:56   Log-Likelihood:                -57.119
converged:                       True   LL-Null:                       -88.057
Covariance Type:            nonrobust   LLR p-value:                 3.658e-15
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -3.7946      0.529     -7.178      0.000      -4.831      -2.759
capabilities_entropy     2.7515      0.445      6.183      0.000       1.879       3.624
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.4118 [0.2463, 0.5772] (n=34)
                  P-value vs 33.3%: 0.3528

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=-0.12, p=0.903
Wilcoxon delta_p: statistic=3319.00, p=0.269
Mean Δp = -0.0018  [-0.0303, 0.0268]
Idea 1 N = 122; 

  Idea 1.5: Calibration Metrics
  NLL: 0.4035, Signed ECE (overconf pos under neg): -0.2362, ECE: 0.2362 (n=155)
  Brier: 0.1341, Reliability (absolute calibration error; lower better): 0.1335, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=155)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.245
Model:                            OLS   Adj. R-squared:                  0.230
Method:                 Least Squares   F-statistic:                     16.31
Date:                Sat, 09 Aug 2025   Prob (F-statistic):           3.12e-09
Time:                        17:34:56   Log-Likelihood:                 43.976
No. Observations:                 155   AIC:                            -79.95
Df Residuals:                     151   BIC:                            -67.78
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.1973      0.086     -2.289      0.023      -0.368      -0.027
p1                    0.2236      0.097      2.312      0.022       0.033       0.415
answer_changed        0.0783      0.139      0.561      0.575      -0.197       0.354
p1:answer_changed     0.3469      0.207      1.680      0.095      -0.061       0.755
==============================================================================
Omnibus:                       19.105   Durbin-Watson:                   1.764
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               43.254
Skew:                           0.496   Prob(JB):                     4.05e-10
Kurtosis:                       5.390   Cond. No.                         22.8
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=0.26, p=0.794
Wilcoxon delta_H: statistic=3619.00, p=0.853
Mean ΔH = 0.0113  [-0.0732, 0.0958]
Paired t-test delta_H Changed: statistic=3.07, p=0.00438
Wilcoxon delta_H Changed: statistic=92.00, p=0.0013
Mean ΔH Changed = 0.2758  [0.0995, 0.4522]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=2.34, p=0.0207
Wilcoxon (p_top2_game vs p_top2_base): statistic=3786.00, p=5.45e-05
Mean Δp_top2 = 0.0142  [0.0023, 0.0261] (n=155)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=1.70, p=0.0912
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=4920.00, p=0.0771
Mean ΔH_unchosen_baseline_set = 0.0676  [-0.0104, 0.1456] (n=155)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  155
Model:                          Logit   Df Residuals:                      152
Method:                           MLE   Df Model:                            2
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.3297
Time:                        17:34:56   Log-Likelihood:                -53.795
converged:                       True   LL-Null:                       -80.256
Covariance Type:            nonrobust   LLR p-value:                 3.224e-12
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.6401      0.342     -4.802      0.000      -2.310      -0.971
p1_z            -2.0557      0.478     -4.303      0.000      -2.992      -1.119
I(p1_z ** 2)    -0.4485      0.295     -1.522      0.128      -1.026       0.129
================================================================================
AUC = 0.879

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  184
Model:                          Logit   Df Residuals:                      182
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.3013
Time:                        17:34:56   Log-Likelihood:                -61.523
converged:                       True   LL-Null:                       -88.057
Covariance Type:            nonrobust   LLR p-value:                 3.224e-13
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -3.2732      0.438     -7.472      0.000      -4.132      -2.415
game_entropy     2.5254      0.411      6.139      0.000       1.719       3.332
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=6067.00, p=0.000733
Paired t-test (game_entropy vs capabilities_entropy): statistic=-3.15, p=0.00189
Mean capabilities_entropy-game_entropy = 0.0832  [0.0315, 0.1350] (n=184)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  184
Model:                          Logit   Df Residuals:                      181
Method:                           MLE   Df Model:                            2
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.3661
Time:                        17:34:56   Log-Likelihood:                -55.816
converged:                       True   LL-Null:                       -88.057
Covariance Type:            nonrobust   LLR p-value:                 9.956e-15
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -3.8623      0.535     -7.218      0.000      -4.911      -2.814
capabilities_entropy     2.0035      0.627      3.198      0.001       0.775       3.231
game_entropy             0.9734      0.609      1.599      0.110      -0.220       2.167
========================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  184
Model:                          Logit   Df Residuals:                      182
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                0.002086
Time:                        17:34:56   Log-Likelihood:                -87.873
converged:                       True   LL-Null:                       -88.057
Covariance Type:            nonrobust   LLR p-value:                    0.5445
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -1.0138      0.795     -1.275      0.202      -2.572       0.544
human_difficulty    -0.1951      0.323     -0.604      0.546      -0.828       0.438
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  184
Model:                          Logit   Df Residuals:                      177
Method:                           MLE   Df Model:                            6
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.08220
Time:                        17:34:56   Log-Likelihood:                -80.818
converged:                       True   LL-Null:                       -88.057
Covariance Type:            nonrobust   LLR p-value:                   0.02474
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -6.2834      2.799     -2.245      0.025     -11.769      -0.798
C(domain_grouped)[T.chemistry]        2.3007      0.733      3.137      0.002       0.863       3.738
C(domain_grouped)[T.physics]          1.8765      0.734      2.556      0.011       0.437       3.316
human_difficulty                     -0.0126      0.332     -0.038      0.970      -0.663       0.638
q_length                              0.2914      0.332      0.877      0.380      -0.360       0.942
avg_word_length                       0.2932      0.276      1.063      0.288      -0.248       0.834
percent_non_alphabetic_whitespace     0.0089      0.036      0.250      0.803      -0.061       0.079
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 0.5517
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  184
Model:                          Logit   Df Residuals:                      176
Method:                           MLE   Df Model:                            7
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.4037
Time:                        17:34:56   Log-Likelihood:                -52.507
converged:                       True   LL-Null:                       -88.057
Covariance Type:            nonrobust   LLR p-value:                 8.858e-13
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                           -13.2191      4.122     -3.207      0.001     -21.298      -5.141
C(domain_grouped)[T.chemistry]        1.4253      0.924      1.542      0.123      -0.387       3.237
C(domain_grouped)[T.physics]          1.1195      0.938      1.193      0.233      -0.719       2.958
human_difficulty                      0.1689      0.405      0.417      0.677      -0.625       0.963
q_length                              0.6440      0.455      1.414      0.157      -0.249       1.536
avg_word_length                       0.6786      0.382      1.775      0.076      -0.071       1.428
percent_non_alphabetic_whitespace     0.0845      0.048      1.763      0.078      -0.009       0.178
capabilities_entropy                  3.0339      0.551      5.509      0.000       1.954       4.113
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  184
Model:                          Logit   Df Residuals:                      176
Method:                           MLE   Df Model:                            7
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.3548
Time:                        17:34:56   Log-Likelihood:                -56.810
converged:                       True   LL-Null:                       -88.057
Covariance Type:            nonrobust   LLR p-value:                 4.790e-11
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -9.8537      3.483     -2.829      0.005     -16.681      -3.027
C(domain_grouped)[T.chemistry]        2.1563      0.909      2.372      0.018       0.375       3.938
C(domain_grouped)[T.physics]          1.7369      0.937      1.855      0.064      -0.099       3.572
human_difficulty                      0.1916      0.404      0.475      0.635      -0.599       0.983
q_length                              0.2314      0.404      0.572      0.567      -0.561       1.024
avg_word_length                       0.5826      0.344      1.692      0.091      -0.092       1.257
percent_non_alphabetic_whitespace     0.0448      0.042      1.058      0.290      -0.038       0.128
game_entropy                          2.5938      0.451      5.748      0.000       1.709       3.478
=====================================================================================================

                  Model 4.95: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  184
Model:                          Logit   Df Residuals:                      175
Method:                           MLE   Df Model:                            8
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.4172
Time:                        17:34:57   Log-Likelihood:                -51.317
converged:                       True   LL-Null:                       -88.057
Covariance Type:            nonrobust   LLR p-value:                 9.942e-13
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                           -13.3740      4.201     -3.184      0.001     -21.607      -5.141
C(domain_grouped)[T.chemistry]        1.4520      0.942      1.541      0.123      -0.395       3.299
C(domain_grouped)[T.physics]          1.1135      0.962      1.158      0.247      -0.772       2.999
human_difficulty                      0.2413      0.416      0.580      0.562      -0.574       1.056
q_length                              0.6193      0.463      1.339      0.181      -0.287       1.526
avg_word_length                       0.6957      0.387      1.797      0.072      -0.063       1.455
percent_non_alphabetic_whitespace     0.0803      0.048      1.666      0.096      -0.014       0.175
capabilities_entropy                  2.2958      0.730      3.145      0.002       0.865       3.727
game_entropy                          0.9704      0.638      1.521      0.128      -0.280       2.221
=====================================================================================================

--- Analyzing gpt-4o-2024-08-06 (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/gpt-4o-2024-08-06_GPQA_redacted_temp0.0_1751721831_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    158
1    105
Name: count, dtype: int64

Answer change%: 0.3992 [0.34005099910497044, 0.4584280883475011] (n=263)
P-value vs 25%: 7.736e-07; P-value vs 0%: 6.692e-40
Phase 2 self-accuracy: 0.4857 [0.3901168791950892, 0.5813116922334822] (n=105)
P-value vs 25%: 1.347e-06; P-value vs 33%: 0.001742

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  263
Model:                          Logit   Df Residuals:                      261
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.04104
Time:                        17:34:57   Log-Likelihood:                -169.66
converged:                       True   LL-Null:                       -176.92
Covariance Type:            nonrobust   LLR p-value:                 0.0001385
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          1.2109      0.452      2.677      0.007       0.324       2.097
p_i_capability    -2.3413      0.634     -3.693      0.000      -3.584      -1.099
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  263
Model:                          Logit   Df Residuals:                      261
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.06442
Time:                        17:34:57   Log-Likelihood:                -165.52
converged:                       True   LL-Null:                       -176.92
Covariance Type:            nonrobust   LLR p-value:                 1.803e-06
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.5554      0.295     -5.277      0.000      -2.133      -0.978
capabilities_entropy     1.1066      0.244      4.527      0.000       0.627       1.586
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.4381 [0.3432, 0.5330] (n=105)
                  P-value vs 33.3%: 0.03049

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=1.85, p=0.066
Wilcoxon delta_p: statistic=4983.00, p=0.252
Mean Δp = 0.0329  [-0.0019, 0.0677]
Idea 1 N = 149; 

  Idea 1.5: Calibration Metrics
  NLL: 3.2163, Signed ECE (overconf pos under neg): 0.1738, ECE: 0.1738 (n=254)
  Brier: 0.0780, Reliability (absolute calibration error; lower better): 0.0772, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=254)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.278
Model:                            OLS   Adj. R-squared:                  0.270
Method:                 Least Squares   F-statistic:                     32.14
Date:                Sat, 09 Aug 2025   Prob (F-statistic):           1.33e-17
Time:                        17:34:57   Log-Likelihood:                -12.446
No. Observations:                 254   AIC:                             32.89
Df Residuals:                     250   BIC:                             47.04
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept             0.0544      0.080      0.683      0.495      -0.103       0.211
p1                   -0.0290      0.103     -0.280      0.779      -0.232       0.175
answer_changed       -0.5521      0.125     -4.431      0.000      -0.798      -0.307
p1:answer_changed     1.1586      0.177      6.529      0.000       0.809       1.508
==============================================================================
Omnibus:                        2.391   Durbin-Watson:                   2.039
Prob(Omnibus):                  0.303   Jarque-Bera (JB):                2.185
Skew:                          -0.141   Prob(JB):                        0.335
Kurtosis:                       2.643   Cond. No.                         19.3
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=5.79, p=4.01e-08
Wilcoxon delta_H: statistic=2565.00, p=1.02e-08
Mean ΔH = 0.2113  [0.1398, 0.2828]
Paired t-test delta_H Changed: statistic=7.44, p=3.07e-11
Wilcoxon delta_H Changed: statistic=771.00, p=1.27e-10
Mean ΔH Changed = 0.2904  [0.2138, 0.3670]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=6.33, p=1.09e-09
Wilcoxon (p_top2_game vs p_top2_base): statistic=8398.00, p=2.92e-11
Mean Δp_top2 = 0.0367  [0.0253, 0.0480] (n=254)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=9.08, p=3.14e-17
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=6223.00, p=1.8e-17
Mean ΔH_unchosen_baseline_set = 0.2440  [0.1913, 0.2966] (n=254)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  254
Model:                          Logit   Df Residuals:                      251
Method:                           MLE   Df Model:                            2
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.06759
Time:                        17:34:57   Log-Likelihood:                -160.59
converged:                       True   LL-Null:                       -172.23
Covariance Type:            nonrobust   LLR p-value:                 8.795e-06
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.0410      0.190     -0.216      0.829      -0.413       0.331
p1_z            -0.6004      0.145     -4.142      0.000      -0.885      -0.316
I(p1_z ** 2)    -0.3668      0.152     -2.415      0.016      -0.664      -0.069
================================================================================
AUC = 0.658

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  263
Model:                          Logit   Df Residuals:                      261
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.05462
Time:                        17:34:57   Log-Likelihood:                -167.26
converged:                       True   LL-Null:                       -176.92
Covariance Type:            nonrobust   LLR p-value:                 1.101e-05
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.2803      0.250     -5.130      0.000      -1.769      -0.791
game_entropy     1.0253      0.241      4.250      0.000       0.552       1.498
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=10235.00, p=7.99e-09
Paired t-test (game_entropy vs capabilities_entropy): statistic=-5.85, p=1.43e-08
Mean capabilities_entropy-game_entropy = 0.1771  [0.1178, 0.2364] (n=263)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  263
Model:                          Logit   Df Residuals:                      260
Method:                           MLE   Df Model:                            2
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.07411
Time:                        17:34:57   Log-Likelihood:                -163.81
converged:                       True   LL-Null:                       -176.92
Covariance Type:            nonrobust   LLR p-value:                 2.023e-06
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.6840      0.305     -5.514      0.000      -2.283      -1.085
capabilities_entropy     0.7754      0.300      2.586      0.010       0.188       1.363
game_entropy             0.5548      0.300      1.848      0.065      -0.034       1.143
========================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  263
Model:                          Logit   Df Residuals:                      261
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                0.004448
Time:                        17:34:57   Log-Likelihood:                -176.13
converged:                       True   LL-Null:                       -176.92
Covariance Type:            nonrobust   LLR p-value:                    0.2096
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept            0.2581      0.548      0.471      0.637      -0.815       1.331
human_difficulty    -0.2877      0.231     -1.246      0.213      -0.740       0.165
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  263
Model:                          Logit   Df Residuals:                      256
Method:                           MLE   Df Model:                            6
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.01505
Time:                        17:34:57   Log-Likelihood:                -174.26
converged:                       True   LL-Null:                       -176.92
Covariance Type:            nonrobust   LLR p-value:                    0.5029
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -0.8454      2.092     -0.404      0.686      -4.945       3.255
C(domain_grouped)[T.chemistry]        0.1397      0.505      0.277      0.782      -0.850       1.129
C(domain_grouped)[T.physics]         -0.0479      0.524     -0.091      0.927      -1.075       0.980
human_difficulty                     -0.3106      0.240     -1.294      0.196      -0.781       0.160
q_length                              0.3413      0.217      1.574      0.116      -0.084       0.766
avg_word_length                      -0.1937      0.239     -0.810      0.418      -0.662       0.275
percent_non_alphabetic_whitespace    -0.0033      0.023     -0.141      0.888      -0.049       0.043
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 0.9955
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  263
Model:                          Logit   Df Residuals:                      255
Method:                           MLE   Df Model:                            7
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.07310
Time:                        17:34:57   Log-Likelihood:                -163.99
converged:                       True   LL-Null:                       -176.92
Covariance Type:            nonrobust   LLR p-value:                 0.0005321
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -1.8719      2.184     -0.857      0.391      -6.152       2.408
C(domain_grouped)[T.chemistry]       -0.2669      0.536     -0.498      0.619      -1.318       0.784
C(domain_grouped)[T.physics]         -0.4546      0.560     -0.811      0.417      -1.553       0.644
human_difficulty                     -0.2957      0.254     -1.164      0.244      -0.794       0.202
q_length                              0.2583      0.227      1.139      0.255      -0.186       0.703
avg_word_length                      -0.0474      0.249     -0.190      0.849      -0.536       0.441
percent_non_alphabetic_whitespace     0.0020      0.024      0.085      0.932      -0.045       0.049
capabilities_entropy                  1.1006      0.255      4.314      0.000       0.601       1.601
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  263
Model:                          Logit   Df Residuals:                      255
Method:                           MLE   Df Model:                            7
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.06291
Time:                        17:34:57   Log-Likelihood:                -165.79
converged:                       True   LL-Null:                       -176.92
Covariance Type:            nonrobust   LLR p-value:                  0.002291
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -2.2555      2.199     -1.026      0.305      -6.566       2.055
C(domain_grouped)[T.chemistry]       -0.1071      0.522     -0.205      0.837      -1.131       0.916
C(domain_grouped)[T.physics]         -0.2726      0.545     -0.500      0.617      -1.340       0.795
human_difficulty                     -0.2970      0.249     -1.193      0.233      -0.785       0.191
q_length                              0.2600      0.225      1.156      0.248      -0.181       0.701
avg_word_length                       0.0570      0.253      0.225      0.822      -0.438       0.552
percent_non_alphabetic_whitespace     0.0043      0.024      0.179      0.858      -0.043       0.052
game_entropy                          1.0247      0.257      3.984      0.000       0.521       1.529
=====================================================================================================

                  Model 4.95: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  263
Model:                          Logit   Df Residuals:                      254
Method:                           MLE   Df Model:                            8
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.08255
Time:                        17:34:57   Log-Likelihood:                -162.32
converged:                       True   LL-Null:                       -176.92
Covariance Type:            nonrobust   LLR p-value:                 0.0002913
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -2.3330      2.215     -1.053      0.292      -6.674       2.008
C(domain_grouped)[T.chemistry]       -0.2888      0.537     -0.538      0.591      -1.342       0.764
C(domain_grouped)[T.physics]         -0.4681      0.561     -0.834      0.404      -1.568       0.632
human_difficulty                     -0.2974      0.256     -1.164      0.244      -0.798       0.203
q_length                              0.2362      0.228      1.035      0.301      -0.211       0.684
avg_word_length                       0.0479      0.256      0.187      0.851      -0.453       0.549
percent_non_alphabetic_whitespace     0.0043      0.024      0.179      0.858      -0.043       0.052
capabilities_entropy                  0.7906      0.304      2.598      0.009       0.194       1.387
game_entropy                          0.5652      0.310      1.822      0.068      -0.043       1.173
=====================================================================================================

--- Analyzing grok-3-latest (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/grok-3-latest_GPQA_redacted_cor_temp0.0_1751718817_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    176
1     27
Name: count, dtype: int64

Answer change%: 0.1330 [0.08629144308167455, 0.17971840913507423] (n=203)
P-value vs 25%: 9.165e-07; P-value vs 0%: 2.398e-08
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=27)
P-value vs 25%: 0; P-value vs 33%: 0

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  203
Model:                          Logit   Df Residuals:                      201
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.01292
Time:                        17:34:57   Log-Likelihood:                -78.560
converged:                       True   LL-Null:                       -79.588
Covariance Type:            nonrobust   LLR p-value:                    0.1516
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept         -0.9051      0.653     -1.386      0.166      -2.185       0.375
p_i_capability    -1.0939      0.717     -1.526      0.127      -2.499       0.311
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  197
Model:                          Logit   Df Residuals:                      195
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1313
Time:                        17:34:57   Log-Likelihood:                -66.767
converged:                       True   LL-Null:                       -76.856
Covariance Type:            nonrobust   LLR p-value:                 7.057e-06
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.5266      0.293     -8.620      0.000      -3.101      -1.952
capabilities_entropy     2.6194      0.578      4.531      0.000       1.486       3.753
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.8462 [0.7075, 0.9848] (n=26)
                  P-value vs 33.3%: 4.248e-13

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=2.86, p=0.00484
Wilcoxon delta_p: statistic=3648.00, p=1.21e-07
Mean Δp = 0.0304  [0.0096, 0.0513]
Idea 1 N = 166; 

  Idea 1.5: Calibration Metrics
  NLL: 0.0495, Signed ECE (overconf pos under neg): -0.0419, ECE: 0.0419 (n=192)
  Brier: 0.0114, Reliability (absolute calibration error; lower better): 0.0110, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=192)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.780
Model:                            OLS   Adj. R-squared:                  0.776
Method:                 Least Squares   F-statistic:                     221.9
Date:                Sat, 09 Aug 2025   Prob (F-statistic):           1.65e-61
Time:                        17:34:57   Log-Likelihood:                 115.13
No. Observations:                 192   AIC:                            -222.3
Df Residuals:                     188   BIC:                            -209.2
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.5241      0.124     -4.216      0.000      -0.769      -0.279
p1                    0.5713      0.128      4.476      0.000       0.320       0.823
answer_changed        0.4907      0.205      2.398      0.017       0.087       0.894
p1:answer_changed     0.3074      0.223      1.378      0.170      -0.133       0.747
==============================================================================
Omnibus:                      124.076   Durbin-Watson:                   2.289
Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1012.982
Skew:                           2.384   Prob(JB):                    1.08e-220
Kurtosis:                      13.192   Cond. No.                         46.7
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-0.46, p=0.645
Wilcoxon delta_H: statistic=6698.00, p=0.708
Mean ΔH = -0.0172  [-0.0900, 0.0556]
Paired t-test delta_H Changed: statistic=1.73, p=0.0952
Wilcoxon delta_H Changed: statistic=94.00, p=0.0382
Mean ΔH Changed = 0.1548  [-0.0202, 0.3297]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=-2.18, p=0.0307
Wilcoxon (p_top2_game vs p_top2_base): statistic=4378.00, p=2.34e-10
Mean Δp_top2 = -0.0042  [-0.0080, -0.0004] (n=192)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=0.18, p=0.859
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=9058.00, p=0.789
Mean ΔH_unchosen_baseline_set = 0.0061  [-0.0615, 0.0737] (n=192)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  192
Model:                          Logit   Df Residuals:                      189
Method:                           MLE   Df Model:                            2
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1330
Time:                        17:34:57   Log-Likelihood:                -66.010
converged:                       True   LL-Null:                       -76.139
Covariance Type:            nonrobust   LLR p-value:                 3.992e-05
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.7695      0.259     -6.834      0.000      -2.277      -1.262
p1_z            -1.5785      0.442     -3.572      0.000      -2.445      -0.712
I(p1_z ** 2)    -0.3139      0.140     -2.237      0.025      -0.589      -0.039
================================================================================
AUC = 0.855

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  203
Model:                          Logit   Df Residuals:                      201
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1439
Time:                        17:34:57   Log-Likelihood:                -68.133
converged:                       True   LL-Null:                       -79.588
Covariance Type:            nonrobust   LLR p-value:                 1.698e-06
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -2.7143      0.324     -8.388      0.000      -3.349      -2.080
game_entropy     2.2806      0.483      4.721      0.000       1.334       3.227
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=5887.00, p=1.41e-06
Paired t-test (game_entropy vs capabilities_entropy): statistic=3.39, p=0.000841
Mean capabilities_entropy-game_entropy = -0.0871  [-0.1374, -0.0368] (n=197)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  197
Model:                          Logit   Df Residuals:                      194
Method:                           MLE   Df Model:                            2
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1859
Time:                        17:34:57   Log-Likelihood:                -62.565
converged:                       True   LL-Null:                       -76.856
Covariance Type:            nonrobust   LLR p-value:                 6.218e-07
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.9546      0.363     -8.145      0.000      -3.666      -2.244
capabilities_entropy     1.9153      0.634      3.020      0.003       0.672       3.158
game_entropy             1.6376      0.549      2.984      0.003       0.562       2.713
========================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  203
Model:                          Logit   Df Residuals:                      201
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:               2.610e-07
Time:                        17:34:57   Log-Likelihood:                -79.588
converged:                       True   LL-Null:                       -79.588
Covariance Type:            nonrobust   LLR p-value:                    0.9949
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -1.8808      0.970     -1.940      0.052      -3.781       0.019
human_difficulty     0.0025      0.392      0.006      0.995      -0.767       0.772
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  203
Model:                          Logit   Df Residuals:                      196
Method:                           MLE   Df Model:                            6
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.04482
Time:                        17:34:57   Log-Likelihood:                -76.021
converged:                       True   LL-Null:                       -79.588
Covariance Type:            nonrobust   LLR p-value:                    0.3086
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -1.4091      3.302     -0.427      0.670      -7.880       5.062
C(domain_grouped)[T.chemistry]        1.3831      0.726      1.904      0.057      -0.041       2.807
C(domain_grouped)[T.physics]          1.0309      0.718      1.435      0.151      -0.377       2.439
human_difficulty                      0.2455      0.411      0.598      0.550      -0.559       1.050
q_length                             -0.4366      0.349     -1.249      0.212      -1.121       0.248
avg_word_length                       0.1122      0.373      0.301      0.764      -0.619       0.843
percent_non_alphabetic_whitespace     0.0009      0.037      0.024      0.981      -0.072       0.073
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 0.1592
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  197
Model:                          Logit   Df Residuals:                      189
Method:                           MLE   Df Model:                            7
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1652
Time:                        17:34:57   Log-Likelihood:                -64.163
converged:                       True   LL-Null:                       -76.856
Covariance Type:            nonrobust   LLR p-value:                 0.0006481
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -3.8867      3.591     -1.082      0.279     -10.926       3.152
C(domain_grouped)[T.chemistry]        1.1964      0.779      1.536      0.125      -0.331       2.723
C(domain_grouped)[T.physics]          0.7942      0.803      0.989      0.323      -0.780       2.368
human_difficulty                      0.1017      0.456      0.223      0.823      -0.791       0.995
q_length                             -0.3409      0.373     -0.913      0.361      -1.073       0.391
avg_word_length                       0.4570      0.392      1.164      0.244      -0.312       1.226
percent_non_alphabetic_whitespace     0.0190      0.038      0.500      0.617      -0.055       0.093
capabilities_entropy                  2.6809      0.619      4.333      0.000       1.468       3.894
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  203
Model:                          Logit   Df Residuals:                      195
Method:                           MLE   Df Model:                            7
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1835
Time:                        17:34:57   Log-Likelihood:                -64.983
converged:                       True   LL-Null:                       -79.588
Covariance Type:            nonrobust   LLR p-value:                 0.0001324
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -4.8303      3.694     -1.308      0.191     -12.070       2.410
C(domain_grouped)[T.chemistry]        1.2992      0.769      1.688      0.091      -0.209       2.807
C(domain_grouped)[T.physics]          1.3918      0.791      1.760      0.078      -0.159       2.942
human_difficulty                      0.1868      0.442      0.422      0.673      -0.680       1.054
q_length                             -0.2744      0.375     -0.732      0.464      -1.009       0.460
avg_word_length                       0.4482      0.405      1.107      0.268      -0.346       1.242
percent_non_alphabetic_whitespace     0.0061      0.039      0.157      0.875      -0.070       0.082
game_entropy                          2.4121      0.534      4.519      0.000       1.366       3.458
=====================================================================================================

                  Model 4.95: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  197
Model:                          Logit   Df Residuals:                      188
Method:                           MLE   Df Model:                            8
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.2188
Time:                        17:34:57   Log-Likelihood:                -60.041
converged:                       True   LL-Null:                       -76.856
Covariance Type:            nonrobust   LLR p-value:                 4.738e-05
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -6.0550      3.884     -1.559      0.119     -13.668       1.558
C(domain_grouped)[T.chemistry]        1.1115      0.801      1.388      0.165      -0.458       2.681
C(domain_grouped)[T.physics]          1.0367      0.844      1.228      0.219      -0.618       2.691
human_difficulty                      0.0533      0.470      0.113      0.910      -0.868       0.974
q_length                             -0.1986      0.385     -0.516      0.606      -0.953       0.556
avg_word_length                       0.6497      0.422      1.539      0.124      -0.178       1.477
percent_non_alphabetic_whitespace     0.0224      0.040      0.561      0.574      -0.056       0.101
capabilities_entropy                  1.9893      0.681      2.919      0.004       0.654       3.325
game_entropy                          1.7255      0.596      2.895      0.004       0.557       2.894
=====================================================================================================

--- Analyzing grok-3-latest (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/grok-3-latest_GPQA_redacted_temp0.0_1751719817_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    152
1     92
Name: count, dtype: int64

Answer change%: 0.3770 [0.3162386124390582, 0.43785974821667945] (n=244)
P-value vs 25%: 4.224e-05; P-value vs 0%: 5.561e-34
Phase 2 self-accuracy: 0.4130 [0.31243026290616926, 0.5136566936155699] (n=92)
P-value vs 25%: 0.001493; P-value vs 33%: 0.1189

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  244
Model:                          Logit   Df Residuals:                      242
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                0.004668
Time:                        17:34:57   Log-Likelihood:                -160.92
converged:                       True   LL-Null:                       -161.67
Covariance Type:            nonrobust   LLR p-value:                    0.2192
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          0.0796      0.489      0.163      0.871      -0.880       1.039
p_i_capability    -0.6865      0.558     -1.231      0.218      -1.779       0.406
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  236
Model:                          Logit   Df Residuals:                      234
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.04144
Time:                        17:34:57   Log-Likelihood:                -149.90
converged:                       True   LL-Null:                       -156.38
Covariance Type:            nonrobust   LLR p-value:                 0.0003180
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -0.9763      0.195     -5.000      0.000      -1.359      -0.594
capabilities_entropy     1.1107      0.315      3.530      0.000       0.494       1.727
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.6705 [0.5722, 0.7687] (n=88)
                  P-value vs 33.3%: 1.72e-11

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=2.32, p=0.0218
Wilcoxon delta_p: statistic=3667.00, p=0.00835
Mean Δp = 0.0355  [0.0055, 0.0656]
Idea 1 N = 140; 

  Idea 1.5: Calibration Metrics
  NLL: 6.9395, Signed ECE (overconf pos under neg): 0.0391, ECE: 0.0391 (n=228)
  Brier: 0.0077, Reliability (absolute calibration error; lower better): 0.0072, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=228)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.842
Model:                            OLS   Adj. R-squared:                  0.840
Method:                 Least Squares   F-statistic:                     398.8
Date:                Sat, 09 Aug 2025   Prob (F-statistic):           1.59e-89
Time:                        17:34:57   Log-Likelihood:                 102.59
No. Observations:                 228   AIC:                            -197.2
Df Residuals:                     224   BIC:                            -183.5
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.4915      0.091     -5.423      0.000      -0.670      -0.313
p1                    0.5765      0.098      5.877      0.000       0.383       0.770
answer_changed        0.3728      0.129      2.886      0.004       0.118       0.627
p1:answer_changed     0.4151      0.144      2.876      0.004       0.131       0.699
==============================================================================
Omnibus:                       61.929   Durbin-Watson:                   1.909
Prob(Omnibus):                  0.000   Jarque-Bera (JB):              174.381
Skew:                           1.169   Prob(JB):                     1.36e-38
Kurtosis:                       6.591   Cond. No.                         30.8
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=0.92, p=0.361
Wilcoxon delta_H: statistic=4447.00, p=0.31
Mean ΔH = 0.0384  [-0.0437, 0.1205]
Paired t-test delta_H Changed: statistic=3.81, p=0.000261
Wilcoxon delta_H Changed: statistic=1189.00, p=0.00138
Mean ΔH Changed = 0.1657  [0.0804, 0.2510]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=-0.78, p=0.435
Wilcoxon (p_top2_game vs p_top2_base): statistic=10793.00, p=0.0234
Mean Δp_top2 = -0.0033  [-0.0115, 0.0049] (n=228)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=2.83, p=0.00507
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=10313.00, p=0.006
Mean ΔH_unchosen_baseline_set = 0.0875  [0.0269, 0.1482] (n=228)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  228
Model:                          Logit   Df Residuals:                      225
Method:                           MLE   Df Model:                            2
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.03840
Time:                        17:34:57   Log-Likelihood:                -146.22
converged:                       True   LL-Null:                       -152.06
Covariance Type:            nonrobust   LLR p-value:                  0.002914
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.2462      0.191     -1.290      0.197      -0.620       0.128
p1_z            -0.7452      0.243     -3.071      0.002      -1.221      -0.270
I(p1_z ** 2)    -0.2382      0.136     -1.752      0.080      -0.505       0.028
================================================================================
AUC = 0.682

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  244
Model:                          Logit   Df Residuals:                      242
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.06762
Time:                        17:34:57   Log-Likelihood:                -150.74
converged:                       True   LL-Null:                       -161.67
Covariance Type:            nonrobust   LLR p-value:                 2.926e-06
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.2537      0.221     -5.660      0.000      -1.688      -0.820
game_entropy     1.3743      0.305      4.502      0.000       0.776       1.972
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=10374.00, p=0.000587
Paired t-test (game_entropy vs capabilities_entropy): statistic=3.36, p=0.000895
Mean capabilities_entropy-game_entropy = -0.1095  [-0.1732, -0.0457] (n=236)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  236
Model:                          Logit   Df Residuals:                      233
Method:                           MLE   Df Model:                            2
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.07774
Time:                        17:34:57   Log-Likelihood:                -144.23
converged:                       True   LL-Null:                       -156.38
Covariance Type:            nonrobust   LLR p-value:                 5.252e-06
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.4017      0.243     -5.759      0.000      -1.879      -0.925
capabilities_entropy     0.7207      0.339      2.127      0.033       0.057       1.385
game_entropy             1.0842      0.327      3.316      0.001       0.443       1.725
========================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  244
Model:                          Logit   Df Residuals:                      242
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                0.003023
Time:                        17:34:57   Log-Likelihood:                -161.19
converged:                       True   LL-Null:                       -161.67
Covariance Type:            nonrobust   LLR p-value:                    0.3228
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept            0.0030      0.528      0.006      0.996      -1.033       1.039
human_difficulty    -0.2172      0.221     -0.983      0.326      -0.650       0.216
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  244
Model:                          Logit   Df Residuals:                      237
Method:                           MLE   Df Model:                            6
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                0.009695
Time:                        17:34:57   Log-Likelihood:                -160.11
converged:                       True   LL-Null:                       -161.67
Covariance Type:            nonrobust   LLR p-value:                    0.7917
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -0.1246      1.894     -0.066      0.948      -3.836       3.587
C(domain_grouped)[T.chemistry]       -0.3424      0.492     -0.696      0.486      -1.306       0.622
C(domain_grouped)[T.physics]         -0.2761      0.524     -0.527      0.598      -1.302       0.750
human_difficulty                     -0.2927      0.229     -1.278      0.201      -0.741       0.156
q_length                              0.0399      0.216      0.185      0.853      -0.383       0.463
avg_word_length                       0.0966      0.203      0.476      0.634      -0.301       0.494
percent_non_alphabetic_whitespace    -0.0111      0.025     -0.443      0.658      -0.060       0.038
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 0.4085
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  236
Model:                          Logit   Df Residuals:                      228
Method:                           MLE   Df Model:                            7
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.05943
Time:                        17:34:57   Log-Likelihood:                -147.09
converged:                       True   LL-Null:                       -156.38
Covariance Type:            nonrobust   LLR p-value:                  0.009585
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -0.6814      1.994     -0.342      0.733      -4.590       3.227
C(domain_grouped)[T.chemistry]       -0.8037      0.533     -1.508      0.132      -1.848       0.241
C(domain_grouped)[T.physics]         -0.8598      0.573     -1.500      0.134      -1.983       0.264
human_difficulty                     -0.3086      0.240     -1.284      0.199      -0.780       0.163
q_length                              0.1188      0.228      0.522      0.602      -0.327       0.565
avg_word_length                       0.1017      0.213      0.477      0.634      -0.316       0.520
percent_non_alphabetic_whitespace    -0.0051      0.026     -0.198      0.843      -0.056       0.046
capabilities_entropy                  1.2261      0.327      3.746      0.000       0.585       1.868
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  244
Model:                          Logit   Df Residuals:                      236
Method:                           MLE   Df Model:                            7
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.08222
Time:                        17:34:57   Log-Likelihood:                -148.38
converged:                       True   LL-Null:                       -161.67
Covariance Type:            nonrobust   LLR p-value:                 0.0003954
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -1.8079      2.022     -0.894      0.371      -5.771       2.156
C(domain_grouped)[T.chemistry]       -0.4108      0.522     -0.788      0.431      -1.433       0.612
C(domain_grouped)[T.physics]         -0.2334      0.559     -0.418      0.676      -1.328       0.861
human_difficulty                     -0.3425      0.243     -1.408      0.159      -0.819       0.134
q_length                              0.0508      0.229      0.222      0.825      -0.398       0.500
avg_word_length                       0.2698      0.218      1.236      0.217      -0.158       0.698
percent_non_alphabetic_whitespace     0.0066      0.026      0.252      0.801      -0.045       0.058
game_entropy                          1.4603      0.314      4.646      0.000       0.844       2.076
=====================================================================================================

                  Model 4.95: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  236
Model:                          Logit   Df Residuals:                      227
Method:                           MLE   Df Model:                            8
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.09730
Time:                        17:34:57   Log-Likelihood:                -141.17
converged:                       True   LL-Null:                       -156.38
Covariance Type:            nonrobust   LLR p-value:                 0.0001772
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -1.5771      2.056     -0.767      0.443      -5.607       2.453
C(domain_grouped)[T.chemistry]       -0.7979      0.553     -1.442      0.149      -1.883       0.287
C(domain_grouped)[T.physics]         -0.7115      0.597     -1.191      0.234      -1.882       0.459
human_difficulty                     -0.3562      0.248     -1.435      0.151      -0.843       0.130
q_length                              0.0955      0.235      0.407      0.684      -0.364       0.555
avg_word_length                       0.2152      0.222      0.970      0.332      -0.220       0.650
percent_non_alphabetic_whitespace     0.0069      0.027      0.258      0.797      -0.045       0.059
capabilities_entropy                  0.8262      0.353      2.337      0.019       0.133       1.519
game_entropy                          1.1423      0.338      3.383      0.001       0.481       1.804
=====================================================================================================
