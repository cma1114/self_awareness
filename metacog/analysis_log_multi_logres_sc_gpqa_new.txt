
--- Analyzing claude-3-5-sonnet-20241022 (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/claude-3-5-sonnet-20241022_GPQA_redacted_cor_temp0.0_1753836130_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    164
1     31
Name: count, dtype: int64

Answer change%: 0.1590 [0.1076529058083461, 0.21029581214037182] (n=195)
P-value vs 25%: 0.0005084; P-value vs 0%: 1.269e-09
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=31)
P-value vs 25%: 0; P-value vs 33%: 0

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  195
Model:                          Logit   Df Residuals:                      193
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.2378
Time:                        16:13:36   Log-Likelihood:                -65.093
converged:                       True   LL-Null:                       -85.403
Covariance Type:            nonrobust   LLR p-value:                 1.849e-10
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          2.8308      0.746      3.794      0.000       1.368       4.293
p_i_capability    -6.1355      1.065     -5.759      0.000      -8.224      -4.048
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  195
Model:                          Logit   Df Residuals:                      193
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.2121
Time:                        16:13:36   Log-Likelihood:                -67.286
converged:                       True   LL-Null:                       -85.403
Covariance Type:            nonrobust   LLR p-value:                 1.750e-09
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -3.7487      0.504     -7.431      0.000      -4.737      -2.760
capabilities_entropy     2.1920      0.401      5.466      0.000       1.406       2.978
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.6129 [0.4414, 0.7844] (n=31)
                  P-value vs 33.3%: 0.001395

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=-2.55, p=0.0117
Wilcoxon delta_p: statistic=1341.00, p=0.00189
Mean Δp = -0.0236  [-0.0418, -0.0055]
Idea 1 N = 164; 

  Idea 1.5: Calibration Metrics
  NLL: 0.2495, Signed ECE (overconf pos under neg): -0.1901, ECE: 0.1901 (n=195)
  Brier: 0.0745, Reliability (absolute calibration error; lower better): 0.0740, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=195)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.701
Model:                            OLS   Adj. R-squared:                  0.696
Method:                 Least Squares   F-statistic:                     149.3
Date:                Wed, 24 Sep 2025   Prob (F-statistic):           7.81e-50
Time:                        16:13:36   Log-Likelihood:                 159.23
No. Observations:                 195   AIC:                            -310.5
Df Residuals:                     191   BIC:                            -297.4
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.3328      0.043     -7.787      0.000      -0.417      -0.249
p1                    0.3633      0.049      7.379      0.000       0.266       0.460
answer_changed        0.0872      0.082      1.060      0.290      -0.075       0.249
p1:answer_changed     0.6475      0.124      5.206      0.000       0.402       0.893
==============================================================================
Omnibus:                       37.097   Durbin-Watson:                   1.781
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               86.570
Skew:                           0.845   Prob(JB):                     1.59e-19
Kurtosis:                       5.792   Cond. No.                         25.4
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=0.50, p=0.619
Wilcoxon delta_H: statistic=2041.50, p=0.581
Mean ΔH = 0.0165  [-0.0485, 0.0816]
Paired t-test delta_H Changed: statistic=3.89, p=0.00051
Wilcoxon delta_H Changed: statistic=72.00, p=0.000287
Mean ΔH Changed = 0.2861  [0.1421, 0.4302]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=3.25, p=0.00134
Wilcoxon (p_top2_game vs p_top2_base): statistic=2524.50, p=0.000758
Mean Δp_top2 = 0.0161  [0.0064, 0.0257] (n=195)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=1.92, p=0.0569
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=3068.50, p=0.0443
Mean ΔH_unchosen_baseline_set = 0.0594  [-0.0014, 0.1202] (n=195)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  195
Model:                          Logit   Df Residuals:                      192
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.2953
Time:                        16:13:36   Log-Likelihood:                -60.185
converged:                       True   LL-Null:                       -85.403
Covariance Type:            nonrobust   LLR p-value:                 1.117e-11
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.8414      0.325     -5.672      0.000      -2.478      -1.205
p1_z            -2.3830      0.505     -4.715      0.000      -3.374      -1.392
I(p1_z ** 2)    -0.7422      0.251     -2.962      0.003      -1.233      -0.251
================================================================================
AUC = 0.859

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  195
Model:                          Logit   Df Residuals:                      193
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.2151
Time:                        16:13:36   Log-Likelihood:                -67.032
converged:                       True   LL-Null:                       -85.403
Covariance Type:            nonrobust   LLR p-value:                 1.348e-09
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -3.6188      0.472     -7.669      0.000      -4.544      -2.694
game_entropy     2.3124      0.414      5.590      0.000       1.502       3.123
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=2492.50, p=0.000566
Paired t-test (game_entropy vs capabilities_entropy): statistic=-3.41, p=0.000786
Mean game_entropy-capabilities_entropy = -0.0833  [-0.1312, -0.0355] (n=195)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  195
Model:                          Logit   Df Residuals:                      192
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.2398
Time:                        16:13:37   Log-Likelihood:                -64.920
converged:                       True   LL-Null:                       -85.403
Covariance Type:            nonrobust   LLR p-value:                 1.271e-09
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -3.9451      0.522     -7.564      0.000      -4.967      -2.923
capabilities_entropy     1.2341      0.599      2.062      0.039       0.061       2.407
game_entropy             1.3145      0.618      2.128      0.033       0.104       2.525
========================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  195
Model:                          Logit   Df Residuals:                      193
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.02511
Time:                        16:13:37   Log-Likelihood:                -83.259
converged:                       True   LL-Null:                       -85.403
Covariance Type:            nonrobust   LLR p-value:                   0.03835
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept            0.0706      0.852      0.083      0.934      -1.600       1.741
human_difficulty    -0.7689      0.379     -2.028      0.043      -1.512      -0.026
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  195
Model:                          Logit   Df Residuals:                      188
Method:                           MLE   Df Model:                            6
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.06694
Time:                        16:13:37   Log-Likelihood:                -79.686
converged:                       True   LL-Null:                       -85.403
Covariance Type:            nonrobust   LLR p-value:                   0.07586
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                             1.2276      3.242      0.379      0.705      -5.127       7.582
C(domain_grouped)[T.chemistry]        0.9306      0.736      1.264      0.206      -0.513       2.374
C(domain_grouped)[T.physics]          0.8810      0.705      1.250      0.211      -0.501       2.263
human_difficulty                     -0.5722      0.390     -1.467      0.142      -1.336       0.192
q_length                              0.0952      0.367      0.259      0.796      -0.625       0.815
avg_word_length                      -0.6103      0.407     -1.501      0.133      -1.407       0.187
percent_non_alphabetic_whitespace    -0.0163      0.038     -0.423      0.672      -0.092       0.059
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 0.7453
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  195
Model:                          Logit   Df Residuals:                      187
Method:                           MLE   Df Model:                            7
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.2533
Time:                        16:13:37   Log-Likelihood:                -63.773
converged:                       True   LL-Null:                       -85.403
Covariance Type:            nonrobust   LLR p-value:                 2.970e-07
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -0.7111      3.615     -0.197      0.844      -7.797       6.375
C(domain_grouped)[T.chemistry]        0.2493      0.803      0.311      0.756      -1.325       1.823
C(domain_grouped)[T.physics]          0.5808      0.757      0.767      0.443      -0.904       2.065
human_difficulty                     -0.7227      0.466     -1.550      0.121      -1.637       0.191
q_length                             -0.2111      0.409     -0.517      0.605      -1.012       0.590
avg_word_length                      -0.1743      0.411     -0.424      0.672      -0.980       0.632
percent_non_alphabetic_whitespace     0.0207      0.043      0.487      0.627      -0.063       0.104
capabilities_entropy                  2.2519      0.446      5.052      0.000       1.378       3.125
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  195
Model:                          Logit   Df Residuals:                      187
Method:                           MLE   Df Model:                            7
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.2509
Time:                        16:13:37   Log-Likelihood:                -63.974
converged:                       True   LL-Null:                       -85.403
Covariance Type:            nonrobust   LLR p-value:                 3.553e-07
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -1.2384      3.485     -0.355      0.722      -8.069       5.592
C(domain_grouped)[T.chemistry]       -0.1548      0.801     -0.193      0.847      -1.725       1.415
C(domain_grouped)[T.physics]          0.1836      0.792      0.232      0.817      -1.368       1.735
human_difficulty                     -0.9125      0.483     -1.889      0.059      -1.859       0.034
q_length                             -0.0206      0.398     -0.052      0.959      -0.801       0.760
avg_word_length                      -0.0874      0.415     -0.211      0.833      -0.901       0.726
percent_non_alphabetic_whitespace     0.0122      0.044      0.279      0.780      -0.073       0.098
game_entropy                          2.3875      0.472      5.055      0.000       1.462       3.313
=====================================================================================================

                  Model 4.95: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  195
Model:                          Logit   Df Residuals:                      186
Method:                           MLE   Df Model:                            8
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.2767
Time:                        16:13:37   Log-Likelihood:                -61.772
converged:                       True   LL-Null:                       -85.403
Covariance Type:            nonrobust   LLR p-value:                 1.366e-07
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -1.1545      3.597     -0.321      0.748      -8.205       5.896
C(domain_grouped)[T.chemistry]       -0.2128      0.822     -0.259      0.796      -1.824       1.399
C(domain_grouped)[T.physics]          0.2103      0.782      0.269      0.788      -1.322       1.742
human_difficulty                     -0.8659      0.491     -1.763      0.078      -1.828       0.097
q_length                             -0.1791      0.411     -0.435      0.663      -0.985       0.627
avg_word_length                      -0.0288      0.422     -0.068      0.946      -0.856       0.798
percent_non_alphabetic_whitespace     0.0222      0.044      0.505      0.614      -0.064       0.108
capabilities_entropy                  1.3430      0.639      2.103      0.035       0.091       2.595
game_entropy                          1.3299      0.676      1.966      0.049       0.004       2.656
=====================================================================================================

--- Analyzing claude-3-5-sonnet-20241022 (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/claude-3-5-sonnet-20241022_GPQA_redacted_temp0.0_1753884209_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    160
1     92
Name: count, dtype: int64

Answer change%: 0.3651 [0.3056363013863806, 0.4245224287723495] (n=252)
P-value vs 25%: 0.000148; P-value vs 0%: 2.259e-33
Phase 2 self-accuracy: 0.3478 [0.25050275604046973, 0.4451494178725737] (n=92)
P-value vs 25%: 0.04883; P-value vs 33%: 0.7653

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  252
Model:                          Logit   Df Residuals:                      250
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1444
Time:                        16:13:37   Log-Likelihood:                -141.50
converged:                       True   LL-Null:                       -165.38
Covariance Type:            nonrobust   LLR p-value:                 4.793e-12
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          2.5015      0.492      5.085      0.000       1.537       3.466
p_i_capability    -4.8166      0.774     -6.224      0.000      -6.333      -3.300
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  252
Model:                          Logit   Df Residuals:                      250
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1593
Time:                        16:13:37   Log-Likelihood:                -139.03
converged:                       True   LL-Null:                       -165.38
Covariance Type:            nonrobust   LLR p-value:                 3.873e-13
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -3.0810      0.451     -6.831      0.000      -3.965      -2.197
capabilities_entropy     2.0218      0.320      6.323      0.000       1.395       2.648
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.6413 [0.5433, 0.7393] (n=92)
                  P-value vs 33.3%: 7.322e-10

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=-2.85, p=0.00489
Wilcoxon delta_p: statistic=3444.50, p=0.00282
Mean Δp = -0.0417  [-0.0703, -0.0131]
Idea 1 N = 160; 

  Idea 1.5: Calibration Metrics
  NLL: 2.6878, Signed ECE (overconf pos under neg): 0.1284, ECE: 0.1284 (n=252)
  Brier: 0.0300, Reliability (absolute calibration error; lower better): 0.0292, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=252)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.696
Model:                            OLS   Adj. R-squared:                  0.692
Method:                 Least Squares   F-statistic:                     188.9
Date:                Wed, 24 Sep 2025   Prob (F-statistic):           9.19e-64
Time:                        16:13:37   Log-Likelihood:                 124.08
No. Observations:                 252   AIC:                            -240.2
Df Residuals:                     248   BIC:                            -226.0
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.3928      0.044     -8.942      0.000      -0.479      -0.306
p1                    0.4817      0.058      8.298      0.000       0.367       0.596
answer_changed        0.1490      0.070      2.132      0.034       0.011       0.287
p1:answer_changed     0.5788      0.112      5.184      0.000       0.359       0.799
==============================================================================
Omnibus:                        6.265   Durbin-Watson:                   2.149
Prob(Omnibus):                  0.044   Jarque-Bera (JB):                6.235
Skew:                           0.351   Prob(JB):                       0.0443
Kurtosis:                       2.681   Cond. No.                         18.8
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-0.07, p=0.941
Wilcoxon delta_H: statistic=4831.00, p=0.829
Mean ΔH = -0.0026  [-0.0718, 0.0665]
Paired t-test delta_H Changed: statistic=8.67, p=1.54e-13
Wilcoxon delta_H Changed: statistic=352.00, p=3.44e-12
Mean ΔH Changed = 0.3432  [0.2656, 0.4208]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=4.99, p=1.12e-06
Wilcoxon (p_top2_game vs p_top2_base): statistic=8744.00, p=3.15e-06
Mean Δp_top2 = 0.0287  [0.0174, 0.0399] (n=252)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=4.32, p=2.24e-05
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=9012.00, p=1.09e-05
Mean ΔH_unchosen_baseline_set = 0.1236  [0.0676, 0.1797] (n=252)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  252
Model:                          Logit   Df Residuals:                      249
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1535
Time:                        16:13:37   Log-Likelihood:                -139.99
converged:                       True   LL-Null:                       -165.38
Covariance Type:            nonrobust   LLR p-value:                 9.369e-12
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.4340      0.209     -2.078      0.038      -0.843      -0.025
p1_z            -1.0766      0.179     -6.024      0.000      -1.427      -0.726
I(p1_z ** 2)    -0.3229      0.189     -1.713      0.087      -0.693       0.047
================================================================================
AUC = 0.749

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  252
Model:                          Logit   Df Residuals:                      250
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1327
Time:                        16:13:37   Log-Likelihood:                -143.44
converged:                       True   LL-Null:                       -165.38
Covariance Type:            nonrobust   LLR p-value:                 3.485e-11
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -2.4973      0.368     -6.794      0.000      -3.218      -1.777
game_entropy     1.7767      0.293      6.059      0.000       1.202       2.351
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=8352.00, p=4.56e-07
Paired t-test (game_entropy vs capabilities_entropy): statistic=-5.13, p=5.72e-07
Mean game_entropy-capabilities_entropy = -0.1339  [-0.1850, -0.0828] (n=252)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  252
Model:                          Logit   Df Residuals:                      249
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1756
Time:                        16:13:37   Log-Likelihood:                -136.35
converged:                       True   LL-Null:                       -165.38
Covariance Type:            nonrobust   LLR p-value:                 2.455e-13
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -3.3114      0.469     -7.066      0.000      -4.230      -2.393
capabilities_entropy     1.4473      0.398      3.636      0.000       0.667       2.227
game_entropy             0.8639      0.376      2.299      0.022       0.127       1.601
========================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  252
Model:                          Logit   Df Residuals:                      250
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:               2.524e-05
Time:                        16:13:37   Log-Likelihood:                -165.38
converged:                       True   LL-Null:                       -165.38
Covariance Type:            nonrobust   LLR p-value:                    0.9272
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -0.6016      0.544     -1.106      0.269      -1.668       0.465
human_difficulty     0.0201      0.220      0.091      0.927      -0.411       0.451
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  252
Model:                          Logit   Df Residuals:                      245
Method:                           MLE   Df Model:                            6
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.01358
Time:                        16:13:37   Log-Likelihood:                -163.14
converged:                       True   LL-Null:                       -165.38
Covariance Type:            nonrobust   LLR p-value:                    0.6102
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                             0.5718      2.110      0.271      0.786      -3.563       4.707
C(domain_grouped)[T.chemistry]        0.4259      0.510      0.835      0.403      -0.573       1.425
C(domain_grouped)[T.physics]          0.5765      0.524      1.099      0.272      -0.451       1.605
human_difficulty                      0.1194      0.231      0.517      0.605      -0.334       0.572
q_length                             -0.1144      0.215     -0.532      0.595      -0.536       0.307
avg_word_length                      -0.2459      0.244     -1.008      0.314      -0.724       0.232
percent_non_alphabetic_whitespace    -0.0076      0.024     -0.314      0.753      -0.055       0.040
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 1.1634
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  252
Model:                          Logit   Df Residuals:                      244
Method:                           MLE   Df Model:                            7
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1698
Time:                        16:13:37   Log-Likelihood:                -137.31
converged:                       True   LL-Null:                       -165.38
Covariance Type:            nonrobust   LLR p-value:                 8.820e-10
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -3.0285      2.412     -1.256      0.209      -7.756       1.699
C(domain_grouped)[T.chemistry]       -0.3808      0.603     -0.632      0.527      -1.562       0.800
C(domain_grouped)[T.physics]          0.0785      0.622      0.126      0.900      -1.141       1.298
human_difficulty                      0.2101      0.259      0.811      0.418      -0.298       0.718
q_length                             -0.1308      0.249     -0.526      0.599      -0.618       0.357
avg_word_length                       0.0200      0.275      0.073      0.942      -0.519       0.559
percent_non_alphabetic_whitespace     0.0190      0.027      0.696      0.487      -0.035       0.073
capabilities_entropy                  2.1040      0.335      6.285      0.000       1.448       2.760
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  252
Model:                          Logit   Df Residuals:                      244
Method:                           MLE   Df Model:                            7
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1432
Time:                        16:13:37   Log-Likelihood:                -141.70
converged:                       True   LL-Null:                       -165.38
Covariance Type:            nonrobust   LLR p-value:                 4.723e-08
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -2.4706      2.362     -1.046      0.296      -7.099       2.158
C(domain_grouped)[T.chemistry]       -0.0451      0.561     -0.080      0.936      -1.145       1.055
C(domain_grouped)[T.physics]          0.3963      0.575      0.689      0.491      -0.731       1.524
human_difficulty                      0.2073      0.254      0.816      0.415      -0.291       0.705
q_length                             -0.1503      0.238     -0.632      0.528      -0.617       0.316
avg_word_length                       0.0022      0.260      0.008      0.993      -0.506       0.511
percent_non_alphabetic_whitespace     0.0170      0.026      0.653      0.514      -0.034       0.068
game_entropy                          1.8253      0.305      5.982      0.000       1.227       2.423
=====================================================================================================

                  Model 4.95: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  252
Model:                          Logit   Df Residuals:                      243
Method:                           MLE   Df Model:                            8
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1879
Time:                        16:13:37   Log-Likelihood:                -134.30
converged:                       True   LL-Null:                       -165.38
Covariance Type:            nonrobust   LLR p-value:                 1.753e-10
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -3.6236      2.449     -1.480      0.139      -8.423       1.176
C(domain_grouped)[T.chemistry]       -0.4194      0.598     -0.702      0.483      -1.591       0.752
C(domain_grouped)[T.physics]          0.1023      0.613      0.167      0.868      -1.100       1.304
human_difficulty                      0.2222      0.263      0.844      0.399      -0.294       0.738
q_length                             -0.1293      0.251     -0.515      0.606      -0.621       0.362
avg_word_length                       0.0719      0.274      0.262      0.793      -0.465       0.609
percent_non_alphabetic_whitespace     0.0250      0.027      0.915      0.360      -0.029       0.079
capabilities_entropy                  1.5135      0.407      3.717      0.000       0.716       2.312
game_entropy                          0.9234      0.380      2.432      0.015       0.179       1.668
=====================================================================================================

--- Analyzing claude-3-haiku-20240307 (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/claude-3-haiku-20240307_GPQA_redacted_cor_temp0.0_1751757100_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    99
1    37
Name: count, dtype: int64

Answer change%: 0.2721 [0.19726629981773552, 0.34685134724108796] (n=136)
P-value vs 25%: 0.5632; P-value vs 0%: 1.008e-12
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=37)
P-value vs 25%: 0; P-value vs 33%: 0

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  136
Model:                          Logit   Df Residuals:                      134
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                0.003839
Time:                        16:13:37   Log-Likelihood:                -79.295
converged:                       True   LL-Null:                       -79.600
Covariance Type:            nonrobust   LLR p-value:                    0.4344
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          0.0928      1.366      0.068      0.946      -2.584       2.769
p_i_capability    -1.1998      1.512     -0.793      0.427      -4.163       1.764
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  136
Model:                          Logit   Df Residuals:                      134
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                0.006125
Time:                        16:13:37   Log-Likelihood:                -79.113
converged:                       True   LL-Null:                       -79.600
Covariance Type:            nonrobust   LLR p-value:                    0.3234
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.3008      0.376     -3.461      0.001      -2.037      -0.564
capabilities_entropy     0.7000      0.698      1.003      0.316      -0.668       2.068
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.2162 [0.0836, 0.3489] (n=37)
                  P-value vs 33.3%: 0.08354

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  136
Model:                          Logit   Df Residuals:                      134
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:               0.0002636
Time:                        16:13:37   Log-Likelihood:                -79.579
converged:                       True   LL-Null:                       -79.600
Covariance Type:            nonrobust   LLR p-value:                    0.8377
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -1.1612      0.886     -1.310      0.190      -2.899       0.576
human_difficulty     0.0742      0.362      0.205      0.838      -0.635       0.784
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  136
Model:                          Logit   Df Residuals:                      129
Method:                           MLE   Df Model:                            6
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.06366
Time:                        16:13:37   Log-Likelihood:                -74.533
converged:                       True   LL-Null:                       -79.600
Covariance Type:            nonrobust   LLR p-value:                    0.1191
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -2.2950      2.747     -0.835      0.404      -7.680       3.090
C(domain_grouped)[T.chemistry]        1.7231      0.658      2.619      0.009       0.434       3.012
C(domain_grouped)[T.physics]          1.2626      0.671      1.881      0.060      -0.053       2.578
human_difficulty                      0.1589      0.374      0.424      0.671      -0.575       0.893
q_length                             -0.2847      0.358     -0.796      0.426      -0.986       0.416
avg_word_length                       0.3485      0.259      1.344      0.179      -0.160       0.857
percent_non_alphabetic_whitespace    -0.0338      0.036     -0.929      0.353      -0.105       0.037
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 0.4420
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  136
Model:                          Logit   Df Residuals:                      128
Method:                           MLE   Df Model:                            7
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.07822
Time:                        16:13:37   Log-Likelihood:                -73.374
converged:                       True   LL-Null:                       -79.600
Covariance Type:            nonrobust   LLR p-value:                   0.08663
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -2.9065      2.775     -1.047      0.295      -8.346       2.533
C(domain_grouped)[T.chemistry]        1.7898      0.666      2.689      0.007       0.485       3.094
C(domain_grouped)[T.physics]          1.3056      0.676      1.931      0.053      -0.020       2.631
human_difficulty                      0.2022      0.381      0.530      0.596      -0.545       0.949
q_length                             -0.3351      0.358     -0.935      0.350      -1.037       0.367
avg_word_length                       0.4067      0.265      1.536      0.125      -0.112       0.926
percent_non_alphabetic_whitespace    -0.0403      0.037     -1.079      0.281      -0.113       0.033
capabilities_entropy                  1.1749      0.763      1.539      0.124      -0.321       2.671
=====================================================================================================

--- Analyzing claude-3-haiku-20240307 (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/claude-3-haiku-20240307_GPQA_redacted_temp0.0_1754158953_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    238
1     57
Name: count, dtype: int64

Answer change%: 0.1932 [0.1481655486064766, 0.2382751293596251] (n=295)
P-value vs 25%: 0.01351; P-value vs 0%: 4.263e-17
Phase 2 self-accuracy: 0.2632 [0.14884214151558706, 0.3774736479580971] (n=57)
P-value vs 25%: 0.8215; P-value vs 33%: 0.2311

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  295
Model:                          Logit   Df Residuals:                      293
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1160
Time:                        16:13:37   Log-Likelihood:                -128.01
converged:                       True   LL-Null:                       -144.80
Covariance Type:            nonrobust   LLR p-value:                 6.805e-09
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          3.1762      0.805      3.944      0.000       1.598       4.755
p_i_capability    -5.3179      0.931     -5.711      0.000      -7.143      -3.493
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  295
Model:                          Logit   Df Residuals:                      293
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1405
Time:                        16:13:37   Log-Likelihood:                -124.46
converged:                       True   LL-Null:                       -144.80
Covariance Type:            nonrobust   LLR p-value:                 1.791e-10
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.9064      0.306     -9.507      0.000      -3.506      -2.307
capabilities_entropy     2.8476      0.465      6.129      0.000       1.937       3.758
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.4386 [0.3098, 0.5674] (n=57)
                  P-value vs 33.3%: 0.1093

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=-0.11, p=0.916
Wilcoxon delta_p: statistic=1719.00, p=0.409
Mean Δp = -0.0009  [-0.0172, 0.0154]
Idea 1 N = 238; 

  Idea 1.5: Calibration Metrics
  NLL: 4.2117, Signed ECE (overconf pos under neg): 0.0400, ECE: 0.0400 (n=295)
  Brier: 0.0110, Reliability (absolute calibration error; lower better): 0.0108, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=295)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.896
Model:                            OLS   Adj. R-squared:                  0.894
Method:                 Least Squares   F-statistic:                     831.8
Date:                Wed, 24 Sep 2025   Prob (F-statistic):          2.27e-142
Time:                        16:13:37   Log-Likelihood:                 262.11
No. Observations:                 295   AIC:                            -516.2
Df Residuals:                     291   BIC:                            -501.5
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.7563      0.054    -13.998      0.000      -0.863      -0.650
p1                    0.8219      0.058     14.084      0.000       0.707       0.937
answer_changed        0.7436      0.078      9.484      0.000       0.589       0.898
p1:answer_changed     0.0617      0.091      0.676      0.500      -0.118       0.241
==============================================================================
Omnibus:                       64.875   Durbin-Watson:                   1.936
Prob(Omnibus):                  0.000   Jarque-Bera (JB):              199.051
Skew:                           0.954   Prob(JB):                     5.98e-44
Kurtosis:                       6.543   Cond. No.                         31.3
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=2.25, p=0.0253
Wilcoxon delta_H: statistic=1417.50, p=0.0356
Mean ΔH = 0.0856  [0.0111, 0.1601]
Paired t-test delta_H Changed: statistic=6.66, p=1.28e-08
Wilcoxon delta_H Changed: statistic=179.00, p=2.65e-07
Mean ΔH Changed = 0.5699  [0.4021, 0.7378]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=1.28, p=0.202
Wilcoxon (p_top2_game vs p_top2_base): statistic=3725.00, p=0.0575
Mean Δp_top2 = 0.0025  [-0.0013, 0.0063] (n=295)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=4.90, p=1.55e-06
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=2810.50, p=1.54e-06
Mean ΔH_unchosen_baseline_set = 0.1792  [0.1076, 0.2508] (n=295)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  295
Model:                          Logit   Df Residuals:                      292
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1285
Time:                        16:13:37   Log-Likelihood:                -126.20
converged:                       True   LL-Null:                       -144.80
Covariance Type:            nonrobust   LLR p-value:                 8.328e-09
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.2894      0.222     -5.802      0.000      -1.725      -0.854
p1_z            -1.4134      0.374     -3.778      0.000      -2.147      -0.680
I(p1_z ** 2)    -0.3189      0.167     -1.913      0.056      -0.646       0.008
================================================================================
AUC = 0.741

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  295
Model:                          Logit   Df Residuals:                      293
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.09078
Time:                        16:13:37   Log-Likelihood:                -131.66
converged:                       True   LL-Null:                       -144.80
Covariance Type:            nonrobust   LLR p-value:                 2.939e-07
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -2.7137      0.313     -8.680      0.000      -3.326      -2.101
game_entropy     2.5620      0.503      5.089      0.000       1.575       3.549
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=4529.00, p=0.893
Paired t-test (game_entropy vs capabilities_entropy): statistic=-0.16, p=0.873
Mean game_entropy-capabilities_entropy = -0.0033  [-0.0436, 0.0370] (n=295)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  295
Model:                          Logit   Df Residuals:                      292
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.2039
Time:                        16:13:37   Log-Likelihood:                -115.28
converged:                       True   LL-Null:                       -144.80
Covariance Type:            nonrobust   LLR p-value:                 1.501e-13
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -4.0098      0.441     -9.086      0.000      -4.875      -3.145
capabilities_entropy     2.7036      0.487      5.554      0.000       1.749       3.658
game_entropy             2.3242      0.538      4.319      0.000       1.270       3.379
========================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  295
Model:                          Logit   Df Residuals:                      293
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.01269
Time:                        16:13:37   Log-Likelihood:                -142.97
converged:                       True   LL-Null:                       -144.80
Covariance Type:            nonrobust   LLR p-value:                   0.05527
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -0.2853      0.613     -0.465      0.642      -1.487       0.916
human_difficulty    -0.4923      0.262     -1.881      0.060      -1.005       0.021
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  295
Model:                          Logit   Df Residuals:                      288
Method:                           MLE   Df Model:                            6
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.03493
Time:                        16:13:37   Log-Likelihood:                -139.74
converged:                       True   LL-Null:                       -144.80
Covariance Type:            nonrobust   LLR p-value:                    0.1198
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -1.1408      2.321     -0.492      0.623      -5.689       3.407
C(domain_grouped)[T.chemistry]        0.6781      0.548      1.238      0.216      -0.396       1.752
C(domain_grouped)[T.physics]          0.2172      0.566      0.383      0.701      -0.893       1.327
human_difficulty                     -0.4673      0.278     -1.680      0.093      -1.013       0.078
q_length                              0.3512      0.249      1.409      0.159      -0.137       0.840
avg_word_length                      -0.3698      0.290     -1.275      0.202      -0.938       0.199
percent_non_alphabetic_whitespace    -0.0036      0.027     -0.134      0.894      -0.057       0.050
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 0.4562
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  295
Model:                          Logit   Df Residuals:                      287
Method:                           MLE   Df Model:                            7
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1598
Time:                        16:13:37   Log-Likelihood:                -121.67
converged:                       True   LL-Null:                       -144.80
Covariance Type:            nonrobust   LLR p-value:                 7.725e-08
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -2.7320      2.585     -1.057      0.291      -7.799       2.335
C(domain_grouped)[T.chemistry]        0.4916      0.580      0.847      0.397      -0.646       1.629
C(domain_grouped)[T.physics]          0.1451      0.605      0.240      0.811      -1.041       1.332
human_difficulty                     -0.4740      0.299     -1.583      0.114      -1.061       0.113
q_length                              0.3124      0.273      1.144      0.252      -0.223       0.847
avg_word_length                      -0.2402      0.317     -0.758      0.449      -0.861       0.381
percent_non_alphabetic_whitespace    -0.0091      0.030     -0.302      0.763      -0.069       0.050
capabilities_entropy                  2.7473      0.478      5.753      0.000       1.811       3.683
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  295
Model:                          Logit   Df Residuals:                      287
Method:                           MLE   Df Model:                            7
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1181
Time:                        16:13:37   Log-Likelihood:                -127.70
converged:                       True   LL-Null:                       -144.80
Covariance Type:            nonrobust   LLR p-value:                 1.571e-05
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -2.8860      2.463     -1.172      0.241      -7.713       1.941
C(domain_grouped)[T.chemistry]        0.6304      0.563      1.119      0.263      -0.474       1.735
C(domain_grouped)[T.physics]          0.1193      0.587      0.203      0.839      -1.031       1.269
human_difficulty                     -0.3807      0.298     -1.276      0.202      -0.965       0.204
q_length                              0.4127      0.261      1.581      0.114      -0.099       0.924
avg_word_length                      -0.3518      0.302     -1.166      0.244      -0.943       0.240
percent_non_alphabetic_whitespace    -0.0155      0.028     -0.555      0.579      -0.070       0.039
game_entropy                          2.5382      0.525      4.835      0.000       1.509       3.567
=====================================================================================================

                  Model 4.95: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  295
Model:                          Logit   Df Residuals:                      286
Method:                           MLE   Df Model:                            8
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.2209
Time:                        16:13:37   Log-Likelihood:                -112.82
converged:                       True   LL-Null:                       -144.80
Covariance Type:            nonrobust   LLR p-value:                 7.702e-11
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -4.3852      2.679     -1.637      0.102      -9.635       0.865
C(domain_grouped)[T.chemistry]        0.4202      0.599      0.701      0.483      -0.754       1.594
C(domain_grouped)[T.physics]          0.0378      0.629      0.060      0.952      -1.195       1.270
human_difficulty                     -0.4127      0.317     -1.302      0.193      -1.034       0.209
q_length                              0.3660      0.278      1.317      0.188      -0.179       0.911
avg_word_length                      -0.1907      0.323     -0.590      0.555      -0.824       0.442
percent_non_alphabetic_whitespace    -0.0181      0.029     -0.620      0.536      -0.075       0.039
capabilities_entropy                  2.6347      0.499      5.275      0.000       1.656       3.614
game_entropy                          2.3412      0.559      4.188      0.000       1.245       3.437
=====================================================================================================

--- Analyzing claude-3-sonnet-20240229 (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/claude-3-sonnet-20240229_GPQA_redacted_cor_temp0.0_1751757247_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    113
1     33
Name: count, dtype: int64

Answer change%: 0.2260 [0.1581828421354376, 0.2938719523851103] (n=146)
P-value vs 25%: 0.4886; P-value vs 0%: 6.59e-11
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=33)
P-value vs 25%: 0; P-value vs 33%: 0

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  146
Model:                          Logit   Df Residuals:                      144
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:               0.0002159
Time:                        16:13:37   Log-Likelihood:                -78.010
converged:                       True   LL-Null:                       -78.027
Covariance Type:            nonrobust   LLR p-value:                    0.8544
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -1.0829      0.829     -1.306      0.191      -2.708       0.542
human_difficulty    -0.0626      0.341     -0.183      0.855      -0.732       0.606
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  146
Model:                          Logit   Df Residuals:                      139
Method:                           MLE   Df Model:                            6
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.04736
Time:                        16:13:37   Log-Likelihood:                -74.332
converged:                       True   LL-Null:                       -78.027
Covariance Type:            nonrobust   LLR p-value:                    0.2863
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -0.5137      3.069     -0.167      0.867      -6.529       5.502
C(domain_grouped)[T.chemistry]        1.3167      0.618      2.129      0.033       0.104       2.529
C(domain_grouped)[T.physics]          0.7130      0.659      1.081      0.279      -0.579       2.005
human_difficulty                      0.0405      0.363      0.112      0.911      -0.670       0.751
q_length                             -0.3611      0.376     -0.961      0.336      -1.097       0.375
avg_word_length                       0.1496      0.360      0.416      0.678      -0.556       0.855
percent_non_alphabetic_whitespace    -0.0228      0.038     -0.595      0.552      -0.098       0.052
=====================================================================================================

--- Analyzing claude-3-sonnet-20240229 (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/claude-3-sonnet-20240229_GPQA_redacted_temp0.0_1751717405_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    217
1     84
Name: count, dtype: int64

Answer change%: 0.2791 [0.228397789428773, 0.32974174545494794] (n=301)
P-value vs 25%: 0.2608; P-value vs 0%: 3.664e-27
Phase 2 self-accuracy: 0.3333 [0.23252366379347328, 0.43414300287319335] (n=84)
P-value vs 25%: 0.1052; P-value vs 33%: 0.9948

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  301
Model:                          Logit   Df Residuals:                      299
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:               1.628e-05
Time:                        16:13:37   Log-Likelihood:                -178.21
converged:                       True   LL-Null:                       -178.21
Covariance Type:            nonrobust   LLR p-value:                    0.9393
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -0.9899      0.551     -1.796      0.072      -2.070       0.090
human_difficulty     0.0172      0.226      0.076      0.939      -0.425       0.460
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  301
Model:                          Logit   Df Residuals:                      294
Method:                           MLE   Df Model:                            6
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                0.009757
Time:                        16:13:37   Log-Likelihood:                -176.48
converged:                       True   LL-Null:                       -178.21
Covariance Type:            nonrobust   LLR p-value:                    0.7469
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -0.1034      1.945     -0.053      0.958      -3.916       3.709
C(domain_grouped)[T.chemistry]        0.1243      0.444      0.280      0.779      -0.745       0.994
C(domain_grouped)[T.physics]          0.0169      0.446      0.038      0.970      -0.858       0.892
human_difficulty                      0.0133      0.234      0.057      0.955      -0.446       0.473
q_length                              0.1372      0.206      0.667      0.505      -0.266       0.541
avg_word_length                      -0.3292      0.230     -1.429      0.153      -0.781       0.122
percent_non_alphabetic_whitespace    -0.0285      0.025     -1.127      0.260      -0.078       0.021
=====================================================================================================

--- Analyzing claude-sonnet-4-20250514 (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/claude-sonnet-4-20250514_GPQA_redacted_cor_temp0.0_1751759117_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    201
1     57
Name: count, dtype: int64

Answer change%: 0.2209 [0.1703065203425982, 0.2715539447736809] (n=258)
P-value vs 25%: 0.2604; P-value vs 0%: 1.193e-17
Phase 2 self-accuracy: 0.0702 [0.003861665647464513, 0.13648921154551794] (n=57)
P-value vs 25%: 1.067e-07; P-value vs 33%: 7.972e-15

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  258
Model:                          Logit   Df Residuals:                      256
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:               0.0006185
Time:                        16:13:37   Log-Likelihood:                -136.16
converged:                       True   LL-Null:                       -136.25
Covariance Type:            nonrobust   LLR p-value:                    0.6814
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -1.5089      0.626     -2.412      0.016      -2.735      -0.283
human_difficulty     0.1053      0.256      0.411      0.681      -0.397       0.607
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  258
Model:                          Logit   Df Residuals:                      251
Method:                           MLE   Df Model:                            6
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.04056
Time:                        16:13:37   Log-Likelihood:                -130.72
converged:                       True   LL-Null:                       -136.25
Covariance Type:            nonrobust   LLR p-value:                   0.08680
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -5.1356      2.232     -2.301      0.021      -9.510      -0.761
C(domain_grouped)[T.chemistry]        0.3862      0.471      0.820      0.412      -0.537       1.309
C(domain_grouped)[T.physics]          0.0263      0.472      0.056      0.956      -0.900       0.952
human_difficulty                      0.0137      0.276      0.050      0.960      -0.527       0.555
q_length                              0.8150      0.278      2.931      0.003       0.270       1.360
avg_word_length                      -0.2420      0.256     -0.944      0.345      -0.744       0.260
percent_non_alphabetic_whitespace    -0.0082      0.028     -0.293      0.770      -0.063       0.047
=====================================================================================================

--- Analyzing claude-sonnet-4-20250514 (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/claude-sonnet-4-20250514_GPQA_redacted_temp0.0_1751718415_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    101
1     88
Name: count, dtype: int64

Answer change%: 0.4656 [0.3944940889380143, 0.5367228422789169] (n=189)
P-value vs 25%: 2.81e-09; P-value vs 0%: 1.078e-37
Phase 2 self-accuracy: 0.4545 [0.35051159823461064, 0.5585793108562984] (n=88)
P-value vs 25%: 0.0001164; P-value vs 33%: 0.02203

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  189
Model:                          Logit   Df Residuals:                      187
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.01636
Time:                        16:13:37   Log-Likelihood:                -128.42
converged:                       True   LL-Null:                       -130.56
Covariance Type:            nonrobust   LLR p-value:                   0.03875
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept            1.1797      0.663      1.779      0.075      -0.120       2.480
human_difficulty    -0.5516      0.272     -2.030      0.042      -1.084      -0.019
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  189
Model:                          Logit   Df Residuals:                      182
Method:                           MLE   Df Model:                            6
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.02865
Time:                        16:13:37   Log-Likelihood:                -126.82
converged:                       True   LL-Null:                       -130.56
Covariance Type:            nonrobust   LLR p-value:                    0.2788
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                             3.8732      2.421      1.600      0.110      -0.872       8.619
C(domain_grouped)[T.chemistry]        0.0007      0.495      0.001      0.999      -0.970       0.972
C(domain_grouped)[T.physics]         -0.2515      0.520     -0.484      0.629      -1.271       0.768
human_difficulty                     -0.5435      0.282     -1.927      0.054      -1.096       0.009
q_length                             -0.2824      0.241     -1.173      0.241      -0.754       0.189
avg_word_length                      -0.1313      0.259     -0.507      0.612      -0.639       0.377
percent_non_alphabetic_whitespace    -0.0395      0.029     -1.353      0.176      -0.097       0.018
=====================================================================================================

--- Analyzing deepseek-chat (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/deepseek-chat_GPQA_redacted_cor_temp0.0_1753813587_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    184
1     23
Name: count, dtype: int64

Answer change%: 0.1111 [0.0682991223890767, 0.1539230998331455] (n=207)
P-value vs 25%: 2.038e-10; P-value vs 0%: 3.643e-07
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=23)
P-value vs 25%: 0; P-value vs 33%: 0

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  207
Model:                          Logit   Df Residuals:                      205
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.03282
Time:                        16:13:37   Log-Likelihood:                -69.839
converged:                       True   LL-Null:                       -72.208
Covariance Type:            nonrobust   LLR p-value:                   0.02948
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept         -0.1072      0.871     -0.123      0.902      -1.814       1.599
p_i_capability    -2.3972      1.066     -2.248      0.025      -4.487      -0.307
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  207
Model:                          Logit   Df Residuals:                      205
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.05213
Time:                        16:13:37   Log-Likelihood:                -68.444
converged:                       True   LL-Null:                       -72.208
Covariance Type:            nonrobust   LLR p-value:                  0.006072
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.7599      0.371     -7.439      0.000      -3.487      -2.033
capabilities_entropy     1.0446      0.378      2.760      0.006       0.303       1.786
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.2174 [0.0488, 0.3860] (n=23)
                  P-value vs 33.3%: 0.1776

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=18.80, p=2.47e-44
Wilcoxon delta_p: statistic=757.00, p=3.15e-26
Mean Δp = 0.6061  [0.5429, 0.6692]
Idea 1 N = 181; 

  Idea 1.5: Calibration Metrics
  NLL: 4.3205, Signed ECE (overconf pos under neg): -0.4360, ECE: 0.5249 (n=180)
  Brier: 0.5463, Reliability (absolute calibration error; lower better): 0.3652, Resolution (relative calibration quality; higher better): 0.0182, Uncertainty: 0.1981 (n=180)
  AUROC: 0.4183

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.147
Model:                            OLS   Adj. R-squared:                  0.134
Method:                 Least Squares   F-statistic:                     11.47
Date:                Wed, 24 Sep 2025   Prob (F-statistic):           5.67e-07
Time:                        16:13:37   Log-Likelihood:                -101.01
No. Observations:                 204   AIC:                             210.0
Df Residuals:                     200   BIC:                             223.3
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.2063      0.147     -1.399      0.163      -0.497       0.084
p1                    0.9410      0.167      5.625      0.000       0.611       1.271
answer_changed        0.3124      0.394      0.794      0.428      -0.464       1.088
p1:answer_changed    -0.4384      0.489     -0.897      0.371      -1.403       0.526
==============================================================================
Omnibus:                       39.719   Durbin-Watson:                   1.915
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               43.675
Skew:                          -1.073   Prob(JB):                     3.28e-10
Kurtosis:                       2.268   Cond. No.                         29.8
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=5.69, p=5.01e-08
Wilcoxon delta_H: statistic=4498.00, p=1.89e-07
Mean ΔH = 0.3226  [0.2115, 0.4337]
Paired t-test delta_H Changed: statistic=1.89, p=0.0727
Wilcoxon delta_H Changed: statistic=77.00, p=0.065
Mean ΔH Changed = 0.3001  [-0.0119, 0.6122]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=4.27, p=3.02e-05
Wilcoxon (p_top2_game vs p_top2_base): statistic=10327.00, p=0.879
Mean Δp_top2 = 0.0277  [0.0150, 0.0404] (n=204)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=6.01, p=8.51e-09
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=5713.00, p=3.08e-08
Mean ΔH_unchosen_baseline_set = 0.3201  [0.2157, 0.4245] (n=204)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  204
Model:                          Logit   Df Residuals:                      201
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.05808
Time:                        16:13:37   Log-Likelihood:                -67.679
converged:                       True   LL-Null:                       -71.852
Covariance Type:            nonrobust   LLR p-value:                   0.01541
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.7979      0.287     -6.262      0.000      -2.361      -1.235
p1_z            -1.0331      0.380     -2.719      0.007      -1.778      -0.288
I(p1_z ** 2)    -0.4270      0.231     -1.846      0.065      -0.880       0.026
================================================================================
AUC = 0.698

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  207
Model:                          Logit   Df Residuals:                      205
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.04618
Time:                        16:13:37   Log-Likelihood:                -68.874
converged:                       True   LL-Null:                       -72.208
Covariance Type:            nonrobust   LLR p-value:                  0.009813
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -3.0370      0.446     -6.811      0.000      -3.911      -2.163
game_entropy     2.1765      0.793      2.745      0.006       0.623       3.730
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=9199.00, p=0.0697
Paired t-test (game_entropy vs capabilities_entropy): statistic=-3.63, p=0.000353
Mean game_entropy-capabilities_entropy = -0.1293  [-0.1991, -0.0596] (n=207)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  207
Model:                          Logit   Df Residuals:                      204
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.07225
Time:                        16:13:37   Log-Likelihood:                -66.992
converged:                       True   LL-Null:                       -72.208
Covariance Type:            nonrobust   LLR p-value:                  0.005425
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -3.2670      0.479     -6.816      0.000      -4.206      -2.328
capabilities_entropy     0.8049      0.410      1.964      0.050       0.002       1.608
game_entropy             1.5166      0.864      1.756      0.079      -0.176       3.209
========================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  207
Model:                          Logit   Df Residuals:                      205
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                0.003904
Time:                        16:13:37   Log-Likelihood:                -71.926
converged:                       True   LL-Null:                       -72.208
Covariance Type:            nonrobust   LLR p-value:                    0.4528
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -1.4011      0.923     -1.517      0.129      -3.211       0.409
human_difficulty    -0.2893      0.388     -0.745      0.456      -1.051       0.472
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  207
Model:                          Logit   Df Residuals:                      200
Method:                           MLE   Df Model:                            6
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.06871
Time:                        16:13:37   Log-Likelihood:                -67.247
converged:                       True   LL-Null:                       -72.208
Covariance Type:            nonrobust   LLR p-value:                    0.1280
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -4.9333      3.648     -1.352      0.176     -12.084       2.217
C(domain_grouped)[T.chemistry]        1.7070      0.739      2.310      0.021       0.259       3.155
C(domain_grouped)[T.physics]          0.4430      0.776      0.571      0.568      -1.078       1.964
human_difficulty                     -0.1444      0.409     -0.353      0.724      -0.947       0.658
q_length                              0.5271      0.390      1.352      0.176      -0.237       1.291
avg_word_length                      -0.1134      0.434     -0.261      0.794      -0.965       0.738
percent_non_alphabetic_whitespace    -0.0371      0.046     -0.801      0.423      -0.128       0.054
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 0.5263
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  207
Model:                          Logit   Df Residuals:                      199
Method:                           MLE   Df Model:                            7
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1058
Time:                        16:13:37   Log-Likelihood:                -64.570
converged:                       True   LL-Null:                       -72.208
Covariance Type:            nonrobust   LLR p-value:                   0.03261
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -4.8318      3.737     -1.293      0.196     -12.156       2.492
C(domain_grouped)[T.chemistry]        1.4459      0.760      1.903      0.057      -0.044       2.935
C(domain_grouped)[T.physics]          0.3041      0.804      0.378      0.705      -1.271       1.879
human_difficulty                     -0.1663      0.421     -0.395      0.693      -0.991       0.659
q_length                              0.4358      0.382      1.142      0.254      -0.312       1.184
avg_word_length                      -0.0999      0.439     -0.228      0.820      -0.960       0.760
percent_non_alphabetic_whitespace    -0.0399      0.047     -0.857      0.391      -0.131       0.051
capabilities_entropy                  0.9478      0.407      2.331      0.020       0.151       1.745
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  207
Model:                          Logit   Df Residuals:                      199
Method:                           MLE   Df Model:                            7
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1047
Time:                        16:13:37   Log-Likelihood:                -64.646
converged:                       True   LL-Null:                       -72.208
Covariance Type:            nonrobust   LLR p-value:                   0.03443
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -5.5144      3.796     -1.453      0.146     -12.955       1.926
C(domain_grouped)[T.chemistry]        1.5191      0.753      2.018      0.044       0.044       2.994
C(domain_grouped)[T.physics]          0.2395      0.799      0.300      0.764      -1.327       1.806
human_difficulty                     -0.1708      0.416     -0.410      0.682      -0.987       0.645
q_length                              0.4805      0.394      1.218      0.223      -0.293       1.254
avg_word_length                      -0.0682      0.454     -0.150      0.881      -0.959       0.822
percent_non_alphabetic_whitespace    -0.0378      0.049     -0.777      0.437      -0.133       0.058
game_entropy                          1.9766      0.830      2.380      0.017       0.349       3.604
=====================================================================================================

                  Model 4.95: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  207
Model:                          Logit   Df Residuals:                      198
Method:                           MLE   Df Model:                            8
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1220
Time:                        16:13:37   Log-Likelihood:                -63.398
converged:                       True   LL-Null:                       -72.208
Covariance Type:            nonrobust   LLR p-value:                   0.02426
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -5.2531      3.823     -1.374      0.169     -12.746       2.240
C(domain_grouped)[T.chemistry]        1.3507      0.766      1.763      0.078      -0.151       2.853
C(domain_grouped)[T.physics]          0.1538      0.818      0.188      0.851      -1.449       1.756
human_difficulty                     -0.1718      0.424     -0.405      0.685      -1.003       0.659
q_length                              0.4157      0.389      1.070      0.285      -0.346       1.177
avg_word_length                      -0.0655      0.452     -0.145      0.885      -0.951       0.820
percent_non_alphabetic_whitespace    -0.0368      0.048     -0.765      0.444      -0.131       0.057
capabilities_entropy                  0.7048      0.441      1.598      0.110      -0.160       1.569
game_entropy                          1.4206      0.906      1.568      0.117      -0.355       3.196
=====================================================================================================

--- Analyzing deepseek-chat (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/deepseek-chat_GPQA_redacted_temp0.0_1753995526_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    188
1     47
Name: count, dtype: int64

Answer change%: 0.2000 [0.1488584188284336, 0.25114158117156643] (n=235)
P-value vs 25%: 0.05534; P-value vs 0%: 1.79e-14
Phase 2 self-accuracy: 0.5208 [0.37950795482256594, 0.6621587118441008] (n=48)
P-value vs 25%: 0.0001726; P-value vs 33%: 0.009189

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  235
Model:                          Logit   Df Residuals:                      233
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                0.009179
Time:                        16:13:37   Log-Likelihood:                -116.52
converged:                       True   LL-Null:                       -117.59
Covariance Type:            nonrobust   LLR p-value:                    0.1418
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept         -0.5075      0.609     -0.834      0.404      -1.701       0.686
p_i_capability    -1.1804      0.803     -1.470      0.141      -2.754       0.393
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  235
Model:                          Logit   Df Residuals:                      233
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.01420
Time:                        16:13:37   Log-Likelihood:                -115.92
converged:                       True   LL-Null:                       -117.59
Covariance Type:            nonrobust   LLR p-value:                   0.06759
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.8517      0.318     -5.824      0.000      -2.475      -1.229
capabilities_entropy     0.5265      0.291      1.808      0.071      -0.044       1.097
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.3404 [0.2050, 0.4759] (n=47)
                  P-value vs 33.3%: 0.9183

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=12.86, p=1.6e-27
Wilcoxon delta_p: statistic=1945.00, p=1.59e-20
Mean Δp = 0.4439  [0.3763, 0.5116]
Idea 1 N = 188; 

  Idea 1.5: Calibration Metrics
  NLL: 3.1653, Signed ECE (overconf pos under neg): 0.0637, ECE: 0.2757 (n=219)
  Brier: 0.2782, Reliability (absolute calibration error; lower better): 0.1358, Resolution (relative calibration quality; higher better): 0.0076, Uncertainty: 0.1493 (n=219)
  AUROC: 0.4169

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.212
Model:                            OLS   Adj. R-squared:                  0.202
Method:                 Least Squares   F-statistic:                     20.72
Date:                Wed, 24 Sep 2025   Prob (F-statistic):           6.30e-12
Time:                        16:13:37   Log-Likelihood:                -123.81
No. Observations:                 235   AIC:                             255.6
Df Residuals:                     231   BIC:                             269.5
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.2987      0.118     -2.537      0.012      -0.531      -0.067
p1                    0.9663      0.148      6.525      0.000       0.675       1.258
answer_changed       -0.2044      0.268     -0.763      0.446      -0.732       0.323
p1:answer_changed     0.4345      0.356      1.222      0.223      -0.266       1.135
==============================================================================
Omnibus:                      167.494   Durbin-Watson:                   2.103
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               39.148
Skew:                          -0.785   Prob(JB):                     3.16e-09
Kurtosis:                       1.761   Cond. No.                         21.5
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=5.78, p=3.09e-08
Wilcoxon delta_H: statistic=4722.00, p=4.08e-08
Mean ΔH = 0.3120  [0.2062, 0.4178]
Paired t-test delta_H Changed: statistic=5.90, p=4.14e-07
Wilcoxon delta_H Changed: statistic=123.00, p=5.08e-06
Mean ΔH Changed = 0.4175  [0.2787, 0.5562]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=8.34, p=6.54e-15
Wilcoxon (p_top2_game vs p_top2_base): statistic=7663.00, p=2.77e-09
Mean Δp_top2 = 0.0575  [0.0440, 0.0710] (n=235)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=7.33, p=3.84e-12
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=6583.00, p=7.8e-12
Mean ΔH_unchosen_baseline_set = 0.3331  [0.2440, 0.4222] (n=235)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  235
Model:                          Logit   Df Residuals:                      232
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.02107
Time:                        16:13:37   Log-Likelihood:                -115.12
converged:                       True   LL-Null:                       -117.59
Covariance Type:            nonrobust   LLR p-value:                   0.08389
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.0909      0.244     -4.471      0.000      -1.569      -0.613
p1_z            -0.3796      0.193     -1.971      0.049      -0.757      -0.002
I(p1_z ** 2)    -0.3383      0.207     -1.634      0.102      -0.744       0.067
================================================================================
AUC = 0.607

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  235
Model:                          Logit   Df Residuals:                      233
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1012
Time:                        16:13:37   Log-Likelihood:                -105.70
converged:                       True   LL-Null:                       -117.59
Covariance Type:            nonrobust   LLR p-value:                 1.072e-06
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -2.7620      0.355     -7.785      0.000      -3.457      -2.067
game_entropy     2.7216      0.574      4.745      0.000       1.597       3.846
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=5539.00, p=1.45e-15
Paired t-test (game_entropy vs capabilities_entropy): statistic=-9.89, p=1.66e-19
Mean game_entropy-capabilities_entropy = -0.3755  [-0.4498, -0.3011] (n=235)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  235
Model:                          Logit   Df Residuals:                      232
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1044
Time:                        16:13:37   Log-Likelihood:                -105.32
converged:                       True   LL-Null:                       -117.59
Covariance Type:            nonrobust   LLR p-value:                 4.655e-06
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.9490      0.423     -6.974      0.000      -3.778      -2.120
capabilities_entropy     0.2738      0.315      0.870      0.384      -0.343       0.890
game_entropy             2.6131      0.583      4.482      0.000       1.470       3.756
========================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  235
Model:                          Logit   Df Residuals:                      233
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.01669
Time:                        16:13:37   Log-Likelihood:                -115.63
converged:                       True   LL-Null:                       -117.59
Covariance Type:            nonrobust   LLR p-value:                   0.04754
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -0.0204      0.711     -0.029      0.977      -1.413       1.372
human_difficulty    -0.5937      0.308     -1.930      0.054      -1.197       0.009
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  235
Model:                          Logit   Df Residuals:                      228
Method:                           MLE   Df Model:                            6
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.04311
Time:                        16:13:37   Log-Likelihood:                -112.53
converged:                       True   LL-Null:                       -117.59
Covariance Type:            nonrobust   LLR p-value:                    0.1189
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                             0.3232      2.296      0.141      0.888      -4.176       4.822
C(domain_grouped)[T.chemistry]       -0.0690      0.536     -0.129      0.898      -1.120       0.982
C(domain_grouped)[T.physics]         -0.4139      0.583     -0.709      0.478      -1.558       0.730
human_difficulty                     -0.7614      0.328     -2.320      0.020      -1.405      -0.118
q_length                              0.0461      0.273      0.169      0.866      -0.489       0.581
avg_word_length                       0.0903      0.243      0.371      0.710      -0.386       0.566
percent_non_alphabetic_whitespace    -0.0600      0.037     -1.625      0.104      -0.132       0.012
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 0.8326
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  235
Model:                          Logit   Df Residuals:                      227
Method:                           MLE   Df Model:                            7
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.06462
Time:                        16:13:37   Log-Likelihood:                -110.00
converged:                       True   LL-Null:                       -117.59
Covariance Type:            nonrobust   LLR p-value:                   0.03353
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                             0.5623      2.289      0.246      0.806      -3.923       5.048
C(domain_grouped)[T.chemistry]       -0.2248      0.556     -0.404      0.686      -1.315       0.865
C(domain_grouped)[T.physics]         -0.5206      0.604     -0.862      0.389      -1.705       0.663
human_difficulty                     -0.7768      0.332     -2.339      0.019      -1.428      -0.126
q_length                             -0.0513      0.279     -0.184      0.854      -0.599       0.496
avg_word_length                       0.0842      0.240      0.351      0.725      -0.385       0.554
percent_non_alphabetic_whitespace    -0.0723      0.038     -1.899      0.058      -0.147       0.002
capabilities_entropy                  0.6926      0.313      2.213      0.027       0.079       1.306
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  235
Model:                          Logit   Df Residuals:                      227
Method:                           MLE   Df Model:                            7
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1443
Time:                        16:13:37   Log-Likelihood:                -100.62
converged:                       True   LL-Null:                       -117.59
Covariance Type:            nonrobust   LLR p-value:                 1.763e-05
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                             0.2631      2.377      0.111      0.912      -4.395       4.921
C(domain_grouped)[T.chemistry]       -0.5477      0.572     -0.957      0.339      -1.670       0.574
C(domain_grouped)[T.physics]         -0.7847      0.614     -1.277      0.201      -1.989       0.419
human_difficulty                     -0.7880      0.351     -2.245      0.025      -1.476      -0.100
q_length                             -0.0855      0.297     -0.288      0.773      -0.667       0.496
avg_word_length                       0.0534      0.246      0.217      0.828      -0.429       0.536
percent_non_alphabetic_whitespace    -0.0599      0.040     -1.501      0.133      -0.138       0.018
game_entropy                          2.8427      0.603      4.715      0.000       1.661       4.024
=====================================================================================================

                  Model 4.95: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  235
Model:                          Logit   Df Residuals:                      226
Method:                           MLE   Df Model:                            8
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1521
Time:                        16:13:37   Log-Likelihood:                -99.707
converged:                       True   LL-Null:                       -117.59
Covariance Type:            nonrobust   LLR p-value:                 1.930e-05
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                             0.4750      2.407      0.197      0.844      -4.243       5.193
C(domain_grouped)[T.chemistry]       -0.6190      0.582     -1.063      0.288      -1.760       0.522
C(domain_grouped)[T.physics]         -0.8498      0.627     -1.356      0.175      -2.078       0.379
human_difficulty                     -0.7903      0.352     -2.245      0.025      -1.480      -0.100
q_length                             -0.1404      0.302     -0.465      0.642      -0.732       0.451
avg_word_length                       0.0364      0.248      0.147      0.883      -0.449       0.522
percent_non_alphabetic_whitespace    -0.0685      0.041     -1.681      0.093      -0.148       0.011
capabilities_entropy                  0.4528      0.337      1.345      0.179      -0.207       1.113
game_entropy                          2.6983      0.610      4.421      0.000       1.502       3.895
=====================================================================================================

--- Analyzing gemini-1.5-pro (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/gemini-1.5-pro_GPQA_redacted_cor_temp0.0_1751757449_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    182
1     19
Name: count, dtype: int64

Answer change%: 0.0945 [0.05408220862790201, 0.1349725177402572] (n=201)
P-value vs 25%: 4.914e-14; P-value vs 0%: 4.633e-06
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=19)
P-value vs 25%: 0; P-value vs 33%: 0

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  201
Model:                          Logit   Df Residuals:                      199
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                0.006038
Time:                        16:13:37   Log-Likelihood:                -62.511
converged:                       True   LL-Null:                       -62.891
Covariance Type:            nonrobust   LLR p-value:                    0.3835
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -3.1667      1.088     -2.909      0.004      -5.300      -1.033
human_difficulty     0.3770      0.433      0.871      0.383      -0.471       1.225
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  201
Model:                          Logit   Df Residuals:                      194
Method:                           MLE   Df Model:                            6
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.02890
Time:                        16:13:37   Log-Likelihood:                -61.073
converged:                       True   LL-Null:                       -62.891
Covariance Type:            nonrobust   LLR p-value:                    0.7259
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -4.4739      3.446     -1.298      0.194     -11.228       2.281
C(domain_grouped)[T.chemistry]        0.8927      0.716      1.247      0.212      -0.510       2.295
C(domain_grouped)[T.physics]          0.0635      0.739      0.086      0.932      -1.386       1.513
human_difficulty                      0.4115      0.449      0.916      0.359      -0.469       1.292
q_length                              0.2464      0.392      0.628      0.530      -0.522       1.015
avg_word_length                      -0.0760      0.400     -0.190      0.850      -0.861       0.709
percent_non_alphabetic_whitespace    -0.0318      0.051     -0.627      0.531      -0.131       0.068
=====================================================================================================

--- Analyzing gemini-1.5-pro (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/gemini-1.5-pro_GPQA_redacted_temp0.0_1751722268_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    187
1     59
Name: count, dtype: int64

Answer change%: 0.2398 [0.1864802956528626, 0.2931945010951049] (n=246)
P-value vs 25%: 0.7089; P-value vs 0%: 1.252e-18
Phase 2 self-accuracy: 0.5085 [0.3809101148274585, 0.6360390377149143] (n=59)
P-value vs 25%: 7.147e-05; P-value vs 33%: 0.007016

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  246
Model:                          Logit   Df Residuals:                      244
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:               1.592e-05
Time:                        16:13:37   Log-Likelihood:                -135.52
converged:                       True   LL-Null:                       -135.52
Covariance Type:            nonrobust   LLR p-value:                    0.9476
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -1.1138      0.624     -1.786      0.074      -2.336       0.108
human_difficulty    -0.0167      0.255     -0.066      0.948      -0.516       0.482
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  246
Model:                          Logit   Df Residuals:                      239
Method:                           MLE   Df Model:                            6
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.01409
Time:                        16:13:37   Log-Likelihood:                -133.61
converged:                       True   LL-Null:                       -135.52
Covariance Type:            nonrobust   LLR p-value:                    0.7010
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                             1.7876      2.380      0.751      0.453      -2.877       6.452
C(domain_grouped)[T.chemistry]       -0.6503      0.491     -1.326      0.185      -1.612       0.311
C(domain_grouped)[T.physics]         -0.4937      0.502     -0.983      0.326      -1.478       0.491
human_difficulty                     -0.0087      0.266     -0.033      0.974      -0.531       0.514
q_length                             -0.0929      0.249     -0.373      0.709      -0.581       0.396
avg_word_length                      -0.3909      0.273     -1.433      0.152      -0.926       0.144
percent_non_alphabetic_whitespace    -0.0102      0.029     -0.352      0.725      -0.067       0.047
=====================================================================================================

--- Analyzing gemini-2.0-flash-001 (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/gemini-2.0-flash-001_GPQA_redacted_cor_temp1.0_1757989025_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    171
1     44
Name: count, dtype: int64

Answer change%: 0.2047 [0.15072310313071696, 0.2585792224506784] (n=215)
P-value vs 25%: 0.09932; P-value vs 0%: 1.023e-13
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=44)
P-value vs 25%: 0; P-value vs 33%: 0

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  215
Model:                          Logit   Df Residuals:                      213
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.06922
Time:                        16:13:37   Log-Likelihood:                -101.42
converged:                       True   LL-Null:                       -108.96
Covariance Type:            nonrobust   LLR p-value:                 0.0001028
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          3.3750      1.266      2.666      0.008       0.894       5.856
p_i_capability    -5.0497      1.346     -3.751      0.000      -7.688      -2.411
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  215
Model:                          Logit   Df Residuals:                      213
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1085
Time:                        16:13:37   Log-Likelihood:                -97.140
converged:                       True   LL-Null:                       -108.96
Covariance Type:            nonrobust   LLR p-value:                 1.164e-06
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.8665      0.220     -8.485      0.000      -2.298      -1.435
capabilities_entropy     2.1548      0.464      4.642      0.000       1.245       3.065
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.5526 [0.3945, 0.7107] (n=38)
                  P-value vs 33.3%: 0.006552

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=4.02, p=0.000143
Wilcoxon delta_p: statistic=574.00, p=3.29e-05
Mean Δp = 0.0799  [0.0410, 0.1189]
Idea 1 N = 72; 

  Idea 1.5: Calibration Metrics
  NLL: 0.2213, Signed ECE (overconf pos under neg): -0.1305, ECE: 0.1305 (n=110)
  Brier: 0.0697, Reliability (absolute calibration error; lower better): 0.0690, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=110)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.686
Model:                            OLS   Adj. R-squared:                  0.677
Method:                 Least Squares   F-statistic:                     77.24
Date:                Wed, 24 Sep 2025   Prob (F-statistic):           1.47e-26
Time:                        16:13:37   Log-Likelihood:                 22.890
No. Observations:                 110   AIC:                            -37.78
Df Residuals:                     106   BIC:                            -26.98
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.1034      0.161     -0.641      0.523      -0.423       0.217
p1                    0.1979      0.172      1.148      0.254      -0.144       0.540
answer_changed       -0.5310      0.246     -2.157      0.033      -1.019      -0.043
p1:answer_changed     1.2446      0.272      4.582      0.000       0.706       1.783
==============================================================================
Omnibus:                        2.084   Durbin-Watson:                   1.849
Prob(Omnibus):                  0.353   Jarque-Bera (JB):                1.613
Skew:                          -0.130   Prob(JB):                        0.446
Kurtosis:                       3.533   Cond. No.                         30.5
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-1.48, p=0.143
Wilcoxon delta_H: statistic=1104.00, p=0.239
Mean ΔH = -0.1037  [-0.2411, 0.0336]
Paired t-test delta_H Changed: statistic=1.41, p=0.168
Wilcoxon delta_H Changed: statistic=297.00, p=0.293
Mean ΔH Changed = 0.1196  [-0.0470, 0.2862]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=-4.50, p=1.68e-05
Wilcoxon (p_top2_game vs p_top2_base): statistic=1058.00, p=2.71e-09
Mean Δp_top2 = -0.0262  [-0.0376, -0.0148] (n=110)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=-0.48, p=0.631
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=2917.00, p=0.686
Mean ΔH_unchosen_baseline_set = -0.0266  [-0.1347, 0.0816] (n=110)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  110
Model:                          Logit   Df Residuals:                      107
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.04630
Time:                        16:13:37   Log-Likelihood:                -67.622
converged:                       True   LL-Null:                       -70.905
Covariance Type:            nonrobust   LLR p-value:                   0.03753
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.3520      0.269     -1.310      0.190      -0.879       0.175
p1_z            -0.9533      0.394     -2.422      0.015      -1.725      -0.182
I(p1_z ** 2)    -0.3198      0.188     -1.698      0.090      -0.689       0.049
================================================================================
AUC = 0.652

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  215
Model:                          Logit   Df Residuals:                      213
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1850
Time:                        16:13:37   Log-Likelihood:                -88.800
converged:                       True   LL-Null:                       -108.96
Covariance Type:            nonrobust   LLR p-value:                 2.159e-10
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -2.3508      0.279     -8.435      0.000      -2.897      -1.805
game_entropy     2.0255      0.342      5.919      0.000       1.355       2.696
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=3996.00, p=7.59e-17
Paired t-test (game_entropy vs capabilities_entropy): statistic=6.08, p=5.45e-09
Mean game_entropy-capabilities_entropy = 0.1779  [0.1206, 0.2353] (n=215)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  215
Model:                          Logit   Df Residuals:                      212
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.2014
Time:                        16:13:37   Log-Likelihood:                -87.011
converged:                       True   LL-Null:                       -108.96
Covariance Type:            nonrobust   LLR p-value:                 2.941e-10
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.4362      0.289     -8.441      0.000      -3.002      -1.870
capabilities_entropy     1.0527      0.553      1.904      0.057      -0.031       2.136
game_entropy             1.6939      0.384      4.413      0.000       0.941       2.446
========================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  215
Model:                          Logit   Df Residuals:                      213
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:               6.494e-05
Time:                        16:13:37   Log-Likelihood:                -108.95
converged:                       True   LL-Null:                       -108.96
Covariance Type:            nonrobust   LLR p-value:                    0.9053
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -1.4430      0.739     -1.952      0.051      -2.892       0.006
human_difficulty     0.0360      0.302      0.119      0.905      -0.557       0.629
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  215
Model:                          Logit   Df Residuals:                      208
Method:                           MLE   Df Model:                            6
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.03518
Time:                        16:13:37   Log-Likelihood:                -105.13
converged:                       True   LL-Null:                       -108.96
Covariance Type:            nonrobust   LLR p-value:                    0.2636
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -0.2816      2.515     -0.112      0.911      -5.212       4.649
C(domain_grouped)[T.chemistry]        1.1724      0.537      2.185      0.029       0.121       2.224
C(domain_grouped)[T.physics]          0.6780      0.515      1.316      0.188      -0.332       1.688
human_difficulty                      0.1167      0.312      0.374      0.708      -0.494       0.728
q_length                             -0.0304      0.270     -0.113      0.910      -0.560       0.499
avg_word_length                      -0.2897      0.295     -0.982      0.326      -0.868       0.288
percent_non_alphabetic_whitespace    -0.0663      0.035     -1.907      0.057      -0.135       0.002
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 0.1784
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  215
Model:                          Logit   Df Residuals:                      207
Method:                           MLE   Df Model:                            7
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1432
Time:                        16:13:37   Log-Likelihood:                -93.356
converged:                       True   LL-Null:                       -108.96
Covariance Type:            nonrobust   LLR p-value:                 5.700e-05
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -0.0117      2.731     -0.004      0.997      -5.365       5.341
C(domain_grouped)[T.chemistry]        0.9041      0.569      1.588      0.112      -0.212       2.020
C(domain_grouped)[T.physics]          0.5131      0.540      0.950      0.342      -0.546       1.572
human_difficulty                      0.1656      0.337      0.492      0.623      -0.494       0.825
q_length                             -0.1960      0.290     -0.677      0.499      -0.764       0.372
avg_word_length                      -0.2176      0.311     -0.700      0.484      -0.827       0.392
percent_non_alphabetic_whitespace    -0.0820      0.038     -2.170      0.030      -0.156      -0.008
capabilities_entropy                  2.2674      0.493      4.604      0.000       1.302       3.233
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  215
Model:                          Logit   Df Residuals:                      207
Method:                           MLE   Df Model:                            7
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.2065
Time:                        16:13:37   Log-Likelihood:                -86.455
converged:                       True   LL-Null:                       -108.96
Covariance Type:            nonrobust   LLR p-value:                 1.364e-07
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -1.4159      2.796     -0.506      0.613      -6.896       4.064
C(domain_grouped)[T.chemistry]        0.4120      0.604      0.683      0.495      -0.771       1.595
C(domain_grouped)[T.physics]          0.2683      0.570      0.470      0.638      -0.850       1.386
human_difficulty                     -0.0732      0.354     -0.207      0.836      -0.767       0.621
q_length                             -0.0604      0.300     -0.201      0.841      -0.648       0.528
avg_word_length                      -0.0350      0.310     -0.113      0.910      -0.642       0.572
percent_non_alphabetic_whitespace    -0.0664      0.038     -1.733      0.083      -0.142       0.009
game_entropy                          2.0947      0.372      5.625      0.000       1.365       2.825
=====================================================================================================

                  Model 4.95: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  215
Model:                          Logit   Df Residuals:                      206
Method:                           MLE   Df Model:                            8
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.2275
Time:                        16:13:37   Log-Likelihood:                -84.173
converged:                       True   LL-Null:                       -108.96
Covariance Type:            nonrobust   LLR p-value:                 4.943e-08
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -1.1683      2.881     -0.406      0.685      -6.815       4.478
C(domain_grouped)[T.chemistry]        0.3997      0.607      0.659      0.510      -0.790       1.589
C(domain_grouped)[T.physics]          0.2444      0.573      0.426      0.670      -0.879       1.368
human_difficulty                      0.0157      0.362      0.043      0.965      -0.694       0.725
q_length                             -0.1217      0.306     -0.398      0.690      -0.721       0.477
avg_word_length                      -0.0598      0.318     -0.188      0.851      -0.682       0.563
percent_non_alphabetic_whitespace    -0.0759      0.040     -1.891      0.059      -0.155       0.003
capabilities_entropy                  1.2204      0.568      2.147      0.032       0.106       2.334
game_entropy                          1.7108      0.411      4.160      0.000       0.905       2.517
=====================================================================================================

--- Analyzing gemini-2.0-flash-001 (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/gemini-2.0-flash-001_GPQA_redacted_temp1.0_1757988130_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    155
1     77
Name: count, dtype: int64

Answer change%: 0.3319 [0.2713028722391558, 0.39249023120912013] (n=232)
P-value vs 25%: 0.008072; P-value vs 0%: 6.932e-27
Phase 2 self-accuracy: 0.3636 [0.2561906588540613, 0.471082068418666] (n=77)
P-value vs 25%: 0.03818; P-value vs 33%: 0.5763

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  232
Model:                          Logit   Df Residuals:                      230
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.07487
Time:                        16:13:37   Log-Likelihood:                -136.40
converged:                       True   LL-Null:                       -147.44
Covariance Type:            nonrobust   LLR p-value:                 2.617e-06
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          3.8155      1.033      3.694      0.000       1.791       5.840
p_i_capability    -4.9078      1.110     -4.422      0.000      -7.083      -2.732
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  232
Model:                          Logit   Df Residuals:                      230
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.09349
Time:                        16:13:37   Log-Likelihood:                -133.65
converged:                       True   LL-Null:                       -147.44
Covariance Type:            nonrobust   LLR p-value:                 1.516e-07
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.2272      0.184     -6.671      0.000      -1.588      -0.867
capabilities_entropy     1.8213      0.367      4.963      0.000       1.102       2.541
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.4714 [0.3545, 0.5884] (n=70)
                  P-value vs 33.3%: 0.02064

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=5.00, p=2.81e-06
Wilcoxon delta_p: statistic=783.00, p=1.29e-07
Mean Δp = 0.1075  [0.0653, 0.1497]
Idea 1 N = 92; 

  Idea 1.5: Calibration Metrics
  NLL: 8.1218, Signed ECE (overconf pos under neg): 0.0436, ECE: 0.0436 (n=160)
  Brier: 0.0189, Reliability (absolute calibration error; lower better): 0.0185, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=160)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.709
Model:                            OLS   Adj. R-squared:                  0.703
Method:                 Least Squares   F-statistic:                     127.5
Date:                Wed, 24 Sep 2025   Prob (F-statistic):           6.96e-42
Time:                        16:13:37   Log-Likelihood:                 22.591
No. Observations:                 161   AIC:                            -37.18
Df Residuals:                     157   BIC:                            -24.86
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept             0.2873      0.168      1.711      0.089      -0.044       0.619
p1                   -0.1936      0.179     -1.080      0.282      -0.547       0.160
answer_changed       -1.0745      0.215     -4.992      0.000      -1.500      -0.649
p1:answer_changed     1.8684      0.236      7.923      0.000       1.403       2.334
==============================================================================
Omnibus:                        7.394   Durbin-Watson:                   2.069
Prob(Omnibus):                  0.025   Jarque-Bera (JB):               13.483
Skew:                          -0.012   Prob(JB):                      0.00118
Kurtosis:                       4.418   Cond. No.                         33.6
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-2.68, p=0.00869
Wilcoxon delta_H: statistic=1491.00, p=0.0116
Mean ΔH = -0.1572  [-0.2721, -0.0423]
Paired t-test delta_H Changed: statistic=-0.78, p=0.439
Wilcoxon delta_H Changed: statistic=1131.00, p=0.514
Mean ΔH Changed = -0.0579  [-0.2039, 0.0881]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=-5.22, p=5.39e-07
Wilcoxon (p_top2_game vs p_top2_base): statistic=2325.00, p=8.58e-13
Mean Δp_top2 = -0.0326  [-0.0448, -0.0204] (n=162)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=-2.47, p=0.0146
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=5222.00, p=0.0211
Mean ΔH_unchosen_baseline_set = -0.1143  [-0.2051, -0.0235] (n=162)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  162
Model:                          Logit   Df Residuals:                      159
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.03523
Time:                        16:13:37   Log-Likelihood:                -106.89
converged:                       True   LL-Null:                       -110.79
Covariance Type:            nonrobust   LLR p-value:                   0.02018
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.2334      0.248     -0.941      0.347      -0.720       0.253
p1_z            -0.5110      0.316     -1.616      0.106      -1.131       0.109
I(p1_z ** 2)    -0.0446      0.193     -0.231      0.818      -0.423       0.334
================================================================================
AUC = 0.666

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  232
Model:                          Logit   Df Residuals:                      230
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1322
Time:                        16:13:37   Log-Likelihood:                -127.94
converged:                       True   LL-Null:                       -147.44
Covariance Type:            nonrobust   LLR p-value:                 4.254e-10
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.6478      0.233     -7.086      0.000      -2.104      -1.192
game_entropy     1.6347      0.281      5.824      0.000       1.085       2.185
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=5499.00, p=4.81e-15
Paired t-test (game_entropy vs capabilities_entropy): statistic=7.26, p=5.85e-12
Mean game_entropy-capabilities_entropy = 0.2542  [0.1856, 0.3228] (n=232)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  232
Model:                          Logit   Df Residuals:                      229
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1659
Time:                        16:13:37   Log-Likelihood:                -122.98
converged:                       True   LL-Null:                       -147.44
Covariance Type:            nonrobust   LLR p-value:                 2.377e-11
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.8338      0.249     -7.374      0.000      -2.321      -1.346
capabilities_entropy     1.2505      0.403      3.100      0.002       0.460       2.041
game_entropy             1.3300      0.296      4.492      0.000       0.750       1.910
========================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  232
Model:                          Logit   Df Residuals:                      230
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                0.001722
Time:                        16:13:37   Log-Likelihood:                -147.19
converged:                       True   LL-Null:                       -147.44
Covariance Type:            nonrobust   LLR p-value:                    0.4761
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -0.2977      0.581     -0.513      0.608      -1.436       0.840
human_difficulty    -0.1705      0.240     -0.710      0.478      -0.641       0.300
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  232
Model:                          Logit   Df Residuals:                      225
Method:                           MLE   Df Model:                            6
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.02136
Time:                        16:13:37   Log-Likelihood:                -144.29
converged:                       True   LL-Null:                       -147.44
Covariance Type:            nonrobust   LLR p-value:                    0.3907
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -1.8183      2.233     -0.814      0.416      -6.196       2.559
C(domain_grouped)[T.chemistry]        0.2323      0.548      0.424      0.672      -0.842       1.307
C(domain_grouped)[T.physics]         -0.0565      0.581     -0.097      0.923      -1.195       1.082
human_difficulty                     -0.1811      0.257     -0.706      0.480      -0.684       0.322
q_length                              0.4197      0.250      1.679      0.093      -0.070       0.910
avg_word_length                      -0.2574      0.260     -0.989      0.322      -0.767       0.253
percent_non_alphabetic_whitespace     0.0149      0.029      0.519      0.604      -0.041       0.071
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 0.2625
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  232
Model:                          Logit   Df Residuals:                      224
Method:                           MLE   Df Model:                            7
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1048
Time:                        16:13:37   Log-Likelihood:                -131.99
converged:                       True   LL-Null:                       -147.44
Covariance Type:            nonrobust   LLR p-value:                 6.494e-05
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -1.7532      2.352     -0.745      0.456      -6.363       2.856
C(domain_grouped)[T.chemistry]        0.0567      0.573      0.099      0.921      -1.066       1.179
C(domain_grouped)[T.physics]         -0.2556      0.613     -0.417      0.677      -1.458       0.947
human_difficulty                     -0.2533      0.277     -0.915      0.360      -0.796       0.289
q_length                              0.3368      0.268      1.255      0.209      -0.189       0.863
avg_word_length                      -0.1832      0.272     -0.674      0.500      -0.716       0.349
percent_non_alphabetic_whitespace     0.0053      0.030      0.176      0.860      -0.054       0.065
capabilities_entropy                  1.7658      0.375      4.709      0.000       1.031       2.501
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  232
Model:                          Logit   Df Residuals:                      224
Method:                           MLE   Df Model:                            7
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1541
Time:                        16:13:37   Log-Likelihood:                -124.71
converged:                       True   LL-Null:                       -147.44
Covariance Type:            nonrobust   LLR p-value:                 1.117e-07
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -3.2361      2.464     -1.313      0.189      -8.066       1.594
C(domain_grouped)[T.chemistry]       -0.2703      0.586     -0.461      0.645      -1.420       0.879
C(domain_grouped)[T.physics]         -0.7842      0.639     -1.228      0.219      -2.036       0.467
human_difficulty                     -0.3215      0.294     -1.092      0.275      -0.899       0.256
q_length                              0.4806      0.276      1.743      0.081      -0.060       1.021
avg_word_length                      -0.0809      0.275     -0.294      0.769      -0.621       0.459
percent_non_alphabetic_whitespace     0.0294      0.031      0.935      0.350      -0.032       0.091
game_entropy                          1.7287      0.299      5.773      0.000       1.142       2.316
=====================================================================================================

                  Model 4.95: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  232
Model:                          Logit   Df Residuals:                      223
Method:                           MLE   Df Model:                            8
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1831
Time:                        16:13:37   Log-Likelihood:                -120.44
converged:                       True   LL-Null:                       -147.44
Covariance Type:            nonrobust   LLR p-value:                 6.910e-09
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -2.8613      2.516     -1.137      0.255      -7.793       2.070
C(domain_grouped)[T.chemistry]       -0.3242      0.589     -0.550      0.582      -1.479       0.830
C(domain_grouped)[T.physics]         -0.8266      0.648     -1.276      0.202      -2.096       0.443
human_difficulty                     -0.3589      0.307     -1.169      0.242      -0.960       0.243
q_length                              0.4062      0.284      1.432      0.152      -0.150       0.962
avg_word_length                      -0.0610      0.281     -0.217      0.828      -0.611       0.489
percent_non_alphabetic_whitespace     0.0206      0.032      0.636      0.525      -0.043       0.084
capabilities_entropy                  1.1836      0.411      2.880      0.004       0.378       1.989
game_entropy                          1.4517      0.314      4.618      0.000       0.835       2.068
=====================================================================================================

--- Analyzing gemini-2.5-flash-lite_nothink (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/gemini-2.5-flash-lite_nothink_GPQA_redacted_cor_temp1.0_1757983987_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    128
1     43
Name: count, dtype: int64

Answer change%: 0.2515 [0.18643507520540595, 0.3164889014027812] (n=171)
P-value vs 25%: 0.9649; P-value vs 0%: 3.475e-14
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=43)
P-value vs 25%: 0; P-value vs 33%: 0

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  171
Model:                          Logit   Df Residuals:                      169
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1159
Time:                        16:13:37   Log-Likelihood:                -85.261
converged:                       True   LL-Null:                       -96.433
Covariance Type:            nonrobust   LLR p-value:                 2.279e-06
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          2.1926      0.724      3.028      0.002       0.773       3.612
p_i_capability    -4.1090      0.905     -4.542      0.000      -5.882      -2.336
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  171
Model:                          Logit   Df Residuals:                      169
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1448
Time:                        16:13:37   Log-Likelihood:                -82.473
converged:                       True   LL-Null:                       -96.433
Covariance Type:            nonrobust   LLR p-value:                 1.265e-07
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.2287      0.326     -6.846      0.000      -2.867      -1.591
capabilities_entropy     1.5733      0.318      4.950      0.000       0.950       2.196
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.2558 [0.1254, 0.3862] (n=43)
                  P-value vs 33.3%: 0.244

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=13.45, p=1.69e-25
Wilcoxon delta_p: statistic=416.00, p=9.56e-17
Mean Δp = 0.5424  [0.4634, 0.6214]
Idea 1 N = 118; 

  Idea 1.5: Calibration Metrics
  NLL: 3.6794, Signed ECE (overconf pos under neg): -0.3717, ECE: 0.5225 (n=169)
  Brier: 0.5291, Reliability (absolute calibration error; lower better): 0.3396, Resolution (relative calibration quality; higher better): 0.0349, Uncertainty: 0.2216 (n=169)
  AUROC: 0.3978

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.191
Model:                            OLS   Adj. R-squared:                  0.175
Method:                 Least Squares   F-statistic:                     12.08
Date:                Wed, 24 Sep 2025   Prob (F-statistic):           3.80e-07
Time:                        16:13:37   Log-Likelihood:                -73.265
No. Observations:                 158   AIC:                             154.5
Df Residuals:                     154   BIC:                             166.8
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.0382      0.177     -0.216      0.829      -0.387       0.311
p1                    0.6687      0.199      3.357      0.001       0.275       1.062
answer_changed       -0.5147      0.280     -1.837      0.068      -1.068       0.039
p1:answer_changed     0.8079      0.362      2.229      0.027       0.092       1.524
==============================================================================
Omnibus:                       60.948   Durbin-Watson:                   1.962
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               21.687
Skew:                          -0.705   Prob(JB):                     1.95e-05
Kurtosis:                       1.858   Cond. No.                         21.0
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=7.58, p=6.44e-12
Wilcoxon delta_H: statistic=1433.00, p=1.46e-10
Mean ΔH = 0.3893  [0.2886, 0.4899]
Paired t-test delta_H Changed: statistic=4.04, p=0.000226
Wilcoxon delta_H Changed: statistic=182.00, p=0.000269
Mean ΔH Changed = 0.3200  [0.1646, 0.4754]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=3.03, p=0.00284
Wilcoxon (p_top2_game vs p_top2_base): statistic=6124.00, p=0.058
Mean Δp_top2 = 0.0192  [0.0068, 0.0316] (n=171)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=8.59, p=5.24e-15
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=2609.00, p=2.53e-13
Mean ΔH_unchosen_baseline_set = 0.3718  [0.2870, 0.4566] (n=171)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  171
Model:                          Logit   Df Residuals:                      168
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1320
Time:                        16:13:37   Log-Likelihood:                -83.702
converged:                       True   LL-Null:                       -96.433
Covariance Type:            nonrobust   LLR p-value:                 2.957e-06
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.9219      0.263     -3.508      0.000      -1.437      -0.407
p1_z            -1.2382      0.307     -4.030      0.000      -1.840      -0.636
I(p1_z ** 2)    -0.3683      0.208     -1.768      0.077      -0.777       0.040
================================================================================
AUC = 0.763

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  171
Model:                          Logit   Df Residuals:                      169
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.2001
Time:                        16:13:37   Log-Likelihood:                -77.141
converged:                       True   LL-Null:                       -96.433
Covariance Type:            nonrobust   LLR p-value:                 5.243e-10
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -2.4334      0.337     -7.228      0.000      -3.093      -1.774
game_entropy     2.2713      0.408      5.574      0.000       1.473       3.070
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=5722.00, p=0.0119
Paired t-test (game_entropy vs capabilities_entropy): statistic=-2.98, p=0.00334
Mean game_entropy-capabilities_entropy = -0.1164  [-0.1931, -0.0398] (n=171)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  171
Model:                          Logit   Df Residuals:                      168
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.2286
Time:                        16:13:37   Log-Likelihood:                -74.392
converged:                       True   LL-Null:                       -96.433
Covariance Type:            nonrobust   LLR p-value:                 2.679e-10
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.7763      0.390     -7.119      0.000      -3.541      -2.012
capabilities_entropy     0.8728      0.373      2.339      0.019       0.142       1.604
game_entropy             1.7838      0.460      3.876      0.000       0.882       2.686
========================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  171
Model:                          Logit   Df Residuals:                      169
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                0.006346
Time:                        16:13:37   Log-Likelihood:                -95.821
converged:                       True   LL-Null:                       -96.433
Covariance Type:            nonrobust   LLR p-value:                    0.2686
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -0.2235      0.803     -0.278      0.781      -1.797       1.350
human_difficulty    -0.3691      0.337     -1.095      0.273      -1.030       0.291
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  171
Model:                          Logit   Df Residuals:                      164
Method:                           MLE   Df Model:                            6
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.06710
Time:                        16:13:37   Log-Likelihood:                -89.962
converged:                       True   LL-Null:                       -96.433
Covariance Type:            nonrobust   LLR p-value:                   0.04397
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -5.4997      2.956     -1.861      0.063     -11.293       0.293
C(domain_grouped)[T.chemistry]        1.7951      0.653      2.748      0.006       0.515       3.075
C(domain_grouped)[T.physics]          1.4975      0.666      2.247      0.025       0.191       2.804
human_difficulty                     -0.2247      0.346     -0.650      0.516      -0.902       0.453
q_length                              0.2611      0.327      0.797      0.425      -0.381       0.903
avg_word_length                       0.3883      0.344      1.130      0.259      -0.285       1.062
percent_non_alphabetic_whitespace     0.0332      0.035      0.939      0.348      -0.036       0.103
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 0.6008
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  171
Model:                          Logit   Df Residuals:                      163
Method:                           MLE   Df Model:                            7
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1890
Time:                        16:13:37   Log-Likelihood:                -78.209
converged:                       True   LL-Null:                       -96.433
Covariance Type:            nonrobust   LLR p-value:                 5.965e-06
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -7.0006      3.173     -2.207      0.027     -13.219      -0.782
C(domain_grouped)[T.chemistry]        1.1804      0.712      1.657      0.098      -0.216       2.577
C(domain_grouped)[T.physics]          1.1590      0.740      1.567      0.117      -0.291       2.609
human_difficulty                     -0.4511      0.378     -1.192      0.233      -1.193       0.290
q_length                              0.2046      0.353      0.580      0.562      -0.486       0.896
avg_word_length                       0.7031      0.372      1.892      0.058      -0.025       1.431
percent_non_alphabetic_whitespace     0.0494      0.039      1.278      0.201      -0.026       0.125
capabilities_entropy                  1.5772      0.350      4.506      0.000       0.891       2.263
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  171
Model:                          Logit   Df Residuals:                      163
Method:                           MLE   Df Model:                            7
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.2459
Time:                        16:13:38   Log-Likelihood:                -72.718
converged:                       True   LL-Null:                       -96.433
Covariance Type:            nonrobust   LLR p-value:                 4.601e-08
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -8.0845      3.471     -2.329      0.020     -14.887      -1.282
C(domain_grouped)[T.chemistry]        1.5958      0.735      2.171      0.030       0.155       3.036
C(domain_grouped)[T.physics]          1.5178      0.763      1.990      0.047       0.023       3.013
human_difficulty                     -0.0627      0.390     -0.161      0.872      -0.827       0.701
q_length                              0.1769      0.358      0.495      0.621      -0.524       0.878
avg_word_length                       0.6580      0.397      1.657      0.097      -0.120       1.436
percent_non_alphabetic_whitespace     0.0545      0.042      1.299      0.194      -0.028       0.137
game_entropy                          2.2537      0.431      5.224      0.000       1.408       3.099
=====================================================================================================

                  Model 4.95: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  171
Model:                          Logit   Df Residuals:                      162
Method:                           MLE   Df Model:                            8
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.2677
Time:                        16:13:38   Log-Likelihood:                -70.622
converged:                       True   LL-Null:                       -96.433
Covariance Type:            nonrobust   LLR p-value:                 1.992e-08
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -8.3078      3.479     -2.388      0.017     -15.126      -1.489
C(domain_grouped)[T.chemistry]        1.3088      0.758      1.727      0.084      -0.176       2.794
C(domain_grouped)[T.physics]          1.3565      0.789      1.719      0.086      -0.190       2.903
human_difficulty                     -0.2188      0.408     -0.536      0.592      -1.019       0.582
q_length                              0.1510      0.363      0.416      0.677      -0.560       0.862
avg_word_length                       0.7771      0.407      1.911      0.056      -0.020       1.574
percent_non_alphabetic_whitespace     0.0582      0.042      1.385      0.166      -0.024       0.141
capabilities_entropy                  0.8277      0.407      2.031      0.042       0.029       1.626
game_entropy                          1.8034      0.485      3.720      0.000       0.853       2.754
=====================================================================================================

--- Analyzing gemini-2.5-flash-lite_nothink (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/gemini-2.5-flash-lite_nothink_GPQA_redacted_temp1.0_1757983795_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    161
1    115
Name: count, dtype: int64

Answer change%: 0.4167 [0.35850372999560914, 0.4748296033377242] (n=276)
P-value vs 25%: 1.951e-08; P-value vs 0%: 8.777e-45
Phase 2 self-accuracy: 0.4870 [0.39560382972708724, 0.5783092137511736] (n=115)
P-value vs 25%: 3.698e-07; P-value vs 33%: 0.0009561

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  276
Model:                          Logit   Df Residuals:                      274
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.02487
Time:                        16:13:38   Log-Likelihood:                -182.80
converged:                       True   LL-Null:                       -187.46
Covariance Type:            nonrobust   LLR p-value:                  0.002261
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          0.9938      0.456      2.180      0.029       0.100       1.887
p_i_capability    -1.8666      0.620     -3.009      0.003      -3.082      -0.651
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  276
Model:                          Logit   Df Residuals:                      274
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.02957
Time:                        16:13:38   Log-Likelihood:                -181.91
converged:                       True   LL-Null:                       -187.46
Covariance Type:            nonrobust   LLR p-value:                 0.0008695
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.0631      0.260     -4.090      0.000      -1.573      -0.554
capabilities_entropy     0.7270      0.223      3.255      0.001       0.289       1.165
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.2783 [0.1964, 0.3602] (n=115)
                  P-value vs 33.3%: 0.1876

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=11.52, p=2.49e-22
Wilcoxon delta_p: statistic=1197.00, p=8.77e-17
Mean Δp = 0.4140  [0.3436, 0.4844]
Idea 1 N = 149; 

  Idea 1.5: Calibration Metrics
  NLL: 3.1277, Signed ECE (overconf pos under neg): 0.0144, ECE: 0.2494 (n=276)
  Brier: 0.2760, Reliability (absolute calibration error; lower better): 0.1111, Resolution (relative calibration quality; higher better): 0.0060, Uncertainty: 0.1681 (n=276)
  AUROC: 0.4489

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.225
Model:                            OLS   Adj. R-squared:                  0.216
Method:                 Least Squares   F-statistic:                     24.87
Date:                Wed, 24 Sep 2025   Prob (F-statistic):           3.68e-14
Time:                        16:13:38   Log-Likelihood:                -98.009
No. Observations:                 261   AIC:                             204.0
Df Residuals:                     257   BIC:                             218.3
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.2913      0.112     -2.600      0.010      -0.512      -0.071
p1                    0.9507      0.146      6.518      0.000       0.664       1.238
answer_changed        0.0856      0.163      0.525      0.600      -0.235       0.407
p1:answer_changed     0.0050      0.223      0.023      0.982      -0.435       0.445
==============================================================================
Omnibus:                       46.584   Durbin-Watson:                   2.017
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               38.628
Skew:                          -0.848   Prob(JB):                     4.09e-09
Kurtosis:                       2.176   Cond. No.                         18.9
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=7.23, p=1.93e-11
Wilcoxon delta_H: statistic=2712.00, p=1.29e-10
Mean ΔH = 0.3587  [0.2614, 0.4560]
Paired t-test delta_H Changed: statistic=4.51, p=1.57e-05
Wilcoxon delta_H Changed: statistic=1841.00, p=3.05e-05
Mean ΔH Changed = 0.2334  [0.1320, 0.3348]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=5.73, p=2.6e-08
Wilcoxon (p_top2_game vs p_top2_base): statistic=12445.00, p=5.06e-07
Mean Δp_top2 = 0.0362  [0.0238, 0.0485] (n=276)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=8.46, p=1.61e-15
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=8983.00, p=2.31e-14
Mean ΔH_unchosen_baseline_set = 0.3065  [0.2355, 0.3775] (n=276)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  276
Model:                          Logit   Df Residuals:                      273
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.02589
Time:                        16:13:38   Log-Likelihood:                -182.60
converged:                       True   LL-Null:                       -187.46
Covariance Type:            nonrobust   LLR p-value:                  0.007806
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.2648      0.183     -1.451      0.147      -0.623       0.093
p1_z            -0.3956      0.129     -3.055      0.002      -0.649      -0.142
I(p1_z ** 2)    -0.0855      0.138     -0.618      0.537      -0.357       0.186
================================================================================
AUC = 0.614

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  276
Model:                          Logit   Df Residuals:                      274
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.09767
Time:                        16:13:38   Log-Likelihood:                -169.15
converged:                       True   LL-Null:                       -187.46
Covariance Type:            nonrobust   LLR p-value:                 1.438e-09
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.5449      0.255     -6.047      0.000      -2.046      -1.044
game_entropy     1.5097      0.266      5.669      0.000       0.988       2.032
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=11951.00, p=6.81e-08
Paired t-test (game_entropy vs capabilities_entropy): statistic=-5.98, p=6.91e-09
Mean game_entropy-capabilities_entropy = -0.2068  [-0.2745, -0.1390] (n=276)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  276
Model:                          Logit   Df Residuals:                      273
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.09933
Time:                        16:13:38   Log-Likelihood:                -168.84
converged:                       True   LL-Null:                       -187.46
Covariance Type:            nonrobust   LLR p-value:                 8.187e-09
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.6733      0.306     -5.465      0.000      -2.273      -1.073
capabilities_entropy     0.2012      0.255      0.790      0.429      -0.298       0.700
game_entropy             1.4175      0.290      4.888      0.000       0.849       1.986
========================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  276
Model:                          Logit   Df Residuals:                      274
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:               8.896e-05
Time:                        16:13:38   Log-Likelihood:                -187.44
converged:                       True   LL-Null:                       -187.46
Covariance Type:            nonrobust   LLR p-value:                    0.8551
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -0.2477      0.501     -0.494      0.621      -1.230       0.735
human_difficulty    -0.0375      0.206     -0.183      0.855      -0.440       0.365
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  276
Model:                          Logit   Df Residuals:                      269
Method:                           MLE   Df Model:                            6
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.02242
Time:                        16:13:38   Log-Likelihood:                -183.25
converged:                       True   LL-Null:                       -187.46
Covariance Type:            nonrobust   LLR p-value:                    0.2099
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -1.8580      1.860     -0.999      0.318      -5.504       1.788
C(domain_grouped)[T.chemistry]        0.5323      0.462      1.153      0.249      -0.372       1.437
C(domain_grouped)[T.physics]          0.8860      0.469      1.891      0.059      -0.032       1.804
human_difficulty                      0.0483      0.218      0.221      0.825      -0.379       0.476
q_length                              0.1481      0.201      0.735      0.462      -0.247       0.543
avg_word_length                      -0.0620      0.197     -0.315      0.753      -0.448       0.324
percent_non_alphabetic_whitespace     0.0214      0.022      0.970      0.332      -0.022       0.065
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 0.9785
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  276
Model:                          Logit   Df Residuals:                      268
Method:                           MLE   Df Model:                            7
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.05073
Time:                        16:13:38   Log-Likelihood:                -177.95
converged:                       True   LL-Null:                       -187.46
Covariance Type:            nonrobust   LLR p-value:                  0.008126
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -2.8223      1.919     -1.471      0.141      -6.583       0.938
C(domain_grouped)[T.chemistry]        0.2564      0.478      0.536      0.592      -0.681       1.194
C(domain_grouped)[T.physics]          0.7852      0.480      1.635      0.102      -0.156       1.727
human_difficulty                      0.1391      0.225      0.617      0.537      -0.303       0.581
q_length                              0.0928      0.205      0.452      0.651      -0.310       0.495
avg_word_length                       0.0282      0.199      0.141      0.888      -0.362       0.419
percent_non_alphabetic_whitespace     0.0295      0.023      1.306      0.192      -0.015       0.074
capabilities_entropy                  0.7603      0.239      3.182      0.001       0.292       1.229
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  276
Model:                          Logit   Df Residuals:                      268
Method:                           MLE   Df Model:                            7
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1211
Time:                        16:13:38   Log-Likelihood:                -164.76
converged:                       True   LL-Null:                       -187.46
Covariance Type:            nonrobust   LLR p-value:                 1.150e-07
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -2.6335      2.007     -1.312      0.189      -6.567       1.300
C(domain_grouped)[T.chemistry]        0.2901      0.498      0.582      0.560      -0.686       1.267
C(domain_grouped)[T.physics]          0.8622      0.507      1.699      0.089      -0.132       1.857
human_difficulty                      0.0925      0.238      0.388      0.698      -0.375       0.560
q_length                              0.0263      0.218      0.121      0.904      -0.401       0.454
avg_word_length                      -0.0200      0.204     -0.098      0.922      -0.420       0.380
percent_non_alphabetic_whitespace     0.0290      0.024      1.208      0.227      -0.018       0.076
game_entropy                          1.5663      0.276      5.667      0.000       1.025       2.108
=====================================================================================================

                  Model 4.95: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  276
Model:                          Logit   Df Residuals:                      267
Method:                           MLE   Df Model:                            8
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1226
Time:                        16:13:38   Log-Likelihood:                -164.47
converged:                       True   LL-Null:                       -187.46
Covariance Type:            nonrobust   LLR p-value:                 2.395e-07
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -2.8588      2.032     -1.407      0.159      -6.841       1.123
C(domain_grouped)[T.chemistry]        0.2275      0.506      0.450      0.653      -0.763       1.218
C(domain_grouped)[T.physics]          0.8336      0.509      1.637      0.102      -0.165       1.832
human_difficulty                      0.1168      0.241      0.485      0.627      -0.355       0.589
q_length                              0.0177      0.218      0.081      0.936      -0.411       0.446
avg_word_length                       0.0030      0.206      0.015      0.988      -0.400       0.406
percent_non_alphabetic_whitespace     0.0309      0.024      1.279      0.201      -0.016       0.078
capabilities_entropy                  0.2085      0.271      0.771      0.441      -0.322       0.739
game_entropy                          1.4757      0.299      4.930      0.000       0.889       2.062
=====================================================================================================

--- Analyzing gemini-2.5-flash-lite_think (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/gemini-2.5-flash-lite_think_GPQA_redacted_cor_temp1.0_1758169794_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    152
1    136
Name: count, dtype: int64

Answer change%: 0.4722 [0.414565412594486, 0.5298790318499584] (n=288)
P-value vs 25%: 4.216e-14; P-value vs 0%: 5.487e-58
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=136)
P-value vs 25%: 0; P-value vs 33%: 0

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  288
Model:                          Logit   Df Residuals:                      286
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.01641
Time:                        16:13:38   Log-Likelihood:                -195.91
converged:                       True   LL-Null:                       -199.18
Covariance Type:            nonrobust   LLR p-value:                   0.01057
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept         61.8264     38.046      1.625      0.104     -12.742     136.395
p_i_capability   -62.0123     38.076     -1.629      0.103    -136.641      12.616
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  288
Model:                          Logit   Df Residuals:                      286
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.01461
Time:                        16:13:38   Log-Likelihood:                -196.27
converged:                       True   LL-Null:                       -199.18
Covariance Type:            nonrobust   LLR p-value:                   0.01584
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -0.1898      0.124     -1.532      0.125      -0.433       0.053
capabilities_entropy     7.8696      4.591      1.714      0.086      -1.128      16.867
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.1148 [0.0582, 0.1713] (n=122)
                  P-value vs 33.3%: 3.596e-14

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=2.02, p=0.0454
Wilcoxon delta_p: statistic=2530.00, p=0.000223
Mean Δp = 0.0109  [0.0003, 0.0214]
Idea 1 N = 127; 

  Idea 1.5: Calibration Metrics
  NLL: 0.0022, Signed ECE (overconf pos under neg): -0.0021, ECE: 0.0021 (n=245)
  Brier: 0.0001, Reliability (absolute calibration error; lower better): 0.0001, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=245)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.991
Model:                            OLS   Adj. R-squared:                  0.991
Method:                 Least Squares   F-statistic:                     7492.
Date:                Wed, 24 Sep 2025   Prob (F-statistic):          2.21e-212
Time:                        16:13:38   Log-Likelihood:                 350.62
No. Observations:                 213   AIC:                            -693.2
Df Residuals:                     209   BIC:                            -679.8
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -2.1474      2.417     -0.889      0.375      -6.912       2.617
p1                    2.1598      2.418      0.893      0.373      -2.608       6.927
answer_changed        2.0311      2.549      0.797      0.426      -2.994       7.056
p1:answer_changed    -1.0448      2.551     -0.410      0.683      -6.074       3.984
==============================================================================
Omnibus:                      367.172   Durbin-Watson:                   2.064
Prob(Omnibus):                  0.000   Jarque-Bera (JB):            66492.417
Skew:                           8.948   Prob(JB):                         0.00
Kurtosis:                      87.686   Cond. No.                     2.36e+03
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The condition number is large, 2.36e+03. This might indicate that there are
strong multicollinearity or other numerical problems.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-3.40, p=0.000916
Wilcoxon delta_H: statistic=2546.00, p=0.00026
Mean ΔH = -0.1781  [-0.2809, -0.0753]
Paired t-test delta_H Changed: statistic=22.80, p=7.24e-45
Wilcoxon delta_H Changed: statistic=28.00, p=8.59e-21
Mean ΔH Changed = 0.9826  [0.8982, 1.0671]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=-1.87, p=0.0628
Wilcoxon (p_top2_game vs p_top2_base): statistic=6776.00, p=8.2e-14
Mean Δp_top2 = -0.0021  [-0.0044, 0.0001] (n=245)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=7.55, p=8.53e-13
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=7692.00, p=3.09e-11
Mean ΔH_unchosen_baseline_set = 0.3809  [0.2821, 0.4798] (n=245)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  245
Model:                          Logit   Df Residuals:                      242
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.03475
Time:                        16:13:38   Log-Likelihood:                -163.76
converged:                       True   LL-Null:                       -169.66
Covariance Type:            nonrobust   LLR p-value:                  0.002753
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.5941      0.326     -1.822      0.068      -1.233       0.045
p1_z             2.3857      1.613      1.479      0.139      -0.776       5.548
I(p1_z ** 2)     3.6155      2.215      1.632      0.103      -0.726       7.956
================================================================================
AUC = 0.587

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  288
Model:                          Logit   Df Residuals:                      286
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                0.001747
Time:                        16:13:38   Log-Likelihood:                -198.83
converged:                       True   LL-Null:                       -199.18
Covariance Type:            nonrobust   LLR p-value:                    0.4042
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.1375      0.122     -1.125      0.261      -0.377       0.102
game_entropy     0.5537      0.676      0.819      0.413      -0.771       1.879
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=11233.00, p=1.3e-11
Paired t-test (game_entropy vs capabilities_entropy): statistic=3.60, p=0.000368
Mean game_entropy-capabilities_entropy = 0.0353  [0.0161, 0.0545] (n=288)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  288
Model:                          Logit   Df Residuals:                      285
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.01462
Time:                        16:13:38   Log-Likelihood:                -196.27
converged:                       True   LL-Null:                       -199.18
Covariance Type:            nonrobust   LLR p-value:                   0.05435
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -0.1884      0.126     -1.494      0.135      -0.435       0.059
capabilities_entropy     7.9329      4.710      1.684      0.092      -1.299      17.165
game_entropy            -0.0462      0.777     -0.059      0.953      -1.569       1.477
========================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  288
Model:                          Logit   Df Residuals:                      286
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                0.003073
Time:                        16:13:38   Log-Likelihood:                -198.57
converged:                       True   LL-Null:                       -199.18
Covariance Type:            nonrobust   LLR p-value:                    0.2685
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -0.6619      0.513     -1.290      0.197      -1.668       0.344
human_difficulty     0.2397      0.217      1.103      0.270      -0.186       0.666
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  288
Model:                          Logit   Df Residuals:                      281
Method:                           MLE   Df Model:                            6
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.01427
Time:                        16:13:38   Log-Likelihood:                -196.34
converged:                       True   LL-Null:                       -199.18
Covariance Type:            nonrobust   LLR p-value:                    0.4595
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -1.3635      1.643     -0.830      0.407      -4.585       1.857
C(domain_grouped)[T.chemistry]        0.0704      0.378      0.186      0.852      -0.671       0.812
C(domain_grouped)[T.physics]         -0.3864      0.357     -1.083      0.279      -1.085       0.313
human_difficulty                      0.2309      0.229      1.009      0.313      -0.218       0.679
q_length                              0.0724      0.205      0.353      0.724      -0.330       0.475
avg_word_length                       0.0633      0.182      0.348      0.728      -0.293       0.419
percent_non_alphabetic_whitespace     0.0195      0.021      0.913      0.361      -0.022       0.061
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 0.0126
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  288
Model:                          Logit   Df Residuals:                      280
Method:                           MLE   Df Model:                            7
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.02501
Time:                        16:13:38   Log-Likelihood:                -194.20
converged:                       True   LL-Null:                       -199.18
Covariance Type:            nonrobust   LLR p-value:                    0.1908
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -1.0963      1.659     -0.661      0.509      -4.348       2.156
C(domain_grouped)[T.chemistry]       -0.0736      0.386     -0.190      0.849      -0.831       0.684
C(domain_grouped)[T.physics]         -0.4033      0.357     -1.129      0.259      -1.104       0.297
human_difficulty                      0.1715      0.232      0.739      0.460      -0.283       0.626
q_length                              0.0308      0.208      0.148      0.882      -0.376       0.438
avg_word_length                       0.0827      0.183      0.452      0.651      -0.276       0.441
percent_non_alphabetic_whitespace     0.0211      0.021      0.981      0.327      -0.021       0.063
capabilities_entropy                  6.8608      4.502      1.524      0.127      -1.962      15.684
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  288
Model:                          Logit   Df Residuals:                      280
Method:                           MLE   Df Model:                            7
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.01515
Time:                        16:13:38   Log-Likelihood:                -196.17
converged:                       True   LL-Null:                       -199.18
Covariance Type:            nonrobust   LLR p-value:                    0.5359
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -1.3410      1.645     -0.815      0.415      -4.565       1.883
C(domain_grouped)[T.chemistry]        0.0396      0.382      0.104      0.918      -0.709       0.788
C(domain_grouped)[T.physics]         -0.3898      0.357     -1.093      0.275      -1.089       0.310
human_difficulty                      0.2197      0.230      0.956      0.339      -0.231       0.670
q_length                              0.0643      0.206      0.312      0.755      -0.339       0.468
avg_word_length                       0.0716      0.182      0.392      0.695      -0.286       0.429
percent_non_alphabetic_whitespace     0.0202      0.021      0.944      0.345      -0.022       0.062
game_entropy                          0.3997      0.682      0.586      0.558      -0.936       1.735
=====================================================================================================

                  Model 4.95: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  288
Model:                          Logit   Df Residuals:                      279
Method:                           MLE   Df Model:                            8
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.02505
Time:                        16:13:38   Log-Likelihood:                -194.19
converged:                       True   LL-Null:                       -199.18
Covariance Type:            nonrobust   LLR p-value:                    0.2665
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -1.1025      1.660     -0.664      0.507      -4.355       2.151
C(domain_grouped)[T.chemistry]       -0.0692      0.388     -0.179      0.858      -0.829       0.691
C(domain_grouped)[T.physics]         -0.4025      0.357     -1.126      0.260      -1.103       0.298
human_difficulty                      0.1732      0.232      0.746      0.456      -0.282       0.629
q_length                              0.0325      0.208      0.156      0.876      -0.375       0.440
avg_word_length                       0.0815      0.183      0.445      0.656      -0.277       0.440
percent_non_alphabetic_whitespace     0.0210      0.022      0.975      0.329      -0.021       0.063
capabilities_entropy                  6.9929      4.610      1.517      0.129      -2.042      16.028
game_entropy                         -0.1027      0.789     -0.130      0.896      -1.648       1.443
=====================================================================================================

--- Analyzing gemini-2.5-flash-lite_think (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/gemini-2.5-flash-lite_think_GPQA_redacted_temp1.0_1758161989_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
1    93
0    66
Name: count, dtype: int64

Answer change%: 0.5849 [0.5083167578154234, 0.6614945629392935] (n=159)
P-value vs 25%: 1.031e-17; P-value vs 0%: 1.186e-50
Phase 2 self-accuracy: 0.5161 [0.41456251894610774, 0.6176955455700213] (n=93)
P-value vs 25%: 2.813e-07; P-value vs 33%: 0.0004095

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  159
Model:                          Logit   Df Residuals:                      157
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.03610
Time:                        16:13:38   Log-Likelihood:                -104.01
converged:                       True   LL-Null:                       -107.91
Covariance Type:            nonrobust   LLR p-value:                  0.005252
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept        148.8903     84.094      1.771      0.077     -15.930     313.711
p_i_capability  -148.7424     84.168     -1.767      0.077    -313.709      16.224
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  159
Model:                          Logit   Df Residuals:                      157
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.03396
Time:                        16:13:38   Log-Likelihood:                -104.24
converged:                       True   LL-Null:                       -107.91
Covariance Type:            nonrobust   LLR p-value:                  0.006782
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept                0.1412      0.183      0.773      0.440      -0.217       0.499
capabilities_entropy    16.9748      9.495      1.788      0.074      -1.636      35.586
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.2024 [0.1165, 0.2883] (n=84)
                  P-value vs 33.3%: 0.002815

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=1.42, p=0.161
Wilcoxon delta_p: statistic=582.00, p=0.0521
Mean Δp = 0.0026  [-0.0010, 0.0062]
Idea 1 N = 57; 

  Idea 1.5: Calibration Metrics
  NLL: 9.3676, Signed ECE (overconf pos under neg): 0.0038, ECE: 0.0038 (n=63)
  Brier: 0.0004, Reliability (absolute calibration error; lower better): 0.0003, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=63)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.995
Model:                            OLS   Adj. R-squared:                  0.995
Method:                 Least Squares   F-statistic:                     7030.
Date:                Wed, 24 Sep 2025   Prob (F-statistic):          4.52e-117
Time:                        16:13:38   Log-Likelihood:                 206.89
No. Observations:                 105   AIC:                            -405.8
Df Residuals:                     101   BIC:                            -395.2
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -1.2052      3.330     -0.362      0.718      -7.810       5.400
p1                    1.2087      3.332      0.363      0.718      -5.401       7.819
answer_changed        0.6853      3.332      0.206      0.837      -5.925       7.296
p1:answer_changed     0.2998      3.335      0.090      0.929      -6.316       6.916
==============================================================================
Omnibus:                      158.988   Durbin-Watson:                   2.096
Prob(Omnibus):                  0.000   Jarque-Bera (JB):             7161.527
Skew:                          -5.655   Prob(JB):                         0.00
Kurtosis:                      41.846   Cond. No.                     3.14e+03
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The condition number is large, 3.14e+03. This might indicate that there are
strong multicollinearity or other numerical problems.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-3.77, p=0.000399
Wilcoxon delta_H: statistic=402.00, p=0.000744
Mean ΔH = -0.2539  [-0.3861, -0.1218]
Paired t-test delta_H Changed: statistic=20.94, p=2.7e-33
Wilcoxon delta_H Changed: statistic=0.00, p=2.46e-14
Mean ΔH Changed = 1.0390  [0.9418, 1.1363]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=-0.27, p=0.788
Wilcoxon (p_top2_game vs p_top2_base): statistic=2833.00, p=0.000175
Mean Δp_top2 = -0.0007  [-0.0061, 0.0046] (n=134)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=7.14, p=5.56e-11
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=1801.00, p=1.5e-09
Mean ΔH_unchosen_baseline_set = 0.4890  [0.3547, 0.6233] (n=134)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  134
Model:                          Logit   Df Residuals:                      131
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.05397
Time:                        16:13:38   Log-Likelihood:                -86.452
converged:                       True   LL-Null:                       -91.384
Covariance Type:            nonrobust   LLR p-value:                  0.007211
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept        1.2404      0.844      1.470      0.142      -0.413       2.894
p1_z           -21.2986     18.287     -1.165      0.244     -57.141      14.544
I(p1_z ** 2)    93.4113    100.027      0.934      0.350    -102.639     289.461
================================================================================
AUC = 0.589

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  159
Model:                          Logit   Df Residuals:                      157
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.01769
Time:                        16:13:38   Log-Likelihood:                -106.00
converged:                       True   LL-Null:                       -107.91
Covariance Type:            nonrobust   LLR p-value:                   0.05069
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept        0.2464      0.169      1.454      0.146      -0.086       0.579
game_entropy     2.5185      1.864      1.351      0.177      -1.135       6.172
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=4685.00, p=0.00397
Paired t-test (game_entropy vs capabilities_entropy): statistic=1.34, p=0.182
Mean game_entropy-capabilities_entropy = 0.0230  [-0.0106, 0.0566] (n=159)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  159
Model:                          Logit   Df Residuals:                      156
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.04629
Time:                        16:13:38   Log-Likelihood:                -102.91
converged:                       True   LL-Null:                       -107.91
Covariance Type:            nonrobust   LLR p-value:                  0.006774
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept                0.0602      0.191      0.315      0.753      -0.315       0.435
capabilities_entropy    16.4703      9.438      1.745      0.081      -2.029      34.969
game_entropy             2.4926      2.028      1.229      0.219      -1.482       6.467
========================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  159
Model:                          Logit   Df Residuals:                      157
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.01728
Time:                        16:13:38   Log-Likelihood:                -106.04
converged:                       True   LL-Null:                       -107.91
Covariance Type:            nonrobust   LLR p-value:                   0.05344
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -0.9854      0.714     -1.380      0.168      -2.385       0.414
human_difficulty     0.5337      0.281      1.897      0.058      -0.018       1.085
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  159
Model:                          Logit   Df Residuals:                      152
Method:                           MLE   Df Model:                            6
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.02296
Time:                        16:13:38   Log-Likelihood:                -105.43
converged:                       True   LL-Null:                       -107.91
Covariance Type:            nonrobust   LLR p-value:                    0.5495
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                             0.1190      2.816      0.042      0.966      -5.400       5.638
C(domain_grouped)[T.chemistry]        0.2347      0.529      0.443      0.658      -0.803       1.272
C(domain_grouped)[T.physics]          0.1084      0.597      0.182      0.856      -1.062       1.279
human_difficulty                      0.5649      0.298      1.898      0.058      -0.018       1.148
q_length                             -0.0234      0.253     -0.093      0.926      -0.519       0.472
avg_word_length                      -0.2421      0.317     -0.764      0.445      -0.863       0.379
percent_non_alphabetic_whitespace    -0.0086      0.033     -0.265      0.791      -0.072       0.055
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 0.0303
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  159
Model:                          Logit   Df Residuals:                      151
Method:                           MLE   Df Model:                            7
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.05025
Time:                        16:13:38   Log-Likelihood:                -102.48
converged:                       True   LL-Null:                       -107.91
Covariance Type:            nonrobust   LLR p-value:                    0.1455
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                             0.5077      2.843      0.179      0.858      -5.064       6.080
C(domain_grouped)[T.chemistry]        0.0497      0.542      0.092      0.927      -1.012       1.111
C(domain_grouped)[T.physics]          0.0168      0.602      0.028      0.978      -1.163       1.196
human_difficulty                      0.4925      0.300      1.640      0.101      -0.096       1.081
q_length                             -0.1101      0.264     -0.417      0.677      -0.628       0.407
avg_word_length                      -0.2012      0.318     -0.632      0.527      -0.825       0.422
percent_non_alphabetic_whitespace    -0.0020      0.033     -0.061      0.951      -0.066       0.062
capabilities_entropy                 15.1199      9.950      1.520      0.129      -4.381      34.621
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  159
Model:                          Logit   Df Residuals:                      151
Method:                           MLE   Df Model:                            7
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.03824
Time:                        16:13:38   Log-Likelihood:                -103.78
converged:                       True   LL-Null:                       -107.91
Covariance Type:            nonrobust   LLR p-value:                    0.3109
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                             0.4053      2.827      0.143      0.886      -5.136       5.947
C(domain_grouped)[T.chemistry]        0.2624      0.530      0.495      0.621      -0.777       1.301
C(domain_grouped)[T.physics]         -0.0153      0.600     -0.026      0.980      -1.192       1.161
human_difficulty                      0.5414      0.299      1.809      0.070      -0.045       1.128
q_length                             -0.0581      0.254     -0.228      0.819      -0.556       0.440
avg_word_length                      -0.2600      0.319     -0.816      0.414      -0.884       0.364
percent_non_alphabetic_whitespace    -0.0108      0.033     -0.330      0.742      -0.075       0.053
game_entropy                          2.6230      1.999      1.312      0.189      -1.295       6.541
=====================================================================================================

                  Model 4.95: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  159
Model:                          Logit   Df Residuals:                      150
Method:                           MLE   Df Model:                            8
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.06156
Time:                        16:13:38   Log-Likelihood:                -101.26
converged:                       True   LL-Null:                       -107.91
Covariance Type:            nonrobust   LLR p-value:                    0.1024
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                             0.8643      2.861      0.302      0.763      -4.743       6.471
C(domain_grouped)[T.chemistry]        0.0774      0.542      0.143      0.887      -0.986       1.141
C(domain_grouped)[T.physics]         -0.0718      0.605     -0.119      0.905      -1.257       1.113
human_difficulty                      0.4772      0.302      1.581      0.114      -0.114       1.069
q_length                             -0.1508      0.266     -0.566      0.571      -0.673       0.371
avg_word_length                      -0.2293      0.320     -0.716      0.474      -0.857       0.399
percent_non_alphabetic_whitespace    -0.0051      0.033     -0.155      0.877      -0.069       0.059
capabilities_entropy                 15.0439      9.866      1.525      0.127      -4.293      34.381
game_entropy                          2.6495      2.190      1.210      0.226      -1.644       6.943
=====================================================================================================

--- Analyzing gemini-2.5-flash-preview-04-17 (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/gemini-2.5-flash-preview-04-17_GPQA_redacted_cor_temp0.0_1751803003_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    240
1     97
Name: count, dtype: int64

Answer change%: 0.2878 [0.2394951544724986, 0.33617250131385157] (n=337)
P-value vs 25%: 0.125; P-value vs 0%: 1.8e-31
Phase 2 self-accuracy: 0.1649 [0.09109122787824837, 0.23880567933824648] (n=97)
P-value vs 25%: 0.02401; P-value vs 33%: 8.211e-06

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  336
Model:                          Logit   Df Residuals:                      334
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.01462
Time:                        16:13:38   Log-Likelihood:                -198.98
converged:                       True   LL-Null:                       -201.93
Covariance Type:            nonrobust   LLR p-value:                   0.01512
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.0049      0.130     -7.759      0.000      -1.259      -0.751
game_entropy     0.9209      0.379      2.433      0.015       0.179       1.663
================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  337
Model:                          Logit   Df Residuals:                      335
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:               2.698e-06
Time:                        16:13:38   Log-Likelihood:                -202.27
converged:                       True   LL-Null:                       -202.27
Covariance Type:            nonrobust   LLR p-value:                    0.9736
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -0.8895      0.510     -1.744      0.081      -1.889       0.110
human_difficulty    -0.0071      0.214     -0.033      0.974      -0.427       0.413
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  337
Model:                          Logit   Df Residuals:                      330
Method:                           MLE   Df Model:                            6
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.03083
Time:                        16:13:38   Log-Likelihood:                -196.03
converged:                       True   LL-Null:                       -202.27
Covariance Type:            nonrobust   LLR p-value:                   0.05226
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -3.3519      1.822     -1.840      0.066      -6.922       0.219
C(domain_grouped)[T.chemistry]        0.7622      0.446      1.708      0.088      -0.112       1.637
C(domain_grouped)[T.physics]          1.1576      0.438      2.645      0.008       0.300       2.016
human_difficulty                      0.1191      0.220      0.541      0.589      -0.313       0.551
q_length                              0.1165      0.209      0.558      0.577      -0.293       0.526
avg_word_length                       0.0852      0.196      0.434      0.664      -0.299       0.469
percent_non_alphabetic_whitespace     0.0280      0.021      1.324      0.186      -0.013       0.069
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  336
Model:                          Logit   Df Residuals:                      328
Method:                           MLE   Df Model:                            7
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.04147
Time:                        16:13:38   Log-Likelihood:                -193.55
converged:                       True   LL-Null:                       -201.93
Covariance Type:            nonrobust   LLR p-value:                   0.01910
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -3.1546      1.831     -1.723      0.085      -6.743       0.433
C(domain_grouped)[T.chemistry]        0.6346      0.453      1.401      0.161      -0.253       1.522
C(domain_grouped)[T.physics]          1.1002      0.441      2.497      0.013       0.237       1.964
human_difficulty                      0.0612      0.223      0.274      0.784      -0.376       0.498
q_length                              0.1040      0.211      0.492      0.622      -0.310       0.518
avg_word_length                       0.0912      0.196      0.464      0.642      -0.294       0.476
percent_non_alphabetic_whitespace     0.0249      0.021      1.170      0.242      -0.017       0.067
game_entropy                          0.7908      0.388      2.038      0.042       0.030       1.551
=====================================================================================================

--- Analyzing gemini-2.5-flash-preview-04-17 (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/gemini-2.5-flash-preview-04-17_GPQA_redacted_temp0.0_1751720035_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
1    55
0    51
Name: count, dtype: int64

Answer change%: 0.5189 [0.42375145415210347, 0.6139843949045003] (n=106)
P-value vs 25%: 3.02e-08; P-value vs 0%: 1.112e-26
Phase 2 self-accuracy: 0.5455 [0.4138609695693659, 0.6770481213397249] (n=55)
P-value vs 25%: 1.08e-05; P-value vs 33%: 0.001554

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  105
Model:                          Logit   Df Residuals:                      103
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:               0.0001199
Time:                        16:13:38   Log-Likelihood:                -72.653
converged:                       True   LL-Null:                       -72.661
Covariance Type:            nonrobust   LLR p-value:                    0.8950
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept        0.1076      0.216      0.497      0.619      -0.316       0.532
game_entropy    -0.0673      0.510     -0.132      0.895      -1.066       0.932
================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  106
Model:                          Logit   Df Residuals:                      104
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:               0.0002191
Time:                        16:13:38   Log-Likelihood:                -73.382
converged:                       True   LL-Null:                       -73.398
Covariance Type:            nonrobust   LLR p-value:                    0.8577
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -0.0799      0.888     -0.090      0.928      -1.821       1.661
human_difficulty     0.0614      0.343      0.179      0.858      -0.610       0.733
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  106
Model:                          Logit   Df Residuals:                       99
Method:                           MLE   Df Model:                            6
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.04391
Time:                        16:13:38   Log-Likelihood:                -70.175
converged:                       True   LL-Null:                       -73.398
Covariance Type:            nonrobust   LLR p-value:                    0.3751
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                             2.5922      3.331      0.778      0.436      -3.937       9.122
C(domain_grouped)[T.chemistry]       -0.1831      0.629     -0.291      0.771      -1.415       1.049
C(domain_grouped)[T.physics]         -0.5180      0.706     -0.734      0.463      -1.901       0.865
human_difficulty                      0.3090      0.379      0.815      0.415      -0.435       1.053
q_length                             -0.2675      0.306     -0.875      0.382      -0.867       0.332
avg_word_length                      -0.3980      0.381     -1.045      0.296      -1.145       0.349
percent_non_alphabetic_whitespace     0.0452      0.045      1.005      0.315      -0.043       0.133
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  105
Model:                          Logit   Df Residuals:                       97
Method:                           MLE   Df Model:                            7
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.04885
Time:                        16:13:38   Log-Likelihood:                -69.112
converged:                       True   LL-Null:                       -72.661
Covariance Type:            nonrobust   LLR p-value:                    0.4186
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                             3.5214      3.434      1.025      0.305      -3.209      10.252
C(domain_grouped)[T.chemistry]       -0.1013      0.648     -0.156      0.876      -1.371       1.168
C(domain_grouped)[T.physics]         -0.5955      0.713     -0.836      0.403      -1.992       0.801
human_difficulty                      0.3363      0.384      0.875      0.381      -0.417       1.089
q_length                             -0.2922      0.308     -0.949      0.343      -0.896       0.312
avg_word_length                      -0.5443      0.402     -1.354      0.176      -1.332       0.244
percent_non_alphabetic_whitespace     0.0307      0.046      0.664      0.507      -0.060       0.121
game_entropy                         -0.2588      0.551     -0.470      0.639      -1.339       0.821
=====================================================================================================

--- Analyzing gemini-2.5-flash_nothink (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/gemini-2.5-flash_nothink_GPQA_redacted_cor_temp1.0_1758161812_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    170
1     48
Name: count, dtype: int64

Answer change%: 0.2202 [0.16517769325735276, 0.2751892792197115] (n=218)
P-value vs 25%: 0.288; P-value vs 0%: 4.31e-15
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=48)
P-value vs 25%: 0; P-value vs 33%: 0

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  218
Model:                          Logit   Df Residuals:                      216
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1296
Time:                        16:13:38   Log-Likelihood:                -100.02
converged:                       True   LL-Null:                       -114.92
Covariance Type:            nonrobust   LLR p-value:                 4.804e-08
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          2.0105      0.624      3.220      0.001       0.787       3.234
p_i_capability    -4.1883      0.803     -5.216      0.000      -5.762      -2.614
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  218
Model:                          Logit   Df Residuals:                      216
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1408
Time:                        16:13:38   Log-Likelihood:                -98.740
converged:                       True   LL-Null:                       -114.92
Covariance Type:            nonrobust   LLR p-value:                 1.285e-08
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.4311      0.313     -7.768      0.000      -3.044      -1.818
capabilities_entropy     1.5067      0.283      5.323      0.000       0.952       2.061
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.6250 [0.4880, 0.7620] (n=48)
                  P-value vs 33.3%: 2.993e-05

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=9.00, p=4.85e-16
Wilcoxon delta_p: statistic=1540.00, p=8.19e-19
Mean Δp = 0.1145  [0.0895, 0.1394]
Idea 1 N = 169; 

  Idea 1.5: Calibration Metrics
  NLL: 0.2317, Signed ECE (overconf pos under neg): -0.1735, ECE: 0.1735 (n=218)
  Brier: 0.0726, Reliability (absolute calibration error; lower better): 0.0718, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=218)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.531
Model:                            OLS   Adj. R-squared:                  0.524
Method:                 Least Squares   F-statistic:                     80.40
Date:                Wed, 24 Sep 2025   Prob (F-statistic):           8.07e-35
Time:                        16:13:38   Log-Likelihood:                 99.863
No. Observations:                 217   AIC:                            -191.7
Df Residuals:                     213   BIC:                            -178.2
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept             0.0228      0.058      0.391      0.697      -0.092       0.138
p1                    0.1051      0.066      1.602      0.111      -0.024       0.234
answer_changed       -0.2526      0.096     -2.637      0.009      -0.441      -0.064
p1:answer_changed     0.8680      0.126      6.910      0.000       0.620       1.116
==============================================================================
Omnibus:                       14.390   Durbin-Watson:                   1.799
Prob(Omnibus):                  0.001   Jarque-Bera (JB):               15.635
Skew:                           0.572   Prob(JB):                     0.000403
Kurtosis:                       3.647   Cond. No.                         21.1
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-4.31, p=2.72e-05
Wilcoxon delta_H: statistic=4568.00, p=2.66e-05
Mean ΔH = -0.1642  [-0.2387, -0.0896]
Paired t-test delta_H Changed: statistic=-1.83, p=0.0732
Wilcoxon delta_H Changed: statistic=403.00, p=0.058
Mean ΔH Changed = -0.1017  [-0.2104, 0.0071]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=-11.74, p=5.99e-25
Wilcoxon (p_top2_game vs p_top2_base): statistic=1140.00, p=5.29e-31
Mean Δp_top2 = -0.0809  [-0.0945, -0.0674] (n=218)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=-4.69, p=4.88e-06
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=7635.00, p=3.98e-06
Mean ΔH_unchosen_baseline_set = -0.1504  [-0.2133, -0.0875] (n=218)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  218
Model:                          Logit   Df Residuals:                      215
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1545
Time:                        16:13:38   Log-Likelihood:                -97.156
converged:                       True   LL-Null:                       -114.92
Covariance Type:            nonrobust   LLR p-value:                 1.936e-08
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.1233      0.234     -4.806      0.000      -1.581      -0.665
p1_z            -1.3991      0.291     -4.810      0.000      -1.969      -0.829
I(p1_z ** 2)    -0.4316      0.182     -2.375      0.018      -0.788      -0.075
================================================================================
AUC = 0.782

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  218
Model:                          Logit   Df Residuals:                      216
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1803
Time:                        16:13:38   Log-Likelihood:                -94.196
converged:                       True   LL-Null:                       -114.92
Covariance Type:            nonrobust   LLR p-value:                 1.214e-10
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -3.7179      0.553     -6.729      0.000      -4.801      -2.635
game_entropy     1.9968      0.371      5.386      0.000       1.270       2.723
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=1591.00, p=1.33e-28
Paired t-test (game_entropy vs capabilities_entropy): statistic=13.34, p=4.95e-30
Mean game_entropy-capabilities_entropy = 0.3989  [0.3403, 0.4575] (n=218)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  218
Model:                          Logit   Df Residuals:                      215
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1889
Time:                        16:13:38   Log-Likelihood:                -93.213
converged:                       True   LL-Null:                       -114.92
Covariance Type:            nonrobust   LLR p-value:                 3.752e-10
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -3.5895      0.549     -6.538      0.000      -4.665      -2.513
capabilities_entropy     0.5451      0.393      1.388      0.165      -0.225       1.315
game_entropy             1.5467      0.485      3.188      0.001       0.596       2.498
========================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  218
Model:                          Logit   Df Residuals:                      216
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:               0.0004477
Time:                        16:13:38   Log-Likelihood:                -114.87
converged:                       True   LL-Null:                       -114.92
Covariance Type:            nonrobust   LLR p-value:                    0.7484
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -1.0321      0.741     -1.392      0.164      -2.485       0.421
human_difficulty    -0.0979      0.305     -0.321      0.749      -0.696       0.501
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  218
Model:                          Logit   Df Residuals:                      211
Method:                           MLE   Df Model:                            6
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.03084
Time:                        16:13:38   Log-Likelihood:                -111.37
converged:                       True   LL-Null:                       -114.92
Covariance Type:            nonrobust   LLR p-value:                    0.3127
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -3.0227      2.445     -1.236      0.216      -7.815       1.770
C(domain_grouped)[T.chemistry]        1.0796      0.525      2.057      0.040       0.051       2.108
C(domain_grouped)[T.physics]          0.6149      0.530      1.161      0.246      -0.423       1.653
human_difficulty                      0.0245      0.314      0.078      0.938      -0.591       0.639
q_length                              0.3539      0.280      1.265      0.206      -0.194       0.902
avg_word_length                      -0.2059      0.276     -0.745      0.456      -0.748       0.336
percent_non_alphabetic_whitespace    -0.0138      0.029     -0.480      0.631      -0.070       0.043
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 0.6210
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  218
Model:                          Logit   Df Residuals:                      210
Method:                           MLE   Df Model:                            7
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1459
Time:                        16:13:38   Log-Likelihood:                -98.145
converged:                       True   LL-Null:                       -114.92
Covariance Type:            nonrobust   LLR p-value:                 2.097e-05
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -3.0390      2.563     -1.186      0.236      -8.062       1.984
C(domain_grouped)[T.chemistry]        0.4030      0.572      0.704      0.481      -0.719       1.525
C(domain_grouped)[T.physics]          0.0484      0.586      0.083      0.934      -1.100       1.197
human_difficulty                     -0.0647      0.347     -0.186      0.852      -0.746       0.616
q_length                              0.0638      0.303      0.210      0.833      -0.531       0.658
avg_word_length                       0.0429      0.282      0.152      0.879      -0.510       0.595
percent_non_alphabetic_whitespace     0.0038      0.029      0.132      0.895      -0.053       0.060
capabilities_entropy                  1.4794      0.309      4.789      0.000       0.874       2.085
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  218
Model:                          Logit   Df Residuals:                      210
Method:                           MLE   Df Model:                            7
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1846
Time:                        16:13:38   Log-Likelihood:                -93.706
converged:                       True   LL-Null:                       -114.92
Covariance Type:            nonrobust   LLR p-value:                 4.315e-07
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -4.2532      2.631     -1.617      0.106      -9.410       0.903
C(domain_grouped)[T.chemistry]        0.3208      0.574      0.559      0.576      -0.804       1.446
C(domain_grouped)[T.physics]          0.1784      0.591      0.302      0.763      -0.981       1.337
human_difficulty                     -0.0847      0.356     -0.238      0.812      -0.782       0.612
q_length                              0.1356      0.298      0.455      0.649      -0.449       0.720
avg_word_length                      -0.0170      0.283     -0.060      0.952      -0.572       0.538
percent_non_alphabetic_whitespace    -0.0154      0.029     -0.539      0.590      -0.071       0.041
game_entropy                          1.9574      0.391      5.009      0.000       1.191       2.723
=====================================================================================================

                  Model 4.95: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  218
Model:                          Logit   Df Residuals:                      209
Method:                           MLE   Df Model:                            8
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1918
Time:                        16:13:38   Log-Likelihood:                -92.872
converged:                       True   LL-Null:                       -114.92
Covariance Type:            nonrobust   LLR p-value:                 5.475e-07
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -3.8997      2.647     -1.473      0.141      -9.089       1.289
C(domain_grouped)[T.chemistry]        0.2315      0.582      0.398      0.691      -0.910       1.373
C(domain_grouped)[T.physics]          0.0364      0.607      0.060      0.952      -1.153       1.226
human_difficulty                     -0.1106      0.360     -0.307      0.759      -0.816       0.595
q_length                              0.0715      0.305      0.234      0.815      -0.526       0.669
avg_word_length                       0.0302      0.285      0.106      0.916      -0.528       0.588
percent_non_alphabetic_whitespace    -0.0096      0.029     -0.332      0.740      -0.066       0.047
capabilities_entropy                  0.5318      0.415      1.280      0.200      -0.282       1.346
game_entropy                          1.5485      0.499      3.104      0.002       0.571       2.526
=====================================================================================================

--- Analyzing gemini-2.5-flash_nothink (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/gemini-2.5-flash_nothink_GPQA_redacted_temp1.0_1758161699_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    144
1     85
Name: count, dtype: int64

Answer change%: 0.3712 [0.30860624113884105, 0.433751837463779] (n=229)
P-value vs 25%: 0.0001472; P-value vs 0%: 3.025e-31
Phase 2 self-accuracy: 0.5059 [0.39959573806129894, 0.6121689678210539] (n=85)
P-value vs 25%: 2.375e-06; P-value vs 33%: 0.001433

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  229
Model:                          Logit   Df Residuals:                      227
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.03339
Time:                        16:13:38   Log-Likelihood:                -146.00
converged:                       True   LL-Null:                       -151.04
Covariance Type:            nonrobust   LLR p-value:                  0.001493
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          0.8154      0.445      1.830      0.067      -0.058       1.689
p_i_capability    -1.9707      0.632     -3.116      0.002      -3.210      -0.731
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  229
Model:                          Logit   Df Residuals:                      227
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.03054
Time:                        16:13:38   Log-Likelihood:                -146.43
converged:                       True   LL-Null:                       -151.04
Covariance Type:            nonrobust   LLR p-value:                  0.002387
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.2556      0.290     -4.331      0.000      -1.824      -0.687
capabilities_entropy     0.6717      0.226      2.967      0.003       0.228       1.115
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.6588 [0.5580, 0.7596] (n=85)
                  P-value vs 33.3%: 2.459e-10

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=10.52, p=1.62e-19
Wilcoxon delta_p: statistic=1089.00, p=1.74e-16
Mean Δp = 0.1519  [0.1236, 0.1803]
Idea 1 N = 144; 

  Idea 1.5: Calibration Metrics
  NLL: 3.1572, Signed ECE (overconf pos under neg): 0.1155, ECE: 0.1155 (n=229)
  Brier: 0.0264, Reliability (absolute calibration error; lower better): 0.0256, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=229)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.643
Model:                            OLS   Adj. R-squared:                  0.638
Method:                 Least Squares   F-statistic:                     133.0
Date:                Wed, 24 Sep 2025   Prob (F-statistic):           2.48e-49
Time:                        16:13:38   Log-Likelihood:                 125.61
No. Observations:                 226   AIC:                            -243.2
Df Residuals:                     222   BIC:                            -229.5
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.0674      0.039     -1.710      0.089      -0.145       0.010
p1                    0.3006      0.052      5.824      0.000       0.199       0.402
answer_changed       -0.1172      0.064     -1.843      0.067      -0.243       0.008
p1:answer_changed     0.6647      0.091      7.298      0.000       0.485       0.844
==============================================================================
Omnibus:                        1.039   Durbin-Watson:                   1.931
Prob(Omnibus):                  0.595   Jarque-Bera (JB):                1.039
Skew:                           0.033   Prob(JB):                        0.595
Kurtosis:                       2.674   Cond. No.                         16.5
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-7.70, p=2.04e-12
Wilcoxon delta_H: statistic=1732.00, p=3.5e-12
Mean ΔH = -0.2450  [-0.3074, -0.1826]
Paired t-test delta_H Changed: statistic=-2.13, p=0.0365
Wilcoxon delta_H Changed: statistic=1294.00, p=0.0194
Mean ΔH Changed = -0.0895  [-0.1721, -0.0069]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=-15.70, p=3.87e-38
Wilcoxon (p_top2_game vs p_top2_base): statistic=1338.00, p=4.58e-32
Mean Δp_top2 = -0.1137  [-0.1279, -0.0995] (n=229)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=-7.25, p=6.26e-12
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=6167.00, p=3.06e-12
Mean ΔH_unchosen_baseline_set = -0.1873  [-0.2379, -0.1367] (n=229)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  229
Model:                          Logit   Df Residuals:                      226
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.04022
Time:                        16:13:38   Log-Likelihood:                -144.97
converged:                       True   LL-Null:                       -151.04
Covariance Type:            nonrobust   LLR p-value:                  0.002301
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.2957      0.226     -1.309      0.191      -0.739       0.147
p1_z            -0.4752      0.147     -3.222      0.001      -0.764      -0.186
I(p1_z ** 2)    -0.2687      0.188     -1.429      0.153      -0.637       0.100
================================================================================
AUC = 0.629

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  229
Model:                          Logit   Df Residuals:                      227
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.03844
Time:                        16:13:38   Log-Likelihood:                -145.24
converged:                       True   LL-Null:                       -151.04
Covariance Type:            nonrobust   LLR p-value:                 0.0006556
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -2.0669      0.517     -4.001      0.000      -3.079      -1.054
game_entropy     1.0348      0.325      3.186      0.001       0.398       1.671
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=2406.00, p=7.99e-27
Paired t-test (game_entropy vs capabilities_entropy): statistic=12.98, p=3.14e-29
Mean game_entropy-capabilities_entropy = 0.4010  [0.3404, 0.4615] (n=229)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  229
Model:                          Logit   Df Residuals:                      226
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.04162
Time:                        16:13:38   Log-Likelihood:                -144.76
converged:                       True   LL-Null:                       -151.04
Covariance Type:            nonrobust   LLR p-value:                  0.001861
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.9812      0.518     -3.823      0.000      -2.997      -0.965
capabilities_entropy     0.2954      0.303      0.976      0.329      -0.298       0.889
game_entropy             0.7618      0.425      1.793      0.073      -0.071       1.594
========================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  229
Model:                          Logit   Df Residuals:                      227
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                0.001200
Time:                        16:13:38   Log-Likelihood:                -150.86
converged:                       True   LL-Null:                       -151.04
Covariance Type:            nonrobust   LLR p-value:                    0.5472
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -0.8481      0.551     -1.538      0.124      -1.929       0.233
human_difficulty     0.1357      0.225      0.602      0.547      -0.306       0.577
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  229
Model:                          Logit   Df Residuals:                      222
Method:                           MLE   Df Model:                            6
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.02444
Time:                        16:13:38   Log-Likelihood:                -147.35
converged:                       True   LL-Null:                       -151.04
Covariance Type:            nonrobust   LLR p-value:                    0.2869
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -2.6255      2.152     -1.220      0.222      -6.843       1.592
C(domain_grouped)[T.chemistry]       -0.1018      0.489     -0.208      0.835      -1.060       0.856
C(domain_grouped)[T.physics]         -0.1662      0.507     -0.328      0.743      -1.160       0.828
human_difficulty                     -0.0354      0.239     -0.148      0.882      -0.504       0.433
q_length                              0.3660      0.230      1.594      0.111      -0.084       0.816
avg_word_length                       0.0935      0.239      0.391      0.696      -0.375       0.562
percent_non_alphabetic_whitespace    -0.0359      0.030     -1.184      0.236      -0.095       0.024
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 1.0479
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  229
Model:                          Logit   Df Residuals:                      221
Method:                           MLE   Df Model:                            7
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.05967
Time:                        16:13:38   Log-Likelihood:                -142.03
converged:                       True   LL-Null:                       -151.04
Covariance Type:            nonrobust   LLR p-value:                   0.01186
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -3.6577      2.297     -1.593      0.111      -8.159       0.843
C(domain_grouped)[T.chemistry]       -0.4089      0.509     -0.803      0.422      -1.407       0.589
C(domain_grouped)[T.physics]         -0.4409      0.525     -0.840      0.401      -1.470       0.588
human_difficulty                     -0.0717      0.245     -0.293      0.769      -0.551       0.408
q_length                              0.3541      0.236      1.499      0.134      -0.109       0.817
avg_word_length                       0.2148      0.265      0.811      0.417      -0.304       0.734
percent_non_alphabetic_whitespace    -0.0286      0.032     -0.891      0.373      -0.091       0.034
capabilities_entropy                  0.7662      0.243      3.154      0.002       0.290       1.242
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  229
Model:                          Logit   Df Residuals:                      221
Method:                           MLE   Df Model:                            7
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.07086
Time:                        16:13:38   Log-Likelihood:                -140.34
converged:                       True   LL-Null:                       -151.04
Covariance Type:            nonrobust   LLR p-value:                  0.003212
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -3.9327      2.314     -1.700      0.089      -8.467       0.602
C(domain_grouped)[T.chemistry]       -0.6579      0.537     -1.225      0.221      -1.711       0.395
C(domain_grouped)[T.physics]         -0.6698      0.552     -1.213      0.225      -1.752       0.412
human_difficulty                     -0.0429      0.244     -0.176      0.861      -0.521       0.436
q_length                              0.2928      0.239      1.223      0.221      -0.177       0.762
avg_word_length                       0.1731      0.261      0.663      0.508      -0.339       0.685
percent_non_alphabetic_whitespace    -0.0354      0.033     -1.087      0.277      -0.099       0.028
game_entropy                          1.2487      0.361      3.460      0.001       0.541       1.956
=====================================================================================================

                  Model 4.95: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  229
Model:                          Logit   Df Residuals:                      220
Method:                           MLE   Df Model:                            8
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.07490
Time:                        16:13:38   Log-Likelihood:                -139.73
converged:                       True   LL-Null:                       -151.04
Covariance Type:            nonrobust   LLR p-value:                  0.003879
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -4.1134      2.351     -1.750      0.080      -8.721       0.494
C(domain_grouped)[T.chemistry]       -0.6586      0.536     -1.230      0.219      -1.708       0.391
C(domain_grouped)[T.physics]         -0.6692      0.550     -1.217      0.224      -1.747       0.409
human_difficulty                     -0.0547      0.245     -0.223      0.824      -0.535       0.426
q_length                              0.3065      0.240      1.277      0.202      -0.164       0.777
avg_word_length                       0.2137      0.271      0.790      0.430      -0.317       0.744
percent_non_alphabetic_whitespace    -0.0323      0.033     -0.981      0.327      -0.097       0.032
capabilities_entropy                  0.3417      0.311      1.098      0.272      -0.268       0.951
game_entropy                          0.9429      0.451      2.089      0.037       0.058       1.828
=====================================================================================================

--- Analyzing gemini-2.5-flash_think (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/gemini-2.5-flash_think_GPQA_redacted_cor_temp1.0_1758262922_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    280
1     55
Name: count, dtype: int64

Answer change%: 0.1642 [0.12451101895488054, 0.20384719000034335] (n=335)
P-value vs 25%: 2.232e-05; P-value vs 0%: 4.982e-16
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=55)
P-value vs 25%: 0; P-value vs 33%: 0

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  310
Model:                          Logit   Df Residuals:                      308
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                0.001033
Time:                        16:13:38   Log-Likelihood:                -140.06
converged:                       True   LL-Null:                       -140.21
Covariance Type:            nonrobust   LLR p-value:                    0.5905
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept         -1.0631      0.992     -1.072      0.284      -3.007       0.880
p_i_capability    -0.5794      1.058     -0.547      0.584      -2.654       1.495
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  335
Model:                          Logit   Df Residuals:                      333
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:               0.0009671
Time:                        16:13:38   Log-Likelihood:                -149.44
converged:                       True   LL-Null:                       -149.59
Covariance Type:            nonrobust   LLR p-value:                    0.5907
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.6781      0.177     -9.507      0.000      -2.024      -1.332
capabilities_entropy     0.1721      0.316      0.544      0.587      -0.448       0.792
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.1154 [0.0285, 0.2022] (n=52)
                  P-value vs 33.3%: 8.685e-07

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=3.80, p=0.00018
Wilcoxon delta_p: statistic=14553.00, p=0.568
Mean Δp = 0.0505  [0.0245, 0.0765]
Idea 1 N = 246; 

  Idea 1.5: Calibration Metrics
  NLL: 0.4692, Signed ECE (overconf pos under neg): -0.1469, ECE: 0.1469 (n=309)
  Brier: 0.1169, Reliability (absolute calibration error; lower better): 0.1166, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=309)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.719
Model:                            OLS   Adj. R-squared:                  0.716
Method:                 Least Squares   F-statistic:                     237.4
Date:                Wed, 24 Sep 2025   Prob (F-statistic):           2.36e-76
Time:                        16:13:38   Log-Likelihood:                 75.870
No. Observations:                 282   AIC:                            -143.7
Df Residuals:                     278   BIC:                            -129.2
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept             0.5617      0.091      6.203      0.000       0.383       0.740
p1                   -0.5407      0.095     -5.695      0.000      -0.728      -0.354
answer_changed       -0.6740      0.226     -2.988      0.003      -1.118      -0.230
p1:answer_changed     1.6400      0.241      6.804      0.000       1.165       2.115
==============================================================================
Omnibus:                      104.833   Durbin-Watson:                   1.986
Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1260.420
Skew:                           1.129   Prob(JB):                    2.01e-274
Kurtosis:                      13.108   Cond. No.                         41.8
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=1.67, p=0.0954
Wilcoxon delta_H: statistic=14471.00, p=0.0775
Mean ΔH = 0.0631  [-0.0108, 0.1370]
Paired t-test delta_H Changed: statistic=7.85, p=2.48e-10
Wilcoxon delta_H Changed: statistic=97.00, p=7e-08
Mean ΔH Changed = 0.7040  [0.5283, 0.8798]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=3.76, p=0.000203
Wilcoxon (p_top2_game vs p_top2_base): statistic=17450.00, p=3.57e-05
Mean Δp_top2 = 0.0093  [0.0045, 0.0141] (n=309)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=4.58, p=6.77e-06
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=17164.00, p=1.59e-05
Mean ΔH_unchosen_baseline_set = 0.1710  [0.0978, 0.2441] (n=309)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  309
Model:                          Logit   Df Residuals:                      306
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                0.003790
Time:                        16:13:38   Log-Likelihood:                -139.49
converged:                       True   LL-Null:                       -140.03
Covariance Type:            nonrobust   LLR p-value:                    0.5882
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.4812      0.202     -7.315      0.000      -1.878      -1.084
p1_z            -0.3519      0.340     -1.036      0.300      -1.018       0.314
I(p1_z ** 2)    -0.1243      0.145     -0.855      0.392      -0.409       0.161
================================================================================
AUC = 0.533

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  335
Model:                          Logit   Df Residuals:                      333
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.02822
Time:                        16:13:38   Log-Likelihood:                -145.37
converged:                       True   LL-Null:                       -149.59
Covariance Type:            nonrobust   LLR p-value:                  0.003666
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.8548      0.174    -10.632      0.000      -2.197      -1.513
game_entropy     1.2174      0.403      3.021      0.003       0.427       2.007
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=19370.00, p=7.67e-07
Paired t-test (game_entropy vs capabilities_entropy): statistic=-5.43, p=1.1e-07
Mean game_entropy-capabilities_entropy = -0.1337  [-0.1820, -0.0854] (n=335)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  335
Model:                          Logit   Df Residuals:                      332
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.02914
Time:                        16:13:38   Log-Likelihood:                -145.23
converged:                       True   LL-Null:                       -149.59
Covariance Type:            nonrobust   LLR p-value:                   0.01279
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.8171      0.187     -9.695      0.000      -2.184      -1.450
capabilities_entropy    -0.1864      0.359     -0.519      0.604      -0.890       0.517
game_entropy             1.3069      0.439      2.977      0.003       0.446       2.167
========================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  335
Model:                          Logit   Df Residuals:                      333
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:               0.0005827
Time:                        16:13:38   Log-Likelihood:                -149.50
converged:                       True   LL-Null:                       -149.59
Covariance Type:            nonrobust   LLR p-value:                    0.6763
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -1.8810      0.627     -3.001      0.003      -3.110      -0.652
human_difficulty     0.1086      0.260      0.418      0.676      -0.400       0.618
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  335
Model:                          Logit   Df Residuals:                      328
Method:                           MLE   Df Model:                            6
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.05542
Time:                        16:13:38   Log-Likelihood:                -141.30
converged:                       True   LL-Null:                       -149.59
Covariance Type:            nonrobust   LLR p-value:                   0.01095
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                             0.4365      2.051      0.213      0.831      -3.583       4.456
C(domain_grouped)[T.chemistry]        0.3655      0.492      0.742      0.458      -0.600       1.331
C(domain_grouped)[T.physics]         -0.1663      0.501     -0.332      0.740      -1.148       0.816
human_difficulty                      0.2808      0.287      0.979      0.327      -0.281       0.843
q_length                             -0.7008      0.248     -2.820      0.005      -1.188      -0.214
avg_word_length                       0.2129      0.212      1.005      0.315      -0.202       0.628
percent_non_alphabetic_whitespace     0.0330      0.024      1.371      0.170      -0.014       0.080
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 0.2824
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  335
Model:                          Logit   Df Residuals:                      327
Method:                           MLE   Df Model:                            7
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.05618
Time:                        16:13:38   Log-Likelihood:                -141.19
converged:                       True   LL-Null:                       -149.59
Covariance Type:            nonrobust   LLR p-value:                   0.01869
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                             0.5654      2.063      0.274      0.784      -3.478       4.609
C(domain_grouped)[T.chemistry]        0.2991      0.513      0.583      0.560      -0.707       1.305
C(domain_grouped)[T.physics]         -0.1982      0.508     -0.390      0.696      -1.194       0.797
human_difficulty                      0.2483      0.294      0.843      0.399      -0.329       0.825
q_length                             -0.7200      0.252     -2.855      0.004      -1.214      -0.226
avg_word_length                       0.2225      0.211      1.053      0.292      -0.192       0.637
percent_non_alphabetic_whitespace     0.0336      0.024      1.398      0.162      -0.013       0.081
capabilities_entropy                  0.1693      0.353      0.479      0.632      -0.523       0.862
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  335
Model:                          Logit   Df Residuals:                      327
Method:                           MLE   Df Model:                            7
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.07833
Time:                        16:13:38   Log-Likelihood:                -137.87
converged:                       True   LL-Null:                       -149.59
Covariance Type:            nonrobust   LLR p-value:                  0.001431
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                             1.4135      2.138      0.661      0.509      -2.777       5.604
C(domain_grouped)[T.chemistry]        0.0792      0.518      0.153      0.878      -0.936       1.094
C(domain_grouped)[T.physics]         -0.2636      0.517     -0.510      0.610      -1.277       0.750
human_difficulty                      0.1935      0.293      0.661      0.509      -0.380       0.767
q_length                             -0.7978      0.258     -3.095      0.002      -1.303      -0.293
avg_word_length                       0.1615      0.218      0.740      0.459      -0.266       0.589
percent_non_alphabetic_whitespace     0.0290      0.024      1.189      0.234      -0.019       0.077
game_entropy                          1.1966      0.453      2.641      0.008       0.308       2.085
=====================================================================================================

                  Model 4.95: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  335
Model:                          Logit   Df Residuals:                      326
Method:                           MLE   Df Model:                            8
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.07881
Time:                        16:13:38   Log-Likelihood:                -137.80
converged:                       True   LL-Null:                       -149.59
Covariance Type:            nonrobust   LLR p-value:                  0.002697
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                             1.3613      2.152      0.633      0.527      -2.856       5.579
C(domain_grouped)[T.chemistry]        0.1212      0.530      0.229      0.819      -0.917       1.159
C(domain_grouped)[T.physics]         -0.2428      0.519     -0.468      0.640      -1.260       0.774
human_difficulty                      0.2170      0.300      0.724      0.469      -0.371       0.805
q_length                             -0.7872      0.259     -3.037      0.002      -1.295      -0.279
avg_word_length                       0.1502      0.222      0.676      0.499      -0.285       0.586
percent_non_alphabetic_whitespace     0.0282      0.025      1.150      0.250      -0.020       0.076
capabilities_entropy                 -0.1473      0.395     -0.373      0.709      -0.921       0.626
game_entropy                          1.2575      0.483      2.606      0.009       0.312       2.203
=====================================================================================================

--- Analyzing gemini-2.5-flash_think (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/gemini-2.5-flash_think_GPQA_redacted_temp1.0_1758250419_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    63
1    49
Name: count, dtype: int64

Answer change%: 0.4375 [0.34562668822468495, 0.529373311775315] (n=112)
P-value vs 25%: 6.334e-05; P-value vs 0%: 1.026e-20
Phase 2 self-accuracy: 0.7755 [0.6586835034090578, 0.8923369047542075] (n=49)
P-value vs 25%: 1.183e-18; P-value vs 33%: 1.138e-13

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  101
Model:                          Logit   Df Residuals:                       99
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.01211
Time:                        16:13:38   Log-Likelihood:                -68.331
converged:                       True   LL-Null:                       -69.169
Covariance Type:            nonrobust   LLR p-value:                    0.1955
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          1.3282      1.258      1.056      0.291      -1.137       3.794
p_i_capability    -1.7538      1.372     -1.279      0.201      -4.442       0.934
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  112
Model:                          Logit   Df Residuals:                      110
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.01568
Time:                        16:13:38   Log-Likelihood:                -75.552
converged:                       True   LL-Null:                       -76.755
Covariance Type:            nonrobust   LLR p-value:                    0.1208
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -0.4928      0.249     -1.979      0.048      -0.981      -0.005
capabilities_entropy     0.5910      0.384      1.539      0.124      -0.162       1.344
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.0682 [0.0000, 0.1427] (n=44)
                  P-value vs 33.3%: 2.998e-12

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=2.87, p=0.00587
Wilcoxon delta_p: statistic=448.00, p=0.0282
Mean Δp = 0.1072  [0.0341, 0.1803]
Idea 1 N = 53; 

  Idea 1.5: Calibration Metrics
  NLL: 10.3454, Signed ECE (overconf pos under neg): 0.0076, ECE: 0.0076 (n=38)
  Brier: 0.0018, Reliability (absolute calibration error; lower better): 0.0018, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=38)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.740
Model:                            OLS   Adj. R-squared:                  0.729
Method:                 Least Squares   F-statistic:                     70.14
Date:                Wed, 24 Sep 2025   Prob (F-statistic):           1.39e-21
Time:                        16:13:38   Log-Likelihood:                 6.5415
No. Observations:                  78   AIC:                            -5.083
Df Residuals:                      74   BIC:                             4.344
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept             0.5266      0.263      2.000      0.049       0.002       1.051
p1                   -0.4467      0.278     -1.604      0.113      -1.001       0.108
answer_changed       -0.8250      0.426     -1.938      0.056      -1.673       0.023
p1:answer_changed     1.7451      0.459      3.805      0.000       0.831       2.659
==============================================================================
Omnibus:                       25.293   Durbin-Watson:                   2.004
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               50.498
Skew:                           1.144   Prob(JB):                     1.08e-11
Kurtosis:                       6.209   Cond. No.                         37.9
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=2.08, p=0.0425
Wilcoxon delta_H: statistic=567.00, p=0.0392
Mean ΔH = 0.1703  [0.0095, 0.3310]
Paired t-test delta_H Changed: statistic=6.19, p=1.92e-07
Wilcoxon delta_H Changed: statistic=100.00, p=5.44e-07
Mean ΔH Changed = 0.5713  [0.3905, 0.7522]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=0.72, p=0.473
Wilcoxon (p_top2_game vs p_top2_base): statistic=1876.00, p=0.0178
Mean Δp_top2 = 0.0055  [-0.0095, 0.0205] (n=101)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=5.38, p=4.98e-07
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=1162.00, p=1.68e-06
Mean ΔH_unchosen_baseline_set = 0.3450  [0.2192, 0.4707] (n=101)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  101
Model:                          Logit   Df Residuals:                       98
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.01636
Time:                        16:13:38   Log-Likelihood:                -68.037
converged:                       True   LL-Null:                       -69.169
Covariance Type:            nonrobust   LLR p-value:                    0.3225
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.1335      0.263     -0.508      0.611      -0.648       0.381
p1_z            -0.4782      0.350     -1.366      0.172      -1.164       0.208
I(p1_z ** 2)    -0.1292      0.169     -0.766      0.444      -0.460       0.201
================================================================================
AUC = 0.632

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  112
Model:                          Logit   Df Residuals:                      110
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:               0.0002787
Time:                        16:13:38   Log-Likelihood:                -76.734
converged:                       True   LL-Null:                       -76.755
Covariance Type:            nonrobust   LLR p-value:                    0.8361
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.2262      0.226     -1.002      0.316      -0.669       0.216
game_entropy    -0.0944      0.457     -0.206      0.836      -0.991       0.802
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=2629.00, p=0.12
Paired t-test (game_entropy vs capabilities_entropy): statistic=-2.36, p=0.0199
Mean game_entropy-capabilities_entropy = -0.1356  [-0.2481, -0.0231] (n=112)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  112
Model:                          Logit   Df Residuals:                      109
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.01692
Time:                        16:13:38   Log-Likelihood:                -75.456
converged:                       True   LL-Null:                       -76.755
Covariance Type:            nonrobust   LLR p-value:                    0.2728
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -0.4485      0.268     -1.672      0.095      -0.974       0.077
capabilities_entropy     0.6165      0.390      1.582      0.114      -0.147       1.380
game_entropy            -0.2043      0.469     -0.435      0.663      -1.124       0.716
========================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  112
Model:                          Logit   Df Residuals:                      110
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.03711
Time:                        16:13:38   Log-Likelihood:                -73.907
converged:                       True   LL-Null:                       -76.755
Covariance Type:            nonrobust   LLR p-value:                   0.01699
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept            1.8198      0.916      1.987      0.047       0.025       3.615
human_difficulty    -0.8302      0.362     -2.295      0.022      -1.539      -0.121
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  112
Model:                          Logit   Df Residuals:                      105
Method:                           MLE   Df Model:                            6
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.04573
Time:                        16:13:38   Log-Likelihood:                -73.245
converged:                       True   LL-Null:                       -76.755
Covariance Type:            nonrobust   LLR p-value:                    0.3190
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                             2.5418      3.285      0.774      0.439      -3.897       8.980
C(domain_grouped)[T.chemistry]        0.3078      0.583      0.528      0.598      -0.836       1.451
C(domain_grouped)[T.physics]          0.2576      0.678      0.380      0.704      -1.072       1.587
human_difficulty                     -0.8097      0.385     -2.100      0.036      -1.565      -0.054
q_length                              0.0661      0.300      0.220      0.826      -0.522       0.654
avg_word_length                      -0.2780      0.390     -0.712      0.476      -1.043       0.487
percent_non_alphabetic_whitespace    -0.0111      0.039     -0.283      0.778      -0.088       0.066
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 0.4028
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  112
Model:                          Logit   Df Residuals:                      104
Method:                           MLE   Df Model:                            7
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.05342
Time:                        16:13:38   Log-Likelihood:                -72.655
converged:                       True   LL-Null:                       -76.755
Covariance Type:            nonrobust   LLR p-value:                    0.3153
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                             2.6732      3.298      0.811      0.418      -3.790       9.136
C(domain_grouped)[T.chemistry]        0.1092      0.615      0.177      0.859      -1.097       1.315
C(domain_grouped)[T.physics]          0.2142      0.683      0.314      0.754      -1.125       1.553
human_difficulty                     -0.7986      0.386     -2.070      0.038      -1.555      -0.042
q_length                              0.0146      0.306      0.048      0.962      -0.585       0.614
avg_word_length                      -0.2581      0.393     -0.657      0.511      -1.028       0.512
percent_non_alphabetic_whitespace    -0.0130      0.040     -0.326      0.744      -0.091       0.065
capabilities_entropy                  0.4630      0.429      1.080      0.280      -0.377       1.303
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  112
Model:                          Logit   Df Residuals:                      104
Method:                           MLE   Df Model:                            7
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.04807
Time:                        16:13:38   Log-Likelihood:                -73.066
converged:                       True   LL-Null:                       -76.755
Covariance Type:            nonrobust   LLR p-value:                    0.3905
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                             2.2731      3.319      0.685      0.493      -4.231       8.777
C(domain_grouped)[T.chemistry]        0.4033      0.605      0.667      0.505      -0.782       1.588
C(domain_grouped)[T.physics]          0.3275      0.688      0.476      0.634      -1.020       1.675
human_difficulty                     -0.8029      0.387     -2.077      0.038      -1.560      -0.045
q_length                              0.0914      0.303      0.302      0.763      -0.503       0.685
avg_word_length                      -0.2625      0.393     -0.669      0.504      -1.032       0.507
percent_non_alphabetic_whitespace    -0.0064      0.040     -0.159      0.873      -0.085       0.073
game_entropy                         -0.2996      0.502     -0.597      0.551      -1.284       0.684
=====================================================================================================

                  Model 4.95: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  112
Model:                          Logit   Df Residuals:                      103
Method:                           MLE   Df Model:                            8
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.05594
Time:                        16:13:38   Log-Likelihood:                -72.462
converged:                       True   LL-Null:                       -76.755
Covariance Type:            nonrobust   LLR p-value:                    0.3783
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                             2.3985      3.329      0.720      0.471      -4.127       8.924
C(domain_grouped)[T.chemistry]        0.2059      0.634      0.325      0.745      -1.038       1.449
C(domain_grouped)[T.physics]          0.2863      0.692      0.414      0.679      -1.070       1.643
human_difficulty                     -0.7906      0.387     -2.044      0.041      -1.549      -0.032
q_length                              0.0404      0.309      0.131      0.896      -0.564       0.645
avg_word_length                      -0.2429      0.395     -0.615      0.538      -1.017       0.531
percent_non_alphabetic_whitespace    -0.0081      0.041     -0.199      0.842      -0.088       0.071
capabilities_entropy                  0.4697      0.430      1.092      0.275      -0.373       1.313
game_entropy                         -0.3121      0.503     -0.620      0.535      -1.298       0.674
=====================================================================================================

--- Analyzing gpt-4.1-2025-04-14 (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/gpt-4.1-2025-04-14_GPQA_redacted_cor_temp1.0_1757988295_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    155
1     63
Name: count, dtype: int64

Answer change%: 0.2890 [0.22881812910545582, 0.3491635222706909] (n=218)
P-value vs 25%: 0.2041; P-value vs 0%: 4.817e-21
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=63)
P-value vs 25%: 0; P-value vs 33%: 0

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  218
Model:                          Logit   Df Residuals:                      216
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.08131
Time:                        16:13:38   Log-Likelihood:                -120.41
converged:                       True   LL-Null:                       -131.07
Covariance Type:            nonrobust   LLR p-value:                 3.895e-06
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          3.1438      0.937      3.354      0.001       1.307       4.981
p_i_capability    -4.3933      1.004     -4.375      0.000      -6.361      -2.425
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  218
Model:                          Logit   Df Residuals:                      216
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.09906
Time:                        16:13:38   Log-Likelihood:                -118.09
converged:                       True   LL-Null:                       -131.07
Covariance Type:            nonrobust   LLR p-value:                 3.469e-07
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.3305      0.184     -7.222      0.000      -1.692      -0.969
capabilities_entropy     1.7331      0.363      4.773      0.000       1.021       2.445
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.3143 [0.1605, 0.4681] (n=35)
                  P-value vs 33.3%: 0.8082

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=5.01, p=0.000128
Wilcoxon delta_p: statistic=8.00, p=0.00192
Mean Δp = 0.5488  [0.3341, 0.7635]
Idea 1 N = 17; 

  Idea 1.5: Calibration Metrics
  NLL: 3.5374, Signed ECE (overconf pos under neg): -0.0150, ECE: 0.3527 (n=39)
  Brier: 0.3445, Reliability (absolute calibration error; lower better): 0.1436, Resolution (relative calibration quality; higher better): 0.0471, Uncertainty: 0.2459 (n=39)
  AUROC: 0.5588

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.278
Model:                            OLS   Adj. R-squared:                  0.216
Method:                 Least Squares   F-statistic:                     4.498
Date:                Wed, 24 Sep 2025   Prob (F-statistic):            0.00902
Time:                        16:13:38   Log-Likelihood:                -17.667
No. Observations:                  39   AIC:                             43.33
Df Residuals:                      35   BIC:                             49.99
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.0291      0.473     -0.062      0.951      -0.989       0.931
p1                    0.6664      0.534      1.249      0.220      -0.417       1.750
answer_changed       -0.4067      0.557     -0.729      0.471      -1.538       0.725
p1:answer_changed     0.6553      0.657      0.998      0.325      -0.678       1.989
==============================================================================
Omnibus:                        7.631   Durbin-Watson:                   2.220
Prob(Omnibus):                  0.022   Jarque-Bera (JB):                7.862
Skew:                          -1.079   Prob(JB):                       0.0196
Kurtosis:                       2.569   Cond. No.                         24.7
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-0.69, p=0.5
Wilcoxon delta_H: statistic=64.00, p=0.579
Mean ΔH = -0.1074  [-0.4128, 0.1979]
Paired t-test delta_H Changed: statistic=2.28, p=0.0331
Wilcoxon delta_H Changed: statistic=72.00, p=0.0794
Mean ΔH Changed = 0.2469  [0.0347, 0.4590]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=1.67, p=0.102
Wilcoxon (p_top2_game vs p_top2_base): statistic=267.00, p=0.0875
Mean Δp_top2 = 0.0219  [-0.0037, 0.0476] (n=39)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=0.98, p=0.334
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=323.00, p=0.357
Mean ΔH_unchosen_baseline_set = 0.0924  [-0.0927, 0.2775] (n=39)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                   39
Model:                          Logit   Df Residuals:                       36
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.06675
Time:                        16:13:38   Log-Likelihood:                -24.928
converged:                       True   LL-Null:                       -26.711
Covariance Type:            nonrobust   LLR p-value:                    0.1681
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept        0.3138      0.687      0.457      0.648      -1.033       1.661
p1_z            -0.6549      0.471     -1.391      0.164      -1.578       0.268
I(p1_z ** 2)    -0.0187      0.617     -0.030      0.976      -1.227       1.190
================================================================================
AUC = 0.671

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  218
Model:                          Logit   Df Residuals:                      216
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.07878
Time:                        16:13:38   Log-Likelihood:                -120.75
converged:                       True   LL-Null:                       -131.07
Covariance Type:            nonrobust   LLR p-value:                 5.509e-06
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.2635      0.180     -7.032      0.000      -1.616      -0.911
game_entropy     1.9515      0.452      4.316      0.000       1.065       2.838
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=5054.00, p=0.254
Paired t-test (game_entropy vs capabilities_entropy): statistic=-1.73, p=0.0857
Mean game_entropy-capabilities_entropy = -0.0521  [-0.1112, 0.0071] (n=218)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  218
Model:                          Logit   Df Residuals:                      215
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1383
Time:                        16:13:38   Log-Likelihood:                -112.94
converged:                       True   LL-Null:                       -131.07
Covariance Type:            nonrobust   LLR p-value:                 1.334e-08
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.5402      0.204     -7.542      0.000      -1.940      -1.140
capabilities_entropy     1.4626      0.382      3.830      0.000       0.714       2.211
game_entropy             1.5306      0.485      3.153      0.002       0.579       2.482
========================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  218
Model:                          Logit   Df Residuals:                      216
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:               0.0005544
Time:                        16:13:38   Log-Likelihood:                -131.00
converged:                       True   LL-Null:                       -131.07
Covariance Type:            nonrobust   LLR p-value:                    0.7030
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -0.6641      0.636     -1.044      0.296      -1.910       0.582
human_difficulty    -0.0998      0.262     -0.381      0.703      -0.613       0.414
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  218
Model:                          Logit   Df Residuals:                      211
Method:                           MLE   Df Model:                            6
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.03971
Time:                        16:13:38   Log-Likelihood:                -125.87
converged:                       True   LL-Null:                       -131.07
Covariance Type:            nonrobust   LLR p-value:                    0.1084
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -0.0536      2.403     -0.022      0.982      -4.764       4.657
C(domain_grouped)[T.chemistry]        0.9806      0.459      2.138      0.032       0.082       1.879
C(domain_grouped)[T.physics]          0.1418      0.448      0.316      0.752      -0.737       1.020
human_difficulty                     -0.0374      0.278     -0.135      0.893      -0.582       0.507
q_length                              0.3364      0.255      1.321      0.186      -0.163       0.836
avg_word_length                      -0.5937      0.314     -1.893      0.058      -1.209       0.021
percent_non_alphabetic_whitespace    -0.0536      0.034     -1.572      0.116      -0.120       0.013
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 0.2120
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  218
Model:                          Logit   Df Residuals:                      210
Method:                           MLE   Df Model:                            7
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1123
Time:                        16:13:38   Log-Likelihood:                -116.35
converged:                       True   LL-Null:                       -131.07
Covariance Type:            nonrobust   LLR p-value:                 0.0001203
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -1.4795      2.557     -0.579      0.563      -6.491       3.532
C(domain_grouped)[T.chemistry]        0.4219      0.498      0.848      0.396      -0.553       1.397
C(domain_grouped)[T.physics]         -0.1110      0.474     -0.234      0.815      -1.040       0.818
human_difficulty                     -0.0663      0.292     -0.227      0.820      -0.639       0.506
q_length                              0.3205      0.269      1.189      0.234      -0.208       0.849
avg_word_length                      -0.3214      0.328     -0.980      0.327      -0.964       0.322
percent_non_alphabetic_whitespace    -0.0232      0.036     -0.643      0.520      -0.094       0.048
capabilities_entropy                  1.5812      0.382      4.138      0.000       0.832       2.330
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  218
Model:                          Logit   Df Residuals:                      210
Method:                           MLE   Df Model:                            7
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1037
Time:                        16:13:38   Log-Likelihood:                -117.48
converged:                       True   LL-Null:                       -131.07
Covariance Type:            nonrobust   LLR p-value:                 0.0003093
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -0.4769      2.513     -0.190      0.849      -5.402       4.449
C(domain_grouped)[T.chemistry]        0.8357      0.479      1.746      0.081      -0.102       1.774
C(domain_grouped)[T.physics]          0.0259      0.466      0.056      0.956      -0.888       0.940
human_difficulty                     -0.0188      0.291     -0.064      0.949      -0.590       0.552
q_length                              0.2244      0.264      0.851      0.395      -0.292       0.741
avg_word_length                      -0.4274      0.318     -1.342      0.180      -1.052       0.197
percent_non_alphabetic_whitespace    -0.0488      0.036     -1.358      0.174      -0.119       0.022
game_entropy                          1.8207      0.464      3.924      0.000       0.911       2.730
=====================================================================================================

                  Model 4.95: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  218
Model:                          Logit   Df Residuals:                      209
Method:                           MLE   Df Model:                            8
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1482
Time:                        16:13:38   Log-Likelihood:                -111.65
converged:                       True   LL-Null:                       -131.07
Covariance Type:            nonrobust   LLR p-value:                 5.260e-06
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -1.5115      2.627     -0.575      0.565      -6.660       3.637
C(domain_grouped)[T.chemistry]        0.3892      0.511      0.762      0.446      -0.612       1.391
C(domain_grouped)[T.physics]         -0.1698      0.486     -0.349      0.727      -1.123       0.784
human_difficulty                     -0.0507      0.303     -0.167      0.867      -0.644       0.543
q_length                              0.2210      0.274      0.807      0.419      -0.316       0.758
avg_word_length                      -0.2297      0.329     -0.697      0.486      -0.875       0.416
percent_non_alphabetic_whitespace    -0.0246      0.038     -0.655      0.513      -0.098       0.049
capabilities_entropy                  1.3395      0.403      3.325      0.001       0.550       2.129
game_entropy                          1.4893      0.494      3.012      0.003       0.520       2.458
=====================================================================================================

--- Analyzing gpt-4.1-2025-04-14 (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/gpt-4.1-2025-04-14_GPQA_redacted_temp1.0_1757987232_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    118
1    111
Name: count, dtype: int64

Answer change%: 0.4847 [0.41998738629837884, 0.5494449281121015] (n=229)
P-value vs 25%: 1.185e-12; P-value vs 0%: 9.046e-49
Phase 2 self-accuracy: 0.4595 [0.3667499387033849, 0.5521689802155341] (n=111)
P-value vs 25%: 9.504e-06; P-value vs 33%: 0.007507

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  229
Model:                          Logit   Df Residuals:                      227
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.01578
Time:                        16:13:38   Log-Likelihood:                -156.12
converged:                       True   LL-Null:                       -158.62
Covariance Type:            nonrobust   LLR p-value:                   0.02526
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          1.5156      0.730      2.075      0.038       0.084       2.947
p_i_capability    -1.7800      0.809     -2.201      0.028      -3.365      -0.195
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  229
Model:                          Logit   Df Residuals:                      227
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.02055
Time:                        16:13:38   Log-Likelihood:                -155.36
converged:                       True   LL-Null:                       -158.62
Covariance Type:            nonrobust   LLR p-value:                   0.01068
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -0.3217      0.168     -1.909      0.056      -0.652       0.009
capabilities_entropy     0.6723      0.268      2.511      0.012       0.147       1.197
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.3472 [0.2373, 0.4572] (n=72)
                  P-value vs 33.3%: 0.8045

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=7.81, p=6.61e-09
Wilcoxon delta_p: statistic=31.00, p=5.53e-07
Mean Δp = 0.5324  [0.3988, 0.6661]
Idea 1 N = 33; 

  Idea 1.5: Calibration Metrics
  NLL: 5.1410, Signed ECE (overconf pos under neg): 0.0414, ECE: 0.3113 (n=82)
  Brier: 0.3017, Reliability (absolute calibration error; lower better): 0.1670, Resolution (relative calibration quality; higher better): 0.0233, Uncertainty: 0.1570 (n=82)
  AUROC: 0.4233

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.215
Model:                            OLS   Adj. R-squared:                  0.185
Method:                 Least Squares   F-statistic:                     7.139
Date:                Wed, 24 Sep 2025   Prob (F-statistic):           0.000268
Time:                        16:13:38   Log-Likelihood:                -30.480
No. Observations:                  82   AIC:                             68.96
Df Residuals:                      78   BIC:                             78.59
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept             0.3662      0.280      1.309      0.194      -0.191       0.923
p1                    0.2048      0.336      0.610      0.544      -0.464       0.873
answer_changed       -0.8543      0.363     -2.350      0.021      -1.578      -0.131
p1:answer_changed     1.1530      0.448      2.575      0.012       0.262       2.044
==============================================================================
Omnibus:                       11.918   Durbin-Watson:                   1.617
Prob(Omnibus):                  0.003   Jarque-Bera (JB):               13.804
Skew:                          -0.999   Prob(JB):                      0.00101
Kurtosis:                       2.780   Cond. No.                         25.9
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=2.85, p=0.00759
Wilcoxon delta_H: statistic=137.00, p=0.0093
Mean ΔH = 0.2924  [0.0913, 0.4935]
Paired t-test delta_H Changed: statistic=3.22, p=0.00232
Wilcoxon delta_H Changed: statistic=325.00, p=0.00368
Mean ΔH Changed = 0.2740  [0.1071, 0.4408]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=4.44, p=2.85e-05
Wilcoxon (p_top2_game vs p_top2_base): statistic=625.00, p=6.47e-07
Mean Δp_top2 = 0.0353  [0.0197, 0.0509] (n=82)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=4.32, p=4.38e-05
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=860.00, p=0.0001
Mean ΔH_unchosen_baseline_set = 0.2814  [0.1537, 0.4090] (n=82)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                   82
Model:                          Logit   Df Residuals:                       79
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.02703
Time:                        16:13:38   Log-Likelihood:                -53.773
converged:                       True   LL-Null:                       -55.267
Covariance Type:            nonrobust   LLR p-value:                    0.2245
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept        0.7468      0.362      2.062      0.039       0.037       1.457
p1_z            -0.3721      0.242     -1.535      0.125      -0.847       0.103
I(p1_z ** 2)    -0.3383      0.269     -1.260      0.208      -0.865       0.188
================================================================================
AUC = 0.579

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  229
Model:                          Logit   Df Residuals:                      227
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.03700
Time:                        16:13:38   Log-Likelihood:                -152.75
converged:                       True   LL-Null:                       -158.62
Covariance Type:            nonrobust   LLR p-value:                 0.0006123
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.3593      0.160     -2.242      0.025      -0.673      -0.045
game_entropy     1.2289      0.375      3.274      0.001       0.493       1.965
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=7546.00, p=0.000132
Paired t-test (game_entropy vs capabilities_entropy): statistic=-4.30, p=2.58e-05
Mean game_entropy-capabilities_entropy = -0.1402  [-0.2041, -0.0762] (n=229)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  229
Model:                          Logit   Df Residuals:                      226
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.04206
Time:                        16:13:38   Log-Likelihood:                -151.95
converged:                       True   LL-Null:                       -158.62
Covariance Type:            nonrobust   LLR p-value:                  0.001266
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -0.4541      0.178     -2.555      0.011      -0.802      -0.106
capabilities_entropy     0.3709      0.293      1.264      0.206      -0.204       0.946
game_entropy             1.0326      0.406      2.544      0.011       0.237       1.828
========================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  229
Model:                          Logit   Df Residuals:                      227
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                0.002000
Time:                        16:13:38   Log-Likelihood:                -158.31
converged:                       True   LL-Null:                       -158.62
Covariance Type:            nonrobust   LLR p-value:                    0.4257
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept            0.3741      0.563      0.664      0.507      -0.730       1.478
human_difficulty    -0.1838      0.231     -0.795      0.427      -0.637       0.270
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  229
Model:                          Logit   Df Residuals:                      222
Method:                           MLE   Df Model:                            6
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                0.008213
Time:                        16:13:38   Log-Likelihood:                -157.32
converged:                       True   LL-Null:                       -158.62
Covariance Type:            nonrobust   LLR p-value:                    0.8565
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                             0.3052      1.927      0.158      0.874      -3.471       4.081
C(domain_grouped)[T.chemistry]       -0.0711      0.534     -0.133      0.894      -1.117       0.975
C(domain_grouped)[T.physics]         -0.1298      0.565     -0.230      0.818      -1.236       0.977
human_difficulty                     -0.1958      0.242     -0.808      0.419      -0.671       0.279
q_length                              0.2021      0.222      0.911      0.363      -0.233       0.637
avg_word_length                      -0.1913      0.208     -0.918      0.359      -0.600       0.217
percent_non_alphabetic_whitespace    -0.0139      0.022     -0.621      0.534      -0.058       0.030
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 0.3897
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  229
Model:                          Logit   Df Residuals:                      221
Method:                           MLE   Df Model:                            7
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.02631
Time:                        16:13:38   Log-Likelihood:                -154.45
converged:                       True   LL-Null:                       -158.62
Covariance Type:            nonrobust   LLR p-value:                    0.3031
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -0.3832      1.960     -0.196      0.845      -4.224       3.457
C(domain_grouped)[T.chemistry]       -0.1931      0.538     -0.359      0.720      -1.249       0.862
C(domain_grouped)[T.physics]         -0.2605      0.570     -0.457      0.648      -1.378       0.857
human_difficulty                     -0.1720      0.246     -0.698      0.485      -0.655       0.311
q_length                              0.2223      0.225      0.987      0.324      -0.219       0.664
avg_word_length                      -0.1205      0.211     -0.572      0.567      -0.533       0.292
percent_non_alphabetic_whitespace    -0.0083      0.023     -0.365      0.715      -0.053       0.036
capabilities_entropy                  0.6518      0.276      2.359      0.018       0.110       1.193
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  229
Model:                          Logit   Df Residuals:                      221
Method:                           MLE   Df Model:                            7
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.04000
Time:                        16:13:39   Log-Likelihood:                -152.28
converged:                       True   LL-Null:                       -158.62
Covariance Type:            nonrobust   LLR p-value:                   0.08005
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                             0.0186      1.943      0.010      0.992      -3.790       3.827
C(domain_grouped)[T.chemistry]       -0.2525      0.538     -0.469      0.639      -1.307       0.802
C(domain_grouped)[T.physics]         -0.2144      0.568     -0.378      0.706      -1.327       0.898
human_difficulty                     -0.1400      0.248     -0.564      0.573      -0.626       0.346
q_length                              0.1150      0.226      0.508      0.611      -0.328       0.558
avg_word_length                      -0.0934      0.211     -0.442      0.658      -0.507       0.320
percent_non_alphabetic_whitespace    -0.0076      0.023     -0.336      0.737      -0.052       0.037
game_entropy                          1.1853      0.389      3.050      0.002       0.423       1.947
=====================================================================================================

                  Model 4.95: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  229
Model:                          Logit   Df Residuals:                      220
Method:                           MLE   Df Model:                            8
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.04513
Time:                        16:13:39   Log-Likelihood:                -151.46
converged:                       True   LL-Null:                       -158.62
Covariance Type:            nonrobust   LLR p-value:                   0.07385
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -0.3369      1.970     -0.171      0.864      -4.198       3.524
C(domain_grouped)[T.chemistry]       -0.2921      0.540     -0.541      0.588      -1.350       0.766
C(domain_grouped)[T.physics]         -0.2758      0.571     -0.483      0.629      -1.394       0.843
human_difficulty                     -0.1354      0.250     -0.542      0.588      -0.625       0.354
q_length                              0.1417      0.229      0.619      0.536      -0.307       0.590
avg_word_length                      -0.0686      0.212     -0.324      0.746      -0.484       0.347
percent_non_alphabetic_whitespace    -0.0055      0.023     -0.242      0.809      -0.050       0.039
capabilities_entropy                  0.3811      0.299      1.273      0.203      -0.206       0.968
game_entropy                          0.9935      0.416      2.385      0.017       0.177       1.810
=====================================================================================================

--- Analyzing gpt-4o-2024-08-06 (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/gpt-4o-2024-08-06_GPQA_redacted_cor_temp1.0_1757988603_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    160
1     26
Name: count, dtype: int64

Answer change%: 0.1398 [0.08995099303667545, 0.1896188994364428] (n=186)
P-value vs 25%: 1.459e-05; P-value vs 0%: 3.847e-08
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=26)
P-value vs 25%: 0; P-value vs 33%: 0

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  186
Model:                          Logit   Df Residuals:                      184
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.2669
Time:                        16:13:39   Log-Likelihood:                -55.164
converged:                       True   LL-Null:                       -75.251
Covariance Type:            nonrobust   LLR p-value:                 2.324e-10
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          2.7159      0.767      3.541      0.000       1.213       4.219
p_i_capability    -6.3089      1.163     -5.426      0.000      -8.588      -4.030
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  186
Model:                          Logit   Df Residuals:                      184
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.2755
Time:                        16:13:39   Log-Likelihood:                -54.517
converged:                       True   LL-Null:                       -75.251
Covariance Type:            nonrobust   LLR p-value:                 1.199e-10
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -4.0064      0.598     -6.702      0.000      -5.178      -2.835
capabilities_entropy     2.3423      0.449      5.222      0.000       1.463       3.221
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.5385 [0.3468, 0.7301] (n=26)
                  P-value vs 33.3%: 0.03589

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=0.57, p=0.568
Wilcoxon delta_p: statistic=3900.00, p=0.267
Mean Δp = 0.0079  [-0.0191, 0.0349]
Idea 1 N = 132; 

  Idea 1.5: Calibration Metrics
  NLL: 0.3421, Signed ECE (overconf pos under neg): -0.1279, ECE: 0.1360 (n=158)
  Brier: 0.0780, Reliability (absolute calibration error; lower better): 0.0377, Resolution (relative calibration quality; higher better): 0.0495, Uncertainty: 0.0910 (n=158)
  AUROC: 0.9749

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.160
Model:                            OLS   Adj. R-squared:                  0.144
Method:                 Least Squares   F-statistic:                     9.812
Date:                Wed, 24 Sep 2025   Prob (F-statistic):           5.82e-06
Time:                        16:13:39   Log-Likelihood:                 44.088
No. Observations:                 158   AIC:                            -80.18
Df Residuals:                     154   BIC:                            -67.93
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.0692      0.069     -0.999      0.319      -0.206       0.068
p1                    0.0920      0.080      1.145      0.254      -0.067       0.251
answer_changed        0.0134      0.146      0.092      0.927      -0.275       0.301
p1:answer_changed     0.3645      0.232      1.568      0.119      -0.095       0.824
==============================================================================
Omnibus:                       11.621   Durbin-Watson:                   1.955
Prob(Omnibus):                  0.003   Jarque-Bera (JB):               29.003
Skew:                           0.110   Prob(JB):                     5.04e-07
Kurtosis:                       5.087   Cond. No.                         24.2
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=1.48, p=0.14
Wilcoxon delta_H: statistic=3710.00, p=0.123
Mean ΔH = 0.0621  [-0.0200, 0.1441]
Paired t-test delta_H Changed: statistic=4.07, p=0.000412
Wilcoxon delta_H Changed: statistic=40.00, p=0.000248
Mean ΔH Changed = 0.3789  [0.1965, 0.5612]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=4.00, p=9.74e-05
Wilcoxon (p_top2_game vs p_top2_base): statistic=3716.00, p=8.51e-06
Mean Δp_top2 = 0.0255  [0.0130, 0.0380] (n=158)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=2.91, p=0.00408
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=4570.00, p=0.00298
Mean ΔH_unchosen_baseline_set = 0.1142  [0.0374, 0.1910] (n=158)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  158
Model:                          Logit   Df Residuals:                      155
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.2526
Time:                        16:13:39   Log-Likelihood:                -52.800
converged:                       True   LL-Null:                       -70.650
Covariance Type:            nonrobust   LLR p-value:                 1.771e-08
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.8992      0.374     -5.079      0.000      -2.632      -1.166
p1_z            -1.9116      0.501     -3.812      0.000      -2.895      -0.929
I(p1_z ** 2)    -0.5312      0.315     -1.687      0.092      -1.148       0.086
================================================================================
AUC = 0.848

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  186
Model:                          Logit   Df Residuals:                      184
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1313
Time:                        16:13:39   Log-Likelihood:                -65.374
converged:                       True   LL-Null:                       -75.251
Covariance Type:            nonrobust   LLR p-value:                 8.808e-06
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -2.9068      0.397     -7.314      0.000      -3.686      -2.128
game_entropy     1.6033      0.380      4.222      0.000       0.859       2.348
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=5578.00, p=2.23e-05
Paired t-test (game_entropy vs capabilities_entropy): statistic=-3.69, p=0.0003
Mean game_entropy-capabilities_entropy = -0.1092  [-0.1674, -0.0511] (n=186)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  186
Model:                          Logit   Df Residuals:                      183
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.2804
Time:                        16:13:39   Log-Likelihood:                -54.153
converged:                       True   LL-Null:                       -75.251
Covariance Type:            nonrobust   LLR p-value:                 6.880e-10
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -4.0011      0.603     -6.640      0.000      -5.182      -2.820
capabilities_entropy     2.7231      0.644      4.225      0.000       1.460       3.986
game_entropy            -0.5208      0.614     -0.848      0.397      -1.725       0.683
========================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  186
Model:                          Logit   Df Residuals:                      184
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:               4.863e-08
Time:                        16:13:39   Log-Likelihood:                -75.251
converged:                       True   LL-Null:                       -75.251
Covariance Type:            nonrobust   LLR p-value:                    0.9978
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -1.8146      0.931     -1.949      0.051      -3.640       0.011
human_difficulty    -0.0010      0.377     -0.003      0.998      -0.740       0.738
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  186
Model:                          Logit   Df Residuals:                      179
Method:                           MLE   Df Model:                            6
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1021
Time:                        16:13:39   Log-Likelihood:                -67.569
converged:                       True   LL-Null:                       -75.251
Covariance Type:            nonrobust   LLR p-value:                   0.01761
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -0.5029      3.625     -0.139      0.890      -7.607       6.602
C(domain_grouped)[T.chemistry]        2.8618      1.085      2.638      0.008       0.735       4.988
C(domain_grouped)[T.physics]          2.1718      1.080      2.011      0.044       0.055       4.289
human_difficulty                      0.2723      0.386      0.706      0.480      -0.484       1.028
q_length                             -0.3332      0.398     -0.837      0.403      -1.113       0.447
avg_word_length                      -0.3835      0.418     -0.918      0.359      -1.203       0.436
percent_non_alphabetic_whitespace    -0.0447      0.042     -1.075      0.282      -0.126       0.037
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 0.5990
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  186
Model:                          Logit   Df Residuals:                      178
Method:                           MLE   Df Model:                            7
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.3274
Time:                        16:13:39   Log-Likelihood:                -50.611
converged:                       True   LL-Null:                       -75.251
Covariance Type:            nonrobust   LLR p-value:                 2.001e-08
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -2.5300      4.259     -0.594      0.552     -10.877       5.817
C(domain_grouped)[T.chemistry]        1.9717      1.186      1.663      0.096      -0.352       4.296
C(domain_grouped)[T.physics]          1.8843      1.188      1.585      0.113      -0.445       4.214
human_difficulty                      0.5895      0.439      1.344      0.179      -0.270       1.449
q_length                             -0.7667      0.489     -1.567      0.117      -1.726       0.192
avg_word_length                       0.0275      0.483      0.057      0.955      -0.920       0.975
percent_non_alphabetic_whitespace    -0.0312      0.040     -0.772      0.440      -0.111       0.048
capabilities_entropy                  2.4165      0.516      4.682      0.000       1.405       3.428
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  186
Model:                          Logit   Df Residuals:                      178
Method:                           MLE   Df Model:                            7
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1945
Time:                        16:13:39   Log-Likelihood:                -60.615
converged:                       True   LL-Null:                       -75.251
Covariance Type:            nonrobust   LLR p-value:                 0.0001291
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -0.9110      3.853     -0.236      0.813      -8.462       6.640
C(domain_grouped)[T.chemistry]        2.2047      1.101      2.002      0.045       0.046       4.363
C(domain_grouped)[T.physics]          1.9425      1.093      1.777      0.076      -0.200       4.085
human_difficulty                      0.4308      0.412      1.046      0.295      -0.376       1.238
q_length                             -0.5723      0.442     -1.296      0.195      -1.438       0.293
avg_word_length                      -0.2350      0.441     -0.533      0.594      -1.098       0.629
percent_non_alphabetic_whitespace    -0.0311      0.041     -0.760      0.447      -0.111       0.049
game_entropy                          1.4674      0.413      3.549      0.000       0.657       2.278
=====================================================================================================

                  Model 4.95: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  186
Model:                          Logit   Df Residuals:                      177
Method:                           MLE   Df Model:                            8
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.3330
Time:                        16:13:39   Log-Likelihood:                -50.192
converged:                       True   LL-Null:                       -75.251
Covariance Type:            nonrobust   LLR p-value:                 3.880e-08
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -2.2474      4.311     -0.521      0.602     -10.696       6.201
C(domain_grouped)[T.chemistry]        2.0345      1.185      1.717      0.086      -0.288       4.357
C(domain_grouped)[T.physics]          1.8724      1.186      1.579      0.114      -0.452       4.197
human_difficulty                      0.5455      0.444      1.228      0.220      -0.325       1.416
q_length                             -0.7740      0.491     -1.575      0.115      -1.737       0.189
avg_word_length                       0.0063      0.489      0.013      0.990      -0.952       0.965
percent_non_alphabetic_whitespace    -0.0340      0.041     -0.837      0.403      -0.114       0.046
capabilities_entropy                  2.8236      0.692      4.080      0.000       1.467       4.180
game_entropy                         -0.5824      0.644     -0.905      0.366      -1.844       0.679
=====================================================================================================

--- Analyzing gpt-4o-2024-08-06 (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/gpt-4o-2024-08-06_GPQA_redacted_temp1.0_1757987499_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    162
1     99
Name: count, dtype: int64

Answer change%: 0.3793 [0.32044462831901316, 0.4381760613361592] (n=261)
P-value vs 25%: 1.666e-05; P-value vs 0%: 1.455e-36
Phase 2 self-accuracy: 0.4646 [0.36640108170924235, 0.5628918475836869] (n=99)
P-value vs 25%: 1.851e-05; P-value vs 33%: 0.008632

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  261
Model:                          Logit   Df Residuals:                      259
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.07256
Time:                        16:13:39   Log-Likelihood:                -160.66
converged:                       True   LL-Null:                       -173.23
Covariance Type:            nonrobust   LLR p-value:                 5.332e-07
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          1.7176      0.471      3.648      0.000       0.795       2.640
p_i_capability    -3.2378      0.677     -4.782      0.000      -4.565      -1.911
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  261
Model:                          Logit   Df Residuals:                      259
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.05623
Time:                        16:13:39   Log-Likelihood:                -163.49
converged:                       True   LL-Null:                       -173.23
Covariance Type:            nonrobust   LLR p-value:                 1.016e-05
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.5742      0.299     -5.266      0.000      -2.160      -0.988
capabilities_entropy     1.0048      0.238      4.213      0.000       0.537       1.472
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.5657 [0.4680, 0.6633] (n=99)
                  P-value vs 33.3%: 3.108e-06

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=-1.06, p=0.293
Wilcoxon delta_p: statistic=5429.00, p=0.271
Mean Δp = -0.0179  [-0.0512, 0.0153]
Idea 1 N = 155; 

  Idea 1.5: Calibration Metrics
  NLL: 3.3029, Signed ECE (overconf pos under neg): 0.0653, ECE: 0.0970 (n=254)
  Brier: 0.0358, Reliability (absolute calibration error; lower better): 0.0176, Resolution (relative calibration quality; higher better): 0.0475, Uncertainty: 0.0658 (n=254)
  AUROC: 0.9946

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.445
Model:                            OLS   Adj. R-squared:                  0.438
Method:                 Least Squares   F-statistic:                     66.82
Date:                Wed, 24 Sep 2025   Prob (F-statistic):           9.24e-32
Time:                        16:13:39   Log-Likelihood:                 20.431
No. Observations:                 254   AIC:                            -32.86
Df Residuals:                     250   BIC:                            -18.71
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.2756      0.068     -4.056      0.000      -0.409      -0.142
p1                    0.3488      0.089      3.934      0.000       0.174       0.523
answer_changed        0.0424      0.105      0.405      0.686      -0.163       0.248
p1:answer_changed     0.5397      0.152      3.556      0.000       0.241       0.839
==============================================================================
Omnibus:                        9.490   Durbin-Watson:                   1.917
Prob(Omnibus):                  0.009   Jarque-Bera (JB):               12.895
Skew:                          -0.273   Prob(JB):                      0.00158
Kurtosis:                       3.959   Cond. No.                         18.4
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=5.76, p=4.47e-08
Wilcoxon delta_H: statistic=2965.00, p=3.75e-08
Mean ΔH = 0.2138  [0.1410, 0.2866]
Paired t-test delta_H Changed: statistic=6.50, p=3.42e-09
Wilcoxon delta_H Changed: statistic=769.00, p=2.61e-09
Mean ΔH Changed = 0.2933  [0.2048, 0.3818]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=6.34, p=1.05e-09
Wilcoxon (p_top2_game vs p_top2_base): statistic=8349.00, p=2.2e-11
Mean Δp_top2 = 0.0395  [0.0273, 0.0517] (n=254)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=8.52, p=1.46e-15
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=6780.00, p=9.68e-16
Mean ΔH_unchosen_baseline_set = 0.2448  [0.1885, 0.3011] (n=254)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  254
Model:                          Logit   Df Residuals:                      251
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.06763
Time:                        16:13:39   Log-Likelihood:                -158.35
converged:                       True   LL-Null:                       -169.84
Covariance Type:            nonrobust   LLR p-value:                 1.028e-05
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.3178      0.199     -1.595      0.111      -0.708       0.073
p1_z            -0.6415      0.144     -4.455      0.000      -0.924      -0.359
I(p1_z ** 2)    -0.1894      0.161     -1.175      0.240      -0.505       0.127
================================================================================
AUC = 0.672

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  261
Model:                          Logit   Df Residuals:                      259
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.05637
Time:                        16:13:39   Log-Likelihood:                -163.47
converged:                       True   LL-Null:                       -173.23
Covariance Type:            nonrobust   LLR p-value:                 9.895e-06
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.4447      0.269     -5.380      0.000      -1.971      -0.918
game_entropy     1.0573      0.249      4.253      0.000       0.570       1.545
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=11013.00, p=6.27e-07
Paired t-test (game_entropy vs capabilities_entropy): statistic=-5.35, p=1.95e-07
Mean game_entropy-capabilities_entropy = -0.1700  [-0.2323, -0.1077] (n=261)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  261
Model:                          Logit   Df Residuals:                      258
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.07079
Time:                        16:13:39   Log-Likelihood:                -160.97
converged:                       True   LL-Null:                       -173.23
Covariance Type:            nonrobust   LLR p-value:                 4.720e-06
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.7805      0.318     -5.607      0.000      -2.403      -1.158
capabilities_entropy     0.6371      0.288      2.214      0.027       0.073       1.201
game_entropy             0.6689      0.301      2.224      0.026       0.080       1.258
========================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  261
Model:                          Logit   Df Residuals:                      259
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.01021
Time:                        16:13:39   Log-Likelihood:                -171.46
converged:                       True   LL-Null:                       -173.23
Covariance Type:            nonrobust   LLR p-value:                   0.06001
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept            0.4877      0.540      0.904      0.366      -0.570       1.546
human_difficulty    -0.4209      0.227     -1.855      0.064      -0.866       0.024
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  261
Model:                          Logit   Df Residuals:                      254
Method:                           MLE   Df Model:                            6
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.02791
Time:                        16:13:39   Log-Likelihood:                -168.40
converged:                       True   LL-Null:                       -173.23
Covariance Type:            nonrobust   LLR p-value:                    0.1392
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                             2.2232      1.984      1.121      0.262      -1.665       6.111
C(domain_grouped)[T.chemistry]       -0.9060      0.482     -1.880      0.060      -1.850       0.038
C(domain_grouped)[T.physics]         -0.5532      0.501     -1.104      0.270      -1.535       0.429
human_difficulty                     -0.4719      0.238     -1.982      0.047      -0.938      -0.005
q_length                              0.0408      0.211      0.194      0.846      -0.372       0.454
avg_word_length                      -0.2360      0.222     -1.066      0.287      -0.670       0.198
percent_non_alphabetic_whitespace    -0.0134      0.025     -0.528      0.597      -0.063       0.036
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 1.0313
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  261
Model:                          Logit   Df Residuals:                      253
Method:                           MLE   Df Model:                            7
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.09060
Time:                        16:13:39   Log-Likelihood:                -157.54
converged:                       True   LL-Null:                       -173.23
Covariance Type:            nonrobust   LLR p-value:                 5.265e-05
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                             1.4960      1.990      0.752      0.452      -2.405       5.397
C(domain_grouped)[T.chemistry]       -1.4974      0.524     -2.860      0.004      -2.524      -0.471
C(domain_grouped)[T.physics]         -1.1758      0.548     -2.146      0.032      -2.250      -0.102
human_difficulty                     -0.5141      0.253     -2.032      0.042      -1.010      -0.018
q_length                             -0.0064      0.218     -0.029      0.977      -0.433       0.420
avg_word_length                      -0.1604      0.214     -0.748      0.454      -0.580       0.260
percent_non_alphabetic_whitespace    -0.0053      0.026     -0.208      0.835      -0.055       0.045
capabilities_entropy                  1.1391      0.258      4.408      0.000       0.633       1.646
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  261
Model:                          Logit   Df Residuals:                      253
Method:                           MLE   Df Model:                            7
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.08766
Time:                        16:13:39   Log-Likelihood:                -158.05
converged:                       True   LL-Null:                       -173.23
Covariance Type:            nonrobust   LLR p-value:                 8.120e-05
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                             1.3962      2.019      0.692      0.489      -2.560       5.353
C(domain_grouped)[T.chemistry]       -1.3943      0.512     -2.725      0.006      -2.397      -0.391
C(domain_grouped)[T.physics]         -1.0435      0.531     -1.965      0.049      -2.084      -0.003
human_difficulty                     -0.4907      0.248     -1.982      0.047      -0.976      -0.005
q_length                             -0.0174      0.221     -0.079      0.937      -0.450       0.415
avg_word_length                      -0.1211      0.219     -0.553      0.581      -0.550       0.308
percent_non_alphabetic_whitespace    -0.0052      0.026     -0.200      0.842      -0.057       0.046
game_entropy                          1.1694      0.270      4.339      0.000       0.641       1.698
=====================================================================================================

                  Model 4.95: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  261
Model:                          Logit   Df Residuals:                      252
Method:                           MLE   Df Model:                            8
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1068
Time:                        16:13:39   Log-Likelihood:                -154.73
converged:                       True   LL-Null:                       -173.23
Covariance Type:            nonrobust   LLR p-value:                 1.148e-05
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                             1.2654      2.017      0.628      0.530      -2.687       5.218
C(domain_grouped)[T.chemistry]       -1.6076      0.527     -3.049      0.002      -2.641      -0.574
C(domain_grouped)[T.physics]         -1.2843      0.551     -2.332      0.020      -2.363      -0.205
human_difficulty                     -0.5197      0.255     -2.041      0.041      -1.019      -0.021
q_length                             -0.0318      0.222     -0.143      0.886      -0.466       0.402
avg_word_length                      -0.1151      0.218     -0.528      0.597      -0.542       0.312
percent_non_alphabetic_whitespace    -0.0030      0.026     -0.113      0.910      -0.054       0.048
capabilities_entropy                  0.7676      0.302      2.542      0.011       0.176       1.360
game_entropy                          0.7352      0.315      2.337      0.019       0.119       1.352
=====================================================================================================

--- Analyzing gpt-4o-mini (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/gpt-4o-mini_GPQA_redacted_cor_temp1.0_1757988839_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    113
1     33
Name: count, dtype: int64

Answer change%: 0.2260 [0.1581828421354376, 0.2938719523851103] (n=146)
P-value vs 25%: 0.4886; P-value vs 0%: 6.59e-11
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=33)
P-value vs 25%: 0; P-value vs 33%: 0

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  146
Model:                          Logit   Df Residuals:                      144
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.02319
Time:                        16:13:39   Log-Likelihood:                -76.218
converged:                       True   LL-Null:                       -78.027
Covariance Type:            nonrobust   LLR p-value:                   0.05713
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          0.3638      0.839      0.433      0.665      -1.281       2.009
p_i_capability    -1.9365      1.012     -1.914      0.056      -3.919       0.046
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  146
Model:                          Logit   Df Residuals:                      144
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.02382
Time:                        16:13:39   Log-Likelihood:                -76.168
converged:                       True   LL-Null:                       -78.027
Covariance Type:            nonrobust   LLR p-value:                   0.05385
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.6293      0.302     -5.388      0.000      -2.222      -1.037
capabilities_entropy     0.6689      0.347      1.926      0.054      -0.012       1.350
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.3030 [0.1462, 0.4598] (n=33)
                  P-value vs 33.3%: 0.7048

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=8.08, p=2.46e-12
Wilcoxon delta_p: statistic=700.00, p=1.26e-08
Mean Δp = 0.4309  [0.3263, 0.5354]
Idea 1 N = 93; 

  Idea 1.5: Calibration Metrics
  NLL: 4.2663, Signed ECE (overconf pos under neg): -0.2032, ECE: 0.4163 (n=126)
  Brier: 0.4187, Reliability (absolute calibration error; lower better): 0.2159, Resolution (relative calibration quality; higher better): 0.0443, Uncertainty: 0.2460 (n=126)
  AUROC: 0.4638

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.320
Model:                            OLS   Adj. R-squared:                  0.303
Method:                 Least Squares   F-statistic:                     19.12
Date:                Wed, 24 Sep 2025   Prob (F-statistic):           3.14e-10
Time:                        16:13:39   Log-Likelihood:                -63.210
No. Observations:                 126   AIC:                             134.4
Df Residuals:                     122   BIC:                             145.8
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.8363      0.192     -4.365      0.000      -1.216      -0.457
p1                    1.5302      0.226      6.779      0.000       1.083       1.977
answer_changed        0.5338      0.345      1.549      0.124      -0.148       1.216
p1:answer_changed    -0.4484      0.419     -1.070      0.287      -1.278       0.381
==============================================================================
Omnibus:                       50.729   Durbin-Watson:                   2.052
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               13.602
Skew:                          -0.543   Prob(JB):                      0.00111
Kurtosis:                       1.812   Cond. No.                         21.1
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=4.69, p=9.53e-06
Wilcoxon delta_H: statistic=1062.00, p=1.67e-05
Mean ΔH = 0.2468  [0.1436, 0.3499]
Paired t-test delta_H Changed: statistic=1.79, p=0.0826
Wilcoxon delta_H Changed: statistic=176.00, p=0.0626
Mean ΔH Changed = 0.2040  [-0.0191, 0.4271]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=2.51, p=0.0134
Wilcoxon (p_top2_game vs p_top2_base): statistic=2672.00, p=0.00122
Mean Δp_top2 = 0.0148  [0.0032, 0.0264] (n=126)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=4.83, p=3.88e-06
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=2105.00, p=3.93e-06
Mean ΔH_unchosen_baseline_set = 0.2356  [0.1400, 0.3311] (n=126)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  126
Model:                          Logit   Df Residuals:                      123
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                0.008557
Time:                        16:13:39   Log-Likelihood:                -71.835
converged:                       True   LL-Null:                       -72.455
Covariance Type:            nonrobust   LLR p-value:                    0.5380
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.1272      0.358     -3.151      0.002      -1.828      -0.426
p1_z            -0.1672      0.266     -0.629      0.529      -0.688       0.354
I(p1_z ** 2)     0.0801      0.291      0.275      0.783      -0.490       0.650
================================================================================
AUC = 0.566

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  146
Model:                          Logit   Df Residuals:                      144
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.08577
Time:                        16:13:39   Log-Likelihood:                -71.335
converged:                       True   LL-Null:                       -78.027
Covariance Type:            nonrobust   LLR p-value:                 0.0002537
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.9838      0.318     -6.236      0.000      -2.607      -1.360
game_entropy     1.5455      0.436      3.544      0.000       0.691       2.400
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=3411.00, p=0.000695
Paired t-test (game_entropy vs capabilities_entropy): statistic=-3.13, p=0.00214
Mean game_entropy-capabilities_entropy = -0.1290  [-0.2099, -0.0481] (n=146)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  146
Model:                          Logit   Df Residuals:                      143
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.08577
Time:                        16:13:39   Log-Likelihood:                -71.335
converged:                       True   LL-Null:                       -78.027
Covariance Type:            nonrobust   LLR p-value:                  0.001240
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.9831      0.341     -5.819      0.000      -2.651      -1.315
capabilities_entropy    -0.0022      0.418     -0.005      0.996      -0.821       0.816
game_entropy             1.5469      0.509      3.040      0.002       0.549       2.544
========================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  146
Model:                          Logit   Df Residuals:                      144
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.03781
Time:                        16:13:39   Log-Likelihood:                -75.077
converged:                       True   LL-Null:                       -78.027
Covariance Type:            nonrobust   LLR p-value:                   0.01514
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept            0.8980      0.907      0.990      0.322      -0.880       2.676
human_difficulty    -0.9075      0.388     -2.337      0.019      -1.669      -0.146
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  146
Model:                          Logit   Df Residuals:                      139
Method:                           MLE   Df Model:                            6
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.04677
Time:                        16:13:39   Log-Likelihood:                -74.377
converged:                       True   LL-Null:                       -78.027
Covariance Type:            nonrobust   LLR p-value:                    0.2941
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                             0.6098      2.965      0.206      0.837      -5.202       6.422
C(domain_grouped)[T.chemistry]        0.3701      0.664      0.558      0.577      -0.931       1.671
C(domain_grouped)[T.physics]          0.4227      0.626      0.675      0.499      -0.804       1.650
human_difficulty                     -0.8325      0.394     -2.112      0.035      -1.605      -0.060
q_length                              0.1461      0.349      0.419      0.675      -0.537       0.829
avg_word_length                      -0.1937      0.345     -0.561      0.575      -0.871       0.483
percent_non_alphabetic_whitespace    -0.0206      0.040     -0.518      0.604      -0.099       0.057
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 0.5386
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  146
Model:                          Logit   Df Residuals:                      138
Method:                           MLE   Df Model:                            7
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.05788
Time:                        16:13:39   Log-Likelihood:                -73.510
converged:                       True   LL-Null:                       -78.027
Covariance Type:            nonrobust   LLR p-value:                    0.2503
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                             0.3761      2.893      0.130      0.897      -5.294       6.046
C(domain_grouped)[T.chemistry]        0.1099      0.704      0.156      0.876      -1.270       1.490
C(domain_grouped)[T.physics]          0.2327      0.651      0.357      0.721      -1.044       1.510
human_difficulty                     -0.7788      0.398     -1.959      0.050      -1.558       0.000
q_length                              0.1010      0.348      0.290      0.772      -0.581       0.783
avg_word_length                      -0.1441      0.327     -0.441      0.659      -0.785       0.497
percent_non_alphabetic_whitespace    -0.0185      0.040     -0.462      0.644      -0.097       0.060
capabilities_entropy                  0.5088      0.386      1.320      0.187      -0.247       1.265
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  146
Model:                          Logit   Df Residuals:                      138
Method:                           MLE   Df Model:                            7
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1211
Time:                        16:13:39   Log-Likelihood:                -68.581
converged:                       True   LL-Null:                       -78.027
Covariance Type:            nonrobust   LLR p-value:                  0.008533
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                             0.1989      3.004      0.066      0.947      -5.689       6.087
C(domain_grouped)[T.chemistry]       -0.2174      0.726     -0.299      0.765      -1.641       1.206
C(domain_grouped)[T.physics]         -0.1316      0.681     -0.193      0.847      -1.466       1.203
human_difficulty                     -0.8433      0.414     -2.037      0.042      -1.655      -0.032
q_length                              0.1115      0.363      0.307      0.759      -0.601       0.824
avg_word_length                      -0.1632      0.329     -0.496      0.620      -0.808       0.482
percent_non_alphabetic_whitespace     0.0022      0.042      0.052      0.959      -0.080       0.084
game_entropy                          1.5667      0.477      3.282      0.001       0.631       2.502
=====================================================================================================

                  Model 4.95: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  146
Model:                          Logit   Df Residuals:                      137
Method:                           MLE   Df Model:                            8
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1230
Time:                        16:13:39   Log-Likelihood:                -68.431
converged:                       True   LL-Null:                       -78.027
Covariance Type:            nonrobust   LLR p-value:                   0.01387
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                             0.2362      3.064      0.077      0.939      -5.769       6.241
C(domain_grouped)[T.chemistry]       -0.1504      0.736     -0.204      0.838      -1.593       1.292
C(domain_grouped)[T.physics]         -0.0839      0.686     -0.122      0.903      -1.428       1.260
human_difficulty                     -0.8732      0.419     -2.086      0.037      -1.694      -0.053
q_length                              0.1376      0.370      0.371      0.710      -0.588       0.863
avg_word_length                      -0.1858      0.342     -0.543      0.587      -0.856       0.485
percent_non_alphabetic_whitespace     0.0036      0.042      0.085      0.932      -0.079       0.086
capabilities_entropy                 -0.2554      0.469     -0.544      0.586      -1.175       0.664
game_entropy                          1.7252      0.563      3.064      0.002       0.622       2.829
=====================================================================================================

--- Analyzing gpt-4o-mini (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/gpt-4o-mini_GPQA_redacted_temp1.0_1757987785_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    190
1    111
Name: count, dtype: int64

Answer change%: 0.3688 [0.31426572728217506, 0.42327580095702755] (n=301)
P-value vs 25%: 1.947e-05; P-value vs 0%: 3.91e-40
Phase 2 self-accuracy: 0.4685 [0.3756378379014432, 0.5612990990354938] (n=111)
P-value vs 25%: 3.977e-06; P-value vs 33%: 0.004234

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  301
Model:                          Logit   Df Residuals:                      299
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.02296
Time:                        16:13:39   Log-Likelihood:                -193.60
converged:                       True   LL-Null:                       -198.15
Covariance Type:            nonrobust   LLR p-value:                  0.002560
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          0.8909      0.488      1.826      0.068      -0.065       1.847
p_i_capability    -1.8225      0.609     -2.994      0.003      -3.016      -0.629
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  301
Model:                          Logit   Df Residuals:                      299
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.02740
Time:                        16:13:39   Log-Likelihood:                -192.72
converged:                       True   LL-Null:                       -198.15
Covariance Type:            nonrobust   LLR p-value:                 0.0009836
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.0572      0.206     -5.140      0.000      -1.460      -0.654
capabilities_entropy     0.7014      0.216      3.248      0.001       0.278       1.125
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.2963 [0.2102, 0.3824] (n=108)
                  P-value vs 33.3%: 0.3993

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=13.10, p=8.56e-28
Wilcoxon delta_p: statistic=1712.00, p=1.72e-19
Mean Δp = 0.4466  [0.3797, 0.5134]
Idea 1 N = 177; 

  Idea 1.5: Calibration Metrics
  NLL: 4.7149, Signed ECE (overconf pos under neg): 0.0263, ECE: 0.3185 (n=285)
  Brier: 0.3028, Reliability (absolute calibration error; lower better): 0.1607, Resolution (relative calibration quality; higher better): 0.0093, Uncertainty: 0.1514 (n=285)
  AUROC: 0.3616

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.262
Model:                            OLS   Adj. R-squared:                  0.254
Method:                 Least Squares   F-statistic:                     33.22
Date:                Wed, 24 Sep 2025   Prob (F-statistic):           2.08e-18
Time:                        16:13:39   Log-Likelihood:                -124.56
No. Observations:                 285   AIC:                             257.1
Df Residuals:                     281   BIC:                             271.7
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.3677      0.124     -2.964      0.003      -0.612      -0.124
p1                    1.0106      0.150      6.743      0.000       0.716       1.306
answer_changed       -0.1657      0.185     -0.895      0.371      -0.530       0.199
p1:answer_changed     0.3078      0.234      1.318      0.189      -0.152       0.767
==============================================================================
Omnibus:                      210.755   Durbin-Watson:                   1.975
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               35.278
Skew:                          -0.599   Prob(JB):                     2.19e-08
Kurtosis:                       1.761   Cond. No.                         20.2
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=3.98, p=0.000102
Wilcoxon delta_H: statistic=5229.00, p=0.000105
Mean ΔH = 0.1726  [0.0875, 0.2577]
Paired t-test delta_H Changed: statistic=3.78, p=0.000254
Wilcoxon delta_H Changed: statistic=1796.00, p=0.000439
Mean ΔH Changed = 0.2067  [0.0997, 0.3138]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=3.61, p=0.000368
Wilcoxon (p_top2_game vs p_top2_base): statistic=15343.00, p=0.0003
Mean Δp_top2 = 0.0184  [0.0084, 0.0284] (n=285)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=5.47, p=1.01e-07
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=13081.00, p=1.61e-07
Mean ΔH_unchosen_baseline_set = 0.1855  [0.1190, 0.2521] (n=285)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  285
Model:                          Logit   Df Residuals:                      282
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.01964
Time:                        16:13:39   Log-Likelihood:                -185.40
converged:                       True   LL-Null:                       -189.11
Covariance Type:            nonrobust   LLR p-value:                   0.02436
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.5175      0.195     -2.650      0.008      -0.900      -0.135
p1_z            -0.3275      0.143     -2.283      0.022      -0.609      -0.046
I(p1_z ** 2)     0.0115      0.153      0.075      0.940      -0.289       0.312
================================================================================
AUC = 0.605

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  301
Model:                          Logit   Df Residuals:                      299
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1094
Time:                        16:13:39   Log-Likelihood:                -176.47
converged:                       True   LL-Null:                       -198.15
Covariance Type:            nonrobust   LLR p-value:                 4.560e-11
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.7240      0.243     -7.092      0.000      -2.200      -1.248
game_entropy     1.6869      0.276      6.113      0.000       1.146       2.228
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=19714.00, p=0.0463
Paired t-test (game_entropy vs capabilities_entropy): statistic=-1.74, p=0.0832
Mean game_entropy-capabilities_entropy = -0.0589  [-0.1254, 0.0075] (n=301)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  301
Model:                          Logit   Df Residuals:                      298
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1116
Time:                        16:13:39   Log-Likelihood:                -176.03
converged:                       True   LL-Null:                       -198.15
Covariance Type:            nonrobust   LLR p-value:                 2.484e-10
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.8318      0.272     -6.724      0.000      -2.366      -1.298
capabilities_entropy     0.2269      0.242      0.936      0.349      -0.248       0.702
game_entropy             1.5972      0.292      5.474      0.000       1.025       2.169
========================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  301
Model:                          Logit   Df Residuals:                      299
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                0.001849
Time:                        16:13:39   Log-Likelihood:                -197.78
converged:                       True   LL-Null:                       -198.15
Covariance Type:            nonrobust   LLR p-value:                    0.3920
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -0.1225      0.499     -0.245      0.806      -1.101       0.856
human_difficulty    -0.1774      0.208     -0.853      0.394      -0.585       0.230
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  301
Model:                          Logit   Df Residuals:                      294
Method:                           MLE   Df Model:                            6
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.01388
Time:                        16:13:39   Log-Likelihood:                -195.40
converged:                       True   LL-Null:                       -198.15
Covariance Type:            nonrobust   LLR p-value:                    0.4814
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -1.6457      1.877     -0.877      0.380      -5.324       2.032
C(domain_grouped)[T.chemistry]       -0.3005      0.393     -0.764      0.445      -1.071       0.470
C(domain_grouped)[T.physics]         -0.1830      0.405     -0.452      0.651      -0.977       0.611
human_difficulty                     -0.2697      0.217     -1.242      0.214      -0.696       0.156
q_length                              0.3592      0.200      1.799      0.072      -0.032       0.750
avg_word_length                      -0.0290      0.218     -0.133      0.894      -0.457       0.399
percent_non_alphabetic_whitespace    -0.0043      0.023     -0.191      0.849      -0.049       0.040
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 0.7127
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  301
Model:                          Logit   Df Residuals:                      293
Method:                           MLE   Df Model:                            7
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.04420
Time:                        16:13:39   Log-Likelihood:                -189.39
converged:                       True   LL-Null:                       -198.15
Covariance Type:            nonrobust   LLR p-value:                   0.01435
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -2.4254      1.935     -1.253      0.210      -6.219       1.368
C(domain_grouped)[T.chemistry]       -0.5762      0.410     -1.404      0.160      -1.381       0.228
C(domain_grouped)[T.physics]         -0.3416      0.419     -0.816      0.415      -1.162       0.479
human_difficulty                     -0.2428      0.221     -1.098      0.272      -0.676       0.191
q_length                              0.3690      0.203      1.815      0.069      -0.029       0.767
avg_word_length                       0.0204      0.225      0.091      0.928      -0.420       0.460
percent_non_alphabetic_whitespace     0.0022      0.023      0.092      0.926      -0.044       0.048
capabilities_entropy                  0.7666      0.225      3.405      0.001       0.325       1.208
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  301
Model:                          Logit   Df Residuals:                      293
Method:                           MLE   Df Model:                            7
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1223
Time:                        16:13:39   Log-Likelihood:                -173.92
converged:                       True   LL-Null:                       -198.15
Covariance Type:            nonrobust   LLR p-value:                 2.908e-08
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -3.0277      2.059     -1.470      0.142      -7.064       1.009
C(domain_grouped)[T.chemistry]       -0.7096      0.431     -1.645      0.100      -1.555       0.136
C(domain_grouped)[T.physics]         -0.4245      0.444     -0.955      0.339      -1.296       0.446
human_difficulty                     -0.1006      0.237     -0.425      0.671      -0.564       0.363
q_length                              0.2840      0.220      1.292      0.196      -0.147       0.715
avg_word_length                       0.0531      0.233      0.228      0.820      -0.403       0.510
percent_non_alphabetic_whitespace     0.0091      0.025      0.368      0.713      -0.039       0.057
game_entropy                          1.7364      0.286      6.069      0.000       1.176       2.297
=====================================================================================================

                  Model 4.95: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  301
Model:                          Logit   Df Residuals:                      292
Method:                           MLE   Df Model:                            8
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1265
Time:                        16:13:39   Log-Likelihood:                -173.09
converged:                       True   LL-Null:                       -198.15
Covariance Type:            nonrobust   LLR p-value:                 3.871e-08
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -3.3051      2.079     -1.590      0.112      -7.381       0.770
C(domain_grouped)[T.chemistry]       -0.7947      0.439     -1.810      0.070      -1.655       0.066
C(domain_grouped)[T.physics]         -0.4784      0.451     -1.060      0.289      -1.363       0.406
human_difficulty                     -0.1020      0.237     -0.429      0.668      -0.567       0.363
q_length                              0.3012      0.221      1.365      0.172      -0.131       0.734
avg_word_length                       0.0662      0.234      0.283      0.777      -0.392       0.525
percent_non_alphabetic_whitespace     0.0115      0.025      0.463      0.644      -0.037       0.060
capabilities_entropy                  0.3208      0.248      1.294      0.196      -0.165       0.807
game_entropy                          1.6203      0.300      5.404      0.000       1.033       2.208
=====================================================================================================

--- Analyzing grok-3-latest (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/grok-3-latest_GPQA_redacted_cor_temp0.0_1751718817_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    176
1     27
Name: count, dtype: int64

Answer change%: 0.1330 [0.08629144308167455, 0.17971840913507423] (n=203)
P-value vs 25%: 9.165e-07; P-value vs 0%: 2.398e-08
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=27)
P-value vs 25%: 0; P-value vs 33%: 0

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  203
Model:                          Logit   Df Residuals:                      201
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.01292
Time:                        16:13:39   Log-Likelihood:                -78.560
converged:                       True   LL-Null:                       -79.588
Covariance Type:            nonrobust   LLR p-value:                    0.1516
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept         -0.9051      0.653     -1.386      0.166      -2.185       0.375
p_i_capability    -1.0939      0.717     -1.526      0.127      -2.499       0.311
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  197
Model:                          Logit   Df Residuals:                      195
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1313
Time:                        16:13:39   Log-Likelihood:                -66.767
converged:                       True   LL-Null:                       -76.856
Covariance Type:            nonrobust   LLR p-value:                 7.057e-06
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.5266      0.293     -8.620      0.000      -3.101      -1.952
capabilities_entropy     2.6194      0.578      4.531      0.000       1.486       3.753
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.8462 [0.7075, 0.9848] (n=26)
                  P-value vs 33.3%: 4.248e-13

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=2.86, p=0.00484
Wilcoxon delta_p: statistic=3648.00, p=1.21e-07
Mean Δp = 0.0304  [0.0096, 0.0513]
Idea 1 N = 166; 

  Idea 1.5: Calibration Metrics
  NLL: 0.0495, Signed ECE (overconf pos under neg): -0.0419, ECE: 0.0419 (n=192)
  Brier: 0.0114, Reliability (absolute calibration error; lower better): 0.0110, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=192)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.780
Model:                            OLS   Adj. R-squared:                  0.776
Method:                 Least Squares   F-statistic:                     221.9
Date:                Wed, 24 Sep 2025   Prob (F-statistic):           1.65e-61
Time:                        16:13:39   Log-Likelihood:                 115.13
No. Observations:                 192   AIC:                            -222.3
Df Residuals:                     188   BIC:                            -209.2
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.5241      0.124     -4.216      0.000      -0.769      -0.279
p1                    0.5713      0.128      4.476      0.000       0.320       0.823
answer_changed        0.4907      0.205      2.398      0.017       0.087       0.894
p1:answer_changed     0.3074      0.223      1.378      0.170      -0.133       0.747
==============================================================================
Omnibus:                      124.076   Durbin-Watson:                   2.289
Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1012.982
Skew:                           2.384   Prob(JB):                    1.08e-220
Kurtosis:                      13.192   Cond. No.                         46.7
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-0.46, p=0.645
Wilcoxon delta_H: statistic=6698.00, p=0.708
Mean ΔH = -0.0172  [-0.0900, 0.0556]
Paired t-test delta_H Changed: statistic=1.73, p=0.0952
Wilcoxon delta_H Changed: statistic=94.00, p=0.0382
Mean ΔH Changed = 0.1548  [-0.0202, 0.3297]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=-2.18, p=0.0307
Wilcoxon (p_top2_game vs p_top2_base): statistic=4378.00, p=2.34e-10
Mean Δp_top2 = -0.0042  [-0.0080, -0.0004] (n=192)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=0.18, p=0.859
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=9058.00, p=0.789
Mean ΔH_unchosen_baseline_set = 0.0061  [-0.0615, 0.0737] (n=192)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  192
Model:                          Logit   Df Residuals:                      189
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1330
Time:                        16:13:39   Log-Likelihood:                -66.010
converged:                       True   LL-Null:                       -76.139
Covariance Type:            nonrobust   LLR p-value:                 3.992e-05
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.7695      0.259     -6.834      0.000      -2.277      -1.262
p1_z            -1.5785      0.442     -3.572      0.000      -2.445      -0.712
I(p1_z ** 2)    -0.3139      0.140     -2.237      0.025      -0.589      -0.039
================================================================================
AUC = 0.855

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  203
Model:                          Logit   Df Residuals:                      201
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1439
Time:                        16:13:39   Log-Likelihood:                -68.133
converged:                       True   LL-Null:                       -79.588
Covariance Type:            nonrobust   LLR p-value:                 1.698e-06
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -2.7143      0.324     -8.388      0.000      -3.349      -2.080
game_entropy     2.2806      0.483      4.721      0.000       1.334       3.227
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=5887.00, p=1.41e-06
Paired t-test (game_entropy vs capabilities_entropy): statistic=3.39, p=0.000841
Mean game_entropy-capabilities_entropy = 0.0871  [0.0368, 0.1374] (n=197)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  197
Model:                          Logit   Df Residuals:                      194
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1859
Time:                        16:13:39   Log-Likelihood:                -62.565
converged:                       True   LL-Null:                       -76.856
Covariance Type:            nonrobust   LLR p-value:                 6.218e-07
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.9546      0.363     -8.145      0.000      -3.666      -2.244
capabilities_entropy     1.9153      0.634      3.020      0.003       0.672       3.158
game_entropy             1.6376      0.549      2.984      0.003       0.562       2.713
========================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  203
Model:                          Logit   Df Residuals:                      201
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:               2.610e-07
Time:                        16:13:39   Log-Likelihood:                -79.588
converged:                       True   LL-Null:                       -79.588
Covariance Type:            nonrobust   LLR p-value:                    0.9949
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -1.8808      0.970     -1.940      0.052      -3.781       0.019
human_difficulty     0.0025      0.392      0.006      0.995      -0.767       0.772
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  203
Model:                          Logit   Df Residuals:                      196
Method:                           MLE   Df Model:                            6
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.04482
Time:                        16:13:39   Log-Likelihood:                -76.021
converged:                       True   LL-Null:                       -79.588
Covariance Type:            nonrobust   LLR p-value:                    0.3086
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -1.4091      3.302     -0.427      0.670      -7.880       5.062
C(domain_grouped)[T.chemistry]        1.3831      0.726      1.904      0.057      -0.041       2.807
C(domain_grouped)[T.physics]          1.0309      0.718      1.435      0.151      -0.377       2.439
human_difficulty                      0.2455      0.411      0.598      0.550      -0.559       1.050
q_length                             -0.4366      0.349     -1.249      0.212      -1.121       0.248
avg_word_length                       0.1122      0.373      0.301      0.764      -0.619       0.843
percent_non_alphabetic_whitespace     0.0009      0.037      0.024      0.981      -0.072       0.073
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 0.1592
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  197
Model:                          Logit   Df Residuals:                      189
Method:                           MLE   Df Model:                            7
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1652
Time:                        16:13:39   Log-Likelihood:                -64.163
converged:                       True   LL-Null:                       -76.856
Covariance Type:            nonrobust   LLR p-value:                 0.0006481
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -3.8867      3.591     -1.082      0.279     -10.926       3.152
C(domain_grouped)[T.chemistry]        1.1964      0.779      1.536      0.125      -0.331       2.723
C(domain_grouped)[T.physics]          0.7942      0.803      0.989      0.323      -0.780       2.368
human_difficulty                      0.1017      0.456      0.223      0.823      -0.791       0.995
q_length                             -0.3409      0.373     -0.913      0.361      -1.073       0.391
avg_word_length                       0.4570      0.392      1.164      0.244      -0.312       1.226
percent_non_alphabetic_whitespace     0.0190      0.038      0.500      0.617      -0.055       0.093
capabilities_entropy                  2.6809      0.619      4.333      0.000       1.468       3.894
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  203
Model:                          Logit   Df Residuals:                      195
Method:                           MLE   Df Model:                            7
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1835
Time:                        16:13:39   Log-Likelihood:                -64.983
converged:                       True   LL-Null:                       -79.588
Covariance Type:            nonrobust   LLR p-value:                 0.0001324
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -4.8303      3.694     -1.308      0.191     -12.070       2.410
C(domain_grouped)[T.chemistry]        1.2992      0.769      1.688      0.091      -0.209       2.807
C(domain_grouped)[T.physics]          1.3918      0.791      1.760      0.078      -0.159       2.942
human_difficulty                      0.1868      0.442      0.422      0.673      -0.680       1.054
q_length                             -0.2744      0.375     -0.732      0.464      -1.009       0.460
avg_word_length                       0.4482      0.405      1.107      0.268      -0.346       1.242
percent_non_alphabetic_whitespace     0.0061      0.039      0.157      0.875      -0.070       0.082
game_entropy                          2.4121      0.534      4.519      0.000       1.366       3.458
=====================================================================================================

                  Model 4.95: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  197
Model:                          Logit   Df Residuals:                      188
Method:                           MLE   Df Model:                            8
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.2188
Time:                        16:13:39   Log-Likelihood:                -60.041
converged:                       True   LL-Null:                       -76.856
Covariance Type:            nonrobust   LLR p-value:                 4.738e-05
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -6.0550      3.884     -1.559      0.119     -13.668       1.558
C(domain_grouped)[T.chemistry]        1.1115      0.801      1.388      0.165      -0.458       2.681
C(domain_grouped)[T.physics]          1.0367      0.844      1.228      0.219      -0.618       2.691
human_difficulty                      0.0533      0.470      0.113      0.910      -0.868       0.974
q_length                             -0.1986      0.385     -0.516      0.606      -0.953       0.556
avg_word_length                       0.6497      0.422      1.539      0.124      -0.178       1.477
percent_non_alphabetic_whitespace     0.0224      0.040      0.561      0.574      -0.056       0.101
capabilities_entropy                  1.9893      0.681      2.919      0.004       0.654       3.325
game_entropy                          1.7255      0.596      2.895      0.004       0.557       2.894
=====================================================================================================

--- Analyzing grok-3-latest (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/grok-3-latest_GPQA_redacted_temp0.0_1751719817_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    152
1     92
Name: count, dtype: int64

Answer change%: 0.3770 [0.3162386124390582, 0.43785974821667945] (n=244)
P-value vs 25%: 4.224e-05; P-value vs 0%: 5.561e-34
Phase 2 self-accuracy: 0.4130 [0.31243026290616926, 0.5136566936155699] (n=92)
P-value vs 25%: 0.001493; P-value vs 33%: 0.1189

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  244
Model:                          Logit   Df Residuals:                      242
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                0.004668
Time:                        16:13:39   Log-Likelihood:                -160.92
converged:                       True   LL-Null:                       -161.67
Covariance Type:            nonrobust   LLR p-value:                    0.2192
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          0.0796      0.489      0.163      0.871      -0.880       1.039
p_i_capability    -0.6865      0.558     -1.231      0.218      -1.779       0.406
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  236
Model:                          Logit   Df Residuals:                      234
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.04144
Time:                        16:13:39   Log-Likelihood:                -149.90
converged:                       True   LL-Null:                       -156.38
Covariance Type:            nonrobust   LLR p-value:                 0.0003180
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -0.9763      0.195     -5.000      0.000      -1.359      -0.594
capabilities_entropy     1.1107      0.315      3.530      0.000       0.494       1.727
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.6705 [0.5722, 0.7687] (n=88)
                  P-value vs 33.3%: 1.72e-11

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=2.32, p=0.0218
Wilcoxon delta_p: statistic=3667.00, p=0.00835
Mean Δp = 0.0355  [0.0055, 0.0656]
Idea 1 N = 140; 

  Idea 1.5: Calibration Metrics
  NLL: 6.9395, Signed ECE (overconf pos under neg): 0.0391, ECE: 0.0391 (n=228)
  Brier: 0.0077, Reliability (absolute calibration error; lower better): 0.0072, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=228)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.842
Model:                            OLS   Adj. R-squared:                  0.840
Method:                 Least Squares   F-statistic:                     398.8
Date:                Wed, 24 Sep 2025   Prob (F-statistic):           1.59e-89
Time:                        16:13:39   Log-Likelihood:                 102.59
No. Observations:                 228   AIC:                            -197.2
Df Residuals:                     224   BIC:                            -183.5
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.4915      0.091     -5.423      0.000      -0.670      -0.313
p1                    0.5765      0.098      5.877      0.000       0.383       0.770
answer_changed        0.3728      0.129      2.886      0.004       0.118       0.627
p1:answer_changed     0.4151      0.144      2.876      0.004       0.131       0.699
==============================================================================
Omnibus:                       61.929   Durbin-Watson:                   1.909
Prob(Omnibus):                  0.000   Jarque-Bera (JB):              174.381
Skew:                           1.169   Prob(JB):                     1.36e-38
Kurtosis:                       6.591   Cond. No.                         30.8
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=0.92, p=0.361
Wilcoxon delta_H: statistic=4447.00, p=0.31
Mean ΔH = 0.0384  [-0.0437, 0.1205]
Paired t-test delta_H Changed: statistic=3.81, p=0.000261
Wilcoxon delta_H Changed: statistic=1189.00, p=0.00138
Mean ΔH Changed = 0.1657  [0.0804, 0.2510]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=-0.78, p=0.435
Wilcoxon (p_top2_game vs p_top2_base): statistic=10793.00, p=0.0234
Mean Δp_top2 = -0.0033  [-0.0115, 0.0049] (n=228)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=2.83, p=0.00507
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=10313.00, p=0.006
Mean ΔH_unchosen_baseline_set = 0.0875  [0.0269, 0.1482] (n=228)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  228
Model:                          Logit   Df Residuals:                      225
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.03840
Time:                        16:13:39   Log-Likelihood:                -146.22
converged:                       True   LL-Null:                       -152.06
Covariance Type:            nonrobust   LLR p-value:                  0.002914
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.2462      0.191     -1.290      0.197      -0.620       0.128
p1_z            -0.7452      0.243     -3.071      0.002      -1.221      -0.270
I(p1_z ** 2)    -0.2382      0.136     -1.752      0.080      -0.505       0.028
================================================================================
AUC = 0.682

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  244
Model:                          Logit   Df Residuals:                      242
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.06762
Time:                        16:13:39   Log-Likelihood:                -150.74
converged:                       True   LL-Null:                       -161.67
Covariance Type:            nonrobust   LLR p-value:                 2.926e-06
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.2537      0.221     -5.660      0.000      -1.688      -0.820
game_entropy     1.3743      0.305      4.502      0.000       0.776       1.972
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=10374.00, p=0.000587
Paired t-test (game_entropy vs capabilities_entropy): statistic=3.36, p=0.000895
Mean game_entropy-capabilities_entropy = 0.1095  [0.0457, 0.1732] (n=236)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  236
Model:                          Logit   Df Residuals:                      233
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.07774
Time:                        16:13:39   Log-Likelihood:                -144.23
converged:                       True   LL-Null:                       -156.38
Covariance Type:            nonrobust   LLR p-value:                 5.252e-06
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.4017      0.243     -5.759      0.000      -1.879      -0.925
capabilities_entropy     0.7207      0.339      2.127      0.033       0.057       1.385
game_entropy             1.0842      0.327      3.316      0.001       0.443       1.725
========================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  244
Model:                          Logit   Df Residuals:                      242
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                0.003023
Time:                        16:13:39   Log-Likelihood:                -161.19
converged:                       True   LL-Null:                       -161.67
Covariance Type:            nonrobust   LLR p-value:                    0.3228
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept            0.0030      0.528      0.006      0.996      -1.033       1.039
human_difficulty    -0.2172      0.221     -0.983      0.326      -0.650       0.216
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  244
Model:                          Logit   Df Residuals:                      237
Method:                           MLE   Df Model:                            6
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                0.009695
Time:                        16:13:39   Log-Likelihood:                -160.11
converged:                       True   LL-Null:                       -161.67
Covariance Type:            nonrobust   LLR p-value:                    0.7917
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -0.1246      1.894     -0.066      0.948      -3.836       3.587
C(domain_grouped)[T.chemistry]       -0.3424      0.492     -0.696      0.486      -1.306       0.622
C(domain_grouped)[T.physics]         -0.2761      0.524     -0.527      0.598      -1.302       0.750
human_difficulty                     -0.2927      0.229     -1.278      0.201      -0.741       0.156
q_length                              0.0399      0.216      0.185      0.853      -0.383       0.463
avg_word_length                       0.0966      0.203      0.476      0.634      -0.301       0.494
percent_non_alphabetic_whitespace    -0.0111      0.025     -0.443      0.658      -0.060       0.038
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 0.4085
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  236
Model:                          Logit   Df Residuals:                      228
Method:                           MLE   Df Model:                            7
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.05943
Time:                        16:13:39   Log-Likelihood:                -147.09
converged:                       True   LL-Null:                       -156.38
Covariance Type:            nonrobust   LLR p-value:                  0.009585
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -0.6814      1.994     -0.342      0.733      -4.590       3.227
C(domain_grouped)[T.chemistry]       -0.8037      0.533     -1.508      0.132      -1.848       0.241
C(domain_grouped)[T.physics]         -0.8598      0.573     -1.500      0.134      -1.983       0.264
human_difficulty                     -0.3086      0.240     -1.284      0.199      -0.780       0.163
q_length                              0.1188      0.228      0.522      0.602      -0.327       0.565
avg_word_length                       0.1017      0.213      0.477      0.634      -0.316       0.520
percent_non_alphabetic_whitespace    -0.0051      0.026     -0.198      0.843      -0.056       0.046
capabilities_entropy                  1.2261      0.327      3.746      0.000       0.585       1.868
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  244
Model:                          Logit   Df Residuals:                      236
Method:                           MLE   Df Model:                            7
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.08222
Time:                        16:13:39   Log-Likelihood:                -148.38
converged:                       True   LL-Null:                       -161.67
Covariance Type:            nonrobust   LLR p-value:                 0.0003954
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -1.8079      2.022     -0.894      0.371      -5.771       2.156
C(domain_grouped)[T.chemistry]       -0.4108      0.522     -0.788      0.431      -1.433       0.612
C(domain_grouped)[T.physics]         -0.2334      0.559     -0.418      0.676      -1.328       0.861
human_difficulty                     -0.3425      0.243     -1.408      0.159      -0.819       0.134
q_length                              0.0508      0.229      0.222      0.825      -0.398       0.500
avg_word_length                       0.2698      0.218      1.236      0.217      -0.158       0.698
percent_non_alphabetic_whitespace     0.0066      0.026      0.252      0.801      -0.045       0.058
game_entropy                          1.4603      0.314      4.646      0.000       0.844       2.076
=====================================================================================================

                  Model 4.95: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  236
Model:                          Logit   Df Residuals:                      227
Method:                           MLE   Df Model:                            8
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.09730
Time:                        16:13:39   Log-Likelihood:                -141.17
converged:                       True   LL-Null:                       -156.38
Covariance Type:            nonrobust   LLR p-value:                 0.0001772
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -1.5771      2.056     -0.767      0.443      -5.607       2.453
C(domain_grouped)[T.chemistry]       -0.7979      0.553     -1.442      0.149      -1.883       0.287
C(domain_grouped)[T.physics]         -0.7115      0.597     -1.191      0.234      -1.882       0.459
human_difficulty                     -0.3562      0.248     -1.435      0.151      -0.843       0.130
q_length                              0.0955      0.235      0.407      0.684      -0.364       0.555
avg_word_length                       0.2152      0.222      0.970      0.332      -0.220       0.650
percent_non_alphabetic_whitespace     0.0069      0.027      0.258      0.797      -0.045       0.059
capabilities_entropy                  0.8262      0.353      2.337      0.019       0.133       1.519
game_entropy                          1.1423      0.338      3.383      0.001       0.481       1.804
=====================================================================================================

--- Analyzing qwen3-235b-a22b-2507 (Redacted, Correct, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/qwen3-235b-a22b-2507_GPQA_redacted_cor_temp0.0_1756235281_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    158
1     46
Name: count, dtype: int64

Answer change%: 0.2255 [0.16814324946958045, 0.2828371426872823] (n=204)
P-value vs 25%: 0.4022; P-value vs 0%: 1.292e-14
Phase 2 self-accuracy: 0.0000 [0.0, 0.0] (n=46)
P-value vs 25%: 0; P-value vs 33%: 0

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  204
Model:                          Logit   Df Residuals:                      202
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1071
Time:                        16:13:39   Log-Likelihood:                -97.224
converged:                       True   LL-Null:                       -108.89
Covariance Type:            nonrobust   LLR p-value:                 1.365e-06
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          3.8099      1.096      3.476      0.001       1.662       5.958
p_i_capability    -5.5422      1.200     -4.619      0.000      -7.894      -3.190
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  204
Model:                          Logit   Df Residuals:                      202
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1148
Time:                        16:13:39   Log-Likelihood:                -96.390
converged:                       True   LL-Null:                       -108.89
Covariance Type:            nonrobust   LLR p-value:                 5.737e-07
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.8433      0.231     -7.973      0.000      -2.296      -1.390
capabilities_entropy     1.8670      0.387      4.820      0.000       1.108       2.626
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.6739 [0.5384, 0.8094] (n=46)
                  P-value vs 33.3%: 8.328e-07

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=2.53, p=0.0125
Wilcoxon delta_p: statistic=2167.00, p=1.29e-05
Mean Δp = 0.0369  [0.0084, 0.0655]
Idea 1 N = 127; 

  Idea 1.5: Calibration Metrics
  NLL: 0.1297, Signed ECE (overconf pos under neg): -0.0886, ECE: 0.0886 (n=173)
  Brier: 0.0355, Reliability (absolute calibration error; lower better): 0.0352, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=173)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.766
Model:                            OLS   Adj. R-squared:                  0.762
Method:                 Least Squares   F-statistic:                     184.3
Date:                Wed, 24 Sep 2025   Prob (F-statistic):           4.79e-53
Time:                        16:13:39   Log-Likelihood:                 67.991
No. Observations:                 173   AIC:                            -128.0
Df Residuals:                     169   BIC:                            -115.4
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.5837      0.127     -4.596      0.000      -0.834      -0.333
p1                    0.6530      0.133      4.920      0.000       0.391       0.915
answer_changed        0.2509      0.174      1.444      0.151      -0.092       0.594
p1:answer_changed     0.5122      0.192      2.672      0.008       0.134       0.891
==============================================================================
Omnibus:                       39.530   Durbin-Watson:                   1.839
Prob(Omnibus):                  0.000   Jarque-Bera (JB):              136.379
Skew:                           0.833   Prob(JB):                     2.43e-30
Kurtosis:                       7.018   Cond. No.                         33.2
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-7.12, p=7.31e-11
Wilcoxon delta_H: statistic=1563.00, p=1.77e-09
Mean ΔH = -0.3803  [-0.4850, -0.2756]
Paired t-test delta_H Changed: statistic=0.37, p=0.715
Wilcoxon delta_H Changed: statistic=528.00, p=0.891
Mean ΔH Changed = 0.0312  [-0.1353, 0.1976]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=-1.82, p=0.0703
Wilcoxon (p_top2_game vs p_top2_base): statistic=4087.00, p=2.97e-07
Mean Δp_top2 = -0.0069  [-0.0144, 0.0005] (n=173)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=-5.74, p=4.22e-08
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=4119.00, p=2.42e-07
Mean ΔH_unchosen_baseline_set = -0.2709  [-0.3634, -0.1784] (n=173)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  173
Model:                          Logit   Df Residuals:                      170
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1071
Time:                        16:13:39   Log-Likelihood:                -89.455
converged:                       True   LL-Null:                       -100.19
Covariance Type:            nonrobust   LLR p-value:                 2.177e-05
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.8721      0.235     -3.703      0.000      -1.334      -0.411
p1_z            -1.2006      0.361     -3.327      0.001      -1.908      -0.493
I(p1_z ** 2)    -0.2542      0.164     -1.551      0.121      -0.575       0.067
================================================================================
AUC = 0.696

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  204
Model:                          Logit   Df Residuals:                      202
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.2242
Time:                        16:13:39   Log-Likelihood:                -84.476
converged:                       True   LL-Null:                       -108.89
Covariance Type:            nonrobust   LLR p-value:                 2.798e-12
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -2.4859      0.306     -8.125      0.000      -3.086      -1.886
game_entropy     2.5448      0.408      6.232      0.000       1.744       3.345
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=5755.00, p=2.83e-05
Paired t-test (game_entropy vs capabilities_entropy): statistic=3.46, p=0.000651
Mean game_entropy-capabilities_entropy = 0.1167  [0.0506, 0.1827] (n=204)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  204
Model:                          Logit   Df Residuals:                      201
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.2572
Time:                        16:13:39   Log-Likelihood:                -80.886
converged:                       True   LL-Null:                       -108.89
Covariance Type:            nonrobust   LLR p-value:                 6.893e-13
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.7208      0.335     -8.114      0.000      -3.378      -2.064
capabilities_entropy     1.1604      0.437      2.655      0.008       0.304       2.017
game_entropy             2.2339      0.427      5.237      0.000       1.398       3.070
========================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  204
Model:                          Logit   Df Residuals:                      202
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:               0.0005795
Time:                        16:13:39   Log-Likelihood:                -108.83
converged:                       True   LL-Null:                       -108.89
Covariance Type:            nonrobust   LLR p-value:                    0.7224
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -0.9834      0.724     -1.359      0.174      -2.402       0.435
human_difficulty    -0.1061      0.299     -0.355      0.723      -0.693       0.481
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  204
Model:                          Logit   Df Residuals:                      197
Method:                           MLE   Df Model:                            6
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.03486
Time:                        16:13:39   Log-Likelihood:                -105.09
converged:                       True   LL-Null:                       -108.89
Covariance Type:            nonrobust   LLR p-value:                    0.2695
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -3.9412      2.457     -1.604      0.109      -8.757       0.875
C(domain_grouped)[T.chemistry]        1.1318      0.543      2.086      0.037       0.068       2.195
C(domain_grouped)[T.physics]          0.4552      0.543      0.838      0.402      -0.609       1.520
human_difficulty                      0.0222      0.318      0.070      0.944      -0.601       0.645
q_length                              0.2448      0.298      0.822      0.411      -0.339       0.829
avg_word_length                       0.0869      0.270      0.322      0.747      -0.442       0.616
percent_non_alphabetic_whitespace     0.0202      0.033      0.620      0.536      -0.044       0.084
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 0.2549
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  204
Model:                          Logit   Df Residuals:                      196
Method:                           MLE   Df Model:                            7
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1269
Time:                        16:13:39   Log-Likelihood:                -95.070
converged:                       True   LL-Null:                       -108.89
Covariance Type:            nonrobust   LLR p-value:                 0.0002557
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -4.2236      2.534     -1.667      0.096      -9.190       0.742
C(domain_grouped)[T.chemistry]        0.5214      0.589      0.885      0.376      -0.634       1.676
C(domain_grouped)[T.physics]          0.1488      0.569      0.262      0.794      -0.965       1.263
human_difficulty                      0.1048      0.339      0.309      0.757      -0.560       0.769
q_length                              0.1519      0.316      0.480      0.631      -0.468       0.772
avg_word_length                       0.1638      0.274      0.598      0.550      -0.373       0.700
percent_non_alphabetic_whitespace     0.0289      0.035      0.831      0.406      -0.039       0.097
capabilities_entropy                  1.7586      0.408      4.307      0.000       0.958       2.559
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  204
Model:                          Logit   Df Residuals:                      196
Method:                           MLE   Df Model:                            7
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.2436
Time:                        16:13:39   Log-Likelihood:                -82.359
converged:                       True   LL-Null:                       -108.89
Covariance Type:            nonrobust   LLR p-value:                 3.607e-09
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -4.9650      2.788     -1.781      0.075     -10.430       0.500
C(domain_grouped)[T.chemistry]        0.3176      0.634      0.501      0.616      -0.925       1.560
C(domain_grouped)[T.physics]          0.0486      0.631      0.077      0.939      -1.189       1.286
human_difficulty                      0.0042      0.367      0.011      0.991      -0.715       0.723
q_length                             -0.0245      0.356     -0.069      0.945      -0.722       0.673
avg_word_length                       0.4268      0.302      1.415      0.157      -0.165       1.018
percent_non_alphabetic_whitespace     0.0526      0.037      1.433      0.152      -0.019       0.124
game_entropy                          2.5990      0.434      5.993      0.000       1.749       3.449
=====================================================================================================

                  Model 4.95: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  204
Model:                          Logit   Df Residuals:                      195
Method:                           MLE   Df Model:                            8
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.2741
Time:                        16:13:39   Log-Likelihood:                -79.044
converged:                       True   LL-Null:                       -108.89
Covariance Type:            nonrobust   LLR p-value:                 5.364e-10
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -5.0341      2.808     -1.793      0.073     -10.537       0.469
C(domain_grouped)[T.chemistry]       -0.0027      0.653     -0.004      0.997      -1.282       1.277
C(domain_grouped)[T.physics]         -0.1090      0.634     -0.172      0.864      -1.352       1.134
human_difficulty                      0.1065      0.376      0.283      0.777      -0.631       0.844
q_length                             -0.0875      0.366     -0.239      0.811      -0.805       0.630
avg_word_length                       0.4503      0.296      1.522      0.128      -0.129       1.030
percent_non_alphabetic_whitespace     0.0531      0.037      1.427      0.154      -0.020       0.126
capabilities_entropy                  1.1656      0.458      2.547      0.011       0.269       2.063
game_entropy                          2.3551      0.449      5.242      0.000       1.474       3.236
=====================================================================================================

--- Analyzing qwen3-235b-a22b-2507 (Redacted, Incorrect, 1 game files) ---
              Game files for analysis: ['./sc_logs_new/qwen3-235b-a22b-2507_GPQA_redacted_temp0.0_1756233720_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    168
1     75
Name: count, dtype: int64

Answer change%: 0.3086 [0.25056233030625347, 0.36672162031103045] (n=243)
P-value vs 25%: 0.04782; P-value vs 0%: 2.107e-25
Phase 2 self-accuracy: 0.4800 [0.36693198969084995, 0.59306801030915] (n=75)
P-value vs 25%: 6.694e-05; P-value vs 33%: 0.01083

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  243
Model:                          Logit   Df Residuals:                      241
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.02900
Time:                        16:13:39   Log-Likelihood:                -145.82
converged:                       True   LL-Null:                       -150.18
Covariance Type:            nonrobust   LLR p-value:                  0.003162
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          1.0815      0.648      1.669      0.095      -0.189       2.352
p_i_capability    -2.2194      0.752     -2.951      0.003      -3.694      -0.745
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  243
Model:                          Logit   Df Residuals:                      241
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.02743
Time:                        16:13:39   Log-Likelihood:                -146.06
converged:                       True   LL-Null:                       -150.18
Covariance Type:            nonrobust   LLR p-value:                  0.004098
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.1772      0.198     -5.959      0.000      -1.564      -0.790
capabilities_entropy     0.7165      0.250      2.862      0.004       0.226       1.207
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.7467 [0.6482, 0.8451] (n=75)
                  P-value vs 33.3%: 1.866e-16

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=1.25, p=0.213
Wilcoxon delta_p: statistic=3603.00, p=0.0302
Mean Δp = 0.0231  [-0.0130, 0.0592]
Idea 1 N = 136; 

  Idea 1.5: Calibration Metrics
  NLL: 12.1265, Signed ECE (overconf pos under neg): 0.0554, ECE: 0.0554 (n=194)
  Brier: 0.0143, Reliability (absolute calibration error; lower better): 0.0137, Resolution (relative calibration quality; higher better): 0.0000, Uncertainty: 0.0000 (n=194)
  AUROC: nan

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.804
Model:                            OLS   Adj. R-squared:                  0.801
Method:                 Least Squares   F-statistic:                     270.7
Date:                Wed, 24 Sep 2025   Prob (F-statistic):           8.80e-70
Time:                        16:13:39   Log-Likelihood:                 70.927
No. Observations:                 202   AIC:                            -133.9
Df Residuals:                     198   BIC:                            -120.6
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.6584      0.076     -8.619      0.000      -0.809      -0.508
p1                    0.7796      0.086      9.092      0.000       0.610       0.949
answer_changed        0.3227      0.117      2.751      0.006       0.091       0.554
p1:answer_changed     0.4306      0.136      3.164      0.002       0.162       0.699
==============================================================================
Omnibus:                       26.421   Durbin-Watson:                   2.053
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               96.830
Skew:                           0.396   Prob(JB):                     9.41e-22
Kurtosis:                       6.298   Cond. No.                         22.7
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-4.32, p=3e-05
Wilcoxon delta_H: statistic=2819.00, p=0.000155
Mean ΔH = -0.2194  [-0.3189, -0.1199]
Paired t-test delta_H Changed: statistic=0.19, p=0.85
Wilcoxon delta_H Changed: statistic=1107.00, p=0.842
Mean ΔH Changed = 0.0132  [-0.1235, 0.1499]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=-0.06, p=0.951
Wilcoxon (p_top2_game vs p_top2_base): statistic=7480.00, p=0.000607
Mean Δp_top2 = -0.0003  [-0.0092, 0.0086] (n=203)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=-3.42, p=0.000756
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=7503.00, p=0.00134
Mean ΔH_unchosen_baseline_set = -0.1426  [-0.2244, -0.0609] (n=203)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  203
Model:                          Logit   Df Residuals:                      200
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.01895
Time:                        16:13:39   Log-Likelihood:                -126.31
converged:                       True   LL-Null:                       -128.75
Covariance Type:            nonrobust   LLR p-value:                   0.08722
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.7860      0.243     -3.232      0.001      -1.263      -0.309
p1_z            -0.2543      0.246     -1.035      0.301      -0.736       0.227
I(p1_z ** 2)     0.0634      0.192      0.331      0.741      -0.312       0.439
================================================================================
AUC = 0.592

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  243
Model:                          Logit   Df Residuals:                      241
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.07500
Time:                        16:13:39   Log-Likelihood:                -138.91
converged:                       True   LL-Null:                       -150.18
Covariance Type:            nonrobust   LLR p-value:                 2.074e-06
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.5965      0.238     -6.717      0.000      -2.062      -1.131
game_entropy     1.3516      0.295      4.578      0.000       0.773       1.930
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=12093.00, p=0.11
Paired t-test (game_entropy vs capabilities_entropy): statistic=1.13, p=0.259
Mean game_entropy-capabilities_entropy = 0.0470  [-0.0345, 0.1286] (n=243)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  243
Model:                          Logit   Df Residuals:                      240
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.08611
Time:                        16:13:39   Log-Likelihood:                -137.24
converged:                       True   LL-Null:                       -150.18
Covariance Type:            nonrobust   LLR p-value:                 2.419e-06
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.7747      0.261     -6.793      0.000      -2.287      -1.263
capabilities_entropy     0.4890      0.267      1.834      0.067      -0.034       1.012
game_entropy             1.2316      0.302      4.081      0.000       0.640       1.823
========================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  243
Model:                          Logit   Df Residuals:                      241
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:               5.022e-06
Time:                        16:13:39   Log-Likelihood:                -150.18
converged:                       True   LL-Null:                       -150.18
Covariance Type:            nonrobust   LLR p-value:                    0.9690
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -0.7845      0.583     -1.345      0.179      -1.927       0.358
human_difficulty    -0.0093      0.239     -0.039      0.969      -0.478       0.459
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  243
Model:                          Logit   Df Residuals:                      236
Method:                           MLE   Df Model:                            6
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.01012
Time:                        16:13:39   Log-Likelihood:                -148.66
converged:                       True   LL-Null:                       -150.18
Covariance Type:            nonrobust   LLR p-value:                    0.8039
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                             0.3420      2.104      0.163      0.871      -3.781       4.465
C(domain_grouped)[T.chemistry]        0.4099      0.512      0.800      0.424      -0.594       1.414
C(domain_grouped)[T.physics]          0.1191      0.538      0.221      0.825      -0.936       1.174
human_difficulty                      0.0384      0.252      0.153      0.879      -0.455       0.532
q_length                             -0.2603      0.219     -1.190      0.234      -0.689       0.168
avg_word_length                       0.0127      0.232      0.055      0.956      -0.443       0.468
percent_non_alphabetic_whitespace    -0.0015      0.024     -0.061      0.952      -0.049       0.046
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 0.4798
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  243
Model:                          Logit   Df Residuals:                      235
Method:                           MLE   Df Model:                            7
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.03513
Time:                        16:13:39   Log-Likelihood:                -144.90
converged:                       True   LL-Null:                       -150.18
Covariance Type:            nonrobust   LLR p-value:                    0.1594
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -0.2601      2.148     -0.121      0.904      -4.471       3.951
C(domain_grouped)[T.chemistry]        0.2881      0.521      0.553      0.580      -0.734       1.310
C(domain_grouped)[T.physics]          0.0078      0.548      0.014      0.989      -1.067       1.082
human_difficulty                      0.0577      0.257      0.225      0.822      -0.445       0.561
q_length                             -0.2226      0.222     -1.003      0.316      -0.658       0.212
avg_word_length                       0.0237      0.237      0.100      0.920      -0.441       0.488
percent_non_alphabetic_whitespace     0.0020      0.025      0.082      0.935      -0.047       0.051
capabilities_entropy                  0.6930      0.253      2.735      0.006       0.196       1.190
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  243
Model:                          Logit   Df Residuals:                      235
Method:                           MLE   Df Model:                            7
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.08914
Time:                        16:13:39   Log-Likelihood:                -136.79
converged:                       True   LL-Null:                       -150.18
Covariance Type:            nonrobust   LLR p-value:                 0.0003663
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -1.4167      2.209     -0.641      0.521      -5.747       2.914
C(domain_grouped)[T.chemistry]        0.3558      0.531      0.671      0.503      -0.684       1.396
C(domain_grouped)[T.physics]          0.0434      0.556      0.078      0.938      -1.045       1.132
human_difficulty                      0.0871      0.261      0.334      0.738      -0.424       0.598
q_length                             -0.2759      0.231     -1.196      0.232      -0.728       0.176
avg_word_length                       0.2010      0.240      0.837      0.403      -0.270       0.672
percent_non_alphabetic_whitespace     0.0090      0.026      0.345      0.730      -0.042       0.060
game_entropy                          1.4345      0.308      4.657      0.000       0.831       2.038
=====================================================================================================

                  Model 4.95: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  243
Model:                          Logit   Df Residuals:                      234
Method:                           MLE   Df Model:                            8
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.09860
Time:                        16:13:39   Log-Likelihood:                -135.37
converged:                       True   LL-Null:                       -150.18
Covariance Type:            nonrobust   LLR p-value:                 0.0002472
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -1.6319      2.230     -0.732      0.464      -6.002       2.738
C(domain_grouped)[T.chemistry]        0.2807      0.536      0.524      0.601      -0.770       1.331
C(domain_grouped)[T.physics]         -0.0250      0.562     -0.044      0.965      -1.127       1.077
human_difficulty                      0.0914      0.263      0.348      0.728      -0.424       0.607
q_length                             -0.2550      0.233     -1.093      0.274      -0.712       0.202
avg_word_length                       0.1947      0.243      0.801      0.423      -0.282       0.671
percent_non_alphabetic_whitespace     0.0099      0.026      0.374      0.709      -0.042       0.062
capabilities_entropy                  0.4573      0.270      1.692      0.091      -0.072       0.987
game_entropy                          1.3254      0.315      4.209      0.000       0.708       1.943
=====================================================================================================
