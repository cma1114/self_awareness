
--- Analyzing claude-3-5-sonnet-20241022 (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_neutral/claude-3-5-sonnet-20241022_SimpleMC_redacted_cor_temp0.0_1754440066_game_data.json', './sc_logs_neutral/claude-3-5-sonnet-20241022_SimpleMC_redacted_temp0.0_1754435021_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    393
1    107
Name: count, dtype: int64

Answer change%: 0.2140 [0.1780514606840268, 0.2499485393159732] (n=500)
P-value vs 25%: 0.04967; P-value vs 0%: 1.867e-31
Phase 2 self-accuracy: 0.3551 [0.2644649355534616, 0.44581543827831405] (n=107)
P-value vs 25%: 0.02305; P-value vs 33%: 0.6322

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.2128
Time:                        16:14:57   Log-Likelihood:                -204.36
converged:                       True   LL-Null:                       -259.60
Covariance Type:            nonrobust   LLR p-value:                 7.689e-26
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          2.5250      0.404      6.253      0.000       1.734       3.316
p_i_capability    -5.9532      0.664     -8.963      0.000      -7.255      -4.651
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.2143
Time:                        16:14:57   Log-Likelihood:                -203.98
converged:                       True   LL-Null:                       -259.60
Covariance Type:            nonrobust   LLR p-value:                 5.206e-26
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -4.2352      0.408    -10.390      0.000      -5.034      -3.436
capabilities_entropy     2.3682      0.274      8.648      0.000       1.832       2.905
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.6636 [0.5740, 0.7531] (n=107)
                  P-value vs 33.3%: 4.855e-13

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=-0.36, p=0.716
Wilcoxon delta_p: statistic=23303.00, p=0.985
Mean Δp = -0.0028  [-0.0177, 0.0121]
Idea 1 N = 393; 

  Idea 1.5: Calibration Metrics
  NLL: 1.0679, Signed ECE (overconf pos under neg): -0.0626, ECE: 0.1490 (n=500)
  Brier: 0.0648, Reliability (absolute calibration error; lower better): 0.0387, Resolution (relative calibration quality; higher better): 0.2126, Uncertainty: 0.2400 (n=500)
  AUROC: 0.9968

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.564
Model:                            OLS   Adj. R-squared:                  0.561
Method:                 Least Squares   F-statistic:                     213.9
Date:                Wed, 24 Sep 2025   Prob (F-statistic):           5.29e-89
Time:                        16:14:57   Log-Likelihood:                 301.57
No. Observations:                 500   AIC:                            -595.1
Df Residuals:                     496   BIC:                            -578.3
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.2418      0.027     -9.109      0.000      -0.294      -0.190
p1                    0.3109      0.033      9.307      0.000       0.245       0.377
answer_changed        0.0366      0.051      0.718      0.473      -0.064       0.137
p1:answer_changed     0.6336      0.086      7.372      0.000       0.465       0.802
==============================================================================
Omnibus:                       13.191   Durbin-Watson:                   1.949
Prob(Omnibus):                  0.001   Jarque-Bera (JB):               14.383
Skew:                           0.332   Prob(JB):                     0.000753
Kurtosis:                       3.499   Cond. No.                         21.4
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=1.01, p=0.314
Wilcoxon delta_H: statistic=22273.00, p=0.38
Mean ΔH = 0.0194  [-0.0183, 0.0570]
Paired t-test delta_H Changed: statistic=9.24, p=2.84e-15
Wilcoxon delta_H Changed: statistic=471.00, p=5.68e-14
Mean ΔH Changed = 0.3299  [0.2599, 0.3998]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=2.50, p=0.0128
Wilcoxon (p_top2_game vs p_top2_base): statistic=37509.00, p=0.031
Mean Δp_top2 = 0.0096  [0.0021, 0.0171] (n=500)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=4.81, p=1.99e-06
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=31186.00, p=1.36e-06
Mean ΔH_unchosen_baseline_set = 0.0858  [0.0509, 0.1208] (n=500)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      497
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.2185
Time:                        16:14:57   Log-Likelihood:                -202.87
converged:                       True   LL-Null:                       -259.60
Covariance Type:            nonrobust   LLR p-value:                 2.293e-25
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.5677      0.186     -8.437      0.000      -1.932      -1.204
p1_z            -1.5166      0.210     -7.230      0.000      -1.928      -1.105
I(p1_z ** 2)    -0.2863      0.168     -1.708      0.088      -0.615       0.042
================================================================================
AUC = 0.815

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1564
Time:                        16:14:57   Log-Likelihood:                -219.01
converged:                       True   LL-Null:                       -259.60
Covariance Type:            nonrobust   LLR p-value:                 2.044e-19
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -3.5822      0.347    -10.318      0.000      -4.263      -2.902
game_entropy     1.9598      0.248      7.899      0.000       1.474       2.446
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=39042.00, p=0.108
Paired t-test (game_entropy vs capabilities_entropy): statistic=-1.79, p=0.0748
Mean game_entropy-capabilities_entropy = -0.0305  [-0.0640, 0.0030] (n=500)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      497
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.2203
Time:                        16:14:57   Log-Likelihood:                -202.42
converged:                       True   LL-Null:                       -259.60
Covariance Type:            nonrobust   LLR p-value:                 1.468e-25
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -4.4190      0.429    -10.306      0.000      -5.259      -3.579
capabilities_entropy     1.9609      0.357      5.498      0.000       1.262       2.660
game_entropy             0.5840      0.335      1.745      0.081      -0.072       1.240
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.760000
                        1                 0.240000
Geography               0                 0.704545
                        1                 0.295455
Misc                    0                 0.851351
                        1                 0.148649
Music                   0                 0.800000
                        1                 0.200000
Other                   0                 0.769231
                        1                 0.230769
Politics                0                 0.805195
                        1                 0.194805
Science and technology  0                 0.785714
                        1                 0.214286
Sports                  0                 0.775000
                        1                 0.225000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.704142
                     1                 0.295858
Number               0                 0.833333
                     1                 0.166667
Other                0                 0.842105
                     1                 0.157895
Person               0                 0.808333
                     1                 0.191667
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.619048  0.380952           21
                       Number               0.777778  0.222222            9
                       Other                0.888889  0.111111           18
                       Person               0.777778  0.222222           27
Geography              Date                 0.533333  0.466667           15
                       Number               0.833333  0.166667           18
                       Other                0.727273  0.272727           11
Misc                   Date                 0.782609  0.217391           23
                       Number               0.777778  0.222222            9
                       Other                0.925926  0.074074           27
                       Person               0.866667  0.133333           15
Music                  Date                 0.666667  0.333333           12
                       Number               1.000000  0.000000            4
                       Other                0.750000  0.250000           12
                       Person               0.916667  0.083333           12
Other                  Date                 0.722222  0.277778           18
                       Number               1.000000  0.000000            7
                       Other                0.785714  0.214286           14
                       Person               0.692308  0.307692           13
Politics               Date                 0.666667  0.333333           36
                       Number               0.833333  0.166667            6
                       Other                0.950000  0.050000           20
                       Person               0.933333  0.066667           15
Science and technology Date                 0.771429  0.228571           35
                       Number               0.714286  0.285714           14
                       Other                0.894737  0.105263           19
                       Person               0.766667  0.233333           30
Sports                 Date                 0.888889  0.111111            9
                       Number               0.909091  0.090909           11
                       Other                0.583333  0.416667           12
                       Person               0.750000  0.250000            8

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      488
Method:                           MLE   Df Model:                           11
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.03007
Time:                        16:14:57   Log-Likelihood:                -251.80
converged:                       True   LL-Null:                       -259.60
Covariance Type:            nonrobust   LLR p-value:                    0.1562
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.1623      1.398     -0.832      0.406      -3.901       1.577
C(topic_grouped)[T.Geography]                  0.3495      0.451      0.775      0.438      -0.534       1.233
C(topic_grouped)[T.Misc]                      -0.5992      0.431     -1.391      0.164      -1.444       0.245
C(topic_grouped)[T.Music]                     -0.2388      0.485     -0.492      0.622      -1.189       0.711
C(topic_grouped)[T.Other]                     -0.0811      0.432     -0.188      0.851      -0.928       0.766
C(topic_grouped)[T.Politics]                  -0.4200      0.410     -1.025      0.305      -1.223       0.383
C(topic_grouped)[T.Science and technology]    -0.2104      0.372     -0.566      0.571      -0.939       0.518
C(topic_grouped)[T.Sports]                     0.0107      0.475      0.023      0.982      -0.919       0.941
C(answer_type_grouped)[T.Number]              -0.8929      0.362     -2.468      0.014      -1.602      -0.184
C(answer_type_grouped)[T.Other]               -0.8032      0.296     -2.715      0.007      -1.383      -0.223
C(answer_type_grouped)[T.Person]              -0.5576      0.295     -1.891      0.059      -1.136       0.020
q_length                                       0.1076      0.302      0.357      0.721      -0.484       0.699
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 1.0251
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      487
Method:                           MLE   Df Model:                           12
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.2378
Time:                        16:14:57   Log-Likelihood:                -197.87
converged:                       True   LL-Null:                       -259.60
Covariance Type:            nonrobust   LLR p-value:                 1.261e-20
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -4.1144      1.671     -2.462      0.014      -7.390      -0.839
C(topic_grouped)[T.Geography]                  0.0357      0.510      0.070      0.944      -0.963       1.034
C(topic_grouped)[T.Misc]                      -0.7060      0.485     -1.457      0.145      -1.656       0.244
C(topic_grouped)[T.Music]                     -0.4749      0.549     -0.865      0.387      -1.551       0.602
C(topic_grouped)[T.Other]                     -0.2804      0.506     -0.554      0.579      -1.271       0.711
C(topic_grouped)[T.Politics]                  -0.2608      0.467     -0.559      0.576      -1.175       0.654
C(topic_grouped)[T.Science and technology]    -0.3514      0.421     -0.835      0.404      -1.177       0.474
C(topic_grouped)[T.Sports]                     0.0101      0.548      0.018      0.985      -1.064       1.084
C(answer_type_grouped)[T.Number]              -1.0797      0.392     -2.755      0.006      -1.848      -0.312
C(answer_type_grouped)[T.Other]               -0.5189      0.339     -1.530      0.126      -1.184       0.146
C(answer_type_grouped)[T.Person]              -0.1076      0.345     -0.312      0.755      -0.784       0.569
q_length                                       0.0933      0.349      0.268      0.789      -0.590       0.777
capabilities_entropy                           2.4011      0.280      8.570      0.000       1.852       2.950
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      487
Method:                           MLE   Df Model:                           12
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1882
Time:                        16:14:57   Log-Likelihood:                -210.76
converged:                       True   LL-Null:                       -259.60
Covariance Type:            nonrobust   LLR p-value:                 1.572e-15
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -4.6018      1.651     -2.787      0.005      -7.839      -1.365
C(topic_grouped)[T.Geography]                  0.2076      0.498      0.417      0.677      -0.769       1.184
C(topic_grouped)[T.Misc]                      -0.8845      0.475     -1.861      0.063      -1.816       0.047
C(topic_grouped)[T.Music]                     -0.6901      0.535     -1.289      0.197      -1.739       0.359
C(topic_grouped)[T.Other]                     -0.4112      0.478     -0.861      0.389      -1.347       0.525
C(topic_grouped)[T.Politics]                  -0.1208      0.452     -0.267      0.789      -1.007       0.765
C(topic_grouped)[T.Science and technology]    -0.2777      0.411     -0.675      0.499      -1.084       0.528
C(topic_grouped)[T.Sports]                     0.0413      0.519      0.080      0.936      -0.975       1.058
C(answer_type_grouped)[T.Number]              -1.1041      0.387     -2.855      0.004      -1.862      -0.346
C(answer_type_grouped)[T.Other]               -0.3215      0.331     -0.970      0.332      -0.971       0.328
C(answer_type_grouped)[T.Person]               0.1280      0.340      0.377      0.706      -0.538       0.794
q_length                                       0.2863      0.342      0.837      0.402      -0.384       0.957
game_entropy                                   2.1313      0.268      7.941      0.000       1.605       2.657
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      486
Method:                           MLE   Df Model:                           13
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.2472
Time:                        16:14:57   Log-Likelihood:                -195.43
converged:                       True   LL-Null:                       -259.60
Covariance Type:            nonrobust   LLR p-value:                 4.456e-21
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -4.7942      1.727     -2.777      0.005      -8.178      -1.410
C(topic_grouped)[T.Geography]                  0.0632      0.513      0.123      0.902      -0.942       1.069
C(topic_grouped)[T.Misc]                      -0.7876      0.489     -1.610      0.107      -1.747       0.171
C(topic_grouped)[T.Music]                     -0.6100      0.559     -1.092      0.275      -1.705       0.485
C(topic_grouped)[T.Other]                     -0.3546      0.507     -0.699      0.484      -1.349       0.640
C(topic_grouped)[T.Politics]                  -0.1629      0.472     -0.345      0.730      -1.089       0.763
C(topic_grouped)[T.Science and technology]    -0.3445      0.424     -0.812      0.417      -1.176       0.487
C(topic_grouped)[T.Sports]                     0.0280      0.548      0.051      0.959      -1.045       1.101
C(answer_type_grouped)[T.Number]              -1.1188      0.394     -2.838      0.005      -1.892      -0.346
C(answer_type_grouped)[T.Other]               -0.4105      0.346     -1.187      0.235      -1.088       0.267
C(answer_type_grouped)[T.Person]               0.0531      0.356      0.149      0.882      -0.645       0.751
q_length                                       0.1679      0.355      0.473      0.637      -0.528       0.864
capabilities_entropy                           1.9007      0.358      5.302      0.000       1.198       2.603
game_entropy                                   0.7747      0.355      2.184      0.029       0.079       1.470
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing claude-3-haiku-20240307 (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_neutral/claude-3-haiku-20240307_SimpleMC_redacted_cor_temp0.0_1754426360_game_data.json', './sc_logs_neutral/claude-3-haiku-20240307_SimpleMC_redacted_temp0.0_1754368901_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    392
1    108
Name: count, dtype: int64

Answer change%: 0.2160 [0.1799298460626621, 0.2520701539373379] (n=500)
P-value vs 25%: 0.06468; P-value vs 0%: 8.244e-32
Phase 2 self-accuracy: 0.3981 [0.30582653935015763, 0.49046975694613865] (n=108)
P-value vs 25%: 0.00166; P-value vs 33%: 0.1666

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.08143
Time:                        16:14:57   Log-Likelihood:                -239.65
converged:                       True   LL-Null:                       -260.90
Covariance Type:            nonrobust   LLR p-value:                 7.103e-11
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          3.0867      0.682      4.523      0.000       1.749       4.424
p_i_capability    -4.9457      0.769     -6.431      0.000      -6.453      -3.438
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.08674
Time:                        16:14:57   Log-Likelihood:                -238.27
converged:                       True   LL-Null:                       -260.90
Covariance Type:            nonrobust   LLR p-value:                 1.724e-11
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.4268      0.215    -11.292      0.000      -2.848      -2.006
capabilities_entropy     2.3553      0.359      6.567      0.000       1.652       3.058
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.5185 [0.4243, 0.6128] (n=108)
                  P-value vs 33.3%: 0.0001173

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=2.56, p=0.0107
Wilcoxon delta_p: statistic=5968.00, p=0.00517
Mean Δp = 0.0160  [0.0038, 0.0282]
Idea 1 N = 392; 

  Idea 1.5: Calibration Metrics
  NLL: 2.9673, Signed ECE (overconf pos under neg): -0.0037, ECE: 0.0373 (n=500)
  Brier: 0.0164, Reliability (absolute calibration error; lower better): 0.0039, Resolution (relative calibration quality; higher better): 0.1977, Uncertainty: 0.2108 (n=500)
  AUROC: 0.9988

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.868
Model:                            OLS   Adj. R-squared:                  0.868
Method:                 Least Squares   F-statistic:                     1091.
Date:                Wed, 24 Sep 2025   Prob (F-statistic):          6.57e-218
Time:                        16:14:57   Log-Likelihood:                 382.60
No. Observations:                 500   AIC:                            -757.2
Df Residuals:                     496   BIC:                            -740.3
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.5984      0.056    -10.765      0.000      -0.708      -0.489
p1                    0.6650      0.060     11.111      0.000       0.547       0.783
answer_changed        0.5493      0.075      7.352      0.000       0.403       0.696
p1:answer_changed     0.2183      0.084      2.597      0.010       0.053       0.383
==============================================================================
Omnibus:                      129.153   Durbin-Watson:                   2.074
Prob(Omnibus):                  0.000   Jarque-Bera (JB):              353.477
Skew:                           1.253   Prob(JB):                     1.75e-77
Kurtosis:                       6.269   Cond. No.                         35.5
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=1.21, p=0.228
Wilcoxon delta_H: statistic=7122.50, p=0.269
Mean ΔH = 0.0350  [-0.0218, 0.0917]
Paired t-test delta_H Changed: statistic=9.79, p=1.49e-16
Wilcoxon delta_H Changed: statistic=645.00, p=1.86e-12
Mean ΔH Changed = 0.6990  [0.5591, 0.8389]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=-4.26, p=2.4e-05
Wilcoxon (p_top2_game vs p_top2_base): statistic=14602.50, p=0.0017
Mean Δp_top2 = -0.0098  [-0.0143, -0.0053] (n=500)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=5.95, p=5.16e-09
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=12502.00, p=1.55e-08
Mean ΔH_unchosen_baseline_set = 0.1784  [0.1196, 0.2372] (n=500)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      497
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.08275
Time:                        16:14:57   Log-Likelihood:                -239.31
converged:                       True   LL-Null:                       -260.90
Covariance Type:            nonrobust   LLR p-value:                 4.206e-10
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.4710      0.164     -8.967      0.000      -1.793      -1.150
p1_z            -0.4008      0.294     -1.361      0.173      -0.978       0.176
I(p1_z ** 2)     0.1003      0.124      0.810      0.418      -0.142       0.343
================================================================================
AUC = 0.649

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1317
Time:                        16:14:57   Log-Likelihood:                -226.54
converged:                       True   LL-Null:                       -260.90
Covariance Type:            nonrobust   LLR p-value:                 1.137e-16
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -2.6538      0.221    -12.009      0.000      -3.087      -2.221
game_entropy     2.2823      0.292      7.806      0.000       1.709       2.855
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=12125.50, p=4.75e-07
Paired t-test (game_entropy vs capabilities_entropy): statistic=5.04, p=6.5e-07
Mean game_entropy-capabilities_entropy = 0.0876  [0.0535, 0.1216] (n=500)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      497
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1741
Time:                        16:14:57   Log-Likelihood:                -215.47
converged:                       True   LL-Null:                       -260.90
Covariance Type:            nonrobust   LLR p-value:                 1.865e-20
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -3.3670      0.288    -11.704      0.000      -3.931      -2.803
capabilities_entropy     1.8501      0.392      4.719      0.000       1.082       2.618
game_entropy             1.9990      0.306      6.540      0.000       1.400       2.598
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.773333
                        1                 0.226667
Geography               0                 0.818182
                        1                 0.181818
Misc                    0                 0.810811
                        1                 0.189189
Music                   0                 0.825000
                        1                 0.175000
Other                   0                 0.769231
                        1                 0.230769
Politics                0                 0.792208
                        1                 0.207792
Science and technology  0                 0.755102
                        1                 0.244898
Sports                  0                 0.750000
                        1                 0.250000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.769231
                     1                 0.230769
Number               0                 0.769231
                     1                 0.230769
Other                0                 0.804511
                     1                 0.195489
Person               0                 0.791667
                     1                 0.208333
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.714286  0.285714           21
                       Number               0.777778  0.222222            9
                       Other                0.722222  0.277778           18
                       Person               0.851852  0.148148           27
Geography              Date                 0.866667  0.133333           15
                       Number               0.777778  0.222222           18
                       Other                0.818182  0.181818           11
Misc                   Date                 0.652174  0.347826           23
                       Number               1.000000  0.000000            9
                       Other                0.888889  0.111111           27
                       Person               0.800000  0.200000           15
Music                  Date                 0.750000  0.250000           12
                       Number               1.000000  0.000000            4
                       Other                0.833333  0.166667           12
                       Person               0.833333  0.166667           12
Other                  Date                 0.888889  0.111111           18
                       Number               0.857143  0.142857            7
                       Other                0.642857  0.357143           14
                       Person               0.692308  0.307692           13
Politics               Date                 0.750000  0.250000           36
                       Number               0.666667  0.333333            6
                       Other                0.950000  0.050000           20
                       Person               0.733333  0.266667           15
Science and technology Date                 0.771429  0.228571           35
                       Number               0.571429  0.428571           14
                       Other                0.842105  0.157895           19
                       Person               0.766667  0.233333           30
Sports                 Date                 0.888889  0.111111            9
                       Number               0.727273  0.272727           11
                       Other                0.583333  0.416667           12
                       Person               0.875000  0.125000            8

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      488
Method:                           MLE   Df Model:                           11
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                0.005409
Time:                        16:14:57   Log-Likelihood:                -259.49
converged:                       True   LL-Null:                       -260.90
Covariance Type:            nonrobust   LLR p-value:                    0.9929
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.6331      1.357     -1.204      0.229      -4.293       1.026
C(topic_grouped)[T.Geography]                 -0.3312      0.493     -0.671      0.502      -1.298       0.636
C(topic_grouped)[T.Misc]                      -0.2332      0.408     -0.571      0.568      -1.033       0.567
C(topic_grouped)[T.Music]                     -0.3163      0.500     -0.632      0.527      -1.297       0.664
C(topic_grouped)[T.Other]                      0.0139      0.431      0.032      0.974      -0.831       0.858
C(topic_grouped)[T.Politics]                  -0.1605      0.403     -0.398      0.691      -0.951       0.630
C(topic_grouped)[T.Science and technology]     0.0731      0.364      0.201      0.841      -0.641       0.787
C(topic_grouped)[T.Sports]                     0.1115      0.462      0.241      0.809      -0.794       1.017
C(answer_type_grouped)[T.Number]               0.0018      0.335      0.005      0.996      -0.655       0.658
C(answer_type_grouped)[T.Other]               -0.1917      0.288     -0.665      0.506      -0.757       0.373
C(answer_type_grouped)[T.Person]              -0.1605      0.296     -0.542      0.588      -0.740       0.419
q_length                                       0.1135      0.292      0.389      0.698      -0.459       0.686
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.4423
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      487
Method:                           MLE   Df Model:                           12
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.09359
Time:                        16:14:57   Log-Likelihood:                -236.48
converged:                       True   LL-Null:                       -260.90
Covariance Type:            nonrobust   LLR p-value:                 2.236e-06
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -3.5744      1.494     -2.392      0.017      -6.503      -0.645
C(topic_grouped)[T.Geography]                 -0.4202      0.531     -0.791      0.429      -1.462       0.621
C(topic_grouped)[T.Misc]                      -0.2521      0.430     -0.586      0.558      -1.095       0.590
C(topic_grouped)[T.Music]                     -0.5086      0.544     -0.935      0.350      -1.575       0.558
C(topic_grouped)[T.Other]                     -0.0480      0.455     -0.105      0.916      -0.939       0.843
C(topic_grouped)[T.Politics]                  -0.1301      0.425     -0.306      0.760      -0.963       0.703
C(topic_grouped)[T.Science and technology]     0.0321      0.385      0.083      0.934      -0.723       0.787
C(topic_grouped)[T.Sports]                    -0.0868      0.494     -0.176      0.861      -1.056       0.882
C(answer_type_grouped)[T.Number]               0.0608      0.357      0.170      0.865      -0.640       0.761
C(answer_type_grouped)[T.Other]               -0.1338      0.307     -0.437      0.662      -0.735       0.467
C(answer_type_grouped)[T.Person]               0.0189      0.314      0.060      0.952      -0.597       0.634
q_length                                       0.2802      0.315      0.891      0.373      -0.337       0.897
capabilities_entropy                           2.4187      0.367      6.594      0.000       1.700       3.138
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      487
Method:                           MLE   Df Model:                           12
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1395
Time:                        16:14:57   Log-Likelihood:                -224.51
converged:                       True   LL-Null:                       -260.90
Covariance Type:            nonrobust   LLR p-value:                 9.651e-11
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -3.8522      1.522     -2.531      0.011      -6.836      -0.869
C(topic_grouped)[T.Geography]                 -0.3809      0.544     -0.701      0.484      -1.446       0.684
C(topic_grouped)[T.Misc]                      -0.2092      0.451     -0.464      0.642      -1.092       0.674
C(topic_grouped)[T.Music]                     -0.3611      0.560     -0.645      0.519      -1.458       0.736
C(topic_grouped)[T.Other]                      0.1112      0.464      0.239      0.811      -0.799       1.021
C(topic_grouped)[T.Politics]                  -0.0985      0.442     -0.223      0.824      -0.966       0.769
C(topic_grouped)[T.Science and technology]     0.2409      0.399      0.603      0.546      -0.541       1.023
C(topic_grouped)[T.Sports]                    -0.1667      0.533     -0.313      0.754      -1.211       0.878
C(answer_type_grouped)[T.Number]               0.0251      0.368      0.068      0.946      -0.696       0.746
C(answer_type_grouped)[T.Other]                0.0405      0.316      0.128      0.898      -0.578       0.659
C(answer_type_grouped)[T.Person]              -0.1888      0.325     -0.580      0.562      -0.826       0.449
q_length                                       0.2740      0.322      0.852      0.394      -0.357       0.905
game_entropy                                   2.3453      0.299      7.856      0.000       1.760       2.930
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      486
Method:                           MLE   Df Model:                           13
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1836
Time:                        16:14:57   Log-Likelihood:                -212.99
converged:                       True   LL-Null:                       -260.90
Covariance Type:            nonrobust   LLR p-value:                 1.068e-14
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -5.0494      1.602     -3.153      0.002      -8.188      -1.910
C(topic_grouped)[T.Geography]                 -0.4595      0.574     -0.800      0.424      -1.585       0.666
C(topic_grouped)[T.Misc]                      -0.2349      0.461     -0.509      0.611      -1.139       0.669
C(topic_grouped)[T.Music]                     -0.4918      0.565     -0.871      0.384      -1.598       0.615
C(topic_grouped)[T.Other]                      0.0574      0.476      0.121      0.904      -0.876       0.991
C(topic_grouped)[T.Politics]                  -0.0851      0.450     -0.189      0.850      -0.967       0.796
C(topic_grouped)[T.Science and technology]     0.2144      0.405      0.530      0.596      -0.579       1.008
C(topic_grouped)[T.Sports]                    -0.3302      0.558     -0.592      0.554      -1.424       0.763
C(answer_type_grouped)[T.Number]               0.0647      0.380      0.170      0.865      -0.681       0.810
C(answer_type_grouped)[T.Other]                0.0286      0.325      0.088      0.930      -0.609       0.666
C(answer_type_grouped)[T.Person]              -0.0829      0.336     -0.247      0.805      -0.742       0.576
q_length                                       0.3751      0.334      1.122      0.262      -0.280       1.030
capabilities_entropy                           1.9264      0.403      4.785      0.000       1.137       2.715
game_entropy                                   2.0633      0.311      6.632      0.000       1.454       2.673
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing claude-3-sonnet-20240229 (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_neutral/claude-3-sonnet-20240229_SimpleMC_redacted_cor_temp0.0_1751845655_game_data.json', './sc_logs_neutral/claude-3-sonnet-20240229_SimpleMC_redacted_temp0.0_1751827442_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    326
1    174
Name: count, dtype: int64

Answer change%: 0.3480 [0.3062480745215214, 0.38975192547847853] (n=500)
P-value vs 25%: 4.216e-06; P-value vs 0%: 5.456e-60
Phase 2 self-accuracy: 0.2874 [0.2201175049181228, 0.3545951387600381] (n=174)
P-value vs 25%: 0.2762; P-value vs 33%: 0.1834
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.573333
                        1                 0.426667
Geography               0                 0.613636
                        1                 0.386364
Misc                    0                 0.743243
                        1                 0.256757
Music                   0                 0.825000
                        1                 0.175000
Other                   0                 0.634615
                        1                 0.365385
Politics                0                 0.623377
                        1                 0.376623
Science and technology  0                 0.663265
                        1                 0.336735
Sports                  0                 0.550000
                        1                 0.450000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.644970
                     1                 0.355030
Number               0                 0.551282
                     1                 0.448718
Other                0                 0.706767
                     1                 0.293233
Person               0                 0.666667
                     1                 0.333333
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.523810  0.476190           21
                       Number               0.333333  0.666667            9
                       Other                0.611111  0.388889           18
                       Person               0.666667  0.333333           27
Geography              Date                 0.600000  0.400000           15
                       Number               0.555556  0.444444           18
                       Other                0.727273  0.272727           11
Misc                   Date                 0.826087  0.173913           23
                       Number               0.777778  0.222222            9
                       Other                0.740741  0.259259           27
                       Person               0.600000  0.400000           15
Music                  Date                 0.750000  0.250000           12
                       Number               0.750000  0.250000            4
                       Other                0.833333  0.166667           12
                       Person               0.916667  0.083333           12
Other                  Date                 0.666667  0.333333           18
                       Number               0.714286  0.285714            7
                       Other                0.714286  0.285714           14
                       Person               0.461538  0.538462           13
Politics               Date                 0.638889  0.361111           36
                       Number               0.333333  0.666667            6
                       Other                0.700000  0.300000           20
                       Person               0.600000  0.400000           15
Science and technology Date                 0.600000  0.400000           35
                       Number               0.571429  0.428571           14
                       Other                0.789474  0.210526           19
                       Person               0.700000  0.300000           30
Sports                 Date                 0.555556  0.444444            9
                       Number               0.454545  0.545455           11
                       Other                0.500000  0.500000           12
                       Person               0.750000  0.250000            8

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      488
Method:                           MLE   Df Model:                           11
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.03121
Time:                        16:14:57   Log-Likelihood:                -313.02
converged:                       True   LL-Null:                       -323.10
Covariance Type:            nonrobust   LLR p-value:                   0.04309
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      1.6745      1.201      1.394      0.163      -0.680       4.029
C(topic_grouped)[T.Geography]                 -0.3424      0.405     -0.845      0.398      -1.137       0.452
C(topic_grouped)[T.Misc]                      -0.7528      0.358     -2.101      0.036      -1.455      -0.051
C(topic_grouped)[T.Music]                     -1.2720      0.480     -2.651      0.008      -2.212      -0.332
C(topic_grouped)[T.Other]                     -0.2845      0.375     -0.759      0.448      -1.019       0.450
C(topic_grouped)[T.Politics]                  -0.1180      0.341     -0.346      0.729      -0.786       0.550
C(topic_grouped)[T.Science and technology]    -0.3810      0.320     -1.191      0.234      -1.008       0.246
C(topic_grouped)[T.Sports]                     0.0383      0.401      0.096      0.924      -0.747       0.824
C(answer_type_grouped)[T.Number]               0.3838      0.291      1.321      0.187      -0.186       0.954
C(answer_type_grouped)[T.Other]               -0.2943      0.255     -1.152      0.249      -0.795       0.206
C(answer_type_grouped)[T.Person]              -0.1454      0.261     -0.557      0.578      -0.657       0.366
q_length                                      -0.4246      0.259     -1.637      0.102      -0.933       0.084
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing claude-opus-4-1-20250805 (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_neutral/claude-opus-4-1-20250805_SimpleMC_neut_redacted_cor_temp0.0_1758369604_game_data.json', './sc_logs_neutral/claude-opus-4-1-20250805_SimpleMC_neut_redacted_temp0.0_1758369148_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    403
1     97
Name: count, dtype: int64

Answer change%: 0.1940 [0.15933976725297372, 0.2286602327470263] (n=500)
P-value vs 25%: 0.001542; P-value vs 0%: 5.31e-28
Phase 2 self-accuracy: 0.4227 [0.3243752258641286, 0.5209855988781394] (n=97)
P-value vs 25%: 0.0005757; P-value vs 33%: 0.07377
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.840000
                        1                 0.160000
Geography               0                 0.818182
                        1                 0.181818
Misc                    0                 0.783784
                        1                 0.216216
Music                   0                 0.750000
                        1                 0.250000
Other                   0                 0.769231
                        1                 0.230769
Politics                0                 0.818182
                        1                 0.181818
Science and technology  0                 0.836735
                        1                 0.163265
Sports                  0                 0.775000
                        1                 0.225000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.798817
                     1                 0.201183
Number               0                 0.743590
                     1                 0.256410
Other                0                 0.842105
                     1                 0.157895
Person               0                 0.816667
                     1                 0.183333
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.857143  0.142857           21
                       Number               0.777778  0.222222            9
                       Other                0.944444  0.055556           18
                       Person               0.777778  0.222222           27
Geography              Date                 0.800000  0.200000           15
                       Number               0.833333  0.166667           18
                       Other                0.818182  0.181818           11
Misc                   Date                 0.826087  0.173913           23
                       Number               0.777778  0.222222            9
                       Other                0.740741  0.259259           27
                       Person               0.800000  0.200000           15
Music                  Date                 0.500000  0.500000           12
                       Number               0.750000  0.250000            4
                       Other                0.916667  0.083333           12
                       Person               0.833333  0.166667           12
Other                  Date                 0.722222  0.277778           18
                       Number               0.571429  0.428571            7
                       Other                0.928571  0.071429           14
                       Person               0.769231  0.230769           13
Politics               Date                 0.833333  0.166667           36
                       Number               0.833333  0.166667            6
                       Other                0.750000  0.250000           20
                       Person               0.866667  0.133333           15
Science and technology Date                 0.885714  0.114286           35
                       Number               0.714286  0.285714           14
                       Other                0.894737  0.105263           19
                       Person               0.800000  0.200000           30
Sports                 Date                 0.666667  0.333333            9
                       Number               0.636364  0.363636           11
                       Other                0.833333  0.166667           12
                       Person               1.000000  0.000000            8

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      488
Method:                           MLE   Df Model:                           11
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.02393
Time:                        16:14:57   Log-Likelihood:                -240.10
converged:                       True   LL-Null:                       -245.99
Covariance Type:            nonrobust   LLR p-value:                    0.3811
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -4.7787      1.452     -3.292      0.001      -7.624      -1.933
C(topic_grouped)[T.Geography]                  0.0556      0.523      0.106      0.915      -0.970       1.082
C(topic_grouped)[T.Misc]                       0.3822      0.429      0.890      0.373      -0.459       1.224
C(topic_grouped)[T.Music]                      0.6262      0.487      1.286      0.198      -0.328       1.581
C(topic_grouped)[T.Other]                      0.4774      0.460      1.038      0.299      -0.424       1.379
C(topic_grouped)[T.Politics]                  -0.0052      0.447     -0.012      0.991      -0.881       0.870
C(topic_grouped)[T.Science and technology]    -0.0751      0.423     -0.178      0.859      -0.904       0.754
C(topic_grouped)[T.Sports]                     0.3604      0.503      0.716      0.474      -0.626       1.347
C(answer_type_grouped)[T.Number]               0.2894      0.338      0.857      0.391      -0.372       0.951
C(answer_type_grouped)[T.Other]               -0.2897      0.311     -0.932      0.351      -0.899       0.319
C(answer_type_grouped)[T.Person]              -0.0625      0.313     -0.200      0.842      -0.676       0.551
q_length                                       0.7043      0.309      2.282      0.022       0.099       1.309
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing claude-sonnet-4-20250514 (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_neutral/claude-sonnet-4-20250514_SimpleMC_redacted_cor_temp0.0_1751828378_game_data.json', './sc_logs_neutral/claude-sonnet-4-20250514_SimpleMC_redacted_temp0.0_1751824015_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    307
1    193
Name: count, dtype: int64

Answer change%: 0.3860 [0.34332820354520355, 0.42867179645479647] (n=500)
P-value vs 25%: 4.194e-10; P-value vs 0%: 2.486e-70
Phase 2 self-accuracy: 0.3886 [0.3198334528643938, 0.4573686196744663] (n=193)
P-value vs 25%: 7.805e-05; P-value vs 33%: 0.113
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.653333
                        1                 0.346667
Geography               0                 0.545455
                        1                 0.454545
Misc                    0                 0.635135
                        1                 0.364865
Music                   0                 0.750000
                        1                 0.250000
Other                   0                 0.596154
                        1                 0.403846
Politics                0                 0.636364
                        1                 0.363636
Science and technology  0                 0.571429
                        1                 0.428571
Sports                  0                 0.525000
                        1                 0.475000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.609467
                     1                 0.390533
Number               0                 0.576923
                     1                 0.423077
Other                0                 0.646617
                     1                 0.353383
Person               0                 0.608333
                     1                 0.391667
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.714286  0.285714           21
                       Number               0.555556  0.444444            9
                       Other                0.777778  0.222222           18
                       Person               0.555556  0.444444           27
Geography              Date                 0.266667  0.733333           15
                       Number               0.666667  0.333333           18
                       Other                0.727273  0.272727           11
Misc                   Date                 0.782609  0.217391           23
                       Number               0.444444  0.555556            9
                       Other                0.592593  0.407407           27
                       Person               0.600000  0.400000           15
Music                  Date                 0.750000  0.250000           12
                       Number               0.750000  0.250000            4
                       Other                0.666667  0.333333           12
                       Person               0.833333  0.166667           12
Other                  Date                 0.444444  0.555556           18
                       Number               0.714286  0.285714            7
                       Other                0.642857  0.357143           14
                       Person               0.692308  0.307692           13
Politics               Date                 0.638889  0.361111           36
                       Number               0.500000  0.500000            6
                       Other                0.600000  0.400000           20
                       Person               0.733333  0.266667           15
Science and technology Date                 0.600000  0.400000           35
                       Number               0.571429  0.428571           14
                       Other                0.684211  0.315789           19
                       Person               0.466667  0.533333           30
Sports                 Date                 0.555556  0.444444            9
                       Number               0.454545  0.545455           11
                       Other                0.500000  0.500000           12
                       Person               0.625000  0.375000            8

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      488
Method:                           MLE   Df Model:                           11
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.01171
Time:                        16:14:57   Log-Likelihood:                -329.56
converged:                       True   LL-Null:                       -333.46
Covariance Type:            nonrobust   LLR p-value:                    0.7303
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -0.7338      1.158     -0.633      0.526      -3.004       1.537
C(topic_grouped)[T.Geography]                  0.4592      0.402      1.144      0.253      -0.328       1.246
C(topic_grouped)[T.Misc]                       0.1045      0.345      0.303      0.762      -0.571       0.780
C(topic_grouped)[T.Music]                     -0.4518      0.439     -1.029      0.304      -1.313       0.409
C(topic_grouped)[T.Other]                      0.2541      0.374      0.680      0.497      -0.478       0.987
C(topic_grouped)[T.Politics]                   0.0809      0.346      0.233      0.815      -0.598       0.760
C(topic_grouped)[T.Science and technology]     0.3391      0.318      1.065      0.287      -0.285       0.963
C(topic_grouped)[T.Sports]                     0.5440      0.403      1.351      0.177      -0.245       1.333
C(answer_type_grouped)[T.Number]               0.0402      0.288      0.140      0.889      -0.524       0.604
C(answer_type_grouped)[T.Other]               -0.1489      0.244     -0.609      0.542      -0.628       0.330
C(answer_type_grouped)[T.Person]               0.0464      0.252      0.184      0.854      -0.447       0.539
q_length                                       0.0254      0.249      0.102      0.919      -0.463       0.514
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing deepseek-chat (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_neutral/deepseek-chat_SimpleMC_redacted_cor_temp0.0_1754439842_game_data.json', './sc_logs_neutral/deepseek-chat_SimpleMC_redacted_temp0.0_1754433214_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    404
1     91
Name: count, dtype: int64

Answer change%: 0.1838 [0.14971503300170516, 0.2179617346750625] (n=495)
P-value vs 25%: 0.0001446; P-value vs 0%: 4.604e-26
Phase 2 self-accuracy: 0.4066 [0.3056718955193283, 0.5075149176674849] (n=91)
P-value vs 25%: 0.002357; P-value vs 33%: 0.1529

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  495
Model:                          Logit   Df Residuals:                      493
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.05227
Time:                        16:14:57   Log-Likelihood:                -223.85
converged:                       True   LL-Null:                       -236.20
Covariance Type:            nonrobust   LLR p-value:                 6.733e-07
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          0.6579      0.435      1.513      0.130      -0.194       1.510
p_i_capability    -2.8386      0.579     -4.904      0.000      -3.973      -1.704
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  495
Model:                          Logit   Df Residuals:                      493
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.06230
Time:                        16:14:57   Log-Likelihood:                -221.48
converged:                       True   LL-Null:                       -236.20
Covariance Type:            nonrobust   LLR p-value:                 5.792e-08
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.4166      0.234    -10.334      0.000      -2.875      -1.958
capabilities_entropy     1.0865      0.208      5.223      0.000       0.679       1.494
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.3297 [0.2331, 0.4263] (n=91)
                  P-value vs 33.3%: 0.9407

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=22.46, p=7.13e-73
Wilcoxon delta_p: statistic=6075.00, p=3.72e-49
Mean Δp = 0.5258  [0.4799, 0.5717]
Idea 1 N = 401; 

  Idea 1.5: Calibration Metrics
  NLL: 3.8173, Signed ECE (overconf pos under neg): -0.2143, ECE: 0.3771 (n=455)
  Brier: 0.4108, Reliability (absolute calibration error; lower better): 0.1739, Resolution (relative calibration quality; higher better): 0.0137, Uncertainty: 0.2480 (n=455)
  AUROC: 0.4243

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.214
Model:                            OLS   Adj. R-squared:                  0.209
Method:                 Least Squares   F-statistic:                     44.35
Date:                Wed, 24 Sep 2025   Prob (F-statistic):           2.32e-25
Time:                        16:14:57   Log-Likelihood:                -253.27
No. Observations:                 492   AIC:                             514.5
Df Residuals:                     488   BIC:                             531.3
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.3716      0.087     -4.292      0.000      -0.542      -0.201
p1                    1.1047      0.104     10.662      0.000       0.901       1.308
answer_changed        0.1604      0.188      0.854      0.393      -0.208       0.529
p1:answer_changed    -0.1504      0.253     -0.594      0.553      -0.648       0.347
==============================================================================
Omnibus:                      128.904   Durbin-Watson:                   1.961
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               97.565
Skew:                          -0.987   Prob(JB):                     6.52e-22
Kurtosis:                       2.071   Cond. No.                         22.6
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=9.76, p=2.44e-20
Wilcoxon delta_H: statistic=19741.00, p=8.54e-19
Mean ΔH = 0.3450  [0.2757, 0.4142]
Paired t-test delta_H Changed: statistic=5.17, p=1.39e-06
Wilcoxon delta_H Changed: statistic=919.00, p=3.37e-06
Mean ΔH Changed = 0.3635  [0.2257, 0.5012]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=9.70, p=1.85e-20
Wilcoxon (p_top2_game vs p_top2_base): statistic=42669.00, p=1.23e-08
Mean Δp_top2 = 0.0392  [0.0313, 0.0471] (n=492)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=11.04, p=1.88e-25
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=29150.00, p=1.86e-23
Mean ΔH_unchosen_baseline_set = 0.3484  [0.2865, 0.4103] (n=492)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  492
Model:                          Logit   Df Residuals:                      489
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.06879
Time:                        16:14:57   Log-Likelihood:                -219.38
converged:                       True   LL-Null:                       -235.58
Covariance Type:            nonrobust   LLR p-value:                 9.155e-08
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.2311      0.172     -7.165      0.000      -1.568      -0.894
p1_z            -0.8681      0.167     -5.201      0.000      -1.195      -0.541
I(p1_z ** 2)    -0.4110      0.147     -2.805      0.005      -0.698      -0.124
================================================================================
AUC = 0.683

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  495
Model:                          Logit   Df Residuals:                      493
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1060
Time:                        16:14:57   Log-Likelihood:                -211.15
converged:                       True   LL-Null:                       -236.20
Covariance Type:            nonrobust   LLR p-value:                 1.466e-12
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -2.7995      0.238    -11.761      0.000      -3.266      -2.333
game_entropy     2.7009      0.397      6.807      0.000       1.923       3.479
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=31061.00, p=1.69e-21
Paired t-test (game_entropy vs capabilities_entropy): statistic=-11.78, p=2.08e-28
Mean game_entropy-capabilities_entropy = -0.2980  [-0.3476, -0.2485] (n=495)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  495
Model:                          Logit   Df Residuals:                      492
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1284
Time:                        16:14:57   Log-Likelihood:                -205.87
converged:                       True   LL-Null:                       -236.20
Covariance Type:            nonrobust   LLR p-value:                 6.766e-14
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -3.1962      0.284    -11.247      0.000      -3.753      -2.639
capabilities_entropy     0.7237      0.225      3.221      0.001       0.283       1.164
game_entropy             2.2563      0.417      5.406      0.000       1.438       3.074
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.866667
                        1                 0.133333
Geography               0                 0.813953
                        1                 0.186047
Misc                    0                 0.794521
                        1                 0.205479
Music                   0                 0.850000
                        1                 0.150000
Other                   0                 0.884615
                        1                 0.115385
Politics                0                 0.750000
                        1                 0.250000
Science and technology  0                 0.793814
                        1                 0.206186
Sports                  0                 0.820513
                        1                 0.179487
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.790419
                     1                 0.209581
Number               0                 0.818182
                     1                 0.181818
Other                0                 0.803030
                     1                 0.196970
Person               0                 0.865546
                     1                 0.134454
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.857143  0.142857           21
                       Number               1.000000  0.000000            9
                       Other                0.777778  0.222222           18
                       Person               0.888889  0.111111           27
Geography              Date                 0.785714  0.214286           14
                       Number               0.888889  0.111111           18
                       Other                0.727273  0.272727           11
Misc                   Date                 0.863636  0.136364           22
                       Number               0.777778  0.222222            9
                       Other                0.777778  0.222222           27
                       Person               0.733333  0.266667           15
Music                  Date                 0.916667  0.083333           12
                       Number               0.750000  0.250000            4
                       Other                0.833333  0.166667           12
                       Person               0.833333  0.166667           12
Other                  Date                 0.777778  0.222222           18
                       Number               1.000000  0.000000            7
                       Other                0.928571  0.071429           14
                       Person               0.923077  0.076923           13
Politics               Date                 0.750000  0.250000           36
                       Number               0.500000  0.500000            6
                       Other                0.842105  0.157895           19
                       Person               0.733333  0.266667           15
Science and technology Date                 0.742857  0.257143           35
                       Number               0.785714  0.214286           14
                       Other                0.684211  0.315789           19
                       Person               0.931034  0.068966           29
Sports                 Date                 0.666667  0.333333            9
                       Number               0.700000  0.300000           10
                       Other                0.916667  0.083333           12
                       Person               1.000000  0.000000            8

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  495
Model:                          Logit   Df Residuals:                      483
Method:                           MLE   Df Model:                           11
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.01793
Time:                        16:14:57   Log-Likelihood:                -231.96
converged:                       True   LL-Null:                       -236.20
Covariance Type:            nonrobust   LLR p-value:                    0.6706
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.9774      1.455     -1.359      0.174      -4.828       0.874
C(topic_grouped)[T.Geography]                  0.2804      0.533      0.526      0.599      -0.764       1.325
C(topic_grouped)[T.Misc]                       0.4569      0.450      1.016      0.310      -0.424       1.338
C(topic_grouped)[T.Music]                      0.1136      0.560      0.203      0.839      -0.984       1.211
C(topic_grouped)[T.Other]                     -0.2100      0.553     -0.380      0.704      -1.294       0.874
C(topic_grouped)[T.Politics]                   0.6843      0.441      1.551      0.121      -0.180       1.549
C(topic_grouped)[T.Science and technology]     0.4939      0.425      1.162      0.245      -0.339       1.327
C(topic_grouped)[T.Sports]                     0.3036      0.542      0.560      0.576      -0.759       1.367
C(answer_type_grouped)[T.Number]              -0.1235      0.364     -0.340      0.734      -0.836       0.589
C(answer_type_grouped)[T.Other]               -0.0363      0.295     -0.123      0.902      -0.615       0.542
C(answer_type_grouped)[T.Person]              -0.4688      0.337     -1.391      0.164      -1.129       0.192
q_length                                       0.0632      0.312      0.203      0.839      -0.548       0.674
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.7340
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  495
Model:                          Logit   Df Residuals:                      482
Method:                           MLE   Df Model:                           12
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.08078
Time:                        16:14:57   Log-Likelihood:                -217.12
converged:                       True   LL-Null:                       -236.20
Covariance Type:            nonrobust   LLR p-value:                 0.0001446
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -2.5125      1.534     -1.638      0.102      -5.520       0.495
C(topic_grouped)[T.Geography]                  0.2189      0.547      0.400      0.689      -0.854       1.291
C(topic_grouped)[T.Misc]                       0.2911      0.465      0.626      0.531      -0.620       1.202
C(topic_grouped)[T.Music]                      0.0593      0.576      0.103      0.918      -1.070       1.189
C(topic_grouped)[T.Other]                     -0.3566      0.567     -0.629      0.529      -1.468       0.755
C(topic_grouped)[T.Politics]                   0.6642      0.455      1.461      0.144      -0.227       1.555
C(topic_grouped)[T.Science and technology]     0.5122      0.440      1.164      0.244      -0.350       1.374
C(topic_grouped)[T.Sports]                     0.2444      0.559      0.437      0.662      -0.852       1.340
C(answer_type_grouped)[T.Number]              -0.1924      0.376     -0.511      0.609      -0.930       0.545
C(answer_type_grouped)[T.Other]                0.0021      0.307      0.007      0.995      -0.599       0.603
C(answer_type_grouped)[T.Person]              -0.4683      0.348     -1.344      0.179      -1.151       0.214
q_length                                      -0.0146      0.326     -0.045      0.964      -0.654       0.625
capabilities_entropy                           1.1046      0.211      5.247      0.000       0.692       1.517
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  495
Model:                          Logit   Df Residuals:                      482
Method:                           MLE   Df Model:                           12
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1301
Time:                        16:14:57   Log-Likelihood:                -205.47
converged:                       True   LL-Null:                       -236.20
Covariance Type:            nonrobust   LLR p-value:                 1.224e-08
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -2.8654      1.571     -1.824      0.068      -5.944       0.213
C(topic_grouped)[T.Geography]                  0.3117      0.580      0.537      0.591      -0.825       1.449
C(topic_grouped)[T.Misc]                       0.2562      0.483      0.531      0.596      -0.690       1.202
C(topic_grouped)[T.Music]                     -0.1432      0.595     -0.240      0.810      -1.310       1.024
C(topic_grouped)[T.Other]                     -0.4763      0.611     -0.779      0.436      -1.674       0.721
C(topic_grouped)[T.Politics]                   0.8389      0.467      1.798      0.072      -0.075       1.753
C(topic_grouped)[T.Science and technology]     0.6091      0.452      1.349      0.177      -0.276       1.494
C(topic_grouped)[T.Sports]                     0.2770      0.593      0.467      0.640      -0.885       1.439
C(answer_type_grouped)[T.Number]              -0.2281      0.418     -0.546      0.585      -1.047       0.591
C(answer_type_grouped)[T.Other]                0.2016      0.314      0.641      0.521      -0.414       0.817
C(answer_type_grouped)[T.Person]              -0.3035      0.358     -0.847      0.397      -1.006       0.399
q_length                                      -0.0676      0.332     -0.203      0.839      -0.719       0.584
game_entropy                                   2.9020      0.418      6.940      0.000       2.082       3.722
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  495
Model:                          Logit   Df Residuals:                      481
Method:                           MLE   Df Model:                           13
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1536
Time:                        16:14:57   Log-Likelihood:                -199.93
converged:                       True   LL-Null:                       -236.20
Covariance Type:            nonrobust   LLR p-value:                 2.723e-10
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -3.1116      1.605     -1.939      0.053      -6.257       0.034
C(topic_grouped)[T.Geography]                  0.2594      0.587      0.442      0.659      -0.891       1.410
C(topic_grouped)[T.Misc]                       0.1692      0.489      0.346      0.729      -0.789       1.127
C(topic_grouped)[T.Music]                     -0.1630      0.603     -0.271      0.787      -1.344       1.018
C(topic_grouped)[T.Other]                     -0.5923      0.620     -0.956      0.339      -1.807       0.622
C(topic_grouped)[T.Politics]                   0.8051      0.472      1.706      0.088      -0.120       1.730
C(topic_grouped)[T.Science and technology]     0.6061      0.459      1.320      0.187      -0.294       1.506
C(topic_grouped)[T.Sports]                     0.2375      0.601      0.395      0.693      -0.940       1.414
C(answer_type_grouped)[T.Number]              -0.2546      0.420     -0.607      0.544      -1.077       0.568
C(answer_type_grouped)[T.Other]                0.2070      0.320      0.647      0.517      -0.420       0.834
C(answer_type_grouped)[T.Person]              -0.3035      0.363     -0.835      0.403      -1.016       0.409
q_length                                      -0.0966      0.339     -0.285      0.775      -0.760       0.567
capabilities_entropy                           0.7468      0.226      3.300      0.001       0.303       1.190
game_entropy                                   2.4640      0.437      5.636      0.000       1.607       3.321
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing gemini-1.5-pro (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_neutral/gemini-1.5-pro_SimpleMC_redacted_cor_temp0.0_1751845219_game_data.json', './sc_logs_neutral/gemini-1.5-pro_SimpleMC_redacted_temp0.0_1751826859_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    409
1     91
Name: count, dtype: int64

Answer change%: 0.1820 [0.14817985738085485, 0.21582014261914514] (n=500)
P-value vs 25%: 8.122e-05; P-value vs 0%: 5.224e-26
Phase 2 self-accuracy: 0.4066 [0.3056718955193283, 0.5075149176674849] (n=91)
P-value vs 25%: 0.002357; P-value vs 33%: 0.1529
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.866667
                        1                 0.133333
Geography               0                 0.772727
                        1                 0.227273
Misc                    0                 0.810811
                        1                 0.189189
Music                   0                 0.775000
                        1                 0.225000
Other                   0                 0.769231
                        1                 0.230769
Politics                0                 0.857143
                        1                 0.142857
Science and technology  0                 0.775510
                        1                 0.224490
Sports                  0                 0.925000
                        1                 0.075000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.869822
                     1                 0.130178
Number               0                 0.794872
                     1                 0.205128
Other                0                 0.774436
                     1                 0.225564
Person               0                 0.808333
                     1                 0.191667
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.952381  0.047619           21
                       Number               0.777778  0.222222            9
                       Other                0.888889  0.111111           18
                       Person               0.814815  0.185185           27
Geography              Date                 0.733333  0.266667           15
                       Number               0.777778  0.222222           18
                       Other                0.818182  0.181818           11
Misc                   Date                 0.913043  0.086957           23
                       Number               0.777778  0.222222            9
                       Other                0.777778  0.222222           27
                       Person               0.733333  0.266667           15
Music                  Date                 0.916667  0.083333           12
                       Number               0.750000  0.250000            4
                       Other                0.416667  0.583333           12
                       Person               1.000000  0.000000           12
Other                  Date                 0.888889  0.111111           18
                       Number               1.000000  0.000000            7
                       Other                0.571429  0.428571           14
                       Person               0.692308  0.307692           13
Politics               Date                 0.888889  0.111111           36
                       Number               1.000000  0.000000            6
                       Other                0.850000  0.150000           20
                       Person               0.733333  0.266667           15
Science and technology Date                 0.771429  0.228571           35
                       Number               0.642857  0.357143           14
                       Other                0.789474  0.210526           19
                       Person               0.833333  0.166667           30
Sports                 Date                 1.000000  0.000000            9
                       Number               0.818182  0.181818           11
                       Other                1.000000  0.000000           12
                       Person               0.875000  0.125000            8

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      488
Method:                           MLE   Df Model:                           11
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.03109
Time:                        16:14:57   Log-Likelihood:                -229.83
converged:                       True   LL-Null:                       -237.21
Covariance Type:            nonrobust   LLR p-value:                    0.1942
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.9503      1.479     -1.319      0.187      -4.849       0.948
C(topic_grouped)[T.Geography]                  0.6541      0.515      1.271      0.204      -0.355       1.663
C(topic_grouped)[T.Misc]                       0.4062      0.456      0.891      0.373      -0.488       1.300
C(topic_grouped)[T.Music]                      0.6330      0.512      1.236      0.216      -0.371       1.637
C(topic_grouped)[T.Other]                      0.6936      0.477      1.455      0.146      -0.241       1.628
C(topic_grouped)[T.Politics]                   0.1803      0.480      0.375      0.707      -0.761       1.122
C(topic_grouped)[T.Science and technology]     0.6898      0.421      1.639      0.101      -0.135       1.515
C(topic_grouped)[T.Sports]                    -0.6910      0.694     -0.995      0.320      -2.052       0.670
C(answer_type_grouped)[T.Number]               0.5694      0.374      1.523      0.128      -0.163       1.302
C(answer_type_grouped)[T.Other]                0.7058      0.314      2.247      0.025       0.090       1.322
C(answer_type_grouped)[T.Person]               0.4894      0.334      1.464      0.143      -0.166       1.145
q_length                                      -0.0812      0.316     -0.257      0.797      -0.701       0.538
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing gemini-2.0-flash-001 (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_neutral/gemini-2.0-flash-001_SimpleMC_neut_redacted_cor_temp1.0_1757986981_game_data.json', './sc_logs_neutral/gemini-2.0-flash-001_SimpleMC_neut_redacted_temp1.0_1758161429_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    362
1    138
Name: count, dtype: int64

Answer change%: 0.2760 [0.23681797178842365, 0.31518202821157637] (n=500)
P-value vs 25%: 0.1934; P-value vs 0%: 2.342e-43
Phase 2 self-accuracy: 0.3841 [0.3029101506623818, 0.46520579136660367] (n=138)
P-value vs 25%: 0.001204; P-value vs 33%: 0.2175

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.06147
Time:                        16:14:57   Log-Likelihood:                -276.46
converged:                       True   LL-Null:                       -294.57
Covariance Type:            nonrobust   LLR p-value:                 1.770e-09
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          2.6981      0.628      4.297      0.000       1.467       3.929
p_i_capability    -4.0586      0.691     -5.872      0.000      -5.413      -2.704
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.08345
Time:                        16:14:57   Log-Likelihood:                -269.99
converged:                       True   LL-Null:                       -294.57
Covariance Type:            nonrobust   LLR p-value:                 2.356e-12
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.5439      0.141    -10.958      0.000      -1.820      -1.268
capabilities_entropy     1.6222      0.240      6.770      0.000       1.153       2.092
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.5678 [0.4784, 0.6572] (n=118)
                  P-value vs 33.3%: 2.728e-07

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=6.49, p=6.15e-10
Wilcoxon delta_p: statistic=6002.00, p=5.38e-09
Mean Δp = 0.0878  [0.0613, 0.1143]
Idea 1 N = 211; 

  Idea 1.5: Calibration Metrics
  NLL: 3.7118, Signed ECE (overconf pos under neg): 0.0058, ECE: 0.0246 (n=327)
  Brier: 0.0447, Reliability (absolute calibration error; lower better): 0.0025, Resolution (relative calibration quality; higher better): 0.1896, Uncertainty: 0.2315 (n=327)
  AUROC: 0.9864

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.611
Model:                            OLS   Adj. R-squared:                  0.607
Method:                 Least Squares   F-statistic:                     167.4
Date:                Wed, 24 Sep 2025   Prob (F-statistic):           2.98e-65
Time:                        16:14:57   Log-Likelihood:                 25.512
No. Observations:                 324   AIC:                            -43.02
Df Residuals:                     320   BIC:                            -27.90
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept             0.1191      0.103      1.151      0.251      -0.084       0.323
p1                   -0.0343      0.112     -0.306      0.760      -0.255       0.186
answer_changed       -0.7354      0.149     -4.940      0.000      -1.028      -0.443
p1:answer_changed     1.4823      0.168      8.800      0.000       1.151       1.814
==============================================================================
Omnibus:                       17.328   Durbin-Watson:                   2.200
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               27.154
Skew:                          -0.364   Prob(JB):                     1.27e-06
Kurtosis:                       4.217   Cond. No.                         28.8
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-1.95, p=0.052
Wilcoxon delta_H: statistic=9465.00, p=0.0414
Mean ΔH = -0.0795  [-0.1593, 0.0003]
Paired t-test delta_H Changed: statistic=1.85, p=0.0664
Wilcoxon delta_H Changed: statistic=2690.00, p=0.0528
Mean ΔH Changed = 0.0979  [-0.0056, 0.2014]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=-4.81, p=2.26e-06
Wilcoxon (p_top2_game vs p_top2_base): statistic=15491.00, p=2.34e-11
Mean Δp_top2 = -0.0166  [-0.0233, -0.0098] (n=328)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=-0.52, p=0.607
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=26058.00, p=0.592
Mean ΔH_unchosen_baseline_set = -0.0168  [-0.0806, 0.0470] (n=328)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  328
Model:                          Logit   Df Residuals:                      325
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.05287
Time:                        16:14:57   Log-Likelihood:                -201.83
converged:                       True   LL-Null:                       -213.10
Covariance Type:            nonrobust   LLR p-value:                 1.279e-05
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.3722      0.163     -2.284      0.022      -0.692      -0.053
p1_z            -0.8562      0.205     -4.176      0.000      -1.258      -0.454
I(p1_z ** 2)    -0.2687      0.118     -2.273      0.023      -0.500      -0.037
================================================================================
AUC = 0.670

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1087
Time:                        16:14:57   Log-Likelihood:                -262.55
converged:                       True   LL-Null:                       -294.57
Covariance Type:            nonrobust   LLR p-value:                 1.225e-15
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.7576      0.158    -11.138      0.000      -2.067      -1.448
game_entropy     1.5859      0.207      7.656      0.000       1.180       1.992
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=45649.00, p=1.51e-07
Paired t-test (game_entropy vs capabilities_entropy): statistic=5.36, p=1.3e-07
Mean game_entropy-capabilities_entropy = 0.1174  [0.0744, 0.1603] (n=500)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      497
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1368
Time:                        16:14:57   Log-Likelihood:                -254.27
converged:                       True   LL-Null:                       -294.57
Covariance Type:            nonrobust   LLR p-value:                 3.162e-18
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.9712      0.173    -11.408      0.000      -2.310      -1.632
capabilities_entropy     1.0697      0.264      4.057      0.000       0.553       1.586
game_entropy             1.2476      0.225      5.549      0.000       0.807       1.688
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.733333
                        1                 0.266667
Geography               0                 0.613636
                        1                 0.386364
Misc                    0                 0.689189
                        1                 0.310811
Music                   0                 0.775000
                        1                 0.225000
Other                   0                 0.769231
                        1                 0.230769
Politics                0                 0.753247
                        1                 0.246753
Science and technology  0                 0.714286
                        1                 0.285714
Sports                  0                 0.750000
                        1                 0.250000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.668639
                     1                 0.331361
Number               0                 0.705128
                     1                 0.294872
Other                0                 0.744361
                     1                 0.255639
Person               0                 0.791667
                     1                 0.208333
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.666667  0.333333           21
                       Number               0.666667  0.333333            9
                       Other                0.666667  0.333333           18
                       Person               0.851852  0.148148           27
Geography              Date                 0.533333  0.466667           15
                       Number               0.555556  0.444444           18
                       Other                0.818182  0.181818           11
Misc                   Date                 0.652174  0.347826           23
                       Number               0.888889  0.111111            9
                       Other                0.629630  0.370370           27
                       Person               0.733333  0.266667           15
Music                  Date                 0.833333  0.166667           12
                       Number               0.750000  0.250000            4
                       Other                0.583333  0.416667           12
                       Person               0.916667  0.083333           12
Other                  Date                 0.666667  0.333333           18
                       Number               1.000000  0.000000            7
                       Other                0.857143  0.142857           14
                       Person               0.692308  0.307692           13
Politics               Date                 0.722222  0.277778           36
                       Number               0.833333  0.166667            6
                       Other                0.850000  0.150000           20
                       Person               0.666667  0.333333           15
Science and technology Date                 0.657143  0.342857           35
                       Number               0.642857  0.357143           14
                       Other                0.736842  0.263158           19
                       Person               0.800000  0.200000           30
Sports                 Date                 0.555556  0.444444            9
                       Number               0.636364  0.363636           11
                       Other                0.916667  0.083333           12
                       Person               0.875000  0.125000            8

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      488
Method:                           MLE   Df Model:                           11
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.01651
Time:                        16:14:57   Log-Likelihood:                -289.70
converged:                       True   LL-Null:                       -294.57
Covariance Type:            nonrobust   LLR p-value:                    0.5552
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -0.7498      1.269     -0.591      0.555      -3.237       1.737
C(topic_grouped)[T.Geography]                  0.4211      0.420      1.002      0.316      -0.402       1.245
C(topic_grouped)[T.Misc]                       0.1720      0.367      0.469      0.639      -0.547       0.890
C(topic_grouped)[T.Music]                     -0.2450      0.463     -0.529      0.597      -1.152       0.662
C(topic_grouped)[T.Other]                     -0.2451      0.423     -0.579      0.563      -1.075       0.585
C(topic_grouped)[T.Politics]                  -0.2120      0.382     -0.555      0.579      -0.962       0.537
C(topic_grouped)[T.Science and technology]     0.0501      0.347      0.144      0.885      -0.631       0.731
C(topic_grouped)[T.Sports]                    -0.1180      0.454     -0.260      0.795      -1.009       0.773
C(answer_type_grouped)[T.Number]              -0.2570      0.308     -0.834      0.404      -0.861       0.347
C(answer_type_grouped)[T.Other]               -0.3790      0.261     -1.451      0.147      -0.891       0.133
C(answer_type_grouped)[T.Person]              -0.6035      0.284     -2.122      0.034      -1.161      -0.046
q_length                                       0.0143      0.274      0.052      0.958      -0.523       0.551
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.3084
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      487
Method:                           MLE   Df Model:                           12
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.09569
Time:                        16:14:57   Log-Likelihood:                -266.38
converged:                       True   LL-Null:                       -294.57
Covariance Type:            nonrobust   LLR p-value:                 1.025e-07
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.0444      1.322     -0.790      0.429      -3.635       1.546
C(topic_grouped)[T.Geography]                  0.5361      0.448      1.195      0.232      -0.343       1.415
C(topic_grouped)[T.Misc]                       0.2316      0.387      0.598      0.550      -0.528       0.991
C(topic_grouped)[T.Music]                     -0.1470      0.483     -0.304      0.761      -1.093       0.799
C(topic_grouped)[T.Other]                     -0.1857      0.445     -0.418      0.676      -1.058       0.686
C(topic_grouped)[T.Politics]                  -0.0267      0.406     -0.066      0.948      -0.823       0.769
C(topic_grouped)[T.Science and technology]     0.1095      0.368      0.298      0.766      -0.611       0.830
C(topic_grouped)[T.Sports]                     0.0417      0.477      0.087      0.930      -0.893       0.977
C(answer_type_grouped)[T.Number]              -0.5600      0.334     -1.678      0.093      -1.214       0.094
C(answer_type_grouped)[T.Other]               -0.3595      0.276     -1.301      0.193      -0.901       0.182
C(answer_type_grouped)[T.Person]              -0.4457      0.298     -1.494      0.135      -1.030       0.139
q_length                                      -0.0666      0.286     -0.233      0.816      -0.627       0.494
capabilities_entropy                           1.6366      0.249      6.567      0.000       1.148       2.125
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      487
Method:                           MLE   Df Model:                           12
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1170
Time:                        16:14:57   Log-Likelihood:                -260.10
converged:                       True   LL-Null:                       -294.57
Covariance Type:            nonrobust   LLR p-value:                 5.053e-10
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.3385      1.356     -0.987      0.324      -3.996       1.320
C(topic_grouped)[T.Geography]                  0.3792      0.453      0.837      0.402      -0.508       1.267
C(topic_grouped)[T.Misc]                       0.0381      0.393      0.097      0.923      -0.733       0.809
C(topic_grouped)[T.Music]                     -0.1091      0.489     -0.223      0.823      -1.067       0.849
C(topic_grouped)[T.Other]                     -0.3571      0.451     -0.793      0.428      -1.240       0.526
C(topic_grouped)[T.Politics]                  -0.4004      0.412     -0.972      0.331      -1.208       0.407
C(topic_grouped)[T.Science and technology]    -0.0917      0.376     -0.244      0.807      -0.829       0.645
C(topic_grouped)[T.Sports]                    -0.0097      0.483     -0.020      0.984      -0.957       0.937
C(answer_type_grouped)[T.Number]              -0.2954      0.335     -0.882      0.378      -0.952       0.361
C(answer_type_grouped)[T.Other]               -0.0165      0.285     -0.058      0.954      -0.575       0.542
C(answer_type_grouped)[T.Person]              -0.2015      0.308     -0.655      0.513      -0.805       0.402
q_length                                      -0.0553      0.292     -0.189      0.850      -0.628       0.517
game_entropy                                   1.5986      0.217      7.352      0.000       1.172       2.025
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      486
Method:                           MLE   Df Model:                           13
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1452
Time:                        16:14:57   Log-Likelihood:                -251.81
converged:                       True   LL-Null:                       -294.57
Covariance Type:            nonrobust   LLR p-value:                 1.001e-12
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.4127      1.367     -1.033      0.301      -4.092       1.266
C(topic_grouped)[T.Geography]                  0.4571      0.464      0.986      0.324      -0.452       1.366
C(topic_grouped)[T.Misc]                       0.1018      0.399      0.255      0.799      -0.681       0.884
C(topic_grouped)[T.Music]                     -0.0872      0.496     -0.176      0.860      -1.059       0.885
C(topic_grouped)[T.Other]                     -0.3313      0.463     -0.716      0.474      -1.238       0.575
C(topic_grouped)[T.Politics]                  -0.2385      0.421     -0.567      0.571      -1.063       0.586
C(topic_grouped)[T.Science and technology]    -0.0264      0.382     -0.069      0.945      -0.774       0.722
C(topic_grouped)[T.Sports]                     0.0919      0.488      0.189      0.850      -0.864       1.048
C(answer_type_grouped)[T.Number]              -0.4825      0.346     -1.393      0.164      -1.161       0.196
C(answer_type_grouped)[T.Other]               -0.0769      0.293     -0.262      0.793      -0.651       0.497
C(answer_type_grouped)[T.Person]              -0.1734      0.312     -0.555      0.579      -0.785       0.439
q_length                                      -0.0939      0.295     -0.318      0.750      -0.672       0.484
capabilities_entropy                           1.1020      0.273      4.040      0.000       0.567       1.637
game_entropy                                   1.2551      0.235      5.332      0.000       0.794       1.716
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing gemini-2.5-flash-lite_nothink (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_neutral/gemini-2.5-flash-lite_nothink_SimpleMC_neut_redacted_cor_temp1.0_1757983727_game_data.json', './sc_logs_neutral/gemini-2.5-flash-lite_nothink_SimpleMC_neut_redacted_temp1.0_1757983564_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    346
1    154
Name: count, dtype: int64

Answer change%: 0.3080 [0.2675338865911868, 0.34846611340881317] (n=500)
P-value vs 25%: 0.004966; P-value vs 0%: 2.521e-50
Phase 2 self-accuracy: 0.3506 [0.2752853595377008, 0.42601334176100053] (n=154)
P-value vs 25%: 0.008856; P-value vs 33%: 0.6462

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.02514
Time:                        16:14:57   Log-Likelihood:                -300.98
converged:                       True   LL-Null:                       -308.75
Covariance Type:            nonrobust   LLR p-value:                 8.157e-05
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          0.7499      0.404      1.856      0.063      -0.042       1.542
p_i_capability    -2.0133      0.514     -3.920      0.000      -3.020      -1.007
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.02983
Time:                        16:14:57   Log-Likelihood:                -299.54
converged:                       True   LL-Null:                       -308.75
Covariance Type:            nonrobust   LLR p-value:                 1.773e-05
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.4610      0.190     -7.705      0.000      -1.833      -1.089
capabilities_entropy     0.7966      0.189      4.219      0.000       0.427       1.167
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.2597 [0.1905, 0.3290] (n=154)
                  P-value vs 33.3%: 0.03727

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=19.95, p=6.27e-58
Wilcoxon delta_p: statistic=4210.00, p=5.13e-38
Mean Δp = 0.4783  [0.4313, 0.5253]
Idea 1 N = 318; 

  Idea 1.5: Calibration Metrics
  NLL: 3.4237, Signed ECE (overconf pos under neg): -0.1584, ECE: 0.3296 (n=498)
  Brier: 0.3613, Reliability (absolute calibration error; lower better): 0.1295, Resolution (relative calibration quality; higher better): 0.0050, Uncertainty: 0.2335 (n=498)
  AUROC: 0.4474

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.139
Model:                            OLS   Adj. R-squared:                  0.133
Method:                 Least Squares   F-statistic:                     24.88
Date:                Wed, 24 Sep 2025   Prob (F-statistic):           6.07e-15
Time:                        16:14:57   Log-Likelihood:                -214.00
No. Observations:                 467   AIC:                             436.0
Df Residuals:                     463   BIC:                             452.6
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.1059      0.098     -1.081      0.280      -0.298       0.087
p1                    0.7288      0.119      6.114      0.000       0.495       0.963
answer_changed       -0.1713      0.157     -1.094      0.275      -0.479       0.137
p1:answer_changed     0.2278      0.200      1.137      0.256      -0.166       0.621
==============================================================================
Omnibus:                      246.175   Durbin-Watson:                   2.054
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               67.082
Skew:                          -0.728   Prob(JB):                     2.71e-15
Kurtosis:                       1.848   Cond. No.                         20.7
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=11.41, p=8.54e-26
Wilcoxon delta_H: statistic=11516.00, p=4.81e-23
Mean ΔH = 0.3860  [0.3197, 0.4523]
Paired t-test delta_H Changed: statistic=6.78, p=2.42e-10
Wilcoxon delta_H Changed: statistic=2689.00, p=3.34e-09
Mean ΔH Changed = 0.2973  [0.2114, 0.3832]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=4.63, p=4.57e-06
Wilcoxon (p_top2_game vs p_top2_base): statistic=44773.00, p=4.71e-08
Mean Δp_top2 = 0.0179  [0.0103, 0.0255] (n=499)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=13.26, p=1.46e-34
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=25126.00, p=6.69e-31
Mean ΔH_unchosen_baseline_set = 0.3586  [0.3056, 0.4116] (n=499)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  499
Model:                          Logit   Df Residuals:                      496
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.02536
Time:                        16:14:57   Log-Likelihood:                -300.56
converged:                       True   LL-Null:                       -308.38
Covariance Type:            nonrobust   LLR p-value:                 0.0004018
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.7706      0.142     -5.426      0.000      -1.049      -0.492
p1_z            -0.4206      0.124     -3.401      0.001      -0.663      -0.178
I(p1_z ** 2)    -0.0634      0.106     -0.596      0.551      -0.272       0.145
================================================================================
AUC = 0.614

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1239
Time:                        16:14:57   Log-Likelihood:                -270.48
converged:                       True   LL-Null:                       -308.75
Covariance Type:            nonrobust   LLR p-value:                 2.165e-18
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.9607      0.185    -10.579      0.000      -2.324      -1.597
game_entropy     1.7217      0.211      8.167      0.000       1.309       2.135
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=39252.00, p=4.79e-13
Paired t-test (game_entropy vs capabilities_entropy): statistic=-6.78, p=3.35e-11
Mean game_entropy-capabilities_entropy = -0.1791  [-0.2308, -0.1273] (n=500)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      497
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1280
Time:                        16:14:57   Log-Likelihood:                -269.22
converged:                       True   LL-Null:                       -308.75
Covariance Type:            nonrobust   LLR p-value:                 6.836e-18
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.1728      0.234     -9.286      0.000      -2.631      -1.714
capabilities_entropy     0.3340      0.211      1.585      0.113      -0.079       0.747
game_entropy             1.6238      0.219      7.406      0.000       1.194       2.053
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.693333
                        1                 0.306667
Geography               0                 0.636364
                        1                 0.363636
Misc                    0                 0.648649
                        1                 0.351351
Music                   0                 0.775000
                        1                 0.225000
Other                   0                 0.692308
                        1                 0.307692
Politics                0                 0.701299
                        1                 0.298701
Science and technology  0                 0.704082
                        1                 0.295918
Sports                  0                 0.700000
                        1                 0.300000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.585799
                     1                 0.414201
Number               0                 0.679487
                     1                 0.320513
Other                0                 0.789474
                     1                 0.210526
Person               0                 0.741667
                     1                 0.258333
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.476190  0.523810           21
                       Number               0.555556  0.444444            9
                       Other                0.888889  0.111111           18
                       Person               0.777778  0.222222           27
Geography              Date                 0.400000  0.600000           15
                       Number               0.777778  0.222222           18
                       Other                0.727273  0.272727           11
Misc                   Date                 0.565217  0.434783           23
                       Number               0.666667  0.333333            9
                       Other                0.740741  0.259259           27
                       Person               0.600000  0.400000           15
Music                  Date                 0.583333  0.416667           12
                       Number               0.500000  0.500000            4
                       Other                0.916667  0.083333           12
                       Person               0.916667  0.083333           12
Other                  Date                 0.611111  0.388889           18
                       Number               1.000000  0.000000            7
                       Other                0.785714  0.214286           14
                       Person               0.538462  0.461538           13
Politics               Date                 0.666667  0.333333           36
                       Number               0.500000  0.500000            6
                       Other                0.850000  0.150000           20
                       Person               0.666667  0.333333           15
Science and technology Date                 0.600000  0.400000           35
                       Number               0.642857  0.357143           14
                       Other                0.736842  0.263158           19
                       Person               0.833333  0.166667           30
Sports                 Date                 0.777778  0.222222            9
                       Number               0.636364  0.363636           11
                       Other                0.666667  0.333333           12
                       Person               0.750000  0.250000            8

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      488
Method:                           MLE   Df Model:                           11
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.03331
Time:                        16:14:57   Log-Likelihood:                -298.46
converged:                       True   LL-Null:                       -308.75
Covariance Type:            nonrobust   LLR p-value:                   0.03809
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      1.0953      1.250      0.877      0.381      -1.354       3.544
C(topic_grouped)[T.Geography]                  0.1314      0.422      0.311      0.755      -0.696       0.959
C(topic_grouped)[T.Misc]                       0.2287      0.358      0.638      0.523      -0.473       0.931
C(topic_grouped)[T.Music]                     -0.4429      0.461     -0.960      0.337      -1.347       0.462
C(topic_grouped)[T.Other]                     -0.0506      0.399     -0.127      0.899      -0.833       0.732
C(topic_grouped)[T.Politics]                  -0.0967      0.367     -0.263      0.792      -0.816       0.623
C(topic_grouped)[T.Science and technology]    -0.1056      0.341     -0.309      0.757      -0.774       0.563
C(topic_grouped)[T.Sports]                    -0.0122      0.437     -0.028      0.978      -0.868       0.844
C(answer_type_grouped)[T.Number]              -0.4415      0.298     -1.479      0.139      -1.026       0.143
C(answer_type_grouped)[T.Other]               -1.0304      0.268     -3.839      0.000      -1.557      -0.504
C(answer_type_grouped)[T.Person]              -0.7220      0.267     -2.700      0.007      -1.246      -0.198
q_length                                      -0.3088      0.270     -1.145      0.252      -0.837       0.220
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.7766
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      487
Method:                           MLE   Df Model:                           12
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.04969
Time:                        16:14:57   Log-Likelihood:                -293.40
converged:                       True   LL-Null:                       -308.75
Covariance Type:            nonrobust   LLR p-value:                  0.002200
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      0.1080      1.304      0.083      0.934      -2.448       2.664
C(topic_grouped)[T.Geography]                  0.1395      0.428      0.326      0.745      -0.700       0.979
C(topic_grouped)[T.Misc]                       0.2181      0.361      0.603      0.546      -0.490       0.927
C(topic_grouped)[T.Music]                     -0.4621      0.467     -0.990      0.322      -1.377       0.452
C(topic_grouped)[T.Other]                     -0.0613      0.403     -0.152      0.879      -0.851       0.729
C(topic_grouped)[T.Politics]                  -0.0721      0.372     -0.194      0.846      -0.801       0.657
C(topic_grouped)[T.Science and technology]    -0.0624      0.345     -0.181      0.856      -0.739       0.614
C(topic_grouped)[T.Sports]                     0.0295      0.443      0.067      0.947      -0.839       0.898
C(answer_type_grouped)[T.Number]              -0.5348      0.303     -1.767      0.077      -1.128       0.058
C(answer_type_grouped)[T.Other]               -0.8101      0.279     -2.904      0.004      -1.357      -0.263
C(answer_type_grouped)[T.Person]              -0.4305      0.285     -1.511      0.131      -0.989       0.128
q_length                                      -0.2362      0.274     -0.861      0.389      -0.774       0.301
capabilities_entropy                           0.6630      0.210      3.151      0.002       0.251       1.075
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      487
Method:                           MLE   Df Model:                           12
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1424
Time:                        16:14:57   Log-Likelihood:                -264.78
converged:                       True   LL-Null:                       -308.75
Covariance Type:            nonrobust   LLR p-value:                 1.241e-13
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -0.3719      1.353     -0.275      0.783      -3.024       2.280
C(topic_grouped)[T.Geography]                 -0.2733      0.462     -0.592      0.554      -1.179       0.632
C(topic_grouped)[T.Misc]                       0.1647      0.387      0.426      0.670      -0.593       0.922
C(topic_grouped)[T.Music]                     -0.5175      0.502     -1.031      0.303      -1.502       0.466
C(topic_grouped)[T.Other]                     -0.3828      0.428     -0.894      0.371      -1.222       0.456
C(topic_grouped)[T.Politics]                  -0.1441      0.397     -0.363      0.717      -0.923       0.635
C(topic_grouped)[T.Science and technology]    -0.2484      0.366     -0.678      0.498      -0.966       0.470
C(topic_grouped)[T.Sports]                    -0.1796      0.468     -0.383      0.701      -1.098       0.738
C(answer_type_grouped)[T.Number]              -0.7305      0.322     -2.266      0.023      -1.362      -0.099
C(answer_type_grouped)[T.Other]               -0.5961      0.292     -2.038      0.042      -1.169      -0.023
C(answer_type_grouped)[T.Person]              -0.2911      0.294     -0.991      0.322      -0.867       0.285
q_length                                      -0.2501      0.290     -0.864      0.388      -0.818       0.318
game_entropy                                   1.7646      0.229      7.703      0.000       1.316       2.214
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      486
Method:                           MLE   Df Model:                           13
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1461
Time:                        16:14:57   Log-Likelihood:                -263.65
converged:                       True   LL-Null:                       -308.75
Covariance Type:            nonrobust   LLR p-value:                 1.279e-13
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -0.7878      1.384     -0.569      0.569      -3.500       1.925
C(topic_grouped)[T.Geography]                 -0.2489      0.463     -0.538      0.591      -1.156       0.658
C(topic_grouped)[T.Misc]                       0.1602      0.388      0.413      0.679      -0.600       0.920
C(topic_grouped)[T.Music]                     -0.5337      0.506     -1.055      0.291      -1.525       0.457
C(topic_grouped)[T.Other]                     -0.3701      0.430     -0.861      0.389      -1.213       0.473
C(topic_grouped)[T.Politics]                  -0.1247      0.398     -0.313      0.754      -0.905       0.656
C(topic_grouped)[T.Science and technology]    -0.2166      0.367     -0.590      0.556      -0.937       0.503
C(topic_grouped)[T.Sports]                    -0.1436      0.471     -0.305      0.761      -1.067       0.780
C(answer_type_grouped)[T.Number]              -0.7599      0.323     -2.354      0.019      -1.393      -0.127
C(answer_type_grouped)[T.Other]               -0.5038      0.300     -1.680      0.093      -1.092       0.084
C(answer_type_grouped)[T.Person]              -0.1623      0.306     -0.530      0.596      -0.762       0.438
q_length                                      -0.2249      0.291     -0.773      0.439      -0.795       0.345
capabilities_entropy                           0.3436      0.228      1.505      0.132      -0.104       0.791
game_entropy                                   1.6985      0.233      7.295      0.000       1.242       2.155
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing gemini-2.5-flash-lite_think (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_neutral/gemini-2.5-flash-lite_think_SimpleMC_neut_redacted_cor_temp1.0_1758214203_game_data.json', './sc_logs_neutral/gemini-2.5-flash-lite_think_SimpleMC_neut_redacted_temp1.0_1758205360_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    314
1    186
Name: count, dtype: int64

Answer change%: 0.3720 [0.329634300575695, 0.414365699424305] (n=500)
P-value vs 25%: 1.661e-08; P-value vs 0%: 2.241e-66
Phase 2 self-accuracy: 0.3548 [0.2860778551131438, 0.4235995642416949] (n=186)
P-value vs 25%: 0.002805; P-value vs 33%: 0.5336

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:               7.741e-06
Time:                        16:14:57   Log-Likelihood:                -330.00
converged:                       True   LL-Null:                       -330.01
Covariance Type:            nonrobust   LLR p-value:                    0.9430
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept        -16.3206    221.659     -0.074      0.941    -450.765     418.124
p_i_capability    15.7981    221.676      0.071      0.943    -418.679     450.275
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:               1.734e-06
Time:                        16:14:57   Log-Likelihood:                -330.01
converged:                       True   LL-Null:                       -330.01
Covariance Type:            nonrobust   LLR p-value:                    0.9730
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -0.5230      0.094     -5.538      0.000      -0.708      -0.338
capabilities_entropy    -0.7572     22.409     -0.034      0.973     -44.678      43.164
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.0769 [0.0367, 0.1171] (n=169)
                  P-value vs 33.3%: 6.644e-36

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=9.39, p=1.13e-15
Wilcoxon delta_p: statistic=143.00, p=6.14e-18
Mean Δp = 0.4494  [0.3557, 0.5432]
Idea 1 N = 109; 

  Idea 1.5: Calibration Metrics
  NLL: 6.4180, Signed ECE (overconf pos under neg): 0.0676, ECE: 0.5217 (n=207)
  Brier: 0.5217, Reliability (absolute calibration error; lower better): 0.2794, Resolution (relative calibration quality; higher better): 0.0006, Uncertainty: 0.2429 (n=207)
  AUROC: 0.4449

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.002
Model:                            OLS   Adj. R-squared:                 -0.015
Method:                 Least Squares   F-statistic:                   0.09819
Date:                Wed, 24 Sep 2025   Prob (F-statistic):              0.961
Time:                        16:14:57   Log-Likelihood:                -134.11
No. Observations:                 187   AIC:                             276.2
Df Residuals:                     183   BIC:                             289.1
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -6.8926    133.447     -0.052      0.959    -270.185     256.400
p1                    7.3427    133.458      0.055      0.956    -255.972     270.658
answer_changed      -62.0492    216.671     -0.286      0.775    -489.544     365.446
p1:answer_changed    62.0277    216.689      0.286      0.775    -365.502     489.558
==============================================================================
Omnibus:                     1098.077   Durbin-Watson:                   2.061
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               31.040
Skew:                           0.246   Prob(JB):                     1.82e-07
Kurtosis:                       1.065   Cond. No.                     1.42e+04
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The condition number is large, 1.42e+04. This might indicate that there are
strong multicollinearity or other numerical problems.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=25.83, p=1.09e-74
Wilcoxon delta_H: statistic=1055.00, p=6.83e-41
Mean ΔH = 0.9870  [0.9121, 1.0619]
Paired t-test delta_H Changed: statistic=19.40, p=2.02e-44
Wilcoxon delta_H Changed: statistic=464.00, p=1.88e-25
Mean ΔH Changed = 0.9464  [0.8508, 1.0421]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=-3.56, p=0.000411
Wilcoxon (p_top2_game vs p_top2_base): statistic=15001.00, p=4.58e-35
Mean Δp_top2 = -0.0000  [-0.0001, -0.0000] (n=435)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=32.31, p=1.45e-117
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=2881.00, p=1.27e-64
Mean ΔH_unchosen_baseline_set = 0.9715  [0.9126, 1.0304] (n=435)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  435
Model:                          Logit   Df Residuals:                      432
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                0.002901
Time:                        16:14:57   Log-Likelihood:                -288.37
converged:                       True   LL-Null:                       -289.21
Covariance Type:            nonrobust   LLR p-value:                    0.4321
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.4514      0.106     -4.261      0.000      -0.659      -0.244
p1_z            -0.2076      0.378     -0.549      0.583      -0.948       0.533
I(p1_z ** 2)    -0.0391      0.050     -0.781      0.435      -0.137       0.059
================================================================================
AUC = 0.510

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:               0.0002184
Time:                        16:14:57   Log-Likelihood:                -329.93
converged:                       True   LL-Null:                       -330.01
Covariance Type:            nonrobust   LLR p-value:                    0.7042
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.5204      0.093     -5.600      0.000      -0.703      -0.338
game_entropy    -0.9766      2.774     -0.352      0.725      -6.414       4.461
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=17019.00, p=3.33e-45
Paired t-test (game_entropy vs capabilities_entropy): statistic=1.53, p=0.127
Mean game_entropy-capabilities_entropy = 0.0028  [-0.0008, 0.0063] (n=500)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      497
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:               0.0002203
Time:                        16:14:57   Log-Likelihood:                -329.93
converged:                       True   LL-Null:                       -330.01
Covariance Type:            nonrobust   LLR p-value:                    0.9299
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -0.5197      0.095     -5.480      0.000      -0.706      -0.334
capabilities_entropy    -0.8061     22.409     -0.036      0.971     -44.728      43.116
game_entropy            -0.9771      2.774     -0.352      0.725      -6.415       4.460
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.653333
                        1                 0.346667
Geography               0                 0.681818
                        1                 0.318182
Misc                    0                 0.608108
                        1                 0.391892
Music                   0                 0.575000
                        1                 0.425000
Other                   0                 0.615385
                        1                 0.384615
Politics                0                 0.688312
                        1                 0.311688
Science and technology  0                 0.581633
                        1                 0.418367
Sports                  0                 0.625000
                        1                 0.375000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.579882
                     1                 0.420118
Number               1                 0.538462
                     0                 0.461538
Other                0                 0.751880
                     1                 0.248120
Person               0                 0.666667
                     1                 0.333333
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.571429  0.428571           21
                       Number               0.444444  0.555556            9
                       Other                0.777778  0.222222           18
                       Person               0.703704  0.296296           27
Geography              Date                 0.600000  0.400000           15
                       Number               0.555556  0.444444           18
                       Other                1.000000  0.000000           11
Misc                   Date                 0.521739  0.478261           23
                       Number               0.555556  0.444444            9
                       Other                0.666667  0.333333           27
                       Person               0.666667  0.333333           15
Music                  Date                 0.583333  0.416667           12
                       Number               0.000000  1.000000            4
                       Other                0.750000  0.250000           12
                       Person               0.583333  0.416667           12
Other                  Date                 0.333333  0.666667           18
                       Number               0.571429  0.428571            7
                       Other                0.857143  0.142857           14
                       Person               0.769231  0.230769           13
Politics               Date                 0.638889  0.361111           36
                       Number               0.666667  0.333333            6
                       Other                0.700000  0.300000           20
                       Person               0.800000  0.200000           15
Science and technology Date                 0.628571  0.371429           35
                       Number               0.357143  0.642857           14
                       Other                0.736842  0.263158           19
                       Person               0.533333  0.466667           30
Sports                 Date                 0.777778  0.222222            9
                       Number               0.363636  0.636364           11
                       Other                0.666667  0.333333           12
                       Person               0.750000  0.250000            8

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      488
Method:                           MLE   Df Model:                           11
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.04032
Time:                        16:14:57   Log-Likelihood:                -316.70
converged:                       True   LL-Null:                       -330.01
Covariance Type:            nonrobust   LLR p-value:                  0.005253
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -0.8751      1.193     -0.734      0.463      -3.213       1.463
C(topic_grouped)[T.Geography]                 -0.4615      0.430     -1.074      0.283      -1.304       0.381
C(topic_grouped)[T.Misc]                       0.2278      0.350      0.650      0.515      -0.459       0.914
C(topic_grouped)[T.Music]                      0.3846      0.411      0.936      0.350      -0.421       1.190
C(topic_grouped)[T.Other]                      0.1381      0.384      0.360      0.719      -0.614       0.890
C(topic_grouped)[T.Politics]                  -0.2247      0.360     -0.624      0.533      -0.931       0.481
C(topic_grouped)[T.Science and technology]     0.2328      0.325      0.715      0.474      -0.405       0.871
C(topic_grouped)[T.Sports]                     0.0065      0.423      0.015      0.988      -0.822       0.835
C(answer_type_grouped)[T.Number]               0.5375      0.287      1.870      0.061      -0.026       1.101
C(answer_type_grouped)[T.Other]               -0.8093      0.258     -3.132      0.002      -1.316      -0.303
C(answer_type_grouped)[T.Person]              -0.4389      0.255     -1.721      0.085      -0.939       0.061
q_length                                       0.1128      0.257      0.439      0.660      -0.390       0.616
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.0008
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      487
Method:                           MLE   Df Model:                           12
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.04044
Time:                        16:14:57   Log-Likelihood:                -316.66
converged:                       True   LL-Null:                       -330.01
Covariance Type:            nonrobust   LLR p-value:                  0.008564
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -0.8778      1.193     -0.736      0.462      -3.216       1.461
C(topic_grouped)[T.Geography]                 -0.4637      0.430     -1.079      0.281      -1.306       0.379
C(topic_grouped)[T.Misc]                       0.2154      0.353      0.610      0.542      -0.477       0.908
C(topic_grouped)[T.Music]                      0.3842      0.411      0.934      0.350      -0.422       1.190
C(topic_grouped)[T.Other]                      0.1340      0.384      0.349      0.727      -0.619       0.886
C(topic_grouped)[T.Politics]                  -0.2263      0.360     -0.628      0.530      -0.933       0.480
C(topic_grouped)[T.Science and technology]     0.2317      0.326      0.712      0.477      -0.406       0.870
C(topic_grouped)[T.Sports]                    -0.0039      0.425     -0.009      0.993      -0.836       0.828
C(answer_type_grouped)[T.Number]               0.5348      0.288      1.860      0.063      -0.029       1.098
C(answer_type_grouped)[T.Other]               -0.8158      0.260     -3.142      0.002      -1.325      -0.307
C(answer_type_grouped)[T.Person]              -0.4453      0.256     -1.739      0.082      -0.947       0.057
q_length                                       0.1138      0.257      0.443      0.658      -0.389       0.617
capabilities_entropy                           6.3427     23.064      0.275      0.783     -38.862      51.548
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      487
Method:                           MLE   Df Model:                           12
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.04039
Time:                        16:14:57   Log-Likelihood:                -316.68
converged:                       True   LL-Null:                       -330.01
Covariance Type:            nonrobust   LLR p-value:                  0.008653
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -0.8699      1.193     -0.729      0.466      -3.208       1.468
C(topic_grouped)[T.Geography]                 -0.4616      0.430     -1.075      0.283      -1.304       0.380
C(topic_grouped)[T.Misc]                       0.2279      0.350      0.651      0.515      -0.459       0.914
C(topic_grouped)[T.Music]                      0.3848      0.411      0.936      0.349      -0.421       1.191
C(topic_grouped)[T.Other]                      0.1388      0.384      0.362      0.717      -0.613       0.891
C(topic_grouped)[T.Politics]                  -0.2246      0.360     -0.624      0.533      -0.931       0.481
C(topic_grouped)[T.Science and technology]     0.2371      0.326      0.727      0.467      -0.402       0.876
C(topic_grouped)[T.Sports]                     0.0070      0.423      0.017      0.987      -0.821       0.835
C(answer_type_grouped)[T.Number]               0.5372      0.287      1.869      0.062      -0.026       1.101
C(answer_type_grouped)[T.Other]               -0.8059      0.259     -3.113      0.002      -1.313      -0.299
C(answer_type_grouped)[T.Person]              -0.4391      0.255     -1.722      0.085      -0.939       0.061
q_length                                       0.1117      0.257      0.435      0.664      -0.392       0.615
game_entropy                                  -0.5644      2.846     -0.198      0.843      -6.143       5.014
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      486
Method:                           MLE   Df Model:                           13
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.04050
Time:                        16:14:57   Log-Likelihood:                -316.64
converged:                       True   LL-Null:                       -330.01
Covariance Type:            nonrobust   LLR p-value:                   0.01354
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -0.8727      1.193     -0.731      0.465      -3.211       1.466
C(topic_grouped)[T.Geography]                 -0.4639      0.430     -1.079      0.280      -1.306       0.378
C(topic_grouped)[T.Misc]                       0.2156      0.353      0.610      0.542      -0.477       0.908
C(topic_grouped)[T.Music]                      0.3844      0.411      0.935      0.350      -0.421       1.190
C(topic_grouped)[T.Other]                      0.1347      0.384      0.351      0.726      -0.618       0.887
C(topic_grouped)[T.Politics]                  -0.2262      0.360     -0.628      0.530      -0.932       0.480
C(topic_grouped)[T.Science and technology]     0.2359      0.326      0.723      0.469      -0.403       0.875
C(topic_grouped)[T.Sports]                    -0.0033      0.425     -0.008      0.994      -0.835       0.829
C(answer_type_grouped)[T.Number]               0.5346      0.288      1.859      0.063      -0.029       1.098
C(answer_type_grouped)[T.Other]               -0.8124      0.260     -3.124      0.002      -1.322      -0.303
C(answer_type_grouped)[T.Person]              -0.4455      0.256     -1.739      0.082      -0.947       0.057
q_length                                       0.1127      0.257      0.439      0.661      -0.391       0.616
capabilities_entropy                           6.3007     23.063      0.273      0.785     -38.903      51.504
game_entropy                                  -0.5583      2.846     -0.196      0.844      -6.136       5.020
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing gemini-2.5-flash-preview-04-17 (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_neutral/gemini-2.5-flash-preview-04-17_SimpleMC_redacted_cor_temp0.0_1751845050_game_data.json', './sc_logs_neutral/gemini-2.5-flash-preview-04-17_SimpleMC_redacted_temp0.0_1751839721_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    374
1    126
Name: count, dtype: int64

Answer change%: 0.2520 [0.21394478690466812, 0.2900552130953319] (n=500)
P-value vs 25%: 0.918; P-value vs 0%: 1.614e-38
Phase 2 self-accuracy: 0.4206 [0.33443802239349496, 0.5068318188763463] (n=126)
P-value vs 25%: 0.0001045; P-value vs 33%: 0.0463

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.01615
Time:                        16:14:58   Log-Likelihood:                -277.70
converged:                       True   LL-Null:                       -282.26
Covariance Type:            nonrobust   LLR p-value:                  0.002529
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.2148      0.115    -10.540      0.000      -1.441      -0.989
game_entropy   333.1888    139.987      2.380      0.017      58.819     607.559
================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.773333
                        1                 0.226667
Geography               0                 0.772727
                        1                 0.227273
Misc                    0                 0.675676
                        1                 0.324324
Music                   0                 0.800000
                        1                 0.200000
Other                   0                 0.788462
                        1                 0.211538
Politics                0                 0.805195
                        1                 0.194805
Science and technology  0                 0.714286
                        1                 0.285714
Sports                  0                 0.675000
                        1                 0.325000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.757396
                     1                 0.242604
Number               0                 0.666667
                     1                 0.333333
Other                0                 0.781955
                     1                 0.218045
Person               0                 0.750000
                     1                 0.250000
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.857143  0.142857           21
                       Number               0.555556  0.444444            9
                       Other                0.777778  0.222222           18
                       Person               0.777778  0.222222           27
Geography              Date                 0.733333  0.266667           15
                       Number               0.722222  0.277778           18
                       Other                0.909091  0.090909           11
Misc                   Date                 0.652174  0.347826           23
                       Number               0.666667  0.333333            9
                       Other                0.629630  0.370370           27
                       Person               0.800000  0.200000           15
Music                  Date                 0.833333  0.166667           12
                       Number               0.500000  0.500000            4
                       Other                0.750000  0.250000           12
                       Person               0.916667  0.083333           12
Other                  Date                 0.722222  0.277778           18
                       Number               0.857143  0.142857            7
                       Other                0.857143  0.142857           14
                       Person               0.769231  0.230769           13
Politics               Date                 0.722222  0.277778           36
                       Number               1.000000  0.000000            6
                       Other                0.950000  0.050000           20
                       Person               0.733333  0.266667           15
Science and technology Date                 0.828571  0.171429           35
                       Number               0.500000  0.500000           14
                       Other                0.789474  0.210526           19
                       Person               0.633333  0.366667           30
Sports                 Date                 0.666667  0.333333            9
                       Number               0.636364  0.363636           11
                       Other                0.666667  0.333333           12
                       Person               0.750000  0.250000            8

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      488
Method:                           MLE   Df Model:                           11
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.01816
Time:                        16:14:58   Log-Likelihood:                -277.14
converged:                       True   LL-Null:                       -282.26
Covariance Type:            nonrobust   LLR p-value:                    0.5079
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -0.5143      1.306     -0.394      0.694      -3.075       2.046
C(topic_grouped)[T.Geography]                 -0.1349      0.470     -0.287      0.774      -1.056       0.786
C(topic_grouped)[T.Misc]                       0.5231      0.375      1.395      0.163      -0.212       1.258
C(topic_grouped)[T.Music]                     -0.1476      0.484     -0.305      0.760      -1.096       0.801
C(topic_grouped)[T.Other]                     -0.0965      0.440     -0.219      0.826      -0.959       0.766
C(topic_grouped)[T.Politics]                  -0.1341      0.407     -0.330      0.742      -0.932       0.663
C(topic_grouped)[T.Science and technology]     0.3078      0.358      0.861      0.389      -0.393       1.009
C(topic_grouped)[T.Sports]                     0.4431      0.441      1.004      0.316      -0.422       1.308
C(answer_type_grouped)[T.Number]               0.4324      0.311      1.392      0.164      -0.176       1.041
C(answer_type_grouped)[T.Other]               -0.1949      0.281     -0.693      0.488      -0.746       0.356
C(answer_type_grouped)[T.Person]              -0.0073      0.284     -0.026      0.979      -0.564       0.549
q_length                                      -0.1622      0.282     -0.576      0.565      -0.714       0.390
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      487
Method:                           MLE   Df Model:                           12
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.03522
Time:                        16:14:58   Log-Likelihood:                -272.32
converged:                       True   LL-Null:                       -282.26
Covariance Type:            nonrobust   LLR p-value:                   0.06931
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -0.6329      1.320     -0.479      0.632      -3.221       1.955
C(topic_grouped)[T.Geography]                 -0.0924      0.473     -0.195      0.845      -1.020       0.835
C(topic_grouped)[T.Misc]                       0.4315      0.384      1.125      0.261      -0.321       1.184
C(topic_grouped)[T.Music]                     -0.1877      0.494     -0.380      0.704      -1.155       0.780
C(topic_grouped)[T.Other]                     -0.1014      0.445     -0.228      0.820      -0.974       0.772
C(topic_grouped)[T.Politics]                  -0.1209      0.410     -0.295      0.768      -0.925       0.683
C(topic_grouped)[T.Science and technology]     0.3511      0.361      0.973      0.330      -0.356       1.058
C(topic_grouped)[T.Sports]                     0.4351      0.445      0.977      0.328      -0.437       1.308
C(answer_type_grouped)[T.Number]               0.4691      0.313      1.500      0.134      -0.144       1.082
C(answer_type_grouped)[T.Other]               -0.2666      0.288     -0.927      0.354      -0.831       0.297
C(answer_type_grouped)[T.Person]               0.0418      0.286      0.146      0.884      -0.519       0.602
q_length                                      -0.1654      0.285     -0.581      0.561      -0.724       0.393
game_entropy                                 360.8089    141.527      2.549      0.011      83.421     638.197
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing gemini-2.5-flash_nothink (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_neutral/gemini-2.5-flash_nothink_SimpleMC_neut_redacted_cor_temp1.0_1757984952_game_data.json', './sc_logs_neutral/gemini-2.5-flash_nothink_SimpleMC_neut_redacted_temp1.0_1757984766_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    347
1    153
Name: count, dtype: int64

Answer change%: 0.3060 [0.26560723923775725, 0.34639276076224274] (n=500)
P-value vs 25%: 0.006582; P-value vs 0%: 7.175e-50
Phase 2 self-accuracy: 0.2876 [0.21586000644258346, 0.35930339225022695] (n=153)
P-value vs 25%: 0.3044; P-value vs 33%: 0.2145

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1164
Time:                        16:14:58   Log-Likelihood:                -272.10
converged:                       True   LL-Null:                       -307.93
Covariance Type:            nonrobust   LLR p-value:                 2.561e-17
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          1.8465      0.339      5.454      0.000       1.183       2.510
p_i_capability    -3.9391      0.500     -7.873      0.000      -4.920      -2.959
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1089
Time:                        16:14:58   Log-Likelihood:                -274.40
converged:                       True   LL-Null:                       -307.93
Covariance Type:            nonrobust   LLR p-value:                 2.631e-16
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.3489      0.248     -9.472      0.000      -2.835      -1.863
capabilities_entropy     1.3777      0.185      7.443      0.000       1.015       1.741
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.5686 [0.4902, 0.6471] (n=153)
                  P-value vs 33.3%: 4.191e-09

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=2.29, p=0.0225
Wilcoxon delta_p: statistic=25117.00, p=0.00668
Mean Δp = 0.0201  [0.0029, 0.0373]
Idea 1 N = 347; 

  Idea 1.5: Calibration Metrics
  NLL: 1.3760, Signed ECE (overconf pos under neg): -0.0393, ECE: 0.1397 (n=500)
  Brier: 0.0702, Reliability (absolute calibration error; lower better): 0.0358, Resolution (relative calibration quality; higher better): 0.2148, Uncertainty: 0.2499 (n=500)
  AUROC: 0.9946

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.613
Model:                            OLS   Adj. R-squared:                  0.610
Method:                 Least Squares   F-statistic:                     260.3
Date:                Wed, 24 Sep 2025   Prob (F-statistic):          2.75e-101
Time:                        16:14:58   Log-Likelihood:                 230.51
No. Observations:                 498   AIC:                            -453.0
Df Residuals:                     494   BIC:                            -436.2
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.1154      0.031     -3.708      0.000      -0.177      -0.054
p1                    0.1767      0.039      4.514      0.000       0.100       0.254
answer_changed       -0.0358      0.050     -0.718      0.473      -0.134       0.062
p1:answer_changed     0.7122      0.074      9.638      0.000       0.567       0.857
==============================================================================
Omnibus:                       11.152   Durbin-Watson:                   1.883
Prob(Omnibus):                  0.004   Jarque-Bera (JB):               19.189
Skew:                           0.087   Prob(JB):                     6.81e-05
Kurtosis:                       3.946   Cond. No.                         17.6
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=0.22, p=0.829
Wilcoxon delta_H: statistic=29509.00, p=0.716
Mean ΔH = 0.0053  [-0.0426, 0.0531]
Paired t-test delta_H Changed: statistic=7.50, p=5.05e-12
Wilcoxon delta_H Changed: statistic=2320.00, p=7.84e-11
Mean ΔH Changed = 0.2259  [0.1669, 0.2850]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=-4.23, p=2.83e-05
Wilcoxon (p_top2_game vs p_top2_base): statistic=48622.00, p=1.48e-05
Mean Δp_top2 = -0.0169  [-0.0247, -0.0090] (n=500)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=3.68, p=0.000263
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=51853.00, p=0.00086
Mean ΔH_unchosen_baseline_set = 0.0728  [0.0340, 0.1116] (n=500)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      497
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1170
Time:                        16:14:58   Log-Likelihood:                -271.90
converged:                       True   LL-Null:                       -307.93
Covariance Type:            nonrobust   LLR p-value:                 2.256e-16
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.8853      0.160     -5.517      0.000      -1.200      -0.571
p1_z            -0.9066      0.123     -7.344      0.000      -1.148      -0.665
I(p1_z ** 2)    -0.0861      0.136     -0.631      0.528      -0.353       0.181
================================================================================
AUC = 0.737

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1141
Time:                        16:14:58   Log-Likelihood:                -272.79
converged:                       True   LL-Null:                       -307.93
Covariance Type:            nonrobust   LLR p-value:                 5.130e-17
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -2.4473      0.258     -9.483      0.000      -2.953      -1.941
game_entropy     1.4233      0.188      7.569      0.000       1.055       1.792
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=58560.00, p=0.209
Paired t-test (game_entropy vs capabilities_entropy): statistic=1.39, p=0.165
Mean game_entropy-capabilities_entropy = 0.0290  [-0.0119, 0.0700] (n=500)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      497
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1311
Time:                        16:14:58   Log-Likelihood:                -267.57
converged:                       True   LL-Null:                       -307.93
Covariance Type:            nonrobust   LLR p-value:                 2.961e-18
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.7137      0.281     -9.655      0.000      -3.265      -2.163
capabilities_entropy     0.7732      0.243      3.178      0.001       0.296       1.250
game_entropy             0.9022      0.247      3.648      0.000       0.418       1.387
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.746667
                        1                 0.253333
Geography               0                 0.659091
                        1                 0.340909
Misc                    0                 0.621622
                        1                 0.378378
Music                   0                 0.675000
                        1                 0.325000
Other                   0                 0.615385
                        1                 0.384615
Politics                0                 0.688312
                        1                 0.311688
Science and technology  0                 0.744898
                        1                 0.255102
Sports                  0                 0.775000
                        1                 0.225000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.633136
                     1                 0.366864
Number               0                 0.641026
                     1                 0.358974
Other                0                 0.744361
                     1                 0.255639
Person               0                 0.758333
                     1                 0.241667
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.619048  0.380952           21
                       Number               0.555556  0.444444            9
                       Other                0.833333  0.166667           18
                       Person               0.851852  0.148148           27
Geography              Date                 0.400000  0.600000           15
                       Number               0.833333  0.166667           18
                       Other                0.727273  0.272727           11
Misc                   Date                 0.521739  0.478261           23
                       Number               0.555556  0.444444            9
                       Other                0.740741  0.259259           27
                       Person               0.600000  0.400000           15
Music                  Date                 0.750000  0.250000           12
                       Number               0.500000  0.500000            4
                       Other                0.583333  0.416667           12
                       Person               0.750000  0.250000           12
Other                  Date                 0.611111  0.388889           18
                       Number               0.571429  0.428571            7
                       Other                0.500000  0.500000           14
                       Person               0.769231  0.230769           13
Politics               Date                 0.666667  0.333333           36
                       Number               0.333333  0.666667            6
                       Other                0.800000  0.200000           20
                       Person               0.733333  0.266667           15
Science and technology Date                 0.771429  0.228571           35
                       Number               0.642857  0.357143           14
                       Other                0.789474  0.210526           19
                       Person               0.733333  0.266667           30
Sports                 Date                 0.555556  0.444444            9
                       Number               0.727273  0.272727           11
                       Other                0.916667  0.083333           12
                       Person               0.875000  0.125000            8

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      488
Method:                           MLE   Df Model:                           11
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.03792
Time:                        16:14:58   Log-Likelihood:                -296.25
converged:                       True   LL-Null:                       -307.93
Covariance Type:            nonrobust   LLR p-value:                   0.01575
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      2.7758      1.281      2.167      0.030       0.265       5.287
C(topic_grouped)[T.Geography]                  0.1802      0.432      0.417      0.677      -0.667       1.027
C(topic_grouped)[T.Misc]                       0.6038      0.365      1.652      0.098      -0.112       1.320
C(topic_grouped)[T.Music]                      0.3261      0.436      0.748      0.454      -0.528       1.181
C(topic_grouped)[T.Other]                      0.5584      0.397      1.405      0.160      -0.220       1.337
C(topic_grouped)[T.Politics]                   0.3825      0.375      1.020      0.308      -0.352       1.117
C(topic_grouped)[T.Science and technology]     0.0096      0.359      0.027      0.979      -0.694       0.713
C(topic_grouped)[T.Sports]                    -0.2122      0.471     -0.450      0.652      -1.136       0.711
C(answer_type_grouped)[T.Number]               0.0432      0.299      0.145      0.885      -0.542       0.628
C(answer_type_grouped)[T.Other]               -0.6261      0.262     -2.388      0.017      -1.140      -0.112
C(answer_type_grouped)[T.Person]              -0.6497      0.276     -2.358      0.018      -1.190      -0.110
q_length                                      -0.7875      0.278     -2.834      0.005      -1.332      -0.243
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 1.0002
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      487
Method:                           MLE   Df Model:                           12
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1340
Time:                        16:14:58   Log-Likelihood:                -266.67
converged:                       True   LL-Null:                       -307.93
Covariance Type:            nonrobust   LLR p-value:                 1.357e-12
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      1.2569      1.373      0.916      0.360      -1.433       3.947
C(topic_grouped)[T.Geography]                 -0.0231      0.459     -0.050      0.960      -0.922       0.876
C(topic_grouped)[T.Misc]                       0.5379      0.386      1.393      0.164      -0.219       1.295
C(topic_grouped)[T.Music]                      0.2994      0.466      0.642      0.521      -0.615       1.213
C(topic_grouped)[T.Other]                      0.4621      0.423      1.092      0.275      -0.367       1.291
C(topic_grouped)[T.Politics]                   0.5227      0.400      1.307      0.191      -0.261       1.307
C(topic_grouped)[T.Science and technology]    -0.0947      0.380     -0.249      0.803      -0.840       0.651
C(topic_grouped)[T.Sports]                    -0.2355      0.497     -0.474      0.635      -1.209       0.738
C(answer_type_grouped)[T.Number]               0.1946      0.316      0.616      0.538      -0.425       0.814
C(answer_type_grouped)[T.Other]               -0.2116      0.284     -0.745      0.456      -0.768       0.345
C(answer_type_grouped)[T.Person]              -0.0693      0.305     -0.228      0.820      -0.666       0.528
q_length                                      -0.8428      0.296     -2.851      0.004      -1.422      -0.263
capabilities_entropy                           1.3927      0.198      7.035      0.000       1.005       1.781
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      487
Method:                           MLE   Df Model:                           12
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1384
Time:                        16:14:58   Log-Likelihood:                -265.31
converged:                       True   LL-Null:                       -307.93
Covariance Type:            nonrobust   LLR p-value:                 4.105e-13
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      1.2421      1.367      0.908      0.364      -1.438       3.922
C(topic_grouped)[T.Geography]                  0.0916      0.459      0.199      0.842      -0.809       0.992
C(topic_grouped)[T.Misc]                       0.4853      0.391      1.241      0.215      -0.281       1.252
C(topic_grouped)[T.Music]                      0.1731      0.474      0.366      0.715      -0.755       1.101
C(topic_grouped)[T.Other]                      0.3936      0.427      0.922      0.356      -0.443       1.230
C(topic_grouped)[T.Politics]                   0.4307      0.402      1.071      0.284      -0.358       1.219
C(topic_grouped)[T.Science and technology]    -0.0637      0.388     -0.164      0.870      -0.824       0.697
C(topic_grouped)[T.Sports]                    -0.3842      0.500     -0.768      0.443      -1.365       0.597
C(answer_type_grouped)[T.Number]              -0.0310      0.313     -0.099      0.921      -0.644       0.582
C(answer_type_grouped)[T.Other]               -0.1288      0.288     -0.447      0.655      -0.693       0.436
C(answer_type_grouped)[T.Person]              -0.0675      0.308     -0.219      0.826      -0.670       0.535
q_length                                      -0.8583      0.295     -2.913      0.004      -1.436      -0.281
game_entropy                                   1.4656      0.205      7.133      0.000       1.063       1.868
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      486
Method:                           MLE   Df Model:                           13
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1561
Time:                        16:14:58   Log-Likelihood:                -259.87
converged:                       True   LL-Null:                       -307.93
Covariance Type:            nonrobust   LLR p-value:                 9.283e-15
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      0.9098      1.393      0.653      0.514      -1.820       3.640
C(topic_grouped)[T.Geography]                  0.0136      0.464      0.029      0.977      -0.897       0.924
C(topic_grouped)[T.Misc]                       0.5031      0.394      1.276      0.202      -0.270       1.276
C(topic_grouped)[T.Music]                      0.1931      0.480      0.402      0.688      -0.749       1.135
C(topic_grouped)[T.Other]                      0.4006      0.431      0.929      0.353      -0.444       1.246
C(topic_grouped)[T.Politics]                   0.5097      0.407      1.252      0.211      -0.288       1.308
C(topic_grouped)[T.Science and technology]    -0.0985      0.391     -0.252      0.801      -0.866       0.669
C(topic_grouped)[T.Sports]                    -0.3333      0.506     -0.659      0.510      -1.325       0.658
C(answer_type_grouped)[T.Number]               0.0829      0.320      0.259      0.795      -0.544       0.709
C(answer_type_grouped)[T.Other]               -0.0550      0.292     -0.188      0.851      -0.628       0.518
C(answer_type_grouped)[T.Person]               0.0786      0.315      0.250      0.803      -0.538       0.695
q_length                                      -0.8716      0.299     -2.910      0.004      -1.459      -0.285
capabilities_entropy                           0.8135      0.250      3.249      0.001       0.323       1.304
game_entropy                                   0.9461      0.260      3.641      0.000       0.437       1.456
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing gemini-2.5-flash_think (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_neutral/gemini-2.5-flash_think_SimpleMC_neut_redacted_cor_temp1.0_1758287106_game_data.json', './sc_logs_neutral/gemini-2.5-flash_think_SimpleMC_neut_redacted_temp1.0_1758279039_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    350
1    150
Name: count, dtype: int64

Answer change%: 0.3000 [0.2598326910947281, 0.34016730890527186] (n=500)
P-value vs 25%: 0.0147; P-value vs 0%: 1.595e-48
Phase 2 self-accuracy: 0.3333 [0.25789428439492185, 0.4087723822717448] (n=150)
P-value vs 25%: 0.03038; P-value vs 33%: 0.9931

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:               0.0009072
Time:                        16:14:58   Log-Likelihood:                -305.16
converged:                       True   LL-Null:                       -305.43
Covariance Type:            nonrobust   LLR p-value:                    0.4566
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept        -44.9433     98.180     -0.458      0.647    -237.373     147.486
p_i_capability    44.1004     98.185      0.449      0.653    -148.339     236.540
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:               0.0008526
Time:                        16:14:58   Log-Likelihood:                -305.17
converged:                       True   LL-Null:                       -305.43
Covariance Type:            nonrobust   LLR p-value:                    0.4705
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -0.8420      0.098     -8.602      0.000      -1.034      -0.650
capabilities_entropy    -6.1363     12.881     -0.476      0.634     -31.383      19.111
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.3267 [0.2516, 0.4017] (n=150)
                  P-value vs 33.3%: 0.8618

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=0.83, p=0.406
Wilcoxon delta_p: statistic=14604.00, p=7.8e-17
Mean Δp = 0.0004  [-0.0005, 0.0012]
Idea 1 N = 350; 

  Idea 1.5: Calibration Metrics
  NLL: 3.7978, Signed ECE (overconf pos under neg): -0.0000, ECE: 0.0000 (n=480)
  Brier: 0.0000, Reliability (absolute calibration error; lower better): 0.0000, Resolution (relative calibration quality; higher better): 0.2066, Uncertainty: 0.2066 (n=480)
  AUROC: 1.0000

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       1.000
Model:                            OLS   Adj. R-squared:                  1.000
Method:                 Least Squares   F-statistic:                 8.641e+05
Date:                Wed, 24 Sep 2025   Prob (F-statistic):               0.00
Time:                        16:14:58   Log-Likelihood:                 1787.2
No. Observations:                 486   AIC:                            -3566.
Df Residuals:                     482   BIC:                            -3550.
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.9902      0.092    -10.777      0.000      -1.171      -0.810
p1                    0.9907      0.092     10.781      0.000       0.810       1.171
answer_changed        0.6824      1.442      0.473      0.636      -2.152       3.516
p1:answer_changed     0.3170      1.442      0.220      0.826      -2.517       3.151
==============================================================================
Omnibus:                     1069.755   Durbin-Watson:                   2.010
Prob(Omnibus):                  0.000   Jarque-Bera (JB):          1978272.633
Skew:                          17.225   Prob(JB):                         0.00
Kurtosis:                     313.654   Cond. No.                     1.08e+04
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The condition number is large, 1.08e+04. This might indicate that there are
strong multicollinearity or other numerical problems.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=3.68, p=0.000265
Wilcoxon delta_H: statistic=22581.00, p=1.77e-05
Mean ΔH = 0.0613  [0.0287, 0.0940]
Paired t-test delta_H Changed: statistic=48.58, p=2.92e-93
Wilcoxon delta_H Changed: statistic=1.00, p=2.35e-26
Mean ΔH Changed = 1.2178  [1.1687, 1.2670]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=0.19, p=0.847
Wilcoxon (p_top2_game vs p_top2_base): statistic=34344.00, p=2.14e-18
Mean Δp_top2 = 0.0000  [-0.0001, 0.0001] (n=500)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=14.86, p=1.27e-41
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=23035.00, p=1.72e-34
Mean ΔH_unchosen_baseline_set = 0.4083  [0.3544, 0.4621] (n=500)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      497
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                0.001387
Time:                        16:14:58   Log-Likelihood:                -305.01
converged:                       True   LL-Null:                       -305.43
Covariance Type:            nonrobust   LLR p-value:                    0.6546
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.8256      0.108     -7.631      0.000      -1.038      -0.614
p1_z            -0.4198      1.054     -0.398      0.690      -2.485       1.646
I(p1_z ** 2)    -0.0321      0.097     -0.332      0.740      -0.221       0.157
================================================================================
AUC = 0.553

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:               0.0001326
Time:                        16:14:58   Log-Likelihood:                -305.39
converged:                       True   LL-Null:                       -305.43
Covariance Type:            nonrobust   LLR p-value:                    0.7759
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.8503      0.098     -8.660      0.000      -1.043      -0.658
game_entropy     0.8065      2.789      0.289      0.772      -4.660       6.273
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=30829.00, p=7.81e-23
Paired t-test (game_entropy vs capabilities_entropy): statistic=1.33, p=0.183
Mean game_entropy-capabilities_entropy = 0.0022  [-0.0010, 0.0055] (n=500)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      497
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                0.001058
Time:                        16:14:58   Log-Likelihood:                -305.11
converged:                       True   LL-Null:                       -305.43
Covariance Type:            nonrobust   LLR p-value:                    0.7239
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -0.8453      0.098     -8.590      0.000      -1.038      -0.652
capabilities_entropy    -6.8128     14.613     -0.466      0.641     -35.454      21.829
game_entropy             1.0178      2.825      0.360      0.719      -4.519       6.555
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.733333
                        1                 0.266667
Geography               0                 0.681818
                        1                 0.318182
Misc                    0                 0.581081
                        1                 0.418919
Music                   0                 0.700000
                        1                 0.300000
Other                   0                 0.692308
                        1                 0.307692
Politics                0                 0.753247
                        1                 0.246753
Science and technology  0                 0.734694
                        1                 0.265306
Sports                  0                 0.700000
                        1                 0.300000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.710059
                     1                 0.289941
Number               0                 0.653846
                     1                 0.346154
Other                0                 0.676692
                     1                 0.323308
Person               0                 0.741667
                     1                 0.258333
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.761905  0.238095           21
                       Number               0.777778  0.222222            9
                       Other                0.722222  0.277778           18
                       Person               0.703704  0.296296           27
Geography              Date                 0.666667  0.333333           15
                       Number               0.666667  0.333333           18
                       Other                0.727273  0.272727           11
Misc                   Date                 0.652174  0.347826           23
                       Number               0.555556  0.444444            9
                       Other                0.518519  0.481481           27
                       Person               0.600000  0.400000           15
Music                  Date                 0.583333  0.416667           12
                       Number               0.500000  0.500000            4
                       Other                0.583333  0.416667           12
                       Person               1.000000  0.000000           12
Other                  Date                 0.666667  0.333333           18
                       Number               0.571429  0.428571            7
                       Other                0.714286  0.285714           14
                       Person               0.769231  0.230769           13
Politics               Date                 0.722222  0.277778           36
                       Number               0.833333  0.166667            6
                       Other                0.800000  0.200000           20
                       Person               0.733333  0.266667           15
Science and technology Date                 0.771429  0.228571           35
                       Number               0.714286  0.285714           14
                       Other                0.684211  0.315789           19
                       Person               0.733333  0.266667           30
Sports                 Date                 0.777778  0.222222            9
                       Number               0.545455  0.454545           11
                       Other                0.750000  0.250000           12
                       Person               0.750000  0.250000            8

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      488
Method:                           MLE   Df Model:                           11
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.01403
Time:                        16:14:58   Log-Likelihood:                -301.15
converged:                       True   LL-Null:                       -305.43
Covariance Type:            nonrobust   LLR p-value:                    0.6613
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.4172      1.243     -1.140      0.254      -3.853       1.018
C(topic_grouped)[T.Geography]                  0.1296      0.430      0.302      0.763      -0.712       0.972
C(topic_grouped)[T.Misc]                       0.6475      0.354      1.827      0.068      -0.047       1.342
C(topic_grouped)[T.Music]                      0.1592      0.434      0.367      0.714      -0.691       1.010
C(topic_grouped)[T.Other]                      0.1810      0.400      0.453      0.651      -0.602       0.964
C(topic_grouped)[T.Politics]                  -0.1414      0.380     -0.372      0.710      -0.887       0.604
C(topic_grouped)[T.Science and technology]    -0.0245      0.349     -0.070      0.944      -0.709       0.660
C(topic_grouped)[T.Sports]                     0.0948      0.437      0.217      0.828      -0.762       0.952
C(answer_type_grouped)[T.Number]               0.2364      0.302      0.782      0.434      -0.356       0.828
C(answer_type_grouped)[T.Other]                0.1056      0.256      0.413      0.680      -0.395       0.607
C(answer_type_grouped)[T.Person]              -0.1497      0.276     -0.543      0.587      -0.690       0.390
q_length                                       0.0900      0.267      0.336      0.737      -0.434       0.614
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.0013
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      487
Method:                           MLE   Df Model:                           12
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.01573
Time:                        16:14:58   Log-Likelihood:                -300.63
converged:                       True   LL-Null:                       -305.43
Covariance Type:            nonrobust   LLR p-value:                    0.6502
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.3668      1.244     -1.099      0.272      -3.805       1.071
C(topic_grouped)[T.Geography]                  0.1251      0.430      0.291      0.771      -0.717       0.967
C(topic_grouped)[T.Misc]                       0.6770      0.356      1.904      0.057      -0.020       1.374
C(topic_grouped)[T.Music]                      0.1568      0.434      0.361      0.718      -0.694       1.007
C(topic_grouped)[T.Other]                      0.1802      0.400      0.451      0.652      -0.603       0.963
C(topic_grouped)[T.Politics]                  -0.1399      0.380     -0.368      0.713      -0.885       0.605
C(topic_grouped)[T.Science and technology]    -0.0203      0.349     -0.058      0.954      -0.705       0.664
C(topic_grouped)[T.Sports]                     0.0938      0.437      0.215      0.830      -0.763       0.951
C(answer_type_grouped)[T.Number]               0.2464      0.302      0.814      0.415      -0.346       0.839
C(answer_type_grouped)[T.Other]                0.1169      0.256      0.457      0.648      -0.385       0.618
C(answer_type_grouped)[T.Person]              -0.1498      0.276     -0.543      0.587      -0.690       0.391
q_length                                       0.0784      0.268      0.293      0.770      -0.446       0.603
capabilities_entropy                          -9.1903     17.254     -0.533      0.594     -43.007      24.627
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      487
Method:                           MLE   Df Model:                           12
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.01403
Time:                        16:14:58   Log-Likelihood:                -301.15
converged:                       True   LL-Null:                       -305.43
Covariance Type:            nonrobust   LLR p-value:                    0.7389
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.4125      1.253     -1.127      0.260      -3.868       1.043
C(topic_grouped)[T.Geography]                  0.1296      0.430      0.302      0.763      -0.712       0.972
C(topic_grouped)[T.Misc]                       0.6470      0.355      1.824      0.068      -0.048       1.342
C(topic_grouped)[T.Music]                      0.1592      0.434      0.367      0.714      -0.691       1.010
C(topic_grouped)[T.Other]                      0.1810      0.400      0.453      0.651      -0.602       0.964
C(topic_grouped)[T.Politics]                  -0.1412      0.380     -0.371      0.710      -0.886       0.604
C(topic_grouped)[T.Science and technology]    -0.0250      0.350     -0.071      0.943      -0.710       0.660
C(topic_grouped)[T.Sports]                     0.0940      0.438      0.215      0.830      -0.765       0.952
C(answer_type_grouped)[T.Number]               0.2355      0.303      0.776      0.438      -0.359       0.830
C(answer_type_grouped)[T.Other]                0.1052      0.256      0.411      0.681      -0.397       0.607
C(answer_type_grouped)[T.Person]              -0.1498      0.276     -0.544      0.587      -0.690       0.390
q_length                                       0.0890      0.270      0.330      0.741      -0.439       0.617
game_entropy                                   0.0845      2.899      0.029      0.977      -5.597       5.766
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      486
Method:                           MLE   Df Model:                           13
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.01576
Time:                        16:14:58   Log-Likelihood:                -300.62
converged:                       True   LL-Null:                       -305.43
Covariance Type:            nonrobust   LLR p-value:                    0.7239
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.3430      1.255     -1.070      0.284      -3.803       1.116
C(topic_grouped)[T.Geography]                  0.1250      0.430      0.291      0.771      -0.717       0.967
C(topic_grouped)[T.Misc]                       0.6755      0.356      1.899      0.058      -0.022       1.373
C(topic_grouped)[T.Music]                      0.1565      0.434      0.361      0.718      -0.694       1.007
C(topic_grouped)[T.Other]                      0.1800      0.400      0.451      0.652      -0.603       0.963
C(topic_grouped)[T.Politics]                  -0.1391      0.380     -0.366      0.715      -0.884       0.606
C(topic_grouped)[T.Science and technology]    -0.0223      0.350     -0.064      0.949      -0.708       0.663
C(topic_grouped)[T.Sports]                     0.0898      0.438      0.205      0.838      -0.769       0.948
C(answer_type_grouped)[T.Number]               0.2428      0.304      0.800      0.424      -0.352       0.838
C(answer_type_grouped)[T.Other]                0.1147      0.256      0.448      0.655      -0.388       0.617
C(answer_type_grouped)[T.Person]              -0.1504      0.276     -0.545      0.585      -0.691       0.390
q_length                                       0.0734      0.270      0.272      0.786      -0.456       0.603
capabilities_entropy                          -9.7241     19.220     -0.506      0.613     -47.394      27.945
game_entropy                                   0.4193      2.932      0.143      0.886      -5.328       6.167
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing gpt-4.1-2025-04-14 (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_neutral/gpt-4.1-2025-04-14_SimpleMC_neut_redacted_cor_temp1.0_1757986326_game_data.json', './sc_logs_neutral/gpt-4.1-2025-04-14_SimpleMC_neut_redacted_temp1.0_1757985243_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    415
1     85
Name: count, dtype: int64

Answer change%: 0.1700 [0.13707493843286117, 0.20292506156713885] (n=500)
P-value vs 25%: 1.915e-06; P-value vs 0%: 4.515e-24
Phase 2 self-accuracy: 0.4118 [0.30713892153354116, 0.5163904902311647] (n=85)
P-value vs 25%: 0.002443; P-value vs 33%: 0.1401

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.03969
Time:                        16:14:58   Log-Likelihood:                -218.90
converged:                       True   LL-Null:                       -227.94
Covariance Type:            nonrobust   LLR p-value:                 2.104e-05
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          0.5917      0.502      1.179      0.239      -0.392       1.576
p_i_capability    -2.5962      0.600     -4.324      0.000      -3.773      -1.419
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.04899
Time:                        16:14:58   Log-Likelihood:                -216.78
converged:                       True   LL-Null:                       -227.94
Covariance Type:            nonrobust   LLR p-value:                 2.292e-06
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.1228      0.180    -11.775      0.000      -2.476      -1.769
capabilities_entropy     0.9809      0.207      4.738      0.000       0.575       1.387
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.2222 [0.1262, 0.3183] (n=72)
                  P-value vs 33.3%: 0.02334

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=9.55, p=2.5e-17
Wilcoxon delta_p: statistic=2001.00, p=1.09e-13
Mean Δp = 0.3653  [0.2903, 0.4402]
Idea 1 N = 158; 

  Idea 1.5: Calibration Metrics
  NLL: 5.0778, Signed ECE (overconf pos under neg): -0.1972, ECE: 0.3782 (n=208)
  Brier: 0.3959, Reliability (absolute calibration error; lower better): 0.1650, Resolution (relative calibration quality; higher better): 0.0121, Uncertainty: 0.2433 (n=208)
  AUROC: 0.4556

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.195
Model:                            OLS   Adj. R-squared:                  0.183
Method:                 Least Squares   F-statistic:                     16.50
Date:                Wed, 24 Sep 2025   Prob (F-statistic):           1.22e-09
Time:                        16:14:58   Log-Likelihood:                -111.65
No. Observations:                 208   AIC:                             231.3
Df Residuals:                     204   BIC:                             244.7
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.4168      0.141     -2.951      0.004      -0.695      -0.138
p1                    1.0178      0.179      5.698      0.000       0.666       1.370
answer_changed        0.1222      0.267      0.458      0.647      -0.404       0.649
p1:answer_changed     0.0922      0.354      0.260      0.795      -0.606       0.791
==============================================================================
Omnibus:                     2818.272   Durbin-Watson:                   1.752
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               26.554
Skew:                          -0.477   Prob(JB):                     1.71e-06
Kurtosis:                       1.532   Cond. No.                         20.5
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=5.78, p=3.98e-08
Wilcoxon delta_H: statistic=3112.00, p=3.79e-08
Mean ΔH = 0.2806  [0.1854, 0.3758]
Paired t-test delta_H Changed: statistic=3.82, p=0.000374
Wilcoxon delta_H Changed: statistic=270.00, p=0.000252
Mean ΔH Changed = 0.2750  [0.1339, 0.4160]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=6.72, p=1.69e-10
Wilcoxon (p_top2_game vs p_top2_base): statistic=4311.00, p=4.54e-14
Mean Δp_top2 = 0.0433  [0.0307, 0.0559] (n=208)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=6.87, p=7.55e-11
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=5194.00, p=6.64e-11
Mean ΔH_unchosen_baseline_set = 0.2792  [0.1995, 0.3589] (n=208)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  208
Model:                          Logit   Df Residuals:                      205
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.01318
Time:                        16:14:58   Log-Likelihood:                -113.21
converged:                       True   LL-Null:                       -114.72
Covariance Type:            nonrobust   LLR p-value:                    0.2206
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.1734      0.234     -5.013      0.000      -1.632      -0.715
p1_z            -0.2791      0.179     -1.558      0.119      -0.630       0.072
I(p1_z ** 2)     0.0027      0.169      0.016      0.987      -0.329       0.335
================================================================================
AUC = 0.583

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1015
Time:                        16:14:58   Log-Likelihood:                -204.80
converged:                       True   LL-Null:                       -227.94
Covariance Type:            nonrobust   LLR p-value:                 1.026e-11
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -2.1677      0.165    -13.133      0.000      -2.491      -1.844
game_entropy     1.8321      0.271      6.771      0.000       1.302       2.362
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=19057.00, p=1.53e-19
Paired t-test (game_entropy vs capabilities_entropy): statistic=-9.34, p=3.28e-19
Mean game_entropy-capabilities_entropy = -0.2220  [-0.2686, -0.1754] (n=500)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      497
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1136
Time:                        16:14:58   Log-Likelihood:                -202.06
converged:                       True   LL-Null:                       -227.94
Covariance Type:            nonrobust   LLR p-value:                 5.730e-12
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.3877      0.197    -12.096      0.000      -2.775      -2.001
capabilities_entropy     0.5489      0.232      2.370      0.018       0.095       1.003
game_entropy             1.5806      0.291      5.428      0.000       1.010       2.151
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.893333
                        1                 0.106667
Geography               0                 0.750000
                        1                 0.250000
Misc                    0                 0.770270
                        1                 0.229730
Music                   0                 0.775000
                        1                 0.225000
Other                   0                 0.865385
                        1                 0.134615
Politics                0                 0.844156
                        1                 0.155844
Science and technology  0                 0.836735
                        1                 0.163265
Sports                  0                 0.875000
                        1                 0.125000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.769231
                     1                 0.230769
Number               0                 0.820513
                     1                 0.179487
Other                0                 0.879699
                     1                 0.120301
Person               0                 0.866667
                     1                 0.133333
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.809524  0.190476           21
                       Number               0.777778  0.222222            9
                       Other                0.944444  0.055556           18
                       Person               0.962963  0.037037           27
Geography              Date                 0.533333  0.466667           15
                       Number               0.833333  0.166667           18
                       Other                0.909091  0.090909           11
Misc                   Date                 0.695652  0.304348           23
                       Number               0.888889  0.111111            9
                       Other                0.740741  0.259259           27
                       Person               0.866667  0.133333           15
Music                  Date                 0.666667  0.333333           12
                       Number               1.000000  0.000000            4
                       Other                0.833333  0.166667           12
                       Person               0.750000  0.250000           12
Other                  Date                 0.722222  0.277778           18
                       Number               1.000000  0.000000            7
                       Other                0.928571  0.071429           14
                       Person               0.923077  0.076923           13
Politics               Date                 0.833333  0.166667           36
                       Number               0.833333  0.166667            6
                       Other                0.900000  0.100000           20
                       Person               0.800000  0.200000           15
Science and technology Date                 0.857143  0.142857           35
                       Number               0.714286  0.285714           14
                       Other                0.894737  0.105263           19
                       Person               0.833333  0.166667           30
Sports                 Date                 0.888889  0.111111            9
                       Number               0.727273  0.272727           11
                       Other                1.000000  0.000000           12
                       Person               0.875000  0.125000            8

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      488
Method:                           MLE   Df Model:                           11
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.03475
Time:                        16:14:58   Log-Likelihood:                -220.02
converged:                       True   LL-Null:                       -227.94
Covariance Type:            nonrobust   LLR p-value:                    0.1470
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.2237      1.551     -0.789      0.430      -4.264       1.816
C(topic_grouped)[T.Geography]                  0.9348      0.530      1.763      0.078      -0.104       1.974
C(topic_grouped)[T.Misc]                       0.9357      0.471      1.987      0.047       0.013       1.859
C(topic_grouped)[T.Music]                      0.9001      0.537      1.676      0.094      -0.153       1.953
C(topic_grouped)[T.Other]                      0.2227      0.557      0.400      0.689      -0.868       1.314
C(topic_grouped)[T.Politics]                   0.3563      0.500      0.712      0.476      -0.624       1.337
C(topic_grouped)[T.Science and technology]     0.4417      0.467      0.945      0.345      -0.474       1.358
C(topic_grouped)[T.Sports]                     0.1956      0.614      0.319      0.750      -1.008       1.399
C(answer_type_grouped)[T.Number]              -0.3744      0.362     -1.036      0.300      -1.083       0.334
C(answer_type_grouped)[T.Other]               -0.8445      0.329     -2.563      0.010      -1.490      -0.199
C(answer_type_grouped)[T.Person]              -0.6135      0.334     -1.835      0.067      -1.269       0.042
q_length                                      -0.1062      0.332     -0.319      0.749      -0.758       0.546
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.4519
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      487
Method:                           MLE   Df Model:                           12
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.07101
Time:                        16:14:58   Log-Likelihood:                -211.76
converged:                       True   LL-Null:                       -227.94
Covariance Type:            nonrobust   LLR p-value:                  0.001213
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -2.2516      1.618     -1.391      0.164      -5.423       0.920
C(topic_grouped)[T.Geography]                  0.9866      0.540      1.827      0.068      -0.072       2.045
C(topic_grouped)[T.Misc]                       0.9531      0.480      1.984      0.047       0.011       1.895
C(topic_grouped)[T.Music]                      0.9270      0.548      1.691      0.091      -0.147       2.001
C(topic_grouped)[T.Other]                      0.2651      0.565      0.469      0.639      -0.843       1.373
C(topic_grouped)[T.Politics]                   0.4303      0.507      0.849      0.396      -0.563       1.424
C(topic_grouped)[T.Science and technology]     0.4192      0.475      0.882      0.378      -0.512       1.351
C(topic_grouped)[T.Sports]                     0.3425      0.624      0.549      0.583      -0.880       1.566
C(answer_type_grouped)[T.Number]              -0.3155      0.368     -0.857      0.392      -1.037       0.406
C(answer_type_grouped)[T.Other]               -0.6013      0.342     -1.757      0.079      -1.272       0.069
C(answer_type_grouped)[T.Person]              -0.2786      0.350     -0.797      0.426      -0.964       0.407
q_length                                      -0.0247      0.343     -0.072      0.943      -0.698       0.648
capabilities_entropy                           0.8888      0.218      4.076      0.000       0.461       1.316
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      487
Method:                           MLE   Df Model:                           12
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1234
Time:                        16:14:58   Log-Likelihood:                -199.83
converged:                       True   LL-Null:                       -227.94
Covariance Type:            nonrobust   LLR p-value:                 1.086e-07
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.9676      1.618     -1.216      0.224      -5.138       1.203
C(topic_grouped)[T.Geography]                  0.3717      0.573      0.649      0.516      -0.751       1.494
C(topic_grouped)[T.Misc]                       0.9168      0.490      1.872      0.061      -0.043       1.877
C(topic_grouped)[T.Music]                      0.7485      0.570      1.312      0.189      -0.370       1.867
C(topic_grouped)[T.Other]                      0.2896      0.575      0.503      0.615      -0.838       1.417
C(topic_grouped)[T.Politics]                   0.1703      0.521      0.327      0.744      -0.851       1.191
C(topic_grouped)[T.Science and technology]     0.3353      0.486      0.690      0.490      -0.617       1.288
C(topic_grouped)[T.Sports]                     0.1450      0.638      0.227      0.820      -1.105       1.395
C(answer_type_grouped)[T.Number]              -0.2328      0.376     -0.618      0.536      -0.971       0.505
C(answer_type_grouped)[T.Other]               -0.7773      0.353     -2.201      0.028      -1.470      -0.085
C(answer_type_grouped)[T.Person]              -0.3799      0.350     -1.085      0.278      -1.066       0.306
q_length                                      -0.0616      0.345     -0.178      0.859      -0.738       0.615
game_entropy                                   1.7917      0.284      6.309      0.000       1.235       2.348
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      486
Method:                           MLE   Df Model:                           13
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1316
Time:                        16:14:58   Log-Likelihood:                -197.95
converged:                       True   LL-Null:                       -227.94
Covariance Type:            nonrobust   LLR p-value:                 5.277e-08
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -2.4062      1.652     -1.456      0.145      -5.644       0.832
C(topic_grouped)[T.Geography]                  0.4414      0.576      0.767      0.443      -0.687       1.570
C(topic_grouped)[T.Misc]                       0.9181      0.490      1.872      0.061      -0.043       1.879
C(topic_grouped)[T.Music]                      0.7728      0.570      1.357      0.175      -0.344       1.889
C(topic_grouped)[T.Other]                      0.2995      0.577      0.519      0.604      -0.831       1.430
C(topic_grouped)[T.Politics]                   0.2095      0.523      0.401      0.689      -0.815       1.234
C(topic_grouped)[T.Science and technology]     0.3146      0.488      0.645      0.519      -0.641       1.271
C(topic_grouped)[T.Sports]                     0.2109      0.641      0.329      0.742      -1.044       1.466
C(answer_type_grouped)[T.Number]              -0.2051      0.378     -0.543      0.587      -0.945       0.535
C(answer_type_grouped)[T.Other]               -0.6767      0.360     -1.882      0.060      -1.381       0.028
C(answer_type_grouped)[T.Person]              -0.2426      0.359     -0.676      0.499      -0.946       0.460
q_length                                      -0.0240      0.350     -0.068      0.945      -0.711       0.663
capabilities_entropy                           0.4684      0.240      1.953      0.051      -0.002       0.939
game_entropy                                   1.5859      0.303      5.240      0.000       0.993       2.179
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing gpt-4o-2024-08-06 (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_neutral/gpt-4o-2024-08-06_SimpleMC_neut_redacted_cor_temp1.0_1757986595_game_data.json', './sc_logs_neutral/gpt-4o-2024-08-06_SimpleMC_neut_redacted_temp1.0_1757985534_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    392
1    108
Name: count, dtype: int64

Answer change%: 0.2160 [0.1799298460626621, 0.2520701539373379] (n=500)
P-value vs 25%: 0.06468; P-value vs 0%: 8.244e-32
Phase 2 self-accuracy: 0.4167 [0.3236867849415003, 0.5096465483918331] (n=108)
P-value vs 25%: 0.0004427; P-value vs 33%: 0.07779

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.07471
Time:                        16:14:58   Log-Likelihood:                -241.41
converged:                       True   LL-Null:                       -260.90
Covariance Type:            nonrobust   LLR p-value:                 4.274e-10
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          0.9833      0.377      2.609      0.009       0.244       1.722
p_i_capability    -3.2317      0.542     -5.964      0.000      -4.294      -2.170
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.08120
Time:                        16:14:58   Log-Likelihood:                -239.71
converged:                       True   LL-Null:                       -260.90
Covariance Type:            nonrobust   LLR p-value:                 7.552e-11
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.5034      0.254     -9.862      0.000      -3.001      -2.006
capabilities_entropy     1.2045      0.200      6.023      0.000       0.813       1.596
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.2407 [0.1601, 0.3214] (n=108)
                  P-value vs 33.3%: 0.0244

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=20.87, p=3.82e-63
Wilcoxon delta_p: statistic=4436.00, p=6e-43
Mean Δp = 0.4895  [0.4436, 0.5355]
Idea 1 N = 346; 

  Idea 1.5: Calibration Metrics
  NLL: 3.4482, Signed ECE (overconf pos under neg): -0.2035, ECE: 0.3920 (n=463)
  Brier: 0.4175, Reliability (absolute calibration error; lower better): 0.1792, Resolution (relative calibration quality; higher better): 0.0127, Uncertainty: 0.2478 (n=463)
  AUROC: 0.3733

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.381
Model:                            OLS   Adj. R-squared:                  0.377
Method:                 Least Squares   F-statistic:                     92.08
Date:                Wed, 24 Sep 2025   Prob (F-statistic):           1.97e-46
Time:                        16:14:58   Log-Likelihood:                -139.18
No. Observations:                 452   AIC:                             286.4
Df Residuals:                     448   BIC:                             302.8
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.4682      0.066     -7.062      0.000      -0.599      -0.338
p1                    1.2687      0.085     14.995      0.000       1.102       1.435
answer_changed        0.1749      0.129      1.355      0.176      -0.079       0.428
p1:answer_changed    -0.2447      0.189     -1.296      0.196      -0.616       0.126
==============================================================================
Omnibus:                       68.595   Durbin-Watson:                   2.118
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               99.476
Skew:                          -1.149   Prob(JB):                     2.51e-22
Kurtosis:                       2.990   Cond. No.                         19.1
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=13.57, p=4.54e-34
Wilcoxon delta_H: statistic=10022.00, p=4.37e-29
Mean ΔH = 0.4158  [0.3557, 0.4758]
Paired t-test delta_H Changed: statistic=4.18, p=6.12e-05
Wilcoxon delta_H Changed: statistic=1625.00, p=8.55e-05
Mean ΔH Changed = 0.2042  [0.1083, 0.3000]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=6.59, p=1.21e-10
Wilcoxon (p_top2_game vs p_top2_base): statistic=32529.00, p=1.95e-13
Mean Δp_top2 = 0.0296  [0.0208, 0.0384] (n=463)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=13.88, p=7.54e-37
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=19749.00, p=4.46e-32
Mean ΔH_unchosen_baseline_set = 0.3669  [0.3150, 0.4187] (n=463)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  463
Model:                          Logit   Df Residuals:                      460
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.06647
Time:                        16:14:58   Log-Likelihood:                -233.66
converged:                       True   LL-Null:                       -250.30
Covariance Type:            nonrobust   LLR p-value:                 5.955e-08
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.1210      0.170     -6.600      0.000      -1.454      -0.788
p1_z            -0.7126      0.135     -5.264      0.000      -0.978      -0.447
I(p1_z ** 2)    -0.2129      0.141     -1.514      0.130      -0.488       0.063
================================================================================
AUC = 0.674

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1142
Time:                        16:14:58   Log-Likelihood:                -231.11
converged:                       True   LL-Null:                       -260.90
Covariance Type:            nonrobust   LLR p-value:                 1.180e-14
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -2.5730      0.238    -10.817      0.000      -3.039      -2.107
game_entropy     1.5018      0.210      7.139      0.000       1.089       1.914
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=40252.00, p=4.46e-12
Paired t-test (game_entropy vs capabilities_entropy): statistic=-7.19, p=2.32e-12
Mean game_entropy-capabilities_entropy = -0.1617  [-0.2058, -0.1177] (n=500)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      497
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1224
Time:                        16:14:58   Log-Likelihood:                -228.97
converged:                       True   LL-Null:                       -260.90
Covariance Type:            nonrobust   LLR p-value:                 1.361e-14
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.8200      0.277    -10.179      0.000      -3.363      -2.277
capabilities_entropy     0.5187      0.252      2.058      0.040       0.025       1.013
game_entropy             1.1740      0.261      4.498      0.000       0.662       1.686
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.720000
                        1                 0.280000
Geography               0                 0.772727
                        1                 0.227273
Misc                    0                 0.783784
                        1                 0.216216
Music                   0                 0.825000
                        1                 0.175000
Other                   0                 0.865385
                        1                 0.134615
Politics                0                 0.688312
                        1                 0.311688
Science and technology  0                 0.857143
                        1                 0.142857
Sports                  0                 0.775000
                        1                 0.225000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.674556
                     1                 0.325444
Number               0                 0.730769
                     1                 0.269231
Other                0                 0.879699
                     1                 0.120301
Person               0                 0.866667
                     1                 0.133333
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.619048  0.380952           21
                       Number               0.777778  0.222222            9
                       Other                0.666667  0.333333           18
                       Person               0.814815  0.185185           27
Geography              Date                 0.533333  0.466667           15
                       Number               0.833333  0.166667           18
                       Other                1.000000  0.000000           11
Misc                   Date                 0.782609  0.217391           23
                       Number               0.555556  0.444444            9
                       Other                0.851852  0.148148           27
                       Person               0.800000  0.200000           15
Music                  Date                 0.583333  0.416667           12
                       Number               0.750000  0.250000            4
                       Other                1.000000  0.000000           12
                       Person               0.916667  0.083333           12
Other                  Date                 0.722222  0.277778           18
                       Number               0.857143  0.142857            7
                       Other                0.928571  0.071429           14
                       Person               1.000000  0.000000           13
Politics               Date                 0.583333  0.416667           36
                       Number               0.333333  0.666667            6
                       Other                0.900000  0.100000           20
                       Person               0.800000  0.200000           15
Science and technology Date                 0.771429  0.228571           35
                       Number               0.928571  0.071429           14
                       Other                0.947368  0.052632           19
                       Person               0.866667  0.133333           30
Sports                 Date                 0.777778  0.222222            9
                       Number               0.545455  0.454545           11
                       Other                0.833333  0.166667           12
                       Person               1.000000  0.000000            8

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      488
Method:                           MLE   Df Model:                           11
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.07399
Time:                        16:14:58   Log-Likelihood:                -241.59
converged:                       True   LL-Null:                       -260.90
Covariance Type:            nonrobust   LLR p-value:                 6.172e-05
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      0.7832      1.425      0.550      0.583      -2.010       3.576
C(topic_grouped)[T.Geography]                 -0.6487      0.468     -1.385      0.166      -1.567       0.269
C(topic_grouped)[T.Misc]                      -0.3910      0.398     -0.984      0.325      -1.170       0.388
C(topic_grouped)[T.Music]                     -0.6542      0.504     -1.297      0.195      -1.643       0.334
C(topic_grouped)[T.Other]                     -1.0738      0.495     -2.167      0.030      -2.045      -0.103
C(topic_grouped)[T.Politics]                   0.0252      0.379      0.066      0.947      -0.719       0.769
C(topic_grouped)[T.Science and technology]    -0.9991      0.400     -2.496      0.013      -1.784      -0.215
C(topic_grouped)[T.Sports]                    -0.3869      0.476     -0.812      0.417      -1.321       0.547
C(answer_type_grouped)[T.Number]              -0.2018      0.318     -0.635      0.526      -0.825       0.421
C(answer_type_grouped)[T.Other]               -1.3222      0.320     -4.132      0.000      -1.949      -0.695
C(answer_type_grouped)[T.Person]              -1.1982      0.326     -3.673      0.000      -1.838      -0.559
q_length                                      -0.2301      0.309     -0.745      0.456      -0.836       0.375
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.8728
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      487
Method:                           MLE   Df Model:                           12
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1261
Time:                        16:14:58   Log-Likelihood:                -228.01
converged:                       True   LL-Null:                       -260.90
Covariance Type:            nonrobust   LLR p-value:                 1.961e-09
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -0.9712      1.538     -0.631      0.528      -3.986       2.044
C(topic_grouped)[T.Geography]                 -0.6368      0.483     -1.319      0.187      -1.583       0.310
C(topic_grouped)[T.Misc]                      -0.4519      0.410     -1.103      0.270      -1.255       0.351
C(topic_grouped)[T.Music]                     -0.6510      0.522     -1.248      0.212      -1.673       0.371
C(topic_grouped)[T.Other]                     -1.0977      0.508     -2.162      0.031      -2.093      -0.102
C(topic_grouped)[T.Politics]                   0.0838      0.396      0.212      0.832      -0.692       0.860
C(topic_grouped)[T.Science and technology]    -1.0062      0.413     -2.438      0.015      -1.815      -0.197
C(topic_grouped)[T.Sports]                    -0.2721      0.497     -0.548      0.584      -1.245       0.701
C(answer_type_grouped)[T.Number]              -0.3194      0.328     -0.973      0.331      -0.963       0.324
C(answer_type_grouped)[T.Other]               -0.9480      0.334     -2.839      0.005      -1.602      -0.294
C(answer_type_grouped)[T.Person]              -0.6996      0.347     -2.017      0.044      -1.379      -0.020
q_length                                      -0.1197      0.325     -0.368      0.713      -0.757       0.518
capabilities_entropy                           1.0754      0.217      4.954      0.000       0.650       1.501
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      487
Method:                           MLE   Df Model:                           12
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1584
Time:                        16:14:58   Log-Likelihood:                -219.57
converged:                       True   LL-Null:                       -260.90
Covariance Type:            nonrobust   LLR p-value:                 1.281e-12
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -0.8862      1.535     -0.577      0.564      -3.894       2.122
C(topic_grouped)[T.Geography]                 -0.8170      0.501     -1.632      0.103      -1.798       0.164
C(topic_grouped)[T.Misc]                      -0.4652      0.416     -1.117      0.264      -1.281       0.351
C(topic_grouped)[T.Music]                     -0.7219      0.529     -1.365      0.172      -1.759       0.315
C(topic_grouped)[T.Other]                     -1.1687      0.521     -2.244      0.025      -2.190      -0.148
C(topic_grouped)[T.Politics]                   0.1078      0.407      0.265      0.791      -0.690       0.905
C(topic_grouped)[T.Science and technology]    -0.9626      0.421     -2.284      0.022      -1.788      -0.137
C(topic_grouped)[T.Sports]                    -0.3322      0.506     -0.656      0.512      -1.325       0.660
C(answer_type_grouped)[T.Number]              -0.3209      0.337     -0.953      0.340      -0.980       0.339
C(answer_type_grouped)[T.Other]               -0.9290      0.339     -2.742      0.006      -1.593      -0.265
C(answer_type_grouped)[T.Person]              -0.6242      0.348     -1.796      0.073      -1.305       0.057
q_length                                      -0.1707      0.329     -0.520      0.603      -0.815       0.473
game_entropy                                   1.4382      0.230      6.255      0.000       0.988       1.889
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      486
Method:                           MLE   Df Model:                           13
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1636
Time:                        16:14:58   Log-Likelihood:                -218.22
converged:                       True   LL-Null:                       -260.90
Covariance Type:            nonrobust   LLR p-value:                 1.067e-12
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.3131      1.571     -0.836      0.403      -4.393       1.767
C(topic_grouped)[T.Geography]                 -0.7861      0.500     -1.572      0.116      -1.766       0.194
C(topic_grouped)[T.Misc]                      -0.4784      0.418     -1.144      0.253      -1.298       0.341
C(topic_grouped)[T.Music]                     -0.7056      0.533     -1.325      0.185      -1.750       0.338
C(topic_grouped)[T.Other]                     -1.1633      0.522     -2.227      0.026      -2.187      -0.140
C(topic_grouped)[T.Politics]                   0.1104      0.409      0.270      0.787      -0.691       0.911
C(topic_grouped)[T.Science and technology]    -0.9733      0.423     -2.301      0.021      -1.802      -0.144
C(topic_grouped)[T.Sports]                    -0.2914      0.508     -0.573      0.566      -1.288       0.705
C(answer_type_grouped)[T.Number]              -0.3449      0.337     -1.024      0.306      -1.005       0.315
C(answer_type_grouped)[T.Other]               -0.8665      0.342     -2.536      0.011      -1.536      -0.197
C(answer_type_grouped)[T.Person]              -0.5300      0.354     -1.498      0.134      -1.223       0.163
q_length                                      -0.1324      0.332     -0.399      0.690      -0.783       0.518
capabilities_entropy                           0.4330      0.264      1.640      0.101      -0.085       0.950
game_entropy                                   1.1826      0.275      4.296      0.000       0.643       1.722
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing gpt-4o-mini (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_neutral/gpt-4o-mini_SimpleMC_neut_redacted_cor_temp1.0_1757986798_game_data.json', './sc_logs_neutral/gpt-4o-mini_SimpleMC_neut_redacted_temp1.0_1757985828_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    381
1    119
Name: count, dtype: int64

Answer change%: 0.2380 [0.2006724872008379, 0.27532751279916207] (n=500)
P-value vs 25%: 0.5286; P-value vs 0%: 7.78e-36
Phase 2 self-accuracy: 0.3529 [0.2670798375227415, 0.438802515418435] (n=119)
P-value vs 25%: 0.01878; P-value vs 33%: 0.649

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.01405
Time:                        16:14:58   Log-Likelihood:                -270.53
converged:                       True   LL-Null:                       -274.38
Covariance Type:            nonrobust   LLR p-value:                  0.005499
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          0.0601      0.444      0.135      0.892      -0.810       0.931
p_i_capability    -1.5288      0.548     -2.790      0.005      -2.603      -0.455
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.01874
Time:                        16:14:58   Log-Likelihood:                -269.24
converged:                       True   LL-Null:                       -274.38
Covariance Type:            nonrobust   LLR p-value:                  0.001342
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.5917      0.178     -8.930      0.000      -1.941      -1.242
capabilities_entropy     0.6094      0.191      3.188      0.001       0.235       0.984
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.3333 [0.2479, 0.4188] (n=117)
                  P-value vs 33.3%: 1

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=15.57, p=3.22e-41
Wilcoxon delta_p: statistic=7311.00, p=6.95e-30
Mean Δp = 0.3974  [0.3473, 0.4474]
Idea 1 N = 326; 

  Idea 1.5: Calibration Metrics
  NLL: 4.1020, Signed ECE (overconf pos under neg): -0.0470, ECE: 0.3182 (n=441)
  Brier: 0.3352, Reliability (absolute calibration error; lower better): 0.1295, Resolution (relative calibration quality; higher better): 0.0066, Uncertainty: 0.2106 (n=441)
  AUROC: 0.4829

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.180
Model:                            OLS   Adj. R-squared:                  0.174
Method:                 Least Squares   F-statistic:                     31.99
Date:                Wed, 24 Sep 2025   Prob (F-statistic):           1.04e-18
Time:                        16:14:58   Log-Likelihood:                -215.78
No. Observations:                 441   AIC:                             439.6
Df Residuals:                     437   BIC:                             455.9
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.3639      0.098     -3.706      0.000      -0.557      -0.171
p1                    0.9498      0.119      7.953      0.000       0.715       1.185
answer_changed        0.0517      0.181      0.286      0.775      -0.304       0.408
p1:answer_changed     0.0865      0.227      0.381      0.703      -0.359       0.532
==============================================================================
Omnibus:                     5789.074   Durbin-Watson:                   1.852
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               53.301
Skew:                          -0.445   Prob(JB):                     2.67e-12
Kurtosis:                       1.547   Cond. No.                         21.3
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=8.15, p=8.03e-15
Wilcoxon delta_H: statistic=13879.00, p=6.43e-14
Mean ΔH = 0.2650  [0.2013, 0.3288]
Paired t-test delta_H Changed: statistic=5.22, p=8.15e-07
Wilcoxon delta_H Changed: statistic=1685.00, p=4.13e-06
Mean ΔH Changed = 0.2611  [0.1630, 0.3591]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=4.10, p=4.91e-05
Wilcoxon (p_top2_game vs p_top2_base): statistic=35969.00, p=1.89e-06
Mean Δp_top2 = 0.0159  [0.0083, 0.0235] (n=441)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=9.66, p=3.73e-20
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=25163.00, p=1.36e-18
Mean ΔH_unchosen_baseline_set = 0.2640  [0.2105, 0.3176] (n=441)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  441
Model:                          Logit   Df Residuals:                      438
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                0.006130
Time:                        16:14:58   Log-Likelihood:                -251.52
converged:                       True   LL-Null:                       -253.07
Covariance Type:            nonrobust   LLR p-value:                    0.2120
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.0425      0.160     -6.503      0.000      -1.357      -0.728
p1_z            -0.1935      0.129     -1.505      0.132      -0.446       0.058
I(p1_z ** 2)    -0.0079      0.119     -0.067      0.947      -0.241       0.225
================================================================================
AUC = 0.557

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1294
Time:                        16:14:58   Log-Likelihood:                -238.88
converged:                       True   LL-Null:                       -274.38
Covariance Type:            nonrobust   LLR p-value:                 3.552e-17
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -2.3079      0.202    -11.425      0.000      -2.704      -1.912
game_entropy     1.7760      0.225      7.887      0.000       1.335       2.217
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=46054.00, p=2.78e-06
Paired t-test (game_entropy vs capabilities_entropy): statistic=-4.70, p=3.3e-06
Mean game_entropy-capabilities_entropy = -0.1213  [-0.1718, -0.0707] (n=500)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      497
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1294
Time:                        16:14:58   Log-Likelihood:                -238.86
converged:                       True   LL-Null:                       -274.38
Covariance Type:            nonrobust   LLR p-value:                 3.758e-16
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.2928      0.224    -10.222      0.000      -2.732      -1.853
capabilities_entropy    -0.0340      0.222     -0.153      0.878      -0.469       0.401
game_entropy             1.7899      0.243      7.365      0.000       1.314       2.266
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.813333
                        1                 0.186667
Geography               0                 0.659091
                        1                 0.340909
Misc                    0                 0.797297
                        1                 0.202703
Music                   0                 0.825000
                        1                 0.175000
Other                   0                 0.769231
                        1                 0.230769
Politics                0                 0.662338
                        1                 0.337662
Science and technology  0                 0.775510
                        1                 0.224490
Sports                  0                 0.800000
                        1                 0.200000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.686391
                     1                 0.313609
Number               0                 0.756410
                     1                 0.243590
Other                0                 0.819549
                     1                 0.180451
Person               0                 0.808333
                     1                 0.191667
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.714286  0.285714           21
                       Number               0.888889  0.111111            9
                       Other                0.833333  0.166667           18
                       Person               0.851852  0.148148           27
Geography              Date                 0.466667  0.533333           15
                       Number               0.666667  0.333333           18
                       Other                0.909091  0.090909           11
Misc                   Date                 0.652174  0.347826           23
                       Number               0.888889  0.111111            9
                       Other                0.925926  0.074074           27
                       Person               0.733333  0.266667           15
Music                  Date                 0.750000  0.250000           12
                       Number               1.000000  0.000000            4
                       Other                0.750000  0.250000           12
                       Person               0.916667  0.083333           12
Other                  Date                 0.722222  0.277778           18
                       Number               0.714286  0.285714            7
                       Other                0.785714  0.214286           14
                       Person               0.846154  0.153846           13
Politics               Date                 0.611111  0.388889           36
                       Number               0.500000  0.500000            6
                       Other                0.800000  0.200000           20
                       Person               0.666667  0.333333           15
Science and technology Date                 0.828571  0.171429           35
                       Number               0.785714  0.214286           14
                       Other                0.684211  0.315789           19
                       Person               0.766667  0.233333           30
Sports                 Date                 0.666667  0.333333            9
                       Number               0.727273  0.272727           11
                       Other                0.833333  0.166667           12
                       Person               1.000000  0.000000            8

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      488
Method:                           MLE   Df Model:                           11
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.03494
Time:                        16:14:58   Log-Likelihood:                -264.79
converged:                       True   LL-Null:                       -274.38
Covariance Type:            nonrobust   LLR p-value:                   0.05801
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -3.2540      1.344     -2.421      0.015      -5.889      -0.619
C(topic_grouped)[T.Geography]                  0.7862      0.455      1.730      0.084      -0.105       1.677
C(topic_grouped)[T.Misc]                       0.0950      0.420      0.226      0.821      -0.728       0.918
C(topic_grouped)[T.Music]                     -0.0556      0.516     -0.108      0.914      -1.066       0.955
C(topic_grouped)[T.Other]                      0.2517      0.448      0.562      0.574      -0.626       1.130
C(topic_grouped)[T.Politics]                   0.6132      0.394      1.555      0.120      -0.160       1.386
C(topic_grouped)[T.Science and technology]     0.1399      0.388      0.361      0.718      -0.620       0.900
C(topic_grouped)[T.Sports]                     0.1051      0.502      0.209      0.834      -0.879       1.089
C(answer_type_grouped)[T.Number]              -0.4004      0.327     -1.224      0.221      -1.042       0.241
C(answer_type_grouped)[T.Other]               -0.6609      0.285     -2.321      0.020      -1.219      -0.103
C(answer_type_grouped)[T.Person]              -0.4876      0.293     -1.663      0.096      -1.062       0.087
q_length                                       0.4777      0.287      1.663      0.096      -0.085       1.041
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.6545
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      487
Method:                           MLE   Df Model:                           12
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.04917
Time:                        16:14:58   Log-Likelihood:                -260.89
converged:                       True   LL-Null:                       -274.38
Covariance Type:            nonrobust   LLR p-value:                  0.007771
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -3.8956      1.376     -2.831      0.005      -6.593      -1.199
C(topic_grouped)[T.Geography]                  0.8098      0.459      1.763      0.078      -0.091       1.710
C(topic_grouped)[T.Misc]                       0.0592      0.424      0.140      0.889      -0.772       0.890
C(topic_grouped)[T.Music]                     -0.0680      0.519     -0.131      0.896      -1.085       0.949
C(topic_grouped)[T.Other]                      0.3056      0.452      0.675      0.499      -0.581       1.192
C(topic_grouped)[T.Politics]                   0.5524      0.398      1.388      0.165      -0.228       1.332
C(topic_grouped)[T.Science and technology]     0.1587      0.391      0.406      0.685      -0.607       0.924
C(topic_grouped)[T.Sports]                     0.1659      0.506      0.328      0.743      -0.825       1.157
C(answer_type_grouped)[T.Number]              -0.5115      0.334     -1.532      0.126      -1.166       0.143
C(answer_type_grouped)[T.Other]               -0.5565      0.289     -1.925      0.054      -1.123       0.010
C(answer_type_grouped)[T.Person]              -0.3984      0.297     -1.341      0.180      -0.980       0.184
q_length                                       0.5265      0.290      1.817      0.069      -0.041       1.094
capabilities_entropy                           0.5588      0.201      2.786      0.005       0.166       0.952
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      487
Method:                           MLE   Df Model:                           12
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1499
Time:                        16:14:58   Log-Likelihood:                -233.25
converged:                       True   LL-Null:                       -274.38
Covariance Type:            nonrobust   LLR p-value:                 1.519e-12
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -4.3081      1.435     -3.003      0.003      -7.120      -1.496
C(topic_grouped)[T.Geography]                  0.5384      0.494      1.090      0.276      -0.430       1.507
C(topic_grouped)[T.Misc]                       0.1601      0.453      0.354      0.724      -0.727       1.048
C(topic_grouped)[T.Music]                     -0.1144      0.562     -0.203      0.839      -1.216       0.987
C(topic_grouped)[T.Other]                      0.0874      0.484      0.181      0.857      -0.862       1.036
C(topic_grouped)[T.Politics]                   0.6717      0.425      1.581      0.114      -0.161       1.505
C(topic_grouped)[T.Science and technology]     0.1151      0.416      0.276      0.782      -0.701       0.931
C(topic_grouped)[T.Sports]                     0.1236      0.536      0.231      0.818      -0.927       1.174
C(answer_type_grouped)[T.Number]              -0.2918      0.349     -0.837      0.403      -0.975       0.391
C(answer_type_grouped)[T.Other]               -0.3600      0.310     -1.162      0.245      -0.967       0.247
C(answer_type_grouped)[T.Person]              -0.2413      0.318     -0.758      0.449      -0.865       0.383
q_length                                       0.4345      0.303      1.434      0.152      -0.159       1.028
game_entropy                                   1.7450      0.233      7.502      0.000       1.289       2.201
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      486
Method:                           MLE   Df Model:                           13
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1500
Time:                        16:14:58   Log-Likelihood:                -233.21
converged:                       True   LL-Null:                       -274.38
Covariance Type:            nonrobust   LLR p-value:                 4.004e-12
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -4.2548      1.450     -2.934      0.003      -7.097      -1.413
C(topic_grouped)[T.Geography]                  0.5312      0.495      1.073      0.283      -0.439       1.501
C(topic_grouped)[T.Misc]                       0.1637      0.453      0.361      0.718      -0.724       1.052
C(topic_grouped)[T.Music]                     -0.1128      0.562     -0.201      0.841      -1.215       0.989
C(topic_grouped)[T.Other]                      0.0763      0.486      0.157      0.875      -0.877       1.029
C(topic_grouped)[T.Politics]                   0.6772      0.426      1.591      0.112      -0.157       1.512
C(topic_grouped)[T.Science and technology]     0.1121      0.417      0.269      0.788      -0.704       0.929
C(topic_grouped)[T.Sports]                     0.1158      0.537      0.216      0.829      -0.937       1.168
C(answer_type_grouped)[T.Number]              -0.2786      0.352     -0.790      0.429      -0.969       0.412
C(answer_type_grouped)[T.Other]               -0.3636      0.310     -1.173      0.241      -0.971       0.244
C(answer_type_grouped)[T.Person]              -0.2448      0.319     -0.768      0.443      -0.870       0.380
q_length                                       0.4287      0.304      1.411      0.158      -0.167       1.024
capabilities_entropy                          -0.0580      0.231     -0.251      0.802      -0.510       0.394
game_entropy                                   1.7686      0.251      7.040      0.000       1.276       2.261
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing grok-3-latest (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_neutral/grok-3-latest_SimpleMC_redacted_cor_temp0.0_1751833664_game_data.json', './sc_logs_neutral/grok-3-latest_SimpleMC_redacted_temp0.0_1751826103_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    411
1     89
Name: count, dtype: int64

Answer change%: 0.1780 [0.1444718957049856, 0.2115281042950144] (n=500)
P-value vs 25%: 2.566e-05; P-value vs 0%: 2.343e-25
Phase 2 self-accuracy: 0.4270 [0.32420253657802284, 0.5297300476916401] (n=89)
P-value vs 25%: 0.0007376; P-value vs 33%: 0.07311

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.2074
Time:                        16:14:58   Log-Likelihood:                -185.61
converged:                       True   LL-Null:                       -234.17
Covariance Type:            nonrobust   LLR p-value:                 6.514e-23
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          3.7402      0.585      6.398      0.000       2.594       4.886
p_i_capability    -6.3800      0.720     -8.863      0.000      -7.791      -4.969
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.2575
Time:                        16:14:58   Log-Likelihood:                -173.88
converged:                       True   LL-Null:                       -234.17
Covariance Type:            nonrobust   LLR p-value:                 4.698e-28
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -3.2294      0.261    -12.350      0.000      -3.742      -2.717
capabilities_entropy     2.8359      0.299      9.472      0.000       2.249       3.423
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.7079 [0.6134, 0.8023] (n=89)
                  P-value vs 33.3%: 7.853e-15

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=-4.06, p=5.79e-05
Wilcoxon delta_p: statistic=23285.00, p=1.04e-14
Mean Δp = -0.0257  [-0.0381, -0.0133]
Idea 1 N = 408; 

  Idea 1.5: Calibration Metrics
  NLL: 2.1840, Signed ECE (overconf pos under neg): -0.0143, ECE: 0.0634 (n=497)
  Brier: 0.0232, Reliability (absolute calibration error; lower better): 0.0147, Resolution (relative calibration quality; higher better): 0.2341, Uncertainty: 0.2423 (n=497)
  AUROC: 0.9996

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.809
Model:                            OLS   Adj. R-squared:                  0.807
Method:                 Least Squares   F-statistic:                     693.9
Date:                Wed, 24 Sep 2025   Prob (F-statistic):          1.76e-176
Time:                        16:14:58   Log-Likelihood:                 355.83
No. Observations:                 497   AIC:                            -703.7
Df Residuals:                     493   BIC:                            -686.8
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.5624      0.043    -13.163      0.000      -0.646      -0.478
p1                    0.5828      0.046     12.682      0.000       0.492       0.673
answer_changed        0.3148      0.068      4.620      0.000       0.181       0.449
p1:answer_changed     0.5521      0.087      6.345      0.000       0.381       0.723
==============================================================================
Omnibus:                      106.513   Durbin-Watson:                   2.160
Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1248.031
Skew:                           0.540   Prob(JB):                    9.85e-272
Kurtosis:                      10.688   Cond. No.                         29.7
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-3.59, p=0.000368
Wilcoxon delta_H: statistic=33156.00, p=0.000328
Mean ΔH = -0.0920  [-0.1422, -0.0418]
Paired t-test delta_H Changed: statistic=4.75, p=7.74e-06
Wilcoxon delta_H Changed: statistic=851.00, p=2.46e-06
Mean ΔH Changed = 0.2212  [0.1300, 0.3125]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=4.81, p=2.01e-06
Wilcoxon (p_top2_game vs p_top2_base): statistic=36812.00, p=5.09e-15
Mean Δp_top2 = 0.0101  [0.0060, 0.0142] (n=497)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=-1.55, p=0.123
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=57319.00, p=0.155
Mean ΔH_unchosen_baseline_set = -0.0359  [-0.0814, 0.0096] (n=497)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  497
Model:                          Logit   Df Residuals:                      494
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.2835
Time:                        16:14:58   Log-Likelihood:                -167.37
converged:                       True   LL-Null:                       -233.58
Covariance Type:            nonrobust   LLR p-value:                 1.745e-29
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.7223      0.178     -9.665      0.000      -2.072      -1.373
p1_z            -1.9223      0.256     -7.515      0.000      -2.424      -1.421
I(p1_z ** 2)    -0.4160      0.125     -3.319      0.001      -0.662      -0.170
================================================================================
AUC = 0.867

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1982
Time:                        16:14:58   Log-Likelihood:                -187.75
converged:                       True   LL-Null:                       -234.17
Covariance Type:            nonrobust   LLR p-value:                 5.648e-22
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -2.6023      0.199    -13.083      0.000      -2.992      -2.212
game_entropy     2.6417      0.296      8.937      0.000       2.062       3.221
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=32740.00, p=2.34e-20
Paired t-test (game_entropy vs capabilities_entropy): statistic=-7.81, p=3.33e-14
Mean game_entropy-capabilities_entropy = -0.1356  [-0.1696, -0.1016] (n=500)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      497
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.2974
Time:                        16:14:58   Log-Likelihood:                -164.52
converged:                       True   LL-Null:                       -234.17
Covariance Type:            nonrobust   LLR p-value:                 5.625e-31
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -3.4713      0.283    -12.256      0.000      -4.026      -2.916
capabilities_entropy     2.1985      0.336      6.543      0.000       1.540       2.857
game_entropy             1.4837      0.346      4.288      0.000       0.806       2.162
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.866667
                        1                 0.133333
Geography               0                 0.818182
                        1                 0.181818
Misc                    0                 0.837838
                        1                 0.162162
Music                   0                 0.875000
                        1                 0.125000
Other                   0                 0.826923
                        1                 0.173077
Politics                0                 0.844156
                        1                 0.155844
Science and technology  0                 0.755102
                        1                 0.244898
Sports                  0                 0.775000
                        1                 0.225000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.846154
                     1                 0.153846
Number               0                 0.794872
                     1                 0.205128
Other                0                 0.834586
                     1                 0.165414
Person               0                 0.791667
                     1                 0.208333
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.904762  0.095238           21
                       Number               0.888889  0.111111            9
                       Other                0.944444  0.055556           18
                       Person               0.777778  0.222222           27
Geography              Date                 0.933333  0.066667           15
                       Number               0.833333  0.166667           18
                       Other                0.636364  0.363636           11
Misc                   Date                 0.956522  0.043478           23
                       Number               0.888889  0.111111            9
                       Other                0.777778  0.222222           27
                       Person               0.733333  0.266667           15
Music                  Date                 0.916667  0.083333           12
                       Number               1.000000  0.000000            4
                       Other                0.833333  0.166667           12
                       Person               0.833333  0.166667           12
Other                  Date                 0.777778  0.222222           18
                       Number               0.714286  0.285714            7
                       Other                0.928571  0.071429           14
                       Person               0.846154  0.153846           13
Politics               Date                 0.833333  0.166667           36
                       Number               1.000000  0.000000            6
                       Other                0.800000  0.200000           20
                       Person               0.866667  0.133333           15
Science and technology Date                 0.742857  0.257143           35
                       Number               0.500000  0.500000           14
                       Other                0.947368  0.052632           19
                       Person               0.766667  0.233333           30
Sports                 Date                 0.777778  0.222222            9
                       Number               0.818182  0.181818           11
                       Other                0.750000  0.250000           12
                       Person               0.750000  0.250000            8

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      488
Method:                           MLE   Df Model:                           11
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.01779
Time:                        16:14:58   Log-Likelihood:                -230.01
converged:                       True   LL-Null:                       -234.17
Covariance Type:            nonrobust   LLR p-value:                    0.6831
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -3.4099      1.468     -2.323      0.020      -6.286      -0.533
C(topic_grouped)[T.Geography]                  0.4463      0.538      0.829      0.407      -0.608       1.501
C(topic_grouped)[T.Misc]                       0.2752      0.468      0.588      0.556      -0.642       1.192
C(topic_grouped)[T.Music]                     -0.0336      0.588     -0.057      0.954      -1.187       1.120
C(topic_grouped)[T.Other]                      0.3559      0.502      0.708      0.479      -0.629       1.341
C(topic_grouped)[T.Politics]                   0.1997      0.473      0.423      0.673      -0.727       1.126
C(topic_grouped)[T.Science and technology]     0.7463      0.416      1.795      0.073      -0.069       1.561
C(topic_grouped)[T.Sports]                     0.6497      0.515      1.261      0.207      -0.360       1.660
C(answer_type_grouped)[T.Number]               0.2840      0.365      0.777      0.437      -0.432       1.000
C(answer_type_grouped)[T.Other]                0.1333      0.321      0.415      0.678      -0.496       0.762
C(answer_type_grouped)[T.Person]               0.4187      0.319      1.313      0.189      -0.206       1.044
q_length                                       0.2924      0.311      0.939      0.348      -0.318       0.903
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.4188
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      487
Method:                           MLE   Df Model:                           12
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.2742
Time:                        16:14:58   Log-Likelihood:                -169.96
converged:                       True   LL-Null:                       -234.17
Covariance Type:            nonrobust   LLR p-value:                 1.278e-21
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -4.9877      1.716     -2.906      0.004      -8.351      -1.624
C(topic_grouped)[T.Geography]                  0.7558      0.632      1.196      0.232      -0.483       1.994
C(topic_grouped)[T.Misc]                       0.1037      0.550      0.188      0.851      -0.975       1.183
C(topic_grouped)[T.Music]                      0.0724      0.690      0.105      0.916      -1.281       1.426
C(topic_grouped)[T.Other]                      0.1457      0.594      0.245      0.806      -1.019       1.311
C(topic_grouped)[T.Politics]                   0.6810      0.555      1.227      0.220      -0.407       1.769
C(topic_grouped)[T.Science and technology]     0.7081      0.493      1.435      0.151      -0.259       1.675
C(topic_grouped)[T.Sports]                     0.7678      0.615      1.249      0.212      -0.437       1.973
C(answer_type_grouped)[T.Number]               0.3036      0.426      0.713      0.476      -0.531       1.138
C(answer_type_grouped)[T.Other]                0.1520      0.382      0.398      0.690      -0.596       0.900
C(answer_type_grouped)[T.Person]               0.5295      0.383      1.383      0.167      -0.221       1.280
q_length                                       0.2347      0.359      0.654      0.513      -0.469       0.938
capabilities_entropy                           2.8978      0.309      9.375      0.000       2.292       3.504
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      487
Method:                           MLE   Df Model:                           12
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.2132
Time:                        16:14:58   Log-Likelihood:                -184.25
converged:                       True   LL-Null:                       -234.17
Covariance Type:            nonrobust   LLR p-value:                 5.967e-16
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -3.4858      1.621     -2.150      0.032      -6.663      -0.308
C(topic_grouped)[T.Geography]                  0.0391      0.588      0.067      0.947      -1.113       1.192
C(topic_grouped)[T.Misc]                      -0.1230      0.533     -0.231      0.818      -1.168       0.922
C(topic_grouped)[T.Music]                     -0.0718      0.647     -0.111      0.912      -1.341       1.197
C(topic_grouped)[T.Other]                      0.0429      0.561      0.076      0.939      -1.057       1.143
C(topic_grouped)[T.Politics]                   0.1465      0.527      0.278      0.781      -0.887       1.180
C(topic_grouped)[T.Science and technology]     0.4597      0.465      0.988      0.323      -0.452       1.372
C(topic_grouped)[T.Sports]                     0.5130      0.571      0.898      0.369      -0.607       1.633
C(answer_type_grouped)[T.Number]               0.5717      0.414      1.380      0.168      -0.241       1.384
C(answer_type_grouped)[T.Other]                0.3209      0.371      0.865      0.387      -0.406       1.048
C(answer_type_grouped)[T.Person]               0.5985      0.371      1.614      0.107      -0.128       1.325
q_length                                       0.0821      0.344      0.239      0.811      -0.591       0.756
game_entropy                                   2.6906      0.305      8.824      0.000       2.093       3.288
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      486
Method:                           MLE   Df Model:                           13
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.3125
Time:                        16:14:58   Log-Likelihood:                -160.99
converged:                       True   LL-Null:                       -234.17
Covariance Type:            nonrobust   LLR p-value:                 1.109e-24
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -4.7406      1.768     -2.681      0.007      -8.207      -1.274
C(topic_grouped)[T.Geography]                  0.5637      0.637      0.885      0.376      -0.685       1.812
C(topic_grouped)[T.Misc]                       0.0287      0.561      0.051      0.959      -1.071       1.128
C(topic_grouped)[T.Music]                      0.0370      0.720      0.051      0.959      -1.375       1.449
C(topic_grouped)[T.Other]                     -0.0009      0.607     -0.002      0.999      -1.190       1.189
C(topic_grouped)[T.Politics]                   0.5303      0.571      0.929      0.353      -0.588       1.649
C(topic_grouped)[T.Science and technology]     0.5852      0.501      1.169      0.242      -0.396       1.566
C(topic_grouped)[T.Sports]                     0.6523      0.627      1.040      0.298      -0.577       1.882
C(answer_type_grouped)[T.Number]               0.4849      0.439      1.105      0.269      -0.375       1.345
C(answer_type_grouped)[T.Other]                0.2687      0.402      0.669      0.503      -0.518       1.056
C(answer_type_grouped)[T.Person]               0.6354      0.397      1.600      0.110      -0.143       1.414
q_length                                       0.1315      0.370      0.356      0.722      -0.593       0.856
capabilities_entropy                           2.2468      0.346      6.486      0.000       1.568       2.926
game_entropy                                   1.4772      0.353      4.189      0.000       0.786       2.168
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing qwen3-235b-a22b-2507 (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_neutral/qwen3-235b-a22b-2507_SimpleMC_neut_redacted_cor_temp0.0_1756222018_game_data.json', './sc_logs_neutral/qwen3-235b-a22b-2507_SimpleMC_neut_redacted_temp0.0_1756220809_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    385
1    115
Name: count, dtype: int64

Answer change%: 0.2300 [0.19311308207114805, 0.266886917928852] (n=500)
P-value vs 25%: 0.2879; P-value vs 0%: 2.404e-34
Phase 2 self-accuracy: 0.2696 [0.18846503695827804, 0.35066539782433065] (n=115)
P-value vs 25%: 0.6363; P-value vs 33%: 0.1253

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.09886
Time:                        16:14:58   Log-Likelihood:                -242.98
converged:                       True   LL-Null:                       -269.64
Covariance Type:            nonrobust   LLR p-value:                 2.843e-13
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          2.1030      0.463      4.544      0.000       1.196       3.010
p_i_capability    -3.9633      0.555     -7.147      0.000      -5.050      -2.876
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.08317
Time:                        16:14:58   Log-Likelihood:                -247.21
converged:                       True   LL-Null:                       -269.64
Covariance Type:            nonrobust   LLR p-value:                 2.128e-11
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.8900      0.164    -11.528      0.000      -2.211      -1.569
capabilities_entropy     1.2149      0.185      6.574      0.000       0.853       1.577
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.7304 [0.6493, 0.8115] (n=115)
                  P-value vs 33.3%: 8.244e-22

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=4.51, p=9.03e-06
Wilcoxon delta_p: statistic=18075.00, p=1.81e-05
Mean Δp = 0.0562  [0.0318, 0.0807]
Idea 1 N = 317; 

  Idea 1.5: Calibration Metrics
  NLL: 4.1093, Signed ECE (overconf pos under neg): -0.0364, ECE: 0.0827 (n=420)
  Brier: 0.0365, Reliability (absolute calibration error; lower better): 0.0224, Resolution (relative calibration quality; higher better): 0.2225, Uncertainty: 0.2364 (n=420)
  AUROC: 0.9970

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.541
Model:                            OLS   Adj. R-squared:                  0.538
Method:                 Least Squares   F-statistic:                     164.9
Date:                Wed, 24 Sep 2025   Prob (F-statistic):           1.41e-70
Time:                        16:14:58   Log-Likelihood:                 52.400
No. Observations:                 423   AIC:                            -96.80
Df Residuals:                     419   BIC:                            -80.61
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.3479      0.071     -4.891      0.000      -0.488      -0.208
p1                    0.4477      0.078      5.765      0.000       0.295       0.600
answer_changed        0.1763      0.102      1.736      0.083      -0.023       0.376
p1:answer_changed     0.4698      0.121      3.885      0.000       0.232       0.707
==============================================================================
Omnibus:                       99.522   Durbin-Watson:                   1.977
Prob(Omnibus):                  0.000   Jarque-Bera (JB):              285.492
Skew:                           1.102   Prob(JB):                     1.01e-62
Kurtosis:                       6.367   Cond. No.                         22.9
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-7.40, p=1.22e-12
Wilcoxon delta_H: statistic=13849.00, p=5.71e-12
Mean ΔH = -0.2799  [-0.3540, -0.2058]
Paired t-test delta_H Changed: statistic=2.92, p=0.00432
Wilcoxon delta_H Changed: statistic=2132.00, p=0.0129
Mean ΔH Changed = 0.1723  [0.0565, 0.2880]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=-1.60, p=0.11
Wilcoxon (p_top2_game vs p_top2_base): statistic=36750.00, p=0.00101
Mean Δp_top2 = -0.0066  [-0.0146, 0.0015] (n=425)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=-4.95, p=1.06e-06
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=32917.00, p=1.54e-06
Mean ΔH_unchosen_baseline_set = -0.1650  [-0.2303, -0.0997] (n=425)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  425
Model:                          Logit   Df Residuals:                      422
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1073
Time:                        16:14:58   Log-Likelihood:                -215.04
converged:                       True   LL-Null:                       -240.90
Covariance Type:            nonrobust   LLR p-value:                 5.893e-12
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.2912      0.181     -7.153      0.000      -1.645      -0.937
p1_z            -0.6447      0.204     -3.155      0.002      -1.045      -0.244
I(p1_z ** 2)     0.1022      0.144      0.710      0.478      -0.180       0.384
================================================================================
AUC = 0.713

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1018
Time:                        16:14:58   Log-Likelihood:                -242.19
converged:                       True   LL-Null:                       -269.64
Covariance Type:            nonrobust   LLR p-value:                 1.274e-13
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -2.0479      0.177    -11.573      0.000      -2.395      -1.701
game_entropy     1.4168      0.198      7.152      0.000       1.029       1.805
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=56060.00, p=0.585
Paired t-test (game_entropy vs capabilities_entropy): statistic=0.81, p=0.417
Mean game_entropy-capabilities_entropy = 0.0233  [-0.0330, 0.0796] (n=500)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      497
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1422
Time:                        16:14:58   Log-Likelihood:                -231.29
converged:                       True   LL-Null:                       -269.64
Covariance Type:            nonrobust   LLR p-value:                 2.207e-17
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.4157      0.206    -11.718      0.000      -2.820      -2.012
capabilities_entropy     0.9136      0.196      4.659      0.000       0.529       1.298
game_entropy             1.1668      0.209      5.593      0.000       0.758       1.576
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.826667
                        1                 0.173333
Geography               0                 0.704545
                        1                 0.295455
Misc                    0                 0.702703
                        1                 0.297297
Music                   0                 0.725000
                        1                 0.275000
Other                   0                 0.846154
                        1                 0.153846
Politics                0                 0.740260
                        1                 0.259740
Science and technology  0                 0.785714
                        1                 0.214286
Sports                  0                 0.825000
                        1                 0.175000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.698225
                     1                 0.301775
Number               0                 0.705128
                     1                 0.294872
Other                0                 0.834586
                     1                 0.165414
Person               0                 0.841667
                     1                 0.158333
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.666667  0.333333           21
                       Number               0.666667  0.333333            9
                       Other                0.888889  0.111111           18
                       Person               0.962963  0.037037           27
Geography              Date                 0.533333  0.466667           15
                       Number               0.722222  0.277778           18
                       Other                0.909091  0.090909           11
Misc                   Date                 0.652174  0.347826           23
                       Number               0.777778  0.222222            9
                       Other                0.703704  0.296296           27
                       Person               0.733333  0.266667           15
Music                  Date                 0.666667  0.333333           12
                       Number               0.000000  1.000000            4
                       Other                0.833333  0.166667           12
                       Person               0.916667  0.083333           12
Other                  Date                 0.666667  0.333333           18
                       Number               1.000000  0.000000            7
                       Other                0.857143  0.142857           14
                       Person               1.000000  0.000000           13
Politics               Date                 0.722222  0.277778           36
                       Number               0.666667  0.333333            6
                       Other                0.850000  0.150000           20
                       Person               0.666667  0.333333           15
Science and technology Date                 0.771429  0.228571           35
                       Number               0.642857  0.357143           14
                       Other                0.842105  0.157895           19
                       Person               0.833333  0.166667           30
Sports                 Date                 0.888889  0.111111            9
                       Number               0.818182  0.181818           11
                       Other                0.916667  0.083333           12
                       Person               0.625000  0.375000            8

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      488
Method:                           MLE   Df Model:                           11
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.03851
Time:                        16:14:58   Log-Likelihood:                -259.25
converged:                       True   LL-Null:                       -269.64
Covariance Type:            nonrobust   LLR p-value:                   0.03585
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.4288      1.365     -1.047      0.295      -4.103       1.246
C(topic_grouped)[T.Geography]                  0.4481      0.467      0.959      0.338      -0.468       1.364
C(topic_grouped)[T.Misc]                       0.6965      0.405      1.721      0.085      -0.097       1.490
C(topic_grouped)[T.Music]                      0.6133      0.475      1.292      0.196      -0.317       1.543
C(topic_grouped)[T.Other]                     -0.2075      0.497     -0.418      0.676      -1.181       0.766
C(topic_grouped)[T.Politics]                   0.3969      0.415      0.957      0.338      -0.416       1.209
C(topic_grouped)[T.Science and technology]     0.1821      0.398      0.457      0.647      -0.598       0.962
C(topic_grouped)[T.Sports]                    -0.0671      0.526     -0.128      0.898      -1.097       0.963
C(answer_type_grouped)[T.Number]              -0.0105      0.312     -0.034      0.973      -0.622       0.601
C(answer_type_grouped)[T.Other]               -0.8071      0.293     -2.758      0.006      -1.381      -0.234
C(answer_type_grouped)[T.Person]              -0.7794      0.309     -2.524      0.012      -1.385      -0.174
q_length                                       0.0655      0.293      0.223      0.823      -0.509       0.640
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.4631
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      487
Method:                           MLE   Df Model:                           12
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1141
Time:                        16:14:58   Log-Likelihood:                -238.89
converged:                       True   LL-Null:                       -269.64
Covariance Type:            nonrobust   LLR p-value:                 1.198e-08
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -3.4381      1.477     -2.327      0.020      -6.334      -0.542
C(topic_grouped)[T.Geography]                  0.2019      0.497      0.406      0.685      -0.772       1.176
C(topic_grouped)[T.Misc]                       0.5759      0.425      1.356      0.175      -0.257       1.408
C(topic_grouped)[T.Music]                      0.7697      0.503      1.532      0.126      -0.215       1.755
C(topic_grouped)[T.Other]                     -0.2246      0.515     -0.436      0.663      -1.235       0.786
C(topic_grouped)[T.Politics]                   0.2406      0.432      0.557      0.577      -0.605       1.087
C(topic_grouped)[T.Science and technology]    -0.0372      0.418     -0.089      0.929      -0.856       0.782
C(topic_grouped)[T.Sports]                    -0.0550      0.543     -0.101      0.919      -1.118       1.008
C(answer_type_grouped)[T.Number]              -0.1161      0.333     -0.349      0.727      -0.769       0.536
C(answer_type_grouped)[T.Other]               -0.6893      0.307     -2.244      0.025      -1.291      -0.087
C(answer_type_grouped)[T.Person]              -0.6681      0.321     -2.083      0.037      -1.297      -0.039
q_length                                       0.3717      0.313      1.189      0.234      -0.241       0.984
capabilities_entropy                           1.2222      0.196      6.238      0.000       0.838       1.606
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      487
Method:                           MLE   Df Model:                           12
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1201
Time:                        16:14:58   Log-Likelihood:                -237.25
converged:                       True   LL-Null:                       -269.64
Covariance Type:            nonrobust   LLR p-value:                 3.007e-09
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.6203      1.434     -1.130      0.259      -4.431       1.191
C(topic_grouped)[T.Geography]                  0.3876      0.494      0.784      0.433      -0.581       1.357
C(topic_grouped)[T.Misc]                       0.7649      0.427      1.790      0.074      -0.073       1.603
C(topic_grouped)[T.Music]                      0.4026      0.503      0.800      0.424      -0.584       1.389
C(topic_grouped)[T.Other]                     -0.2119      0.516     -0.411      0.681      -1.223       0.799
C(topic_grouped)[T.Politics]                   0.1347      0.440      0.306      0.760      -0.728       0.998
C(topic_grouped)[T.Science and technology]     0.0369      0.420      0.088      0.930      -0.786       0.860
C(topic_grouped)[T.Sports]                    -0.1610      0.554     -0.291      0.771      -1.247       0.925
C(answer_type_grouped)[T.Number]              -0.1831      0.336     -0.545      0.585      -0.841       0.475
C(answer_type_grouped)[T.Other]               -0.4755      0.310     -1.536      0.125      -1.082       0.131
C(answer_type_grouped)[T.Person]              -0.3532      0.329     -1.074      0.283      -0.998       0.291
q_length                                      -0.0821      0.310     -0.265      0.791      -0.689       0.525
game_entropy                                   1.3683      0.213      6.411      0.000       0.950       1.787
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      486
Method:                           MLE   Df Model:                           13
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1598
Time:                        16:14:58   Log-Likelihood:                -226.56
converged:                       True   LL-Null:                       -269.64
Covariance Type:            nonrobust   LLR p-value:                 7.533e-13
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -3.1667      1.515     -2.090      0.037      -6.136      -0.198
C(topic_grouped)[T.Geography]                  0.2026      0.509      0.398      0.691      -0.796       1.201
C(topic_grouped)[T.Misc]                       0.6422      0.438      1.466      0.143      -0.217       1.501
C(topic_grouped)[T.Music]                      0.5474      0.522      1.048      0.295      -0.476       1.571
C(topic_grouped)[T.Other]                     -0.2814      0.531     -0.530      0.596      -1.322       0.759
C(topic_grouped)[T.Politics]                   0.0431      0.449      0.096      0.923      -0.838       0.924
C(topic_grouped)[T.Science and technology]    -0.1103      0.430     -0.257      0.797      -0.952       0.732
C(topic_grouped)[T.Sports]                    -0.1478      0.560     -0.264      0.792      -1.245       0.949
C(answer_type_grouped)[T.Number]              -0.2197      0.344     -0.639      0.523      -0.893       0.454
C(answer_type_grouped)[T.Other]               -0.4825      0.319     -1.512      0.130      -1.108       0.143
C(answer_type_grouped)[T.Person]              -0.3607      0.337     -1.069      0.285      -1.022       0.301
q_length                                       0.1958      0.324      0.605      0.545      -0.439       0.831
capabilities_entropy                           0.9444      0.206      4.590      0.000       0.541       1.348
game_entropy                                   1.0938      0.223      4.894      0.000       0.656       1.532
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.
