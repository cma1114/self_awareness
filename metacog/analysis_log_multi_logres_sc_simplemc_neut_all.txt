
--- Analyzing claude-3-5-sonnet-20241022 (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_neutral/claude-3-5-sonnet-20241022_SimpleMC_redacted_cor_temp0.0_1754440066_game_data.json', './sc_logs_neutral/claude-3-5-sonnet-20241022_SimpleMC_redacted_temp0.0_1754435021_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    393
1    107
Name: count, dtype: int64

Answer change%: 0.2140 [0.1780514606840268, 0.2499485393159732] (n=500)
P-value vs 25%: 0.04967; P-value vs 0%: 1.867e-31
Phase 2 self-accuracy: 0.3551 [0.2644649355534616, 0.44581543827831405] (n=107)
P-value vs 25%: 0.02305; P-value vs 33%: 0.6322

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.2128
Time:                        12:35:50   Log-Likelihood:                -204.36
converged:                       True   LL-Null:                       -259.60
Covariance Type:            nonrobust   LLR p-value:                 7.689e-26
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          2.5250      0.404      6.253      0.000       1.734       3.316
p_i_capability    -5.9532      0.664     -8.963      0.000      -7.255      -4.651
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.2143
Time:                        12:35:50   Log-Likelihood:                -203.98
converged:                       True   LL-Null:                       -259.60
Covariance Type:            nonrobust   LLR p-value:                 5.206e-26
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -4.2352      0.408    -10.390      0.000      -5.034      -3.436
capabilities_entropy     2.3682      0.274      8.648      0.000       1.832       2.905
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.6636 [0.5740, 0.7531] (n=107)
                  P-value vs 33.3%: 4.855e-13

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=-0.36, p=0.716
Wilcoxon delta_p: statistic=23303.00, p=0.985
Mean Δp = -0.0028  [-0.0177, 0.0121]
Idea 1 N = 393; 

  Idea 1.5: Calibration Metrics
  NLL: 1.0679, Signed ECE (overconf pos under neg): -0.0626, ECE: 0.1490 (n=500)
  Brier: 0.0648, Reliability (absolute calibration error; lower better): 0.0387, Resolution (relative calibration quality; higher better): 0.2126, Uncertainty: 0.2400 (n=500)
  AUROC: 0.9968

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.564
Model:                            OLS   Adj. R-squared:                  0.561
Method:                 Least Squares   F-statistic:                     213.9
Date:                Sat, 09 Aug 2025   Prob (F-statistic):           5.29e-89
Time:                        12:35:50   Log-Likelihood:                 301.57
No. Observations:                 500   AIC:                            -595.1
Df Residuals:                     496   BIC:                            -578.3
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.2418      0.027     -9.109      0.000      -0.294      -0.190
p1                    0.3109      0.033      9.307      0.000       0.245       0.377
answer_changed        0.0366      0.051      0.718      0.473      -0.064       0.137
p1:answer_changed     0.6336      0.086      7.372      0.000       0.465       0.802
==============================================================================
Omnibus:                       13.191   Durbin-Watson:                   1.949
Prob(Omnibus):                  0.001   Jarque-Bera (JB):               14.383
Skew:                           0.332   Prob(JB):                     0.000753
Kurtosis:                       3.499   Cond. No.                         21.4
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=1.01, p=0.314
Wilcoxon delta_H: statistic=22273.00, p=0.38
Mean ΔH = 0.0194  [-0.0183, 0.0570]
Paired t-test delta_H Changed: statistic=9.24, p=2.84e-15
Wilcoxon delta_H Changed: statistic=471.00, p=5.68e-14
Mean ΔH Changed = 0.3299  [0.2599, 0.3998]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=2.50, p=0.0128
Wilcoxon (p_top2_game vs p_top2_base): statistic=37509.00, p=0.031
Mean Δp_top2 = 0.0096  [0.0021, 0.0171] (n=500)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=4.81, p=1.99e-06
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=31186.00, p=1.36e-06
Mean ΔH_unchosen_baseline_set = 0.0858  [0.0509, 0.1208] (n=500)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      497
Method:                           MLE   Df Model:                            2
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.2185
Time:                        12:35:50   Log-Likelihood:                -202.87
converged:                       True   LL-Null:                       -259.60
Covariance Type:            nonrobust   LLR p-value:                 2.293e-25
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.5677      0.186     -8.437      0.000      -1.932      -1.204
p1_z            -1.5166      0.210     -7.230      0.000      -1.928      -1.105
I(p1_z ** 2)    -0.2863      0.168     -1.708      0.088      -0.615       0.042
================================================================================
AUC = 0.815

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1564
Time:                        12:35:50   Log-Likelihood:                -219.01
converged:                       True   LL-Null:                       -259.60
Covariance Type:            nonrobust   LLR p-value:                 2.044e-19
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -3.5822      0.347    -10.318      0.000      -4.263      -2.902
game_entropy     1.9598      0.248      7.899      0.000       1.474       2.446
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=39042.00, p=0.108
Paired t-test (game_entropy vs capabilities_entropy): statistic=-1.79, p=0.0748
Mean capabilities_entropy-game_entropy = 0.0305  [-0.0030, 0.0640] (n=500)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      497
Method:                           MLE   Df Model:                            2
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.2203
Time:                        12:35:50   Log-Likelihood:                -202.42
converged:                       True   LL-Null:                       -259.60
Covariance Type:            nonrobust   LLR p-value:                 1.468e-25
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -4.4190      0.429    -10.306      0.000      -5.259      -3.579
capabilities_entropy     1.9609      0.357      5.498      0.000       1.262       2.660
game_entropy             0.5840      0.335      1.745      0.081      -0.072       1.240
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.760000
                        1                 0.240000
Geography               0                 0.704545
                        1                 0.295455
Misc                    0                 0.851351
                        1                 0.148649
Music                   0                 0.800000
                        1                 0.200000
Other                   0                 0.769231
                        1                 0.230769
Politics                0                 0.805195
                        1                 0.194805
Science and technology  0                 0.785714
                        1                 0.214286
Sports                  0                 0.775000
                        1                 0.225000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.704142
                     1                 0.295858
Number               0                 0.833333
                     1                 0.166667
Other                0                 0.842105
                     1                 0.157895
Person               0                 0.808333
                     1                 0.191667
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.619048  0.380952           21
                       Number               0.777778  0.222222            9
                       Other                0.888889  0.111111           18
                       Person               0.777778  0.222222           27
Geography              Date                 0.533333  0.466667           15
                       Number               0.833333  0.166667           18
                       Other                0.727273  0.272727           11
Misc                   Date                 0.782609  0.217391           23
                       Number               0.777778  0.222222            9
                       Other                0.925926  0.074074           27
                       Person               0.866667  0.133333           15
Music                  Date                 0.666667  0.333333           12
                       Number               1.000000  0.000000            4
                       Other                0.750000  0.250000           12
                       Person               0.916667  0.083333           12
Other                  Date                 0.722222  0.277778           18
                       Number               1.000000  0.000000            7
                       Other                0.785714  0.214286           14
                       Person               0.692308  0.307692           13
Politics               Date                 0.666667  0.333333           36
                       Number               0.833333  0.166667            6
                       Other                0.950000  0.050000           20
                       Person               0.933333  0.066667           15
Science and technology Date                 0.771429  0.228571           35
                       Number               0.714286  0.285714           14
                       Other                0.894737  0.105263           19
                       Person               0.766667  0.233333           30
Sports                 Date                 0.888889  0.111111            9
                       Number               0.909091  0.090909           11
                       Other                0.583333  0.416667           12
                       Person               0.750000  0.250000            8

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      488
Method:                           MLE   Df Model:                           11
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.03007
Time:                        12:35:50   Log-Likelihood:                -251.80
converged:                       True   LL-Null:                       -259.60
Covariance Type:            nonrobust   LLR p-value:                    0.1562
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.1623      1.398     -0.832      0.406      -3.901       1.577
C(topic_grouped)[T.Geography]                  0.3495      0.451      0.775      0.438      -0.534       1.233
C(topic_grouped)[T.Misc]                      -0.5992      0.431     -1.391      0.164      -1.444       0.245
C(topic_grouped)[T.Music]                     -0.2388      0.485     -0.492      0.622      -1.189       0.711
C(topic_grouped)[T.Other]                     -0.0811      0.432     -0.188      0.851      -0.928       0.766
C(topic_grouped)[T.Politics]                  -0.4200      0.410     -1.025      0.305      -1.223       0.383
C(topic_grouped)[T.Science and technology]    -0.2104      0.372     -0.566      0.571      -0.939       0.518
C(topic_grouped)[T.Sports]                     0.0107      0.475      0.023      0.982      -0.919       0.941
C(answer_type_grouped)[T.Number]              -0.8929      0.362     -2.468      0.014      -1.602      -0.184
C(answer_type_grouped)[T.Other]               -0.8032      0.296     -2.715      0.007      -1.383      -0.223
C(answer_type_grouped)[T.Person]              -0.5576      0.295     -1.891      0.059      -1.136       0.020
q_length                                       0.1076      0.302      0.357      0.721      -0.484       0.699
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 1.0251
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      487
Method:                           MLE   Df Model:                           12
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.2378
Time:                        12:35:50   Log-Likelihood:                -197.87
converged:                       True   LL-Null:                       -259.60
Covariance Type:            nonrobust   LLR p-value:                 1.261e-20
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -4.1144      1.671     -2.462      0.014      -7.390      -0.839
C(topic_grouped)[T.Geography]                  0.0357      0.510      0.070      0.944      -0.963       1.034
C(topic_grouped)[T.Misc]                      -0.7060      0.485     -1.457      0.145      -1.656       0.244
C(topic_grouped)[T.Music]                     -0.4749      0.549     -0.865      0.387      -1.551       0.602
C(topic_grouped)[T.Other]                     -0.2804      0.506     -0.554      0.579      -1.271       0.711
C(topic_grouped)[T.Politics]                  -0.2608      0.467     -0.559      0.576      -1.175       0.654
C(topic_grouped)[T.Science and technology]    -0.3514      0.421     -0.835      0.404      -1.177       0.474
C(topic_grouped)[T.Sports]                     0.0101      0.548      0.018      0.985      -1.064       1.084
C(answer_type_grouped)[T.Number]              -1.0797      0.392     -2.755      0.006      -1.848      -0.312
C(answer_type_grouped)[T.Other]               -0.5189      0.339     -1.530      0.126      -1.184       0.146
C(answer_type_grouped)[T.Person]              -0.1076      0.345     -0.312      0.755      -0.784       0.569
q_length                                       0.0933      0.349      0.268      0.789      -0.590       0.777
capabilities_entropy                           2.4011      0.280      8.570      0.000       1.852       2.950
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      487
Method:                           MLE   Df Model:                           12
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1882
Time:                        12:35:50   Log-Likelihood:                -210.76
converged:                       True   LL-Null:                       -259.60
Covariance Type:            nonrobust   LLR p-value:                 1.572e-15
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -4.6018      1.651     -2.787      0.005      -7.839      -1.365
C(topic_grouped)[T.Geography]                  0.2076      0.498      0.417      0.677      -0.769       1.184
C(topic_grouped)[T.Misc]                      -0.8845      0.475     -1.861      0.063      -1.816       0.047
C(topic_grouped)[T.Music]                     -0.6901      0.535     -1.289      0.197      -1.739       0.359
C(topic_grouped)[T.Other]                     -0.4112      0.478     -0.861      0.389      -1.347       0.525
C(topic_grouped)[T.Politics]                  -0.1208      0.452     -0.267      0.789      -1.007       0.765
C(topic_grouped)[T.Science and technology]    -0.2777      0.411     -0.675      0.499      -1.084       0.528
C(topic_grouped)[T.Sports]                     0.0413      0.519      0.080      0.936      -0.975       1.058
C(answer_type_grouped)[T.Number]              -1.1041      0.387     -2.855      0.004      -1.862      -0.346
C(answer_type_grouped)[T.Other]               -0.3215      0.331     -0.970      0.332      -0.971       0.328
C(answer_type_grouped)[T.Person]               0.1280      0.340      0.377      0.706      -0.538       0.794
q_length                                       0.2863      0.342      0.837      0.402      -0.384       0.957
game_entropy                                   2.1313      0.268      7.941      0.000       1.605       2.657
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      486
Method:                           MLE   Df Model:                           13
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.2472
Time:                        12:35:50   Log-Likelihood:                -195.43
converged:                       True   LL-Null:                       -259.60
Covariance Type:            nonrobust   LLR p-value:                 4.456e-21
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -4.7942      1.727     -2.777      0.005      -8.178      -1.410
C(topic_grouped)[T.Geography]                  0.0632      0.513      0.123      0.902      -0.942       1.069
C(topic_grouped)[T.Misc]                      -0.7876      0.489     -1.610      0.107      -1.747       0.171
C(topic_grouped)[T.Music]                     -0.6100      0.559     -1.092      0.275      -1.705       0.485
C(topic_grouped)[T.Other]                     -0.3546      0.507     -0.699      0.484      -1.349       0.640
C(topic_grouped)[T.Politics]                  -0.1629      0.472     -0.345      0.730      -1.089       0.763
C(topic_grouped)[T.Science and technology]    -0.3445      0.424     -0.812      0.417      -1.176       0.487
C(topic_grouped)[T.Sports]                     0.0280      0.548      0.051      0.959      -1.045       1.101
C(answer_type_grouped)[T.Number]              -1.1188      0.394     -2.838      0.005      -1.892      -0.346
C(answer_type_grouped)[T.Other]               -0.4105      0.346     -1.187      0.235      -1.088       0.267
C(answer_type_grouped)[T.Person]               0.0531      0.356      0.149      0.882      -0.645       0.751
q_length                                       0.1679      0.355      0.473      0.637      -0.528       0.864
capabilities_entropy                           1.9007      0.358      5.302      0.000       1.198       2.603
game_entropy                                   0.7747      0.355      2.184      0.029       0.079       1.470
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing claude-3-haiku-20240307 (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_neutral/claude-3-haiku-20240307_SimpleMC_redacted_cor_temp0.0_1754426360_game_data.json', './sc_logs_neutral/claude-3-haiku-20240307_SimpleMC_redacted_temp0.0_1754368901_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    392
1    108
Name: count, dtype: int64

Answer change%: 0.2160 [0.1799298460626621, 0.2520701539373379] (n=500)
P-value vs 25%: 0.06468; P-value vs 0%: 8.244e-32
Phase 2 self-accuracy: 0.3981 [0.30582653935015763, 0.49046975694613865] (n=108)
P-value vs 25%: 0.00166; P-value vs 33%: 0.1666

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.08143
Time:                        12:35:50   Log-Likelihood:                -239.65
converged:                       True   LL-Null:                       -260.90
Covariance Type:            nonrobust   LLR p-value:                 7.103e-11
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          3.0867      0.682      4.523      0.000       1.749       4.424
p_i_capability    -4.9457      0.769     -6.431      0.000      -6.453      -3.438
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.08674
Time:                        12:35:50   Log-Likelihood:                -238.27
converged:                       True   LL-Null:                       -260.90
Covariance Type:            nonrobust   LLR p-value:                 1.724e-11
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.4268      0.215    -11.292      0.000      -2.848      -2.006
capabilities_entropy     2.3553      0.359      6.567      0.000       1.652       3.058
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.5185 [0.4243, 0.6128] (n=108)
                  P-value vs 33.3%: 0.0001173

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=2.56, p=0.0107
Wilcoxon delta_p: statistic=5968.00, p=0.00517
Mean Δp = 0.0160  [0.0038, 0.0282]
Idea 1 N = 392; 

  Idea 1.5: Calibration Metrics
  NLL: 2.9673, Signed ECE (overconf pos under neg): -0.0037, ECE: 0.0373 (n=500)
  Brier: 0.0164, Reliability (absolute calibration error; lower better): 0.0039, Resolution (relative calibration quality; higher better): 0.1977, Uncertainty: 0.2108 (n=500)
  AUROC: 0.9988

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.868
Model:                            OLS   Adj. R-squared:                  0.868
Method:                 Least Squares   F-statistic:                     1091.
Date:                Sat, 09 Aug 2025   Prob (F-statistic):          6.57e-218
Time:                        12:35:50   Log-Likelihood:                 382.60
No. Observations:                 500   AIC:                            -757.2
Df Residuals:                     496   BIC:                            -740.3
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.5984      0.056    -10.765      0.000      -0.708      -0.489
p1                    0.6650      0.060     11.111      0.000       0.547       0.783
answer_changed        0.5493      0.075      7.352      0.000       0.403       0.696
p1:answer_changed     0.2183      0.084      2.597      0.010       0.053       0.383
==============================================================================
Omnibus:                      129.153   Durbin-Watson:                   2.074
Prob(Omnibus):                  0.000   Jarque-Bera (JB):              353.477
Skew:                           1.253   Prob(JB):                     1.75e-77
Kurtosis:                       6.269   Cond. No.                         35.5
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=1.21, p=0.228
Wilcoxon delta_H: statistic=7122.50, p=0.269
Mean ΔH = 0.0350  [-0.0218, 0.0917]
Paired t-test delta_H Changed: statistic=9.79, p=1.49e-16
Wilcoxon delta_H Changed: statistic=645.00, p=1.86e-12
Mean ΔH Changed = 0.6990  [0.5591, 0.8389]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=-4.26, p=2.4e-05
Wilcoxon (p_top2_game vs p_top2_base): statistic=14602.50, p=0.0017
Mean Δp_top2 = -0.0098  [-0.0143, -0.0053] (n=500)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=5.95, p=5.16e-09
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=12502.00, p=1.55e-08
Mean ΔH_unchosen_baseline_set = 0.1784  [0.1196, 0.2372] (n=500)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      497
Method:                           MLE   Df Model:                            2
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.08275
Time:                        12:35:50   Log-Likelihood:                -239.31
converged:                       True   LL-Null:                       -260.90
Covariance Type:            nonrobust   LLR p-value:                 4.206e-10
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.4710      0.164     -8.967      0.000      -1.793      -1.150
p1_z            -0.4008      0.294     -1.361      0.173      -0.978       0.176
I(p1_z ** 2)     0.1003      0.124      0.810      0.418      -0.142       0.343
================================================================================
AUC = 0.649

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1317
Time:                        12:35:50   Log-Likelihood:                -226.54
converged:                       True   LL-Null:                       -260.90
Covariance Type:            nonrobust   LLR p-value:                 1.137e-16
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -2.6538      0.221    -12.009      0.000      -3.087      -2.221
game_entropy     2.2823      0.292      7.806      0.000       1.709       2.855
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=12125.50, p=4.75e-07
Paired t-test (game_entropy vs capabilities_entropy): statistic=5.04, p=6.5e-07
Mean capabilities_entropy-game_entropy = -0.0876  [-0.1216, -0.0535] (n=500)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      497
Method:                           MLE   Df Model:                            2
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1741
Time:                        12:35:50   Log-Likelihood:                -215.47
converged:                       True   LL-Null:                       -260.90
Covariance Type:            nonrobust   LLR p-value:                 1.865e-20
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -3.3670      0.288    -11.704      0.000      -3.931      -2.803
capabilities_entropy     1.8501      0.392      4.719      0.000       1.082       2.618
game_entropy             1.9990      0.306      6.540      0.000       1.400       2.598
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.773333
                        1                 0.226667
Geography               0                 0.818182
                        1                 0.181818
Misc                    0                 0.810811
                        1                 0.189189
Music                   0                 0.825000
                        1                 0.175000
Other                   0                 0.769231
                        1                 0.230769
Politics                0                 0.792208
                        1                 0.207792
Science and technology  0                 0.755102
                        1                 0.244898
Sports                  0                 0.750000
                        1                 0.250000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.769231
                     1                 0.230769
Number               0                 0.769231
                     1                 0.230769
Other                0                 0.804511
                     1                 0.195489
Person               0                 0.791667
                     1                 0.208333
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.714286  0.285714           21
                       Number               0.777778  0.222222            9
                       Other                0.722222  0.277778           18
                       Person               0.851852  0.148148           27
Geography              Date                 0.866667  0.133333           15
                       Number               0.777778  0.222222           18
                       Other                0.818182  0.181818           11
Misc                   Date                 0.652174  0.347826           23
                       Number               1.000000  0.000000            9
                       Other                0.888889  0.111111           27
                       Person               0.800000  0.200000           15
Music                  Date                 0.750000  0.250000           12
                       Number               1.000000  0.000000            4
                       Other                0.833333  0.166667           12
                       Person               0.833333  0.166667           12
Other                  Date                 0.888889  0.111111           18
                       Number               0.857143  0.142857            7
                       Other                0.642857  0.357143           14
                       Person               0.692308  0.307692           13
Politics               Date                 0.750000  0.250000           36
                       Number               0.666667  0.333333            6
                       Other                0.950000  0.050000           20
                       Person               0.733333  0.266667           15
Science and technology Date                 0.771429  0.228571           35
                       Number               0.571429  0.428571           14
                       Other                0.842105  0.157895           19
                       Person               0.766667  0.233333           30
Sports                 Date                 0.888889  0.111111            9
                       Number               0.727273  0.272727           11
                       Other                0.583333  0.416667           12
                       Person               0.875000  0.125000            8

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      488
Method:                           MLE   Df Model:                           11
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                0.005409
Time:                        12:35:50   Log-Likelihood:                -259.49
converged:                       True   LL-Null:                       -260.90
Covariance Type:            nonrobust   LLR p-value:                    0.9929
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.6331      1.357     -1.204      0.229      -4.293       1.026
C(topic_grouped)[T.Geography]                 -0.3312      0.493     -0.671      0.502      -1.298       0.636
C(topic_grouped)[T.Misc]                      -0.2332      0.408     -0.571      0.568      -1.033       0.567
C(topic_grouped)[T.Music]                     -0.3163      0.500     -0.632      0.527      -1.297       0.664
C(topic_grouped)[T.Other]                      0.0139      0.431      0.032      0.974      -0.831       0.858
C(topic_grouped)[T.Politics]                  -0.1605      0.403     -0.398      0.691      -0.951       0.630
C(topic_grouped)[T.Science and technology]     0.0731      0.364      0.201      0.841      -0.641       0.787
C(topic_grouped)[T.Sports]                     0.1115      0.462      0.241      0.809      -0.794       1.017
C(answer_type_grouped)[T.Number]               0.0018      0.335      0.005      0.996      -0.655       0.658
C(answer_type_grouped)[T.Other]               -0.1917      0.288     -0.665      0.506      -0.757       0.373
C(answer_type_grouped)[T.Person]              -0.1605      0.296     -0.542      0.588      -0.740       0.419
q_length                                       0.1135      0.292      0.389      0.698      -0.459       0.686
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.4423
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      487
Method:                           MLE   Df Model:                           12
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.09359
Time:                        12:35:50   Log-Likelihood:                -236.48
converged:                       True   LL-Null:                       -260.90
Covariance Type:            nonrobust   LLR p-value:                 2.236e-06
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -3.5744      1.494     -2.392      0.017      -6.503      -0.645
C(topic_grouped)[T.Geography]                 -0.4202      0.531     -0.791      0.429      -1.462       0.621
C(topic_grouped)[T.Misc]                      -0.2521      0.430     -0.586      0.558      -1.095       0.590
C(topic_grouped)[T.Music]                     -0.5086      0.544     -0.935      0.350      -1.575       0.558
C(topic_grouped)[T.Other]                     -0.0480      0.455     -0.105      0.916      -0.939       0.843
C(topic_grouped)[T.Politics]                  -0.1301      0.425     -0.306      0.760      -0.963       0.703
C(topic_grouped)[T.Science and technology]     0.0321      0.385      0.083      0.934      -0.723       0.787
C(topic_grouped)[T.Sports]                    -0.0868      0.494     -0.176      0.861      -1.056       0.882
C(answer_type_grouped)[T.Number]               0.0608      0.357      0.170      0.865      -0.640       0.761
C(answer_type_grouped)[T.Other]               -0.1338      0.307     -0.437      0.662      -0.735       0.467
C(answer_type_grouped)[T.Person]               0.0189      0.314      0.060      0.952      -0.597       0.634
q_length                                       0.2802      0.315      0.891      0.373      -0.337       0.897
capabilities_entropy                           2.4187      0.367      6.594      0.000       1.700       3.138
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      487
Method:                           MLE   Df Model:                           12
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1395
Time:                        12:35:50   Log-Likelihood:                -224.51
converged:                       True   LL-Null:                       -260.90
Covariance Type:            nonrobust   LLR p-value:                 9.651e-11
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -3.8522      1.522     -2.531      0.011      -6.836      -0.869
C(topic_grouped)[T.Geography]                 -0.3809      0.544     -0.701      0.484      -1.446       0.684
C(topic_grouped)[T.Misc]                      -0.2092      0.451     -0.464      0.642      -1.092       0.674
C(topic_grouped)[T.Music]                     -0.3611      0.560     -0.645      0.519      -1.458       0.736
C(topic_grouped)[T.Other]                      0.1112      0.464      0.239      0.811      -0.799       1.021
C(topic_grouped)[T.Politics]                  -0.0985      0.442     -0.223      0.824      -0.966       0.769
C(topic_grouped)[T.Science and technology]     0.2409      0.399      0.603      0.546      -0.541       1.023
C(topic_grouped)[T.Sports]                    -0.1667      0.533     -0.313      0.754      -1.211       0.878
C(answer_type_grouped)[T.Number]               0.0251      0.368      0.068      0.946      -0.696       0.746
C(answer_type_grouped)[T.Other]                0.0405      0.316      0.128      0.898      -0.578       0.659
C(answer_type_grouped)[T.Person]              -0.1888      0.325     -0.580      0.562      -0.826       0.449
q_length                                       0.2740      0.322      0.852      0.394      -0.357       0.905
game_entropy                                   2.3453      0.299      7.856      0.000       1.760       2.930
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      486
Method:                           MLE   Df Model:                           13
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1836
Time:                        12:35:50   Log-Likelihood:                -212.99
converged:                       True   LL-Null:                       -260.90
Covariance Type:            nonrobust   LLR p-value:                 1.068e-14
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -5.0494      1.602     -3.153      0.002      -8.188      -1.910
C(topic_grouped)[T.Geography]                 -0.4595      0.574     -0.800      0.424      -1.585       0.666
C(topic_grouped)[T.Misc]                      -0.2349      0.461     -0.509      0.611      -1.139       0.669
C(topic_grouped)[T.Music]                     -0.4918      0.565     -0.871      0.384      -1.598       0.615
C(topic_grouped)[T.Other]                      0.0574      0.476      0.121      0.904      -0.876       0.991
C(topic_grouped)[T.Politics]                  -0.0851      0.450     -0.189      0.850      -0.967       0.796
C(topic_grouped)[T.Science and technology]     0.2144      0.405      0.530      0.596      -0.579       1.008
C(topic_grouped)[T.Sports]                    -0.3302      0.558     -0.592      0.554      -1.424       0.763
C(answer_type_grouped)[T.Number]               0.0647      0.380      0.170      0.865      -0.681       0.810
C(answer_type_grouped)[T.Other]                0.0286      0.325      0.088      0.930      -0.609       0.666
C(answer_type_grouped)[T.Person]              -0.0829      0.336     -0.247      0.805      -0.742       0.576
q_length                                       0.3751      0.334      1.122      0.262      -0.280       1.030
capabilities_entropy                           1.9264      0.403      4.785      0.000       1.137       2.715
game_entropy                                   2.0633      0.311      6.632      0.000       1.454       2.673
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing claude-3-sonnet-20240229 (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_neutral/claude-3-sonnet-20240229_SimpleMC_redacted_cor_temp0.0_1751845655_game_data.json', './sc_logs_neutral/claude-3-sonnet-20240229_SimpleMC_redacted_temp0.0_1751827442_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    210
1    120
Name: count, dtype: int64

Answer change%: 0.3636 [0.3117351573776906, 0.4155375698950367] (n=330)
P-value vs 25%: 1.776e-05; P-value vs 0%: 6.519e-43
Phase 2 self-accuracy: 0.2874 [0.2201175049181228, 0.3545951387600381] (n=174)
P-value vs 25%: 0.2762; P-value vs 33%: 0.1834

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  330
Model:                          Logit   Df Residuals:                      328
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1284
Time:                        12:35:51   Log-Likelihood:                -188.53
converged:                       True   LL-Null:                       -216.31
Covariance Type:            nonrobust   LLR p-value:                 9.111e-14
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          2.6679      0.474      5.626      0.000       1.738       3.597
p_i_capability    -4.8051      0.702     -6.845      0.000      -6.181      -3.429
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  330
Model:                          Logit   Df Residuals:                      328
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1327
Time:                        12:35:51   Log-Likelihood:                -187.60
converged:                       True   LL-Null:                       -216.31
Covariance Type:            nonrobust   LLR p-value:                 3.508e-14
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.8079      0.371     -7.570      0.000      -3.535      -2.081
capabilities_entropy     1.9609      0.288      6.809      0.000       1.396       2.525
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.3000 [0.2180, 0.3820] (n=120)
                  P-value vs 33.3%: 0.4256
                  Grouped rare topic into 'Misc'/'Other': ['History', 'TV shows', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': None
topic_grouped           answer_changed
Art                     0                 0.509091
                        1                 0.490909
Geography               0                 0.586207
                        1                 0.413793
Misc                    0                 0.795455
                        1                 0.204545
Music                   0                 0.777778
                        1                 0.222222
Other                   0                 0.612903
                        1                 0.387097
Politics                0                 0.686275
                        1                 0.313725
Science and technology  0                 0.640625
                        1                 0.359375
Sports                  1                 0.517241
                        0                 0.482759
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.609091
                     1                 0.390909
Number               0                 0.521739
                     1                 0.478261
Other                0                 0.739726
                     1                 0.260274
Person               0                 0.641026
                     1                 0.358974
Place                0                 0.652174
                     1                 0.347826
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.470588  0.529412           17
                       Number               0.375000  0.625000            8
                       Other                0.555556  0.444444            9
                       Person               0.555556  0.444444           18
                       Place                0.666667  0.333333            3
Geography              Date                 0.600000  0.400000           10
                       Number               0.444444  0.555556            9
                       Other                1.000000  0.000000            3
                       Place                0.571429  0.428571            7
Misc                   Date                 0.800000  0.200000           15
                       Number               1.000000  0.000000            4
                       Other                0.785714  0.214286           14
                       Person               0.700000  0.300000           10
                       Place                1.000000  0.000000            1
Music                  Date                 0.625000  0.375000            8
                       Number               0.666667  0.333333            3
                       Other                0.857143  0.142857            7
                       Person               1.000000  0.000000            7
                       Place                0.500000  0.500000            2
Other                  Date                 0.555556  0.444444            9
                       Number               0.500000  0.500000            2
                       Other                0.875000  0.125000            8
                       Person               0.444444  0.555556            9
                       Place                0.666667  0.333333            3
Politics               Date                 0.727273  0.272727           22
                       Number               1.000000  0.000000            2
                       Other                0.750000  0.250000           12
                       Person               0.500000  0.500000           10
                       Place                0.600000  0.400000            5
Science and technology Date                 0.545455  0.454545           22
                       Number               0.444444  0.555556            9
                       Other                0.833333  0.166667           12
                       Person               0.684211  0.315789           19
                       Place                1.000000  0.000000            2
Sports                 Date                 0.428571  0.571429            7
                       Number               0.444444  0.555556            9
                       Other                0.375000  0.625000            8
                       Person               0.800000  0.200000            5

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  330
Model:                          Logit   Df Residuals:                      317
Method:                           MLE   Df Model:                           12
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.06077
Time:                        12:35:51   Log-Likelihood:                -203.16
converged:                       True   LL-Null:                       -216.31
Covariance Type:            nonrobust   LLR p-value:                  0.009767
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      3.8532      1.551      2.484      0.013       0.813       6.893
C(topic_grouped)[T.Geography]                 -0.4372      0.488     -0.896      0.370      -1.394       0.520
C(topic_grouped)[T.Misc]                      -1.2683      0.471     -2.695      0.007      -2.191      -0.346
C(topic_grouped)[T.Music]                     -1.2908      0.546     -2.365      0.018      -2.360      -0.221
C(topic_grouped)[T.Other]                     -0.3347      0.465     -0.719      0.472      -1.247       0.577
C(topic_grouped)[T.Politics]                  -0.5245      0.421     -1.247      0.212      -1.349       0.300
C(topic_grouped)[T.Science and technology]    -0.5389      0.382     -1.411      0.158      -1.288       0.210
C(topic_grouped)[T.Sports]                     0.1246      0.476      0.262      0.794      -0.809       1.058
C(answer_type_grouped)[T.Number]               0.3306      0.378      0.874      0.382      -0.411       1.072
C(answer_type_grouped)[T.Other]               -0.7201      0.348     -2.071      0.038      -1.402      -0.039
C(answer_type_grouped)[T.Person]              -0.2767      0.323     -0.856      0.392      -0.910       0.357
C(answer_type_grouped)[T.Place]               -0.2278      0.500     -0.456      0.649      -1.208       0.752
q_length                                      -0.8300      0.336     -2.473      0.013      -1.488      -0.172
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 1.0787
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  330
Model:                          Logit   Df Residuals:                      316
Method:                           MLE   Df Model:                           13
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1912
Time:                        12:35:51   Log-Likelihood:                -174.96
converged:                       True   LL-Null:                       -216.31
Covariance Type:            nonrobust   LLR p-value:                 3.412e-12
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      2.2855      1.725      1.325      0.185      -1.095       5.666
C(topic_grouped)[T.Geography]                 -0.1446      0.538     -0.269      0.788      -1.198       0.909
C(topic_grouped)[T.Misc]                      -1.1871      0.507     -2.341      0.019      -2.181      -0.193
C(topic_grouped)[T.Music]                     -1.1608      0.606     -1.914      0.056      -2.349       0.028
C(topic_grouped)[T.Other]                     -0.0513      0.514     -0.100      0.921      -1.060       0.957
C(topic_grouped)[T.Politics]                  -0.2401      0.474     -0.507      0.612      -1.169       0.689
C(topic_grouped)[T.Science and technology]    -0.4951      0.429     -1.154      0.249      -1.336       0.346
C(topic_grouped)[T.Sports]                    -0.2524      0.522     -0.484      0.629      -1.275       0.770
C(answer_type_grouped)[T.Number]               0.5442      0.411      1.324      0.185      -0.261       1.350
C(answer_type_grouped)[T.Other]               -0.6289      0.383     -1.643      0.100      -1.379       0.121
C(answer_type_grouped)[T.Person]               0.2999      0.367      0.816      0.414      -0.420       1.020
C(answer_type_grouped)[T.Place]               -0.2117      0.544     -0.389      0.697      -1.277       0.854
q_length                                      -1.0883      0.378     -2.879      0.004      -1.829      -0.347
capabilities_entropy                           2.1401      0.320      6.690      0.000       1.513       2.767
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing claude-sonnet-4-20250514 (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_neutral/claude-sonnet-4-20250514_SimpleMC_redacted_cor_temp0.0_1751828378_game_data.json', './sc_logs_neutral/claude-sonnet-4-20250514_SimpleMC_redacted_temp0.0_1751824015_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    307
1    193
Name: count, dtype: int64

Answer change%: 0.3860 [0.34332820354520355, 0.42867179645479647] (n=500)
P-value vs 25%: 4.194e-10; P-value vs 0%: 2.486e-70
Phase 2 self-accuracy: 0.3886 [0.3198334528643938, 0.4573686196744663] (n=193)
P-value vs 25%: 7.805e-05; P-value vs 33%: 0.113
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.653333
                        1                 0.346667
Geography               0                 0.545455
                        1                 0.454545
Misc                    0                 0.635135
                        1                 0.364865
Music                   0                 0.750000
                        1                 0.250000
Other                   0                 0.596154
                        1                 0.403846
Politics                0                 0.636364
                        1                 0.363636
Science and technology  0                 0.571429
                        1                 0.428571
Sports                  0                 0.525000
                        1                 0.475000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.609467
                     1                 0.390533
Number               0                 0.576923
                     1                 0.423077
Other                0                 0.646617
                     1                 0.353383
Person               0                 0.608333
                     1                 0.391667
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.714286  0.285714           21
                       Number               0.555556  0.444444            9
                       Other                0.777778  0.222222           18
                       Person               0.555556  0.444444           27
Geography              Date                 0.266667  0.733333           15
                       Number               0.666667  0.333333           18
                       Other                0.727273  0.272727           11
Misc                   Date                 0.782609  0.217391           23
                       Number               0.444444  0.555556            9
                       Other                0.592593  0.407407           27
                       Person               0.600000  0.400000           15
Music                  Date                 0.750000  0.250000           12
                       Number               0.750000  0.250000            4
                       Other                0.666667  0.333333           12
                       Person               0.833333  0.166667           12
Other                  Date                 0.444444  0.555556           18
                       Number               0.714286  0.285714            7
                       Other                0.642857  0.357143           14
                       Person               0.692308  0.307692           13
Politics               Date                 0.638889  0.361111           36
                       Number               0.500000  0.500000            6
                       Other                0.600000  0.400000           20
                       Person               0.733333  0.266667           15
Science and technology Date                 0.600000  0.400000           35
                       Number               0.571429  0.428571           14
                       Other                0.684211  0.315789           19
                       Person               0.466667  0.533333           30
Sports                 Date                 0.555556  0.444444            9
                       Number               0.454545  0.545455           11
                       Other                0.500000  0.500000           12
                       Person               0.625000  0.375000            8

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      488
Method:                           MLE   Df Model:                           11
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.01171
Time:                        12:35:51   Log-Likelihood:                -329.56
converged:                       True   LL-Null:                       -333.46
Covariance Type:            nonrobust   LLR p-value:                    0.7303
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -0.7338      1.158     -0.633      0.526      -3.004       1.537
C(topic_grouped)[T.Geography]                  0.4592      0.402      1.144      0.253      -0.328       1.246
C(topic_grouped)[T.Misc]                       0.1045      0.345      0.303      0.762      -0.571       0.780
C(topic_grouped)[T.Music]                     -0.4518      0.439     -1.029      0.304      -1.313       0.409
C(topic_grouped)[T.Other]                      0.2541      0.374      0.680      0.497      -0.478       0.987
C(topic_grouped)[T.Politics]                   0.0809      0.346      0.233      0.815      -0.598       0.760
C(topic_grouped)[T.Science and technology]     0.3391      0.318      1.065      0.287      -0.285       0.963
C(topic_grouped)[T.Sports]                     0.5440      0.403      1.351      0.177      -0.245       1.333
C(answer_type_grouped)[T.Number]               0.0402      0.288      0.140      0.889      -0.524       0.604
C(answer_type_grouped)[T.Other]               -0.1489      0.244     -0.609      0.542      -0.628       0.330
C(answer_type_grouped)[T.Person]               0.0464      0.252      0.184      0.854      -0.447       0.539
q_length                                       0.0254      0.249      0.102      0.919      -0.463       0.514
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing deepseek-chat (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_neutral/deepseek-chat_SimpleMC_redacted_cor_temp0.0_1754439842_game_data.json', './sc_logs_neutral/deepseek-chat_SimpleMC_redacted_temp0.0_1754433214_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    409
1     91
Name: count, dtype: int64

Answer change%: 0.1820 [0.14817985738085485, 0.21582014261914514] (n=500)
P-value vs 25%: 8.122e-05; P-value vs 0%: 5.224e-26
Phase 2 self-accuracy: 0.4066 [0.3056718955193283, 0.5075149176674849] (n=91)
P-value vs 25%: 0.002357; P-value vs 33%: 0.1529

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1844
Time:                        12:35:51   Log-Likelihood:                -193.47
converged:                       True   LL-Null:                       -237.21
Covariance Type:            nonrobust   LLR p-value:                 8.553e-21
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          5.1729      0.778      6.648      0.000       3.648       6.698
p_i_capability    -7.6668      0.893     -8.587      0.000      -9.417      -5.917
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.2024
Time:                        12:35:51   Log-Likelihood:                -189.19
converged:                       True   LL-Null:                       -237.21
Covariance Type:            nonrobust   LLR p-value:                 1.133e-22
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -3.3802      0.263    -12.866      0.000      -3.895      -2.865
capabilities_entropy     3.4864      0.393      8.864      0.000       2.716       4.257
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.7473 [0.6580, 0.8365] (n=91)
                  P-value vs 33.3%: 1.03e-19

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=-0.37, p=0.71
Wilcoxon delta_p: statistic=4517.00, p=0.653
Mean Δp = -0.0020  [-0.0127, 0.0086]
Idea 1 N = 409; 

  Idea 1.5: Calibration Metrics
  NLL: 1.9508, Signed ECE (overconf pos under neg): -0.0212, ECE: 0.0664 (n=500)
  Brier: 0.0168, Reliability (absolute calibration error; lower better): 0.0135, Resolution (relative calibration quality; higher better): 0.2463, Uncertainty: 0.2495 (n=500)
  AUROC: 0.9999

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.890
Model:                            OLS   Adj. R-squared:                  0.889
Method:                 Least Squares   F-statistic:                     1340.
Date:                Sat, 09 Aug 2025   Prob (F-statistic):          2.17e-237
Time:                        12:35:51   Log-Likelihood:                 465.66
No. Observations:                 500   AIC:                            -923.3
Df Residuals:                     496   BIC:                            -906.5
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.7076      0.049    -14.501      0.000      -0.803      -0.612
p1                    0.7610      0.052     14.528      0.000       0.658       0.864
answer_changed        0.6188      0.067      9.229      0.000       0.487       0.751
p1:answer_changed     0.2019      0.078      2.586      0.010       0.049       0.355
==============================================================================
Omnibus:                      192.947   Durbin-Watson:                   1.915
Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1296.672
Skew:                           1.524   Prob(JB):                    2.70e-282
Kurtosis:                      10.277   Cond. No.                         37.2
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=0.01, p=0.992
Wilcoxon delta_H: statistic=4717.50, p=0.985
Mean ΔH = 0.0002  [-0.0475, 0.0480]
Paired t-test delta_H Changed: statistic=8.78, p=9.91e-14
Wilcoxon delta_H Changed: statistic=399.00, p=2.02e-11
Mean ΔH Changed = 0.5468  [0.4247, 0.6689]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=1.17, p=0.241
Wilcoxon (p_top2_game vs p_top2_base): statistic=11842.50, p=0.318
Mean Δp_top2 = 0.0018  [-0.0012, 0.0047] (n=500)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=4.03, p=6.58e-05
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=9125.50, p=8.18e-05
Mean ΔH_unchosen_baseline_set = 0.0997  [0.0512, 0.1483] (n=500)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      497
Method:                           MLE   Df Model:                            2
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.2114
Time:                        12:35:51   Log-Likelihood:                -187.06
converged:                       True   LL-Null:                       -237.21
Covariance Type:            nonrobust   LLR p-value:                 1.660e-22
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.4460      0.159     -9.102      0.000      -1.757      -1.135
p1_z            -1.8026      0.262     -6.872      0.000      -2.317      -1.288
I(p1_z ** 2)    -0.3698      0.101     -3.654      0.000      -0.568      -0.171
================================================================================
AUC = 0.824

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1071
Time:                        12:35:51   Log-Likelihood:                -211.81
converged:                       True   LL-Null:                       -237.21
Covariance Type:            nonrobust   LLR p-value:                 1.029e-12
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -2.8188      0.238    -11.850      0.000      -3.285      -2.353
game_entropy     2.7201      0.397      6.852      0.000       1.942       3.498
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=10930.00, p=0.0541
Paired t-test (game_entropy vs capabilities_entropy): statistic=-2.13, p=0.034
Mean capabilities_entropy-game_entropy = 0.0294  [0.0023, 0.0566] (n=500)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      497
Method:                           MLE   Df Model:                            2
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.2362
Time:                        12:35:51   Log-Likelihood:                -181.19
converged:                       True   LL-Null:                       -237.21
Covariance Type:            nonrobust   LLR p-value:                 4.691e-25
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -4.0246      0.331    -12.164      0.000      -4.673      -3.376
capabilities_entropy     3.0624      0.410      7.472      0.000       2.259       3.866
game_entropy             1.8268      0.458      3.985      0.000       0.928       2.725
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.866667
                        1                 0.133333
Geography               0                 0.818182
                        1                 0.181818
Misc                    0                 0.797297
                        1                 0.202703
Music                   0                 0.850000
                        1                 0.150000
Other                   0                 0.884615
                        1                 0.115385
Politics                0                 0.753247
                        1                 0.246753
Science and technology  0                 0.795918
                        1                 0.204082
Sports                  0                 0.825000
                        1                 0.175000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.792899
                     1                 0.207101
Number               0                 0.820513
                     1                 0.179487
Other                0                 0.804511
                     1                 0.195489
Person               0                 0.866667
                     1                 0.133333
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.857143  0.142857           21
                       Number               1.000000  0.000000            9
                       Other                0.777778  0.222222           18
                       Person               0.888889  0.111111           27
Geography              Date                 0.800000  0.200000           15
                       Number               0.888889  0.111111           18
                       Other                0.727273  0.272727           11
Misc                   Date                 0.869565  0.130435           23
                       Number               0.777778  0.222222            9
                       Other                0.777778  0.222222           27
                       Person               0.733333  0.266667           15
Music                  Date                 0.916667  0.083333           12
                       Number               0.750000  0.250000            4
                       Other                0.833333  0.166667           12
                       Person               0.833333  0.166667           12
Other                  Date                 0.777778  0.222222           18
                       Number               1.000000  0.000000            7
                       Other                0.928571  0.071429           14
                       Person               0.923077  0.076923           13
Politics               Date                 0.750000  0.250000           36
                       Number               0.500000  0.500000            6
                       Other                0.850000  0.150000           20
                       Person               0.733333  0.266667           15
Science and technology Date                 0.742857  0.257143           35
                       Number               0.785714  0.214286           14
                       Other                0.684211  0.315789           19
                       Person               0.933333  0.066667           30
Sports                 Date                 0.666667  0.333333            9
                       Number               0.727273  0.272727           11
                       Other                0.916667  0.083333           12
                       Person               1.000000  0.000000            8

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      488
Method:                           MLE   Df Model:                           11
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.01729
Time:                        12:35:51   Log-Likelihood:                -233.11
converged:                       True   LL-Null:                       -237.21
Covariance Type:            nonrobust   LLR p-value:                    0.6951
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.9329      1.457     -1.326      0.185      -4.789       0.923
C(topic_grouped)[T.Geography]                  0.2497      0.532      0.470      0.639      -0.792       1.292
C(topic_grouped)[T.Misc]                       0.4376      0.449      0.974      0.330      -0.443       1.318
C(topic_grouped)[T.Music]                      0.1130      0.560      0.202      0.840      -0.984       1.211
C(topic_grouped)[T.Other]                     -0.2104      0.553     -0.380      0.704      -1.294       0.874
C(topic_grouped)[T.Politics]                   0.6686      0.441      1.517      0.129      -0.195       1.532
C(topic_grouped)[T.Science and technology]     0.4849      0.425      1.141      0.254      -0.348       1.318
C(topic_grouped)[T.Sports]                     0.2716      0.542      0.501      0.616      -0.791       1.334
C(answer_type_grouped)[T.Number]              -0.1196      0.363     -0.330      0.742      -0.831       0.591
C(answer_type_grouped)[T.Other]               -0.0335      0.294     -0.114      0.909      -0.611       0.544
C(answer_type_grouped)[T.Person]              -0.4694      0.337     -1.394      0.163      -1.130       0.191
q_length                                       0.0530      0.312      0.170      0.865      -0.559       0.665
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.4642
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      487
Method:                           MLE   Df Model:                           12
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.2267
Time:                        12:35:51   Log-Likelihood:                -183.44
converged:                       True   LL-Null:                       -237.21
Covariance Type:            nonrobust   LLR p-value:                 1.841e-17
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -4.6046      1.725     -2.669      0.008      -7.986      -1.223
C(topic_grouped)[T.Geography]                  0.2577      0.616      0.418      0.676      -0.950       1.465
C(topic_grouped)[T.Misc]                       0.5631      0.512      1.101      0.271      -0.440       1.566
C(topic_grouped)[T.Music]                      0.1904      0.633      0.301      0.764      -1.051       1.432
C(topic_grouped)[T.Other]                     -0.6853      0.666     -1.029      0.303      -1.990       0.620
C(topic_grouped)[T.Politics]                   0.5671      0.499      1.136      0.256      -0.411       1.545
C(topic_grouped)[T.Science and technology]     0.6610      0.485      1.364      0.173      -0.289       1.611
C(topic_grouped)[T.Sports]                     0.1922      0.651      0.295      0.768      -1.083       1.468
C(answer_type_grouped)[T.Number]              -0.2882      0.437     -0.659      0.510      -1.145       0.568
C(answer_type_grouped)[T.Other]               -0.0179      0.333     -0.054      0.957      -0.671       0.635
C(answer_type_grouped)[T.Person]              -0.6112      0.401     -1.523      0.128      -1.397       0.175
q_length                                       0.2174      0.357      0.609      0.543      -0.482       0.917
capabilities_entropy                           3.6318      0.405      8.973      0.000       2.839       4.425
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      487
Method:                           MLE   Df Model:                           12
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1307
Time:                        12:35:51   Log-Likelihood:                -206.21
converged:                       True   LL-Null:                       -237.21
Covariance Type:            nonrobust   LLR p-value:                 9.781e-09
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -2.8442      1.574     -1.807      0.071      -5.929       0.241
C(topic_grouped)[T.Geography]                  0.2858      0.579      0.494      0.622      -0.849       1.421
C(topic_grouped)[T.Misc]                       0.2433      0.483      0.504      0.614      -0.703       1.189
C(topic_grouped)[T.Music]                     -0.1462      0.596     -0.245      0.806      -1.314       1.022
C(topic_grouped)[T.Other]                     -0.4801      0.612     -0.785      0.433      -1.680       0.719
C(topic_grouped)[T.Politics]                   0.8243      0.466      1.768      0.077      -0.090       1.738
C(topic_grouped)[T.Science and technology]     0.6019      0.452      1.333      0.183      -0.283       1.487
C(topic_grouped)[T.Sports]                     0.2559      0.593      0.432      0.666      -0.906       1.418
C(answer_type_grouped)[T.Number]              -0.2263      0.417     -0.542      0.588      -1.045       0.592
C(answer_type_grouped)[T.Other]                0.2016      0.314      0.643      0.520      -0.413       0.816
C(answer_type_grouped)[T.Person]              -0.3061      0.358     -0.854      0.393      -1.009       0.397
q_length                                      -0.0745      0.333     -0.224      0.823      -0.727       0.578
game_entropy                                   2.9224      0.418      6.990      0.000       2.103       3.742
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      486
Method:                           MLE   Df Model:                           13
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.2622
Time:                        12:35:51   Log-Likelihood:                -175.02
converged:                       True   LL-Null:                       -237.21
Covariance Type:            nonrobust   LLR p-value:                 2.738e-20
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -4.7357      1.794     -2.639      0.008      -8.252      -1.219
C(topic_grouped)[T.Geography]                  0.2694      0.637      0.423      0.672      -0.980       1.519
C(topic_grouped)[T.Misc]                       0.5173      0.531      0.975      0.330      -0.523       1.557
C(topic_grouped)[T.Music]                      0.0848      0.644      0.132      0.895      -1.177       1.346
C(topic_grouped)[T.Other]                     -0.7672      0.712     -1.077      0.281      -2.163       0.629
C(topic_grouped)[T.Politics]                   0.7450      0.515      1.446      0.148      -0.265       1.755
C(topic_grouped)[T.Science and technology]     0.7658      0.505      1.516      0.130      -0.224       1.756
C(topic_grouped)[T.Sports]                     0.2666      0.683      0.391      0.696      -1.071       1.605
C(answer_type_grouped)[T.Number]              -0.3224      0.479     -0.673      0.501      -1.262       0.617
C(answer_type_grouped)[T.Other]                0.1575      0.340      0.464      0.643      -0.508       0.823
C(answer_type_grouped)[T.Person]              -0.4830      0.407     -1.187      0.235      -1.280       0.314
q_length                                       0.0705      0.372      0.190      0.850      -0.658       0.799
capabilities_entropy                           3.1669      0.422      7.502      0.000       2.340       3.994
game_entropy                                   1.9406      0.478      4.058      0.000       1.003       2.878
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing gemini-1.5-pro (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_neutral/gemini-1.5-pro_SimpleMC_redacted_cor_temp0.0_1751845219_game_data.json', './sc_logs_neutral/gemini-1.5-pro_SimpleMC_redacted_temp0.0_1751826859_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    409
1     91
Name: count, dtype: int64

Answer change%: 0.1820 [0.14817985738085485, 0.21582014261914514] (n=500)
P-value vs 25%: 8.122e-05; P-value vs 0%: 5.224e-26
Phase 2 self-accuracy: 0.4066 [0.3056718955193283, 0.5075149176674849] (n=91)
P-value vs 25%: 0.002357; P-value vs 33%: 0.1529
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.866667
                        1                 0.133333
Geography               0                 0.772727
                        1                 0.227273
Misc                    0                 0.810811
                        1                 0.189189
Music                   0                 0.775000
                        1                 0.225000
Other                   0                 0.769231
                        1                 0.230769
Politics                0                 0.857143
                        1                 0.142857
Science and technology  0                 0.775510
                        1                 0.224490
Sports                  0                 0.925000
                        1                 0.075000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.869822
                     1                 0.130178
Number               0                 0.794872
                     1                 0.205128
Other                0                 0.774436
                     1                 0.225564
Person               0                 0.808333
                     1                 0.191667
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.952381  0.047619           21
                       Number               0.777778  0.222222            9
                       Other                0.888889  0.111111           18
                       Person               0.814815  0.185185           27
Geography              Date                 0.733333  0.266667           15
                       Number               0.777778  0.222222           18
                       Other                0.818182  0.181818           11
Misc                   Date                 0.913043  0.086957           23
                       Number               0.777778  0.222222            9
                       Other                0.777778  0.222222           27
                       Person               0.733333  0.266667           15
Music                  Date                 0.916667  0.083333           12
                       Number               0.750000  0.250000            4
                       Other                0.416667  0.583333           12
                       Person               1.000000  0.000000           12
Other                  Date                 0.888889  0.111111           18
                       Number               1.000000  0.000000            7
                       Other                0.571429  0.428571           14
                       Person               0.692308  0.307692           13
Politics               Date                 0.888889  0.111111           36
                       Number               1.000000  0.000000            6
                       Other                0.850000  0.150000           20
                       Person               0.733333  0.266667           15
Science and technology Date                 0.771429  0.228571           35
                       Number               0.642857  0.357143           14
                       Other                0.789474  0.210526           19
                       Person               0.833333  0.166667           30
Sports                 Date                 1.000000  0.000000            9
                       Number               0.818182  0.181818           11
                       Other                1.000000  0.000000           12
                       Person               0.875000  0.125000            8

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      488
Method:                           MLE   Df Model:                           11
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.03109
Time:                        12:35:51   Log-Likelihood:                -229.83
converged:                       True   LL-Null:                       -237.21
Covariance Type:            nonrobust   LLR p-value:                    0.1942
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.9503      1.479     -1.319      0.187      -4.849       0.948
C(topic_grouped)[T.Geography]                  0.6541      0.515      1.271      0.204      -0.355       1.663
C(topic_grouped)[T.Misc]                       0.4062      0.456      0.891      0.373      -0.488       1.300
C(topic_grouped)[T.Music]                      0.6330      0.512      1.236      0.216      -0.371       1.637
C(topic_grouped)[T.Other]                      0.6936      0.477      1.455      0.146      -0.241       1.628
C(topic_grouped)[T.Politics]                   0.1803      0.480      0.375      0.707      -0.761       1.122
C(topic_grouped)[T.Science and technology]     0.6898      0.421      1.639      0.101      -0.135       1.515
C(topic_grouped)[T.Sports]                    -0.6910      0.694     -0.995      0.320      -2.052       0.670
C(answer_type_grouped)[T.Number]               0.5694      0.374      1.523      0.128      -0.163       1.302
C(answer_type_grouped)[T.Other]                0.7058      0.314      2.247      0.025       0.090       1.322
C(answer_type_grouped)[T.Person]               0.4894      0.334      1.464      0.143      -0.166       1.145
q_length                                      -0.0812      0.316     -0.257      0.797      -0.701       0.538
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing gemini-2.0-flash-001 (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_neutral/gemini-2.0-flash-001_SimpleMC_redacted_cor_temp0.0_1754341330_game_data.json', './sc_logs_neutral/gemini-2.0-flash-001_SimpleMC_redacted_temp0.0_1754341125_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    373
1    127
Name: count, dtype: int64

Answer change%: 0.2540 [0.21584518423107232, 0.29215481576892766] (n=500)
P-value vs 25%: 0.8372; P-value vs 0%: 6.553e-39
Phase 2 self-accuracy: 0.4252 [0.33921618147345844, 0.5111775193139432] (n=127)
P-value vs 25%: 6.505e-05; P-value vs 33%: 0.03558

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.05935
Time:                        12:35:51   Log-Likelihood:                -266.53
converged:                       True   LL-Null:                       -283.34
Covariance Type:            nonrobust   LLR p-value:                 6.660e-09
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          2.4392      0.615      3.964      0.000       1.233       3.645
p_i_capability    -3.9260      0.685     -5.733      0.000      -5.268      -2.584
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.05905
Time:                        12:35:51   Log-Likelihood:                -266.61
converged:                       True   LL-Null:                       -283.34
Covariance Type:            nonrobust   LLR p-value:                 7.270e-09
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.5678      0.143    -10.967      0.000      -1.848      -1.288
capabilities_entropy     1.3061      0.228      5.735      0.000       0.860       1.752
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.7212 [0.6350, 0.8073] (n=104)
                  P-value vs 33.3%: 1.148e-18

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=2.95, p=0.00348
Wilcoxon delta_p: statistic=10247.00, p=0.0117
Mean Δp = 0.0346  [0.0116, 0.0575]
Idea 1 N = 225; 

  Idea 1.5: Calibration Metrics
  NLL: 3.5067, Signed ECE (overconf pos under neg): 0.0096, ECE: 0.0665 (n=326)
  Brier: 0.0202, Reliability (absolute calibration error; lower better): 0.0158, Resolution (relative calibration quality; higher better): 0.2289, Uncertainty: 0.2326 (n=326)
  AUROC: 0.9998

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.829
Model:                            OLS   Adj. R-squared:                  0.828
Method:                 Least Squares   F-statistic:                     521.3
Date:                Sat, 09 Aug 2025   Prob (F-statistic):          3.35e-123
Time:                        12:35:51   Log-Likelihood:                 155.35
No. Observations:                 326   AIC:                            -302.7
Df Residuals:                     322   BIC:                            -287.5
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.4852      0.067     -7.252      0.000      -0.617      -0.354
p1                    0.5747      0.073      7.858      0.000       0.431       0.719
answer_changed        0.3126      0.097      3.230      0.001       0.122       0.503
p1:answer_changed     0.4768      0.110      4.323      0.000       0.260       0.694
==============================================================================
Omnibus:                       27.502   Durbin-Watson:                   2.076
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               31.915
Skew:                           0.736   Prob(JB):                     1.17e-07
Kurtosis:                       3.427   Cond. No.                         27.5
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-3.06, p=0.00247
Wilcoxon delta_H: statistic=10223.00, p=0.00818
Mean ΔH = -0.1107  [-0.1815, -0.0398]
Paired t-test delta_H Changed: statistic=4.34, p=3.41e-05
Wilcoxon delta_H Changed: statistic=1382.00, p=5.27e-05
Mean ΔH Changed = 0.2325  [0.1275, 0.3376]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=-2.80, p=0.00535
Wilcoxon (p_top2_game vs p_top2_base): statistic=19301.00, p=1.13e-05
Mean Δp_top2 = -0.0099  [-0.0168, -0.0030] (n=327)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=-0.15, p=0.881
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=26671.00, p=0.933
Mean ΔH_unchosen_baseline_set = -0.0047  [-0.0658, 0.0565] (n=327)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  327
Model:                          Logit   Df Residuals:                      324
Method:                           MLE   Df Model:                            2
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.03825
Time:                        12:35:51   Log-Likelihood:                -194.42
converged:                       True   LL-Null:                       -202.15
Covariance Type:            nonrobust   LLR p-value:                 0.0004382
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.8503      0.171     -4.973      0.000      -1.185      -0.515
p1_z            -0.4395      0.201     -2.182      0.029      -0.834      -0.045
I(p1_z ** 2)     0.0132      0.124      0.106      0.915      -0.230       0.256
================================================================================
AUC = 0.651

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.07579
Time:                        12:35:51   Log-Likelihood:                -261.87
converged:                       True   LL-Null:                       -283.34
Covariance Type:            nonrobust   LLR p-value:                 5.615e-11
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.7122      0.155    -11.075      0.000      -2.015      -1.409
game_entropy     1.3444      0.209      6.430      0.000       0.935       1.754
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=49380.00, p=4.17e-05
Paired t-test (game_entropy vs capabilities_entropy): statistic=3.67, p=0.000265
Mean capabilities_entropy-game_entropy = -0.0803  [-0.1231, -0.0375] (n=500)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      497
Method:                           MLE   Df Model:                            2
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.09622
Time:                        12:35:51   Log-Likelihood:                -256.08
converged:                       True   LL-Null:                       -283.34
Covariance Type:            nonrobust   LLR p-value:                 1.443e-12
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.8990      0.170    -11.189      0.000      -2.232      -1.566
capabilities_entropy     0.8602      0.251      3.430      0.001       0.369       1.352
game_entropy             1.0486      0.228      4.600      0.000       0.602       1.495
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.760000
                        1                 0.240000
Geography               0                 0.659091
                        1                 0.340909
Misc                    0                 0.716216
                        1                 0.283784
Music                   0                 0.825000
                        1                 0.175000
Other                   0                 0.692308
                        1                 0.307692
Politics                0                 0.857143
                        1                 0.142857
Science and technology  0                 0.724490
                        1                 0.275510
Sports                  0                 0.700000
                        1                 0.300000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.745562
                     1                 0.254438
Number               0                 0.653846
                     1                 0.346154
Other                0                 0.751880
                     1                 0.248120
Person               0                 0.800000
                     1                 0.200000
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.666667  0.333333           21
                       Number               0.555556  0.444444            9
                       Other                0.722222  0.277778           18
                       Person               0.925926  0.074074           27
Geography              Date                 0.666667  0.333333           15
                       Number               0.666667  0.333333           18
                       Other                0.636364  0.363636           11
Misc                   Date                 0.739130  0.260870           23
                       Number               0.666667  0.333333            9
                       Other                0.740741  0.259259           27
                       Person               0.666667  0.333333           15
Music                  Date                 0.833333  0.166667           12
                       Number               1.000000  0.000000            4
                       Other                0.750000  0.250000           12
                       Person               0.833333  0.166667           12
Other                  Date                 0.666667  0.333333           18
                       Number               0.714286  0.285714            7
                       Other                0.785714  0.214286           14
                       Person               0.615385  0.384615           13
Politics               Date                 0.805556  0.194444           36
                       Number               0.833333  0.166667            6
                       Other                1.000000  0.000000           20
                       Person               0.800000  0.200000           15
Science and technology Date                 0.800000  0.200000           35
                       Number               0.571429  0.428571           14
                       Other                0.578947  0.421053           19
                       Person               0.800000  0.200000           30
Sports                 Date                 0.666667  0.333333            9
                       Number               0.545455  0.454545           11
                       Other                0.750000  0.250000           12
                       Person               0.875000  0.125000            8

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      488
Method:                           MLE   Df Model:                           11
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.02646
Time:                        12:35:51   Log-Likelihood:                -275.85
converged:                       True   LL-Null:                       -283.34
Covariance Type:            nonrobust   LLR p-value:                    0.1828
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      0.0746      1.316      0.057      0.955      -2.505       2.654
C(topic_grouped)[T.Geography]                  0.2754      0.432      0.637      0.524      -0.572       1.122
C(topic_grouped)[T.Misc]                       0.1948      0.378      0.516      0.606      -0.545       0.935
C(topic_grouped)[T.Music]                     -0.4202      0.499     -0.842      0.400      -1.398       0.557
C(topic_grouped)[T.Other]                      0.2983      0.407      0.732      0.464      -0.500       1.097
C(topic_grouped)[T.Politics]                  -0.6213      0.432     -1.438      0.150      -1.468       0.225
C(topic_grouped)[T.Science and technology]     0.1817      0.356      0.511      0.610      -0.516       0.879
C(topic_grouped)[T.Sports]                     0.2132      0.444      0.480      0.631      -0.657       1.083
C(answer_type_grouped)[T.Number]               0.3301      0.307      1.076      0.282      -0.271       0.932
C(answer_type_grouped)[T.Other]               -0.0880      0.273     -0.322      0.747      -0.623       0.447
C(answer_type_grouped)[T.Person]              -0.3554      0.296     -1.200      0.230      -0.936       0.225
q_length                                      -0.2536      0.285     -0.889      0.374      -0.813       0.305
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.3228
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      487
Method:                           MLE   Df Model:                           12
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.08092
Time:                        12:35:51   Log-Likelihood:                -260.41
converged:                       True   LL-Null:                       -283.34
Covariance Type:            nonrobust   LLR p-value:                 7.338e-06
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      0.3191      1.362      0.234      0.815      -2.351       2.989
C(topic_grouped)[T.Geography]                  0.2447      0.449      0.545      0.586      -0.636       1.125
C(topic_grouped)[T.Misc]                       0.1162      0.392      0.296      0.767      -0.653       0.885
C(topic_grouped)[T.Music]                     -0.5220      0.516     -1.012      0.312      -1.533       0.489
C(topic_grouped)[T.Other]                      0.0901      0.423      0.213      0.831      -0.738       0.919
C(topic_grouped)[T.Politics]                  -0.6403      0.446     -1.437      0.151      -1.514       0.233
C(topic_grouped)[T.Science and technology]     0.1188      0.369      0.322      0.747      -0.604       0.842
C(topic_grouped)[T.Sports]                     0.3059      0.461      0.664      0.507      -0.598       1.209
C(answer_type_grouped)[T.Number]               0.1572      0.320      0.491      0.623      -0.470       0.784
C(answer_type_grouped)[T.Other]               -0.1286      0.285     -0.452      0.652      -0.687       0.430
C(answer_type_grouped)[T.Person]              -0.2793      0.308     -0.908      0.364      -0.882       0.323
q_length                                      -0.3992      0.297     -1.343      0.179      -0.982       0.183
capabilities_entropy                           1.2971      0.236      5.495      0.000       0.834       1.760
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      487
Method:                           MLE   Df Model:                           12
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1003
Time:                        12:35:51   Log-Likelihood:                -254.91
converged:                       True   LL-Null:                       -283.34
Covariance Type:            nonrobust   LLR p-value:                 8.379e-08
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -0.1977      1.374     -0.144      0.886      -2.891       2.496
C(topic_grouped)[T.Geography]                  0.1723      0.451      0.382      0.702      -0.711       1.056
C(topic_grouped)[T.Misc]                       0.0188      0.398      0.047      0.962      -0.762       0.799
C(topic_grouped)[T.Music]                     -0.3988      0.519     -0.769      0.442      -1.416       0.618
C(topic_grouped)[T.Other]                      0.2064      0.426      0.485      0.628      -0.628       1.041
C(topic_grouped)[T.Politics]                  -0.8204      0.453     -1.813      0.070      -1.708       0.067
C(topic_grouped)[T.Science and technology]     0.1131      0.372      0.304      0.761      -0.617       0.843
C(topic_grouped)[T.Sports]                     0.3010      0.462      0.651      0.515      -0.605       1.207
C(answer_type_grouped)[T.Number]               0.3019      0.324      0.931      0.352      -0.334       0.937
C(answer_type_grouped)[T.Other]                0.2074      0.293      0.707      0.480      -0.368       0.782
C(answer_type_grouped)[T.Person]              -0.0470      0.315     -0.149      0.881      -0.664       0.570
q_length                                      -0.3552      0.298     -1.191      0.234      -0.940       0.229
game_entropy                                   1.4048      0.222      6.317      0.000       0.969       1.841
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      486
Method:                           MLE   Df Model:                           13
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1185
Time:                        12:35:51   Log-Likelihood:                -249.76
converged:                       True   LL-Null:                       -283.34
Covariance Type:            nonrobust   LLR p-value:                 2.666e-09
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      0.0012      1.387      0.001      0.999      -2.717       2.720
C(topic_grouped)[T.Geography]                  0.1860      0.458      0.406      0.685      -0.712       1.084
C(topic_grouped)[T.Misc]                       0.0051      0.405      0.013      0.990      -0.789       0.799
C(topic_grouped)[T.Music]                     -0.4765      0.530     -0.899      0.368      -1.515       0.562
C(topic_grouped)[T.Other]                      0.0837      0.434      0.193      0.847      -0.767       0.934
C(topic_grouped)[T.Politics]                  -0.7648      0.455     -1.680      0.093      -1.657       0.127
C(topic_grouped)[T.Science and technology]     0.0957      0.377      0.254      0.799      -0.643       0.834
C(topic_grouped)[T.Sports]                     0.3523      0.470      0.750      0.453      -0.568       1.273
C(answer_type_grouped)[T.Number]               0.2009      0.330      0.610      0.542      -0.445       0.847
C(answer_type_grouped)[T.Other]                0.1246      0.300      0.416      0.678      -0.463       0.712
C(answer_type_grouped)[T.Person]              -0.0440      0.318     -0.139      0.890      -0.667       0.579
q_length                                      -0.4284      0.302     -1.417      0.156      -1.021       0.164
capabilities_entropy                           0.8438      0.261      3.237      0.001       0.333       1.355
game_entropy                                   1.1142      0.242      4.607      0.000       0.640       1.588
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing gemini-2.5-flash-preview-04-17 (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_neutral/gemini-2.5-flash-preview-04-17_SimpleMC_redacted_cor_temp0.0_1751845050_game_data.json', './sc_logs_neutral/gemini-2.5-flash-preview-04-17_SimpleMC_redacted_temp0.0_1751839721_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    374
1    126
Name: count, dtype: int64

Answer change%: 0.2520 [0.21394478690466812, 0.2900552130953319] (n=500)
P-value vs 25%: 0.918; P-value vs 0%: 1.614e-38
Phase 2 self-accuracy: 0.4206 [0.33443802239349496, 0.5068318188763463] (n=126)
P-value vs 25%: 0.0001045; P-value vs 33%: 0.0463

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.01615
Time:                        12:35:51   Log-Likelihood:                -277.70
converged:                       True   LL-Null:                       -282.26
Covariance Type:            nonrobust   LLR p-value:                  0.002529
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.2148      0.115    -10.540      0.000      -1.441      -0.989
game_entropy   333.1888    139.987      2.380      0.017      58.819     607.559
================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.773333
                        1                 0.226667
Geography               0                 0.772727
                        1                 0.227273
Misc                    0                 0.675676
                        1                 0.324324
Music                   0                 0.800000
                        1                 0.200000
Other                   0                 0.788462
                        1                 0.211538
Politics                0                 0.805195
                        1                 0.194805
Science and technology  0                 0.714286
                        1                 0.285714
Sports                  0                 0.675000
                        1                 0.325000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.757396
                     1                 0.242604
Number               0                 0.666667
                     1                 0.333333
Other                0                 0.781955
                     1                 0.218045
Person               0                 0.750000
                     1                 0.250000
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.857143  0.142857           21
                       Number               0.555556  0.444444            9
                       Other                0.777778  0.222222           18
                       Person               0.777778  0.222222           27
Geography              Date                 0.733333  0.266667           15
                       Number               0.722222  0.277778           18
                       Other                0.909091  0.090909           11
Misc                   Date                 0.652174  0.347826           23
                       Number               0.666667  0.333333            9
                       Other                0.629630  0.370370           27
                       Person               0.800000  0.200000           15
Music                  Date                 0.833333  0.166667           12
                       Number               0.500000  0.500000            4
                       Other                0.750000  0.250000           12
                       Person               0.916667  0.083333           12
Other                  Date                 0.722222  0.277778           18
                       Number               0.857143  0.142857            7
                       Other                0.857143  0.142857           14
                       Person               0.769231  0.230769           13
Politics               Date                 0.722222  0.277778           36
                       Number               1.000000  0.000000            6
                       Other                0.950000  0.050000           20
                       Person               0.733333  0.266667           15
Science and technology Date                 0.828571  0.171429           35
                       Number               0.500000  0.500000           14
                       Other                0.789474  0.210526           19
                       Person               0.633333  0.366667           30
Sports                 Date                 0.666667  0.333333            9
                       Number               0.636364  0.363636           11
                       Other                0.666667  0.333333           12
                       Person               0.750000  0.250000            8

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      488
Method:                           MLE   Df Model:                           11
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.01816
Time:                        12:35:51   Log-Likelihood:                -277.14
converged:                       True   LL-Null:                       -282.26
Covariance Type:            nonrobust   LLR p-value:                    0.5079
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -0.5143      1.306     -0.394      0.694      -3.075       2.046
C(topic_grouped)[T.Geography]                 -0.1349      0.470     -0.287      0.774      -1.056       0.786
C(topic_grouped)[T.Misc]                       0.5231      0.375      1.395      0.163      -0.212       1.258
C(topic_grouped)[T.Music]                     -0.1476      0.484     -0.305      0.760      -1.096       0.801
C(topic_grouped)[T.Other]                     -0.0965      0.440     -0.219      0.826      -0.959       0.766
C(topic_grouped)[T.Politics]                  -0.1341      0.407     -0.330      0.742      -0.932       0.663
C(topic_grouped)[T.Science and technology]     0.3078      0.358      0.861      0.389      -0.393       1.009
C(topic_grouped)[T.Sports]                     0.4431      0.441      1.004      0.316      -0.422       1.308
C(answer_type_grouped)[T.Number]               0.4324      0.311      1.392      0.164      -0.176       1.041
C(answer_type_grouped)[T.Other]               -0.1949      0.281     -0.693      0.488      -0.746       0.356
C(answer_type_grouped)[T.Person]              -0.0073      0.284     -0.026      0.979      -0.564       0.549
q_length                                      -0.1622      0.282     -0.576      0.565      -0.714       0.390
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      487
Method:                           MLE   Df Model:                           12
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.03522
Time:                        12:35:51   Log-Likelihood:                -272.32
converged:                       True   LL-Null:                       -282.26
Covariance Type:            nonrobust   LLR p-value:                   0.06931
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -0.6329      1.320     -0.479      0.632      -3.221       1.955
C(topic_grouped)[T.Geography]                 -0.0924      0.473     -0.195      0.845      -1.020       0.835
C(topic_grouped)[T.Misc]                       0.4315      0.384      1.125      0.261      -0.321       1.184
C(topic_grouped)[T.Music]                     -0.1877      0.494     -0.380      0.704      -1.155       0.780
C(topic_grouped)[T.Other]                     -0.1014      0.445     -0.228      0.820      -0.974       0.772
C(topic_grouped)[T.Politics]                  -0.1209      0.410     -0.295      0.768      -0.925       0.683
C(topic_grouped)[T.Science and technology]     0.3511      0.361      0.973      0.330      -0.356       1.058
C(topic_grouped)[T.Sports]                     0.4351      0.445      0.977      0.328      -0.437       1.308
C(answer_type_grouped)[T.Number]               0.4691      0.313      1.500      0.134      -0.144       1.082
C(answer_type_grouped)[T.Other]               -0.2666      0.288     -0.927      0.354      -0.831       0.297
C(answer_type_grouped)[T.Person]               0.0418      0.286      0.146      0.884      -0.519       0.602
q_length                                      -0.1654      0.285     -0.581      0.561      -0.724       0.393
game_entropy                                 360.8089    141.527      2.549      0.011      83.421     638.197
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing gpt-4.1-2025-04-14 (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_neutral/gpt-4.1-2025-04-14_SimpleMC_redacted_cor_temp0.0_1751833247_game_data.json', './sc_logs_neutral/gpt-4.1-2025-04-14_SimpleMC_redacted_temp0.0_1751825599_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    402
1     90
Name: count, dtype: int64

Answer change%: 0.1829 [0.1487655034028868, 0.21708815513369856] (n=492)
P-value vs 25%: 0.000119; P-value vs 0%: 9.088e-26
Phase 2 self-accuracy: 0.3111 [0.2154667903478113, 0.40675543187441093] (n=90)
P-value vs 25%: 0.2105; P-value vs 33%: 0.6538

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  492
Model:                          Logit   Df Residuals:                      490
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1438
Time:                        12:35:51   Log-Likelihood:                -200.44
converged:                       True   LL-Null:                       -234.09
Covariance Type:            nonrobust   LLR p-value:                 2.326e-16
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          2.5541      0.504      5.064      0.000       1.566       3.543
p_i_capability    -4.9487      0.628     -7.874      0.000      -6.180      -3.717
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  492
Model:                          Logit   Df Residuals:                      490
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1575
Time:                        12:35:51   Log-Likelihood:                -197.22
converged:                       True   LL-Null:                       -234.09
Covariance Type:            nonrobust   LLR p-value:                 8.846e-18
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.5909      0.211    -12.301      0.000      -3.004      -2.178
capabilities_entropy     1.7975      0.224      8.038      0.000       1.359       2.236
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.7439 [0.6494, 0.8384] (n=82)
                  P-value vs 33.3%: 1.625e-17

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=-8.38, p=4.55e-14
Wilcoxon delta_p: statistic=1188.00, p=1.46e-15
Mean Δp = -0.1203  [-0.1484, -0.0922]
Idea 1 N = 143; 

  Idea 1.5: Calibration Metrics
  NLL: 2.8516, Signed ECE (overconf pos under neg): -0.0017, ECE: 0.1349 (n=209)
  Brier: 0.0433, Reliability (absolute calibration error; lower better): 0.0369, Resolution (relative calibration quality; higher better): 0.2250, Uncertainty: 0.2314 (n=209)
  AUROC: 1.0000

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.873
Model:                            OLS   Adj. R-squared:                  0.871
Method:                 Least Squares   F-statistic:                     469.5
Date:                Sat, 09 Aug 2025   Prob (F-statistic):           1.55e-91
Time:                        12:35:51   Log-Likelihood:                 132.83
No. Observations:                 209   AIC:                            -257.7
Df Residuals:                     205   BIC:                            -244.3
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.6660      0.049    -13.474      0.000      -0.763      -0.569
p1                    0.6820      0.060     11.315      0.000       0.563       0.801
answer_changed        0.5820      0.077      7.561      0.000       0.430       0.734
p1:answer_changed     0.2332      0.103      2.258      0.025       0.030       0.437
==============================================================================
Omnibus:                       18.550   Durbin-Watson:                   1.928
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               34.169
Skew:                           0.459   Prob(JB):                     3.80e-08
Kurtosis:                       4.756   Cond. No.                         20.5
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=5.98, p=1.75e-08
Wilcoxon delta_H: statistic=2174.00, p=2.06e-09
Mean ΔH = 0.2243  [0.1507, 0.2978]
Paired t-test delta_H Changed: statistic=8.80, p=1.13e-12
Wilcoxon delta_H Changed: statistic=107.00, p=1.79e-10
Mean ΔH Changed = 0.5279  [0.4103, 0.6455]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=8.17, p=3.02e-14
Wilcoxon (p_top2_game vs p_top2_base): statistic=2217.00, p=1.49e-23
Mean Δp_top2 = 0.0430  [0.0327, 0.0533] (n=209)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=9.61, p=2.42e-18
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=3344.00, p=2.91e-18
Mean ΔH_unchosen_baseline_set = 0.3202  [0.2549, 0.3854] (n=209)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  209
Model:                          Logit   Df Residuals:                      206
Method:                           MLE   Df Model:                            2
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.07190
Time:                        12:35:51   Log-Likelihood:                -120.97
converged:                       True   LL-Null:                       -130.34
Covariance Type:            nonrobust   LLR p-value:                 8.515e-05
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.7940      0.220     -3.602      0.000      -1.226      -0.362
p1_z            -0.6875      0.184     -3.742      0.000      -1.047      -0.327
I(p1_z ** 2)    -0.0569      0.170     -0.335      0.738      -0.390       0.276
================================================================================
AUC = 0.681

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  492
Model:                          Logit   Df Residuals:                      490
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1541
Time:                        12:35:51   Log-Likelihood:                -198.02
converged:                       True   LL-Null:                       -234.09
Covariance Type:            nonrobust   LLR p-value:                 1.986e-17
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -2.2540      0.172    -13.126      0.000      -2.591      -1.917
game_entropy     2.3245      0.288      8.061      0.000       1.759       2.890
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=11779.00, p=7.29e-30
Paired t-test (game_entropy vs capabilities_entropy): statistic=-11.00, p=2.56e-25
Mean capabilities_entropy-game_entropy = 0.2186  [0.1797, 0.2576] (n=492)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  492
Model:                          Logit   Df Residuals:                      489
Method:                           MLE   Df Model:                            2
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1986
Time:                        12:35:51   Log-Likelihood:                -187.61
converged:                       True   LL-Null:                       -234.09
Covariance Type:            nonrobust   LLR p-value:                 6.515e-21
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.7143      0.219    -12.386      0.000      -3.144      -2.285
capabilities_entropy     1.1986      0.264      4.547      0.000       0.682       1.715
game_entropy             1.4971      0.342      4.376      0.000       0.827       2.168
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': None
topic_grouped           answer_changed
Art                     0                 0.864865
                        1                 0.135135
Geography               0                 0.790698
                        1                 0.209302
Misc                    0                 0.756757
                        1                 0.243243
Music                   0                 0.900000
                        1                 0.100000
Other                   0                 0.784314
                        1                 0.215686
Politics                0                 0.840000
                        1                 0.160000
Science and technology  0                 0.802083
                        1                 0.197917
Sports                  0                 0.820513
                        1                 0.179487
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.781818
                     1                 0.218182
Number               0                 0.766234
                     1                 0.233766
Other                0                 0.868687
                     1                 0.131313
Person               0                 0.830508
                     1                 0.169492
Place                0                 0.909091
                     1                 0.090909
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.800000  0.200000           20
                       Number               0.666667  0.333333            9
                       Other                0.923077  0.076923           13
                       Person               0.925926  0.074074           27
                       Place                1.000000  0.000000            5
Geography              Date                 0.642857  0.357143           14
                       Number               0.833333  0.166667           18
                       Other                1.000000  0.000000            3
                       Place                0.875000  0.125000            8
Misc                   Date                 0.739130  0.260870           23
                       Number               0.888889  0.111111            9
                       Other                0.760000  0.240000           25
                       Person               0.666667  0.333333           15
                       Place                1.000000  0.000000            2
Music                  Date                 1.000000  0.000000           12
                       Number               0.500000  0.500000            4
                       Other                0.800000  0.200000           10
                       Person               1.000000  0.000000           12
                       Place                1.000000  0.000000            2
Other                  Date                 0.666667  0.333333           18
                       Number               0.714286  0.285714            7
                       Other                0.888889  0.111111            9
                       Person               0.833333  0.166667           12
                       Place                1.000000  0.000000            5
Politics               Date                 0.800000  0.200000           35
                       Number               0.833333  0.166667            6
                       Other                0.928571  0.071429           14
                       Person               0.785714  0.214286           14
                       Place                1.000000  0.000000            6
Science and technology Date                 0.852941  0.147059           34
                       Number               0.714286  0.285714           14
                       Other                0.933333  0.066667           15
                       Person               0.766667  0.233333           30
                       Place                0.333333  0.666667            3
Sports                 Date                 0.666667  0.333333            9
                       Number               0.800000  0.200000           10
                       Other                0.900000  0.100000           10
                       Person               0.875000  0.125000            8
                       Place                1.000000  0.000000            2

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  492
Model:                          Logit   Df Residuals:                      479
Method:                           MLE   Df Model:                           12
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.03861
Time:                        12:35:51   Log-Likelihood:                -225.06
converged:                       True   LL-Null:                       -234.09
Covariance Type:            nonrobust   LLR p-value:                    0.1134
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      1.7671      1.521      1.162      0.245      -1.213       4.747
C(topic_grouped)[T.Geography]                  0.3834      0.530      0.723      0.470      -0.656       1.422
C(topic_grouped)[T.Misc]                       0.7758      0.443      1.751      0.080      -0.092       1.644
C(topic_grouped)[T.Music]                     -0.3580      0.632     -0.567      0.571      -1.596       0.880
C(topic_grouped)[T.Other]                      0.5314      0.489      1.088      0.277      -0.426       1.489
C(topic_grouped)[T.Politics]                   0.3123      0.475      0.658      0.511      -0.618       1.243
C(topic_grouped)[T.Science and technology]     0.4563      0.431      1.058      0.290      -0.389       1.301
C(topic_grouped)[T.Sports]                     0.3187      0.546      0.583      0.560      -0.752       1.390
C(answer_type_grouped)[T.Number]               0.0911      0.342      0.266      0.790      -0.579       0.762
C(answer_type_grouped)[T.Other]               -0.7254      0.362     -2.005      0.045      -1.434      -0.016
C(answer_type_grouped)[T.Person]              -0.3504      0.320     -1.094      0.274      -0.978       0.278
C(answer_type_grouped)[T.Place]               -1.0371      0.644     -1.611      0.107      -2.299       0.224
q_length                                      -0.7533      0.330     -2.286      0.022      -1.399      -0.107
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.4489
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  492
Model:                          Logit   Df Residuals:                      478
Method:                           MLE   Df Model:                           13
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1822
Time:                        12:35:51   Log-Likelihood:                -191.45
converged:                       True   LL-Null:                       -234.09
Covariance Type:            nonrobust   LLR p-value:                 1.104e-12
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -0.2424      1.693     -0.143      0.886      -3.561       3.076
C(topic_grouped)[T.Geography]                  0.3398      0.573      0.593      0.553      -0.782       1.462
C(topic_grouped)[T.Misc]                       0.7206      0.484      1.489      0.136      -0.228       1.669
C(topic_grouped)[T.Music]                     -0.4467      0.677     -0.660      0.509      -1.773       0.879
C(topic_grouped)[T.Other]                      0.6286      0.535      1.175      0.240      -0.420       1.677
C(topic_grouped)[T.Politics]                   0.4650      0.514      0.905      0.365      -0.542       1.472
C(topic_grouped)[T.Science and technology]     0.3762      0.470      0.801      0.423      -0.545       1.297
C(topic_grouped)[T.Sports]                     0.6555      0.588      1.116      0.265      -0.496       1.807
C(answer_type_grouped)[T.Number]               0.3320      0.371      0.894      0.371      -0.396       1.060
C(answer_type_grouped)[T.Other]               -0.2352      0.408     -0.576      0.564      -1.035       0.565
C(answer_type_grouped)[T.Person]               0.3843      0.366      1.050      0.294      -0.333       1.102
C(answer_type_grouped)[T.Place]               -0.2400      0.683     -0.351      0.725      -1.579       1.099
q_length                                      -0.6397      0.366     -1.750      0.080      -1.356       0.077
capabilities_entropy                           1.8472      0.241      7.654      0.000       1.374       2.320
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  492
Model:                          Logit   Df Residuals:                      478
Method:                           MLE   Df Model:                           13
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1845
Time:                        12:35:51   Log-Likelihood:                -190.91
converged:                       True   LL-Null:                       -234.09
Covariance Type:            nonrobust   LLR p-value:                 6.903e-13
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      0.3778      1.668      0.226      0.821      -2.892       3.648
C(topic_grouped)[T.Geography]                  0.1636      0.584      0.280      0.779      -0.981       1.309
C(topic_grouped)[T.Misc]                       0.7439      0.477      1.561      0.119      -0.190       1.678
C(topic_grouped)[T.Music]                     -0.9736      0.720     -1.351      0.177      -2.386       0.438
C(topic_grouped)[T.Other]                      0.3431      0.543      0.632      0.528      -0.722       1.408
C(topic_grouped)[T.Politics]                   0.2942      0.512      0.575      0.565      -0.709       1.297
C(topic_grouped)[T.Science and technology]     0.1851      0.475      0.390      0.697      -0.746       1.116
C(topic_grouped)[T.Sports]                     0.2040      0.588      0.347      0.729      -0.949       1.357
C(answer_type_grouped)[T.Number]               0.1244      0.376      0.331      0.741      -0.612       0.860
C(answer_type_grouped)[T.Other]               -0.4734      0.405     -1.170      0.242      -1.267       0.320
C(answer_type_grouped)[T.Person]               0.1474      0.361      0.408      0.683      -0.561       0.856
C(answer_type_grouped)[T.Place]               -0.6140      0.692     -0.887      0.375      -1.971       0.743
q_length                                      -0.6293      0.360     -1.749      0.080      -1.335       0.076
game_entropy                                   2.3955      0.307      7.792      0.000       1.793       2.998
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  492
Model:                          Logit   Df Residuals:                      477
Method:                           MLE   Df Model:                           14
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.2281
Time:                        12:35:51   Log-Likelihood:                -180.69
converged:                       True   LL-Null:                       -234.09
Covariance Type:            nonrobust   LLR p-value:                 2.319e-16
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -0.4259      1.737     -0.245      0.806      -3.831       2.979
C(topic_grouped)[T.Geography]                  0.1950      0.600      0.325      0.745      -0.980       1.370
C(topic_grouped)[T.Misc]                       0.7564      0.494      1.531      0.126      -0.212       1.725
C(topic_grouped)[T.Music]                     -0.9205      0.735     -1.252      0.211      -2.362       0.521
C(topic_grouped)[T.Other]                      0.5261      0.556      0.947      0.344      -0.563       1.615
C(topic_grouped)[T.Politics]                   0.4424      0.525      0.842      0.400      -0.587       1.472
C(topic_grouped)[T.Science and technology]     0.2448      0.488      0.501      0.616      -0.712       1.202
C(topic_grouped)[T.Sports]                     0.4927      0.605      0.815      0.415      -0.692       1.678
C(answer_type_grouped)[T.Number]               0.2457      0.384      0.640      0.522      -0.507       0.998
C(answer_type_grouped)[T.Other]               -0.2749      0.427     -0.644      0.519      -1.111       0.561
C(answer_type_grouped)[T.Person]               0.4758      0.378      1.258      0.209      -0.266       1.217
C(answer_type_grouped)[T.Place]               -0.2732      0.706     -0.387      0.699      -1.657       1.111
q_length                                      -0.6174      0.375     -1.647      0.100      -1.352       0.117
capabilities_entropy                           1.2407      0.277      4.486      0.000       0.699       1.783
game_entropy                                   1.6264      0.352      4.615      0.000       0.936       2.317
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing gpt-4o-2024-08-06 (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_neutral/gpt-4o-2024-08-06_SimpleMC_redacted_cor_temp0.0_1751845435_game_data.json', './sc_logs_neutral/gpt-4o-2024-08-06_SimpleMC_redacted_temp0.0_1751827128_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    391
1    109
Name: count, dtype: int64

Answer change%: 0.2180 [0.18180948925708143, 0.25419051074291854] (n=500)
P-value vs 25%: 0.08309; P-value vs 0%: 3.626e-32
Phase 2 self-accuracy: 0.3670 [0.27649033257005706, 0.45745462155838335] (n=109)
P-value vs 25%: 0.01128; P-value vs 33%: 0.4618

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.07467
Time:                        12:35:51   Log-Likelihood:                -242.61
converged:                       True   LL-Null:                       -262.18
Covariance Type:            nonrobust   LLR p-value:                 3.920e-10
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          0.4455      0.293      1.521      0.128      -0.129       1.020
p_i_capability    -2.5750      0.428     -6.022      0.000      -3.413      -1.737
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1991
Time:                        12:35:51   Log-Likelihood:                -209.99
converged:                       True   LL-Null:                       -262.18
Covariance Type:            nonrobust   LLR p-value:                 1.666e-24
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -3.4546      0.327    -10.557      0.000      -4.096      -2.813
capabilities_entropy     2.0711      0.246      8.434      0.000       1.590       2.552
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.7523 [0.6713, 0.8333] (n=109)
                  P-value vs 33.3%: 3.957e-24

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=-6.62, p=1.32e-10
Wilcoxon delta_p: statistic=19000.00, p=2.07e-11
Mean Δp = -0.0453  [-0.0587, -0.0319]
Idea 1 N = 358; 

  Idea 1.5: Calibration Metrics
  NLL: 1.7392, Signed ECE (overconf pos under neg): -0.0210, ECE: 0.1280 (n=465)
  Brier: 0.0594, Reliability (absolute calibration error; lower better): 0.0318, Resolution (relative calibration quality; higher better): 0.2219, Uncertainty: 0.2496 (n=465)
  AUROC: 0.9961

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.719
Model:                            OLS   Adj. R-squared:                  0.717
Method:                 Least Squares   F-statistic:                     393.4
Date:                Sat, 09 Aug 2025   Prob (F-statistic):          1.14e-126
Time:                        12:35:51   Log-Likelihood:                 339.44
No. Observations:                 465   AIC:                            -670.9
Df Residuals:                     461   BIC:                            -654.3
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.3036      0.025    -12.030      0.000      -0.353      -0.254
p1                    0.3263      0.031     10.558      0.000       0.266       0.387
answer_changed        0.0715      0.049      1.468      0.143      -0.024       0.167
p1:answer_changed     0.6730      0.077      8.728      0.000       0.521       0.825
==============================================================================
Omnibus:                       15.476   Durbin-Watson:                   1.785
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               23.339
Skew:                           0.261   Prob(JB):                     8.55e-06
Kurtosis:                       3.965   Cond. No.                         21.7
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=1.93, p=0.0542
Wilcoxon delta_H: statistic=27733.00, p=0.0248
Mean ΔH = 0.0414  [-0.0006, 0.0835]
Paired t-test delta_H Changed: statistic=9.37, p=1.49e-15
Wilcoxon delta_H Changed: statistic=337.00, p=3.41e-15
Mean ΔH Changed = 0.3404  [0.2692, 0.4116]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=8.06, p=6.47e-15
Wilcoxon (p_top2_game vs p_top2_base): statistic=29688.00, p=3.04e-17
Mean Δp_top2 = 0.0259  [0.0196, 0.0322] (n=465)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=5.68, p=2.34e-08
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=36841.00, p=3.28e-09
Mean ΔH_unchosen_baseline_set = 0.1102  [0.0722, 0.1482] (n=465)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  465
Model:                          Logit   Df Residuals:                      462
Method:                           MLE   Df Model:                            2
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1963
Time:                        12:35:51   Log-Likelihood:                -201.58
converged:                       True   LL-Null:                       -250.82
Covariance Type:            nonrobust   LLR p-value:                 4.101e-22
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.4425      0.186     -7.746      0.000      -1.807      -1.077
p1_z            -1.3748      0.193     -7.120      0.000      -1.753      -0.996
I(p1_z ** 2)    -0.2220      0.170     -1.307      0.191      -0.555       0.111
================================================================================
AUC = 0.799

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1705
Time:                        12:35:51   Log-Likelihood:                -217.47
converged:                       True   LL-Null:                       -262.18
Covariance Type:            nonrobust   LLR p-value:                 3.182e-21
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -2.8948      0.259    -11.196      0.000      -3.402      -2.388
game_entropy     1.8603      0.223      8.354      0.000       1.424       2.297
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=34445.00, p=2.83e-18
Paired t-test (game_entropy vs capabilities_entropy): statistic=-8.96, p=6.69e-18
Mean capabilities_entropy-game_entropy = 0.1392  [0.1088, 0.1697] (n=500)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      497
Method:                           MLE   Df Model:                            2
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.2065
Time:                        12:35:51   Log-Likelihood:                -208.05
converged:                       True   LL-Null:                       -262.18
Covariance Type:            nonrobust   LLR p-value:                 3.085e-24
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -3.4902      0.329    -10.606      0.000      -4.135      -2.845
capabilities_entropy     1.5443      0.362      4.269      0.000       0.835       2.253
game_entropy             0.6687      0.343      1.947      0.052      -0.004       1.342
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.733333
                        1                 0.266667
Geography               0                 0.772727
                        1                 0.227273
Misc                    0                 0.743243
                        1                 0.256757
Music                   0                 0.800000
                        1                 0.200000
Other                   0                 0.807692
                        1                 0.192308
Politics                0                 0.766234
                        1                 0.233766
Science and technology  0                 0.806122
                        1                 0.193878
Sports                  0                 0.875000
                        1                 0.125000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.727811
                     1                 0.272189
Number               0                 0.769231
                     1                 0.230769
Other                0                 0.827068
                     1                 0.172932
Person               0                 0.816667
                     1                 0.183333
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.476190  0.523810           21
                       Number               0.777778  0.222222            9
                       Other                0.833333  0.166667           18
                       Person               0.851852  0.148148           27
Geography              Date                 0.800000  0.200000           15
                       Number               0.666667  0.333333           18
                       Other                0.909091  0.090909           11
Misc                   Date                 0.695652  0.304348           23
                       Number               0.888889  0.111111            9
                       Other                0.814815  0.185185           27
                       Person               0.600000  0.400000           15
Music                  Date                 0.833333  0.166667           12
                       Number               1.000000  0.000000            4
                       Other                0.750000  0.250000           12
                       Person               0.750000  0.250000           12
Other                  Date                 0.833333  0.166667           18
                       Number               0.714286  0.285714            7
                       Other                0.785714  0.214286           14
                       Person               0.846154  0.153846           13
Politics               Date                 0.638889  0.361111           36
                       Number               0.833333  0.166667            6
                       Other                0.900000  0.100000           20
                       Person               0.866667  0.133333           15
Science and technology Date                 0.857143  0.142857           35
                       Number               0.642857  0.357143           14
                       Other                0.789474  0.210526           19
                       Person               0.833333  0.166667           30
Sports                 Date                 0.777778  0.222222            9
                       Number               0.909091  0.090909           11
                       Other                0.833333  0.166667           12
                       Person               1.000000  0.000000            8

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      488
Method:                           MLE   Df Model:                           11
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.02262
Time:                        12:35:51   Log-Likelihood:                -256.25
converged:                       True   LL-Null:                       -262.18
Covariance Type:            nonrobust   LLR p-value:                    0.3743
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                      0.9810      1.390      0.706      0.480      -1.744       3.706
C(topic_grouped)[T.Geography]                 -0.3762      0.462     -0.814      0.416      -1.282       0.530
C(topic_grouped)[T.Misc]                      -0.0534      0.378     -0.141      0.888      -0.795       0.688
C(topic_grouped)[T.Music]                     -0.3966      0.478     -0.830      0.406      -1.333       0.539
C(topic_grouped)[T.Other]                     -0.4833      0.443     -1.091      0.275      -1.351       0.385
C(topic_grouped)[T.Politics]                  -0.1840      0.387     -0.476      0.634      -0.942       0.574
C(topic_grouped)[T.Science and technology]    -0.4448      0.370     -1.203      0.229      -1.169       0.280
C(topic_grouped)[T.Sports]                    -0.9671      0.551     -1.756      0.079      -2.047       0.113
C(answer_type_grouped)[T.Number]              -0.1463      0.330     -0.443      0.658      -0.794       0.501
C(answer_type_grouped)[T.Other]               -0.6248      0.292     -2.138      0.033      -1.198      -0.052
C(answer_type_grouped)[T.Person]              -0.5642      0.301     -1.877      0.061      -1.153       0.025
q_length                                      -0.3675      0.302     -1.219      0.223      -0.958       0.223
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.8282
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      487
Method:                           MLE   Df Model:                           12
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.2167
Time:                        12:35:51   Log-Likelihood:                -205.38
converged:                       True   LL-Null:                       -262.18
Covariance Type:            nonrobust   LLR p-value:                 1.156e-18
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -2.1048      1.635     -1.287      0.198      -5.310       1.100
C(topic_grouped)[T.Geography]                 -0.6042      0.517     -1.168      0.243      -1.618       0.409
C(topic_grouped)[T.Misc]                      -0.2241      0.430     -0.522      0.602      -1.066       0.618
C(topic_grouped)[T.Music]                     -0.3993      0.547     -0.730      0.466      -1.472       0.673
C(topic_grouped)[T.Other]                     -0.6122      0.496     -1.234      0.217      -1.585       0.361
C(topic_grouped)[T.Politics]                  -0.3270      0.442     -0.740      0.459      -1.193       0.539
C(topic_grouped)[T.Science and technology]    -0.6303      0.418     -1.507      0.132      -1.450       0.190
C(topic_grouped)[T.Sports]                    -1.0521      0.608     -1.730      0.084      -2.244       0.140
C(answer_type_grouped)[T.Number]              -0.1797      0.359     -0.500      0.617      -0.884       0.524
C(answer_type_grouped)[T.Other]                0.1057      0.336      0.315      0.753      -0.553       0.765
C(answer_type_grouped)[T.Person]               0.4145      0.362      1.146      0.252      -0.294       1.123
q_length                                      -0.2595      0.347     -0.748      0.455      -0.939       0.421
capabilities_entropy                           2.2193      0.265      8.363      0.000       1.699       2.739
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      487
Method:                           MLE   Df Model:                           12
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1889
Time:                        12:35:51   Log-Likelihood:                -212.64
converged:                       True   LL-Null:                       -262.18
Covariance Type:            nonrobust   LLR p-value:                 8.443e-16
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -1.1995      1.579     -0.760      0.447      -4.294       1.895
C(topic_grouped)[T.Geography]                 -0.5223      0.504     -1.035      0.300      -1.511       0.466
C(topic_grouped)[T.Misc]                      -0.1153      0.417     -0.276      0.782      -0.933       0.703
C(topic_grouped)[T.Music]                     -0.3294      0.539     -0.611      0.541      -1.385       0.726
C(topic_grouped)[T.Other]                     -0.5290      0.480     -1.102      0.270      -1.470       0.412
C(topic_grouped)[T.Politics]                  -0.1186      0.427     -0.278      0.781      -0.955       0.718
C(topic_grouped)[T.Science and technology]    -0.5935      0.413     -1.439      0.150      -1.402       0.215
C(topic_grouped)[T.Sports]                    -0.9004      0.598     -1.505      0.132      -2.073       0.272
C(answer_type_grouped)[T.Number]              -0.3674      0.358     -1.026      0.305      -1.069       0.335
C(answer_type_grouped)[T.Other]               -0.2018      0.329     -0.613      0.540      -0.847       0.443
C(answer_type_grouped)[T.Person]               0.2382      0.348      0.685      0.493      -0.443       0.919
q_length                                      -0.3151      0.340     -0.927      0.354      -0.981       0.351
game_entropy                                   1.9861      0.241      8.234      0.000       1.513       2.459
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      486
Method:                           MLE   Df Model:                           13
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.2268
Time:                        12:35:51   Log-Likelihood:                -202.71
converged:                       True   LL-Null:                       -262.18
Covariance Type:            nonrobust   LLR p-value:                 3.250e-19
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -2.1448      1.647     -1.302      0.193      -5.373       1.084
C(topic_grouped)[T.Geography]                 -0.6085      0.518     -1.175      0.240      -1.624       0.407
C(topic_grouped)[T.Misc]                      -0.2002      0.430     -0.466      0.641      -1.042       0.642
C(topic_grouped)[T.Music]                     -0.3648      0.554     -0.658      0.510      -1.451       0.721
C(topic_grouped)[T.Other]                     -0.5906      0.495     -1.193      0.233      -1.561       0.379
C(topic_grouped)[T.Politics]                  -0.2626      0.442     -0.594      0.552      -1.129       0.603
C(topic_grouped)[T.Science and technology]    -0.6433      0.422     -1.526      0.127      -1.470       0.183
C(topic_grouped)[T.Sports]                    -1.0164      0.612     -1.660      0.097      -2.216       0.184
C(answer_type_grouped)[T.Number]              -0.2733      0.365     -0.749      0.454      -0.988       0.442
C(answer_type_grouped)[T.Other]                0.0643      0.340      0.189      0.850      -0.603       0.732
C(answer_type_grouped)[T.Person]               0.4816      0.364      1.321      0.186      -0.233       1.196
q_length                                      -0.2698      0.350     -0.771      0.441      -0.956       0.416
capabilities_entropy                           1.6150      0.370      4.362      0.000       0.889       2.341
game_entropy                                   0.8032      0.352      2.284      0.022       0.114       1.492
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.

--- Analyzing grok-3-latest (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_neutral/grok-3-latest_SimpleMC_redacted_cor_temp0.0_1751833664_game_data.json', './sc_logs_neutral/grok-3-latest_SimpleMC_redacted_temp0.0_1751826103_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    411
1     89
Name: count, dtype: int64

Answer change%: 0.1780 [0.1444718957049856, 0.2115281042950144] (n=500)
P-value vs 25%: 2.566e-05; P-value vs 0%: 2.343e-25
Phase 2 self-accuracy: 0.4270 [0.32420253657802284, 0.5297300476916401] (n=89)
P-value vs 25%: 0.0007376; P-value vs 33%: 0.07311

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.2074
Time:                        12:35:51   Log-Likelihood:                -185.61
converged:                       True   LL-Null:                       -234.17
Covariance Type:            nonrobust   LLR p-value:                 6.514e-23
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          3.7402      0.585      6.398      0.000       2.594       4.886
p_i_capability    -6.3800      0.720     -8.863      0.000      -7.791      -4.969
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.2575
Time:                        12:35:51   Log-Likelihood:                -173.88
converged:                       True   LL-Null:                       -234.17
Covariance Type:            nonrobust   LLR p-value:                 4.698e-28
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -3.2294      0.261    -12.350      0.000      -3.742      -2.717
capabilities_entropy     2.8359      0.299      9.472      0.000       2.249       3.423
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.7079 [0.6134, 0.8023] (n=89)
                  P-value vs 33.3%: 7.853e-15

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=-4.06, p=5.79e-05
Wilcoxon delta_p: statistic=23285.00, p=1.04e-14
Mean Δp = -0.0257  [-0.0381, -0.0133]
Idea 1 N = 408; 

  Idea 1.5: Calibration Metrics
  NLL: 2.1840, Signed ECE (overconf pos under neg): -0.0143, ECE: 0.0634 (n=497)
  Brier: 0.0232, Reliability (absolute calibration error; lower better): 0.0147, Resolution (relative calibration quality; higher better): 0.2341, Uncertainty: 0.2423 (n=497)
  AUROC: 0.9996

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.809
Model:                            OLS   Adj. R-squared:                  0.807
Method:                 Least Squares   F-statistic:                     693.9
Date:                Sat, 09 Aug 2025   Prob (F-statistic):          1.76e-176
Time:                        12:35:51   Log-Likelihood:                 355.83
No. Observations:                 497   AIC:                            -703.7
Df Residuals:                     493   BIC:                            -686.8
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.5624      0.043    -13.163      0.000      -0.646      -0.478
p1                    0.5828      0.046     12.682      0.000       0.492       0.673
answer_changed        0.3148      0.068      4.620      0.000       0.181       0.449
p1:answer_changed     0.5521      0.087      6.345      0.000       0.381       0.723
==============================================================================
Omnibus:                      106.513   Durbin-Watson:                   2.160
Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1248.031
Skew:                           0.540   Prob(JB):                    9.85e-272
Kurtosis:                      10.688   Cond. No.                         29.7
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-3.59, p=0.000368
Wilcoxon delta_H: statistic=33156.00, p=0.000328
Mean ΔH = -0.0920  [-0.1422, -0.0418]
Paired t-test delta_H Changed: statistic=4.75, p=7.74e-06
Wilcoxon delta_H Changed: statistic=851.00, p=2.46e-06
Mean ΔH Changed = 0.2212  [0.1300, 0.3125]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=4.81, p=2.01e-06
Wilcoxon (p_top2_game vs p_top2_base): statistic=36812.00, p=5.09e-15
Mean Δp_top2 = 0.0101  [0.0060, 0.0142] (n=497)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=-1.55, p=0.123
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=57319.00, p=0.155
Mean ΔH_unchosen_baseline_set = -0.0359  [-0.0814, 0.0096] (n=497)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  497
Model:                          Logit   Df Residuals:                      494
Method:                           MLE   Df Model:                            2
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.2835
Time:                        12:35:51   Log-Likelihood:                -167.37
converged:                       True   LL-Null:                       -233.58
Covariance Type:            nonrobust   LLR p-value:                 1.745e-29
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.7223      0.178     -9.665      0.000      -2.072      -1.373
p1_z            -1.9223      0.256     -7.515      0.000      -2.424      -1.421
I(p1_z ** 2)    -0.4160      0.125     -3.319      0.001      -0.662      -0.170
================================================================================
AUC = 0.867

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      498
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1982
Time:                        12:35:51   Log-Likelihood:                -187.75
converged:                       True   LL-Null:                       -234.17
Covariance Type:            nonrobust   LLR p-value:                 5.648e-22
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -2.6023      0.199    -13.083      0.000      -2.992      -2.212
game_entropy     2.6417      0.296      8.937      0.000       2.062       3.221
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=32740.00, p=2.34e-20
Paired t-test (game_entropy vs capabilities_entropy): statistic=-7.81, p=3.33e-14
Mean capabilities_entropy-game_entropy = 0.1356  [0.1016, 0.1696] (n=500)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      497
Method:                           MLE   Df Model:                            2
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.2974
Time:                        12:35:51   Log-Likelihood:                -164.52
converged:                       True   LL-Null:                       -234.17
Covariance Type:            nonrobust   LLR p-value:                 5.625e-31
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -3.4713      0.283    -12.256      0.000      -4.026      -2.916
capabilities_entropy     2.1985      0.336      6.543      0.000       1.540       2.857
game_entropy             1.4837      0.346      4.288      0.000       0.806       2.162
========================================================================================
                  Grouped rare topic into 'Misc'/'Other': ['TV shows', 'History', 'Video games']
                  Grouped rare answer_type into 'Misc'/'Other': ['Place']
topic_grouped           answer_changed
Art                     0                 0.866667
                        1                 0.133333
Geography               0                 0.818182
                        1                 0.181818
Misc                    0                 0.837838
                        1                 0.162162
Music                   0                 0.875000
                        1                 0.125000
Other                   0                 0.826923
                        1                 0.173077
Politics                0                 0.844156
                        1                 0.155844
Science and technology  0                 0.755102
                        1                 0.244898
Sports                  0                 0.775000
                        1                 0.225000
Name: proportion, dtype: float64

answer_type_grouped  answer_changed
Date                 0                 0.846154
                     1                 0.153846
Number               0                 0.794872
                     1                 0.205128
Other                0                 0.834586
                     1                 0.165414
Person               0                 0.791667
                     1                 0.208333
Name: proportion, dtype: float64

                  topic+answer_type By answer_changed:

answer_changed                                     0         1  total_count
topic_grouped          answer_type_grouped                                 
Art                    Date                 0.904762  0.095238           21
                       Number               0.888889  0.111111            9
                       Other                0.944444  0.055556           18
                       Person               0.777778  0.222222           27
Geography              Date                 0.933333  0.066667           15
                       Number               0.833333  0.166667           18
                       Other                0.636364  0.363636           11
Misc                   Date                 0.956522  0.043478           23
                       Number               0.888889  0.111111            9
                       Other                0.777778  0.222222           27
                       Person               0.733333  0.266667           15
Music                  Date                 0.916667  0.083333           12
                       Number               1.000000  0.000000            4
                       Other                0.833333  0.166667           12
                       Person               0.833333  0.166667           12
Other                  Date                 0.777778  0.222222           18
                       Number               0.714286  0.285714            7
                       Other                0.928571  0.071429           14
                       Person               0.846154  0.153846           13
Politics               Date                 0.833333  0.166667           36
                       Number               1.000000  0.000000            6
                       Other                0.800000  0.200000           20
                       Person               0.866667  0.133333           15
Science and technology Date                 0.742857  0.257143           35
                       Number               0.500000  0.500000           14
                       Other                0.947368  0.052632           19
                       Person               0.766667  0.233333           30
Sports                 Date                 0.777778  0.222222            9
                       Number               0.818182  0.181818           11
                       Other                0.750000  0.250000           12
                       Person               0.750000  0.250000            8

                  Model 4 (No Interactions): answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      488
Method:                           MLE   Df Model:                           11
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.01779
Time:                        12:35:51   Log-Likelihood:                -230.01
converged:                       True   LL-Null:                       -234.17
Covariance Type:            nonrobust   LLR p-value:                    0.6831
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -3.4099      1.468     -2.323      0.020      -6.286      -0.533
C(topic_grouped)[T.Geography]                  0.4463      0.538      0.829      0.407      -0.608       1.501
C(topic_grouped)[T.Misc]                       0.2752      0.468      0.588      0.556      -0.642       1.192
C(topic_grouped)[T.Music]                     -0.0336      0.588     -0.057      0.954      -1.187       1.120
C(topic_grouped)[T.Other]                      0.3559      0.502      0.708      0.479      -0.629       1.341
C(topic_grouped)[T.Politics]                   0.1997      0.473      0.423      0.673      -0.727       1.126
C(topic_grouped)[T.Science and technology]     0.7463      0.416      1.795      0.073      -0.069       1.561
C(topic_grouped)[T.Sports]                     0.6497      0.515      1.261      0.207      -0.360       1.660
C(answer_type_grouped)[T.Number]               0.2840      0.365      0.777      0.437      -0.432       1.000
C(answer_type_grouped)[T.Other]                0.1333      0.321      0.415      0.678      -0.496       0.762
C(answer_type_grouped)[T.Person]               0.4187      0.319      1.313      0.189      -0.206       1.044
q_length                                       0.2924      0.311      0.939      0.348      -0.318       0.903
==============================================================================================================

                  Model 4.6: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy
Mean capabilities_entropy = 0.4188
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      487
Method:                           MLE   Df Model:                           12
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.2742
Time:                        12:35:51   Log-Likelihood:                -169.96
converged:                       True   LL-Null:                       -234.17
Covariance Type:            nonrobust   LLR p-value:                 1.278e-21
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -4.9877      1.716     -2.906      0.004      -8.351      -1.624
C(topic_grouped)[T.Geography]                  0.7558      0.632      1.196      0.232      -0.483       1.994
C(topic_grouped)[T.Misc]                       0.1037      0.550      0.188      0.851      -0.975       1.183
C(topic_grouped)[T.Music]                      0.0724      0.690      0.105      0.916      -1.281       1.426
C(topic_grouped)[T.Other]                      0.1457      0.594      0.245      0.806      -1.019       1.311
C(topic_grouped)[T.Politics]                   0.6810      0.555      1.227      0.220      -0.407       1.769
C(topic_grouped)[T.Science and technology]     0.7081      0.493      1.435      0.151      -0.259       1.675
C(topic_grouped)[T.Sports]                     0.7678      0.615      1.249      0.212      -0.437       1.973
C(answer_type_grouped)[T.Number]               0.3036      0.426      0.713      0.476      -0.531       1.138
C(answer_type_grouped)[T.Other]                0.1520      0.382      0.398      0.690      -0.596       0.900
C(answer_type_grouped)[T.Person]               0.5295      0.383      1.383      0.167      -0.221       1.280
q_length                                       0.2347      0.359      0.654      0.513      -0.469       0.938
capabilities_entropy                           2.8978      0.309      9.375      0.000       2.292       3.504
==============================================================================================================

                  Model 4.8: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      487
Method:                           MLE   Df Model:                           12
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.2132
Time:                        12:35:51   Log-Likelihood:                -184.25
converged:                       True   LL-Null:                       -234.17
Covariance Type:            nonrobust   LLR p-value:                 5.967e-16
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -3.4858      1.621     -2.150      0.032      -6.663      -0.308
C(topic_grouped)[T.Geography]                  0.0391      0.588      0.067      0.947      -1.113       1.192
C(topic_grouped)[T.Misc]                      -0.1230      0.533     -0.231      0.818      -1.168       0.922
C(topic_grouped)[T.Music]                     -0.0718      0.647     -0.111      0.912      -1.341       1.197
C(topic_grouped)[T.Other]                      0.0429      0.561      0.076      0.939      -1.057       1.143
C(topic_grouped)[T.Politics]                   0.1465      0.527      0.278      0.781      -0.887       1.180
C(topic_grouped)[T.Science and technology]     0.4597      0.465      0.988      0.323      -0.452       1.372
C(topic_grouped)[T.Sports]                     0.5130      0.571      0.898      0.369      -0.607       1.633
C(answer_type_grouped)[T.Number]               0.5717      0.414      1.380      0.168      -0.241       1.384
C(answer_type_grouped)[T.Other]                0.3209      0.371      0.865      0.387      -0.406       1.048
C(answer_type_grouped)[T.Person]               0.5985      0.371      1.614      0.107      -0.128       1.325
q_length                                       0.0821      0.344      0.239      0.811      -0.591       0.756
game_entropy                                   2.6906      0.305      8.824      0.000       2.093       3.288
==============================================================================================================

                  Model 4.95: answer_changed ~ C(topic_grouped) + C(answer_type_grouped) + q_length + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  500
Model:                          Logit   Df Residuals:                      486
Method:                           MLE   Df Model:                           13
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.3125
Time:                        12:35:51   Log-Likelihood:                -160.99
converged:                       True   LL-Null:                       -234.17
Covariance Type:            nonrobust   LLR p-value:                 1.109e-24
==============================================================================================================
                                                 coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------
Intercept                                     -4.7406      1.768     -2.681      0.007      -8.207      -1.274
C(topic_grouped)[T.Geography]                  0.5637      0.637      0.885      0.376      -0.685       1.812
C(topic_grouped)[T.Misc]                       0.0287      0.561      0.051      0.959      -1.071       1.128
C(topic_grouped)[T.Music]                      0.0370      0.720      0.051      0.959      -1.375       1.449
C(topic_grouped)[T.Other]                     -0.0009      0.607     -0.002      0.999      -1.190       1.189
C(topic_grouped)[T.Politics]                   0.5303      0.571      0.929      0.353      -0.588       1.649
C(topic_grouped)[T.Science and technology]     0.5852      0.501      1.169      0.242      -0.396       1.566
C(topic_grouped)[T.Sports]                     0.6523      0.627      1.040      0.298      -0.577       1.882
C(answer_type_grouped)[T.Number]               0.4849      0.439      1.105      0.269      -0.375       1.345
C(answer_type_grouped)[T.Other]                0.2687      0.402      0.669      0.503      -0.518       1.056
C(answer_type_grouped)[T.Person]               0.6354      0.397      1.600      0.110      -0.143       1.414
q_length                                       0.1315      0.370      0.356      0.722      -0.593       0.856
capabilities_entropy                           2.2468      0.346      6.486      0.000       1.568       2.926
game_entropy                                   1.4772      0.353      4.189      0.000       0.786       2.168
==============================================================================================================
                    Skipping Model 6: No deterministic categories removed, would be same as Model 5.
