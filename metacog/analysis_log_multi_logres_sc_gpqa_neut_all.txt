
--- Analyzing claude-3-5-sonnet-20241022 (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_neutral/claude-3-5-sonnet-20241022_GPQA_redacted_cor_temp0.0_1754437810_game_data.json', './sc_logs_neutral/claude-3-5-sonnet-20241022_GPQA_redacted_temp0.0_1754429083_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    342
1    105
Name: count, dtype: int64

Answer change%: 0.2349 [0.19559915162998304, 0.27419950608813776] (n=447)
P-value vs 25%: 0.4514; P-value vs 0%: 1.07e-31
Phase 2 self-accuracy: 0.2571 [0.1735453502381671, 0.34074036404754715] (n=105)
P-value vs 25%: 0.867; P-value vs 33%: 0.07532

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1558
Time:                        12:35:30   Log-Likelihood:                -205.71
converged:                       True   LL-Null:                       -243.67
Covariance Type:            nonrobust   LLR p-value:                 2.944e-18
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          2.0288      0.394      5.149      0.000       1.256       2.801
p_i_capability    -4.7811      0.602     -7.937      0.000      -5.962      -3.600
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1480
Time:                        12:35:30   Log-Likelihood:                -207.61
converged:                       True   LL-Null:                       -243.67
Covariance Type:            nonrobust   LLR p-value:                 2.018e-17
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -3.2108      0.322     -9.975      0.000      -3.842      -2.580
capabilities_entropy     1.7935      0.235      7.639      0.000       1.333       2.254
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.7143 [0.6279, 0.8007] (n=105)
                  P-value vs 33.3%: 5.573e-18

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=-7.83, p=6.13e-14
Wilcoxon delta_p: statistic=6568.50, p=5.25e-14
Mean Δp = -0.0592  [-0.0740, -0.0444]
Idea 1 N = 342; 

  Idea 1.5: Calibration Metrics
  NLL: 1.6241, Signed ECE (overconf pos under neg): -0.0105, ECE: 0.1124 (n=447)
  Brier: 0.0494, Reliability (absolute calibration error; lower better): 0.0241, Resolution (relative calibration quality; higher better): 0.2211, Uncertainty: 0.2459 (n=447)
  AUROC: 0.9959

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.750
Model:                            OLS   Adj. R-squared:                  0.748
Method:                 Least Squares   F-statistic:                     442.0
Date:                Sat, 09 Aug 2025   Prob (F-statistic):          9.36e-133
Time:                        12:35:30   Log-Likelihood:                 308.10
No. Observations:                 447   AIC:                            -608.2
Df Residuals:                     443   BIC:                            -591.8
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.3584      0.026    -13.708      0.000      -0.410      -0.307
p1                    0.3858      0.033     11.828      0.000       0.322       0.450
answer_changed        0.1436      0.047      3.031      0.003       0.050       0.237
p1:answer_changed     0.6290      0.074      8.505      0.000       0.484       0.774
==============================================================================
Omnibus:                        9.967   Durbin-Watson:                   1.891
Prob(Omnibus):                  0.007   Jarque-Bera (JB):               13.040
Skew:                           0.212   Prob(JB):                      0.00147
Kurtosis:                       3.721   Cond. No.                         19.7
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-0.14, p=0.888
Wilcoxon delta_H: statistic=14477.50, p=0.672
Mean ΔH = -0.0033  [-0.0496, 0.0429]
Paired t-test delta_H Changed: statistic=11.01, p=3.83e-19
Wilcoxon delta_H Changed: statistic=167.00, p=6.21e-17
Mean ΔH Changed = 0.4195  [0.3448, 0.4942]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=10.33, p=1.39e-22
Wilcoxon (p_top2_game vs p_top2_base): statistic=11706.00, p=1.79e-23
Mean Δp_top2 = 0.0355  [0.0287, 0.0422] (n=447)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=4.40, p=1.38e-05
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=20923.50, p=3.45e-07
Mean ΔH_unchosen_baseline_set = 0.0960  [0.0532, 0.1388] (n=447)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      444
Method:                           MLE   Df Model:                            2
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1669
Time:                        12:35:30   Log-Likelihood:                -203.01
converged:                       True   LL-Null:                       -243.67
Covariance Type:            nonrobust   LLR p-value:                 2.194e-18
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.1747      0.179     -6.545      0.000      -1.526      -0.823
p1_z            -1.2924      0.186     -6.964      0.000      -1.656      -0.929
I(p1_z ** 2)    -0.3667      0.160     -2.294      0.022      -0.680      -0.053
================================================================================
AUC = 0.779

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1461
Time:                        12:35:30   Log-Likelihood:                -208.07
converged:                       True   LL-Null:                       -243.67
Covariance Type:            nonrobust   LLR p-value:                 3.208e-17
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -2.8931      0.272    -10.630      0.000      -3.427      -2.360
game_entropy     1.8659      0.238      7.854      0.000       1.400       2.332
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=11395.00, p=3.35e-24
Paired t-test (game_entropy vs capabilities_entropy): statistic=-10.61, p=1.34e-23
Mean capabilities_entropy-game_entropy = 0.1842  [0.1502, 0.2183] (n=447)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      444
Method:                           MLE   Df Model:                            2
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1654
Time:                        12:35:30   Log-Likelihood:                -203.36
converged:                       True   LL-Null:                       -243.67
Covariance Type:            nonrobust   LLR p-value:                 3.116e-18
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -3.3013      0.321    -10.273      0.000      -3.931      -2.671
capabilities_entropy     1.0506      0.344      3.050      0.002       0.376       1.726
game_entropy             1.0172      0.355      2.864      0.004       0.321       1.713
========================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:               6.523e-05
Time:                        12:35:30   Log-Likelihood:                -243.66
converged:                       True   LL-Null:                       -243.67
Covariance Type:            nonrobust   LLR p-value:                    0.8585
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -1.0985      0.475     -2.314      0.021      -2.029      -0.168
human_difficulty    -0.0348      0.195     -0.178      0.859      -0.417       0.348
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      440
Method:                           MLE   Df Model:                            6
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.02478
Time:                        12:35:30   Log-Likelihood:                -237.64
converged:                       True   LL-Null:                       -243.67
Covariance Type:            nonrobust   LLR p-value:                   0.06032
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -1.3656      1.767     -0.773      0.440      -4.828       2.097
C(domain_grouped)[T.chemistry]        0.5255      0.394      1.332      0.183      -0.248       1.298
C(domain_grouped)[T.physics]          0.6328      0.393      1.609      0.108      -0.138       1.404
human_difficulty                      0.0446      0.202      0.221      0.825      -0.350       0.440
q_length                              0.2330      0.192      1.216      0.224      -0.142       0.608
avg_word_length                      -0.3797      0.215     -1.765      0.078      -0.801       0.042
percent_non_alphabetic_whitespace    -0.0087      0.021     -0.410      0.682      -0.050       0.033
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 0.9810
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      439
Method:                           MLE   Df Model:                            7
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1605
Time:                        12:35:30   Log-Likelihood:                -204.55
converged:                       True   LL-Null:                       -243.67
Covariance Type:            nonrobust   LLR p-value:                 3.148e-14
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -4.1630      1.935     -2.151      0.031      -7.955      -0.371
C(domain_grouped)[T.chemistry]       -0.3319      0.440     -0.754      0.451      -1.195       0.531
C(domain_grouped)[T.physics]          0.1657      0.437      0.379      0.705      -0.691       1.022
human_difficulty                      0.0528      0.221      0.239      0.811      -0.380       0.486
q_length                              0.1753      0.211      0.831      0.406      -0.238       0.589
avg_word_length                      -0.0787      0.225     -0.350      0.726      -0.520       0.362
percent_non_alphabetic_whitespace     0.0177      0.023      0.774      0.439      -0.027       0.062
capabilities_entropy                  1.8376      0.250      7.360      0.000       1.348       2.327
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      439
Method:                           MLE   Df Model:                            7
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1595
Time:                        12:35:30   Log-Likelihood:                -204.81
converged:                       True   LL-Null:                       -243.67
Covariance Type:            nonrobust   LLR p-value:                 4.011e-14
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -3.7426      1.898     -1.972      0.049      -7.463      -0.022
C(domain_grouped)[T.chemistry]       -0.4155      0.442     -0.940      0.347      -1.282       0.451
C(domain_grouped)[T.physics]          0.0816      0.435      0.187      0.851      -0.771       0.934
human_difficulty                      0.0692      0.224      0.308      0.758      -0.370       0.509
q_length                              0.1617      0.208      0.777      0.437      -0.246       0.570
avg_word_length                      -0.0892      0.221     -0.403      0.687      -0.523       0.345
percent_non_alphabetic_whitespace     0.0237      0.022      1.054      0.292      -0.020       0.068
game_entropy                          1.9264      0.257      7.502      0.000       1.423       2.430
=====================================================================================================

                  Model 4.95: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      438
Method:                           MLE   Df Model:                            8
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1795
Time:                        12:35:30   Log-Likelihood:                -199.93
converged:                       True   LL-Null:                       -243.67
Covariance Type:            nonrobust   LLR p-value:                 1.498e-15
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -4.3367      1.939     -2.237      0.025      -8.137      -0.537
C(domain_grouped)[T.chemistry]       -0.5349      0.449     -1.191      0.233      -1.415       0.345
C(domain_grouped)[T.physics]          0.0274      0.441      0.062      0.950      -0.836       0.891
human_difficulty                      0.0725      0.226      0.321      0.749      -0.371       0.515
q_length                              0.1573      0.212      0.741      0.459      -0.259       0.573
avg_word_length                      -0.0406      0.226     -0.180      0.857      -0.483       0.402
percent_non_alphabetic_whitespace     0.0247      0.023      1.071      0.284      -0.020       0.070
capabilities_entropy                  1.0867      0.350      3.108      0.002       0.401       1.772
game_entropy                          1.0840      0.363      2.986      0.003       0.372       1.796
=====================================================================================================

--- Analyzing claude-3-haiku-20240307 (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_neutral/claude-3-haiku-20240307_GPQA_redacted_cor_temp0.0_1754422886_game_data.json', './sc_logs_neutral/claude-3-haiku-20240307_GPQA_redacted_temp0.0_1754341516_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    361
1     86
Name: count, dtype: int64

Answer change%: 0.1924 [0.15585196154695458, 0.2289355104888396] (n=447)
P-value vs 25%: 0.002003; P-value vs 0%: 5.765e-25
Phase 2 self-accuracy: 0.1977 [0.11350595102809745, 0.28184288618120484] (n=86)
P-value vs 25%: 0.223; P-value vs 33%: 0.001626

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1344
Time:                        12:35:30   Log-Likelihood:                -189.47
converged:                       True   LL-Null:                       -218.88
Covariance Type:            nonrobust   LLR p-value:                 1.712e-14
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          3.5039      0.657      5.335      0.000       2.217       4.791
p_i_capability    -5.7431      0.767     -7.491      0.000      -7.246      -4.241
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1509
Time:                        12:35:30   Log-Likelihood:                -185.85
converged:                       True   LL-Null:                       -218.88
Covariance Type:            nonrobust   LLR p-value:                 4.343e-16
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.9848      0.254    -11.757      0.000      -3.482      -2.487
capabilities_entropy     2.9068      0.375      7.747      0.000       2.171       3.642
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.5698 [0.4651, 0.6744] (n=86)
                  P-value vs 33.3%: 9.488e-06

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=0.50, p=0.615
Wilcoxon delta_p: statistic=3542.00, p=0.592
Mean Δp = 0.0035  [-0.0102, 0.0172]
Idea 1 N = 361; 

  Idea 1.5: Calibration Metrics
  NLL: 2.8327, Signed ECE (overconf pos under neg): -0.0156, ECE: 0.0407 (n=447)
  Brier: 0.0213, Reliability (absolute calibration error; lower better): 0.0049, Resolution (relative calibration quality; higher better): 0.2084, Uncertainty: 0.2244 (n=447)
  AUROC: 0.9984

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.870
Model:                            OLS   Adj. R-squared:                  0.869
Method:                 Least Squares   F-statistic:                     984.0
Date:                Sat, 09 Aug 2025   Prob (F-statistic):          1.97e-195
Time:                        12:35:30   Log-Likelihood:                 348.86
No. Observations:                 447   AIC:                            -689.7
Df Residuals:                     443   BIC:                            -673.3
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.6364      0.048    -13.389      0.000      -0.730      -0.543
p1                    0.6974      0.051     13.567      0.000       0.596       0.798
answer_changed        0.5257      0.071      7.358      0.000       0.385       0.666
p1:answer_changed     0.3193      0.085      3.777      0.000       0.153       0.485
==============================================================================
Omnibus:                      114.732   Durbin-Watson:                   1.997
Prob(Omnibus):                  0.000   Jarque-Bera (JB):              345.706
Skew:                           1.192   Prob(JB):                     8.53e-76
Kurtosis:                       6.588   Cond. No.                         31.3
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=0.39, p=0.697
Wilcoxon delta_H: statistic=3626.00, p=0.748
Mean ΔH = 0.0115  [-0.0464, 0.0694]
Paired t-test delta_H Changed: statistic=6.98, p=6.16e-10
Wilcoxon delta_H Changed: statistic=643.00, p=1.25e-07
Mean ΔH Changed = 0.5228  [0.3760, 0.6697]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=-0.08, p=0.936
Wilcoxon (p_top2_game vs p_top2_base): statistic=8834.50, p=0.252
Mean Δp_top2 = -0.0001  [-0.0031, 0.0029] (n=447)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=3.74, p=0.000212
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=7777.00, p=0.000376
Mean ΔH_unchosen_baseline_set = 0.1099  [0.0522, 0.1675] (n=447)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      444
Method:                           MLE   Df Model:                            2
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1702
Time:                        12:35:30   Log-Likelihood:                -181.63
converged:                       True   LL-Null:                       -218.88
Covariance Type:            nonrobust   LLR p-value:                 6.607e-17
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.1218      0.188     -5.980      0.000      -1.489      -0.754
p1_z            -1.9115      0.307     -6.223      0.000      -2.514      -1.309
I(p1_z ** 2)    -0.5584      0.146     -3.824      0.000      -0.845      -0.272
================================================================================
AUC = 0.750

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.04477
Time:                        12:35:30   Log-Likelihood:                -209.08
converged:                       True   LL-Null:                       -218.88
Covariance Type:            nonrobust   LLR p-value:                 9.546e-06
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -2.2418      0.227     -9.876      0.000      -2.687      -1.797
game_entropy     1.6499      0.365      4.526      0.000       0.935       2.364
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=9152.50, p=0.455
Paired t-test (game_entropy vs capabilities_entropy): statistic=-0.98, p=0.328
Mean capabilities_entropy-game_entropy = 0.0158  [-0.0158, 0.0473] (n=447)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      444
Method:                           MLE   Df Model:                            2
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1596
Time:                        12:35:30   Log-Likelihood:                -183.94
converged:                       True   LL-Null:                       -218.88
Covariance Type:            nonrobust   LLR p-value:                 6.681e-16
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -3.2709      0.301    -10.877      0.000      -3.860      -2.681
capabilities_entropy     2.6833      0.390      6.885      0.000       1.919       3.447
game_entropy             0.8367      0.423      1.978      0.048       0.007       1.666
========================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                0.001788
Time:                        12:35:30   Log-Likelihood:                -218.49
converged:                       True   LL-Null:                       -218.88
Covariance Type:            nonrobust   LLR p-value:                    0.3763
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -0.9949      0.510     -1.951      0.051      -1.994       0.004
human_difficulty    -0.1869      0.212     -0.880      0.379      -0.603       0.229
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      440
Method:                           MLE   Df Model:                            6
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.03348
Time:                        12:35:30   Log-Likelihood:                -211.56
converged:                       True   LL-Null:                       -218.88
Covariance Type:            nonrobust   LLR p-value:                   0.02312
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                             1.1103      1.900      0.584      0.559      -2.614       4.835
C(domain_grouped)[T.chemistry]        0.8096      0.406      1.995      0.046       0.014       1.605
C(domain_grouped)[T.physics]          0.0122      0.423      0.029      0.977      -0.817       0.842
human_difficulty                     -0.1196      0.225     -0.530      0.596      -0.562       0.322
q_length                              0.0550      0.204      0.270      0.787      -0.345       0.455
avg_word_length                      -0.5585      0.237     -2.354      0.019      -1.024      -0.094
percent_non_alphabetic_whitespace    -0.0494      0.025     -1.992      0.046      -0.098      -0.001
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 0.4659
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      439
Method:                           MLE   Df Model:                            7
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1740
Time:                        12:35:30   Log-Likelihood:                -180.79
converged:                       True   LL-Null:                       -218.88
Covariance Type:            nonrobust   LLR p-value:                 8.237e-14
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                             0.0871      2.083      0.042      0.967      -3.995       4.169
C(domain_grouped)[T.chemistry]        0.5647      0.433      1.304      0.192      -0.284       1.413
C(domain_grouped)[T.physics]         -0.2817      0.455     -0.619      0.536      -1.173       0.610
human_difficulty                     -0.0775      0.248     -0.313      0.755      -0.564       0.409
q_length                             -0.0627      0.223     -0.281      0.778      -0.499       0.374
avg_word_length                      -0.4813      0.260     -1.849      0.064      -0.991       0.029
percent_non_alphabetic_whitespace    -0.0551      0.028     -1.994      0.046      -0.109      -0.001
capabilities_entropy                  2.9017      0.392      7.398      0.000       2.133       3.670
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      439
Method:                           MLE   Df Model:                            7
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.07151
Time:                        12:35:30   Log-Likelihood:                -203.23
converged:                       True   LL-Null:                       -218.88
Covariance Type:            nonrobust   LLR p-value:                 5.459e-05
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                             0.0129      1.945      0.007      0.995      -3.799       3.825
C(domain_grouped)[T.chemistry]        0.6412      0.413      1.552      0.121      -0.168       1.451
C(domain_grouped)[T.physics]         -0.1689      0.437     -0.387      0.699      -1.025       0.688
human_difficulty                     -0.1150      0.233     -0.494      0.621      -0.571       0.341
q_length                              0.0648      0.207      0.314      0.754      -0.340       0.470
avg_word_length                      -0.4829      0.238     -2.029      0.042      -0.949      -0.017
percent_non_alphabetic_whitespace    -0.0404      0.025     -1.606      0.108      -0.090       0.009
game_entropy                          1.5491      0.374      4.146      0.000       0.817       2.281
=====================================================================================================

                  Model 4.95: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      438
Method:                           MLE   Df Model:                            8
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1812
Time:                        12:35:30   Log-Likelihood:                -179.23
converged:                       True   LL-Null:                       -218.88
Covariance Type:            nonrobust   LLR p-value:                 6.727e-14
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -0.4830      2.096     -0.230      0.818      -4.591       3.625
C(domain_grouped)[T.chemistry]        0.4876      0.433      1.125      0.261      -0.362       1.337
C(domain_grouped)[T.physics]         -0.3685      0.460     -0.802      0.423      -1.270       0.533
human_difficulty                     -0.0824      0.250     -0.329      0.742      -0.573       0.408
q_length                             -0.0392      0.222     -0.177      0.860      -0.474       0.396
avg_word_length                      -0.4380      0.259     -1.691      0.091      -0.946       0.070
percent_non_alphabetic_whitespace    -0.0497      0.028     -1.800      0.072      -0.104       0.004
capabilities_entropy                  2.7008      0.406      6.654      0.000       1.905       3.496
game_entropy                          0.7765      0.434      1.789      0.074      -0.074       1.627
=====================================================================================================

--- Analyzing claude-3-sonnet-20240229 (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_neutral/claude-3-sonnet-20240229_GPQA_redacted_cor_temp0.0_1751845558_game_data.json', './sc_logs_neutral/claude-3-sonnet-20240229_GPQA_redacted_temp0.0_1751827240_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    333
1    114
Name: count, dtype: int64

Answer change%: 0.2550 [0.21462611592929715, 0.2954409981646626] (n=447)
P-value vs 25%: 0.8071; P-value vs 0%: 3.779e-35
Phase 2 self-accuracy: 0.2632 [0.18232445043764473, 0.34399133903603946] (n=114)
P-value vs 25%: 0.7497; P-value vs 33%: 0.09037

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1734
Time:                        12:35:30   Log-Likelihood:                -209.80
converged:                       True   LL-Null:                       -253.81
Covariance Type:            nonrobust   LLR p-value:                 6.541e-21
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          2.6534      0.429      6.181      0.000       1.812       3.495
p_i_capability    -5.3854      0.637     -8.455      0.000      -6.634      -4.137
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1601
Time:                        12:35:30   Log-Likelihood:                -213.18
converged:                       True   LL-Null:                       -253.81
Covariance Type:            nonrobust   LLR p-value:                 1.984e-19
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -3.1939      0.315    -10.151      0.000      -3.811      -2.577
capabilities_entropy     2.0065      0.248      8.101      0.000       1.521       2.492
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.3333 [0.2468, 0.4199] (n=114)
                  P-value vs 33.3%: 1

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                0.001720
Time:                        12:35:30   Log-Likelihood:                -253.37
converged:                       True   LL-Null:                       -253.81
Covariance Type:            nonrobust   LLR p-value:                    0.3501
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -0.6519      0.462     -1.412      0.158      -1.557       0.253
human_difficulty    -0.1783      0.192     -0.930      0.352      -0.554       0.197
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      440
Method:                           MLE   Df Model:                            6
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.01499
Time:                        12:35:30   Log-Likelihood:                -250.00
converged:                       True   LL-Null:                       -253.81
Covariance Type:            nonrobust   LLR p-value:                    0.2681
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -0.7860      1.671     -0.470      0.638      -4.061       2.489
C(domain_grouped)[T.chemistry]        0.6981      0.378      1.846      0.065      -0.043       1.439
C(domain_grouped)[T.physics]          0.6900      0.382      1.806      0.071      -0.059       1.439
human_difficulty                     -0.1084      0.196     -0.553      0.581      -0.493       0.276
q_length                              0.0768      0.182      0.423      0.672      -0.279       0.433
avg_word_length                      -0.1966      0.196     -1.003      0.316      -0.581       0.187
percent_non_alphabetic_whitespace    -0.0206      0.021     -0.986      0.324      -0.062       0.020
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 0.9275
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      439
Method:                           MLE   Df Model:                            7
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1626
Time:                        12:35:30   Log-Likelihood:                -212.54
converged:                       True   LL-Null:                       -253.81
Covariance Type:            nonrobust   LLR p-value:                 4.191e-15
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -2.8105      1.815     -1.549      0.121      -6.367       0.746
C(domain_grouped)[T.chemistry]       -0.2886      0.432     -0.668      0.504      -1.136       0.558
C(domain_grouped)[T.physics]         -0.2709      0.447     -0.606      0.544      -1.147       0.605
human_difficulty                     -0.1925      0.214     -0.897      0.369      -0.613       0.228
q_length                              0.0504      0.204      0.246      0.805      -0.350       0.451
avg_word_length                      -0.0057      0.201     -0.028      0.977      -0.399       0.388
percent_non_alphabetic_whitespace    -0.0035      0.023     -0.150      0.880      -0.050       0.042
capabilities_entropy                  2.0684      0.266      7.790      0.000       1.548       2.589
=====================================================================================================

--- Analyzing claude-sonnet-4-20250514 (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_neutral/claude-sonnet-4-20250514_GPQA_redacted_cor_temp0.0_1751827811_game_data.json', './sc_logs_neutral/claude-sonnet-4-20250514_GPQA_redacted_temp0.0_1751824757_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    304
1    143
Name: count, dtype: int64

Answer change%: 0.3199 [0.27666992396704365, 0.3631511051157304] (n=447)
P-value vs 25%: 0.001531; P-value vs 0%: 1.202e-47
Phase 2 self-accuracy: 0.2517 [0.18061262306948928, 0.32288388042701427] (n=143)
P-value vs 25%: 0.9616; P-value vs 33%: 0.02518

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:               0.0002237
Time:                        12:35:30   Log-Likelihood:                -280.12
converged:                       True   LL-Null:                       -280.18
Covariance Type:            nonrobust   LLR p-value:                    0.7233
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -0.6056      0.431     -1.404      0.160      -1.451       0.240
human_difficulty    -0.0628      0.177     -0.354      0.724      -0.411       0.285
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      440
Method:                           MLE   Df Model:                            6
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.01618
Time:                        12:35:30   Log-Likelihood:                -275.65
converged:                       True   LL-Null:                       -280.18
Covariance Type:            nonrobust   LLR p-value:                    0.1699
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -1.5093      1.507     -1.002      0.316      -4.462       1.444
C(domain_grouped)[T.chemistry]        0.8777      0.334      2.628      0.009       0.223       1.532
C(domain_grouped)[T.physics]          0.4770      0.342      1.394      0.163      -0.194       1.148
human_difficulty                     -0.0201      0.184     -0.109      0.913      -0.381       0.341
q_length                              0.0918      0.167      0.548      0.583      -0.236       0.420
avg_word_length                      -0.0193      0.169     -0.114      0.909      -0.350       0.311
percent_non_alphabetic_whitespace    -0.0265      0.020     -1.340      0.180      -0.065       0.012
=====================================================================================================

--- Analyzing deepseek-chat (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_neutral/deepseek-chat_GPQA_redacted_cor_temp0.0_1754437275_game_data.json', './sc_logs_neutral/deepseek-chat_GPQA_redacted_temp0.0_1754429196_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    389
1     58
Name: count, dtype: int64

Answer change%: 0.1298 [0.09860265598161921, 0.1609051739960094] (n=447)
P-value vs 25%: 3.861e-14; P-value vs 0%: 3.246e-16
Phase 2 self-accuracy: 0.3276 [0.20680059475128126, 0.44837181904182216] (n=58)
P-value vs 25%: 0.208; P-value vs 33%: 0.93

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1665
Time:                        12:35:30   Log-Likelihood:                -143.78
converged:                       True   LL-Null:                       -172.51
Covariance Type:            nonrobust   LLR p-value:                 3.467e-14
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          4.9237      0.922      5.339      0.000       3.116       6.731
p_i_capability    -7.7482      1.058     -7.324      0.000      -9.822      -5.675
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1675
Time:                        12:35:30   Log-Likelihood:                -143.61
converged:                       True   LL-Null:                       -172.51
Covariance Type:            nonrobust   LLR p-value:                 2.919e-14
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -3.6432      0.308    -11.836      0.000      -4.246      -3.040
capabilities_entropy     3.4543      0.471      7.327      0.000       2.530       4.378
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.6207 [0.4958, 0.7456] (n=58)
                  P-value vs 33.3%: 6.475e-06

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=-1.00, p=0.319
Wilcoxon delta_p: statistic=2795.50, p=0.358
Mean Δp = -0.0046  [-0.0135, 0.0044]
Idea 1 N = 389; 

  Idea 1.5: Calibration Metrics
  NLL: 2.2315, Signed ECE (overconf pos under neg): -0.0091, ECE: 0.0519 (n=447)
  Brier: 0.0093, Reliability (absolute calibration error; lower better): 0.0091, Resolution (relative calibration quality; higher better): 0.2489, Uncertainty: 0.2489 (n=447)
  AUROC: 1.0000

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.895
Model:                            OLS   Adj. R-squared:                  0.894
Method:                 Least Squares   F-statistic:                     1258.
Date:                Sat, 09 Aug 2025   Prob (F-statistic):          2.71e-216
Time:                        12:35:30   Log-Likelihood:                 485.54
No. Observations:                 447   AIC:                            -963.1
Df Residuals:                     443   BIC:                            -946.7
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.6224      0.046    -13.403      0.000      -0.714      -0.531
p1                    0.6630      0.050     13.359      0.000       0.565       0.760
answer_changed        0.5505      0.070      7.813      0.000       0.412       0.689
p1:answer_changed     0.2700      0.082      3.287      0.001       0.109       0.431
==============================================================================
Omnibus:                      154.611   Durbin-Watson:                   1.880
Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1275.734
Skew:                           1.248   Prob(JB):                    9.50e-278
Kurtosis:                      10.891   Cond. No.                         41.5
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-1.38, p=0.169
Wilcoxon delta_H: statistic=2624.00, p=0.154
Mean ΔH = -0.0310  [-0.0751, 0.0131]
Paired t-test delta_H Changed: statistic=6.86, p=5.54e-09
Wilcoxon delta_H Changed: statistic=206.00, p=4.9e-07
Mean ΔH Changed = 0.5904  [0.4216, 0.7591]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=0.09, p=0.925
Wilcoxon (p_top2_game vs p_top2_base): statistic=6064.00, p=0.522
Mean Δp_top2 = 0.0001  [-0.0025, 0.0027] (n=447)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=2.02, p=0.044
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=5929.00, p=0.0491
Mean ΔH_unchosen_baseline_set = 0.0496  [0.0015, 0.0978] (n=447)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      444
Method:                           MLE   Df Model:                            2
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1947
Time:                        12:35:30   Log-Likelihood:                -138.91
converged:                       True   LL-Null:                       -172.51
Covariance Type:            nonrobust   LLR p-value:                 2.572e-15
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.9533      0.184    -10.635      0.000      -2.313      -1.593
p1_z            -1.6549      0.290     -5.713      0.000      -2.223      -1.087
I(p1_z ** 2)    -0.2945      0.096     -3.061      0.002      -0.483      -0.106
================================================================================
AUC = 0.779

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1199
Time:                        12:35:30   Log-Likelihood:                -151.82
converged:                       True   LL-Null:                       -172.51
Covariance Type:            nonrobust   LLR p-value:                 1.257e-10
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -3.3539      0.294    -11.400      0.000      -3.931      -2.777
game_entropy     3.1402      0.504      6.226      0.000       2.152       4.129
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=5554.00, p=0.131
Paired t-test (game_entropy vs capabilities_entropy): statistic=-1.71, p=0.0885
Mean capabilities_entropy-game_entropy = 0.0205  [-0.0030, 0.0439] (n=447)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      444
Method:                           MLE   Df Model:                            2
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.2066
Time:                        12:35:30   Log-Likelihood:                -136.87
converged:                       True   LL-Null:                       -172.51
Covariance Type:            nonrobust   LLR p-value:                 3.324e-16
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -4.3028      0.385    -11.163      0.000      -5.058      -3.547
capabilities_entropy     2.8223      0.512      5.509      0.000       1.818       3.826
game_entropy             2.1269      0.578      3.678      0.000       0.994       3.260
========================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                0.006787
Time:                        12:35:30   Log-Likelihood:                -171.33
converged:                       True   LL-Null:                       -172.51
Covariance Type:            nonrobust   LLR p-value:                    0.1260
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -1.0091      0.598     -1.688      0.091      -2.181       0.162
human_difficulty    -0.3846      0.255     -1.510      0.131      -0.884       0.115
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      440
Method:                           MLE   Df Model:                            6
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.04795
Time:                        12:35:30   Log-Likelihood:                -164.23
converged:                       True   LL-Null:                       -172.51
Covariance Type:            nonrobust   LLR p-value:                   0.01112
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -2.4326      2.267     -1.073      0.283      -6.876       2.011
C(domain_grouped)[T.chemistry]        1.2541      0.532      2.357      0.018       0.211       2.297
C(domain_grouped)[T.physics]          0.8881      0.548      1.620      0.105      -0.186       1.963
human_difficulty                     -0.3977      0.261     -1.526      0.127      -0.908       0.113
q_length                              0.3832      0.247      1.553      0.120      -0.100       0.867
avg_word_length                      -0.2495      0.272     -0.919      0.358      -0.782       0.283
percent_non_alphabetic_whitespace    -0.0780      0.033     -2.333      0.020      -0.143      -0.012
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 0.4245
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      439
Method:                           MLE   Df Model:                            7
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.2030
Time:                        12:35:30   Log-Likelihood:                -137.49
converged:                       True   LL-Null:                       -172.51
Covariance Type:            nonrobust   LLR p-value:                 1.451e-12
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -2.8719      2.411     -1.191      0.234      -7.598       1.854
C(domain_grouped)[T.chemistry]        0.5246      0.565      0.929      0.353      -0.582       1.631
C(domain_grouped)[T.physics]          0.2376      0.589      0.403      0.687      -0.917       1.392
human_difficulty                     -0.4310      0.296     -1.454      0.146      -1.012       0.150
q_length                              0.2760      0.270      1.021      0.307      -0.254       0.806
avg_word_length                      -0.2251      0.263     -0.855      0.393      -0.741       0.291
percent_non_alphabetic_whitespace    -0.0942      0.037     -2.541      0.011      -0.167      -0.022
capabilities_entropy                  3.5036      0.504      6.953      0.000       2.516       4.491
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      439
Method:                           MLE   Df Model:                            7
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1503
Time:                        12:35:30   Log-Likelihood:                -146.58
converged:                       True   LL-Null:                       -172.51
Covariance Type:            nonrobust   LLR p-value:                 6.239e-09
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -2.9462      2.373     -1.241      0.214      -7.598       1.706
C(domain_grouped)[T.chemistry]        0.8270      0.553      1.495      0.135      -0.257       1.911
C(domain_grouped)[T.physics]          0.5388      0.574      0.939      0.348      -0.586       1.663
human_difficulty                     -0.4790      0.282     -1.696      0.090      -1.033       0.075
q_length                              0.2974      0.262      1.136      0.256      -0.216       0.810
avg_word_length                      -0.2216      0.278     -0.797      0.425      -0.767       0.323
percent_non_alphabetic_whitespace    -0.0713      0.036     -1.997      0.046      -0.141      -0.001
game_entropy                          2.9783      0.524      5.681      0.000       1.951       4.006
=====================================================================================================

                  Model 4.95: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      438
Method:                           MLE   Df Model:                            8
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.2348
Time:                        12:35:30   Log-Likelihood:                -132.00
converged:                       True   LL-Null:                       -172.51
Covariance Type:            nonrobust   LLR p-value:                 3.053e-14
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -3.2025      2.464     -1.300      0.194      -8.033       1.628
C(domain_grouped)[T.chemistry]        0.3025      0.578      0.524      0.600      -0.830       1.435
C(domain_grouped)[T.physics]          0.1075      0.598      0.180      0.857      -1.064       1.279
human_difficulty                     -0.4649      0.302     -1.539      0.124      -1.057       0.127
q_length                              0.2521      0.274      0.922      0.357      -0.284       0.788
avg_word_length                      -0.2224      0.273     -0.816      0.414      -0.757       0.312
percent_non_alphabetic_whitespace    -0.0845      0.038     -2.230      0.026      -0.159      -0.010
capabilities_entropy                  2.9281      0.543      5.390      0.000       1.863       3.993
game_entropy                          1.9870      0.602      3.302      0.001       0.808       3.166
=====================================================================================================

--- Analyzing gemini-1.5-pro (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_neutral/gemini-1.5-pro_GPQA_redacted_cor_temp0.0_1751845110_game_data.json', './sc_logs_neutral/gemini-1.5-pro_GPQA_redacted_temp0.0_1751826706_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    376
1     71
Name: count, dtype: int64

Answer change%: 0.1588 [0.12495150075454864, 0.19272187732151402] (n=447)
P-value vs 25%: 1.342e-07; P-value vs 0%: 4.027e-20
Phase 2 self-accuracy: 0.3521 [0.24101384534522574, 0.46321150676745027] (n=71)
P-value vs 25%: 0.07163; P-value vs 33%: 0.736

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:               6.127e-05
Time:                        12:35:30   Log-Likelihood:                -195.66
converged:                       True   LL-Null:                       -195.67
Covariance Type:            nonrobust   LLR p-value:                    0.8769
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -1.7498      0.551     -3.173      0.002      -2.831      -0.669
human_difficulty     0.0349      0.225      0.155      0.877      -0.407       0.477
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      440
Method:                           MLE   Df Model:                            6
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                0.009893
Time:                        12:35:30   Log-Likelihood:                -193.73
converged:                       True   LL-Null:                       -195.67
Covariance Type:            nonrobust   LLR p-value:                    0.6941
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                             0.3261      1.983      0.164      0.869      -3.561       4.213
C(domain_grouped)[T.chemistry]        0.0840      0.413      0.203      0.839      -0.726       0.894
C(domain_grouped)[T.physics]         -0.0219      0.414     -0.053      0.958      -0.834       0.790
human_difficulty                      0.0745      0.233      0.319      0.750      -0.383       0.532
q_length                              0.0056      0.214      0.026      0.979      -0.414       0.425
avg_word_length                      -0.4375      0.246     -1.781      0.075      -0.919       0.044
percent_non_alphabetic_whitespace    -0.0278      0.025     -1.097      0.273      -0.078       0.022
=====================================================================================================

--- Analyzing gemini-2.0-flash-001 (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_neutral/gemini-2.0-flash-001_GPQA_redacted_cor_temp0.0_1754341249_game_data.json', './sc_logs_neutral/gemini-2.0-flash-001_GPQA_redacted_temp0.0_1754341030_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    349
1     98
Name: count, dtype: int64

Answer change%: 0.2192 [0.18088520635934915, 0.25759354084423025] (n=447)
P-value vs 25%: 0.116; P-value vs 0%: 3.919e-29
Phase 2 self-accuracy: 0.3571 [0.2622762705656283, 0.452009443720086] (n=98)
P-value vs 25%: 0.02686; P-value vs 33%: 0.6179

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1376
Time:                        12:35:31   Log-Likelihood:                -202.74
converged:                       True   LL-Null:                       -235.10
Covariance Type:            nonrobust   LLR p-value:                 8.676e-16
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          4.6427      0.788      5.892      0.000       3.098       6.187
p_i_capability    -6.5108      0.865     -7.527      0.000      -8.206      -4.815
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1608
Time:                        12:35:31   Log-Likelihood:                -197.30
converged:                       True   LL-Null:                       -235.10
Covariance Type:            nonrobust   LLR p-value:                 3.471e-18
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.0556      0.169    -12.192      0.000      -2.386      -1.725
capabilities_entropy     2.3171      0.285      8.127      0.000       1.758       2.876
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.7093 [0.6133, 0.8053] (n=86)
                  P-value vs 33.3%: 1.612e-14

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=0.93, p=0.356
Wilcoxon delta_p: statistic=7823.00, p=0.559
Mean Δp = 0.0103  [-0.0115, 0.0322]
Idea 1 N = 181; 

  Idea 1.5: Calibration Metrics
  NLL: 4.7074, Signed ECE (overconf pos under neg): -0.0102, ECE: 0.0616 (n=263)
  Brier: 0.0198, Reliability (absolute calibration error; lower better): 0.0175, Resolution (relative calibration quality; higher better): 0.2195, Uncertainty: 0.2214 (n=263)
  AUROC: 1.0000

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.864
Model:                            OLS   Adj. R-squared:                  0.862
Method:                 Least Squares   F-statistic:                     544.7
Date:                Sat, 09 Aug 2025   Prob (F-statistic):          2.81e-111
Time:                        12:35:31   Log-Likelihood:                 155.74
No. Observations:                 262   AIC:                            -303.5
Df Residuals:                     258   BIC:                            -289.2
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.5306      0.077     -6.848      0.000      -0.683      -0.378
p1                    0.5826      0.083      7.040      0.000       0.420       0.746
answer_changed        0.3978      0.104      3.825      0.000       0.193       0.603
p1:answer_changed     0.4408      0.118      3.737      0.000       0.209       0.673
==============================================================================
Omnibus:                       39.513   Durbin-Watson:                   1.911
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               75.605
Skew:                           0.792   Prob(JB):                     3.82e-17
Kurtosis:                       5.102   Cond. No.                         30.6
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-1.86, p=0.0644
Wilcoxon delta_H: statistic=6968.00, p=0.0725
Mean ΔH = -0.0772  [-0.1584, 0.0041]
Paired t-test delta_H Changed: statistic=4.07, p=0.000106
Wilcoxon delta_H Changed: statistic=784.00, p=8.04e-06
Mean ΔH Changed = 0.2303  [0.1194, 0.3411]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=-1.20, p=0.233
Wilcoxon (p_top2_game vs p_top2_base): statistic=15974.00, p=0.187
Mean Δp_top2 = -0.0040  [-0.0106, 0.0026] (n=265)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=0.59, p=0.558
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=16874.00, p=0.549
Mean ΔH_unchosen_baseline_set = 0.0203  [-0.0475, 0.0881] (n=265)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  265
Model:                          Logit   Df Residuals:                      262
Method:                           MLE   Df Model:                            2
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1112
Time:                        12:35:31   Log-Likelihood:                -147.11
converged:                       True   LL-Null:                       -165.51
Covariance Type:            nonrobust   LLR p-value:                 1.021e-08
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.6517      0.200     -3.254      0.001      -1.044      -0.259
p1_z            -1.0594      0.256     -4.139      0.000      -1.561      -0.558
I(p1_z ** 2)    -0.2063      0.156     -1.323      0.186      -0.512       0.099
================================================================================
AUC = 0.741

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1120
Time:                        12:35:31   Log-Likelihood:                -208.76
converged:                       True   LL-Null:                       -235.10
Covariance Type:            nonrobust   LLR p-value:                 3.941e-13
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.8696      0.157    -11.892      0.000      -2.178      -1.561
game_entropy     1.7868      0.254      7.042      0.000       1.289       2.284
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=46902.00, p=0.247
Paired t-test (game_entropy vs capabilities_entropy): statistic=0.18, p=0.855
Mean capabilities_entropy-game_entropy = -0.0033  [-0.0393, 0.0326] (n=447)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      444
Method:                           MLE   Df Model:                            2
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1808
Time:                        12:35:31   Log-Likelihood:                -192.59
converged:                       True   LL-Null:                       -235.10
Covariance Type:            nonrobust   LLR p-value:                 3.473e-19
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.2017      0.181    -12.182      0.000      -2.556      -1.847
capabilities_entropy     1.8195      0.325      5.595      0.000       1.182       2.457
game_entropy             0.9433      0.302      3.120      0.002       0.351       1.536
========================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                0.002124
Time:                        12:35:31   Log-Likelihood:                -234.60
converged:                       True   LL-Null:                       -235.10
Covariance Type:            nonrobust   LLR p-value:                    0.3176
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -0.7968      0.486     -1.639      0.101      -1.749       0.156
human_difficulty    -0.2012      0.202     -0.994      0.320      -0.598       0.196
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      440
Method:                           MLE   Df Model:                            6
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.03364
Time:                        12:35:31   Log-Likelihood:                -227.19
converged:                       True   LL-Null:                       -235.10
Covariance Type:            nonrobust   LLR p-value:                   0.01477
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                             0.0274      1.821      0.015      0.988      -3.541       3.596
C(domain_grouped)[T.chemistry]        0.6596      0.391      1.686      0.092      -0.107       1.427
C(domain_grouped)[T.physics]         -0.0070      0.406     -0.017      0.986      -0.803       0.789
human_difficulty                     -0.1140      0.216     -0.527      0.598      -0.538       0.310
q_length                              0.1798      0.198      0.907      0.364      -0.209       0.568
avg_word_length                      -0.5087      0.224     -2.271      0.023      -0.948      -0.070
percent_non_alphabetic_whitespace    -0.0092      0.022     -0.427      0.669      -0.051       0.033
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 0.2568
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      439
Method:                           MLE   Df Model:                            7
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1762
Time:                        12:35:31   Log-Likelihood:                -193.68
converged:                       True   LL-Null:                       -235.10
Covariance Type:            nonrobust   LLR p-value:                 3.634e-15
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -1.2327      1.960     -0.629      0.529      -5.074       2.608
C(domain_grouped)[T.chemistry]        0.1811      0.426      0.425      0.671      -0.654       1.016
C(domain_grouped)[T.physics]         -0.4438      0.448     -0.991      0.322      -1.322       0.434
human_difficulty                     -0.0764      0.240     -0.319      0.750      -0.546       0.393
q_length                              0.1103      0.216      0.510      0.610      -0.314       0.534
avg_word_length                      -0.2750      0.234     -1.174      0.240      -0.734       0.184
percent_non_alphabetic_whitespace     0.0076      0.023      0.331      0.740      -0.037       0.052
capabilities_entropy                  2.2798      0.300      7.600      0.000       1.692       2.868
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      439
Method:                           MLE   Df Model:                            7
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1266
Time:                        12:35:31   Log-Likelihood:                -205.33
converged:                       True   LL-Null:                       -235.10
Covariance Type:            nonrobust   LLR p-value:                 1.872e-10
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -0.8663      1.900     -0.456      0.648      -4.590       2.858
C(domain_grouped)[T.chemistry]        0.2733      0.410      0.667      0.505      -0.529       1.076
C(domain_grouped)[T.physics]         -0.3324      0.429     -0.774      0.439      -1.174       0.509
human_difficulty                     -0.0532      0.229     -0.232      0.816      -0.502       0.395
q_length                              0.0522      0.209      0.250      0.803      -0.357       0.462
avg_word_length                      -0.2609      0.228     -1.145      0.252      -0.708       0.186
percent_non_alphabetic_whitespace     0.0040      0.023      0.174      0.862      -0.041       0.049
game_entropy                          1.7063      0.266      6.407      0.000       1.184       2.228
=====================================================================================================

                  Model 4.95: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      438
Method:                           MLE   Df Model:                            8
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1939
Time:                        12:35:31   Log-Likelihood:                -189.51
converged:                       True   LL-Null:                       -235.10
Covariance Type:            nonrobust   LLR p-value:                 2.687e-16
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -1.3488      1.971     -0.684      0.494      -5.213       2.515
C(domain_grouped)[T.chemistry]        0.0461      0.431      0.107      0.915      -0.798       0.891
C(domain_grouped)[T.physics]         -0.5582      0.454     -1.229      0.219      -1.448       0.332
human_difficulty                     -0.0637      0.244     -0.261      0.794      -0.541       0.414
q_length                              0.0519      0.219      0.237      0.812      -0.377       0.481
avg_word_length                      -0.1985      0.232     -0.854      0.393      -0.654       0.257
percent_non_alphabetic_whitespace     0.0115      0.023      0.494      0.621      -0.034       0.057
capabilities_entropy                  1.8455      0.335      5.509      0.000       1.189       2.502
game_entropy                          0.9153      0.313      2.928      0.003       0.303       1.528
=====================================================================================================

--- Analyzing gemini-2.5-flash-preview-04-17 (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_neutral/gemini-2.5-flash-preview-04-17_GPQA_redacted_cor_temp0.0_1751846071_game_data.json', './sc_logs_neutral/gemini-2.5-flash-preview-04-17_GPQA_redacted_temp0.0_1751828022_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    350
1     93
Name: count, dtype: int64

Answer change%: 0.2099 [0.1720079428201272, 0.2478566169992859] (n=443)
P-value vs 25%: 0.03838; P-value vs 0%: 2.005e-27
Phase 2 self-accuracy: 0.4409 [0.3399541505419334, 0.5417662795655935] (n=93)
P-value vs 25%: 0.0002096; P-value vs 33%: 0.03617

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  436
Model:                          Logit   Df Residuals:                      434
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.05123
Time:                        12:35:31   Log-Likelihood:                -214.40
converged:                       True   LL-Null:                       -225.98
Covariance Type:            nonrobust   LLR p-value:                 1.496e-06
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.6354      0.144    -11.349      0.000      -1.918      -1.353
game_entropy     1.2857      0.264      4.875      0.000       0.769       1.803
================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  443
Model:                          Logit   Df Residuals:                      441
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                0.008518
Time:                        12:35:31   Log-Likelihood:                -225.70
converged:                       True   LL-Null:                       -227.64
Covariance Type:            nonrobust   LLR p-value:                   0.04892
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -2.2856      0.509     -4.494      0.000      -3.282      -1.289
human_difficulty     0.3993      0.203      1.970      0.049       0.002       0.797
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  443
Model:                          Logit   Df Residuals:                      436
Method:                           MLE   Df Model:                            6
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.04883
Time:                        12:35:31   Log-Likelihood:                -216.53
converged:                       True   LL-Null:                       -227.64
Covariance Type:            nonrobust   LLR p-value:                  0.001100
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -2.4945      1.741     -1.433      0.152      -5.907       0.918
C(domain_grouped)[T.chemistry]        0.5474      0.363      1.510      0.131      -0.163       1.258
C(domain_grouped)[T.physics]         -0.4695      0.393     -1.194      0.232      -1.240       0.301
human_difficulty                      0.5654      0.224      2.527      0.011       0.127       1.004
q_length                             -0.0265      0.194     -0.136      0.891      -0.407       0.354
avg_word_length                      -0.0722      0.190     -0.380      0.704      -0.445       0.300
percent_non_alphabetic_whitespace     0.0234      0.021      1.124      0.261      -0.017       0.064
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  436
Model:                          Logit   Df Residuals:                      428
Method:                           MLE   Df Model:                            7
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.08763
Time:                        12:35:31   Log-Likelihood:                -206.18
converged:                       True   LL-Null:                       -225.98
Covariance Type:            nonrobust   LLR p-value:                 1.498e-06
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -1.6347      1.771     -0.923      0.356      -5.106       1.837
C(domain_grouped)[T.chemistry]        0.2097      0.384      0.546      0.585      -0.543       0.962
C(domain_grouped)[T.physics]         -0.6230      0.403     -1.545      0.122      -1.414       0.167
human_difficulty                      0.5396      0.231      2.333      0.020       0.086       0.993
q_length                             -0.1756      0.202     -0.870      0.384      -0.571       0.220
avg_word_length                      -0.0662      0.190     -0.349      0.727      -0.438       0.306
percent_non_alphabetic_whitespace     0.0230      0.021      1.084      0.278      -0.019       0.065
game_entropy                          1.1432      0.285      4.013      0.000       0.585       1.702
=====================================================================================================

--- Analyzing gpt-4.1-2025-04-14 (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_neutral/gpt-4.1-2025-04-14_GPQA_redacted_cor_temp0.0_1751832342_game_data.json', './sc_logs_neutral/gpt-4.1-2025-04-14_GPQA_redacted_temp0.0_1751825484_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    344
1    103
Name: count, dtype: int64

Answer change%: 0.2304 [0.19138731838086948, 0.2694627934759538] (n=447)
P-value vs 25%: 0.3257; P-value vs 0%: 5.922e-31
Phase 2 self-accuracy: 0.2816 [0.19469594050311953, 0.36841085561338527] (n=103)
P-value vs 25%: 0.4765; P-value vs 33%: 0.2457

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.08317
Time:                        12:35:31   Log-Likelihood:                -221.22
converged:                       True   LL-Null:                       -241.29
Covariance Type:            nonrobust   LLR p-value:                 2.367e-10
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          2.3220      0.566      4.099      0.000       1.212       3.432
p_i_capability    -4.0095      0.642     -6.248      0.000      -5.267      -2.752
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1039
Time:                        12:35:31   Log-Likelihood:                -216.22
converged:                       True   LL-Null:                       -241.29
Covariance Type:            nonrobust   LLR p-value:                 1.436e-12
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.8378      0.160    -11.469      0.000      -2.152      -1.524
capabilities_entropy     1.5530      0.225      6.912      0.000       1.113       1.993
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.6471 [0.5335, 0.7606] (n=68)
                  P-value vs 33.3%: 6.179e-08

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=-3.92, p=0.000221
Wilcoxon delta_p: statistic=394.00, p=2.63e-05
Mean Δp = -0.1045  [-0.1567, -0.0523]
Idea 1 N = 63; 

  Idea 1.5: Calibration Metrics
  NLL: 4.3440, Signed ECE (overconf pos under neg): 0.0225, ECE: 0.0970 (n=111)
  Brier: 0.0317, Reliability (absolute calibration error; lower better): 0.0239, Resolution (relative calibration quality; higher better): 0.1566, Uncertainty: 0.1643 (n=111)
  AUROC: 0.9985

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.885
Model:                            OLS   Adj. R-squared:                  0.882
Method:                 Least Squares   F-statistic:                     275.0
Date:                Sat, 09 Aug 2025   Prob (F-statistic):           3.99e-50
Time:                        12:35:31   Log-Likelihood:                 59.036
No. Observations:                 111   AIC:                            -110.1
Df Residuals:                     107   BIC:                            -99.23
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.6291      0.074     -8.466      0.000      -0.776      -0.482
p1                    0.6653      0.091      7.282      0.000       0.484       0.846
answer_changed        0.4995      0.112      4.452      0.000       0.277       0.722
p1:answer_changed     0.3974      0.147      2.705      0.008       0.106       0.689
==============================================================================
Omnibus:                       25.560   Durbin-Watson:                   1.629
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               37.580
Skew:                           1.103   Prob(JB):                     6.91e-09
Kurtosis:                       4.805   Cond. No.                         20.3
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=4.05, p=0.000144
Wilcoxon delta_H: statistic=489.00, p=0.000381
Mean ΔH = 0.2333  [0.1204, 0.3462]
Paired t-test delta_H Changed: statistic=6.54, p=4.03e-08
Wilcoxon delta_H Changed: statistic=96.00, p=2.51e-08
Mean ΔH Changed = 0.4753  [0.3329, 0.6176]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=5.90, p=4.15e-08
Wilcoxon (p_top2_game vs p_top2_base): statistic=700.00, p=1.39e-12
Mean Δp_top2 = 0.0441  [0.0294, 0.0588] (n=111)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=7.26, p=5.82e-11
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=1006.00, p=6.22e-10
Mean ΔH_unchosen_baseline_set = 0.3379  [0.2467, 0.4292] (n=111)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  111
Model:                          Logit   Df Residuals:                      108
Method:                           MLE   Df Model:                            2
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.05005
Time:                        12:35:31   Log-Likelihood:                -72.123
converged:                       True   LL-Null:                       -75.923
Covariance Type:            nonrobust   LLR p-value:                   0.02238
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept        0.0842      0.291      0.290      0.772      -0.485       0.654
p1_z            -0.5527      0.219     -2.522      0.012      -0.982      -0.123
I(p1_z ** 2)    -0.3844      0.227     -1.696      0.090      -0.829       0.060
================================================================================
AUC = 0.644

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.08597
Time:                        12:35:31   Log-Likelihood:                -220.54
converged:                       True   LL-Null:                       -241.29
Covariance Type:            nonrobust   LLR p-value:                 1.186e-10
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.5936      0.137    -11.612      0.000      -1.863      -1.325
game_entropy     1.9423      0.314      6.195      0.000       1.328       2.557
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=10374.50, p=6.66e-20
Paired t-test (game_entropy vs capabilities_entropy): statistic=-8.46, p=3.81e-16
Mean capabilities_entropy-game_entropy = 0.1660  [0.1275, 0.2045] (n=447)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      444
Method:                           MLE   Df Model:                            2
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1250
Time:                        12:35:31   Log-Likelihood:                -211.12
converged:                       True   LL-Null:                       -241.29
Covariance Type:            nonrobust   LLR p-value:                 7.901e-14
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.8947      0.163    -11.634      0.000      -2.214      -1.576
capabilities_entropy     1.1377      0.260      4.374      0.000       0.628       1.648
game_entropy             1.1588      0.365      3.178      0.001       0.444       1.874
========================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:               0.0003775
Time:                        12:35:31   Log-Likelihood:                -241.19
converged:                       True   LL-Null:                       -241.29
Covariance Type:            nonrobust   LLR p-value:                    0.6695
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -1.0075      0.478     -2.110      0.035      -1.944      -0.071
human_difficulty    -0.0840      0.197     -0.426      0.670      -0.470       0.302
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      440
Method:                           MLE   Df Model:                            6
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.03556
Time:                        12:35:31   Log-Likelihood:                -232.71
converged:                       True   LL-Null:                       -241.29
Covariance Type:            nonrobust   LLR p-value:                  0.008717
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -1.1798      1.819     -0.649      0.517      -4.745       2.386
C(domain_grouped)[T.chemistry]        1.0593      0.431      2.455      0.014       0.214       1.905
C(domain_grouped)[T.physics]          0.7737      0.436      1.774      0.076      -0.081       1.628
human_difficulty                      0.0468      0.206      0.227      0.820      -0.357       0.451
q_length                              0.2040      0.195      1.045      0.296      -0.179       0.587
avg_word_length                      -0.4548      0.223     -2.035      0.042      -0.893      -0.017
percent_non_alphabetic_whitespace    -0.0094      0.021     -0.441      0.659      -0.051       0.032
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 0.3226
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      439
Method:                           MLE   Df Model:                            7
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1188
Time:                        12:35:31   Log-Likelihood:                -212.63
converged:                       True   LL-Null:                       -241.29
Covariance Type:            nonrobust   LLR p-value:                 5.172e-10
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -2.0384      1.890     -1.078      0.281      -5.743       1.666
C(domain_grouped)[T.chemistry]        0.6576      0.447      1.470      0.142      -0.219       1.534
C(domain_grouped)[T.physics]          0.5238      0.454      1.153      0.249      -0.367       1.414
human_difficulty                      0.1940      0.218      0.891      0.373      -0.233       0.621
q_length                              0.0869      0.208      0.418      0.676      -0.321       0.494
avg_word_length                      -0.2799      0.228     -1.226      0.220      -0.727       0.167
percent_non_alphabetic_whitespace     0.0025      0.022      0.111      0.912      -0.041       0.046
capabilities_entropy                  1.4483      0.233      6.212      0.000       0.991       1.905
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      439
Method:                           MLE   Df Model:                            7
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1034
Time:                        12:35:31   Log-Likelihood:                -216.33
converged:                       True   LL-Null:                       -241.29
Covariance Type:            nonrobust   LLR p-value:                 1.498e-08
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -1.4442      1.886     -0.766      0.444      -5.142       2.253
C(domain_grouped)[T.chemistry]        0.7588      0.441      1.720      0.086      -0.106       1.624
C(domain_grouped)[T.physics]          0.6135      0.445      1.379      0.168      -0.258       1.485
human_difficulty                      0.0627      0.214      0.293      0.770      -0.357       0.482
q_length                              0.1098      0.205      0.536      0.592      -0.291       0.511
avg_word_length                      -0.3276      0.232     -1.413      0.158      -0.782       0.127
percent_non_alphabetic_whitespace    -0.0028      0.022     -0.126      0.900      -0.047       0.041
game_entropy                          1.7648      0.320      5.515      0.000       1.138       2.392
=====================================================================================================

                  Model 4.95: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      438
Method:                           MLE   Df Model:                            8
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1369
Time:                        12:35:31   Log-Likelihood:                -208.26
converged:                       True   LL-Null:                       -241.29
Covariance Type:            nonrobust   LLR p-value:                 2.986e-11
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -1.9472      1.908     -1.020      0.308      -5.687       1.793
C(domain_grouped)[T.chemistry]        0.6076      0.451      1.348      0.178      -0.276       1.491
C(domain_grouped)[T.physics]          0.5137      0.458      1.122      0.262      -0.384       1.411
human_difficulty                      0.1691      0.221      0.766      0.443      -0.263       0.602
q_length                              0.0538      0.210      0.256      0.798      -0.358       0.466
avg_word_length                      -0.2504      0.231     -1.082      0.279      -0.704       0.203
percent_non_alphabetic_whitespace     0.0023      0.022      0.103      0.918      -0.041       0.046
capabilities_entropy                  1.0724      0.266      4.034      0.000       0.551       1.593
game_entropy                          1.0758      0.366      2.938      0.003       0.358       1.794
=====================================================================================================

--- Analyzing gpt-4o-2024-08-06 (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_neutral/gpt-4o-2024-08-06_GPQA_redacted_cor_temp0.0_1751845346_game_data.json', './sc_logs_neutral/gpt-4o-2024-08-06_GPQA_redacted_temp0.0_1751827002_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    323
1    124
Name: count, dtype: int64

Answer change%: 0.2774 [0.2359000658299225, 0.31890977757052497] (n=447)
P-value vs 25%: 0.1956; P-value vs 0%: 3.303e-39
Phase 2 self-accuracy: 0.3306 [0.24784207243892525, 0.4134482501417199] (n=124)
P-value vs 25%: 0.05628; P-value vs 33%: 0.9555

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.08063
Time:                        12:35:31   Log-Likelihood:                -242.66
converged:                       True   LL-Null:                       -263.95
Covariance Type:            nonrobust   LLR p-value:                 6.833e-11
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          0.9814      0.322      3.044      0.002       0.350       1.613
p_i_capability    -2.7899      0.451     -6.180      0.000      -3.675      -1.905
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.2093
Time:                        12:35:31   Log-Likelihood:                -208.71
converged:                       True   LL-Null:                       -263.95
Covariance Type:            nonrobust   LLR p-value:                 7.746e-26
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.9767      0.287    -10.369      0.000      -3.539      -2.414
capabilities_entropy     2.0576      0.231      8.899      0.000       1.604       2.511
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.3387 [0.2554, 0.4220] (n=124)
                  P-value vs 33.3%: 0.8993

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=-0.83, p=0.406
Wilcoxon delta_p: statistic=15221.00, p=0.00252
Mean Δp = -0.0087  [-0.0291, 0.0118]
Idea 1 N = 277; 

  Idea 1.5: Calibration Metrics
  NLL: 2.2041, Signed ECE (overconf pos under neg): 0.0200, ECE: 0.0502 (n=399)
  Brier: 0.0981, Reliability (absolute calibration error; lower better): 0.0088, Resolution (relative calibration quality; higher better): 0.1441, Uncertainty: 0.2327 (n=399)
  AUROC: 0.9347

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.142
Model:                            OLS   Adj. R-squared:                  0.136
Method:                 Least Squares   F-statistic:                     21.75
Date:                Sat, 09 Aug 2025   Prob (F-statistic):           4.71e-13
Time:                        12:35:31   Log-Likelihood:                 38.942
No. Observations:                 398   AIC:                            -69.88
Df Residuals:                     394   BIC:                            -53.94
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.0700      0.055     -1.279      0.202      -0.178       0.038
p1                    0.0764      0.066      1.155      0.249      -0.054       0.206
answer_changed       -0.1852      0.095     -1.949      0.052      -0.372       0.002
p1:answer_changed     0.5808      0.142      4.083      0.000       0.301       0.860
==============================================================================
Omnibus:                       11.333   Durbin-Watson:                   1.973
Prob(Omnibus):                  0.003   Jarque-Bera (JB):               13.143
Skew:                           0.308   Prob(JB):                      0.00140
Kurtosis:                       3.642   Cond. No.                         20.7
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=5.14, p=5.1e-07
Wilcoxon delta_H: statistic=12490.00, p=4.04e-07
Mean ΔH = 0.1371  [0.0849, 0.1894]
Paired t-test delta_H Changed: statistic=8.60, p=3.53e-14
Wilcoxon delta_H Changed: statistic=835.00, p=2.48e-13
Mean ΔH Changed = 0.3019  [0.2331, 0.3707]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=8.51, p=3.69e-16
Wilcoxon (p_top2_game vs p_top2_base): statistic=16216.00, p=9.16e-25
Mean Δp_top2 = 0.0356  [0.0274, 0.0438] (n=399)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=8.62, p=1.66e-16
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=20494.00, p=9.71e-17
Mean ΔH_unchosen_baseline_set = 0.1871  [0.1445, 0.2297] (n=399)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  399
Model:                          Logit   Df Residuals:                      396
Method:                           MLE   Df Model:                            2
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.2029
Time:                        12:35:31   Log-Likelihood:                -195.16
converged:                       True   LL-Null:                       -244.83
Covariance Type:            nonrobust   LLR p-value:                 2.680e-22
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.6066      0.171     -3.557      0.000      -0.941      -0.272
p1_z            -1.4858      0.195     -7.601      0.000      -1.869      -1.103
I(p1_z ** 2)    -0.6391      0.165     -3.879      0.000      -0.962      -0.316
================================================================================
AUC = 0.772

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1418
Time:                        12:35:31   Log-Likelihood:                -226.51
converged:                       True   LL-Null:                       -263.95
Covariance Type:            nonrobust   LLR p-value:                 4.998e-18
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -2.1509      0.205    -10.490      0.000      -2.553      -1.749
game_entropy     1.6421      0.205      8.014      0.000       1.240       2.044
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=22096.00, p=1.39e-24
Paired t-test (game_entropy vs capabilities_entropy): statistic=-10.38, p=9.48e-23
Mean capabilities_entropy-game_entropy = 0.1984  [0.1609, 0.2358] (n=447)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      444
Method:                           MLE   Df Model:                            2
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.2118
Time:                        12:35:31   Log-Likelihood:                -208.05
converged:                       True   LL-Null:                       -263.95
Covariance Type:            nonrobust   LLR p-value:                 5.303e-25
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.9864      0.287    -10.401      0.000      -3.549      -2.424
capabilities_entropy     1.8065      0.314      5.750      0.000       1.191       2.422
game_entropy             0.3458      0.300      1.155      0.248      -0.241       0.933
========================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                0.009905
Time:                        12:35:31   Log-Likelihood:                -261.33
converged:                       True   LL-Null:                       -263.95
Covariance Type:            nonrobust   LLR p-value:                   0.02221
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept            0.0497      0.454      0.110      0.913      -0.839       0.939
human_difficulty    -0.4306      0.191     -2.254      0.024      -0.805      -0.056
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      440
Method:                           MLE   Df Model:                            6
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.03225
Time:                        12:35:31   Log-Likelihood:                -255.43
converged:                       True   LL-Null:                       -263.95
Covariance Type:            nonrobust   LLR p-value:                  0.009188
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -3.1889      1.655     -1.927      0.054      -6.432       0.054
C(domain_grouped)[T.chemistry]        0.9506      0.388      2.448      0.014       0.189       1.712
C(domain_grouped)[T.physics]          0.9169      0.396      2.313      0.021       0.140       1.694
human_difficulty                     -0.3691      0.197     -1.874      0.061      -0.755       0.017
q_length                              0.3726      0.184      2.021      0.043       0.011       0.734
avg_word_length                       0.0003      0.184      0.002      0.999      -0.361       0.362
percent_non_alphabetic_whitespace     0.0094      0.020      0.482      0.630      -0.029       0.048
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 0.8128
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      439
Method:                           MLE   Df Model:                            7
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.2218
Time:                        12:35:31   Log-Likelihood:                -205.41
converged:                       True   LL-Null:                       -263.95
Covariance Type:            nonrobust   LLR p-value:                 3.106e-22
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -5.8845      1.878     -3.133      0.002      -9.566      -2.203
C(domain_grouped)[T.chemistry]       -0.0472      0.459     -0.103      0.918      -0.947       0.853
C(domain_grouped)[T.physics]          0.1002      0.472      0.212      0.832      -0.825       1.026
human_difficulty                     -0.3379      0.224     -1.506      0.132      -0.778       0.102
q_length                              0.3508      0.209      1.675      0.094      -0.060       0.761
avg_word_length                       0.2756      0.200      1.378      0.168      -0.116       0.668
percent_non_alphabetic_whitespace     0.0304      0.022      1.356      0.175      -0.014       0.074
capabilities_entropy                  2.1157      0.249      8.504      0.000       1.628       2.603
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      439
Method:                           MLE   Df Model:                            7
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1543
Time:                        12:35:31   Log-Likelihood:                -223.23
converged:                       True   LL-Null:                       -263.95
Covariance Type:            nonrobust   LLR p-value:                 6.993e-15
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -5.0613      1.774     -2.853      0.004      -8.539      -1.584
C(domain_grouped)[T.chemistry]        0.3590      0.425      0.844      0.398      -0.474       1.192
C(domain_grouped)[T.physics]          0.5110      0.437      1.169      0.243      -0.346       1.368
human_difficulty                     -0.2948      0.212     -1.388      0.165      -0.711       0.121
q_length                              0.2973      0.200      1.486      0.137      -0.095       0.689
avg_word_length                       0.2745      0.193      1.422      0.155      -0.104       0.653
percent_non_alphabetic_whitespace     0.0250      0.021      1.212      0.226      -0.015       0.066
game_entropy                          1.6183      0.217      7.461      0.000       1.193       2.043
=====================================================================================================

                  Model 4.95: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      438
Method:                           MLE   Df Model:                            8
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.2244
Time:                        12:35:31   Log-Likelihood:                -204.71
converged:                       True   LL-Null:                       -263.95
Covariance Type:            nonrobust   LLR p-value:                 6.843e-22
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -6.0069      1.891     -3.176      0.001      -9.714      -2.300
C(domain_grouped)[T.chemistry]       -0.0521      0.459     -0.114      0.910      -0.951       0.847
C(domain_grouped)[T.physics]          0.1058      0.473      0.224      0.823      -0.821       1.032
human_difficulty                     -0.3270      0.225     -1.453      0.146      -0.768       0.114
q_length                              0.3411      0.210      1.625      0.104      -0.070       0.753
avg_word_length                       0.3035      0.203      1.492      0.136      -0.095       0.702
percent_non_alphabetic_whitespace     0.0314      0.022      1.398      0.162      -0.013       0.075
capabilities_entropy                  1.8625      0.325      5.733      0.000       1.226       2.499
game_entropy                          0.3593      0.304      1.183      0.237      -0.236       0.955
=====================================================================================================

--- Analyzing grok-3-latest (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_neutral/grok-3-latest_GPQA_redacted_cor_temp0.0_1751833528_game_data.json', './sc_logs_neutral/grok-3-latest_GPQA_redacted_temp0.0_1751825913_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    369
1     78
Name: count, dtype: int64

Answer change%: 0.1745 [0.13931247588832357, 0.20968081270228045] (n=447)
P-value vs 25%: 2.6e-05; P-value vs 0%: 2.466e-22
Phase 2 self-accuracy: 0.2308 [0.1372678412973719, 0.32427062024108966] (n=78)
P-value vs 25%: 0.6869; P-value vs 33%: 0.03212

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.01499
Time:                        12:35:31   Log-Likelihood:                -203.83
converged:                       True   LL-Null:                       -206.94
Covariance Type:            nonrobust   LLR p-value:                   0.01274
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept         -0.5466      0.399     -1.369      0.171      -1.329       0.236
p_i_capability    -1.1763      0.453     -2.598      0.009      -2.064      -0.289
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  433
Model:                          Logit   Df Residuals:                      431
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.09725
Time:                        12:35:31   Log-Likelihood:                -181.58
converged:                       True   LL-Null:                       -201.14
Covariance Type:            nonrobust   LLR p-value:                 3.980e-10
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.2396      0.190    -11.811      0.000      -2.611      -1.868
capabilities_entropy     1.8021      0.291      6.203      0.000       1.233       2.372
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.8000 [0.7095, 0.8905] (n=75)
                  P-value vs 33.3%: 5.323e-24

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=0.01, p=0.995
Wilcoxon delta_p: statistic=21836.00, p=1.57e-05
Mean Δp = 0.0000  [-0.0140, 0.0141]
Idea 1 N = 345; 

  Idea 1.5: Calibration Metrics
  NLL: 3.7898, Signed ECE (overconf pos under neg): 0.0021, ECE: 0.0384 (n=420)
  Brier: 0.0094, Reliability (absolute calibration error; lower better): 0.0079, Resolution (relative calibration quality; higher better): 0.2470, Uncertainty: 0.2482 (n=420)
  AUROC: 1.0000

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.850
Model:                            OLS   Adj. R-squared:                  0.849
Method:                 Least Squares   F-statistic:                     784.3
Date:                Sat, 09 Aug 2025   Prob (F-statistic):          8.90e-171
Time:                        12:35:31   Log-Likelihood:                 286.61
No. Observations:                 420   AIC:                            -565.2
Df Residuals:                     416   BIC:                            -549.1
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.5360      0.055     -9.684      0.000      -0.645      -0.427
p1                    0.5698      0.058      9.755      0.000       0.455       0.685
answer_changed        0.3887      0.091      4.251      0.000       0.209       0.568
p1:answer_changed     0.4671      0.104      4.513      0.000       0.264       0.671
==============================================================================
Omnibus:                      117.878   Durbin-Watson:                   2.204
Prob(Omnibus):                  0.000   Jarque-Bera (JB):              396.029
Skew:                           1.255   Prob(JB):                     1.01e-86
Kurtosis:                       7.041   Cond. No.                         34.0
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-0.90, p=0.367
Wilcoxon delta_H: statistic=27872.00, p=0.288
Mean ΔH = -0.0249  [-0.0790, 0.0292]
Paired t-test delta_H Changed: statistic=5.38, p=8.25e-07
Wilcoxon delta_H Changed: statistic=425.00, p=1.29e-07
Mean ΔH Changed = 0.2416  [0.1537, 0.3296]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=1.89, p=0.0596
Wilcoxon (p_top2_game vs p_top2_base): statistic=24980.00, p=1.13e-14
Mean Δp_top2 = 0.0042  [-0.0002, 0.0086] (n=420)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=0.92, p=0.356
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=41760.00, p=0.326
Mean ΔH_unchosen_baseline_set = 0.0227  [-0.0254, 0.0708] (n=420)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  420
Model:                          Logit   Df Residuals:                      417
Method:                           MLE   Df Model:                            2
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.09713
Time:                        12:35:31   Log-Likelihood:                -177.93
converged:                       True   LL-Null:                       -197.07
Covariance Type:            nonrobust   LLR p-value:                 4.863e-09
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.4597      0.162     -8.984      0.000      -1.778      -1.141
p1_z            -1.1217      0.240     -4.681      0.000      -1.591      -0.652
I(p1_z ** 2)    -0.2321      0.103     -2.262      0.024      -0.433      -0.031
================================================================================
AUC = 0.780

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1011
Time:                        12:35:31   Log-Likelihood:                -186.02
converged:                       True   LL-Null:                       -206.94
Covariance Type:            nonrobust   LLR p-value:                 9.919e-11
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -2.1971      0.181    -12.171      0.000      -2.551      -1.843
game_entropy     1.8614      0.295      6.309      0.000       1.283       2.440
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=34672.00, p=2.31e-06
Paired t-test (game_entropy vs capabilities_entropy): statistic=-1.82, p=0.0689
Mean capabilities_entropy-game_entropy = 0.0348  [-0.0026, 0.0723] (n=433)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  433
Model:                          Logit   Df Residuals:                      430
Method:                           MLE   Df Model:                            2
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1310
Time:                        12:35:31   Log-Likelihood:                -174.80
converged:                       True   LL-Null:                       -201.14
Covariance Type:            nonrobust   LLR p-value:                 3.626e-12
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.4674      0.210    -11.754      0.000      -2.879      -2.056
capabilities_entropy     1.2785      0.327      3.912      0.000       0.638       1.919
game_entropy             1.2305      0.330      3.732      0.000       0.584       1.877
========================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                0.002244
Time:                        12:35:31   Log-Likelihood:                -206.47
converged:                       True   LL-Null:                       -206.94
Covariance Type:            nonrobust   LLR p-value:                    0.3352
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -1.0566      0.529     -1.996      0.046      -2.094      -0.019
human_difficulty    -0.2119      0.221     -0.958      0.338      -0.645       0.222
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      440
Method:                           MLE   Df Model:                            6
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                 0.01463
Time:                        12:35:31   Log-Likelihood:                -203.91
converged:                       True   LL-Null:                       -206.94
Covariance Type:            nonrobust   LLR p-value:                    0.4170
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -2.3180      1.914     -1.211      0.226      -6.069       1.433
C(domain_grouped)[T.chemistry]        0.9430      0.463      2.036      0.042       0.035       1.851
C(domain_grouped)[T.physics]          0.8717      0.473      1.844      0.065      -0.055       1.798
human_difficulty                     -0.1344      0.226     -0.596      0.551      -0.576       0.308
q_length                              0.0632      0.208      0.303      0.762      -0.345       0.472
avg_word_length                    2.558e-05      0.216      0.000      1.000      -0.422       0.422
percent_non_alphabetic_whitespace    -0.0091      0.024     -0.385      0.700      -0.055       0.037
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 0.2951
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  433
Model:                          Logit   Df Residuals:                      425
Method:                           MLE   Df Model:                            7
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1028
Time:                        12:35:31   Log-Likelihood:                -180.46
converged:                       True   LL-Null:                       -201.14
Covariance Type:            nonrobust   LLR p-value:                 6.866e-07
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -3.5230      1.970     -1.788      0.074      -7.384       0.338
C(domain_grouped)[T.chemistry]        0.4761      0.488      0.976      0.329      -0.480       1.432
C(domain_grouped)[T.physics]          0.4047      0.508      0.796      0.426      -0.591       1.401
human_difficulty                     -0.2060      0.239     -0.862      0.389      -0.674       0.262
q_length                              0.1347      0.220      0.612      0.540      -0.297       0.566
avg_word_length                       0.1249      0.216      0.579      0.563      -0.298       0.548
percent_non_alphabetic_whitespace     0.0027      0.024      0.114      0.909      -0.044       0.050
capabilities_entropy                  1.7811      0.300      5.936      0.000       1.193       2.369
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      439
Method:                           MLE   Df Model:                            7
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1114
Time:                        12:35:31   Log-Likelihood:                -183.89
converged:                       True   LL-Null:                       -206.94
Covariance Type:            nonrobust   LLR p-value:                 8.362e-08
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -4.0015      1.988     -2.012      0.044      -7.899      -0.104
C(domain_grouped)[T.chemistry]        0.7814      0.491      1.590      0.112      -0.182       1.745
C(domain_grouped)[T.physics]          0.8273      0.506      1.634      0.102      -0.165       1.820
human_difficulty                     -0.1593      0.235     -0.678      0.498      -0.619       0.301
q_length                              0.1194      0.222      0.537      0.591      -0.316       0.555
avg_word_length                       0.1498      0.217      0.690      0.490      -0.276       0.575
percent_non_alphabetic_whitespace     0.0099      0.025      0.395      0.693      -0.039       0.059
game_entropy                          1.8558      0.299      6.200      0.000       1.269       2.442
=====================================================================================================

                  Model 4.95: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  433
Model:                          Logit   Df Residuals:                      424
Method:                           MLE   Df Model:                            8
Date:                Sat, 09 Aug 2025   Pseudo R-squ.:                  0.1370
Time:                        12:35:31   Log-Likelihood:                -173.59
converged:                       True   LL-Null:                       -201.14
Covariance Type:            nonrobust   LLR p-value:                 4.226e-09
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -4.1548      2.020     -2.057      0.040      -8.114      -0.196
C(domain_grouped)[T.chemistry]        0.4658      0.505      0.923      0.356      -0.524       1.455
C(domain_grouped)[T.physics]          0.4740      0.525      0.902      0.367      -0.556       1.504
human_difficulty                     -0.2062      0.243     -0.850      0.396      -0.682       0.270
q_length                              0.1512      0.227      0.667      0.505      -0.293       0.596
avg_word_length                       0.1684      0.218      0.771      0.440      -0.260       0.596
percent_non_alphabetic_whitespace     0.0119      0.025      0.478      0.632      -0.037       0.061
capabilities_entropy                  1.2421      0.338      3.677      0.000       0.580       1.904
game_entropy                          1.2556      0.335      3.750      0.000       0.599       1.912
=====================================================================================================
