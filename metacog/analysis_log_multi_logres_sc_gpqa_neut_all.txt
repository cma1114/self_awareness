
--- Analyzing claude-3-5-sonnet-20241022 (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_neutral/claude-3-5-sonnet-20241022_GPQA_redacted_cor_temp0.0_1754437810_game_data.json', './sc_logs_neutral/claude-3-5-sonnet-20241022_GPQA_redacted_temp0.0_1754429083_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    342
1    105
Name: count, dtype: int64

Answer change%: 0.2349 [0.19559915162998304, 0.27419950608813776] (n=447)
P-value vs 25%: 0.4514; P-value vs 0%: 1.07e-31
Phase 2 self-accuracy: 0.2571 [0.1735453502381671, 0.34074036404754715] (n=105)
P-value vs 25%: 0.867; P-value vs 33%: 0.07532

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1558
Time:                        16:14:14   Log-Likelihood:                -205.71
converged:                       True   LL-Null:                       -243.67
Covariance Type:            nonrobust   LLR p-value:                 2.944e-18
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          2.0288      0.394      5.149      0.000       1.256       2.801
p_i_capability    -4.7811      0.602     -7.937      0.000      -5.962      -3.600
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1480
Time:                        16:14:14   Log-Likelihood:                -207.61
converged:                       True   LL-Null:                       -243.67
Covariance Type:            nonrobust   LLR p-value:                 2.018e-17
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -3.2108      0.322     -9.975      0.000      -3.842      -2.580
capabilities_entropy     1.7935      0.235      7.639      0.000       1.333       2.254
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.7143 [0.6279, 0.8007] (n=105)
                  P-value vs 33.3%: 5.573e-18

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=-7.83, p=6.13e-14
Wilcoxon delta_p: statistic=6568.50, p=5.25e-14
Mean Δp = -0.0592  [-0.0740, -0.0444]
Idea 1 N = 342; 

  Idea 1.5: Calibration Metrics
  NLL: 1.6241, Signed ECE (overconf pos under neg): -0.0105, ECE: 0.1124 (n=447)
  Brier: 0.0494, Reliability (absolute calibration error; lower better): 0.0241, Resolution (relative calibration quality; higher better): 0.2211, Uncertainty: 0.2459 (n=447)
  AUROC: 0.9959

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.750
Model:                            OLS   Adj. R-squared:                  0.748
Method:                 Least Squares   F-statistic:                     442.0
Date:                Wed, 24 Sep 2025   Prob (F-statistic):          9.36e-133
Time:                        16:14:14   Log-Likelihood:                 308.10
No. Observations:                 447   AIC:                            -608.2
Df Residuals:                     443   BIC:                            -591.8
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.3584      0.026    -13.708      0.000      -0.410      -0.307
p1                    0.3858      0.033     11.828      0.000       0.322       0.450
answer_changed        0.1436      0.047      3.031      0.003       0.050       0.237
p1:answer_changed     0.6290      0.074      8.505      0.000       0.484       0.774
==============================================================================
Omnibus:                        9.967   Durbin-Watson:                   1.891
Prob(Omnibus):                  0.007   Jarque-Bera (JB):               13.040
Skew:                           0.212   Prob(JB):                      0.00147
Kurtosis:                       3.721   Cond. No.                         19.7
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-0.14, p=0.888
Wilcoxon delta_H: statistic=14477.50, p=0.672
Mean ΔH = -0.0033  [-0.0496, 0.0429]
Paired t-test delta_H Changed: statistic=11.01, p=3.83e-19
Wilcoxon delta_H Changed: statistic=167.00, p=6.21e-17
Mean ΔH Changed = 0.4195  [0.3448, 0.4942]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=10.33, p=1.39e-22
Wilcoxon (p_top2_game vs p_top2_base): statistic=11706.00, p=1.79e-23
Mean Δp_top2 = 0.0355  [0.0287, 0.0422] (n=447)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=4.40, p=1.38e-05
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=20923.50, p=3.45e-07
Mean ΔH_unchosen_baseline_set = 0.0960  [0.0532, 0.1388] (n=447)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      444
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1669
Time:                        16:14:14   Log-Likelihood:                -203.01
converged:                       True   LL-Null:                       -243.67
Covariance Type:            nonrobust   LLR p-value:                 2.194e-18
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.1747      0.179     -6.545      0.000      -1.526      -0.823
p1_z            -1.2924      0.186     -6.964      0.000      -1.656      -0.929
I(p1_z ** 2)    -0.3667      0.160     -2.294      0.022      -0.680      -0.053
================================================================================
AUC = 0.779

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1461
Time:                        16:14:14   Log-Likelihood:                -208.07
converged:                       True   LL-Null:                       -243.67
Covariance Type:            nonrobust   LLR p-value:                 3.208e-17
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -2.8931      0.272    -10.630      0.000      -3.427      -2.360
game_entropy     1.8659      0.238      7.854      0.000       1.400       2.332
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=11395.00, p=3.35e-24
Paired t-test (game_entropy vs capabilities_entropy): statistic=-10.61, p=1.34e-23
Mean game_entropy-capabilities_entropy = -0.1842  [-0.2183, -0.1502] (n=447)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      444
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1654
Time:                        16:14:14   Log-Likelihood:                -203.36
converged:                       True   LL-Null:                       -243.67
Covariance Type:            nonrobust   LLR p-value:                 3.116e-18
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -3.3013      0.321    -10.273      0.000      -3.931      -2.671
capabilities_entropy     1.0506      0.344      3.050      0.002       0.376       1.726
game_entropy             1.0172      0.355      2.864      0.004       0.321       1.713
========================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:               6.523e-05
Time:                        16:14:14   Log-Likelihood:                -243.66
converged:                       True   LL-Null:                       -243.67
Covariance Type:            nonrobust   LLR p-value:                    0.8585
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -1.0985      0.475     -2.314      0.021      -2.029      -0.168
human_difficulty    -0.0348      0.195     -0.178      0.859      -0.417       0.348
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      440
Method:                           MLE   Df Model:                            6
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.02478
Time:                        16:14:14   Log-Likelihood:                -237.64
converged:                       True   LL-Null:                       -243.67
Covariance Type:            nonrobust   LLR p-value:                   0.06032
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -1.3656      1.767     -0.773      0.440      -4.828       2.097
C(domain_grouped)[T.chemistry]        0.5255      0.394      1.332      0.183      -0.248       1.298
C(domain_grouped)[T.physics]          0.6328      0.393      1.609      0.108      -0.138       1.404
human_difficulty                      0.0446      0.202      0.221      0.825      -0.350       0.440
q_length                              0.2330      0.192      1.216      0.224      -0.142       0.608
avg_word_length                      -0.3797      0.215     -1.765      0.078      -0.801       0.042
percent_non_alphabetic_whitespace    -0.0087      0.021     -0.410      0.682      -0.050       0.033
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 0.9810
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      439
Method:                           MLE   Df Model:                            7
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1605
Time:                        16:14:14   Log-Likelihood:                -204.55
converged:                       True   LL-Null:                       -243.67
Covariance Type:            nonrobust   LLR p-value:                 3.148e-14
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -4.1630      1.935     -2.151      0.031      -7.955      -0.371
C(domain_grouped)[T.chemistry]       -0.3319      0.440     -0.754      0.451      -1.195       0.531
C(domain_grouped)[T.physics]          0.1657      0.437      0.379      0.705      -0.691       1.022
human_difficulty                      0.0528      0.221      0.239      0.811      -0.380       0.486
q_length                              0.1753      0.211      0.831      0.406      -0.238       0.589
avg_word_length                      -0.0787      0.225     -0.350      0.726      -0.520       0.362
percent_non_alphabetic_whitespace     0.0177      0.023      0.774      0.439      -0.027       0.062
capabilities_entropy                  1.8376      0.250      7.360      0.000       1.348       2.327
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      439
Method:                           MLE   Df Model:                            7
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1595
Time:                        16:14:14   Log-Likelihood:                -204.81
converged:                       True   LL-Null:                       -243.67
Covariance Type:            nonrobust   LLR p-value:                 4.011e-14
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -3.7426      1.898     -1.972      0.049      -7.463      -0.022
C(domain_grouped)[T.chemistry]       -0.4155      0.442     -0.940      0.347      -1.282       0.451
C(domain_grouped)[T.physics]          0.0816      0.435      0.187      0.851      -0.771       0.934
human_difficulty                      0.0692      0.224      0.308      0.758      -0.370       0.509
q_length                              0.1617      0.208      0.777      0.437      -0.246       0.570
avg_word_length                      -0.0892      0.221     -0.403      0.687      -0.523       0.345
percent_non_alphabetic_whitespace     0.0237      0.022      1.054      0.292      -0.020       0.068
game_entropy                          1.9264      0.257      7.502      0.000       1.423       2.430
=====================================================================================================

                  Model 4.95: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      438
Method:                           MLE   Df Model:                            8
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1795
Time:                        16:14:14   Log-Likelihood:                -199.93
converged:                       True   LL-Null:                       -243.67
Covariance Type:            nonrobust   LLR p-value:                 1.498e-15
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -4.3367      1.939     -2.237      0.025      -8.137      -0.537
C(domain_grouped)[T.chemistry]       -0.5349      0.449     -1.191      0.233      -1.415       0.345
C(domain_grouped)[T.physics]          0.0274      0.441      0.062      0.950      -0.836       0.891
human_difficulty                      0.0725      0.226      0.321      0.749      -0.371       0.515
q_length                              0.1573      0.212      0.741      0.459      -0.259       0.573
avg_word_length                      -0.0406      0.226     -0.180      0.857      -0.483       0.402
percent_non_alphabetic_whitespace     0.0247      0.023      1.071      0.284      -0.020       0.070
capabilities_entropy                  1.0867      0.350      3.108      0.002       0.401       1.772
game_entropy                          1.0840      0.363      2.986      0.003       0.372       1.796
=====================================================================================================

--- Analyzing claude-3-haiku-20240307 (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_neutral/claude-3-haiku-20240307_GPQA_redacted_cor_temp0.0_1754422886_game_data.json', './sc_logs_neutral/claude-3-haiku-20240307_GPQA_redacted_temp0.0_1754341516_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    361
1     86
Name: count, dtype: int64

Answer change%: 0.1924 [0.15585196154695458, 0.2289355104888396] (n=447)
P-value vs 25%: 0.002003; P-value vs 0%: 5.765e-25
Phase 2 self-accuracy: 0.1977 [0.11350595102809745, 0.28184288618120484] (n=86)
P-value vs 25%: 0.223; P-value vs 33%: 0.001626

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1344
Time:                        16:14:14   Log-Likelihood:                -189.47
converged:                       True   LL-Null:                       -218.88
Covariance Type:            nonrobust   LLR p-value:                 1.712e-14
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          3.5039      0.657      5.335      0.000       2.217       4.791
p_i_capability    -5.7431      0.767     -7.491      0.000      -7.246      -4.241
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1509
Time:                        16:14:14   Log-Likelihood:                -185.85
converged:                       True   LL-Null:                       -218.88
Covariance Type:            nonrobust   LLR p-value:                 4.343e-16
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.9848      0.254    -11.757      0.000      -3.482      -2.487
capabilities_entropy     2.9068      0.375      7.747      0.000       2.171       3.642
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.5698 [0.4651, 0.6744] (n=86)
                  P-value vs 33.3%: 9.488e-06

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=0.50, p=0.615
Wilcoxon delta_p: statistic=3542.00, p=0.592
Mean Δp = 0.0035  [-0.0102, 0.0172]
Idea 1 N = 361; 

  Idea 1.5: Calibration Metrics
  NLL: 2.8327, Signed ECE (overconf pos under neg): -0.0156, ECE: 0.0407 (n=447)
  Brier: 0.0213, Reliability (absolute calibration error; lower better): 0.0049, Resolution (relative calibration quality; higher better): 0.2084, Uncertainty: 0.2244 (n=447)
  AUROC: 0.9984

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.870
Model:                            OLS   Adj. R-squared:                  0.869
Method:                 Least Squares   F-statistic:                     984.0
Date:                Wed, 24 Sep 2025   Prob (F-statistic):          1.97e-195
Time:                        16:14:14   Log-Likelihood:                 348.86
No. Observations:                 447   AIC:                            -689.7
Df Residuals:                     443   BIC:                            -673.3
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.6364      0.048    -13.389      0.000      -0.730      -0.543
p1                    0.6974      0.051     13.567      0.000       0.596       0.798
answer_changed        0.5257      0.071      7.358      0.000       0.385       0.666
p1:answer_changed     0.3193      0.085      3.777      0.000       0.153       0.485
==============================================================================
Omnibus:                      114.732   Durbin-Watson:                   1.997
Prob(Omnibus):                  0.000   Jarque-Bera (JB):              345.706
Skew:                           1.192   Prob(JB):                     8.53e-76
Kurtosis:                       6.588   Cond. No.                         31.3
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=0.39, p=0.697
Wilcoxon delta_H: statistic=3626.00, p=0.748
Mean ΔH = 0.0115  [-0.0464, 0.0694]
Paired t-test delta_H Changed: statistic=6.98, p=6.16e-10
Wilcoxon delta_H Changed: statistic=643.00, p=1.25e-07
Mean ΔH Changed = 0.5228  [0.3760, 0.6697]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=-0.08, p=0.936
Wilcoxon (p_top2_game vs p_top2_base): statistic=8834.50, p=0.252
Mean Δp_top2 = -0.0001  [-0.0031, 0.0029] (n=447)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=3.74, p=0.000212
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=7777.00, p=0.000376
Mean ΔH_unchosen_baseline_set = 0.1099  [0.0522, 0.1675] (n=447)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      444
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1702
Time:                        16:14:14   Log-Likelihood:                -181.63
converged:                       True   LL-Null:                       -218.88
Covariance Type:            nonrobust   LLR p-value:                 6.607e-17
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.1218      0.188     -5.980      0.000      -1.489      -0.754
p1_z            -1.9115      0.307     -6.223      0.000      -2.514      -1.309
I(p1_z ** 2)    -0.5584      0.146     -3.824      0.000      -0.845      -0.272
================================================================================
AUC = 0.750

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.04477
Time:                        16:14:14   Log-Likelihood:                -209.08
converged:                       True   LL-Null:                       -218.88
Covariance Type:            nonrobust   LLR p-value:                 9.546e-06
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -2.2418      0.227     -9.876      0.000      -2.687      -1.797
game_entropy     1.6499      0.365      4.526      0.000       0.935       2.364
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=9152.50, p=0.455
Paired t-test (game_entropy vs capabilities_entropy): statistic=-0.98, p=0.328
Mean game_entropy-capabilities_entropy = -0.0158  [-0.0473, 0.0158] (n=447)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      444
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1596
Time:                        16:14:14   Log-Likelihood:                -183.94
converged:                       True   LL-Null:                       -218.88
Covariance Type:            nonrobust   LLR p-value:                 6.681e-16
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -3.2709      0.301    -10.877      0.000      -3.860      -2.681
capabilities_entropy     2.6833      0.390      6.885      0.000       1.919       3.447
game_entropy             0.8367      0.423      1.978      0.048       0.007       1.666
========================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                0.001788
Time:                        16:14:14   Log-Likelihood:                -218.49
converged:                       True   LL-Null:                       -218.88
Covariance Type:            nonrobust   LLR p-value:                    0.3763
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -0.9949      0.510     -1.951      0.051      -1.994       0.004
human_difficulty    -0.1869      0.212     -0.880      0.379      -0.603       0.229
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      440
Method:                           MLE   Df Model:                            6
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.03348
Time:                        16:14:14   Log-Likelihood:                -211.56
converged:                       True   LL-Null:                       -218.88
Covariance Type:            nonrobust   LLR p-value:                   0.02312
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                             1.1103      1.900      0.584      0.559      -2.614       4.835
C(domain_grouped)[T.chemistry]        0.8096      0.406      1.995      0.046       0.014       1.605
C(domain_grouped)[T.physics]          0.0122      0.423      0.029      0.977      -0.817       0.842
human_difficulty                     -0.1196      0.225     -0.530      0.596      -0.562       0.322
q_length                              0.0550      0.204      0.270      0.787      -0.345       0.455
avg_word_length                      -0.5585      0.237     -2.354      0.019      -1.024      -0.094
percent_non_alphabetic_whitespace    -0.0494      0.025     -1.992      0.046      -0.098      -0.001
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 0.4659
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      439
Method:                           MLE   Df Model:                            7
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1740
Time:                        16:14:14   Log-Likelihood:                -180.79
converged:                       True   LL-Null:                       -218.88
Covariance Type:            nonrobust   LLR p-value:                 8.237e-14
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                             0.0871      2.083      0.042      0.967      -3.995       4.169
C(domain_grouped)[T.chemistry]        0.5647      0.433      1.304      0.192      -0.284       1.413
C(domain_grouped)[T.physics]         -0.2817      0.455     -0.619      0.536      -1.173       0.610
human_difficulty                     -0.0775      0.248     -0.313      0.755      -0.564       0.409
q_length                             -0.0627      0.223     -0.281      0.778      -0.499       0.374
avg_word_length                      -0.4813      0.260     -1.849      0.064      -0.991       0.029
percent_non_alphabetic_whitespace    -0.0551      0.028     -1.994      0.046      -0.109      -0.001
capabilities_entropy                  2.9017      0.392      7.398      0.000       2.133       3.670
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      439
Method:                           MLE   Df Model:                            7
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.07151
Time:                        16:14:14   Log-Likelihood:                -203.23
converged:                       True   LL-Null:                       -218.88
Covariance Type:            nonrobust   LLR p-value:                 5.459e-05
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                             0.0129      1.945      0.007      0.995      -3.799       3.825
C(domain_grouped)[T.chemistry]        0.6412      0.413      1.552      0.121      -0.168       1.451
C(domain_grouped)[T.physics]         -0.1689      0.437     -0.387      0.699      -1.025       0.688
human_difficulty                     -0.1150      0.233     -0.494      0.621      -0.571       0.341
q_length                              0.0648      0.207      0.314      0.754      -0.340       0.470
avg_word_length                      -0.4829      0.238     -2.029      0.042      -0.949      -0.017
percent_non_alphabetic_whitespace    -0.0404      0.025     -1.606      0.108      -0.090       0.009
game_entropy                          1.5491      0.374      4.146      0.000       0.817       2.281
=====================================================================================================

                  Model 4.95: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      438
Method:                           MLE   Df Model:                            8
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1812
Time:                        16:14:14   Log-Likelihood:                -179.23
converged:                       True   LL-Null:                       -218.88
Covariance Type:            nonrobust   LLR p-value:                 6.727e-14
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -0.4830      2.096     -0.230      0.818      -4.591       3.625
C(domain_grouped)[T.chemistry]        0.4876      0.433      1.125      0.261      -0.362       1.337
C(domain_grouped)[T.physics]         -0.3685      0.460     -0.802      0.423      -1.270       0.533
human_difficulty                     -0.0824      0.250     -0.329      0.742      -0.573       0.408
q_length                             -0.0392      0.222     -0.177      0.860      -0.474       0.396
avg_word_length                      -0.4380      0.259     -1.691      0.091      -0.946       0.070
percent_non_alphabetic_whitespace    -0.0497      0.028     -1.800      0.072      -0.104       0.004
capabilities_entropy                  2.7008      0.406      6.654      0.000       1.905       3.496
game_entropy                          0.7765      0.434      1.789      0.074      -0.074       1.627
=====================================================================================================

--- Analyzing claude-3-sonnet-20240229 (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_neutral/claude-3-sonnet-20240229_GPQA_redacted_cor_temp0.0_1751845558_game_data.json', './sc_logs_neutral/claude-3-sonnet-20240229_GPQA_redacted_temp0.0_1751827240_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    333
1    114
Name: count, dtype: int64

Answer change%: 0.2550 [0.21462611592929715, 0.2954409981646626] (n=447)
P-value vs 25%: 0.8071; P-value vs 0%: 3.779e-35
Phase 2 self-accuracy: 0.2632 [0.18232445043764473, 0.34399133903603946] (n=114)
P-value vs 25%: 0.7497; P-value vs 33%: 0.09037

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                0.001720
Time:                        16:14:14   Log-Likelihood:                -253.37
converged:                       True   LL-Null:                       -253.81
Covariance Type:            nonrobust   LLR p-value:                    0.3501
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -0.6519      0.462     -1.412      0.158      -1.557       0.253
human_difficulty    -0.1783      0.192     -0.930      0.352      -0.554       0.197
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      440
Method:                           MLE   Df Model:                            6
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.01499
Time:                        16:14:14   Log-Likelihood:                -250.00
converged:                       True   LL-Null:                       -253.81
Covariance Type:            nonrobust   LLR p-value:                    0.2681
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -0.7860      1.671     -0.470      0.638      -4.061       2.489
C(domain_grouped)[T.chemistry]        0.6981      0.378      1.846      0.065      -0.043       1.439
C(domain_grouped)[T.physics]          0.6900      0.382      1.806      0.071      -0.059       1.439
human_difficulty                     -0.1084      0.196     -0.553      0.581      -0.493       0.276
q_length                              0.0768      0.182      0.423      0.672      -0.279       0.433
avg_word_length                      -0.1966      0.196     -1.003      0.316      -0.581       0.187
percent_non_alphabetic_whitespace    -0.0206      0.021     -0.986      0.324      -0.062       0.020
=====================================================================================================

--- Analyzing claude-sonnet-4-20250514 (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_neutral/claude-sonnet-4-20250514_GPQA_redacted_cor_temp0.0_1751827811_game_data.json', './sc_logs_neutral/claude-sonnet-4-20250514_GPQA_redacted_temp0.0_1751824757_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    304
1    143
Name: count, dtype: int64

Answer change%: 0.3199 [0.27666992396704365, 0.3631511051157304] (n=447)
P-value vs 25%: 0.001531; P-value vs 0%: 1.202e-47
Phase 2 self-accuracy: 0.2517 [0.18061262306948928, 0.32288388042701427] (n=143)
P-value vs 25%: 0.9616; P-value vs 33%: 0.02518

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:               0.0002237
Time:                        16:14:14   Log-Likelihood:                -280.12
converged:                       True   LL-Null:                       -280.18
Covariance Type:            nonrobust   LLR p-value:                    0.7233
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -0.6056      0.431     -1.404      0.160      -1.451       0.240
human_difficulty    -0.0628      0.177     -0.354      0.724      -0.411       0.285
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      440
Method:                           MLE   Df Model:                            6
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.01618
Time:                        16:14:14   Log-Likelihood:                -275.65
converged:                       True   LL-Null:                       -280.18
Covariance Type:            nonrobust   LLR p-value:                    0.1699
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -1.5093      1.507     -1.002      0.316      -4.462       1.444
C(domain_grouped)[T.chemistry]        0.8777      0.334      2.628      0.009       0.223       1.532
C(domain_grouped)[T.physics]          0.4770      0.342      1.394      0.163      -0.194       1.148
human_difficulty                     -0.0201      0.184     -0.109      0.913      -0.381       0.341
q_length                              0.0918      0.167      0.548      0.583      -0.236       0.420
avg_word_length                      -0.0193      0.169     -0.114      0.909      -0.350       0.311
percent_non_alphabetic_whitespace    -0.0265      0.020     -1.340      0.180      -0.065       0.012
=====================================================================================================

--- Analyzing deepseek-chat (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_neutral/deepseek-chat_GPQA_redacted_cor_temp0.0_1754437275_game_data.json', './sc_logs_neutral/deepseek-chat_GPQA_redacted_temp0.0_1754429196_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    384
1     58
Name: count, dtype: int64

Answer change%: 0.1312 [0.09974464973960304, 0.16269878917442412] (n=442)
P-value vs 25%: 1.405e-13; P-value vs 0%: 3.066e-16
Phase 2 self-accuracy: 0.3276 [0.20680059475128126, 0.44837181904182216] (n=58)
P-value vs 25%: 0.208; P-value vs 33%: 0.93

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  442
Model:                          Logit   Df Residuals:                      440
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.01579
Time:                        16:14:14   Log-Likelihood:                -169.09
converged:                       True   LL-Null:                       -171.81
Covariance Type:            nonrobust   LLR p-value:                   0.01983
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept         -0.6456      0.531     -1.215      0.224      -1.687       0.396
p_i_capability    -1.5948      0.677     -2.357      0.018      -2.921      -0.269
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  442
Model:                          Logit   Df Residuals:                      440
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.02239
Time:                        16:14:14   Log-Likelihood:                -167.96
converged:                       True   LL-Null:                       -171.81
Covariance Type:            nonrobust   LLR p-value:                  0.005538
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.4046      0.250     -9.602      0.000      -2.895      -1.914
capabilities_entropy     0.6662      0.241      2.762      0.006       0.194       1.139
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.3103 [0.1913, 0.4294] (n=58)
                  P-value vs 33.3%: 0.7051

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=21.55, p=7.18e-68
Wilcoxon delta_p: statistic=5829.00, p=8.48e-46
Mean Δp = 0.5150  [0.4682, 0.5619]
Idea 1 N = 381; 

  Idea 1.5: Calibration Metrics
  NLL: 3.6864, Signed ECE (overconf pos under neg): -0.1617, ECE: 0.3741 (n=399)
  Brier: 0.3991, Reliability (absolute calibration error; lower better): 0.1686, Resolution (relative calibration quality; higher better): 0.0162, Uncertainty: 0.2449 (n=399)
  AUROC: 0.4180

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.187
Model:                            OLS   Adj. R-squared:                  0.182
Method:                 Least Squares   F-statistic:                     33.39
Date:                Wed, 24 Sep 2025   Prob (F-statistic):           1.93e-19
Time:                        16:14:14   Log-Likelihood:                -234.34
No. Observations:                 439   AIC:                             476.7
Df Residuals:                     435   BIC:                             493.0
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.2818      0.089     -3.154      0.002      -0.457      -0.106
p1                    0.9823      0.107      9.182      0.000       0.772       1.193
answer_changed       -0.0957      0.246     -0.389      0.698      -0.580       0.388
p1:answer_changed     0.2066      0.317      0.651      0.515      -0.417       0.830
==============================================================================
Omnibus:                      196.957   Durbin-Watson:                   1.982
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               81.939
Skew:                          -0.902   Prob(JB):                     1.61e-18
Kurtosis:                       1.893   Cond. No.                         26.4
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=7.66, p=1.53e-13
Wilcoxon delta_H: statistic=20662.00, p=6.51e-13
Mean ΔH = 0.3014  [0.2243, 0.3785]
Paired t-test delta_H Changed: statistic=5.34, p=1.7e-06
Wilcoxon delta_H Changed: statistic=259.00, p=3.87e-06
Mean ΔH Changed = 0.4223  [0.2672, 0.5774]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=9.06, p=4.48e-18
Wilcoxon (p_top2_game vs p_top2_base): statistic=35747.00, p=2.41e-06
Mean Δp_top2 = 0.0433  [0.0339, 0.0526] (n=439)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=8.88, p=1.69e-17
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=25953.00, p=1.14e-16
Mean ΔH_unchosen_baseline_set = 0.3174  [0.2474, 0.3874] (n=439)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  439
Model:                          Logit   Df Residuals:                      436
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.03754
Time:                        16:14:14   Log-Likelihood:                -164.95
converged:                       True   LL-Null:                       -171.38
Covariance Type:            nonrobust   LLR p-value:                  0.001605
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.5123      0.200     -7.550      0.000      -1.905      -1.120
p1_z            -0.6878      0.202     -3.401      0.001      -1.084      -0.291
I(p1_z ** 2)    -0.4704      0.178     -2.642      0.008      -0.819      -0.121
================================================================================
AUC = 0.650

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  442
Model:                          Logit   Df Residuals:                      440
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1297
Time:                        16:14:14   Log-Likelihood:                -149.52
converged:                       True   LL-Null:                       -171.81
Covariance Type:            nonrobust   LLR p-value:                 2.440e-11
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -3.4416      0.303    -11.375      0.000      -4.035      -2.849
game_entropy     3.3714      0.525      6.425      0.000       2.343       4.400
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=26525.00, p=7.06e-17
Paired t-test (game_entropy vs capabilities_entropy): statistic=-10.62, p=1.27e-23
Mean game_entropy-capabilities_entropy = -0.2870  [-0.3400, -0.2341] (n=442)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  442
Model:                          Logit   Df Residuals:                      439
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1332
Time:                        16:14:14   Log-Likelihood:                -148.92
converged:                       True   LL-Null:                       -171.81
Covariance Type:            nonrobust   LLR p-value:                 1.149e-10
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -3.5930      0.340    -10.574      0.000      -4.259      -2.927
capabilities_entropy     0.2940      0.268      1.097      0.273      -0.231       0.819
game_entropy             3.2123      0.541      5.940      0.000       2.152       4.272
========================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  442
Model:                          Logit   Df Residuals:                      440
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                0.006558
Time:                        16:14:14   Log-Likelihood:                -170.68
converged:                       True   LL-Null:                       -171.81
Covariance Type:            nonrobust   LLR p-value:                    0.1333
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -1.0150      0.597     -1.701      0.089      -2.184       0.154
human_difficulty    -0.3766      0.254     -1.481      0.139      -0.875       0.122
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  442
Model:                          Logit   Df Residuals:                      435
Method:                           MLE   Df Model:                            6
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.04839
Time:                        16:14:14   Log-Likelihood:                -163.49
converged:                       True   LL-Null:                       -171.81
Covariance Type:            nonrobust   LLR p-value:                   0.01075
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -2.4640      2.262     -1.089      0.276      -6.897       1.969
C(domain_grouped)[T.chemistry]        1.2742      0.532      2.394      0.017       0.231       2.317
C(domain_grouped)[T.physics]          0.9100      0.548      1.660      0.097      -0.164       1.984
human_difficulty                     -0.3859      0.260     -1.484      0.138      -0.896       0.124
q_length                              0.3790      0.248      1.531      0.126      -0.106       0.864
avg_word_length                      -0.2442      0.270     -0.903      0.366      -0.774       0.286
percent_non_alphabetic_whitespace    -0.0779      0.033     -2.341      0.019      -0.143      -0.013
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 0.6891
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  442
Model:                          Logit   Df Residuals:                      434
Method:                           MLE   Df Model:                            7
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.06566
Time:                        16:14:14   Log-Likelihood:                -160.53
converged:                       True   LL-Null:                       -171.81
Covariance Type:            nonrobust   LLR p-value:                  0.002032
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -2.5163      2.257     -1.115      0.265      -6.941       1.908
C(domain_grouped)[T.chemistry]        1.0748      0.543      1.979      0.048       0.010       2.139
C(domain_grouped)[T.physics]          0.8005      0.558      1.433      0.152      -0.294       1.895
human_difficulty                     -0.3874      0.263     -1.473      0.141      -0.903       0.128
q_length                              0.3130      0.249      1.259      0.208      -0.174       0.800
avg_word_length                      -0.2141      0.265     -0.806      0.420      -0.734       0.306
percent_non_alphabetic_whitespace    -0.0819      0.034     -2.424      0.015      -0.148      -0.016
capabilities_entropy                  0.6179      0.255      2.428      0.015       0.119       1.117
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  442
Model:                          Logit   Df Residuals:                      434
Method:                           MLE   Df Model:                            7
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1581
Time:                        16:14:14   Log-Likelihood:                -144.64
converged:                       True   LL-Null:                       -171.81
Covariance Type:            nonrobust   LLR p-value:                 2.027e-09
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -3.0576      2.376     -1.287      0.198      -7.715       1.600
C(domain_grouped)[T.chemistry]        0.8402      0.554      1.517      0.129      -0.245       1.926
C(domain_grouped)[T.physics]          0.5246      0.576      0.911      0.362      -0.604       1.654
human_difficulty                     -0.4393      0.284     -1.548      0.122      -0.996       0.117
q_length                              0.2893      0.263      1.099      0.272      -0.227       0.805
avg_word_length                      -0.2275      0.277     -0.820      0.412      -0.771       0.316
percent_non_alphabetic_whitespace    -0.0689      0.035     -1.945      0.052      -0.138       0.001
game_entropy                          3.1928      0.548      5.828      0.000       2.119       4.266
=====================================================================================================

                  Model 4.95: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  442
Model:                          Logit   Df Residuals:                      433
Method:                           MLE   Df Model:                            8
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1610
Time:                        16:14:14   Log-Likelihood:                -144.15
converged:                       True   LL-Null:                       -171.81
Covariance Type:            nonrobust   LLR p-value:                 3.838e-09
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -3.0667      2.371     -1.293      0.196      -7.714       1.580
C(domain_grouped)[T.chemistry]        0.7840      0.558      1.404      0.160      -0.311       1.879
C(domain_grouped)[T.physics]          0.5001      0.580      0.862      0.389      -0.637       1.637
human_difficulty                     -0.4272      0.284     -1.502      0.133      -0.985       0.130
q_length                              0.2657      0.264      1.007      0.314      -0.251       0.783
avg_word_length                      -0.2217      0.275     -0.806      0.420      -0.761       0.318
percent_non_alphabetic_whitespace    -0.0714      0.036     -2.005      0.045      -0.141      -0.002
capabilities_entropy                  0.2790      0.280      0.997      0.319      -0.269       0.828
game_entropy                          3.0560      0.561      5.444      0.000       1.956       4.156
=====================================================================================================

--- Analyzing gemini-1.5-pro (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_neutral/gemini-1.5-pro_GPQA_redacted_cor_temp0.0_1751845110_game_data.json', './sc_logs_neutral/gemini-1.5-pro_GPQA_redacted_temp0.0_1751826706_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    376
1     71
Name: count, dtype: int64

Answer change%: 0.1588 [0.12495150075454864, 0.19272187732151402] (n=447)
P-value vs 25%: 1.342e-07; P-value vs 0%: 4.027e-20
Phase 2 self-accuracy: 0.3521 [0.24101384534522574, 0.46321150676745027] (n=71)
P-value vs 25%: 0.07163; P-value vs 33%: 0.736

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:               6.127e-05
Time:                        16:14:14   Log-Likelihood:                -195.66
converged:                       True   LL-Null:                       -195.67
Covariance Type:            nonrobust   LLR p-value:                    0.8769
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -1.7498      0.551     -3.173      0.002      -2.831      -0.669
human_difficulty     0.0349      0.225      0.155      0.877      -0.407       0.477
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      440
Method:                           MLE   Df Model:                            6
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                0.009893
Time:                        16:14:14   Log-Likelihood:                -193.73
converged:                       True   LL-Null:                       -195.67
Covariance Type:            nonrobust   LLR p-value:                    0.6941
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                             0.3261      1.983      0.164      0.869      -3.561       4.213
C(domain_grouped)[T.chemistry]        0.0840      0.413      0.203      0.839      -0.726       0.894
C(domain_grouped)[T.physics]         -0.0219      0.414     -0.053      0.958      -0.834       0.790
human_difficulty                      0.0745      0.233      0.319      0.750      -0.383       0.532
q_length                              0.0056      0.214      0.026      0.979      -0.414       0.425
avg_word_length                      -0.4375      0.246     -1.781      0.075      -0.919       0.044
percent_non_alphabetic_whitespace    -0.0278      0.025     -1.097      0.273      -0.078       0.022
=====================================================================================================

--- Analyzing gemini-2.0-flash-001 (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_neutral/gemini-2.0-flash-001_GPQA_neut_redacted_cor_temp1.0_1757986899_game_data.json', './sc_logs_neutral/gemini-2.0-flash-001_GPQA_neut_redacted_temp1.0_1757986019_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    335
1    112
Name: count, dtype: int64

Answer change%: 0.2506 [0.21038776814866694, 0.29073080008399527] (n=447)
P-value vs 25%: 0.9782; P-value vs 0%: 2.293e-34
Phase 2 self-accuracy: 0.2946 [0.21021387129609906, 0.37907184298961527] (n=112)
P-value vs 25%: 0.3; P-value vs 33%: 0.3732

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1294
Time:                        16:14:14   Log-Likelihood:                -219.09
converged:                       True   LL-Null:                       -251.64
Covariance Type:            nonrobust   LLR p-value:                 7.117e-16
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          5.2127      0.879      5.928      0.000       3.489       6.936
p_i_capability    -6.8205      0.941     -7.244      0.000      -8.666      -4.975
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1520
Time:                        16:14:14   Log-Likelihood:                -213.38
converged:                       True   LL-Null:                       -251.64
Covariance Type:            nonrobust   LLR p-value:                 2.186e-18
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.7750      0.151    -11.726      0.000      -2.072      -1.478
capabilities_entropy     2.4487      0.304      8.043      0.000       1.852       3.045
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.5657 [0.4680, 0.6633] (n=99)
                  P-value vs 33.3%: 3.108e-06

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=4.80, p=3.66e-06
Wilcoxon delta_p: statistic=3428.00, p=7.35e-07
Mean Δp = 0.0700  [0.0414, 0.0986]
Idea 1 N = 158; 

  Idea 1.5: Calibration Metrics
  NLL: 4.9259, Signed ECE (overconf pos under neg): -0.0289, ECE: 0.0433 (n=255)
  Brier: 0.0419, Reliability (absolute calibration error; lower better): 0.0092, Resolution (relative calibration quality; higher better): 0.2044, Uncertainty: 0.2384 (n=255)
  AUROC: 0.9902

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.678
Model:                            OLS   Adj. R-squared:                  0.674
Method:                 Least Squares   F-statistic:                     176.2
Date:                Wed, 24 Sep 2025   Prob (F-statistic):           1.78e-61
Time:                        16:14:14   Log-Likelihood:                 30.017
No. Observations:                 255   AIC:                            -52.03
Df Residuals:                     251   BIC:                            -37.87
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept             0.0976      0.141      0.694      0.488      -0.179       0.375
p1                   -0.0294      0.149     -0.197      0.844      -0.323       0.264
answer_changed       -0.7359      0.177     -4.155      0.000      -1.085      -0.387
p1:answer_changed     1.5359      0.195      7.866      0.000       1.151       1.920
==============================================================================
Omnibus:                       15.993   Durbin-Watson:                   2.088
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               39.923
Skew:                          -0.187   Prob(JB):                     2.14e-09
Kurtosis:                       4.902   Cond. No.                         33.7
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-1.30, p=0.196
Wilcoxon delta_H: statistic=5722.00, p=0.332
Mean ΔH = -0.0573  [-0.1438, 0.0293]
Paired t-test delta_H Changed: statistic=3.48, p=0.000741
Wilcoxon delta_H Changed: statistic=1474.00, p=0.000747
Mean ΔH Changed = 0.1974  [0.0864, 0.3085]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=-2.51, p=0.0128
Wilcoxon (p_top2_game vs p_top2_base): statistic=12401.00, p=0.000643
Mean Δp_top2 = -0.0096  [-0.0171, -0.0021] (n=256)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=1.13, p=0.26
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=14835.00, p=0.174
Mean ΔH_unchosen_baseline_set = 0.0402  [-0.0296, 0.1100] (n=256)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  256
Model:                          Logit   Df Residuals:                      253
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.08466
Time:                        16:14:14   Log-Likelihood:                -155.93
converged:                       True   LL-Null:                       -170.35
Covariance Type:            nonrobust   LLR p-value:                 5.455e-07
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.3327      0.188     -1.770      0.077      -0.701       0.036
p1_z            -0.9513      0.250     -3.804      0.000      -1.441      -0.461
I(p1_z ** 2)    -0.1766      0.138     -1.278      0.201      -0.447       0.094
================================================================================
AUC = 0.687

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1301
Time:                        16:14:14   Log-Likelihood:                -218.89
converged:                       True   LL-Null:                       -251.64
Covariance Type:            nonrobust   LLR p-value:                 5.826e-16
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.8174      0.159    -11.414      0.000      -2.129      -1.505
game_entropy     1.9418      0.254      7.641      0.000       1.444       2.440
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=36652.00, p=9.21e-07
Paired t-test (game_entropy vs capabilities_entropy): statistic=3.80, p=0.000163
Mean game_entropy-capabilities_entropy = 0.0784  [0.0380, 0.1189] (n=447)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      444
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.2039
Time:                        16:14:14   Log-Likelihood:                -200.33
converged:                       True   LL-Null:                       -251.64
Covariance Type:            nonrobust   LLR p-value:                 5.190e-23
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.1560      0.183    -11.787      0.000      -2.515      -1.798
capabilities_entropy     1.9208      0.324      5.926      0.000       1.286       2.556
game_entropy             1.4067      0.277      5.070      0.000       0.863       1.950
========================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:               0.0008094
Time:                        16:14:14   Log-Likelihood:                -251.43
converged:                       True   LL-Null:                       -251.64
Covariance Type:            nonrobust   LLR p-value:                    0.5233
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -0.8073      0.464     -1.739      0.082      -1.717       0.102
human_difficulty    -0.1222      0.192     -0.637      0.524      -0.498       0.254
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      440
Method:                           MLE   Df Model:                            6
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.01591
Time:                        16:14:14   Log-Likelihood:                -247.63
converged:                       True   LL-Null:                       -251.64
Covariance Type:            nonrobust   LLR p-value:                    0.2376
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -2.3661      1.651     -1.433      0.152      -5.603       0.870
C(domain_grouped)[T.chemistry]        0.2933      0.368      0.797      0.425      -0.428       1.014
C(domain_grouped)[T.physics]          0.3355      0.372      0.901      0.368      -0.395       1.066
human_difficulty                     -0.0452      0.200     -0.226      0.821      -0.437       0.346
q_length                              0.1712      0.184      0.929      0.353      -0.190       0.533
avg_word_length                      -0.0417      0.185     -0.225      0.822      -0.404       0.321
percent_non_alphabetic_whitespace     0.0323      0.019      1.658      0.097      -0.006       0.071
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 0.2220
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      439
Method:                           MLE   Df Model:                            7
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1580
Time:                        16:14:14   Log-Likelihood:                -211.88
converged:                       True   LL-Null:                       -251.64
Covariance Type:            nonrobust   LLR p-value:                 1.729e-14
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -2.4583      1.781     -1.380      0.168      -5.950       1.033
C(domain_grouped)[T.chemistry]       -0.1027      0.399     -0.258      0.797      -0.884       0.679
C(domain_grouped)[T.physics]          0.1053      0.404      0.261      0.794      -0.686       0.896
human_difficulty                     -0.0711      0.222     -0.321      0.748      -0.505       0.363
q_length                              0.0130      0.202      0.064      0.949      -0.384       0.410
avg_word_length                       0.1066      0.196      0.543      0.587      -0.278       0.492
percent_non_alphabetic_whitespace     0.0321      0.021      1.522      0.128      -0.009       0.073
capabilities_entropy                  2.4436      0.315      7.757      0.000       1.826       3.061
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      439
Method:                           MLE   Df Model:                            7
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1409
Time:                        16:14:14   Log-Likelihood:                -216.18
converged:                       True   LL-Null:                       -251.64
Covariance Type:            nonrobust   LLR p-value:                 9.644e-13
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -2.9648      1.770     -1.675      0.094      -6.434       0.504
C(domain_grouped)[T.chemistry]       -0.1551      0.399     -0.389      0.697      -0.936       0.626
C(domain_grouped)[T.physics]         -0.0380      0.406     -0.094      0.925      -0.835       0.759
human_difficulty                      0.0066      0.220      0.030      0.976      -0.425       0.438
q_length                              0.0325      0.198      0.164      0.869      -0.355       0.420
avg_word_length                       0.1278      0.196      0.650      0.516      -0.257       0.513
percent_non_alphabetic_whitespace     0.0474      0.022      2.166      0.030       0.005       0.090
game_entropy                          1.9717      0.264      7.462      0.000       1.454       2.490
=====================================================================================================

                  Model 4.95: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      438
Method:                           MLE   Df Model:                            8
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.2122
Time:                        16:14:14   Log-Likelihood:                -198.23
converged:                       True   LL-Null:                       -251.64
Covariance Type:            nonrobust   LLR p-value:                 1.722e-19
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -2.9469      1.851     -1.592      0.111      -6.575       0.681
C(domain_grouped)[T.chemistry]       -0.3467      0.412     -0.841      0.400      -1.154       0.461
C(domain_grouped)[T.physics]         -0.1358      0.421     -0.322      0.747      -0.962       0.690
human_difficulty                     -0.0111      0.235     -0.047      0.962      -0.472       0.450
q_length                             -0.0478      0.208     -0.230      0.818      -0.456       0.361
avg_word_length                       0.1979      0.203      0.974      0.330      -0.200       0.596
percent_non_alphabetic_whitespace     0.0409      0.022      1.841      0.066      -0.003       0.084
capabilities_entropy                  1.9317      0.333      5.794      0.000       1.278       2.585
game_entropy                          1.4775      0.286      5.157      0.000       0.916       2.039
=====================================================================================================

--- Analyzing gemini-2.5-flash-lite_nothink (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_neutral/gemini-2.5-flash-lite_nothink_GPQA_neut_redacted_cor_temp1.0_1757983669_game_data.json', './sc_logs_neutral/gemini-2.5-flash-lite_nothink_GPQA_neut_redacted_temp1.0_1757983467_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    314
1    133
Name: count, dtype: int64

Answer change%: 0.2975 [0.2551575398784204, 0.33992075989786597] (n=447)
P-value vs 25%: 0.02792; P-value vs 0%: 4.442e-43
Phase 2 self-accuracy: 0.3459 [0.26502785076763935, 0.4267014725406313] (n=133)
P-value vs 25%: 0.02011; P-value vs 33%: 0.7551

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.05995
Time:                        16:14:14   Log-Likelihood:                -255.81
converged:                       True   LL-Null:                       -272.12
Covariance Type:            nonrobust   LLR p-value:                 1.118e-08
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          1.2592      0.385      3.268      0.001       0.504       2.014
p_i_capability    -2.8658      0.515     -5.561      0.000      -3.876      -1.856
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.07684
Time:                        16:14:14   Log-Likelihood:                -251.21
converged:                       True   LL-Null:                       -272.12
Covariance Type:            nonrobust   LLR p-value:                 9.998e-11
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.9076      0.214     -8.895      0.000      -2.328      -1.487
capabilities_entropy     1.1433      0.186      6.154      0.000       0.779       1.507
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.3158 [0.2368, 0.3948] (n=133)
                  P-value vs 33.3%: 0.6634

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=18.44, p=4.7e-51
Wilcoxon delta_p: statistic=3923.00, p=1.67e-34
Mean Δp = 0.4786  [0.4277, 0.5295]
Idea 1 N = 296; 

  Idea 1.5: Calibration Metrics
  NLL: 3.3372, Signed ECE (overconf pos under neg): -0.1322, ECE: 0.3501 (n=445)
  Brier: 0.3722, Reliability (absolute calibration error; lower better): 0.1402, Resolution (relative calibration quality; higher better): 0.0086, Uncertainty: 0.2371 (n=445)
  AUROC: 0.4285

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.194
Model:                            OLS   Adj. R-squared:                  0.189
Method:                 Least Squares   F-statistic:                     34.08
Date:                Wed, 24 Sep 2025   Prob (F-statistic):           9.49e-20
Time:                        16:14:14   Log-Likelihood:                -195.34
No. Observations:                 428   AIC:                             398.7
Df Residuals:                     424   BIC:                             414.9
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.1967      0.090     -2.195      0.029      -0.373      -0.021
p1                    0.8554      0.110      7.780      0.000       0.639       1.072
answer_changed       -0.0909      0.148     -0.612      0.541      -0.383       0.201
p1:answer_changed     0.2161      0.201      1.075      0.283      -0.179       0.611
==============================================================================
Omnibus:                      105.772   Durbin-Watson:                   2.046
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               71.016
Skew:                          -0.881   Prob(JB):                     3.79e-16
Kurtosis:                       2.062   Cond. No.                         18.7
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=11.73, p=1.36e-26
Wilcoxon delta_H: statistic=8865.00, p=6.71e-23
Mean ΔH = 0.4053  [0.3376, 0.4731]
Paired t-test delta_H Changed: statistic=6.22, p=6.19e-09
Wilcoxon delta_H Changed: statistic=1986.00, p=2.92e-08
Mean ΔH Changed = 0.3074  [0.2105, 0.4044]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=7.49, p=3.71e-13
Wilcoxon (p_top2_game vs p_top2_base): statistic=29191.00, p=2.2e-14
Mean Δp_top2 = 0.0329  [0.0243, 0.0415] (n=447)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=13.23, p=5.95e-34
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=19207.00, p=1.44e-29
Mean ΔH_unchosen_baseline_set = 0.3762  [0.3205, 0.4319] (n=447)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      444
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.06797
Time:                        16:14:14   Log-Likelihood:                -253.62
converged:                       True   LL-Null:                       -272.12
Covariance Type:            nonrobust   LLR p-value:                 9.263e-09
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.6899      0.156     -4.414      0.000      -0.996      -0.384
p1_z            -0.7464      0.133     -5.611      0.000      -1.007      -0.486
I(p1_z ** 2)    -0.2616      0.126     -2.079      0.038      -0.508      -0.015
================================================================================
AUC = 0.675

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1473
Time:                        16:14:14   Log-Likelihood:                -232.04
converged:                       True   LL-Null:                       -272.12
Covariance Type:            nonrobust   LLR p-value:                 3.449e-19
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -2.0419      0.194    -10.529      0.000      -2.422      -1.662
game_entropy     1.8156      0.221      8.220      0.000       1.383       2.248
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=23354.00, p=1.45e-22
Paired t-test (game_entropy vs capabilities_entropy): statistic=-10.92, p=9.21e-25
Mean game_entropy-capabilities_entropy = -0.2640  [-0.3114, -0.2166] (n=447)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      444
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1514
Time:                        16:14:14   Log-Likelihood:                -230.92
converged:                       True   LL-Null:                       -272.12
Covariance Type:            nonrobust   LLR p-value:                 1.276e-18
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.2173      0.232     -9.566      0.000      -2.672      -1.763
capabilities_entropy     0.3458      0.231      1.499      0.134      -0.106       0.798
game_entropy             1.5958      0.263      6.076      0.000       1.081       2.111
========================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                0.004503
Time:                        16:14:14   Log-Likelihood:                -270.89
converged:                       True   LL-Null:                       -272.12
Covariance Type:            nonrobust   LLR p-value:                    0.1175
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -0.1866      0.442     -0.422      0.673      -1.052       0.679
human_difficulty    -0.2860      0.184     -1.554      0.120      -0.647       0.075
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      440
Method:                           MLE   Df Model:                            6
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.02413
Time:                        16:14:14   Log-Likelihood:                -265.55
converged:                       True   LL-Null:                       -272.12
Covariance Type:            nonrobust   LLR p-value:                   0.04097
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -1.4479      1.595     -0.908      0.364      -4.575       1.679
C(domain_grouped)[T.chemistry]        0.9392      0.372      2.522      0.012       0.209       1.669
C(domain_grouped)[T.physics]          0.7443      0.381      1.954      0.051      -0.002       1.491
human_difficulty                     -0.1612      0.191     -0.846      0.398      -0.535       0.212
q_length                              0.0611      0.175      0.349      0.727      -0.282       0.404
avg_word_length                      -0.0496      0.180     -0.275      0.783      -0.403       0.304
percent_non_alphabetic_whitespace     0.0127      0.019      0.673      0.501      -0.024       0.050
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 0.8340
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      439
Method:                           MLE   Df Model:                            7
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.08510
Time:                        16:14:14   Log-Likelihood:                -248.96
converged:                       True   LL-Null:                       -272.12
Covariance Type:            nonrobust   LLR p-value:                 7.593e-08
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -2.3380      1.640     -1.425      0.154      -5.553       0.877
C(domain_grouped)[T.chemistry]        0.3800      0.397      0.958      0.338      -0.397       1.157
C(domain_grouped)[T.physics]          0.4201      0.401      1.048      0.295      -0.365       1.205
human_difficulty                     -0.1352      0.199     -0.680      0.497      -0.525       0.255
q_length                             -0.0218      0.180     -0.121      0.904      -0.375       0.332
avg_word_length                       0.0847      0.182      0.467      0.641      -0.271       0.441
percent_non_alphabetic_whitespace     0.0229      0.019      1.175      0.240      -0.015       0.061
capabilities_entropy                  1.0820      0.196      5.520      0.000       0.698       1.466
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      439
Method:                           MLE   Df Model:                            7
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1594
Time:                        16:14:14   Log-Likelihood:                -228.75
converged:                       True   LL-Null:                       -272.12
Covariance Type:            nonrobust   LLR p-value:                 5.806e-16
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -2.2920      1.730     -1.325      0.185      -5.683       1.099
C(domain_grouped)[T.chemistry]        0.3462      0.410      0.844      0.399      -0.458       1.150
C(domain_grouped)[T.physics]          0.4558      0.418      1.090      0.276      -0.364       1.275
human_difficulty                     -0.1078      0.211     -0.511      0.609      -0.522       0.306
q_length                             -0.1125      0.191     -0.588      0.556      -0.487       0.262
avg_word_length                       0.1154      0.190      0.609      0.543      -0.256       0.487
percent_non_alphabetic_whitespace     0.0328      0.020      1.603      0.109      -0.007       0.073
game_entropy                          1.8181      0.230      7.907      0.000       1.367       2.269
=====================================================================================================

                  Model 4.95: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      438
Method:                           MLE   Df Model:                            8
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1620
Time:                        16:14:14   Log-Likelihood:                -228.04
converged:                       True   LL-Null:                       -272.12
Covariance Type:            nonrobust   LLR p-value:                 1.096e-15
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -2.4303      1.734     -1.402      0.161      -5.828       0.967
C(domain_grouped)[T.chemistry]        0.2470      0.419      0.590      0.555      -0.574       1.068
C(domain_grouped)[T.physics]          0.3833      0.423      0.906      0.365      -0.446       1.213
human_difficulty                     -0.0998      0.212     -0.472      0.637      -0.514       0.315
q_length                             -0.1188      0.191     -0.621      0.535      -0.494       0.256
avg_word_length                       0.1309      0.189      0.691      0.489      -0.240       0.502
percent_non_alphabetic_whitespace     0.0335      0.021      1.633      0.103      -0.007       0.074
capabilities_entropy                  0.2870      0.239      1.200      0.230      -0.182       0.756
game_entropy                          1.6489      0.268      6.156      0.000       1.124       2.174
=====================================================================================================

--- Analyzing gemini-2.5-flash-lite_think (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_neutral/gemini-2.5-flash-lite_think_GPQA_neut_redacted_cor_temp1.0_1758206330_game_data.json', './sc_logs_neutral/gemini-2.5-flash-lite_think_GPQA_neut_redacted_temp1.0_1758198560_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    328
1    119
Name: count, dtype: int64

Answer change%: 0.2662 [0.22524629171821187, 0.30719218702899176] (n=447)
P-value vs 25%: 0.4378; P-value vs 0%: 3.791e-37
Phase 2 self-accuracy: 0.3866 [0.2990626922482543, 0.4740465514492247] (n=119)
P-value vs 25%: 0.00222; P-value vs 33%: 0.2303

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.05461
Time:                        16:14:14   Log-Likelihood:                -244.87
converged:                       True   LL-Null:                       -259.02
Covariance Type:            nonrobust   LLR p-value:                 1.044e-07
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept        114.4658     35.784      3.199      0.001      44.330     184.602
p_i_capability  -115.6644     35.824     -3.229      0.001    -185.878     -45.451
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.05852
Time:                        16:14:14   Log-Likelihood:                -243.86
converged:                       True   LL-Null:                       -259.02
Covariance Type:            nonrobust   LLR p-value:                 3.669e-08
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.2314      0.120    -10.252      0.000      -1.467      -0.996
capabilities_entropy    16.7741      4.686      3.579      0.000       7.589      25.959
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.2105 [0.1357, 0.2854] (n=114)
                  P-value vs 33.3%: 0.001299

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=3.95, p=0.0001
Wilcoxon delta_p: statistic=7662.00, p=5.09e-19
Mean Δp = 0.0067  [0.0034, 0.0101]
Idea 1 N = 281; 

  Idea 1.5: Calibration Metrics
  NLL: 1.9568, Signed ECE (overconf pos under neg): -0.0009, ECE: 0.0025 (n=314)
  Brier: 0.0002, Reliability (absolute calibration error; lower better): 0.0001, Resolution (relative calibration quality; higher better): 0.1642, Uncertainty: 0.1642 (n=314)
  AUROC: 1.0000

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.992
Model:                            OLS   Adj. R-squared:                  0.992
Method:                 Least Squares   F-statistic:                 1.434e+04
Date:                Wed, 24 Sep 2025   Prob (F-statistic):               0.00
Time:                        16:14:14   Log-Likelihood:                 682.37
No. Observations:                 346   AIC:                            -1357.
Df Residuals:                     342   BIC:                            -1341.
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.3094      0.806     -0.384      0.701      -1.894       1.275
p1                    0.3164      0.806      0.392      0.695      -1.269       1.902
answer_changed        0.2884      0.808      0.357      0.721      -1.301       1.878
p1:answer_changed     0.6915      0.809      0.855      0.393      -0.899       2.282
==============================================================================
Omnibus:                      150.017   Durbin-Watson:                   1.975
Prob(Omnibus):                  0.000   Jarque-Bera (JB):            38497.926
Skew:                          -0.403   Prob(JB):                         0.00
Kurtosis:                      54.669   Cond. No.                     1.28e+03
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The condition number is large, 1.28e+03. This might indicate that there are
strong multicollinearity or other numerical problems.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-4.07, p=6.17e-05
Wilcoxon delta_H: statistic=14064.00, p=2.5e-05
Mean ΔH = -0.1266  [-0.1876, -0.0656]
Paired t-test delta_H Changed: statistic=19.49, p=6.12e-38
Wilcoxon delta_H Changed: statistic=61.00, p=9.52e-20
Mean ΔH Changed = 0.9117  [0.8200, 1.0034]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=-1.83, p=0.0681
Wilcoxon (p_top2_game vs p_top2_base): statistic=13833.00, p=8.92e-29
Mean Δp_top2 = -0.0021  [-0.0044, 0.0002] (n=395)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=4.93, p=1.21e-06
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=30065.00, p=6.85e-05
Mean ΔH_unchosen_baseline_set = 0.1731  [0.1043, 0.2419] (n=395)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  395
Model:                          Logit   Df Residuals:                      392
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.05194
Time:                        16:14:14   Log-Likelihood:                -225.03
converged:                       True   LL-Null:                       -237.36
Covariance Type:            nonrobust   LLR p-value:                 4.428e-06
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.6890      0.145     -4.744      0.000      -0.974      -0.404
p1_z            -2.9038      0.954     -3.044      0.002      -4.773      -1.034
I(p1_z ** 2)    -0.1515      0.117     -1.298      0.194      -0.380       0.077
================================================================================
AUC = 0.659

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.02229
Time:                        16:14:14   Log-Likelihood:                -253.25
converged:                       True   LL-Null:                       -259.02
Covariance Type:            nonrobust   LLR p-value:                 0.0006781
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.1385      0.115     -9.868      0.000      -1.365      -0.912
game_entropy     1.9980      0.646      3.095      0.002       0.733       3.263
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=21965.00, p=8.46e-25
Paired t-test (game_entropy vs capabilities_entropy): statistic=4.28, p=2.33e-05
Mean game_entropy-capabilities_entropy = 0.0374  [0.0203, 0.0546] (n=447)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      444
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.07015
Time:                        16:14:14   Log-Likelihood:                -240.85
converged:                       True   LL-Null:                       -259.02
Covariance Type:            nonrobust   LLR p-value:                 1.283e-08
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.3131      0.126    -10.383      0.000      -1.561      -1.065
capabilities_entropy    15.6110      4.671      3.342      0.001       6.456      24.766
game_entropy             1.5828      0.668      2.370      0.018       0.274       2.892
========================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.01171
Time:                        16:14:14   Log-Likelihood:                -255.99
converged:                       True   LL-Null:                       -259.02
Covariance Type:            nonrobust   LLR p-value:                   0.01379
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -2.1166      0.468     -4.520      0.000      -3.034      -1.199
human_difficulty     0.4585      0.187      2.453      0.014       0.092       0.825
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      440
Method:                           MLE   Df Model:                            6
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.08025
Time:                        16:14:15   Log-Likelihood:                -238.23
converged:                       True   LL-Null:                       -259.02
Covariance Type:            nonrobust   LLR p-value:                 2.230e-07
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -4.1350      1.627     -2.542      0.011      -7.323      -0.947
C(domain_grouped)[T.chemistry]        1.3743      0.354      3.883      0.000       0.681       2.068
C(domain_grouped)[T.physics]          0.0135      0.376      0.036      0.971      -0.723       0.750
human_difficulty                      0.6185      0.208      2.976      0.003       0.211       1.026
q_length                              0.1289      0.181      0.712      0.477      -0.226       0.484
avg_word_length                       0.0768      0.173      0.443      0.658      -0.263       0.416
percent_non_alphabetic_whitespace    -0.0171      0.021     -0.804      0.422      -0.059       0.025
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 0.0189
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      439
Method:                           MLE   Df Model:                            7
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1157
Time:                        16:14:15   Log-Likelihood:                -229.06
converged:                       True   LL-Null:                       -259.02
Covariance Type:            nonrobust   LLR p-value:                 1.564e-10
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -3.6999      1.664     -2.223      0.026      -6.962      -0.438
C(domain_grouped)[T.chemistry]        1.1655      0.362      3.219      0.001       0.456       1.875
C(domain_grouped)[T.physics]         -0.0386      0.381     -0.101      0.919      -0.786       0.709
human_difficulty                      0.5131      0.214      2.403      0.016       0.095       0.932
q_length                              0.0463      0.188      0.246      0.805      -0.322       0.414
avg_word_length                       0.1235      0.175      0.705      0.481      -0.220       0.467
percent_non_alphabetic_whitespace    -0.0124      0.021     -0.578      0.563      -0.054       0.030
capabilities_entropy                 13.1147      4.875      2.690      0.007       3.560      22.670
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      439
Method:                           MLE   Df Model:                            7
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.09114
Time:                        16:14:15   Log-Likelihood:                -235.41
converged:                       True   LL-Null:                       -259.02
Covariance Type:            nonrobust   LLR p-value:                 5.073e-08
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -3.8237      1.641     -2.330      0.020      -7.040      -0.607
C(domain_grouped)[T.chemistry]        1.2922      0.358      3.609      0.000       0.590       1.994
C(domain_grouped)[T.physics]          0.0001      0.378      0.000      1.000      -0.741       0.741
human_difficulty                      0.5652      0.211      2.684      0.007       0.152       0.978
q_length                              0.0724      0.183      0.395      0.693      -0.287       0.432
avg_word_length                       0.0949      0.174      0.544      0.586      -0.247       0.437
percent_non_alphabetic_whitespace    -0.0150      0.021     -0.699      0.485      -0.057       0.027
game_entropy                          1.4889      0.666      2.235      0.025       0.183       2.794
=====================================================================================================

                  Model 4.95: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      438
Method:                           MLE   Df Model:                            8
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1214
Time:                        16:14:15   Log-Likelihood:                -227.59
converged:                       True   LL-Null:                       -259.02
Covariance Type:            nonrobust   LLR p-value:                 1.271e-10
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -3.4929      1.674     -2.087      0.037      -6.774      -0.212
C(domain_grouped)[T.chemistry]        1.1083      0.365      3.036      0.002       0.393       1.824
C(domain_grouped)[T.physics]         -0.0349      0.382     -0.091      0.927      -0.785       0.715
human_difficulty                      0.4838      0.215      2.251      0.024       0.063       0.905
q_length                              0.0036      0.190      0.019      0.985      -0.368       0.376
avg_word_length                       0.1367      0.176      0.777      0.437      -0.208       0.482
percent_non_alphabetic_whitespace    -0.0106      0.022     -0.491      0.624      -0.053       0.032
capabilities_entropy                 12.7479      4.871      2.617      0.009       3.200      22.295
game_entropy                          1.1542      0.693      1.665      0.096      -0.204       2.513
=====================================================================================================

--- Analyzing gemini-2.5-flash-preview-04-17 (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_neutral/gemini-2.5-flash-preview-04-17_GPQA_redacted_cor_temp0.0_1751846071_game_data.json', './sc_logs_neutral/gemini-2.5-flash-preview-04-17_GPQA_redacted_temp0.0_1751828022_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    350
1     93
Name: count, dtype: int64

Answer change%: 0.2099 [0.1720079428201272, 0.2478566169992859] (n=443)
P-value vs 25%: 0.03838; P-value vs 0%: 2.005e-27
Phase 2 self-accuracy: 0.4409 [0.3399541505419334, 0.5417662795655935] (n=93)
P-value vs 25%: 0.0002096; P-value vs 33%: 0.03617

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  436
Model:                          Logit   Df Residuals:                      434
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.05123
Time:                        16:14:15   Log-Likelihood:                -214.40
converged:                       True   LL-Null:                       -225.98
Covariance Type:            nonrobust   LLR p-value:                 1.496e-06
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.6354      0.144    -11.349      0.000      -1.918      -1.353
game_entropy     1.2857      0.264      4.875      0.000       0.769       1.803
================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  443
Model:                          Logit   Df Residuals:                      441
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                0.008518
Time:                        16:14:15   Log-Likelihood:                -225.70
converged:                       True   LL-Null:                       -227.64
Covariance Type:            nonrobust   LLR p-value:                   0.04892
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -2.2856      0.509     -4.494      0.000      -3.282      -1.289
human_difficulty     0.3993      0.203      1.970      0.049       0.002       0.797
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  443
Model:                          Logit   Df Residuals:                      436
Method:                           MLE   Df Model:                            6
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.04883
Time:                        16:14:15   Log-Likelihood:                -216.53
converged:                       True   LL-Null:                       -227.64
Covariance Type:            nonrobust   LLR p-value:                  0.001100
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -2.4945      1.741     -1.433      0.152      -5.907       0.918
C(domain_grouped)[T.chemistry]        0.5474      0.363      1.510      0.131      -0.163       1.258
C(domain_grouped)[T.physics]         -0.4695      0.393     -1.194      0.232      -1.240       0.301
human_difficulty                      0.5654      0.224      2.527      0.011       0.127       1.004
q_length                             -0.0265      0.194     -0.136      0.891      -0.407       0.354
avg_word_length                      -0.0722      0.190     -0.380      0.704      -0.445       0.300
percent_non_alphabetic_whitespace     0.0234      0.021      1.124      0.261      -0.017       0.064
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  436
Model:                          Logit   Df Residuals:                      428
Method:                           MLE   Df Model:                            7
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.08763
Time:                        16:14:15   Log-Likelihood:                -206.18
converged:                       True   LL-Null:                       -225.98
Covariance Type:            nonrobust   LLR p-value:                 1.498e-06
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -1.6347      1.771     -0.923      0.356      -5.106       1.837
C(domain_grouped)[T.chemistry]        0.2097      0.384      0.546      0.585      -0.543       0.962
C(domain_grouped)[T.physics]         -0.6230      0.403     -1.545      0.122      -1.414       0.167
human_difficulty                      0.5396      0.231      2.333      0.020       0.086       0.993
q_length                             -0.1756      0.202     -0.870      0.384      -0.571       0.220
avg_word_length                      -0.0662      0.190     -0.349      0.727      -0.438       0.306
percent_non_alphabetic_whitespace     0.0230      0.021      1.084      0.278      -0.019       0.065
game_entropy                          1.1432      0.285      4.013      0.000       0.585       1.702
=====================================================================================================

--- Analyzing gemini-2.5-flash_nothink (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_neutral/gemini-2.5-flash_nothink_GPQA_neut_redacted_cor_temp1.0_1757984863_game_data.json', './sc_logs_neutral/gemini-2.5-flash_nothink_GPQA_neut_redacted_temp1.0_1757984658_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    336
1    111
Name: count, dtype: int64

Answer change%: 0.2483 [0.20827072617021533, 0.2883735691317981] (n=447)
P-value vs 25%: 0.9346; P-value vs 0%: 5.602e-34
Phase 2 self-accuracy: 0.2793 [0.19581714941393935, 0.36274140914461916] (n=111)
P-value vs 25%: 0.4917; P-value vs 33%: 0.2071

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1420
Time:                        16:14:15   Log-Likelihood:                -214.96
converged:                       True   LL-Null:                       -250.54
Covariance Type:            nonrobust   LLR p-value:                 3.292e-17
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          1.9041      0.379      5.019      0.000       1.161       2.648
p_i_capability    -4.2536      0.543     -7.831      0.000      -5.318      -3.189
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1208
Time:                        16:14:15   Log-Likelihood:                -220.28
converged:                       True   LL-Null:                       -250.54
Covariance Type:            nonrobust   LLR p-value:                 7.318e-15
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.4585      0.245    -10.053      0.000      -2.938      -1.979
capabilities_entropy     1.3697      0.191      7.173      0.000       0.995       1.744
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.7207 [0.6373, 0.8042] (n=111)
                  P-value vs 33.3%: 9.276e-20

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=-0.65, p=0.518
Wilcoxon delta_p: statistic=27601.00, p=0.692
Mean Δp = -0.0053  [-0.0212, 0.0107]
Idea 1 N = 336; 

  Idea 1.5: Calibration Metrics
  NLL: 1.7304, Signed ECE (overconf pos under neg): -0.0255, ECE: 0.1049 (n=447)
  Brier: 0.0489, Reliability (absolute calibration error; lower better): 0.0242, Resolution (relative calibration quality; higher better): 0.2253, Uncertainty: 0.2498 (n=447)
  AUROC: 0.9964

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.707
Model:                            OLS   Adj. R-squared:                  0.705
Method:                 Least Squares   F-statistic:                     355.2
Date:                Wed, 24 Sep 2025   Prob (F-statistic):          2.43e-117
Time:                        16:14:15   Log-Likelihood:                 260.77
No. Observations:                 446   AIC:                            -513.5
Df Residuals:                     442   BIC:                            -497.1
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.2291      0.030     -7.714      0.000      -0.288      -0.171
p1                    0.2763      0.036      7.781      0.000       0.207       0.346
answer_changed        0.0942      0.050      1.875      0.061      -0.005       0.193
p1:answer_changed     0.6351      0.073      8.726      0.000       0.492       0.778
==============================================================================
Omnibus:                       15.879   Durbin-Watson:                   2.065
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               17.403
Skew:                           0.404   Prob(JB):                     0.000166
Kurtosis:                       3.532   Cond. No.                         18.5
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=1.59, p=0.112
Wilcoxon delta_H: statistic=24578.00, p=0.0363
Mean ΔH = 0.0430  [-0.0098, 0.0958]
Paired t-test delta_H Changed: statistic=5.39, p=4.11e-07
Wilcoxon delta_H Changed: statistic=1441.00, p=9.35e-07
Mean ΔH Changed = 0.2019  [0.1285, 0.2754]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=0.69, p=0.493
Wilcoxon (p_top2_game vs p_top2_base): statistic=48911.00, p=0.673
Mean Δp_top2 = 0.0028  [-0.0052, 0.0107] (n=447)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=3.66, p=0.00028
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=38563.00, p=2.57e-05
Mean ΔH_unchosen_baseline_set = 0.0825  [0.0383, 0.1266] (n=447)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      444
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1482
Time:                        16:14:15   Log-Likelihood:                -213.41
converged:                       True   LL-Null:                       -250.54
Covariance Type:            nonrobust   LLR p-value:                 7.512e-17
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.1071      0.177     -6.241      0.000      -1.455      -0.759
p1_z            -1.1495      0.170     -6.759      0.000      -1.483      -0.816
I(p1_z ** 2)    -0.2672      0.152     -1.754      0.079      -0.566       0.031
================================================================================
AUC = 0.770

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1283
Time:                        16:14:15   Log-Likelihood:                -218.39
converged:                       True   LL-Null:                       -250.54
Covariance Type:            nonrobust   LLR p-value:                 1.069e-15
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -2.5016      0.245    -10.210      0.000      -2.982      -2.021
game_entropy     1.4641      0.198      7.387      0.000       1.076       1.853
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=46368.00, p=0.176
Paired t-test (game_entropy vs capabilities_entropy): statistic=-1.41, p=0.16
Mean game_entropy-capabilities_entropy = -0.0300  [-0.0717, 0.0118] (n=447)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      444
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1432
Time:                        16:14:15   Log-Likelihood:                -214.65
converged:                       True   LL-Null:                       -250.54
Covariance Type:            nonrobust   LLR p-value:                 2.604e-16
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.7065      0.265    -10.215      0.000      -3.226      -2.187
capabilities_entropy     0.7251      0.268      2.709      0.007       0.200       1.250
game_entropy             0.9259      0.278      3.330      0.001       0.381       1.471
========================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                0.001255
Time:                        16:14:15   Log-Likelihood:                -250.22
converged:                       True   LL-Null:                       -250.54
Covariance Type:            nonrobust   LLR p-value:                    0.4277
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -0.7481      0.466     -1.607      0.108      -1.661       0.164
human_difficulty    -0.1525      0.193     -0.790      0.429      -0.531       0.226
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      440
Method:                           MLE   Df Model:                            6
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.02516
Time:                        16:14:15   Log-Likelihood:                -244.23
converged:                       True   LL-Null:                       -250.54
Covariance Type:            nonrobust   LLR p-value:                   0.04970
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -1.2938      1.689     -0.766      0.444      -4.604       2.017
C(domain_grouped)[T.chemistry]        1.0141      0.401      2.530      0.011       0.228       1.800
C(domain_grouped)[T.physics]          1.1073      0.405      2.736      0.006       0.314       1.900
human_difficulty                     -0.0947      0.196     -0.482      0.630      -0.480       0.290
q_length                              0.0298      0.183      0.163      0.870      -0.328       0.388
avg_word_length                      -0.0788      0.195     -0.405      0.686      -0.460       0.303
percent_non_alphabetic_whitespace    -0.0380      0.022     -1.704      0.088      -0.082       0.006
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 0.8397
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      439
Method:                           MLE   Df Model:                            7
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1314
Time:                        16:14:15   Log-Likelihood:                -217.62
converged:                       True   LL-Null:                       -250.54
Covariance Type:            nonrobust   LLR p-value:                 1.020e-11
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -2.2861      1.722     -1.328      0.184      -5.661       1.088
C(domain_grouped)[T.chemistry]        0.3476      0.433      0.802      0.422      -0.501       1.197
C(domain_grouped)[T.physics]          0.6011      0.441      1.364      0.172      -0.262       1.465
human_difficulty                     -0.1556      0.210     -0.741      0.459      -0.567       0.256
q_length                             -0.1222      0.196     -0.623      0.533      -0.506       0.262
avg_word_length                       0.1516      0.191      0.792      0.428      -0.224       0.527
percent_non_alphabetic_whitespace    -0.0227      0.023     -0.974      0.330      -0.068       0.023
capabilities_entropy                  1.3660      0.202      6.754      0.000       0.970       1.762
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      439
Method:                           MLE   Df Model:                            7
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1400
Time:                        16:14:15   Log-Likelihood:                -215.47
converged:                       True   LL-Null:                       -250.54
Covariance Type:            nonrobust   LLR p-value:                 1.391e-12
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -1.8865      1.743     -1.082      0.279      -5.303       1.530
C(domain_grouped)[T.chemistry]        0.2852      0.435      0.655      0.512      -0.568       1.139
C(domain_grouped)[T.physics]          0.5288      0.442      1.196      0.232      -0.338       1.395
human_difficulty                     -0.1703      0.213     -0.799      0.424      -0.588       0.248
q_length                             -0.1321      0.194     -0.681      0.496      -0.512       0.248
avg_word_length                       0.0994      0.194      0.511      0.609      -0.282       0.480
percent_non_alphabetic_whitespace    -0.0292      0.023     -1.257      0.209      -0.075       0.016
game_entropy                          1.4681      0.210      6.999      0.000       1.057       1.879
=====================================================================================================

                  Model 4.95: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      438
Method:                           MLE   Df Model:                            8
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1543
Time:                        16:14:15   Log-Likelihood:                -211.89
converged:                       True   LL-Null:                       -250.54
Covariance Type:            nonrobust   LLR p-value:                 1.707e-13
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -2.1666      1.761     -1.230      0.219      -5.618       1.285
C(domain_grouped)[T.chemistry]        0.1756      0.443      0.396      0.692      -0.693       1.044
C(domain_grouped)[T.physics]          0.4445      0.451      0.987      0.324      -0.439       1.328
human_difficulty                     -0.1777      0.215     -0.826      0.409      -0.599       0.244
q_length                             -0.1535      0.198     -0.776      0.438      -0.541       0.234
avg_word_length                       0.1515      0.196      0.775      0.438      -0.232       0.535
percent_non_alphabetic_whitespace    -0.0246      0.024     -1.043      0.297      -0.071       0.022
capabilities_entropy                  0.7274      0.274      2.655      0.008       0.190       1.264
game_entropy                          0.9507      0.284      3.350      0.001       0.395       1.507
=====================================================================================================

--- Analyzing gemini-2.5-flash_think (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_neutral/gemini-2.5-flash_think_GPQA_neut_redacted_cor_temp1.0_1758279477_game_data.json', './sc_logs_neutral/gemini-2.5-flash_think_GPQA_neut_redacted_temp1.0_1758243352_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    410
1     37
Name: count, dtype: int64

Answer change%: 0.0828 [0.05723059672992752, 0.10831750170407695] (n=447)
P-value vs 25%: 1.094e-37; P-value vs 0%: 2.135e-10
Phase 2 self-accuracy: 0.3784 [0.22210915969490116, 0.5346475970618556] (n=37)
P-value vs 25%: 0.1074; P-value vs 33%: 0.5693

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  411
Model:                          Logit   Df Residuals:                      409
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:               0.0001122
Time:                        16:14:15   Log-Likelihood:                -119.67
converged:                       True   LL-Null:                       -119.68
Covariance Type:            nonrobust   LLR p-value:                    0.8698
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept         -2.1856      1.153     -1.895      0.058      -4.446       0.075
p_i_capability    -0.2039      1.235     -0.165      0.869      -2.624       2.216
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:               2.067e-05
Time:                        16:14:15   Log-Likelihood:                -127.61
converged:                       True   LL-Null:                       -127.62
Covariance Type:            nonrobust   LLR p-value:                    0.9421
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.3969      0.206    -11.631      0.000      -2.801      -1.993
capabilities_entropy    -0.0268      0.371     -0.072      0.942      -0.753       0.699
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.2000 [0.0675, 0.3325] (n=35)
                  P-value vs 33.3%: 0.04861

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=7.03, p=1.24e-11
Wilcoxon delta_p: statistic=12021.00, p=3.25e-18
Mean Δp = 0.0893  [0.0644, 0.1142]
Idea 1 N = 328; 

  Idea 1.5: Calibration Metrics
  NLL: 1.5508, Signed ECE (overconf pos under neg): -0.1299, ECE: 0.1299 (n=347)
  Brier: 0.1043, Reliability (absolute calibration error; lower better): 0.0600, Resolution (relative calibration quality; higher better): 0.0512, Uncertainty: 0.0975 (n=347)
  AUROC: 0.9946

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.366
Model:                            OLS   Adj. R-squared:                  0.361
Method:                 Least Squares   F-statistic:                     65.18
Date:                Wed, 24 Sep 2025   Prob (F-statistic):           2.80e-33
Time:                        16:14:15   Log-Likelihood:                 27.086
No. Observations:                 342   AIC:                            -46.17
Df Residuals:                     338   BIC:                            -30.83
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept             0.2963      0.092      3.216      0.001       0.115       0.478
p1                   -0.2208      0.097     -2.267      0.024      -0.412      -0.029
answer_changed       -0.8434      0.322     -2.620      0.009      -1.477      -0.210
p1:answer_changed     1.7758      0.343      5.183      0.000       1.102       2.450
==============================================================================
Omnibus:                      118.202   Durbin-Watson:                   2.078
Prob(Omnibus):                  0.000   Jarque-Bera (JB):              399.341
Skew:                           1.530   Prob(JB):                     1.92e-87
Kurtosis:                       7.320   Cond. No.                         53.1
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=7.81, p=5.94e-14
Wilcoxon delta_H: statistic=20043.00, p=4.5e-13
Mean ΔH = 0.2528  [0.1894, 0.3163]
Paired t-test delta_H Changed: statistic=3.42, p=0.00165
Wilcoxon delta_H Changed: statistic=142.00, p=0.0038
Mean ΔH Changed = 0.4057  [0.1731, 0.6382]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=-1.63, p=0.104
Wilcoxon (p_top2_game vs p_top2_base): statistic=29430.00, p=1.23e-07
Mean Δp_top2 = -0.0052  [-0.0115, 0.0011] (n=410)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=8.49, p=3.96e-16
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=23499.00, p=8.57e-15
Mean ΔH_unchosen_baseline_set = 0.2659  [0.2045, 0.3273] (n=410)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  410
Model:                          Logit   Df Residuals:                      407
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.01358
Time:                        16:14:15   Log-Likelihood:                -117.97
converged:                       True   LL-Null:                       -119.59
Covariance Type:            nonrobust   LLR p-value:                    0.1970
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -2.6725      0.259    -10.318      0.000      -3.180      -2.165
p1_z             0.5904      0.411      1.437      0.151      -0.215       1.396
I(p1_z ** 2)     0.2650      0.149      1.780      0.075      -0.027       0.557
================================================================================
AUC = 0.452

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.01532
Time:                        16:14:15   Log-Likelihood:                -125.66
converged:                       True   LL-Null:                       -127.62
Covariance Type:            nonrobust   LLR p-value:                   0.04798
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -2.7169      0.247    -11.012      0.000      -3.200      -2.233
game_entropy     0.6665      0.329      2.028      0.043       0.023       1.310
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=36031.00, p=2.82e-07
Paired t-test (game_entropy vs capabilities_entropy): statistic=3.67, p=0.000267
Mean game_entropy-capabilities_entropy = 0.0887  [0.0414, 0.1361] (n=447)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      444
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.01885
Time:                        16:14:15   Log-Likelihood:                -125.21
converged:                       True   LL-Null:                       -127.62
Covariance Type:            nonrobust   LLR p-value:                   0.09020
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.6623      0.251    -10.592      0.000      -3.155      -2.170
capabilities_entropy    -0.3816      0.413     -0.925      0.355      -1.190       0.427
game_entropy             0.8039      0.356      2.257      0.024       0.106       1.502
========================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:               0.0002171
Time:                        16:14:15   Log-Likelihood:                -127.59
converged:                       True   LL-Null:                       -127.62
Covariance Type:            nonrobust   LLR p-value:                    0.8139
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -2.5725      0.733     -3.511      0.000      -4.008      -1.137
human_difficulty     0.0703      0.298      0.236      0.814      -0.514       0.654
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      440
Method:                           MLE   Df Model:                            6
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.02542
Time:                        16:14:15   Log-Likelihood:                -124.37
converged:                       True   LL-Null:                       -127.62
Covariance Type:            nonrobust   LLR p-value:                    0.3708
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -0.1344      2.443     -0.055      0.956      -4.922       4.653
C(domain_grouped)[T.chemistry]       -0.3167      0.470     -0.674      0.500      -1.237       0.604
C(domain_grouped)[T.physics]         -1.1494      0.528     -2.176      0.030      -2.185      -0.114
human_difficulty                      0.0182      0.328      0.056      0.956      -0.624       0.660
q_length                             -0.1221      0.273     -0.447      0.655      -0.657       0.413
avg_word_length                      -0.1928      0.280     -0.689      0.491      -0.741       0.356
percent_non_alphabetic_whitespace    -0.0211      0.034     -0.631      0.528      -0.087       0.045
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 0.3126
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      439
Method:                           MLE   Df Model:                            7
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.02545
Time:                        16:14:15   Log-Likelihood:                -124.37
converged:                       True   LL-Null:                       -127.62
Covariance Type:            nonrobust   LLR p-value:                    0.4833
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -0.1510      2.454     -0.062      0.951      -4.961       4.659
C(domain_grouped)[T.chemistry]       -0.3016      0.507     -0.595      0.552      -1.294       0.691
C(domain_grouped)[T.physics]         -1.1428      0.535     -2.138      0.033      -2.191      -0.095
human_difficulty                      0.0219      0.331      0.066      0.947      -0.627       0.671
q_length                             -0.1193      0.275     -0.433      0.665      -0.659       0.421
avg_word_length                      -0.1943      0.281     -0.691      0.489      -0.745       0.357
percent_non_alphabetic_whitespace    -0.0212      0.034     -0.633      0.527      -0.087       0.045
capabilities_entropy                 -0.0322      0.407     -0.079      0.937      -0.830       0.766
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      439
Method:                           MLE   Df Model:                            7
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.04347
Time:                        16:14:15   Log-Likelihood:                -122.07
converged:                       True   LL-Null:                       -127.62
Covariance Type:            nonrobust   LLR p-value:                    0.1346
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                             0.7647      2.480      0.308      0.758      -4.096       5.626
C(domain_grouped)[T.chemistry]       -0.5718      0.493     -1.160      0.246      -1.538       0.394
C(domain_grouped)[T.physics]         -1.1881      0.532     -2.232      0.026      -2.232      -0.145
human_difficulty                      0.0079      0.333      0.024      0.981      -0.645       0.661
q_length                             -0.3081      0.287     -1.072      0.284      -0.871       0.255
avg_word_length                      -0.1796      0.274     -0.655      0.512      -0.717       0.358
percent_non_alphabetic_whitespace    -0.0325      0.035     -0.933      0.351      -0.101       0.036
game_entropy                          0.8095      0.372      2.178      0.029       0.081       1.538
=====================================================================================================

                  Model 4.95: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      438
Method:                           MLE   Df Model:                            8
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.04629
Time:                        16:14:15   Log-Likelihood:                -121.71
converged:                       True   LL-Null:                       -127.62
Covariance Type:            nonrobust   LLR p-value:                    0.1597
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                             0.6851      2.513      0.273      0.785      -4.240       5.610
C(domain_grouped)[T.chemistry]       -0.4245      0.520     -0.816      0.414      -1.444       0.595
C(domain_grouped)[T.physics]         -1.1143      0.537     -2.077      0.038      -2.166      -0.063
human_difficulty                      0.0431      0.337      0.128      0.898      -0.618       0.705
q_length                             -0.2965      0.287     -1.033      0.302      -0.859       0.266
avg_word_length                      -0.1952      0.280     -0.697      0.486      -0.744       0.354
percent_non_alphabetic_whitespace    -0.0359      0.035     -1.012      0.311      -0.105       0.034
capabilities_entropy                 -0.3664      0.441     -0.831      0.406      -1.231       0.498
game_entropy                          0.9193      0.391      2.349      0.019       0.152       1.686
=====================================================================================================

--- Analyzing gpt-4.1-2025-04-14 (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_neutral/gpt-4.1-2025-04-14_GPQA_neut_redacted_cor_temp1.0_1757986186_game_data.json', './sc_logs_neutral/gpt-4.1-2025-04-14_GPQA_neut_redacted_temp1.0_1757985109_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    352
1     95
Name: count, dtype: int64

Answer change%: 0.2125 [0.17460345748301676, 0.25045247092861633] (n=447)
P-value vs 25%: 0.0528; P-value vs 0%: 4.583e-28
Phase 2 self-accuracy: 0.2526 [0.16525450878533485, 0.340008649109402] (n=95)
P-value vs 25%: 0.9529; P-value vs 33%: 0.07143

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.06724
Time:                        16:14:15   Log-Likelihood:                -215.68
converged:                       True   LL-Null:                       -231.23
Covariance Type:            nonrobust   LLR p-value:                 2.455e-08
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          1.8847      0.570      3.307      0.001       0.768       3.002
p_i_capability    -3.6166      0.645     -5.605      0.000      -4.881      -2.352
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.07697
Time:                        16:14:15   Log-Likelihood:                -213.43
converged:                       True   LL-Null:                       -231.23
Covariance Type:            nonrobust   LLR p-value:                 2.431e-09
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.8188      0.158    -11.538      0.000      -2.128      -1.510
capabilities_entropy     1.3270      0.223      5.948      0.000       0.890       1.764
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.3429 [0.2317, 0.4541] (n=70)
                  P-value vs 33.3%: 0.8667

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=6.45, p=3.25e-08
Wilcoxon delta_p: statistic=208.00, p=2.49e-06
Mean Δp = 0.4057  [0.2824, 0.5291]
Idea 1 N = 55; 

  Idea 1.5: Calibration Metrics
  NLL: 4.6672, Signed ECE (overconf pos under neg): -0.0041, ECE: 0.3479 (n=96)
  Brier: 0.3573, Reliability (absolute calibration error; lower better): 0.1851, Resolution (relative calibration quality; higher better): 0.0251, Uncertainty: 0.1975 (n=96)
  AUROC: 0.4258

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.178
Model:                            OLS   Adj. R-squared:                  0.152
Method:                 Least Squares   F-statistic:                     6.660
Date:                Wed, 24 Sep 2025   Prob (F-statistic):           0.000404
Time:                        16:14:15   Log-Likelihood:                -52.004
No. Observations:                  96   AIC:                             112.0
Df Residuals:                      92   BIC:                             122.3
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.0451      0.268     -0.168      0.867      -0.577       0.487
p1                    0.5654      0.328      1.722      0.088      -0.087       1.218
answer_changed       -0.5138      0.373     -1.377      0.172      -1.255       0.228
p1:answer_changed     0.7829      0.466      1.679      0.097      -0.143       1.709
==============================================================================
Omnibus:                       78.646   Durbin-Watson:                   1.942
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               12.507
Skew:                          -0.561   Prob(JB):                      0.00192
Kurtosis:                       1.634   Cond. No.                         22.1
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=3.35, p=0.00147
Wilcoxon delta_H: statistic=403.00, p=0.00211
Mean ΔH = 0.2477  [0.1029, 0.3926]
Paired t-test delta_H Changed: statistic=3.07, p=0.0038
Wilcoxon delta_H Changed: statistic=222.00, p=0.00611
Mean ΔH Changed = 0.2961  [0.1073, 0.4850]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=4.89, p=4.04e-06
Wilcoxon (p_top2_game vs p_top2_base): statistic=810.00, p=2.9e-08
Mean Δp_top2 = 0.0377  [0.0226, 0.0528] (n=96)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=4.57, p=1.49e-05
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=1200.00, p=3.75e-05
Mean ΔH_unchosen_baseline_set = 0.2684  [0.1532, 0.3836] (n=96)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                   96
Model:                          Logit   Df Residuals:                       93
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.02254
Time:                        16:14:15   Log-Likelihood:                -64.041
converged:                       True   LL-Null:                       -65.518
Covariance Type:            nonrobust   LLR p-value:                    0.2283
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -0.6707      0.345     -1.942      0.052      -1.347       0.006
p1_z            -0.1042      0.221     -0.473      0.636      -0.536       0.328
I(p1_z ** 2)     0.3738      0.273      1.368      0.171      -0.162       0.909
================================================================================
AUC = 0.564

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1493
Time:                        16:14:15   Log-Likelihood:                -196.70
converged:                       True   LL-Null:                       -231.23
Covariance Type:            nonrobust   LLR p-value:                 9.585e-17
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.9369      0.157    -12.338      0.000      -2.245      -1.629
game_entropy     2.6710      0.344      7.756      0.000       1.996       3.346
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=15718.00, p=3.26e-10
Paired t-test (game_entropy vs capabilities_entropy): statistic=-6.10, p=2.28e-09
Mean game_entropy-capabilities_entropy = -0.1295  [-0.1712, -0.0879] (n=447)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      444
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1662
Time:                        16:14:15   Log-Likelihood:                -192.79
converged:                       True   LL-Null:                       -231.23
Covariance Type:            nonrobust   LLR p-value:                 2.019e-17
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.1254      0.178    -11.969      0.000      -2.474      -1.777
capabilities_entropy     0.7333      0.258      2.846      0.004       0.228       1.238
game_entropy             2.2864      0.368      6.210      0.000       1.565       3.008
========================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:               9.580e-05
Time:                        16:14:15   Log-Likelihood:                -231.21
converged:                       True   LL-Null:                       -231.23
Covariance Type:            nonrobust   LLR p-value:                    0.8333
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -1.2091      0.492     -2.459      0.014      -2.173      -0.245
human_difficulty    -0.0425      0.202     -0.210      0.833      -0.439       0.354
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      440
Method:                           MLE   Df Model:                            6
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.02168
Time:                        16:14:15   Log-Likelihood:                -226.21
converged:                       True   LL-Null:                       -231.23
Covariance Type:            nonrobust   LLR p-value:                    0.1236
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -2.5714      1.782     -1.443      0.149      -6.065       0.922
C(domain_grouped)[T.chemistry]        1.2513      0.434      2.886      0.004       0.402       2.101
C(domain_grouped)[T.physics]          0.9782      0.444      2.201      0.028       0.107       1.849
human_difficulty                      0.0483      0.208      0.232      0.817      -0.360       0.457
q_length                              0.0597      0.193      0.309      0.757      -0.318       0.438
avg_word_length                      -0.0037      0.200     -0.019      0.985      -0.396       0.388
percent_non_alphabetic_whitespace    -0.0181      0.022     -0.806      0.420      -0.062       0.026
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 0.3030
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      439
Method:                           MLE   Df Model:                            7
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.08758
Time:                        16:14:15   Log-Likelihood:                -210.98
converged:                       True   LL-Null:                       -231.23
Covariance Type:            nonrobust   LLR p-value:                 1.009e-06
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -3.9440      1.837     -2.147      0.032      -7.545      -0.343
C(domain_grouped)[T.chemistry]        0.8734      0.449      1.944      0.052      -0.007       1.754
C(domain_grouped)[T.physics]          0.7496      0.462      1.622      0.105      -0.156       1.655
human_difficulty                      0.0600      0.218      0.275      0.783      -0.367       0.487
q_length                              0.0487      0.204      0.239      0.811      -0.351       0.448
avg_word_length                       0.2190      0.202      1.082      0.279      -0.178       0.616
percent_non_alphabetic_whitespace -5.066e-05      0.023     -0.002      0.998      -0.044       0.044
capabilities_entropy                  1.2866      0.234      5.494      0.000       0.828       1.746
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      439
Method:                           MLE   Df Model:                            7
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1603
Time:                        16:14:15   Log-Likelihood:                -194.16
converged:                       True   LL-Null:                       -231.23
Covariance Type:            nonrobust   LLR p-value:                 2.150e-13
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -3.5735      1.911     -1.870      0.062      -7.320       0.173
C(domain_grouped)[T.chemistry]        0.8591      0.461      1.862      0.063      -0.045       1.763
C(domain_grouped)[T.physics]          0.6125      0.479      1.279      0.201      -0.326       1.551
human_difficulty                      0.0706      0.230      0.307      0.759      -0.380       0.522
q_length                              0.0150      0.211      0.071      0.943      -0.399       0.429
avg_word_length                       0.1847      0.207      0.893      0.372      -0.221       0.590
percent_non_alphabetic_whitespace    -0.0122      0.023     -0.532      0.595      -0.057       0.033
game_entropy                          2.6489      0.355      7.470      0.000       1.954       3.344
=====================================================================================================

                  Model 4.95: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      438
Method:                           MLE   Df Model:                            8
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1765
Time:                        16:14:15   Log-Likelihood:                -190.42
converged:                       True   LL-Null:                       -231.23
Covariance Type:            nonrobust   LLR p-value:                 2.307e-14
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -4.2060      1.940     -2.168      0.030      -8.008      -0.404
C(domain_grouped)[T.chemistry]        0.7103      0.473      1.502      0.133      -0.216       1.637
C(domain_grouped)[T.physics]          0.5433      0.489      1.112      0.266      -0.415       1.501
human_difficulty                      0.0768      0.232      0.331      0.741      -0.378       0.532
q_length                              0.0079      0.214      0.037      0.970      -0.411       0.427
avg_word_length                       0.2895      0.209      1.385      0.166      -0.120       0.699
percent_non_alphabetic_whitespace    -0.0043      0.023     -0.186      0.852      -0.050       0.041
capabilities_entropy                  0.7397      0.267      2.774      0.006       0.217       1.262
game_entropy                          2.3011      0.373      6.164      0.000       1.569       3.033
=====================================================================================================

--- Analyzing gpt-4o-2024-08-06 (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_neutral/gpt-4o-2024-08-06_GPQA_neut_redacted_cor_temp1.0_1757986489_game_data.json', './sc_logs_neutral/gpt-4o-2024-08-06_GPQA_neut_redacted_temp1.0_1757985389_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    343
1    104
Name: count, dtype: int64

Answer change%: 0.2327 [0.19349246617632646, 0.27183191861114553] (n=447)
P-value vs 25%: 0.3856; P-value vs 0%: 2.524e-31
Phase 2 self-accuracy: 0.2981 [0.21016650224523448, 0.38598734390861167] (n=104)
P-value vs 25%: 0.2838; P-value vs 33%: 0.4362

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1731
Time:                        16:14:15   Log-Likelihood:                -200.51
converged:                       True   LL-Null:                       -242.49
Covariance Type:            nonrobust   LLR p-value:                 5.085e-20
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          2.3107      0.414      5.576      0.000       1.498       3.123
p_i_capability    -5.0791      0.622     -8.163      0.000      -6.299      -3.860
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1563
Time:                        16:14:15   Log-Likelihood:                -204.59
converged:                       True   LL-Null:                       -242.49
Covariance Type:            nonrobust   LLR p-value:                 3.158e-18
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.9516      0.293    -10.061      0.000      -3.527      -2.377
capabilities_entropy     1.7023      0.223      7.633      0.000       1.265       2.139
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.5673 [0.4721, 0.6625] (n=104)
                  P-value vs 33.3%: 1.465e-06

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=-3.57, p=0.000411
Wilcoxon delta_p: statistic=15104.00, p=3.09e-07
Mean Δp = -0.0359  [-0.0556, -0.0162]
Idea 1 N = 302; 

  Idea 1.5: Calibration Metrics
  NLL: 2.1659, Signed ECE (overconf pos under neg): -0.0083, ECE: 0.1046 (n=406)
  Brier: 0.0527, Reliability (absolute calibration error; lower better): 0.0227, Resolution (relative calibration quality; higher better): 0.2057, Uncertainty: 0.2366 (n=406)
  AUROC: 0.9956

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.334
Model:                            OLS   Adj. R-squared:                  0.329
Method:                 Least Squares   F-statistic:                     67.15
Date:                Wed, 24 Sep 2025   Prob (F-statistic):           3.22e-35
Time:                        16:14:15   Log-Likelihood:                 70.686
No. Observations:                 406   AIC:                            -133.4
Df Residuals:                     402   BIC:                            -117.3
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.1733      0.046     -3.789      0.000      -0.263      -0.083
p1                    0.1766      0.057      3.109      0.002       0.065       0.288
answer_changed       -0.0195      0.084     -0.233      0.816      -0.184       0.145
p1:answer_changed     0.5811      0.129      4.514      0.000       0.328       0.834
==============================================================================
Omnibus:                       24.728   Durbin-Watson:                   2.027
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               81.648
Skew:                          -0.035   Prob(JB):                     1.86e-18
Kurtosis:                       5.196   Cond. No.                         19.8
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=5.75, p=2.13e-08
Wilcoxon delta_H: statistic=14041.00, p=5.97e-09
Mean ΔH = 0.1383  [0.0912, 0.1853]
Paired t-test delta_H Changed: statistic=11.17, p=1.9e-19
Wilcoxon delta_H Changed: statistic=206.00, p=4.2e-16
Mean ΔH Changed = 0.4280  [0.3528, 0.5031]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=9.88, p=9.19e-21
Wilcoxon (p_top2_game vs p_top2_base): statistic=14286.00, p=3.23e-30
Mean Δp_top2 = 0.0417  [0.0335, 0.0500] (n=406)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=9.97, p=4.44e-21
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=18815.00, p=3.16e-21
Mean ΔH_unchosen_baseline_set = 0.2125  [0.1707, 0.2542] (n=406)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  406
Model:                          Logit   Df Residuals:                      403
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1519
Time:                        16:14:15   Log-Likelihood:                -195.91
converged:                       True   LL-Null:                       -231.01
Covariance Type:            nonrobust   LLR p-value:                 5.711e-16
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.0868      0.182     -5.960      0.000      -1.444      -0.729
p1_z            -1.1646      0.172     -6.753      0.000      -1.503      -0.827
I(p1_z ** 2)    -0.2877      0.162     -1.781      0.075      -0.604       0.029
================================================================================
AUC = 0.763

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1050
Time:                        16:14:15   Log-Likelihood:                -217.03
converged:                       True   LL-Null:                       -242.49
Covariance Type:            nonrobust   LLR p-value:                 9.637e-13
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -2.2375      0.214    -10.474      0.000      -2.656      -1.819
game_entropy     1.4105      0.209      6.764      0.000       1.002       1.819
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=17588.00, p=1.43e-32
Paired t-test (game_entropy vs capabilities_entropy): statistic=-12.38, p=1.76e-30
Mean game_entropy-capabilities_entropy = -0.2309  [-0.2674, -0.1943] (n=447)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      444
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1571
Time:                        16:14:15   Log-Likelihood:                -204.40
converged:                       True   LL-Null:                       -242.49
Covariance Type:            nonrobust   LLR p-value:                 2.879e-17
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.9517      0.293    -10.071      0.000      -3.526      -2.377
capabilities_entropy     1.5591      0.320      4.874      0.000       0.932       2.186
game_entropy             0.1965      0.317      0.620      0.535      -0.424       0.817
========================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                0.004338
Time:                        16:14:15   Log-Likelihood:                -241.43
converged:                       True   LL-Null:                       -242.49
Covariance Type:            nonrobust   LLR p-value:                    0.1470
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -0.5197      0.477     -1.090      0.276      -1.454       0.415
human_difficulty    -0.2872      0.200     -1.438      0.150      -0.679       0.104
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      440
Method:                           MLE   Df Model:                            6
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.01104
Time:                        16:14:15   Log-Likelihood:                -239.81
converged:                       True   LL-Null:                       -242.49
Covariance Type:            nonrobust   LLR p-value:                    0.4990
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -0.3808      1.694     -0.225      0.822      -3.701       2.940
C(domain_grouped)[T.chemistry]        0.3059      0.375      0.816      0.414      -0.429       1.040
C(domain_grouped)[T.physics]          0.2396      0.382      0.628      0.530      -0.508       0.988
human_difficulty                     -0.2107      0.207     -1.020      0.308      -0.615       0.194
q_length                             -0.0028      0.187     -0.015      0.988      -0.369       0.363
avg_word_length                      -0.1336      0.195     -0.684      0.494      -0.516       0.249
percent_non_alphabetic_whitespace     0.0088      0.020      0.435      0.664      -0.031       0.048
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 0.8514
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      439
Method:                           MLE   Df Model:                            7
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1662
Time:                        16:14:15   Log-Likelihood:                -202.19
converged:                       True   LL-Null:                       -242.49
Covariance Type:            nonrobust   LLR p-value:                 1.047e-14
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -1.7939      1.784     -1.006      0.315      -5.290       1.702
C(domain_grouped)[T.chemistry]       -0.8277      0.448     -1.847      0.065      -1.706       0.050
C(domain_grouped)[T.physics]         -0.7640      0.457     -1.672      0.094      -1.659       0.131
human_difficulty                     -0.1387      0.227     -0.612      0.540      -0.583       0.305
q_length                             -0.0959      0.202     -0.474      0.635      -0.492       0.300
avg_word_length                       0.0168      0.197      0.085      0.932      -0.368       0.402
percent_non_alphabetic_whitespace     0.0217      0.022      1.006      0.314      -0.021       0.064
capabilities_entropy                  1.8390      0.243      7.566      0.000       1.363       2.315
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      439
Method:                           MLE   Df Model:                            7
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1110
Time:                        16:14:15   Log-Likelihood:                -215.56
converged:                       True   LL-Null:                       -242.49
Covariance Type:            nonrobust   LLR p-value:                 2.512e-09
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -1.7135      1.724     -0.994      0.320      -5.093       1.666
C(domain_grouped)[T.chemistry]       -0.4038      0.413     -0.978      0.328      -1.213       0.406
C(domain_grouped)[T.physics]         -0.3217      0.423     -0.760      0.447      -1.152       0.508
human_difficulty                     -0.1587      0.217     -0.730      0.465      -0.585       0.267
q_length                             -0.0859      0.199     -0.431      0.667      -0.477       0.305
avg_word_length                       0.0883      0.192      0.460      0.645      -0.288       0.465
percent_non_alphabetic_whitespace     0.0234      0.021      1.137      0.256      -0.017       0.064
game_entropy                          1.4783      0.225      6.574      0.000       1.038       1.919
=====================================================================================================

                  Model 4.95: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      438
Method:                           MLE   Df Model:                            8
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1673
Time:                        16:14:15   Log-Likelihood:                -201.92
converged:                       True   LL-Null:                       -242.49
Covariance Type:            nonrobust   LLR p-value:                 2.892e-14
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -1.8934      1.794     -1.055      0.291      -5.410       1.623
C(domain_grouped)[T.chemistry]       -0.8343      0.449     -1.858      0.063      -1.714       0.046
C(domain_grouped)[T.physics]         -0.7665      0.459     -1.671      0.095      -1.665       0.132
human_difficulty                     -0.1402      0.227     -0.619      0.536      -0.585       0.304
q_length                             -0.0993      0.203     -0.489      0.625      -0.497       0.298
avg_word_length                       0.0408      0.200      0.204      0.838      -0.352       0.433
percent_non_alphabetic_whitespace     0.0229      0.022      1.057      0.291      -0.020       0.065
capabilities_entropy                  1.6700      0.332      5.028      0.000       1.019       2.321
game_entropy                          0.2408      0.325      0.740      0.459      -0.397       0.878
=====================================================================================================

--- Analyzing gpt-4o-mini (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_neutral/gpt-4o-mini_GPQA_neut_redacted_cor_temp1.0_1757986726_game_data.json', './sc_logs_neutral/gpt-4o-mini_GPQA_neut_redacted_temp1.0_1757985669_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    342
1    105
Name: count, dtype: int64

Answer change%: 0.2349 [0.19559915162998304, 0.27419950608813776] (n=447)
P-value vs 25%: 0.4514; P-value vs 0%: 1.07e-31
Phase 2 self-accuracy: 0.3048 [0.2167177432856282, 0.3928060662381814] (n=105)
P-value vs 25%: 0.2228; P-value vs 33%: 0.5296

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.04002
Time:                        16:14:15   Log-Likelihood:                -233.92
converged:                       True   LL-Null:                       -243.67
Covariance Type:            nonrobust   LLR p-value:                 1.004e-05
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          0.7535      0.443      1.702      0.089      -0.114       1.621
p_i_capability    -2.4672      0.562     -4.387      0.000      -3.569      -1.365
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.04368
Time:                        16:14:15   Log-Likelihood:                -233.03
converged:                       True   LL-Null:                       -243.67
Covariance Type:            nonrobust   LLR p-value:                 3.957e-06
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -1.8461      0.198     -9.302      0.000      -2.235      -1.457
capabilities_entropy     0.9079      0.201      4.519      0.000       0.514       1.302
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.2885 [0.2014, 0.3755] (n=104)
                  P-value vs 33.3%: 0.3125

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=15.61, p=1.92e-40
Wilcoxon delta_p: statistic=5924.00, p=1.25e-27
Mean Δp = 0.4304  [0.3763, 0.4844]
Idea 1 N = 296; 

  Idea 1.5: Calibration Metrics
  NLL: 4.3985, Signed ECE (overconf pos under neg): -0.0441, ECE: 0.3392 (n=399)
  Brier: 0.3363, Reliability (absolute calibration error; lower better): 0.1312, Resolution (relative calibration quality; higher better): 0.0066, Uncertainty: 0.2113 (n=399)
  AUROC: 0.4369

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.249
Model:                            OLS   Adj. R-squared:                  0.244
Method:                 Least Squares   F-statistic:                     43.71
Date:                Wed, 24 Sep 2025   Prob (F-statistic):           2.07e-24
Time:                        16:14:15   Log-Likelihood:                -194.91
No. Observations:                 399   AIC:                             397.8
Df Residuals:                     395   BIC:                             413.8
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.5163      0.102     -5.085      0.000      -0.716      -0.317
p1                    1.1716      0.122      9.573      0.000       0.931       1.412
answer_changed        0.0724      0.175      0.413      0.680      -0.272       0.417
p1:answer_changed     0.0116      0.225      0.052      0.959      -0.430       0.453
==============================================================================
Omnibus:                      692.250   Durbin-Watson:                   1.992
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               50.338
Skew:                          -0.567   Prob(JB):                     1.17e-11
Kurtosis:                       1.680   Cond. No.                         20.0
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=7.59, p=4.21e-13
Wilcoxon delta_H: statistic=11438.00, p=8.59e-13
Mean ΔH = 0.2309  [0.1713, 0.2905]
Paired t-test delta_H Changed: statistic=3.72, p=0.000325
Wilcoxon delta_H Changed: statistic=1614.00, p=0.000464
Mean ΔH Changed = 0.2043  [0.0967, 0.3119]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=4.83, p=1.92e-06
Wilcoxon (p_top2_game vs p_top2_base): statistic=24256.00, p=1.75e-11
Mean Δp_top2 = 0.0171  [0.0101, 0.0240] (n=399)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=8.42, p=7.08e-16
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=21609.00, p=2.1e-15
Mean ΔH_unchosen_baseline_set = 0.2240  [0.1719, 0.2762] (n=399)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  399
Model:                          Logit   Df Residuals:                      396
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.02796
Time:                        16:14:15   Log-Likelihood:                -221.50
converged:                       True   LL-Null:                       -227.87
Covariance Type:            nonrobust   LLR p-value:                  0.001711
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.2046      0.187     -6.447      0.000      -1.571      -0.838
p1_z            -0.3327      0.138     -2.417      0.016      -0.602      -0.063
I(p1_z ** 2)     0.1140      0.145      0.785      0.432      -0.171       0.398
================================================================================
AUC = 0.614

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1313
Time:                        16:14:15   Log-Likelihood:                -211.68
converged:                       True   LL-Null:                       -243.67
Covariance Type:            nonrobust   LLR p-value:                 1.255e-15
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -2.3042      0.212    -10.876      0.000      -2.719      -1.889
game_entropy     1.7536      0.234      7.482      0.000       1.294       2.213
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=33956.00, p=4.95e-08
Paired t-test (game_entropy vs capabilities_entropy): statistic=-5.38, p=1.17e-07
Mean game_entropy-capabilities_entropy = -0.1309  [-0.1785, -0.0832] (n=447)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      444
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1315
Time:                        16:14:15   Log-Likelihood:                -211.64
converged:                       True   LL-Null:                       -243.67
Covariance Type:            nonrobust   LLR p-value:                 1.227e-14
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.3299      0.231    -10.071      0.000      -2.783      -1.876
capabilities_entropy     0.0703      0.249      0.283      0.777      -0.417       0.558
game_entropy             1.7127      0.275      6.233      0.000       1.174       2.251
========================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                0.006045
Time:                        16:14:15   Log-Likelihood:                -242.20
converged:                       True   LL-Null:                       -243.67
Covariance Type:            nonrobust   LLR p-value:                   0.08609
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -0.3853      0.476     -0.809      0.418      -1.318       0.548
human_difficulty    -0.3398      0.200     -1.698      0.089      -0.732       0.052
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      440
Method:                           MLE   Df Model:                            6
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.01162
Time:                        16:14:15   Log-Likelihood:                -240.84
converged:                       True   LL-Null:                       -243.67
Covariance Type:            nonrobust   LLR p-value:                    0.4621
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -1.9268      1.661     -1.160      0.246      -5.183       1.329
C(domain_grouped)[T.chemistry]        0.4816      0.367      1.312      0.189      -0.238       1.201
C(domain_grouped)[T.physics]          0.2446      0.379      0.645      0.519      -0.499       0.988
human_difficulty                     -0.3200      0.207     -1.543      0.123      -0.726       0.086
q_length                              0.1822      0.187      0.973      0.330      -0.185       0.549
avg_word_length                       0.0223      0.184      0.121      0.904      -0.339       0.383
percent_non_alphabetic_whitespace     0.0008      0.021      0.039      0.969      -0.039       0.041
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 0.6558
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      439
Method:                           MLE   Df Model:                            7
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.04916
Time:                        16:14:15   Log-Likelihood:                -231.69
converged:                       True   LL-Null:                       -243.67
Covariance Type:            nonrobust   LLR p-value:                  0.001160
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -2.4178      1.653     -1.462      0.144      -5.659       0.823
C(domain_grouped)[T.chemistry]        0.1158      0.387      0.299      0.765      -0.643       0.874
C(domain_grouped)[T.physics]         -0.0162      0.399     -0.040      0.968      -0.799       0.767
human_difficulty                     -0.2817      0.211     -1.337      0.181      -0.694       0.131
q_length                              0.1532      0.187      0.821      0.412      -0.213       0.519
avg_word_length                       0.0565      0.180      0.314      0.754      -0.296       0.409
percent_non_alphabetic_whitespace     0.0050      0.021      0.239      0.811      -0.036       0.046
capabilities_entropy                  0.8775      0.208      4.210      0.000       0.469       1.286
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      439
Method:                           MLE   Df Model:                            7
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1333
Time:                        16:14:15   Log-Likelihood:                -211.19
converged:                       True   LL-Null:                       -243.67
Covariance Type:            nonrobust   LLR p-value:                 1.526e-11
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -2.3162      1.779     -1.302      0.193      -5.803       1.171
C(domain_grouped)[T.chemistry]       -0.2081      0.406     -0.512      0.609      -1.005       0.588
C(domain_grouped)[T.physics]         -0.1720      0.417     -0.413      0.680      -0.989       0.645
human_difficulty                     -0.1825      0.222     -0.822      0.411      -0.617       0.253
q_length                              0.0645      0.202      0.319      0.750      -0.332       0.461
avg_word_length                       0.0365      0.191      0.191      0.849      -0.338       0.411
percent_non_alphabetic_whitespace     0.0050      0.022      0.223      0.823      -0.039       0.049
game_entropy                          1.7627      0.244      7.220      0.000       1.284       2.241
=====================================================================================================

                  Model 4.95: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      438
Method:                           MLE   Df Model:                            8
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1336
Time:                        16:14:15   Log-Likelihood:                -211.12
converged:                       True   LL-Null:                       -243.67
Covariance Type:            nonrobust   LLR p-value:                 4.582e-11
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -2.3628      1.780     -1.328      0.184      -5.851       1.125
C(domain_grouped)[T.chemistry]       -0.2270      0.410     -0.554      0.580      -1.030       0.576
C(domain_grouped)[T.physics]         -0.1898      0.421     -0.451      0.652      -1.014       0.635
human_difficulty                     -0.1844      0.222     -0.830      0.406      -0.619       0.251
q_length                              0.0663      0.202      0.328      0.743      -0.330       0.462
avg_word_length                       0.0398      0.191      0.209      0.835      -0.334       0.414
percent_non_alphabetic_whitespace     0.0054      0.022      0.242      0.809      -0.038       0.049
capabilities_entropy                  0.0961      0.251      0.382      0.702      -0.397       0.589
game_entropy                          1.7097      0.280      6.105      0.000       1.161       2.259
=====================================================================================================

--- Analyzing grok-3-latest (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_neutral/grok-3-latest_GPQA_redacted_cor_temp0.0_1751833528_game_data.json', './sc_logs_neutral/grok-3-latest_GPQA_redacted_temp0.0_1751825913_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    369
1     78
Name: count, dtype: int64

Answer change%: 0.1745 [0.13931247588832357, 0.20968081270228045] (n=447)
P-value vs 25%: 2.6e-05; P-value vs 0%: 2.466e-22
Phase 2 self-accuracy: 0.2308 [0.1372678412973719, 0.32427062024108966] (n=78)
P-value vs 25%: 0.6869; P-value vs 33%: 0.03212

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.01499
Time:                        16:14:15   Log-Likelihood:                -203.83
converged:                       True   LL-Null:                       -206.94
Covariance Type:            nonrobust   LLR p-value:                   0.01274
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept         -0.5466      0.399     -1.369      0.171      -1.329       0.236
p_i_capability    -1.1763      0.453     -2.598      0.009      -2.064      -0.289
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  433
Model:                          Logit   Df Residuals:                      431
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.09725
Time:                        16:14:15   Log-Likelihood:                -181.58
converged:                       True   LL-Null:                       -201.14
Covariance Type:            nonrobust   LLR p-value:                 3.980e-10
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.2396      0.190    -11.811      0.000      -2.611      -1.868
capabilities_entropy     1.8021      0.291      6.203      0.000       1.233       2.372
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.8000 [0.7095, 0.8905] (n=75)
                  P-value vs 33.3%: 5.323e-24

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=0.01, p=0.995
Wilcoxon delta_p: statistic=21836.00, p=1.57e-05
Mean Δp = 0.0000  [-0.0140, 0.0141]
Idea 1 N = 345; 

  Idea 1.5: Calibration Metrics
  NLL: 3.7898, Signed ECE (overconf pos under neg): 0.0021, ECE: 0.0384 (n=420)
  Brier: 0.0094, Reliability (absolute calibration error; lower better): 0.0079, Resolution (relative calibration quality; higher better): 0.2470, Uncertainty: 0.2482 (n=420)
  AUROC: 1.0000

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.850
Model:                            OLS   Adj. R-squared:                  0.849
Method:                 Least Squares   F-statistic:                     784.3
Date:                Wed, 24 Sep 2025   Prob (F-statistic):          8.90e-171
Time:                        16:14:16   Log-Likelihood:                 286.61
No. Observations:                 420   AIC:                            -565.2
Df Residuals:                     416   BIC:                            -549.1
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.5360      0.055     -9.684      0.000      -0.645      -0.427
p1                    0.5698      0.058      9.755      0.000       0.455       0.685
answer_changed        0.3887      0.091      4.251      0.000       0.209       0.568
p1:answer_changed     0.4671      0.104      4.513      0.000       0.264       0.671
==============================================================================
Omnibus:                      117.878   Durbin-Watson:                   2.204
Prob(Omnibus):                  0.000   Jarque-Bera (JB):              396.029
Skew:                           1.255   Prob(JB):                     1.01e-86
Kurtosis:                       7.041   Cond. No.                         34.0
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-0.90, p=0.367
Wilcoxon delta_H: statistic=27872.00, p=0.288
Mean ΔH = -0.0249  [-0.0790, 0.0292]
Paired t-test delta_H Changed: statistic=5.38, p=8.25e-07
Wilcoxon delta_H Changed: statistic=425.00, p=1.29e-07
Mean ΔH Changed = 0.2416  [0.1537, 0.3296]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=1.89, p=0.0596
Wilcoxon (p_top2_game vs p_top2_base): statistic=24980.00, p=1.13e-14
Mean Δp_top2 = 0.0042  [-0.0002, 0.0086] (n=420)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=0.92, p=0.356
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=41760.00, p=0.326
Mean ΔH_unchosen_baseline_set = 0.0227  [-0.0254, 0.0708] (n=420)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  420
Model:                          Logit   Df Residuals:                      417
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.09713
Time:                        16:14:16   Log-Likelihood:                -177.93
converged:                       True   LL-Null:                       -197.07
Covariance Type:            nonrobust   LLR p-value:                 4.863e-09
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.4597      0.162     -8.984      0.000      -1.778      -1.141
p1_z            -1.1217      0.240     -4.681      0.000      -1.591      -0.652
I(p1_z ** 2)    -0.2321      0.103     -2.262      0.024      -0.433      -0.031
================================================================================
AUC = 0.780

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1011
Time:                        16:14:16   Log-Likelihood:                -186.02
converged:                       True   LL-Null:                       -206.94
Covariance Type:            nonrobust   LLR p-value:                 9.919e-11
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -2.1971      0.181    -12.171      0.000      -2.551      -1.843
game_entropy     1.8614      0.295      6.309      0.000       1.283       2.440
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=34672.00, p=2.31e-06
Paired t-test (game_entropy vs capabilities_entropy): statistic=-1.82, p=0.0689
Mean game_entropy-capabilities_entropy = -0.0348  [-0.0723, 0.0026] (n=433)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  433
Model:                          Logit   Df Residuals:                      430
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1310
Time:                        16:14:16   Log-Likelihood:                -174.80
converged:                       True   LL-Null:                       -201.14
Covariance Type:            nonrobust   LLR p-value:                 3.626e-12
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.4674      0.210    -11.754      0.000      -2.879      -2.056
capabilities_entropy     1.2785      0.327      3.912      0.000       0.638       1.919
game_entropy             1.2305      0.330      3.732      0.000       0.584       1.877
========================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                0.002244
Time:                        16:14:16   Log-Likelihood:                -206.47
converged:                       True   LL-Null:                       -206.94
Covariance Type:            nonrobust   LLR p-value:                    0.3352
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -1.0566      0.529     -1.996      0.046      -2.094      -0.019
human_difficulty    -0.2119      0.221     -0.958      0.338      -0.645       0.222
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      440
Method:                           MLE   Df Model:                            6
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.01463
Time:                        16:14:16   Log-Likelihood:                -203.91
converged:                       True   LL-Null:                       -206.94
Covariance Type:            nonrobust   LLR p-value:                    0.4170
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -2.3180      1.914     -1.211      0.226      -6.069       1.433
C(domain_grouped)[T.chemistry]        0.9430      0.463      2.036      0.042       0.035       1.851
C(domain_grouped)[T.physics]          0.8717      0.473      1.844      0.065      -0.055       1.798
human_difficulty                     -0.1344      0.226     -0.596      0.551      -0.576       0.308
q_length                              0.0632      0.208      0.303      0.762      -0.345       0.472
avg_word_length                    2.558e-05      0.216      0.000      1.000      -0.422       0.422
percent_non_alphabetic_whitespace    -0.0091      0.024     -0.385      0.700      -0.055       0.037
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 0.2951
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  433
Model:                          Logit   Df Residuals:                      425
Method:                           MLE   Df Model:                            7
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1028
Time:                        16:14:16   Log-Likelihood:                -180.46
converged:                       True   LL-Null:                       -201.14
Covariance Type:            nonrobust   LLR p-value:                 6.866e-07
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -3.5230      1.970     -1.788      0.074      -7.384       0.338
C(domain_grouped)[T.chemistry]        0.4761      0.488      0.976      0.329      -0.480       1.432
C(domain_grouped)[T.physics]          0.4047      0.508      0.796      0.426      -0.591       1.401
human_difficulty                     -0.2060      0.239     -0.862      0.389      -0.674       0.262
q_length                              0.1347      0.220      0.612      0.540      -0.297       0.566
avg_word_length                       0.1249      0.216      0.579      0.563      -0.298       0.548
percent_non_alphabetic_whitespace     0.0027      0.024      0.114      0.909      -0.044       0.050
capabilities_entropy                  1.7811      0.300      5.936      0.000       1.193       2.369
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      439
Method:                           MLE   Df Model:                            7
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1114
Time:                        16:14:16   Log-Likelihood:                -183.89
converged:                       True   LL-Null:                       -206.94
Covariance Type:            nonrobust   LLR p-value:                 8.362e-08
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -4.0015      1.988     -2.012      0.044      -7.899      -0.104
C(domain_grouped)[T.chemistry]        0.7814      0.491      1.590      0.112      -0.182       1.745
C(domain_grouped)[T.physics]          0.8273      0.506      1.634      0.102      -0.165       1.820
human_difficulty                     -0.1593      0.235     -0.678      0.498      -0.619       0.301
q_length                              0.1194      0.222      0.537      0.591      -0.316       0.555
avg_word_length                       0.1498      0.217      0.690      0.490      -0.276       0.575
percent_non_alphabetic_whitespace     0.0099      0.025      0.395      0.693      -0.039       0.059
game_entropy                          1.8558      0.299      6.200      0.000       1.269       2.442
=====================================================================================================

                  Model 4.95: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  433
Model:                          Logit   Df Residuals:                      424
Method:                           MLE   Df Model:                            8
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1370
Time:                        16:14:16   Log-Likelihood:                -173.59
converged:                       True   LL-Null:                       -201.14
Covariance Type:            nonrobust   LLR p-value:                 4.226e-09
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -4.1548      2.020     -2.057      0.040      -8.114      -0.196
C(domain_grouped)[T.chemistry]        0.4658      0.505      0.923      0.356      -0.524       1.455
C(domain_grouped)[T.physics]          0.4740      0.525      0.902      0.367      -0.556       1.504
human_difficulty                     -0.2062      0.243     -0.850      0.396      -0.682       0.270
q_length                              0.1512      0.227      0.667      0.505      -0.293       0.596
avg_word_length                       0.1684      0.218      0.771      0.440      -0.260       0.596
percent_non_alphabetic_whitespace     0.0119      0.025      0.478      0.632      -0.037       0.061
capabilities_entropy                  1.2421      0.338      3.677      0.000       0.580       1.904
game_entropy                          1.2556      0.335      3.750      0.000       0.599       1.912
=====================================================================================================

--- Analyzing qwen3-235b-a22b-2507 (Redacted, 2 game files) ---
              Game files for analysis: ['./sc_logs_neutral/qwen3-235b-a22b-2507_GPQA_neut_redacted_cor_temp0.0_1756232480_game_data.json', './sc_logs_neutral/qwen3-235b-a22b-2507_GPQA_neut_redacted_temp0.0_1756230853_game_data.json']

                  Delegation to teammate occurred: Not found
                  Phase 1 self-accuracy (from completed results, total - phase2): Not found
                  Phase 2 self-accuracy: Not found
                  Statistical test (P2 self vs P1): Not found
df_model['answer_changed'].value_counts()= answer_changed
0    357
1     90
Name: count, dtype: int64

Answer change%: 0.2013 [0.16416803583224268, 0.23851652792614655] (n=447)
P-value vs 25%: 0.01031; P-value vs 0%: 2.524e-26
Phase 2 self-accuracy: 0.2778 [0.18524171663788147, 0.3703138389176741] (n=90)
P-value vs 25%: 0.5563; P-value vs 33%: 0.2421

  Model 1.4: Answer Changed ~ capabilities_prob
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1327
Time:                        16:14:16   Log-Likelihood:                -194.72
converged:                       True   LL-Null:                       -224.51
Covariance Type:            nonrobust   LLR p-value:                 1.173e-14
==================================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept          3.0018      0.582      5.161      0.000       1.862       4.142
p_i_capability    -5.1093      0.684     -7.473      0.000      -6.449      -3.769
==================================================================================

  Model 1.5: Answer Changed ~ capabilities_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1399
Time:                        16:14:16   Log-Likelihood:                -193.10
converged:                       True   LL-Null:                       -224.51
Covariance Type:            nonrobust   LLR p-value:                 2.260e-15
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.2592      0.190    -11.875      0.000      -2.632      -1.886
capabilities_entropy     1.7610      0.232      7.593      0.000       1.306       2.216
========================================================================================

  Idea 0: On Change trials, second-choice token in baseline gets selected in the game more often than chance (33%)
                  Proportion of changes to 2nd choice: 0.7778 [0.6919, 0.8637] (n=90)
                  P-value vs 33.3%: 3.602e-24

  Idea 1: Chosen token in baseline gets lower prob in game even when the answer does not change
Paired t-test delta_p: statistic=0.98, p=0.33
Wilcoxon delta_p: statistic=17508.00, p=0.161
Mean Δp = 0.0106  [-0.0107, 0.0318]
Idea 1 N = 283; 

  Idea 1.5: Calibration Metrics
  NLL: 6.9687, Signed ECE (overconf pos under neg): -0.0119, ECE: 0.0560 (n=357)
  Brier: 0.0262, Reliability (absolute calibration error; lower better): 0.0139, Resolution (relative calibration quality; higher better): 0.2335, Uncertainty: 0.2457 (n=357)
  AUROC: 0.9967

  Idea 2: Decrease in game prob of chosen token scales with its baseline probability
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                delta_p   R-squared:                       0.723
Model:                            OLS   Adj. R-squared:                  0.720
Method:                 Least Squares   F-statistic:                     315.5
Date:                Wed, 24 Sep 2025   Prob (F-statistic):          9.72e-101
Time:                        16:14:16   Log-Likelihood:                 143.13
No. Observations:                 367   AIC:                            -278.3
Df Residuals:                     363   BIC:                            -262.6
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================
                        coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.6573      0.062    -10.601      0.000      -0.779      -0.535
p1                    0.7298      0.067     10.908      0.000       0.598       0.861
answer_changed        0.4782      0.094      5.062      0.000       0.292       0.664
p1:answer_changed     0.2447      0.113      2.162      0.031       0.022       0.467
==============================================================================
Omnibus:                       38.507   Durbin-Watson:                   1.930
Prob(Omnibus):                  0.000   Jarque-Bera (JB):              139.246
Skew:                           0.371   Prob(JB):                     5.80e-31
Kurtosis:                       5.925   Cond. No.                         25.4
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

  Idea 3: Entropy of unchosen tokens in game is lower than in baseline when the answer doesn't change
Paired t-test delta_H: statistic=-5.94, p=8.41e-09
Wilcoxon delta_H: statistic=12524.00, p=6e-08
Mean ΔH = -0.2063  [-0.2744, -0.1382]
Paired t-test delta_H Changed: statistic=4.21, p=6.38e-05
Wilcoxon delta_H Changed: statistic=861.00, p=6.22e-05
Mean ΔH Changed = 0.2161  [0.1156, 0.3167]

  Idea 4: Percentage of probability mass devoted to top two tokens in the game is higher than in baseline (sharpening)
Paired t-test (p_top2_game vs p_top2_base): statistic=1.47, p=0.143
Wilcoxon (p_top2_game vs p_top2_base): statistic=31081.00, p=0.187
Mean Δp_top2 = 0.0046  [-0.0016, 0.0108] (n=367)

  Idea 4.5: Game entropy over the tokens that were NOT the top token in the baseline is lower than over the same tokens in the baseline
Paired t-test (H_base_set_in_base vs H_base_set_in_game): statistic=-3.58, p=0.000395
Wilcoxon (H_base_set_in_base vs H_base_set_in_game): statistic=27389.00, p=0.00289
Mean ΔH_unchosen_baseline_set = -0.1097  [-0.1697, -0.0496] (n=367)

  Model 1.51: Answer Changed ~ p1_z + I(p1_z**2)
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  367
Model:                          Logit   Df Residuals:                      364
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1348
Time:                        16:14:16   Log-Likelihood:                -170.81
converged:                       True   LL-Null:                       -197.42
Covariance Type:            nonrobust   LLR p-value:                 2.780e-12
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -1.1532      0.185     -6.220      0.000      -1.517      -0.790
p1_z            -1.1945      0.236     -5.064      0.000      -1.657      -0.732
I(p1_z ** 2)    -0.2620      0.143     -1.827      0.068      -0.543       0.019
================================================================================
AUC = 0.744

  Model 1.6: Answer Changed ~ Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1359
Time:                        16:14:16   Log-Likelihood:                -193.99
converged:                       True   LL-Null:                       -224.51
Covariance Type:            nonrobust   LLR p-value:                 5.589e-15
================================================================================
                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept       -2.2643      0.192    -11.811      0.000      -2.640      -1.889
game_entropy     1.8928      0.253      7.471      0.000       1.396       2.389
================================================================================

  Idea 5: Game entropy is different than capabilities entropy
Wilcoxon (game_entropy vs capabilities_entropy): statistic=40728.00, p=0.247
Paired t-test (game_entropy vs capabilities_entropy): statistic=-0.80, p=0.425
Mean game_entropy-capabilities_entropy = -0.0208  [-0.0718, 0.0302] (n=447)

  Model 1.7: Answer Changed ~ capabilities_entropy + Game Entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      444
Method:                           MLE   Df Model:                            2
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.2104
Time:                        16:14:16   Log-Likelihood:                -177.27
converged:                       True   LL-Null:                       -224.51
Covariance Type:            nonrobust   LLR p-value:                 3.038e-21
========================================================================================
                           coef    std err          z      P>|z|      [0.025      0.975]
----------------------------------------------------------------------------------------
Intercept               -2.7989      0.237    -11.800      0.000      -3.264      -2.334
capabilities_entropy     1.4091      0.247      5.710      0.000       0.925       1.893
game_entropy             1.5243      0.273      5.586      0.000       0.989       2.059
========================================================================================

  Model 2: Answer Changed ~ human_difficulty
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      445
Method:                           MLE   Df Model:                            1
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:               0.0004541
Time:                        16:14:16   Log-Likelihood:                -224.41
converged:                       True   LL-Null:                       -224.51
Covariance Type:            nonrobust   LLR p-value:                    0.6516
====================================================================================
                       coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -1.1575      0.501     -2.309      0.021      -2.140      -0.175
human_difficulty    -0.0933      0.207     -0.451      0.652      -0.499       0.313
====================================================================================
                  Grouped rare domain into 'Misc'/'Other': None

                  Model 4 (No Interactions): answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      440
Method:                           MLE   Df Model:                            6
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                 0.03464
Time:                        16:14:16   Log-Likelihood:                -216.73
converged:                       True   LL-Null:                       -224.51
Covariance Type:            nonrobust   LLR p-value:                   0.01635
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                             0.7193      1.844      0.390      0.697      -2.895       4.334
C(domain_grouped)[T.chemistry]        0.3518      0.385      0.913      0.361      -0.403       1.107
C(domain_grouped)[T.physics]         -0.3698      0.406     -0.911      0.362      -1.166       0.426
human_difficulty                      0.0325      0.225      0.144      0.885      -0.408       0.473
q_length                             -0.0557      0.200     -0.278      0.781      -0.448       0.336
avg_word_length                      -0.4291      0.222     -1.930      0.054      -0.865       0.007
percent_non_alphabetic_whitespace     0.0091      0.021      0.428      0.668      -0.033       0.051
=====================================================================================================

                  Model 4.6: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy
Mean capabilities_entropy = 0.3771
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      439
Method:                           MLE   Df Model:                            7
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1714
Time:                        16:14:16   Log-Likelihood:                -186.02
converged:                       True   LL-Null:                       -224.51
Covariance Type:            nonrobust   LLR p-value:                 5.695e-14
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                             0.0696      1.960      0.036      0.972      -3.772       3.911
C(domain_grouped)[T.chemistry]       -0.3234      0.427     -0.758      0.449      -1.160       0.513
C(domain_grouped)[T.physics]         -0.9352      0.449     -2.085      0.037      -1.814      -0.056
human_difficulty                      0.0717      0.247      0.290      0.771      -0.412       0.556
q_length                             -0.0273      0.216     -0.126      0.899      -0.451       0.396
avg_word_length                      -0.4541      0.240     -1.889      0.059      -0.925       0.017
percent_non_alphabetic_whitespace     0.0217      0.023      0.939      0.348      -0.024       0.067
capabilities_entropy                  1.8227      0.245      7.433      0.000       1.342       2.303
=====================================================================================================

                  Model 4.8: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      439
Method:                           MLE   Df Model:                            7
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.1559
Time:                        16:14:16   Log-Likelihood:                -189.50
converged:                       True   LL-Null:                       -224.51
Covariance Type:            nonrobust   LLR p-value:                 1.470e-12
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -0.9900      1.973     -0.502      0.616      -4.856       2.876
C(domain_grouped)[T.chemistry]       -0.0737      0.418     -0.176      0.860      -0.892       0.745
C(domain_grouped)[T.physics]         -0.6934      0.442     -1.570      0.116      -1.559       0.172
human_difficulty                      0.0579      0.241      0.240      0.810      -0.415       0.531
q_length                             -0.0179      0.213     -0.084      0.933      -0.436       0.400
avg_word_length                      -0.2575      0.227     -1.134      0.257      -0.703       0.188
percent_non_alphabetic_whitespace     0.0198      0.023      0.873      0.383      -0.025       0.064
game_entropy                          1.8588      0.264      7.048      0.000       1.342       2.376
=====================================================================================================

                  Model 4.95: answer_changed ~ human_difficulty + q_length + C(domain_grouped) + avg_word_length + percent_non_alphabetic_whitespace + capabilities_entropy + game_entropy
                           Logit Regression Results                           
==============================================================================
Dep. Variable:         answer_changed   No. Observations:                  447
Model:                          Logit   Df Residuals:                      438
Method:                           MLE   Df Model:                            8
Date:                Wed, 24 Sep 2025   Pseudo R-squ.:                  0.2347
Time:                        16:14:16   Log-Likelihood:                -171.81
converged:                       True   LL-Null:                       -224.51
Covariance Type:            nonrobust   LLR p-value:                 3.361e-19
=====================================================================================================
                                        coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            -1.4153      2.039     -0.694      0.488      -5.412       2.582
C(domain_grouped)[T.chemistry]       -0.5527      0.454     -1.218      0.223      -1.442       0.337
C(domain_grouped)[T.physics]         -1.0597      0.472     -2.245      0.025      -1.985      -0.135
human_difficulty                      0.0963      0.254      0.379      0.705      -0.402       0.595
q_length                              0.0220      0.224      0.098      0.922      -0.418       0.462
avg_word_length                      -0.3059      0.240     -1.273      0.203      -0.777       0.165
percent_non_alphabetic_whitespace     0.0294      0.024      1.222      0.222      -0.018       0.077
capabilities_entropy                  1.5151      0.261      5.812      0.000       1.004       2.026
game_entropy                          1.5091      0.287      5.266      0.000       0.947       2.071
=====================================================================================================
